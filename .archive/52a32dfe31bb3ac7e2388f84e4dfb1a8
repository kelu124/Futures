<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Predicting sex from retinal fundus photographs using automated deep learning | Scientific Reports</title>
    
        
    

<link rel="preconnect" href="https://push-content.springernature.io" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"computer-science;translational-research","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Scientific Reports","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/s41598-021-89743-x"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":true,"legacy":{"webtrendsLicenceType":"http://creativecommons.org/licenses/by/4.0/"}}},"contentInfo":{"authors":["Edward Korot","Nikolas Pontikos","Xiaoxuan Liu","Siegfried K. Wagner","Livia Faes","Josef Huemer","Konstantinos Balaskas","Alastair K. Denniston","Anthony Khawaja","Pearse A. Keane"],"publishedAt":1620864000,"publishedAtString":"2021-05-13","title":"Predicting sex from retinal fundus photographs using automated deep learning","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"srep","title":"scientific reports","volume":"11","issue":"1"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"recommendationAB","active":false}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"FR","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { html{text-size-adjust:100%;box-sizing:border-box;font-family:sans-serif;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:1.76;min-height:100%}article,aside,header,main,nav,section{display:block}h1{font-size:2em}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}svg:not(:root){overflow:hidden}button,input,select{font-family:sans-serif;font-size:100%;line-height:1.15}select{margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;cursor:pointer}.c-card--major .c-card__title,.u-h1,.u-h2,button,h1{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-card--major .c-card__title,.u-h1,.u-h2,h1{font-weight:700}h1{font-size:2rem;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2{font-size:1.5rem;letter-spacing:-.0117156rem;line-height:1.6rem;margin-bottom:8px}.u-h3,h2{letter-spacing:-.0117156rem}h2{font-size:1.5rem;line-height:1.6rem}.u-h3{font-size:1.25rem;margin-bottom:8px}.c-card__title,.u-h3,h2{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-weight:700}.c-card__title,.u-h3{line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title{font-size:1.25rem;margin-bottom:8px}.c-card__title,h3{font-size:1.25rem}.u-h4{margin-bottom:8px}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-reading-companion__figure-title,.u-h4,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4{font-size:1.125rem}body,button,div,form,h1,h2,h3,input{margin:0;padding:0}p{padding:0}nav ol,nav ul{list-style:none none}body{font-size:1.125rem}p{margin:0 0 28px}ol,ul{margin-bottom:28px;margin-top:0}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-identifiers__open{color:#b74616}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg{margin:1px 4px 0 0}.c-article-author-list__button:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;display:inline-block;font-size:.875rem;font-weight:700;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px;text-decoration:none}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-editorial-summary__container .c-article-editorial-summary__button:focus{outline:3px solid #fece3e;will-change:transform}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px!important}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a{color:inherit}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__list--inline>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.c-header__menu--global svg,.js .c-author-list__hide{display:none;visibility:hidden}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}.c-breadcrumbs__chevron{fill:#888;margin:4px 4px 0}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px;padding:0}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:768px){.u-show-at-md{display:block;visibility:visible}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-link-inherit{color:inherit}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-text-bold{font-weight:700}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px} }</style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-423f305a02.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-423f305a02.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-f85fef52e3.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://collect.nature.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                e.src = 'https://cmp-static.nature.com/production_live/consent-bundle-8-14.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        var polyfillsUrl = function() {
            var features = {
                'IntersectionObserver': window.IntersectionObserver,
                'Promise': window.Promise,
                'URLSearchParams': window.URLSearchParams,
                'Symbol.iterator': window.Symbol && Symbol.iterator,
                'Array.from': Array.from,
                'Array.prototype.includes': Array.prototype.includes,
                'Array.prototype.find': Array.prototype.find,
                'Array.prototype.forEach': Array.prototype.forEach,
                'NodeList.prototype.forEach': NodeList.prototype.forEach,
                'Element.prototype.closest': Element.prototype.closest,
                'Element.prototype.prepend': Element.prototype.prepend,
                'Element.prototype.remove': Element.prototype.remove,
                'Object.assign': Object.assign
            };
            var req = [];
            for (var feature in features) {
                if (Object.prototype.hasOwnProperty.call(features, feature) && !features[feature]) {
                    req.push(feature);
                }
            }
            if (req.length) {
                return 'https://polyfill.io/v3/polyfill.min.js?features=' + req.join('%2C') + '&flags=always';
            }
            return null;
        };

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    {src: polyfillsUrl(), test: 'polyfills-js', noinit: true},
                    
                        {src: '/static/js/global-article-es6-bundle-fa1413f1cb.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-feaa239d4d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-f2b2e65421.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-1210870038.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-c634a291c7.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        
                            var conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-885b4d4cd7.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-6a76e92cf3.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-8756d483f5.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-25e28a6fc8.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>



<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Predicting sex from retinal fundus photographs using automated deep learning","description":"Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers.","datePublished":"2021-05-13","dateModified":"2021-05-13","pageStart":"1","pageEnd":"8","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1038/s41598-021-89743-x","keywords":"Computer science,Translational research,Science,Humanities and Social Sciences,multidisciplinary","image":"https://static-content.springer.com/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig1_HTML.png","isPartOf":{"name":"Scientific Reports","issn":["2045-2322"],"volumeNumber":"11","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Korot, Edward","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Pontikos, Nikolas","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Liu, Xiaoxuan","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"University Hospitals Birmingham NHS Foundation Trust","address":{"name":"Department of Ophthalmology, University Hospitals Birmingham NHS Foundation Trust, Birmingham, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Birmingham","address":{"name":"Academic Unit of Ophthalmology, Institute of Inflammation & Ageing, College of Medical and Dental Sciences, University of Birmingham, Birmingham, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Wagner, Siegfried K.","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Faes, Livia","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"Eye Clinic, Cantonal Hospital of Lucerne","address":{"name":"Eye Clinic, Cantonal Hospital of Lucerne, Lucerne, Switzerland","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Huemer, Josef","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"Vienna Institute for Research in Ocular Surgery, A Karl Landsteiner Institute, Hanusch Hospital","address":{"name":"Vienna Institute for Research in Ocular Surgery, A Karl Landsteiner Institute, Hanusch Hospital, Vienna, Austria","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Balaskas, Konstantinos","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Denniston, Alastair K.","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"University Hospitals Birmingham NHS Foundation Trust","address":{"name":"Department of Ophthalmology, University Hospitals Birmingham NHS Foundation Trust, Birmingham, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Birmingham","address":{"name":"Academic Unit of Ophthalmology, Institute of Inflammation & Ageing, College of Medical and Dental Sciences, University of Birmingham, Birmingham, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"Health Data Research UK","address":{"name":"Health Data Research UK, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Khawaja, Anthony","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"email":"anthony.khawaja@nhs.net","@type":"Person"},{"name":"Keane, Pearse A.","affiliation":[{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology","address":{"name":"NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"email":"pearse.keane1@nhs.net","@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>






    
        
        
        
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41598-021-89743-x">
    
    
    <meta name="journal_id" content="41598"/>
    <meta name="dc.title" content="Predicting sex from retinal fundus photographs using automated deep learning"/>
    <meta name="dc.source" content="Scientific Reports 2021 11:1"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2021-05-13"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2021 The Author(s)"/>
    <meta name="dc.rights" content="2021 The Author(s)"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p&#8201;=&#8201;0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers."/>
    <meta name="prism.issn" content="2045-2322"/>
    <meta name="prism.publicationName" content="Scientific Reports"/>
    <meta name="prism.publicationDate" content="2021-05-13"/>
    <meta name="prism.volume" content="11"/>
    <meta name="prism.number" content="1"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="1"/>
    <meta name="prism.endingPage" content="8"/>
    <meta name="prism.copyright" content="2021 The Author(s)"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41598-021-89743-x"/>
    <meta name="prism.doi" content="doi:10.1038/s41598-021-89743-x"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41598-021-89743-x.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41598-021-89743-x"/>
    <meta name="citation_journal_title" content="Scientific Reports"/>
    <meta name="citation_journal_abbrev" content="Sci Rep"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="2045-2322"/>
    <meta name="citation_title" content="Predicting sex from retinal fundus photographs using automated deep learning"/>
    <meta name="citation_volume" content="11"/>
    <meta name="citation_issue" content="1"/>
    <meta name="citation_online_date" content="2021/05/13"/>
    <meta name="citation_firstpage" content="1"/>
    <meta name="citation_lastpage" content="8"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_fulltext_world_readable" content=""/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41598-021-89743-x"/>
    <meta name="DOI" content="10.1038/s41598-021-89743-x"/>
    <meta name="size" content="124228"/>
    <meta name="citation_doi" content="10.1038/s41598-021-89743-x"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41598-021-89743-x&amp;api_key="/>
    <meta name="description" content="Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p&#8201;=&#8201;0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers."/>
    <meta name="dc.creator" content="Korot, Edward"/>
    <meta name="dc.creator" content="Pontikos, Nikolas"/>
    <meta name="dc.creator" content="Liu, Xiaoxuan"/>
    <meta name="dc.creator" content="Wagner, Siegfried K."/>
    <meta name="dc.creator" content="Faes, Livia"/>
    <meta name="dc.creator" content="Huemer, Josef"/>
    <meta name="dc.creator" content="Balaskas, Konstantinos"/>
    <meta name="dc.creator" content="Denniston, Alastair K."/>
    <meta name="dc.creator" content="Khawaja, Anthony"/>
    <meta name="dc.creator" content="Keane, Pearse A."/>
    <meta name="dc.subject" content="Computer science"/>
    <meta name="dc.subject" content="Translational research"/>
    <meta name="citation_reference" content="citation_journal_title=Arch. Ophthalmol.; citation_title=150 years since Babbage&#8217;s ophthalmoscope; citation_author=CR Keeler; citation_volume=115; citation_publication_date=1997; citation_pages=1456-1457; citation_doi=10.1001/archopht.1997.01100160626017; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=Optical coherence tomography in Alzheimer&#8217;s disease: A meta-analysis; citation_author=G Coppola; citation_volume=10; citation_publication_date=2015; citation_pages=0134750; citation_doi=10.1371/journal.pone.0134750; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Br. J. Radiol.; citation_title=Retinal imaging as a source of biomarkers for diagnosis, characterization and prognosis of chronic illness or long-term conditions; citation_author=TJ MacGillivray; citation_volume=87; citation_publication_date=2014; citation_pages=20130832; citation_doi=10.1259/bjr.20130832; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=Am. J. Ophthalmol.; citation_title=The relationship of retinal and renal arteriolosclerosis in living patients with essential hypertension; citation_author=JP Wendland; citation_volume=35; citation_publication_date=1952; citation_pages=1748-1752; citation_doi=10.1016/0002-9394(52)92013-8; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Ophthalmology; citation_title=The prevalence and risk factors of retinal microvascular abnormalities in older persons: The Cardiovascular Health Study; citation_author=TY Wong; citation_volume=110; citation_publication_date=2003; citation_pages=658-666; citation_doi=10.1016/S0161-6420(02)01931-0; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Acta Neuropathol. Commun.; citation_title=The retina as an early biomarker of neurodegeneration in a rotenone-induced model of Parkinson&#8217;s disease: Evidence for a neuroprotective effect of rosiglitazone in the eye and brain; citation_author=EM Normando; citation_volume=4; citation_publication_date=2016; citation_pages=86; citation_doi=10.1186/s40478-016-0346-z; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Am. J. Epidemiol.; citation_title=Prediction of incident stroke events based on retinal vessel caliber: A systematic review and individual-participant meta-analysis; citation_author=K McGeechan; citation_volume=170; citation_publication_date=2009; citation_pages=1323-1332; citation_doi=10.1093/aje/kwp306; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Alzheimers. Dement.; citation_title=Retinal thickness in Alzheimer&#8217;s disease: A systematic review and meta-analysis; citation_author=J Haan, FD Verbraak, PJ Visser, FH Bouwman; citation_volume=6; citation_publication_date=2017; citation_pages=162-170; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA Neurol.; citation_title=Association of retinal nerve fiber layer thinning with current and future cognitive decline: A study using optical coherence tomography; citation_author=F Ko; citation_volume=75; citation_publication_date=2018; citation_pages=1198-1205; citation_doi=10.1001/jamaneurol.2018.1578; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Alzheimers. Dement.; citation_title=A systematic review and meta-analysis of retinal nerve fiber layer change in dementia, using optical coherence tomography; citation_author=KL Thomson, JM Yeo, B Waddell, JR Cameron, S Pal; citation_volume=1; citation_publication_date=2015; citation_pages=136-143; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=Am. J. Ophthalmol.; citation_title=Retinal vascular fractal dimension and its relationship with cardiovascular and ocular risk factors; citation_author=CY Cheung; citation_volume=154; citation_publication_date=2012; citation_pages=663-674.e1; citation_doi=10.1016/j.ajo.2012.04.016; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA Neurol.; citation_title=Association of retinal neurodegeneration on optical coherence tomography with dementia: A population-based study; citation_author=U Mutlu; citation_volume=75; citation_publication_date=2018; citation_pages=1256-1263; citation_doi=10.1001/jamaneurol.2018.1563; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Ophthalmology; citation_title=Retinal vasculometry associations with cardiometabolic risk factors in the European prospective investigation of cancer-norfolk study; citation_author=CG Owen; citation_volume=126; citation_publication_date=2019; citation_pages=96-106; citation_doi=10.1016/j.ophtha.2018.07.022; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Med.; citation_title=Clinically applicable deep learning for diagnosis and referral in retinal disease; citation_author=J Fauw; citation_volume=24; citation_publication_date=2018; citation_pages=1342-1350; citation_doi=10.1038/s41591-018-0107-6; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Ophthalmology; citation_title=Fully automated detection and quantification of macular fluid in OCT using deep learning; citation_author=T Schlegl; citation_volume=125; citation_publication_date=2018; citation_pages=549-558; citation_doi=10.1016/j.ophtha.2017.10.031; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA Ophthalmol.; citation_title=Finding glaucoma in color fundus photographs using deep learning; citation_author=KD Bojikian, CS Lee, AY Lee; citation_publication_date=2019; citation_doi=10.1001/jamaophthalmol.2019.3512; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA; citation_title=Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes; citation_author=DSW Ting; citation_volume=318; citation_publication_date=2017; citation_pages=2211-2223; citation_doi=10.1001/jama.2017.18152; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA; citation_title=Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs; citation_author=V Gulshan; citation_volume=316; citation_publication_date=2016; citation_pages=2402-2410; citation_doi=10.1001/jama.2016.17216; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=A fast learning algorithm for deep belief nets; citation_author=GE Hinton, S Osindero, Y-W Teh; citation_volume=18; citation_publication_date=2006; citation_pages=1527-1554; citation_doi=10.1162/neco.2006.18.7.1527; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Transl. Vis. Sci. Technol.; citation_title=Insights into systemic disease through retinal imaging-based oculomics; citation_author=SK Wagner; citation_volume=9; citation_publication_date=2020; citation_pages=6-6; citation_doi=10.1167/tvst.9.2.6; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Transl. Vis. Sci. Technol.; citation_title=Will AI replace ophthalmologists?; citation_author=E Korot; citation_volume=9; citation_publication_date=2020; citation_pages=2-2; citation_doi=10.1167/tvst.9.2.2; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning; citation_author=R Poplin; citation_volume=2; citation_publication_date=2018; citation_pages=158-164; citation_doi=10.1038/s41551-018-0195-0; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Biomed. Eng.; citation_title=Eyeing cardiovascular risk factors; citation_author=DSW Ting, TY Wong; citation_volume=2; citation_publication_date=2018; citation_pages=140-141; citation_doi=10.1038/s41551-018-0210-5; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Lancet Digit. Health; citation_title=Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study; citation_author=L Faes; citation_volume=1; citation_publication_date=2019; citation_pages=e232-e242; citation_doi=10.1016/S2589-7500(19)30108-6; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=Transl. Vis. Sci. Technol.; citation_title=Factors in color fundus photographs that can be used by humans to determine sex of individuals; citation_author=T Yamashita; citation_volume=9; citation_publication_date=2020; citation_pages=4-4; citation_doi=10.1167/tvst.9.2.4; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Eye Res.; citation_title=Effects of sex and age on the normal retinal and choroidal structures on optical coherence tomography; citation_author=S Ooto, M Hangai, N Yoshimura; citation_volume=40; citation_publication_date=2015; citation_pages=213-225; citation_doi=10.3109/02713683.2014.952828; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=Macular thickness by age and gender in healthy eyes using spectral domain optical coherence tomography; citation_author=M Adhi, S Aziz, K Muhammad, MI Adhi; citation_volume=7; citation_publication_date=2012; citation_pages=37638; citation_doi=10.1371/journal.pone.0037638; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=Association of ocular, cardiovascular, morphometric and lifestyle parameters with retinal nerve fibre layer thickness; citation_author=J Lamparter; citation_volume=13; citation_publication_date=2018; citation_pages=e0197682; citation_doi=10.1371/journal.pone.0197682; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=Steroids; citation_title=The estrogenic retina: The potential contribution to healthy aging and age-related neurodegenerative diseases of the retina; citation_author=C Cascio, I Deidda, D Russo, P Guarneri; citation_volume=103; citation_publication_date=2015; citation_pages=31-41; citation_doi=10.1016/j.steroids.2015.08.002; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Eye Res.; citation_title=Gender differences in ocular blood flow; citation_author=D Schmidl, L Schmetterer, G Garh&#246;fer, A Popa-Cherecheanu; citation_volume=40; citation_publication_date=2015; citation_pages=201-212; citation_doi=10.3109/02713683.2014.906625; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Transl. Vis. Sci. Technol.; citation_title=Factors in color fundus photographs that can be used by humans to determine sex of individuals; citation_author=S Dieck; citation_volume=9; citation_publication_date=2020; citation_pages=8-8; citation_doi=10.1167/tvst.9.7.8; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=BMC Med. Res. Methodol.; citation_title=External validation of multivariable prediction models: A systematic review of methodological conduct and reporting; citation_author=GS Collins; citation_volume=14; citation_publication_date=2014; citation_pages=40; citation_doi=10.1186/1471-2288-14-40; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=J. Clin. Epidemiol.; citation_title=Prediction models need appropriate internal, internal-external, and external validation; citation_author=EW Steyerberg, FE Harrell; citation_volume=69; citation_publication_date=2016; citation_pages=245-247; citation_doi=10.1016/j.jclinepi.2015.04.005; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Transl. Vis. Sci. Technol.; citation_title=A clinician&#8217;s guide to artificial intelligence: How to critically appraise machine learning studies; citation_author=L Faes; citation_volume=9; citation_publication_date=2020; citation_pages=7-7; citation_doi=10.1167/tvst.9.2.7; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=The long road to fairer algorithms; citation_author=MJ Kusner, JR Loftus; citation_volume=578; citation_publication_date=2020; citation_pages=34-36; citation_doi=10.1038/d41586-020-00274-3; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=BMC Med.; citation_title=Key challenges for delivering clinical impact with artificial intelligence; citation_author=CJ Kelly, A Karthikesalingam, M Suleyman, G Corrado, D King; citation_volume=17; citation_publication_date=2019; citation_pages=195; citation_doi=10.1186/s12916-019-1426-2; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Calif. L. Rev.; citation_title=Big data&#8217;s disparate impact; citation_author=S Barocas, AD Selbst; citation_publication_date=2016; citation_doi=10.2139/ssrn.2477899; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Med.; citation_title=UK biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age; citation_author=C Sudlow; citation_volume=12; citation_publication_date=2015; citation_pages=1001779; citation_doi=10.1371/journal.pmed.1001779; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=Optical coherence tomography in the UK Biobank study: Rapid automated analysis of retinal thickness for large population-based studies; citation_author=PA Keane; citation_volume=11; citation_publication_date=2016; citation_pages=e0164095; citation_doi=10.1371/journal.pone.0164095; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Lancet Digit. Health; citation_title=A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: A systematic review and meta-analysis; citation_author=X Liu; citation_volume=1; citation_publication_date=2019; citation_pages=e271-e297; citation_doi=10.1016/S2589-7500(19)30123-2; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=NPJ Digit. Med.; citation_title=Presenting machine learning model information to clinical end users with model facts labels; citation_author=MP Sendak, M Gao, N Brajer, S Balu; citation_volume=3; citation_publication_date=2020; citation_pages=41; citation_doi=10.1038/s41746-020-0253-3; citation_id=CR41"/>
    <meta name="citation_reference" content="Kapishnikov, A., Bolukbasi, T., Vi&#233;gas, F. &amp; Terry, M. XRAI: Better Attributions Through Regions. arXiv [cs.CV] (2019)."/>
    <meta name="citation_author" content="Korot, Edward"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author" content="Pontikos, Nikolas"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author" content="Liu, Xiaoxuan"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author_institution" content="Department of Ophthalmology, University Hospitals Birmingham NHS Foundation Trust, Birmingham, UK"/>
    <meta name="citation_author_institution" content="Academic Unit of Ophthalmology, Institute of Inflammation &amp; Ageing, College of Medical and Dental Sciences, University of Birmingham, Birmingham, UK"/>
    <meta name="citation_author" content="Wagner, Siegfried K."/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author" content="Faes, Livia"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author_institution" content="Eye Clinic, Cantonal Hospital of Lucerne, Lucerne, Switzerland"/>
    <meta name="citation_author" content="Huemer, Josef"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author_institution" content="Vienna Institute for Research in Ocular Surgery, A Karl Landsteiner Institute, Hanusch Hospital, Vienna, Austria"/>
    <meta name="citation_author" content="Balaskas, Konstantinos"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author" content="Denniston, Alastair K."/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author_institution" content="Department of Ophthalmology, University Hospitals Birmingham NHS Foundation Trust, Birmingham, UK"/>
    <meta name="citation_author_institution" content="Academic Unit of Ophthalmology, Institute of Inflammation &amp; Ageing, College of Medical and Dental Sciences, University of Birmingham, Birmingham, UK"/>
    <meta name="citation_author_institution" content="Health Data Research UK, London, UK"/>
    <meta name="citation_author" content="Khawaja, Anthony"/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="citation_author" content="Keane, Pearse A."/>
    <meta name="citation_author_institution" content="NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@SciReports"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Predicting sex from retinal fundus photographs using automated deep learning"/>
    <meta name="twitter:description" content="Scientific Reports - Predicting sex from retinal fundus photographs using automated deep learning"/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41598-021-89743-x"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Predicting sex from retinal fundus photographs using automated deep learning - Scientific Reports"/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'false'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://collect.nature.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/scientific_reports/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41598-021-89743-x;doi=10.1038/s41598-021-89743-x;subjmeta=117,308,575,639,692,705;kwrd=Computer+science,Translational+research">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/scientific_reports/article&amp;sz=728x90&amp;c=-2095712135&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41598-021-89743-x%26doi%3D10.1038/s41598-021-89743-x%26subjmeta%3D117,308,575,639,692,705%26kwrd%3DComputer+science,Translational+research">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/scientific_reports/article&amp;sz=728x90&amp;c=-2095712135&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41598-021-89743-x%26doi%3D10.1038/s41598-021-89743-x%26subjmeta%3D117,308,575,639,692,705%26kwrd%3DComputer+science,Translational+research"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#cedde4">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/srep"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="//media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg" media="(min-width: 875px)">
                                <img src="//media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg" height="32" alt="Scientific Reports">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link"
                               href="#search-menu"
                               data-header-expander
                               data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <span>Search</span><svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding">
                            
                                
                                    <a class="c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41598-021-89743-x'>Log in</a>
                                
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;288"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/srep.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/srep" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:scientific reports"><span itemprop="name">scientific reports</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/srep/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Predicting sex from retinal fundus photographs using automated deep learning
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41598-021-89743-x.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            </a>
        </div>
    

                </div>
                
    <div class="c-recommendations__container u-container u-display-none" data-component-recommendations>
        <aside class="c-status-message c-status-message--success u-display-none" data-component-status-msg>
            <svg class="c-status-message__icon" width="24" height="24" role="img" aria-label="success:" focusable="false">
                <use xlink:href="#icon-success"></use>
            </svg>
            <div class="c-status-message__message" tabindex="-1" id="success-message">
                Your article has downloaded
            </div>
        </aside>

        <div class="c-recommendations-header u-display-flex u-justify-content-space-between">
            <h2 class="c-recommendations-title" id="recommendation-heading">Similar articles being viewed by others</h2>
            <button class="c-recommendations-close u-flex-static" type="button" aria-label="Close" data-track="click" data-track-action="close recommendations">
                <svg class="u-icon" width="16" height="16" aria-hidden="true" focusable="false"><use xlink:href="#icon-close"></use></svg>
            </button>
        </div>

        <section aria-roledescription="carousel" aria-labelledby="recommendation-heading">
            <p class="u-visually-hidden">Carousel with three slides shown at a time. Use the Previous and Next buttons to navigate three slides at a time, or the slide dot buttons at the end to jump three slides at a time.</p>
            <div class="c-recommendations-list-container">
                <div class="c-recommendations-list">
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 1 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-021-86577-5/MediaObjects/41598_2021_86577_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41598-021-86577-5" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41598-021-86577-5">Assessment of patient specific information in the wild on fundus photography and optical coherence tomography</a></h3>
                                        <p class="u-sans-serif u-mb-0">21 April 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Marion R. Munk, Thomas Kurmann, … Raphael Sznitman</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 2 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41746-020-00317-z/MediaObjects/41746_2020_317_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41746-020-00317-z" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41746-020-00317-z">Predicting risk of late age-related macular degeneration using deep learning</a></h3>
                                        <p class="u-sans-serif u-mb-0">27 August 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Yifan Peng, Tiarnan D. Keenan, … Zhiyong Lu</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 3 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41551-022-00867-5/MediaObjects/41551_2022_867_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41551-022-00867-5" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41551-022-00867-5">Detection of signs of disease in external photographs of the eyes via deep learning</a></h3>
                                        <p class="u-sans-serif u-mb-0">29 March 2022</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Boris Babenko, Akinori Mitani, … Yun Liu</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 4 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41746-019-0097-x/MediaObjects/41746_2019_97_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41746-019-0097-x" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41746-019-0097-x">Deep learning in estimating prevalence and systemic risk factors for diabetic retinopathy: a multi-ethnic study</a></h3>
                                        <p class="u-sans-serif u-mb-0">10 April 2019</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Daniel S. W. Ting, Carol Y. Cheung, … Tien Yin Wong</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 5 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs43587-022-00171-6/MediaObjects/43587_2022_171_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s43587-022-00171-6" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s43587-022-00171-6">Detecting visually significant cataract using retinal photograph-based deep learning</a></h3>
                                        <p class="u-sans-serif u-mb-0">21 February 2022</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Yih-Chung Tham, Jocelyn Hui Lin Goh, … Ching-Yu Cheng</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 6 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41467-019-13922-8/MediaObjects/41467_2019_13922_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41467-019-13922-8" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41467-019-13922-8">Predicting optical coherence tomography-derived diabetic macular edema grades from fundus photographs using deep learning</a></h3>
                                        <p class="u-sans-serif u-mb-0">08 January 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Avinash V. Varadarajan, Pinal Bavishi, … Dale R. Webster</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 7 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-022-09642-7/MediaObjects/41598_2022_9642_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41598-022-09642-7" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41598-022-09642-7">Prediction of treatment outcome in neovascular age-related macular degeneration using a novel convolutional neural network</a></h3>
                                        <p class="u-sans-serif u-mb-0">07 April 2022</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Tsai-Chu Yeh, An-Chun Luo, … Yu-Bai Chou</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 8 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-020-79809-7/MediaObjects/41598_2020_79809_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41598-020-79809-7" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41598-020-79809-7">Development and validation of deep learning algorithms for automated eye laterality detection with anterior segment photography</a></h3>
                                        <p class="u-sans-serif u-mb-0">12 January 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Ce Zheng, Xiaolin Xie, … Xu Chen</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 9 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height ">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-018-35044-9/MediaObjects/41598_2018_35044_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link u-link-inherit" href="https://doi.org/10.1038/s41598-018-35044-9" data-track="click" data-track-action="click recommendations" data-track-label="10.1038/s41598-018-35044-9">Performance of Deep Learning Architectures and Transfer Learning for Detecting Glaucomatous Optic Neuropathy in Fundus Photographs</a></h3>
                                        <p class="u-sans-serif u-mb-0">12 November 2018</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Mark Christopher, Akram Belghith, … Linda M. Zangwill</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                </div>
            </div>
        </section>
    </div>
    <div class="js-greyout-page-background" style="display:none" data-component-grey-background></div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer.push({
                recommendations: {
                    recommender: 'semantic',
                    model: 'specter',
                    policy_id: 'NA',
                    timestamp: 1670703716
                }
            });
        </script>
    

            </div>
        
        <article lang="en">
            
                <div class="c-pdf-button__container u-mb-16 u-hide-at-lg js-context-bar-sticky-point-mobile">
                    <div class="c-pdf-container">
                        
                            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41598-021-89743-x.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            </a>
        </div>
    

                        
                    </div>
                </div>
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
    
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    
        <li class="c-article-identifiers__item">
            <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
        </li>
    
    

                        <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2021-05-13">13 May 2021</time></a></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Predicting sex from retinal fundus photographs using automated deep learning</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Edward-Korot" data-author-popup="auth-Edward-Korot">Edward Korot</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Nikolas-Pontikos" data-author-popup="auth-Nikolas-Pontikos">Nikolas Pontikos</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Xiaoxuan-Liu" data-author-popup="auth-Xiaoxuan-Liu">Xiaoxuan Liu</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Siegfried_K_-Wagner" data-author-popup="auth-Siegfried_K_-Wagner">Siegfried K. Wagner</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Livia-Faes" data-author-popup="auth-Livia-Faes">Livia Faes</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff4">4</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Josef-Huemer" data-author-popup="auth-Josef-Huemer">Josef Huemer</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff5">5</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Konstantinos-Balaskas" data-author-popup="auth-Konstantinos-Balaskas">Konstantinos Balaskas</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Alastair_K_-Denniston" data-author-popup="auth-Alastair_K_-Denniston">Alastair K. Denniston</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a>,<a href="#Aff6">6</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Anthony-Khawaja" data-author-popup="auth-Anthony-Khawaja" data-corresp-id="c1">Anthony Khawaja<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 10 authors for this article" title="Show all 10 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Pearse_A_-Keane" data-author-popup="auth-Pearse_A_-Keane" data-corresp-id="c2">Pearse A. Keane<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-plus"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/srep"><i data-test="journal-title">Scientific Reports</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 11</b>, Article number: <span data-test="article-number">10286</span> (<span data-test="article-publication-year">2021</span>)
            <a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">45k <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">21 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">619 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/articles/s41598-021-89743-x/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>

                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/computer-science" data-track="click" data-track-action="view subject" data-track-label="link">Computer science</a></li><li class="c-article-subject-list__subject"><a href="/subjects/translational-research" data-track="click" data-track-action="view subject" data-track-label="link">Translational research</a></li>
        </ul>
    </div>

                
    

    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers.</p></div></div></section>
            <noscript>
                
            </noscript>

                
            
                <div class="main-content">
                <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>The retina is the only tissue in the body where neural and vascular tissue can be visualized simultaneously in a non-invasive manner. Ophthalmologists have been doing so since the ophthalmoscope was introduced into clinical practice in the mid 1800s<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Keeler, C. R. 150 years since Babbage’s ophthalmoscope. Arch. Ophthalmol. 115, 1456–1457 (1997)." href="/articles/s41598-021-89743-x#ref-CR1" id="ref-link-section-d195684229e516">1</a></sup>. It has also been increasingly recognized that retinal biomarkers may map effectively to systemic indices of healthy ageing and disease<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Coppola, G. et al. Optical coherence tomography in Alzheimer’s disease: A meta-analysis. PLoS ONE 10, 0134750 (2015)." href="#ref-CR2" id="ref-link-section-d195684229e520">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="MacGillivray, T. J. et al. Retinal imaging as a source of biomarkers for diagnosis, characterization and prognosis of chronic illness or long-term conditions. Br. J. Radiol. 87, 20130832 (2014)." href="#ref-CR3" id="ref-link-section-d195684229e520_1">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wendland, J. P. The relationship of retinal and renal arteriolosclerosis in living patients with essential hypertension. Am. J. Ophthalmol. 35, 1748–1752 (1952)." href="#ref-CR4" id="ref-link-section-d195684229e520_2">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wong, T. Y. et al. The prevalence and risk factors of retinal microvascular abnormalities in older persons: The Cardiovascular Health Study. Ophthalmology 110, 658–666 (2003)." href="#ref-CR5" id="ref-link-section-d195684229e520_3">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Normando, E. M. et al. The retina as an early biomarker of neurodegeneration in a rotenone-induced model of Parkinson’s disease: Evidence for a neuroprotective effect of rosiglitazone in the eye and brain. Acta Neuropathol. Commun. 4, 86 (2016)." href="/articles/s41598-021-89743-x#ref-CR6" id="ref-link-section-d195684229e523">6</a></sup>. Examples of these oculomics-based findings include vascular tortuosity and arteriolar narrowing for cardiovascular disease, and retinal cell layer changes for neurological disorders<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="McGeechan, K. et al. Prediction of incident stroke events based on retinal vessel caliber: A systematic review and individual-participant meta-analysis. Am. J. Epidemiol. 170, 1323–1332 (2009)." href="#ref-CR7" id="ref-link-section-d195684229e527">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="den Haan, J., Verbraak, F. D., Visser, P. J. &amp; Bouwman, F. H. Retinal thickness in Alzheimer’s disease: A systematic review and meta-analysis. Alzheimers. Dement. 6, 162–170 (2017)." href="#ref-CR8" id="ref-link-section-d195684229e527_1">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ko, F. et al. Association of retinal nerve fiber layer thinning with current and future cognitive decline: A study using optical coherence tomography. JAMA Neurol. 75, 1198–1205 (2018)." href="#ref-CR9" id="ref-link-section-d195684229e527_2">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Thomson, K. L., Yeo, J. M., Waddell, B., Cameron, J. R. &amp; Pal, S. A systematic review and meta-analysis of retinal nerve fiber layer change in dementia, using optical coherence tomography. Alzheimers. Dement. 1, 136–143 (2015)." href="#ref-CR10" id="ref-link-section-d195684229e527_3">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cheung, C. Y. et al. Retinal vascular fractal dimension and its relationship with cardiovascular and ocular risk factors. Am. J. Ophthalmol. 154, 663-674.e1 (2012)." href="/articles/s41598-021-89743-x#ref-CR11" id="ref-link-section-d195684229e530">11</a></sup>.</p><p>Relationships between retinal morphology and systemic health have traditionally been evaluated using statistical modelling, such as multivariable regression. However, such techniques may have limited incremental value when leveraged on very large datasets and for complex data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Mutlu, U. et al. Association of retinal neurodegeneration on optical coherence tomography with dementia: A population-based study. JAMA Neurol. 75, 1256–1263 (2018)." href="/articles/s41598-021-89743-x#ref-CR12" id="ref-link-section-d195684229e537">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Owen, C. G. et al. Retinal vasculometry associations with cardiometabolic risk factors in the European prospective investigation of cancer-norfolk study. Ophthalmology 126, 96–106 (2019)." href="/articles/s41598-021-89743-x#ref-CR13" id="ref-link-section-d195684229e540">13</a></sup>. As data availability has increased, and mathematical models have improved, the success of deep learning in ophthalmic disease classification in the research setting has been striking<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="De Fauw, J. et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med. 24, 1342–1350 (2018)." href="#ref-CR14" id="ref-link-section-d195684229e544">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schlegl, T. et al. Fully automated detection and quantification of macular fluid in OCT using deep learning. Ophthalmology 125, 549–558 (2018)." href="#ref-CR15" id="ref-link-section-d195684229e544_1">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bojikian, K. D., Lee, C. S. &amp; Lee, A. Y. Finding glaucoma in color fundus photographs using deep learning. JAMA Ophthalmol. &#xA;                  https://doi.org/10.1001/jamaophthalmol.2019.3512&#xA;                  &#xA;                 (2019)." href="#ref-CR16" id="ref-link-section-d195684229e544_2">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ting, D. S. W. et al. Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes. JAMA 318, 2211–2223 (2017)." href="#ref-CR17" id="ref-link-section-d195684229e544_3">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Gulshan, V. et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA 316, 2402–2410 (2016)." href="/articles/s41598-021-89743-x#ref-CR18" id="ref-link-section-d195684229e547">18</a></sup>. Deep neural networks, which process input images by applying mathematical operations to connected nonlinear units in multiple layers, largely avoid manual feature engineering, and are able to derive previously hidden patterns in large volumes of data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Hinton, G. E., Osindero, S. &amp; Teh, Y.-W. A fast learning algorithm for deep belief nets. Neural Comput. 18, 1527–1554 (2006)." href="/articles/s41598-021-89743-x#ref-CR19" id="ref-link-section-d195684229e551">19</a></sup>.</p><p>The discovery of quantitative relationships between retinal appearance and systemic pathophysiology readily aligns with pre-established conceptions of microvascular and degenerative tissue-level insults<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Wagner, S. K. et al. Insights into systemic disease through retinal imaging-based oculomics. Transl. Vis. Sci. Technol. 9, 6–6 (2020)." href="/articles/s41598-021-89743-x#ref-CR20" id="ref-link-section-d195684229e558">20</a></sup>. However, deep learning has shown that these algorithms demonstrate capability in tasks which were not previously thought possible<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Korot, E. et al. Will AI replace ophthalmologists?. Transl. Vis. Sci. Technol. 9, 2–2 (2020)." href="/articles/s41598-021-89743-x#ref-CR21" id="ref-link-section-d195684229e562">21</a></sup>. Harnessing this power, new insights into relationships between retinal structure and systemic pathophysiology could expand existing knowledge of disease mechanisms. A study by Poplin et al. demonstrated a deep-learning learning algorithm which could accurately predict cardiovascular risk factors from fundus photos<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. Nat. Biomed. Eng. 2, 158–164 (2018)." href="/articles/s41598-021-89743-x#ref-CR22" id="ref-link-section-d195684229e566">22</a></sup>; More surprising to ophthalmologists was the successful prediction of demographic information such as age and gender, the latter with an area under the curve (AUC) of 0.97. Here, the physiologic cause and effect relationships are not readily apparent to domain experts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Korot, E. et al. Will AI replace ophthalmologists?. Transl. Vis. Sci. Technol. 9, 2–2 (2020)." href="/articles/s41598-021-89743-x#ref-CR21" id="ref-link-section-d195684229e570">21</a></sup>. Predicting gender from fundus photos, previously inconceivable to those who spent their careers looking at retinas, also withstood external validation on an independent dataset of patients with different baseline demographics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Ting, D. S. W. &amp; Wong, T. Y. Eyeing cardiovascular risk factors. Nat. Biomed. Eng. 2, 140–141 (2018)." href="/articles/s41598-021-89743-x#ref-CR23" id="ref-link-section-d195684229e574">23</a></sup>. Although not likely to be clinically useful, this finding hints at the future potential of deep learning for the discovery of novel associations through unbiased modelling of high-dimensional data.</p><p>We previously reported on the ability of physicians to create automated machine learning (AutoML) models for medical image analysis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Faes, L. et al. Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study. Lancet Digit. Health 1, e232–e242 (2019)." href="/articles/s41598-021-89743-x#ref-CR24" id="ref-link-section-d195684229e581">24</a></sup>. Since that proof of concept, AutoML platforms have advanced significantly, with multiple employing code free deep learning (CFDL). Herein, we demonstrate AutoML as a tool for automated discovery of novel insights by performing sex classification from retinal fundus photos, and comparing its performance to the bespoke deep learning model by Poplin et al<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. Nat. Biomed. Eng. 2, 158–164 (2018)." href="/articles/s41598-021-89743-x#ref-CR22" id="ref-link-section-d195684229e585">22</a></sup>.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">CFDL model results</h3><p>The CFDL model had an AUROC and AUPRC of 0.93 and 0.94 respectively (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-021-89743-x#Tab1">1</a>). Overall sensitivity (recall), specificity, PPV (precision), and ACC were 88.8%, 83.6%, 87.3%, and 86.5% respectively (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-021-89743-x#Fig1">1</a>). Genetic sex was discordant from reported sex in one validation set image, and this image was incorrectly predicted by the model; that is the model predicted sex consistent with genetic sex in this case (Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41598-021-89743-x#MOESM1">S1</a>). To evaluate reproducibility and address varying performance of deep learning algorithms involving random seed initiation, we retrained the model to identical specifications, and found similar performance with an AUC of 0.93.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Comparison of reported fundus photo sex prediction algorithms.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41598-021-89743-x/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Figure 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-021-89743-x/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="634"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Precision-recall curve.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-021-89743-x/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec4">External validation</h3><p>External validation was performed on the Moorfields dataset. This dataset differed from the UK Biobank development set with respect to both fundus camera used, and in sourcing from a pathology-rich population at a tertiary ophthalmic referral center. The resulting sensitivity, specificity, PPV and ACC were 83.9%, 72.2%, 78.2%, and 78.6% respectively.</p><h3 class="c-article__sub-heading" id="Sec5">Presence of foveal pathology</h3><p>To evaluate the influence of foveal pathology on the performance of the CFDL model, we subgrouped the Moorfields external validation dataset into fundus photos with (n = 108) and without (n = 144) foveal pathology (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-021-89743-x#Tab2">2</a>). The model classified sex correctly in 85.4% of patients without foveal pathology, a population more similar to the largely health UK Biobank population, compared to 69.4% in patients with foveal pathology. Logistic regression showed that presence of foveal pathology was a significant factor in model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Sex was not associated with presence of foveal pathology (p = 0.94). This suggests that the fovea may be a salient region of fundus photographs for the neural network’s sex classification performance. Region attribution saliency maps suggest the optic nerve and vascular arcades as additional important input regions for the model’s prediction (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-021-89743-x#Fig2">2</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Model performance on external validation dataset subgrouped by presence of foveal pathology.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41598-021-89743-x/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Figure 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-021-89743-x/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="274"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Region based saliency maps for model prediction: colors represent regions in order of decreasing performance: Yellow, Green, Blue. Images sourced at random from validation set, with the addition of an ungradable image.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-021-89743-x/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec6">Ungradable UK biobank images</h3><p>Consensus ungradable images (n = 714), which were formerly removed from the UK Biobank validation dataset were separately processed by the model as an experimental adjunct batch prediction. The resulting sensitivity, specificity, PPV and accuracy were 82.6%, 71.2%, 75.2%, and 77.0% respectively.</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Discussion</h2><div class="c-article-section__content" id="Sec7-content"><p>Our results demonstrate robust overall performance of the CFDL model for predicting sex from retinal fundus photos. The AUROC of 0.93 from this framework, which does not require coding expertise, suggests significant capability of the CFDL platform for this task. Our code-free model’s performance is comparable with the Poplin et al. model AUROC of 0.97, which was designed and tuned by machine learning experts (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-021-89743-x#Tab1">1</a>). Our model was trained on a similar (UK Biobank), albeit significantly smaller dataset, as it did not include the additional 1.5 + million EyePACS fundus photos which Poplin et al. also utilized for training.</p><p>To our knowledge, two other studies have attempted to perform this image classification task. Yamashita et al. performed logistic regression on several features that were identified to be associated with sex. These features included papillomacular angle, retinal vessel angles and retinal artery trajectory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Yamashita, T. et al. Factors in color fundus photographs that can be used by humans to determine sex of individuals. Transl. Vis. Sci. Technol. 9, 4–4 (2020)." href="/articles/s41598-021-89743-x#ref-CR25" id="ref-link-section-d195684229e987">25</a></sup>. They achieved an AUROC of 0.78, which further underscores the limitations of a classical machine learning approach, utilizing human-identified features for such novel tasks. Deep learning, even utilizing our CFDL approach, seems to outperform manual feature engineering significantly. Various studies have shown retinal morphology differences between the sexes, including retinal and choroidal thickness<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ooto, S., Hangai, M. &amp; Yoshimura, N. Effects of sex and age on the normal retinal and choroidal structures on optical coherence tomography. Curr. Eye Res. 40, 213–225 (2015)." href="#ref-CR26" id="ref-link-section-d195684229e991">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Adhi, M., Aziz, S., Muhammad, K. &amp; Adhi, M. I. Macular thickness by age and gender in healthy eyes using spectral domain optical coherence tomography. PLoS ONE 7, 37638 (2012)." href="#ref-CR27" id="ref-link-section-d195684229e991_1">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Lamparter, J. et al. Association of ocular, cardiovascular, morphometric and lifestyle parameters with retinal nerve fibre layer thickness. PLoS ONE 13, e0197682 (2018)." href="/articles/s41598-021-89743-x#ref-CR28" id="ref-link-section-d195684229e994">28</a></sup>. Others have demonstrated variation of ocular blood flow and have suggested the effect of sex hormones, but thus far, consensus is lacking<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Cascio, C., Deidda, I., Russo, D. &amp; Guarneri, P. The estrogenic retina: The potential contribution to healthy aging and age-related neurodegenerative diseases of the retina. Steroids 103, 31–41 (2015)." href="/articles/s41598-021-89743-x#ref-CR29" id="ref-link-section-d195684229e998">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Schmidl, D., Schmetterer, L., Garhöfer, G. &amp; Popa-Cherecheanu, A. Gender differences in ocular blood flow. Curr. Eye Res. 40, 201–212 (2015)." href="/articles/s41598-021-89743-x#ref-CR30" id="ref-link-section-d195684229e1001">30</a></sup>. The coder-engineered deep learning model developed by Dieck et al. for this task, which also included an image preprocessing step, demonstrated an accuracy of 82.9%, which was lower than our automated code-free approach<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Dieck, S. et al. Factors in color fundus photographs that can be used by humans to determine sex of individuals. Transl. Vis. Sci. Technol. 9, 8–8 (2020)." href="/articles/s41598-021-89743-x#ref-CR31" id="ref-link-section-d195684229e1005">31</a></sup>. The retinal features apparent to domain experts for this task may go unanswered, as the power of deep learning in integrating population-level patterns from billions of pixel-level variations is impossible for humans to match.</p><p>Performance of our model was slightly worse with external validation on the Moorfields dataset, which is typical when deep learning models are evaluated with datasets dissimilar from their training data distribution<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Collins, G. S. et al. External validation of multivariable prediction models: A systematic review of methodological conduct and reporting. BMC Med. Res. Methodol. 14, 40 (2014)." href="/articles/s41598-021-89743-x#ref-CR32" id="ref-link-section-d195684229e1012">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Steyerberg, E. W. &amp; Harrell, F. E. Jr. Prediction models need appropriate internal, internal-external, and external validation. J. Clin. Epidemiol. 69, 245–247 (2016)." href="/articles/s41598-021-89743-x#ref-CR33" id="ref-link-section-d195684229e1015">33</a></sup>. Specifically, the Moorfields dataset was obtained from a tertiary referral center, and 42.9% of the fundus photos contained foveal pathology. In eyes without foveal pathology, the external validation accuracy was within 1.5% of the Biobank validation set. The worse performance in pathologic eyes suggests the significance of the fovea for sex prediction, and was similarly demonstrated in the attention maps of Poplin et al. The region-based saliency maps we generated suggest that the optic nerve and vascular arcades are also regions of importance (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-021-89743-x#Fig2">2</a>). In the study by Poplin et al., when subgrouped for diabetic retinopathy (DR) presence, their model similarly trended towards worse performance for pathologic images compared with healthy controls. Furthermore, the ophthalmologists in that study “repeatedly reported highlighting of the macula for the gender predictions” when interpreting the attention maps<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. Nat. Biomed. Eng. 2, 158–164 (2018)." href="/articles/s41598-021-89743-x#ref-CR22" id="ref-link-section-d195684229e1022">22</a></sup>. These findings highlight the importance of considering machine learning performance only in context of the specific training and evaluation datasets utilized. This is especially critical for our task, when the salient features of an input image are unclear to domain experts.</p><p>Ungradable images from the UK Biobank validation dataset were labeled as such by retina specialists to the guidelines of lacking adequate visibility of the macula, optic nerve, and vascular arcades (Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41598-021-89743-x#MOESM1">S2</a>). However, those images demonstrated only a slight reduction in model performance. Furthermore, the model shows similar salient regions in ungradable input images as in gradables (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-021-89743-x#Fig2">2</a>). This suggests that the model is sensitive to signal in poor quality images from subtle pixel-level luminance variations, which are likely indifferentiable to humans. This finding underscores the promising ability of deep neural networks to utilize salient features in medical imaging which may remain hidden to human experts.</p><p>Through characterization of high-dimensional data, our findings suggest that deep learning will be a useful tool for the exploration of novel disease and biomarker associations. Clinician driven research, particularly through the use of AutoML, has the potential to move this field forward. Crucially, AutoML as a platform does not fully automate the process of machine learning. Data preparation remains an essential manual step. As demonstrated by population differences in our external validation dataset, tasks such as equitable and representative acquisition, cleaning, and subgrouping of datasets remain important factors for the production of useful models. Clinicians are uniquely positioned to understand both the complexities of the clinical data, and the use-cases for the design of clinically relevant production algorithms.</p><p>While our deep learning model was specifically designed for the task of sex prediction, we emphasize that this task has no inherent clinical utility. Instead, we aimed to demonstrate that AutoML could classify these images independent of salient retinal features being known to domain experts, that is, retina specialists cannot readily perform this task. We intended to show that our framework’s performance may be comparable to state of the art algorithms designed for the same task by coders. This portends for the capacity of AutoML, utilized by clinician use-case experts, to design models for tasks where specific retinal features have not been categorized. Examples of such use-cases include cardiovascular and neurological disease characterization from retinal photos.</p><h3 class="c-article__sub-heading" id="Sec8">Limitations</h3><p>Our study had several limitations. The design of the CFDL model was inherently opaque due to the framework’s automated nature with respect to model architecture and hyperparameters. While this opacity is not unique to CFDL, there is potential to further reduce ML explainability due to lack of insight of model architectures and parameters employed. Although we compared our performance to other models via AUROC, we were unable to compare performance using clinically relevant metrics such as sensitivity and specificity, as these were not provided by the authors of the other studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Faes, L. et al. A clinician’s guide to artificial intelligence: How to critically appraise machine learning studies. Transl. Vis. Sci. Technol. 9, 7–7 (2020)." href="/articles/s41598-021-89743-x#ref-CR34" id="ref-link-section-d195684229e1049">34</a></sup>. The UK Biobank dataset, composed of a generally healthy Caucasian population, was not fully representative of the general UK population, and demonstrates potential for algorithmic bias<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kusner, M. J. &amp; Loftus, J. R. The long road to fairer algorithms. Nature 578, 34–36 (2020)." href="#ref-CR35" id="ref-link-section-d195684229e1053">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kelly, C. J., Karthikesalingam, A., Suleyman, M., Corrado, G. &amp; King, D. Key challenges for delivering clinical impact with artificial intelligence. BMC Med. 17, 195 (2019)." href="#ref-CR36" id="ref-link-section-d195684229e1053_1">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Barocas, S. &amp; Selbst, A. D. Big data’s disparate impact. Calif. L. Rev. &#xA;                  https://doi.org/10.2139/ssrn.2477899&#xA;                  &#xA;                 (2016)." href="/articles/s41598-021-89743-x#ref-CR37" id="ref-link-section-d195684229e1056">37</a></sup>. Although we attempted to address this with an external validation population with a higher prevalence of pathology, our patient level data was limited and did not include additional demographic information. Since both datasets were from UK populations and de-identified, there is the potential of overlap at the patient level.</p><p>Through our investigations of predicting other novel systemic signals from fundus photos, we noted several inherent limitations of the CFDL platform. Utilizing buckets of varying range, which were necessary due to lack of support for continuous variable prediction, we were unable to successfully predict age. Experiments to predict smoking status resulted in models with significantly lower AUC (0.64) as compared with Poplin et al. (0.71)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. Nat. Biomed. Eng. 2, 158–164 (2018)." href="/articles/s41598-021-89743-x#ref-CR22" id="ref-link-section-d195684229e1063">22</a></sup>. We have engaged the platform development team, and aim to repeat our experiments as new platform features are released.</p></div></div></section><section data-title="Conclusion"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Conclusion</h2><div class="c-article-section__content" id="Sec9-content"><p>We demonstrate clinician-driven design of a deep learning sex classification model from retinal fundus photographs, and comparable performance to the same task in a landmark study. In contrast to the latter model designed by expert engineers, our model was created by clinicians without coding. Our external validation on a population with high levels of foveal pathology suggests that the foveal region is important for this task. This demonstrates AutoML as a tool for novel insight discovery for medical imaging by its clinician end users. Although ophthalmologists may continue to ponder what these deep learning models are “looking at”, our study demonstrates the robust potential of CFDL to characterize images independent of experts’ knowledge of contributing features, and its ability to democratize access to deep learning.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Methods</h2><div class="c-article-section__content" id="Sec10-content"><h3 class="c-article__sub-heading" id="Sec11">Participants and data</h3><p>This work utilized two datasets. For deep learning model development, we used the UK Biobank dataset, which is an observational study in the United Kingdom that began in 2006 and has recruited over 500,000 participants—85,262 of which received eye imaging<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Sudlow, C. et al. UK biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age. PLoS Med. 12, 1001779 (2015)." href="/articles/s41598-021-89743-x#ref-CR38" id="ref-link-section-d195684229e1088">38</a></sup>. Eye imaging was obtained at 6 centers in the UK and comprises over 10 terabytes of data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Keane, P. A. et al. Optical coherence tomography in the UK Biobank study: Rapid automated analysis of retinal thickness for large population-based studies. PLoS ONE 11, e0164095 (2016)." href="/articles/s41598-021-89743-x#ref-CR39" id="ref-link-section-d195684229e1092">39</a></sup>. Participants volunteered to provide data including other medical imaging, laboratory results, and detailed subjective questionnaires. Consent was provided by each participant, and the study was approved by the North West Multi-Centre Research Ethics Committee. Detailed protocols may be located at <a href="http://www.ukbiobank.ac.uk">www.ukbiobank.ac.uk</a>. Retinal imaging was obtained with a Topcon OCT-1000 MKII. Each capture consisted of optical coherence tomography and a paired 45-degree retinal fundus photograph. The UK Biobank fundus photo dataset of 175,825 images was split chronologically to train, tuning, and validation sets (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-021-89743-x#Tab3">3</a>). The train/tuning and validation sets contained 53.6% and 56.0% reported women respectively. For temporal validation, chronologic splits were performed to simulate model performance on the validation set in a manner which would align with a prospective trial<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Liu, X. et al. A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: A systematic review and meta-analysis. Lancet Digit. Health 1, e271–e297 (2019)." href="/articles/s41598-021-89743-x#ref-CR40" id="ref-link-section-d195684229e1106">40</a></sup>; that is a model trained on the first chronological period of data (training dataset), and then evaluated on the subsequent chronological period of data (validation dataset). Participant level splits were preserved throughout—each participant’s left, right, and repeat photos were never split between image subsets.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Dataset characteristics of UK biobank and moorfields external validation sets.</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/s41598-021-89743-x/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>For external validation, we utilized an anonymized clinical dataset convenience sampled from Moorfields Eye Hospital of 400 adult patients. These patients received 45-degree fundus photography with Topcon OCT-2000 in December 2019. In order to obtain a representative dataset of all patients presenting from that time period, no other filters were applied. Both datasets consisted of 50% left and 50% right eyes. Average age in the external validation dataset was 64.0 as compared with the UK Biobank validation dataset average of 55.7 (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/s41598-021-89743-x#Tab3">3</a>). Input of the external validation dataset into Cloud AutoML was through the Moorfields Eye Hospital Research Informatics Strategy Data Platform, a secure cloud-based infrastructure facilitating storage and processing of anonymized clinical data. Project-specific approval from local information governance was granted following submission of a Cloud AutoML data privacy impact assessment and separate dataset-specific treatment standard operating procedure. Research and development approval by the Institutional Review Board at Moorfields was obtained (ROAD17/031). Local and national research opt-outs were queried, and the corresponding patients were excluded. All methods were performed in accordance with the relevant guidelines and regulations.</p><p>Participants in the UK Biobank study have provided written informed consent. The external validation set is part of a retrospective, non-interventional study on de-identified data. National and local opt-out guidance was followed for anonymized datasets, Moorfields information governance waived the requirement for informed consent accordingly.</p><h3 class="c-article__sub-heading" id="Sec12">Data processing and labeling</h3><p>The gender variable, as described by the UK Biobank, was acquired from the central registry at recruitment, but in some cases was updated by the participant. Therefore, this field may contain a mixture of NHS recorded gender and self-reported gender. Genetic sex in the UK Biobank was determined by genotyping performed at Affymetrix3 Inc. with quality control of the data at the Wellcome Trust Centre for Human Genetics.</p><p>Ungradable images were removed from both validation datasets. De-identified images were assessed for gradability by two retina specialists masked to patient demographics (E.K., H.K.). Gradability was defined as a field of view ensuring adequate visibility of the vascular arcades, macula, and optic nerve, and sufficient image quality to exclude microaneurysm sized features. Any disagreements were resolved via in-person discussion. In cases where agreements could still not be resolved (n = 122), a gradability algorithm, described in a model card (Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41598-021-89743-x#MOESM1">S2</a>), was used to adjudicate disagreements, with 70 of the disagreed images being classified as ungradable<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Sendak, M. P., Gao, M., Brajer, N. &amp; Balu, S. Presenting machine learning model information to clinical end users with model facts labels. NPJ Digit. Med. 3, 41 (2020)." href="/articles/s41598-021-89743-x#ref-CR41" id="ref-link-section-d195684229e1313">41</a></sup>. After ungradables were removed, 252 Moorfields images remained for external validation. Ungradable rate was 35.7% and 32.2% in the UK Biobank validation and Moorfields datasets respectively. Moorfields images were also graded for presence of foveal pathology. This was defined as any retinal lesion which extended into the central one disc diameter around the fovea. Examples of foveal lesions included but were not limited to macular holes, microaneurysms, RPE tears, and pigment atrophy (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41598-021-89743-x#Fig3">3</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Figure 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41598-021-89743-x/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="674"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Representative Fundus Photos. Correct (<b>A</b>) and incorrect (<b>B</b>) cases without (1) and with (2) foveal pathology.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41598-021-89743-x/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec13">Model training</h3><p>Our deep learning model was trained using code-free deep learning (CFDL) with the Google Cloud AutoML platform. As described and demonstrated in a supplemental video of our prior work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Faes, L. et al. Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study. Lancet Digit. Health 1, e232–e242 (2019)." href="/articles/s41598-021-89743-x#ref-CR24" id="ref-link-section-d195684229e1352">24</a></sup>, the platform provides a graphical user interface (GUI) for data upload, labeling, and model training. Alternatively, the CFDL platform provides the option of image upload via shell-scripting utilizing a .csv spreadsheet containing labels with associated cloud storage locations. We utilized the latter upload approach for the efficient management of our large datasets. Automated machine learning was then employed, which entails neural architecture search and hyperparameter tuning. Training was performed with maximum allowable cloud graphics processing unit (GPU) hours, and early stopping was enabled, which automatically terminated training when no further model improvement was noted after 581 node-hours. Each node hour represents eight cloud nodes used in parallel, and each node is equivalent to a NVIDIA Tesla V100 GPU. XRAI region based attribution saliency maps were generated from an edge optimized version of the model utilizing the AutoML explainable AI framework<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Kapishnikov, A., Bolukbasi, T., Viégas, F. &amp; Terry, M. XRAI: Better Attributions Through Regions. arXiv [cs.CV] (2019)." href="/articles/s41598-021-89743-x#ref-CR42" id="ref-link-section-d195684229e1356">42</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec14">Statistical analysis</h3><p>Statistical analysis was performed with Microsoft Excel and Stata. The model was evaluated at a softmax confidence threshold of 0.5. Area under the precision recall curve (AUPRC) was provided by the platform, and area under the receiver operating characteristic curve (AUROC) was obtained via shell-scripting in order to enable comparison with other reported models. We manually calculated sensitivity, specificity, positive predictive value (PPV), and accuracy (ACC) from confusion matrices provided by the CFDL platform (Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41598-021-89743-x#MOESM1">S3</a>, <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41598-021-89743-x#MOESM1">S4</a>). The former four metrics were calculated with respect to prediction of female sex. For subgroup analysis of model performance on images with foveal pathology, a chi squared test was performed.</p></div></div></section>
                </div>
            

            <div>
            <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
              
              <p>The primary dataset that supports the findings of this study is available, with restrictions, from UK Biobank. The external validation data that support the findings of this study are available on request from the corresponding author PAK. The data are not publicly available due to containing information that could compromise research participant privacy/consent.</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Keeler, C. R. 150 years since Babbage’s ophthalmoscope. <i>Arch. Ophthalmol.</i> <b>115</b>, 1456–1457 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/archopht.1997.01100160626017" data-track-action="article reference" href="https://doi.org/10.1001%2Farchopht.1997.01100160626017" aria-label="Article reference 1" data-doi="10.1001/archopht.1997.01100160626017">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=1997stsp.book.....K" aria-label="ADS reference 1">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1c%2FjtlCktg%3D%3D" aria-label="CAS reference 1">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9366679" aria-label="PubMed reference 1">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=150%20years%20since%20Babbage%E2%80%99s%20ophthalmoscope&amp;journal=Arch.%20Ophthalmol.&amp;doi=10.1001%2Farchopht.1997.01100160626017&amp;volume=115&amp;pages=1456-1457&amp;publication_year=1997&amp;author=Keeler%2CCR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Coppola, G. <i>et al.</i> Optical coherence tomography in Alzheimer’s disease: A meta-analysis. <i>PLoS ONE</i> <b>10</b>, 0134750 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0134750" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0134750" aria-label="Article reference 2" data-doi="10.1371/journal.pone.0134750">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Optical%20coherence%20tomography%20in%20Alzheimer%E2%80%99s%20disease%3A%20A%20meta-analysis&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0134750&amp;volume=10&amp;publication_year=2015&amp;author=Coppola%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">MacGillivray, T. J. <i>et al.</i> Retinal imaging as a source of biomarkers for diagnosis, characterization and prognosis of chronic illness or long-term conditions. <i>Br. J. Radiol.</i> <b>87</b>, 20130832 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1259/bjr.20130832" data-track-action="article reference" href="https://doi.org/10.1259%2Fbjr.20130832" aria-label="Article reference 3" data-doi="10.1259/bjr.20130832">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC2cfivF2ltg%3D%3D" aria-label="CAS reference 3">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24936979" aria-label="PubMed reference 3">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4112401" aria-label="PubMed Central reference 3">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Retinal%20imaging%20as%20a%20source%20of%20biomarkers%20for%20diagnosis%2C%20characterization%20and%20prognosis%20of%20chronic%20illness%20or%20long-term%20conditions&amp;journal=Br.%20J.%20Radiol.&amp;doi=10.1259%2Fbjr.20130832&amp;volume=87&amp;publication_year=2014&amp;author=MacGillivray%2CTJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Wendland, J. P. The relationship of retinal and renal arteriolosclerosis in living patients with essential hypertension. <i>Am. J. Ophthalmol.</i> <b>35</b>, 1748–1752 (1952).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0002-9394(52)92013-8" data-track-action="article reference" href="https://doi.org/10.1016%2F0002-9394%2852%2992013-8" aria-label="Article reference 4" data-doi="10.1016/0002-9394(52)92013-8">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaG3s%2Fjt1antA%3D%3D" aria-label="CAS reference 4">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=13007745" aria-label="PubMed reference 4">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20relationship%20of%20retinal%20and%20renal%20arteriolosclerosis%20in%20living%20patients%20with%20essential%20hypertension&amp;journal=Am.%20J.%20Ophthalmol.&amp;doi=10.1016%2F0002-9394%2852%2992013-8&amp;volume=35&amp;pages=1748-1752&amp;publication_year=1952&amp;author=Wendland%2CJP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Wong, T. Y. <i>et al.</i> The prevalence and risk factors of retinal microvascular abnormalities in older persons: The Cardiovascular Health Study. <i>Ophthalmology</i> <b>110</b>, 658–666 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0161-6420(02)01931-0" data-track-action="article reference" href="https://doi.org/10.1016%2FS0161-6420%2802%2901931-0" aria-label="Article reference 5" data-doi="10.1016/S0161-6420(02)01931-0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12689883" aria-label="PubMed reference 5">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20prevalence%20and%20risk%20factors%20of%20retinal%20microvascular%20abnormalities%20in%20older%20persons%3A%20The%20Cardiovascular%20Health%20Study&amp;journal=Ophthalmology&amp;doi=10.1016%2FS0161-6420%2802%2901931-0&amp;volume=110&amp;pages=658-666&amp;publication_year=2003&amp;author=Wong%2CTY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Normando, E. M. <i>et al.</i> The retina as an early biomarker of neurodegeneration in a rotenone-induced model of Parkinson’s disease: Evidence for a neuroprotective effect of rosiglitazone in the eye and brain. <i>Acta Neuropathol. Commun.</i> <b>4</b>, 86 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1186/s40478-016-0346-z" data-track-action="article reference" href="https://doi.org/10.1186%2Fs40478-016-0346-z" aria-label="Article reference 6" data-doi="10.1186/s40478-016-0346-z">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27535749" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4989531" aria-label="PubMed Central reference 6">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20retina%20as%20an%20early%20biomarker%20of%20neurodegeneration%20in%20a%20rotenone-induced%20model%20of%20Parkinson%E2%80%99s%20disease%3A%20Evidence%20for%20a%20neuroprotective%20effect%20of%20rosiglitazone%20in%20the%20eye%20and%20brain&amp;journal=Acta%20Neuropathol.%20Commun.&amp;doi=10.1186%2Fs40478-016-0346-z&amp;volume=4&amp;publication_year=2016&amp;author=Normando%2CEM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">McGeechan, K. <i>et al.</i> Prediction of incident stroke events based on retinal vessel caliber: A systematic review and individual-participant meta-analysis. <i>Am. J. Epidemiol.</i> <b>170</b>, 1323–1332 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/aje/kwp306" data-track-action="article reference" href="https://doi.org/10.1093%2Faje%2Fkwp306" aria-label="Article reference 7" data-doi="10.1093/aje/kwp306">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19884126" aria-label="PubMed reference 7">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2800263" aria-label="PubMed Central reference 7">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Prediction%20of%20incident%20stroke%20events%20based%20on%20retinal%20vessel%20caliber%3A%20A%20systematic%20review%20and%20individual-participant%20meta-analysis&amp;journal=Am.%20J.%20Epidemiol.&amp;doi=10.1093%2Faje%2Fkwp306&amp;volume=170&amp;pages=1323-1332&amp;publication_year=2009&amp;author=McGeechan%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">den Haan, J., Verbraak, F. D., Visser, P. J. &amp; Bouwman, F. H. Retinal thickness in Alzheimer’s disease: A systematic review and meta-analysis. <i>Alzheimers. Dement.</i> <b>6</b>, 162–170 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Retinal%20thickness%20in%20Alzheimer%E2%80%99s%20disease%3A%20A%20systematic%20review%20and%20meta-analysis&amp;journal=Alzheimers.%20Dement.&amp;volume=6&amp;pages=162-170&amp;publication_year=2017&amp;author=Haan%2CJ&amp;author=Verbraak%2CFD&amp;author=Visser%2CPJ&amp;author=Bouwman%2CFH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Ko, F. <i>et al.</i> Association of retinal nerve fiber layer thinning with current and future cognitive decline: A study using optical coherence tomography. <i>JAMA Neurol.</i> <b>75</b>, 1198–1205 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jamaneurol.2018.1578" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamaneurol.2018.1578" aria-label="Article reference 9" data-doi="10.1001/jamaneurol.2018.1578">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29946685" aria-label="PubMed reference 9">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6233846" aria-label="PubMed Central reference 9">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Association%20of%20retinal%20nerve%20fiber%20layer%20thinning%20with%20current%20and%20future%20cognitive%20decline%3A%20A%20study%20using%20optical%20coherence%20tomography&amp;journal=JAMA%20Neurol.&amp;doi=10.1001%2Fjamaneurol.2018.1578&amp;volume=75&amp;pages=1198-1205&amp;publication_year=2018&amp;author=Ko%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Thomson, K. L., Yeo, J. M., Waddell, B., Cameron, J. R. &amp; Pal, S. A systematic review and meta-analysis of retinal nerve fiber layer change in dementia, using optical coherence tomography. <i>Alzheimers. Dement.</i> <b>1</b>, 136–143 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20systematic%20review%20and%20meta-analysis%20of%20retinal%20nerve%20fiber%20layer%20change%20in%20dementia%2C%20using%20optical%20coherence%20tomography&amp;journal=Alzheimers.%20Dement.&amp;volume=1&amp;pages=136-143&amp;publication_year=2015&amp;author=Thomson%2CKL&amp;author=Yeo%2CJM&amp;author=Waddell%2CB&amp;author=Cameron%2CJR&amp;author=Pal%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Cheung, C. Y. <i>et al.</i> Retinal vascular fractal dimension and its relationship with cardiovascular and ocular risk factors. <i>Am. J. Ophthalmol.</i> <b>154</b>, 663-674.e1 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.ajo.2012.04.016" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ajo.2012.04.016" aria-label="Article reference 11" data-doi="10.1016/j.ajo.2012.04.016">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22840482" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Retinal%20vascular%20fractal%20dimension%20and%20its%20relationship%20with%20cardiovascular%20and%20ocular%20risk%20factors&amp;journal=Am.%20J.%20Ophthalmol.&amp;doi=10.1016%2Fj.ajo.2012.04.016&amp;volume=154&amp;pages=663-674.e1&amp;publication_year=2012&amp;author=Cheung%2CCY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Mutlu, U. <i>et al.</i> Association of retinal neurodegeneration on optical coherence tomography with dementia: A population-based study. <i>JAMA Neurol.</i> <b>75</b>, 1256–1263 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jamaneurol.2018.1563" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamaneurol.2018.1563" aria-label="Article reference 12" data-doi="10.1001/jamaneurol.2018.1563">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29946702" aria-label="PubMed reference 12">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6233847" aria-label="PubMed Central reference 12">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Association%20of%20retinal%20neurodegeneration%20on%20optical%20coherence%20tomography%20with%20dementia%3A%20A%20population-based%20study&amp;journal=JAMA%20Neurol.&amp;doi=10.1001%2Fjamaneurol.2018.1563&amp;volume=75&amp;pages=1256-1263&amp;publication_year=2018&amp;author=Mutlu%2CU">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Owen, C. G. <i>et al.</i> Retinal vasculometry associations with cardiometabolic risk factors in the European prospective investigation of cancer-norfolk study. <i>Ophthalmology</i> <b>126</b>, 96–106 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.ophtha.2018.07.022" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ophtha.2018.07.022" aria-label="Article reference 13" data-doi="10.1016/j.ophtha.2018.07.022">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30075201" aria-label="PubMed reference 13">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Retinal%20vasculometry%20associations%20with%20cardiometabolic%20risk%20factors%20in%20the%20European%20prospective%20investigation%20of%20cancer-norfolk%20study&amp;journal=Ophthalmology&amp;doi=10.1016%2Fj.ophtha.2018.07.022&amp;volume=126&amp;pages=96-106&amp;publication_year=2019&amp;author=Owen%2CCG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">De Fauw, J. <i>et al.</i> Clinically applicable deep learning for diagnosis and referral in retinal disease. <i>Nat. Med.</i> <b>24</b>, 1342–1350 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41591-018-0107-6" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-018-0107-6" aria-label="Article reference 14" data-doi="10.1038/s41591-018-0107-6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30104768" aria-label="PubMed reference 14">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Clinically%20applicable%20deep%20learning%20for%20diagnosis%20and%20referral%20in%20retinal%20disease&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-018-0107-6&amp;volume=24&amp;pages=1342-1350&amp;publication_year=2018&amp;author=Fauw%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Schlegl, T. <i>et al.</i> Fully automated detection and quantification of macular fluid in OCT using deep learning. <i>Ophthalmology</i> <b>125</b>, 549–558 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.ophtha.2017.10.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ophtha.2017.10.031" aria-label="Article reference 15" data-doi="10.1016/j.ophtha.2017.10.031">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29224926" aria-label="PubMed reference 15">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Fully%20automated%20detection%20and%20quantification%20of%20macular%20fluid%20in%20OCT%20using%20deep%20learning&amp;journal=Ophthalmology&amp;doi=10.1016%2Fj.ophtha.2017.10.031&amp;volume=125&amp;pages=549-558&amp;publication_year=2018&amp;author=Schlegl%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Bojikian, K. D., Lee, C. S. &amp; Lee, A. Y. Finding glaucoma in color fundus photographs using deep learning. <i>JAMA Ophthalmol.</i> <a href="https://doi.org/10.1001/jamaophthalmol.2019.3512">https://doi.org/10.1001/jamaophthalmol.2019.3512</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jamaophthalmol.2019.3512" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamaophthalmol.2019.3512" aria-label="Article reference 16" data-doi="10.1001/jamaophthalmol.2019.3512">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31513255" aria-label="PubMed reference 16">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7335661" aria-label="PubMed Central reference 16">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Finding%20glaucoma%20in%20color%20fundus%20photographs%20using%20deep%20learning&amp;journal=JAMA%20Ophthalmol.&amp;doi=10.1001%2Fjamaophthalmol.2019.3512&amp;publication_year=2019&amp;author=Bojikian%2CKD&amp;author=Lee%2CCS&amp;author=Lee%2CAY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Ting, D. S. W. <i>et al.</i> Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes. <i>JAMA</i> <b>318</b>, 2211–2223 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jama.2017.18152" data-track-action="article reference" href="https://doi.org/10.1001%2Fjama.2017.18152" aria-label="Article reference 17" data-doi="10.1001/jama.2017.18152">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29234807" aria-label="PubMed reference 17">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5820739" aria-label="PubMed Central reference 17">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20and%20validation%20of%20a%20deep%20learning%20system%20for%20diabetic%20retinopathy%20and%20related%20eye%20diseases%20using%20retinal%20images%20from%20multiethnic%20populations%20with%20diabetes&amp;journal=JAMA&amp;doi=10.1001%2Fjama.2017.18152&amp;volume=318&amp;pages=2211-2223&amp;publication_year=2017&amp;author=Ting%2CDSW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Gulshan, V. <i>et al.</i> Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. <i>JAMA</i> <b>316</b>, 2402–2410 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jama.2016.17216" data-track-action="article reference" href="https://doi.org/10.1001%2Fjama.2016.17216" aria-label="Article reference 18" data-doi="10.1001/jama.2016.17216">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27898976" aria-label="PubMed reference 18">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20and%20validation%20of%20a%20deep%20learning%20algorithm%20for%20detection%20of%20diabetic%20retinopathy%20in%20retinal%20fundus%20photographs&amp;journal=JAMA&amp;doi=10.1001%2Fjama.2016.17216&amp;volume=316&amp;pages=2402-2410&amp;publication_year=2016&amp;author=Gulshan%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Hinton, G. E., Osindero, S. &amp; Teh, Y.-W. A fast learning algorithm for deep belief nets. <i>Neural Comput.</i> <b>18</b>, 1527–1554 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/neco.2006.18.7.1527" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.2006.18.7.1527" aria-label="Article reference 19" data-doi="10.1162/neco.2006.18.7.1527">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2224485" aria-label="MathSciNet reference 19">MathSciNet</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16764513" aria-label="PubMed reference 19">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="math reference" href="http://www.emis.de/MATH-item?1106.68094" aria-label="MATH reference 19">MATH</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.2006.18.7.1527&amp;volume=18&amp;pages=1527-1554&amp;publication_year=2006&amp;author=Hinton%2CGE&amp;author=Osindero%2CS&amp;author=Teh%2CY-W">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Wagner, S. K. <i>et al.</i> Insights into systemic disease through retinal imaging-based oculomics. <i>Transl. Vis. Sci. Technol.</i> <b>9</b>, 6–6 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1167/tvst.9.2.6" data-track-action="article reference" href="https://doi.org/10.1167%2Ftvst.9.2.6" aria-label="Article reference 20" data-doi="10.1167/tvst.9.2.6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32704412" aria-label="PubMed reference 20">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7343674" aria-label="PubMed Central reference 20">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Insights%20into%20systemic%20disease%20through%20retinal%20imaging-based%20oculomics&amp;journal=Transl.%20Vis.%20Sci.%20Technol.&amp;doi=10.1167%2Ftvst.9.2.6&amp;volume=9&amp;pages=6-6&amp;publication_year=2020&amp;author=Wagner%2CSK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Korot, E. <i>et al.</i> Will AI replace ophthalmologists?. <i>Transl. Vis. Sci. Technol.</i> <b>9</b>, 2–2 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1167/tvst.9.2.2" data-track-action="article reference" href="https://doi.org/10.1167%2Ftvst.9.2.2" aria-label="Article reference 21" data-doi="10.1167/tvst.9.2.2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32518707" aria-label="PubMed reference 21">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7255629" aria-label="PubMed Central reference 21">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Will%20AI%20replace%20ophthalmologists%3F&amp;journal=Transl.%20Vis.%20Sci.%20Technol.&amp;doi=10.1167%2Ftvst.9.2.2&amp;volume=9&amp;pages=2-2&amp;publication_year=2020&amp;author=Korot%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Poplin, R. <i>et al.</i> Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. <i>Nat. Biomed. Eng.</i> <b>2</b>, 158–164 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41551-018-0195-0" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-018-0195-0" aria-label="Article reference 22" data-doi="10.1038/s41551-018-0195-0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31015713" aria-label="PubMed reference 22">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Prediction%20of%20cardiovascular%20risk%20factors%20from%20retinal%20fundus%20photographs%20via%20deep%20learning&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-018-0195-0&amp;volume=2&amp;pages=158-164&amp;publication_year=2018&amp;author=Poplin%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Ting, D. S. W. &amp; Wong, T. Y. Eyeing cardiovascular risk factors. <i>Nat. Biomed. Eng.</i> <b>2</b>, 140–141 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41551-018-0210-5" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41551-018-0210-5" aria-label="Article reference 23" data-doi="10.1038/s41551-018-0210-5">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31015720" aria-label="PubMed reference 23">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Eyeing%20cardiovascular%20risk%20factors&amp;journal=Nat.%20Biomed.%20Eng.&amp;doi=10.1038%2Fs41551-018-0210-5&amp;volume=2&amp;pages=140-141&amp;publication_year=2018&amp;author=Ting%2CDSW&amp;author=Wong%2CTY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Faes, L. <i>et al.</i> Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study. <i>Lancet Digit. Health</i> <b>1</b>, e232–e242 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S2589-7500(19)30108-6" data-track-action="article reference" href="https://doi.org/10.1016%2FS2589-7500%2819%2930108-6" aria-label="Article reference 24" data-doi="10.1016/S2589-7500(19)30108-6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33323271" aria-label="PubMed reference 24">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Automated%20deep%20learning%20design%20for%20medical%20image%20classification%20by%20health-care%20professionals%20with%20no%20coding%20experience%3A%20a%20feasibility%20study&amp;journal=Lancet%20Digit.%20Health&amp;doi=10.1016%2FS2589-7500%2819%2930108-6&amp;volume=1&amp;pages=e232-e242&amp;publication_year=2019&amp;author=Faes%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Yamashita, T. <i>et al.</i> Factors in color fundus photographs that can be used by humans to determine sex of individuals. <i>Transl. Vis. Sci. Technol.</i> <b>9</b>, 4–4 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1167/tvst.9.2.4" data-track-action="article reference" href="https://doi.org/10.1167%2Ftvst.9.2.4" aria-label="Article reference 25" data-doi="10.1167/tvst.9.2.4">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32518709" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7255626" aria-label="PubMed Central reference 25">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Factors%20in%20color%20fundus%20photographs%20that%20can%20be%20used%20by%20humans%20to%20determine%20sex%20of%20individuals&amp;journal=Transl.%20Vis.%20Sci.%20Technol.&amp;doi=10.1167%2Ftvst.9.2.4&amp;volume=9&amp;pages=4-4&amp;publication_year=2020&amp;author=Yamashita%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Ooto, S., Hangai, M. &amp; Yoshimura, N. Effects of sex and age on the normal retinal and choroidal structures on optical coherence tomography. <i>Curr. Eye Res.</i> <b>40</b>, 213–225 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3109/02713683.2014.952828" data-track-action="article reference" href="https://doi.org/10.3109%2F02713683.2014.952828" aria-label="Article reference 26" data-doi="10.3109/02713683.2014.952828">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25153829" aria-label="PubMed reference 26">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20sex%20and%20age%20on%20the%20normal%20retinal%20and%20choroidal%20structures%20on%20optical%20coherence%20tomography&amp;journal=Curr.%20Eye%20Res.&amp;doi=10.3109%2F02713683.2014.952828&amp;volume=40&amp;pages=213-225&amp;publication_year=2015&amp;author=Ooto%2CS&amp;author=Hangai%2CM&amp;author=Yoshimura%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Adhi, M., Aziz, S., Muhammad, K. &amp; Adhi, M. I. Macular thickness by age and gender in healthy eyes using spectral domain optical coherence tomography. <i>PLoS ONE</i> <b>7</b>, 37638 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0037638" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0037638" aria-label="Article reference 27" data-doi="10.1371/journal.pone.0037638">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012PLoSO...737638A" aria-label="ADS reference 27">ADS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Macular%20thickness%20by%20age%20and%20gender%20in%20healthy%20eyes%20using%20spectral%20domain%20optical%20coherence%20tomography&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0037638&amp;volume=7&amp;publication_year=2012&amp;author=Adhi%2CM&amp;author=Aziz%2CS&amp;author=Muhammad%2CK&amp;author=Adhi%2CMI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Lamparter, J. <i>et al.</i> Association of ocular, cardiovascular, morphometric and lifestyle parameters with retinal nerve fibre layer thickness. <i>PLoS ONE</i> <b>13</b>, e0197682 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0197682" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0197682" aria-label="Article reference 28" data-doi="10.1371/journal.pone.0197682">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29787603" aria-label="PubMed reference 28">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5963756" aria-label="PubMed Central reference 28">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Association%20of%20ocular%2C%20cardiovascular%2C%20morphometric%20and%20lifestyle%20parameters%20with%20retinal%20nerve%20fibre%20layer%20thickness&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0197682&amp;volume=13&amp;publication_year=2018&amp;author=Lamparter%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Cascio, C., Deidda, I., Russo, D. &amp; Guarneri, P. The estrogenic retina: The potential contribution to healthy aging and age-related neurodegenerative diseases of the retina. <i>Steroids</i> <b>103</b>, 31–41 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.steroids.2015.08.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.steroids.2015.08.002" aria-label="Article reference 29" data-doi="10.1016/j.steroids.2015.08.002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXhtlWhtb7P" aria-label="CAS reference 29">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26265586" aria-label="PubMed reference 29">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20estrogenic%20retina%3A%20The%20potential%20contribution%20to%20healthy%20aging%20and%20age-related%20neurodegenerative%20diseases%20of%20the%20retina&amp;journal=Steroids&amp;doi=10.1016%2Fj.steroids.2015.08.002&amp;volume=103&amp;pages=31-41&amp;publication_year=2015&amp;author=Cascio%2CC&amp;author=Deidda%2CI&amp;author=Russo%2CD&amp;author=Guarneri%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Schmidl, D., Schmetterer, L., Garhöfer, G. &amp; Popa-Cherecheanu, A. Gender differences in ocular blood flow. <i>Curr. Eye Res.</i> <b>40</b>, 201–212 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3109/02713683.2014.906625" data-track-action="article reference" href="https://doi.org/10.3109%2F02713683.2014.906625" aria-label="Article reference 30" data-doi="10.3109/02713683.2014.906625">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXhslamsr8%3D" aria-label="CAS reference 30">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24892919" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Gender%20differences%20in%20ocular%20blood%20flow&amp;journal=Curr.%20Eye%20Res.&amp;doi=10.3109%2F02713683.2014.906625&amp;volume=40&amp;pages=201-212&amp;publication_year=2015&amp;author=Schmidl%2CD&amp;author=Schmetterer%2CL&amp;author=Garh%C3%B6fer%2CG&amp;author=Popa-Cherecheanu%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Dieck, S. <i>et al.</i> Factors in color fundus photographs that can be used by humans to determine sex of individuals. <i>Transl. Vis. Sci. Technol.</i> <b>9</b>, 8–8 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1167/tvst.9.7.8" data-track-action="article reference" href="https://doi.org/10.1167%2Ftvst.9.7.8" aria-label="Article reference 31" data-doi="10.1167/tvst.9.7.8">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32832215" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7414790" aria-label="PubMed Central reference 31">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Factors%20in%20color%20fundus%20photographs%20that%20can%20be%20used%20by%20humans%20to%20determine%20sex%20of%20individuals&amp;journal=Transl.%20Vis.%20Sci.%20Technol.&amp;doi=10.1167%2Ftvst.9.7.8&amp;volume=9&amp;pages=8-8&amp;publication_year=2020&amp;author=Dieck%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Collins, G. S. <i>et al.</i> External validation of multivariable prediction models: A systematic review of methodological conduct and reporting. <i>BMC Med. Res. Methodol.</i> <b>14</b>, 40 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1186/1471-2288-14-40" data-track-action="article reference" href="https://doi.org/10.1186%2F1471-2288-14-40" aria-label="Article reference 32" data-doi="10.1186/1471-2288-14-40">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24645774" aria-label="PubMed reference 32">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3999945" aria-label="PubMed Central reference 32">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=External%20validation%20of%20multivariable%20prediction%20models%3A%20A%20systematic%20review%20of%20methodological%20conduct%20and%20reporting&amp;journal=BMC%20Med.%20Res.%20Methodol.&amp;doi=10.1186%2F1471-2288-14-40&amp;volume=14&amp;publication_year=2014&amp;author=Collins%2CGS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Steyerberg, E. W. &amp; Harrell, F. E. Jr. Prediction models need appropriate internal, internal-external, and external validation. <i>J. Clin. Epidemiol.</i> <b>69</b>, 245–247 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jclinepi.2015.04.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jclinepi.2015.04.005" aria-label="Article reference 33" data-doi="10.1016/j.jclinepi.2015.04.005">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25981519" aria-label="PubMed reference 33">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Prediction%20models%20need%20appropriate%20internal%2C%20internal-external%2C%20and%20external%20validation&amp;journal=J.%20Clin.%20Epidemiol.&amp;doi=10.1016%2Fj.jclinepi.2015.04.005&amp;volume=69&amp;pages=245-247&amp;publication_year=2016&amp;author=Steyerberg%2CEW&amp;author=Harrell%2CFE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Faes, L. <i>et al.</i> A clinician’s guide to artificial intelligence: How to critically appraise machine learning studies. <i>Transl. Vis. Sci. Technol.</i> <b>9</b>, 7–7 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1167/tvst.9.2.7" data-track-action="article reference" href="https://doi.org/10.1167%2Ftvst.9.2.7" aria-label="Article reference 34" data-doi="10.1167/tvst.9.2.7">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32704413" aria-label="PubMed reference 34">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7346877" aria-label="PubMed Central reference 34">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20clinician%E2%80%99s%20guide%20to%20artificial%20intelligence%3A%20How%20to%20critically%20appraise%20machine%20learning%20studies&amp;journal=Transl.%20Vis.%20Sci.%20Technol.&amp;doi=10.1167%2Ftvst.9.2.7&amp;volume=9&amp;pages=7-7&amp;publication_year=2020&amp;author=Faes%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Kusner, M. J. &amp; Loftus, J. R. The long road to fairer algorithms. <i>Nature</i> <b>578</b>, 34–36 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/d41586-020-00274-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fd41586-020-00274-3" aria-label="Article reference 35" data-doi="10.1038/d41586-020-00274-3">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2020Natur.578...34K" aria-label="ADS reference 35">ADS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXjsFSntrc%3D" aria-label="CAS reference 35">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32020122" aria-label="PubMed reference 35">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20long%20road%20to%20fairer%20algorithms&amp;journal=Nature&amp;doi=10.1038%2Fd41586-020-00274-3&amp;volume=578&amp;pages=34-36&amp;publication_year=2020&amp;author=Kusner%2CMJ&amp;author=Loftus%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Kelly, C. J., Karthikesalingam, A., Suleyman, M., Corrado, G. &amp; King, D. Key challenges for delivering clinical impact with artificial intelligence. <i>BMC Med.</i> <b>17</b>, 195 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1186/s12916-019-1426-2" data-track-action="article reference" href="https://doi.org/10.1186%2Fs12916-019-1426-2" aria-label="Article reference 36" data-doi="10.1186/s12916-019-1426-2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31665002" aria-label="PubMed reference 36">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6821018" aria-label="PubMed Central reference 36">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Key%20challenges%20for%20delivering%20clinical%20impact%20with%20artificial%20intelligence&amp;journal=BMC%20Med.&amp;doi=10.1186%2Fs12916-019-1426-2&amp;volume=17&amp;publication_year=2019&amp;author=Kelly%2CCJ&amp;author=Karthikesalingam%2CA&amp;author=Suleyman%2CM&amp;author=Corrado%2CG&amp;author=King%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Barocas, S. &amp; Selbst, A. D. Big data’s disparate impact. <i>Calif. L. Rev.</i> <a href="https://doi.org/10.2139/ssrn.2477899">https://doi.org/10.2139/ssrn.2477899</a> (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.2139/ssrn.2477899" data-track-action="article reference" href="https://doi.org/10.2139%2Fssrn.2477899" aria-label="Article reference 37" data-doi="10.2139/ssrn.2477899">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Big%20data%E2%80%99s%20disparate%20impact&amp;journal=Calif.%20L.%20Rev.&amp;doi=10.2139%2Fssrn.2477899&amp;publication_year=2016&amp;author=Barocas%2CS&amp;author=Selbst%2CAD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Sudlow, C. <i>et al.</i> UK biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age. <i>PLoS Med.</i> <b>12</b>, 1001779 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pmed.1001779" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pmed.1001779" aria-label="Article reference 38" data-doi="10.1371/journal.pmed.1001779">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=UK%20biobank%3A%20An%20open%20access%20resource%20for%20identifying%20the%20causes%20of%20a%20wide%20range%20of%20complex%20diseases%20of%20middle%20and%20old%20age&amp;journal=PLoS%20Med.&amp;doi=10.1371%2Fjournal.pmed.1001779&amp;volume=12&amp;publication_year=2015&amp;author=Sudlow%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Keane, P. A. <i>et al.</i> Optical coherence tomography in the UK Biobank study: Rapid automated analysis of retinal thickness for large population-based studies. <i>PLoS ONE</i> <b>11</b>, e0164095 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0164095" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0164095" aria-label="Article reference 39" data-doi="10.1371/journal.pone.0164095">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27716837" aria-label="PubMed reference 39">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5055325" aria-label="PubMed Central reference 39">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Optical%20coherence%20tomography%20in%20the%20UK%20Biobank%20study%3A%20Rapid%20automated%20analysis%20of%20retinal%20thickness%20for%20large%20population-based%20studies&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0164095&amp;volume=11&amp;publication_year=2016&amp;author=Keane%2CPA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Liu, X. <i>et al.</i> A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: A systematic review and meta-analysis. <i>Lancet Digit. Health</i> <b>1</b>, e271–e297 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S2589-7500(19)30123-2" data-track-action="article reference" href="https://doi.org/10.1016%2FS2589-7500%2819%2930123-2" aria-label="Article reference 40" data-doi="10.1016/S2589-7500(19)30123-2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33323251" aria-label="PubMed reference 40">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20comparison%20of%20deep%20learning%20performance%20against%20health-care%20professionals%20in%20detecting%20diseases%20from%20medical%20imaging%3A%20A%20systematic%20review%20and%20meta-analysis&amp;journal=Lancet%20Digit.%20Health&amp;doi=10.1016%2FS2589-7500%2819%2930123-2&amp;volume=1&amp;pages=e271-e297&amp;publication_year=2019&amp;author=Liu%2CX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Sendak, M. P., Gao, M., Brajer, N. &amp; Balu, S. Presenting machine learning model information to clinical end users with model facts labels. <i>NPJ Digit. Med.</i> <b>3</b>, 41 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41746-020-0253-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-020-0253-3" aria-label="Article reference 41" data-doi="10.1038/s41746-020-0253-3">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32219182" aria-label="PubMed reference 41">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7090057" aria-label="PubMed Central reference 41">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Presenting%20machine%20learning%20model%20information%20to%20clinical%20end%20users%20with%20model%20facts%20labels&amp;journal=NPJ%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-020-0253-3&amp;volume=3&amp;publication_year=2020&amp;author=Sendak%2CMP&amp;author=Gao%2CM&amp;author=Brajer%2CN&amp;author=Balu%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Kapishnikov, A., Bolukbasi, T., Viégas, F. &amp; Terry, M. XRAI: Better Attributions Through Regions. <i>arXiv [cs.CV]</i> (2019).</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-021-89743-x?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This research has been conducted using the UK Biobank Resource under application number 36741. This work was supported by Springboard (190016A (EK)) and Career Development (190028A (PAK)) Awards from Moorfields Eye Charity, a UK Research &amp; Innovation (UKRI) Future Leaders Fellowship (MR/T019050/1 (PAK)), and a UK National Institute for Health Research (NIHR) Clinician Scientist Award (NIHR-CS–2014-12-023 (PAK)). The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, or the Department of Health. We would like to thank Ryan Poplin and Yun Liu for their thoughtful review and comments on the manuscript.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">NIHR Biomedical Research Center at Moorfields Eye Hospital NHS Foundation Trust and UCL Institute of Ophthalmology, London, UK</p><p class="c-article-author-affiliation__authors-list">Edward Korot, Nikolas Pontikos, Xiaoxuan Liu, Siegfried K. Wagner, Livia Faes, Josef Huemer, Konstantinos Balaskas, Alastair K. Denniston, Anthony Khawaja &amp; Pearse A. Keane</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Ophthalmology, University Hospitals Birmingham NHS Foundation Trust, Birmingham, UK</p><p class="c-article-author-affiliation__authors-list">Xiaoxuan Liu &amp; Alastair K. Denniston</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Academic Unit of Ophthalmology, Institute of Inflammation &amp; Ageing, College of Medical and Dental Sciences, University of Birmingham, Birmingham, UK</p><p class="c-article-author-affiliation__authors-list">Xiaoxuan Liu &amp; Alastair K. Denniston</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Eye Clinic, Cantonal Hospital of Lucerne, Lucerne, Switzerland</p><p class="c-article-author-affiliation__authors-list">Livia Faes</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Vienna Institute for Research in Ocular Surgery, A Karl Landsteiner Institute, Hanusch Hospital, Vienna, Austria</p><p class="c-article-author-affiliation__authors-list">Josef Huemer</p></li><li id="Aff6"><p class="c-article-author-affiliation__address">Health Data Research UK, London, UK</p><p class="c-article-author-affiliation__authors-list">Alastair K. Denniston</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Edward-Korot"><span class="c-article-authors-search__title u-h3 js-search-name">Edward Korot</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Edward%20Korot" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Edward%20Korot" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Edward%20Korot%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Nikolas-Pontikos"><span class="c-article-authors-search__title u-h3 js-search-name">Nikolas Pontikos</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Nikolas%20Pontikos" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nikolas%20Pontikos" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nikolas%20Pontikos%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Xiaoxuan-Liu"><span class="c-article-authors-search__title u-h3 js-search-name">Xiaoxuan Liu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Xiaoxuan%20Liu" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Xiaoxuan%20Liu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Xiaoxuan%20Liu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Siegfried_K_-Wagner"><span class="c-article-authors-search__title u-h3 js-search-name">Siegfried K. Wagner</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Siegfried%20K.%20Wagner" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Siegfried%20K.%20Wagner" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Siegfried%20K.%20Wagner%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Livia-Faes"><span class="c-article-authors-search__title u-h3 js-search-name">Livia Faes</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Livia%20Faes" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Livia%20Faes" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Livia%20Faes%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Josef-Huemer"><span class="c-article-authors-search__title u-h3 js-search-name">Josef Huemer</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Josef%20Huemer" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Josef%20Huemer" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Josef%20Huemer%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Konstantinos-Balaskas"><span class="c-article-authors-search__title u-h3 js-search-name">Konstantinos Balaskas</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Konstantinos%20Balaskas" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Konstantinos%20Balaskas" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Konstantinos%20Balaskas%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Alastair_K_-Denniston"><span class="c-article-authors-search__title u-h3 js-search-name">Alastair K. Denniston</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Alastair%20K.%20Denniston" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alastair%20K.%20Denniston" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alastair%20K.%20Denniston%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Anthony-Khawaja"><span class="c-article-authors-search__title u-h3 js-search-name">Anthony Khawaja</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Anthony%20Khawaja" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Anthony%20Khawaja" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Anthony%20Khawaja%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Pearse_A_-Keane"><span class="c-article-authors-search__title u-h3 js-search-name">Pearse A. Keane</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Pearse%20A.%20Keane" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Pearse%20A.%20Keane" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Pearse%20A.%20Keane%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>E.K. initiated the project. E.K. and A.K. created the dataset. E.K. contributed to software engineering. E.K., N.P., S.K.W., A.K., and P.A.K. analyzed the results. E.K. and A.K. contributed to the overall experimental design. E.K. designed the model architectures. J.H., A.K.D., K.B., P.A.K. contributed clinical expertise. E.K., A.K. contributed to subgroup analysis experiments. A.K., X.L., L.F. contributed to statistical analysis. E.K., A.K. contributed to experiments using segmentation data. S.K.W., X.L. contributed to literature reviews. E.K. managed the project. E.K., J.H., A.K. wrote the paper.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:anthony.khawaja@nhs.net">Anthony Khawaja</a> or <a id="corresp-c2" href="mailto:pearse.keane1@nhs.net">Pearse A. Keane</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar1">Competing interests</h3>
                <p>EK is a consultant for Google Health. PAK has received speaker fees from Heidelberg Engineering, Topcon, Haag-Streit, Allergan, Novartis and Bayer. PAK has served on advisory boards for Novartis and Bayer, and is a consultant for DeepMind, Roche, Novartis and Apellis. KB has received research grants from Novartis, Bayer. Heidelberg and Roche. KB has received speaker fees from Novartis, Bayer, TopCon, Heidelberg, Allergan, Alimera. KB is a consultant for Novartis, Bayer and Roche. AK is a consultant to Aerie, Allergan, Novartis, Google Health, Reichert and Santen. All other co-authors have no competing interests to declare.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publisher's note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Supplementary Information"><div class="c-article-section" id="Sec15-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec15">Supplementary Information</h2><div class="c-article-section__content" id="Sec15-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-021-89743-x/MediaObjects/41598_2021_89743_MOESM1_ESM.docx" data-supp-info-image="">Supplementary Information.</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Predicting%20sex%20from%20retinal%20fundus%20photographs%20using%20automated%20deep%20learning&amp;author=Edward%20Korot%20et%20al&amp;contentID=10.1038%2Fs41598-021-89743-x&amp;copyright=The%20Author%28s%29&amp;publication=2045-2322&amp;publicationDate=2021-05-13&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41598-021-89743-x" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-021-89743-x" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Korot, E., Pontikos, N., Liu, X. <i>et al.</i> Predicting sex from retinal fundus photographs using automated deep learning.
                    <i>Sci Rep</i> <b>11</b>, 10286 (2021). https://doi.org/10.1038/s41598-021-89743-x</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-021-89743-x?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-04-07">07 April 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-04-22">22 April 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-05-13">13 May 2021</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41598-021-89743-x</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Estimation of best corrected visual acuity based on deep neural network" href="https://doi.org/10.1038/s41598-022-22586-2">
                                        Estimation of best corrected visual acuity based on deep neural network
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Woongsup Lee</li><li>Jin Hyun Kim</li><li>Yong Seop Han</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Evaluating an automated machine learning model that predicts visual acuity outcomes in patients with neovascular age-related macular degeneration" href="https://doi.org/10.1007/s00417-021-05544-y">
                                        Evaluating an automated machine learning model that predicts visual acuity outcomes in patients with neovascular age-related macular degeneration
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Abdallah Abbas</li><li>Ciara O’Byrne</li><li>Pearse A. Keane</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Graefe&#x27;s Archive for Clinical and Experimental Ophthalmology</i> (2022)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
                <section data-title="Comments"><div class="c-article-section" id="article-comments-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-comments">Comments</h2><div class="c-article-section__content" id="article-comments-content"><p>By submitting a comment you agree to abide by our <a href="/info/tandc.html">Terms</a> and <a href="/info/community-guidelines.html">Community Guidelines</a>. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.</p></div></div></section>
                <div id="inject-comments">
                    <div class="placeholder" data-replace="true"
                         data-disqus-placeholder="/platform/disqus?doi=10.1038/s41598-021-89743-x #article-comments-container">
                </div>
            </div>
            

            <span data-recommended="jobs"></span>
</div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            
                
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41598-021-89743-x.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            </a>
        </div>
    

            
        
    </div>

    
        
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/scientific_reports/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41598-021-89743-x;doi=10.1038/s41598-021-89743-x;subjmeta=117,308,575,639,692,705;kwrd=Computer+science,Translational+research">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/scientific_reports/article&amp;sz=300x250&amp;c=992241895&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41598-021-89743-x%26doi%3D10.1038/s41598-021-89743-x%26subjmeta%3D117,308,575,639,692,705%26kwrd%3DComputer+science,Translational+research">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/scientific_reports/article&amp;sz=300x250&amp;c=992241895&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41598-021-89743-x%26doi%3D10.1038/s41598-021-89743-x%26subjmeta%3D117,308,575,639,692,705%26kwrd%3DComputer+science,Translational+research"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/browse-subjects"
                                   data-track="click"
                                   data-track-action="subjects"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Subjects
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://www.facebook.com/scientificreports"
                               data-track="click"
                               data-track-action="facebook"
                               data-track-label="link">Follow us on Facebook
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/SciReports"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;288"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/srep.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/about"
                                   data-track="click"
                                   data-track-action="about scientific reports"
                                   data-track-label="link">
                                    About Scientific Reports
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/open-access"
                                   data-track="click"
                                   data-track-action="open access"
                                   data-track-label="link">
                                    Open Access
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/journal-policies"
                                   data-track="click"
                                   data-track-action="journal policies"
                                   data-track-label="link">
                                    Journal policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/guide-to-referees"
                                   data-track="click"
                                   data-track-action="guide to referees"
                                   data-track-label="link">
                                    Guide to referees
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/calls-for-papers"
                                   data-track="click"
                                   data-track-action="calls for papers"
                                   data-track-label="link">
                                    Calls for Papers
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/editorschoice"
                                   data-track="click"
                                   data-track-action="editor&#x27;s choice"
                                   data-track-label="link">
                                    Editor&#x27;s Choice
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/highlights"
                                   data-track="click"
                                   data-track-action="journal highlights"
                                   data-track-label="link">
                                    Journal highlights
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/srep/author-instructions"
                                   data-track="click"
                                   data-track-action="for authors"
                                   data-track-label="link">
                                    For authors
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://author-welcome.nature.com/41598"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="srep">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Scientific Reports (<i>Sci Rep</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">2045-2322</span> (online)
    </span>
    


                
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects/"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://nano.nature.com/"
                                                  data-track="click" data-track-action="nano" data-track-label="link">Nano</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies/"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints/"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/researcher-training/"
                                                  data-track="click" data-track-action="nature research academies"
                                                  data-track-label="link">Nature Research Academies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions/"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Career development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natureevents/"
                                                  data-track="click" data-track-action="nature events"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        events</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp/"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr/"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast/"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Manage cookies/Do not sell my data
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">California Privacy Statement</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2022 Springer Nature Limited</p>
</div>

    </div>
    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 10 10" xmlns="http://www.w3.org/2000/svg">
            <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="currentColor" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-success" viewBox="0 0 18 18">
            <path d="M9 0a9 9 0 110 18A9 9 0 019 0zm3.486 4.982l-4.718 5.506L5.14 8.465a.991.991 0 00-1.423.133 1.06 1.06 0 00.13 1.463l3.407 2.733a1 1 0 001.387-.133l5.385-6.334a1.06 1.06 0 00-.116-1.464.991.991 0 00-1.424.119z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
        <symbol id="icon-warning" viewBox="0 0 18 18">
            <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-plus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-minus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-error" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-springer-arrow-left">
            <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/>
        </symbol>
        <symbol id="icon-springer-arrow-right">
            <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/>
        </symbol>
        <symbol id="icon-arrow-up" viewBox="0 0 16 16">
            <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-tick" viewBox="0 0 24 24">
            <path d="M12,24 C5.372583,24 0,18.627417 0,12 C0,5.372583 5.372583,0 12,0 C18.627417,0 24,5.372583 24,12 C24,18.627417 18.627417,24 12,24 Z M7.657,10.79 C7.45285634,10.6137568 7.18569967,10.5283283 6.91717333,10.5534259 C6.648647,10.5785236 6.40194824,10.7119794 6.234,10.923 C5.87705269,11.3666969 5.93445559,12.0131419 6.364,12.387 L10.261,15.754 C10.6765468,16.112859 11.3037113,16.0695601 11.666,15.657 L17.759,8.713 C18.120307,8.27302248 18.0695334,7.62621189 17.644,7.248 C17.4414817,7.06995024 17.1751516,6.9821166 16.9064461,7.00476032 C16.6377406,7.02740404 16.3898655,7.15856958 16.22,7.368 L10.768,13.489 L7.657,10.79 Z"/>
        </symbol>
        <symbol id="icon-expand-image" viewBox="0 0 18 18">
            <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-close" viewBox="0 0 16 16">
            <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-right" viewBox="0 0 7 12">
            <path d="M2.782 5 .3 2.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 0 1 1.417 0l4.176 4.177a1.001 1.001 0 0 1 0 1.416l-4.176 4.177a.991.991 0 0 1-1.4.016A1 1 0 0 1 .3 9.481L2.782 7l1.013-.998L2.782 5Z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69">
            <style type="text/css">.st0 {
                fill: none;
            }

            .st1 {
                clip-path: url(#SVGID_2_);
                fill: none;
                stroke: #01324B;
                stroke-width: 2;
                stroke-linecap: round;
            }

            .st2 {
                clip-path: url(#SVGID_2_);
                fill: none;
                stroke: #01324B;
                stroke-width: 2;
                stroke-linecap: round;
                stroke-linejoin: round;
            }</style>
            <rect id="transparent_background" class="st0" width="56.69" height="56.69"/>
            <g>
                <clipPath id="SVGID_2_">
                    <use xlink:href="#SVGID_1_" style="overflow:visible"/>
                </clipPath>
                <path class="st1" d="M21.14,34.46c0-6.77,5.48-12.26,12.24-12.26c6.76,0,12.24,5.49,12.24,12.26c0,6.77-5.48,12.26-12.24,12.26
		C26.62,46.71,21.14,41.23,21.14,34.46z M40.47,45.12l10.23,9.22c0,0,1.21,1.09,2.3-0.12l2.09-2.32c0,0,1.09-1.21-0.12-2.3
		l-10.23-9.22 M25.45,34.46c0-4.38,3.55-7.94,7.93-7.94c4.38,0,7.93,3.55,7.93,7.94c0,4.38-3.55,7.94-7.93,7.94
		C29,42.39,25.45,38.84,25.45,34.46z M43.03,47.45l4.14-4.81"/>
                <path class="st2" d="M8.26,9.75H28.6 M8.26,15.98H28.6 M8.26,22.18h12.5 M35.18,16.98V4.86c0,0,0-2.93-2.93-2.93H4.13
		c0,0-2.93,0-2.93,2.93v37.57c0,0,0,2.93,2.93,2.93h15.01 M8.26,9.75H28.6 M8.26,15.98H28.6 M8.26,22.18h12.5"/>
            </g>
            <g/>
            <g/>
            <g/>
            <g/>
            <g/>
            <g/>
        </symbol>
    </svg>

</footer>




    
        

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="redesign banner visible">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="redesign banner dismiss">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="/briefing/signup/formfeedback" method="post" data-location="banner" data-track="submit" data-track-action="transmit-form">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="DirectEmailBannerRedesign2020">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">
                        <label class="nature-briefing-banner__email-label" for="banner-EmailAddressInput">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="banner-EmailAddressInput" name="email" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="1" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="redesign banner dismiss">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="redesign banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="/briefing/signup/">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>

    




<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41598-021-89743-x&amp;format=js&amp;last_modified=2021-05-13" async></script>
<img src="/62xt6bz3/article/s41598-021-89743-x" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>