{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYRCprJ4J0cI",
    "outputId": "066239a8-dd50-4d85-c151-ddd8da56aec9"
   },
   "outputs": [],
   "source": [
    "#!pip install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o5jrHZ02ZH-E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlgmlppcmG8l",
    "outputId": "aaf052c3-4eda-45a0-bd8b-e8c5dc300cd2"
   },
   "outputs": [],
   "source": [
    "#!npx degit kelu124/substack/.archive substack --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CHOiqPcGm3MZ"
   },
   "outputs": [],
   "source": [
    "files = os.listdir('.archive')\n",
    "file_names = []\n",
    "for name in files:\n",
    "    if not ('type' in name):\n",
    "        file_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_parquet('articles.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DONE = list(D.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2M0eAjrBkcxj",
    "outputId": "d13e7cf3-e36f-4c28-83f8-32fcde073306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xbf in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xc4 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xd0 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xf3 in position 6637: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xbf in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 11: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc4 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xd4 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xb5 in position 11: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xbf in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x9c in position 147: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xf6 in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x94 in position 4479: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xa0 in position 683: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xb5 in position 11: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "errors = []\n",
    "for file_name in file_names:\n",
    "    if file_name not in DONE:\n",
    "        with io.open(f'.archive/{file_name}', mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                mytree = html.fromstring(\"\".join(f.readlines()))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors.append(file_name)\n",
    "                continue\n",
    "            try:\n",
    "                content = trafilatura.extract(mytree)\n",
    "                articles.append((file_name, content))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jhx063gpXZP",
    "outputId": "b75f3fc9-5e0e-422a-8e5e-abc40b8de788"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, content, LEN]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW = pd.DataFrame(articles, columns = ['file_name', 'content'])\n",
    "NEW[\"LEN\"] = NEW[\"content\"].apply(lambda x: len(str(x)))\n",
    "NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1598)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NEW),len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e-b5jUsupaOX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58612e45effab1e47df9a86b14dfae85</td>\n",
       "      <td>Discover more from The Generalist\\nLife in a K...</td>\n",
       "      <td>22376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115b59fc3f0d7b148482545adb1a8038</td>\n",
       "      <td>Google DeepMind researchers have discovered 2....</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab122d29aed97045e0cc1ea77bdef44</td>\n",
       "      <td>The Responsible AI Institute\\nNavigating Organ...</td>\n",
       "      <td>13194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b7b3c515859db4c0f6537824019cb7b</td>\n",
       "      <td>PANAMA CITY, Oct 31 (Reuters) – The Panama Can...</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338c551fe29e9fb73aa8d412dc77788e</td>\n",
       "      <td>By Rishad Tobaccowala\\nDecades ago, the Book o...</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>d89d7cc690ceaaafaecc9f40ff8230c5</td>\n",
       "      <td>My kids and I just played D&amp;D with ChatGPT4 as...</td>\n",
       "      <td>34489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>de8ad50911f7ef9e91749296d5638e43</td>\n",
       "      <td>Access Check\\nOur systems have detected unusua...</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     58612e45effab1e47df9a86b14dfae85   \n",
       "1     115b59fc3f0d7b148482545adb1a8038   \n",
       "2     fab122d29aed97045e0cc1ea77bdef44   \n",
       "3     8b7b3c515859db4c0f6537824019cb7b   \n",
       "4     338c551fe29e9fb73aa8d412dc77788e   \n",
       "...                                ...   \n",
       "1593  e8b7faf708568f9f39abe04b778c4631   \n",
       "1594  b79a2baa87b68283198416791b93bce4   \n",
       "1595  d89d7cc690ceaaafaecc9f40ff8230c5   \n",
       "1596  69637dcd83c48ebde0610a61a27b1989   \n",
       "1597  de8ad50911f7ef9e91749296d5638e43   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     Discover more from The Generalist\\nLife in a K...  22376  \n",
       "1     Google DeepMind researchers have discovered 2....   3950  \n",
       "2     The Responsible AI Institute\\nNavigating Organ...  13194  \n",
       "3     PANAMA CITY, Oct 31 (Reuters) – The Panama Can...   2049  \n",
       "4     By Rishad Tobaccowala\\nDecades ago, the Book o...   5082  \n",
       "...                                                 ...    ...  \n",
       "1593  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1594  The U.S. government has restricted sales of Nv...   2125  \n",
       "1595  My kids and I just played D&D with ChatGPT4 as...  34489  \n",
       "1596  The newest Kindle is the first truly new Kindl...   6249  \n",
       "1597  Access Check\\nOur systems have detected unusua...    457  \n",
       "\n",
       "[1598 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([NEW,D]).reset_index(drop=True)\n",
    "len(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kkOCiNSEpnRm"
   },
   "outputs": [],
   "source": [
    "df.to_parquet('articles.parquet.gzip',compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "djucDjpLcv4L"
   },
   "outputs": [],
   "source": [
    "# More testing here about the coherent text that has to be found, find upper elements if p doesn't mention classes. \n",
    "# or merge everything than clean up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "eAhNl6kbCjHj",
    "outputId": "16506629-352b-4909-9b93-602d025bd233"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58612e45effab1e47df9a86b14dfae85</td>\n",
       "      <td>Discover more from The Generalist\\nLife in a K...</td>\n",
       "      <td>22376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115b59fc3f0d7b148482545adb1a8038</td>\n",
       "      <td>Google DeepMind researchers have discovered 2....</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab122d29aed97045e0cc1ea77bdef44</td>\n",
       "      <td>The Responsible AI Institute\\nNavigating Organ...</td>\n",
       "      <td>13194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b7b3c515859db4c0f6537824019cb7b</td>\n",
       "      <td>PANAMA CITY, Oct 31 (Reuters) – The Panama Can...</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338c551fe29e9fb73aa8d412dc77788e</td>\n",
       "      <td>By Rishad Tobaccowala\\nDecades ago, the Book o...</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>d89d7cc690ceaaafaecc9f40ff8230c5</td>\n",
       "      <td>My kids and I just played D&amp;D with ChatGPT4 as...</td>\n",
       "      <td>34489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>de8ad50911f7ef9e91749296d5638e43</td>\n",
       "      <td>Access Check\\nOur systems have detected unusua...</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     58612e45effab1e47df9a86b14dfae85   \n",
       "1     115b59fc3f0d7b148482545adb1a8038   \n",
       "2     fab122d29aed97045e0cc1ea77bdef44   \n",
       "3     8b7b3c515859db4c0f6537824019cb7b   \n",
       "4     338c551fe29e9fb73aa8d412dc77788e   \n",
       "...                                ...   \n",
       "1593  e8b7faf708568f9f39abe04b778c4631   \n",
       "1594  b79a2baa87b68283198416791b93bce4   \n",
       "1595  d89d7cc690ceaaafaecc9f40ff8230c5   \n",
       "1596  69637dcd83c48ebde0610a61a27b1989   \n",
       "1597  de8ad50911f7ef9e91749296d5638e43   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     Discover more from The Generalist\\nLife in a K...  22376  \n",
       "1     Google DeepMind researchers have discovered 2....   3950  \n",
       "2     The Responsible AI Institute\\nNavigating Organ...  13194  \n",
       "3     PANAMA CITY, Oct 31 (Reuters) – The Panama Can...   2049  \n",
       "4     By Rishad Tobaccowala\\nDecades ago, the Book o...   5082  \n",
       "...                                                 ...    ...  \n",
       "1593  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1594  The U.S. government has restricted sales of Nv...   2125  \n",
       "1595  My kids and I just played D&D with ChatGPT4 as...  34489  \n",
       "1596  The newest Kindle is the first truly new Kindl...   6249  \n",
       "1597  Access Check\\nOur systems have detected unusua...    457  \n",
       "\n",
       "[1598 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('articles.parquet.gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "S6yT9zwZCmZM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58612e45effab1e47df9a86b14dfae85</td>\n",
       "      <td>Discover more from The Generalist\\nLife in a K...</td>\n",
       "      <td>22376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115b59fc3f0d7b148482545adb1a8038</td>\n",
       "      <td>Google DeepMind researchers have discovered 2....</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab122d29aed97045e0cc1ea77bdef44</td>\n",
       "      <td>The Responsible AI Institute\\nNavigating Organ...</td>\n",
       "      <td>13194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b7b3c515859db4c0f6537824019cb7b</td>\n",
       "      <td>PANAMA CITY, Oct 31 (Reuters) – The Panama Can...</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338c551fe29e9fb73aa8d412dc77788e</td>\n",
       "      <td>By Rishad Tobaccowala\\nDecades ago, the Book o...</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>3fbb11d6e949d1e662aa6a146bb6cda0</td>\n",
       "      <td>China’s growing number of insomniacs are turni...</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>d89d7cc690ceaaafaecc9f40ff8230c5</td>\n",
       "      <td>My kids and I just played D&amp;D with ChatGPT4 as...</td>\n",
       "      <td>34489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     58612e45effab1e47df9a86b14dfae85   \n",
       "1     115b59fc3f0d7b148482545adb1a8038   \n",
       "2     fab122d29aed97045e0cc1ea77bdef44   \n",
       "3     8b7b3c515859db4c0f6537824019cb7b   \n",
       "4     338c551fe29e9fb73aa8d412dc77788e   \n",
       "...                                ...   \n",
       "1592  3fbb11d6e949d1e662aa6a146bb6cda0   \n",
       "1593  e8b7faf708568f9f39abe04b778c4631   \n",
       "1594  b79a2baa87b68283198416791b93bce4   \n",
       "1595  d89d7cc690ceaaafaecc9f40ff8230c5   \n",
       "1596  69637dcd83c48ebde0610a61a27b1989   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     Discover more from The Generalist\\nLife in a K...  22376  \n",
       "1     Google DeepMind researchers have discovered 2....   3950  \n",
       "2     The Responsible AI Institute\\nNavigating Organ...  13194  \n",
       "3     PANAMA CITY, Oct 31 (Reuters) – The Panama Can...   2049  \n",
       "4     By Rishad Tobaccowala\\nDecades ago, the Book o...   5082  \n",
       "...                                                 ...    ...  \n",
       "1592  China’s growing number of insomniacs are turni...   2859  \n",
       "1593  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1594  The U.S. government has restricted sales of Nv...   2125  \n",
       "1595  My kids and I just played D&D with ChatGPT4 as...  34489  \n",
       "1596  The newest Kindle is the first truly new Kindl...   6249  \n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unaccessible articles\n",
    "df = df[~(df['content'] == \"Please switch to a supported browser to continue using twitter.com. You can see a list of supported browsers in our Help Center.\\nHelp Center\\nTerms of Service\\nPrivacy Policy\\nCookie Policy\\nImprint\\nAds info\\n© 2022 Twitter, Inc.\")]\n",
    "df = df[df.LEN >= 1500]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "2F4lQyQ8C2-6",
    "outputId": "f462f9e6-d89a-4f1d-ac6f-daadebd0005c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11612.282031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20382.649288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>496896.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LEN\n",
       "count    1280.000000\n",
       "mean    11612.282031\n",
       "std     20382.649288\n",
       "min      1505.000000\n",
       "25%      3761.000000\n",
       "50%      6830.000000\n",
       "75%     12885.000000\n",
       "max    496896.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD7XlA9GPOwn",
    "outputId": "cba21fd0-86e1-4d91-a84f-9312450d518c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1062640)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF Feature Generation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Initialize regex tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# # Vectorize document using TF-IDF\n",
    "tf_idf_vect = TfidfVectorizer(lowercase=True,\n",
    "                        stop_words='english',\n",
    "                        ngram_range = (1,2),\n",
    "                        tokenizer = tokenizer.tokenize)\n",
    "\n",
    "# Fit and Transfrom Text Data\n",
    "X_train_counts = tf_idf_vect.fit_transform(df['content'])\n",
    "\n",
    "# Check Shape of Count Vector\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h84TuTLcPj8a",
    "outputId": "d7fb2ddf-1270-4d8f-b843-4894c47af982"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1062640 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2828 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EnlSHztpPjV8"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unusual file processing time, aborting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create Kmeans object and fit it to the training data \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get the labels using KMeans\u001b[39;00m\n\u001b[1;32m      7\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1410\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1406\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1410\u001b[0m     centers_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:952\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, init_size, n_centroids)\u001b[0m\n\u001b[1;32m    949\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 952\u001b[0m     centers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    959\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mpermutation(n_samples)[:n_clusters]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:224\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    221\u001b[0m np\u001b[38;5;241m.\u001b[39mclip(candidate_ids, \u001b[38;5;28;01mNone\u001b[39;00m, closest_dist_sq\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, out\u001b[38;5;241m=\u001b[39mcandidate_ids)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Compute distances to center candidates\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m distance_to_candidates \u001b[38;5;241m=\u001b[39m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[1;32m    229\u001b[0m np\u001b[38;5;241m.\u001b[39mminimum(closest_dist_sq, distance_to_candidates, out\u001b[38;5;241m=\u001b[39mdistance_to_candidates)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:369\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    371\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:152\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    155\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m ):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:623\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    622\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:537\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[1;32m    540\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_compressed.py:512\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    509\u001b[0m K2, N \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    511\u001b[0m major_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((M, N))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 512\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# convert to this format\u001b[39;00m\n\u001b[1;32m    514\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m    515\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices))\n\u001b[1;32m    517\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat_maxnnz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_compressed.py:33\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     31\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m arg1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m \u001b[43marg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_self(arg1)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg1, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:376\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Forward the copy kwarg, if it's accepted.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_csc.py:140\u001b[0m, in \u001b[0;36mcsc_matrix.tocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    137\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m    138\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 140\u001b[0m \u001b[43mcsc_tocsr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m          \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m          \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_csr_container(\n\u001b[1;32m    149\u001b[0m     (data, indices, indptr),\n\u001b[1;32m    150\u001b[0m     shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    151\u001b[0m )\n\u001b[1;32m    152\u001b[0m A\u001b[38;5;241m.\u001b[39mhas_sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/trafilatura/core.py:978\u001b[0m, in \u001b[0;36mtimeout_handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeout_handler\u001b[39m(signum, frame):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;124;03m'''Raise a timeout exception to handle rare malicious files'''\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munusual file processing time, aborting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unusual file processing time, aborting"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create Kmeans object and fit it to the training data \n",
    "kmeans = KMeans(n_clusters=10).fit(X_train_counts)\n",
    "\n",
    "# Get the labels using KMeans\n",
    "pred_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwYEKEkbQPoa"
   },
   "outputs": [],
   "source": [
    "# Import WordCloud and STOPWORDS\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "def word_cloud(text,wc_title,wc_file_name='wordcloud.jpeg'):\n",
    "    # Create stopword list\n",
    "    stopword_list = set(STOPWORDS) \n",
    "\n",
    "    # Create WordCloud \n",
    "    word_cloud = WordCloud(width = 800, height = 500, \n",
    "                           background_color ='white', \n",
    "                           stopwords = stopword_list, \n",
    "                           min_font_size = 14).generate(text) \n",
    "\n",
    "    # Set wordcloud figure size\n",
    "    plt.figure(figsize = (8, 6)) \n",
    "    \n",
    "    # Set title for word cloud\n",
    "    plt.title(wc_title)\n",
    "    \n",
    "    # Show image\n",
    "    plt.imshow(word_cloud) \n",
    "\n",
    "    # Remove Axis\n",
    "    plt.axis(\"off\")  \n",
    "\n",
    "    # save word cloud\n",
    "    # plt.savefig(wc_file_name,bbox_inches='tight')\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5tqLF7gePy8k",
    "outputId": "21d14f18-dd15-46e8-9f2e-6508702549d7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_df=pd.DataFrame({\"text\":df['content'],\"labels\":pred_labels})\n",
    "\n",
    "\n",
    "for i in new_df.labels.unique():\n",
    "    new_new_df=new_df[new_df.labels==i]\n",
    "    text=\"\".join(new_new_df.text.tolist())\n",
    "    word_cloud(text,f\"group {i}\",f'{i}.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfoGIIlWRLmc"
   },
   "outputs": [],
   "source": [
    "# new_df includes the category for errord ones as well.\n",
    "\n",
    "# No context is given, so the group name is default to the group number.\n",
    "\n",
    "# We can use the common words found in each group to formulate a title?\n",
    "new_df.to_csv('grouped_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ETpJY7IpPN63",
    "outputId": "8e6c28d8-ddc4-4830-930b-1060132061e3"
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
