{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYRCprJ4J0cI",
    "outputId": "066239a8-dd50-4d85-c151-ddd8da56aec9"
   },
   "outputs": [],
   "source": [
    "#!pip install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o5jrHZ02ZH-E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlgmlppcmG8l",
    "outputId": "aaf052c3-4eda-45a0-bd8b-e8c5dc300cd2"
   },
   "outputs": [],
   "source": [
    "#!npx degit kelu124/substack/.archive substack --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CHOiqPcGm3MZ"
   },
   "outputs": [],
   "source": [
    "files = os.listdir('.archive')\n",
    "file_names = []\n",
    "for name in files:\n",
    "    if not ('type' in name):\n",
    "        file_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_parquet('articles.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DONE = list(D.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2M0eAjrBkcxj",
    "outputId": "d13e7cf3-e36f-4c28-83f8-32fcde073306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xbf in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xc4 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xd0 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xf3 in position 6637: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xbf in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 11: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc4 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xd4 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xb5 in position 11: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xbf in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x9c in position 147: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc7 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xf6 in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lxml.etree._Element' object has no attribute 'text_content'\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x94 in position 4479: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xa0 in position 683: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0xb5 in position 11: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "errors = []\n",
    "for file_name in file_names:\n",
    "    if file_name not in DONE:\n",
    "        with io.open(f'.archive/{file_name}', mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                mytree = html.fromstring(\"\".join(f.readlines()))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors.append(file_name)\n",
    "                continue\n",
    "            try:\n",
    "                content = trafilatura.extract(mytree)\n",
    "                articles.append((file_name, content))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                errors.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jhx063gpXZP",
    "outputId": "b75f3fc9-5e0e-422a-8e5e-abc40b8de788"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, content, LEN]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW = pd.DataFrame(articles, columns = ['file_name', 'content'])\n",
    "NEW[\"LEN\"] = NEW[\"content\"].apply(lambda x: len(str(x)))\n",
    "NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1598)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NEW),len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e-b5jUsupaOX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58612e45effab1e47df9a86b14dfae85</td>\n",
       "      <td>Discover more from The Generalist\\nLife in a K...</td>\n",
       "      <td>22376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115b59fc3f0d7b148482545adb1a8038</td>\n",
       "      <td>Google DeepMind researchers have discovered 2....</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab122d29aed97045e0cc1ea77bdef44</td>\n",
       "      <td>The Responsible AI Institute\\nNavigating Organ...</td>\n",
       "      <td>13194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b7b3c515859db4c0f6537824019cb7b</td>\n",
       "      <td>PANAMA CITY, Oct 31 (Reuters) – The Panama Can...</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338c551fe29e9fb73aa8d412dc77788e</td>\n",
       "      <td>By Rishad Tobaccowala\\nDecades ago, the Book o...</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>d89d7cc690ceaaafaecc9f40ff8230c5</td>\n",
       "      <td>My kids and I just played D&amp;D with ChatGPT4 as...</td>\n",
       "      <td>34489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>de8ad50911f7ef9e91749296d5638e43</td>\n",
       "      <td>Access Check\\nOur systems have detected unusua...</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     58612e45effab1e47df9a86b14dfae85   \n",
       "1     115b59fc3f0d7b148482545adb1a8038   \n",
       "2     fab122d29aed97045e0cc1ea77bdef44   \n",
       "3     8b7b3c515859db4c0f6537824019cb7b   \n",
       "4     338c551fe29e9fb73aa8d412dc77788e   \n",
       "...                                ...   \n",
       "1593  e8b7faf708568f9f39abe04b778c4631   \n",
       "1594  b79a2baa87b68283198416791b93bce4   \n",
       "1595  d89d7cc690ceaaafaecc9f40ff8230c5   \n",
       "1596  69637dcd83c48ebde0610a61a27b1989   \n",
       "1597  de8ad50911f7ef9e91749296d5638e43   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     Discover more from The Generalist\\nLife in a K...  22376  \n",
       "1     Google DeepMind researchers have discovered 2....   3950  \n",
       "2     The Responsible AI Institute\\nNavigating Organ...  13194  \n",
       "3     PANAMA CITY, Oct 31 (Reuters) – The Panama Can...   2049  \n",
       "4     By Rishad Tobaccowala\\nDecades ago, the Book o...   5082  \n",
       "...                                                 ...    ...  \n",
       "1593  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1594  The U.S. government has restricted sales of Nv...   2125  \n",
       "1595  My kids and I just played D&D with ChatGPT4 as...  34489  \n",
       "1596  The newest Kindle is the first truly new Kindl...   6249  \n",
       "1597  Access Check\\nOur systems have detected unusua...    457  \n",
       "\n",
       "[1598 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([NEW,D]).reset_index(drop=True)\n",
    "len(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kkOCiNSEpnRm"
   },
   "outputs": [],
   "source": [
    "df.to_parquet('articles.parquet.gzip',compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "djucDjpLcv4L"
   },
   "outputs": [],
   "source": [
    "# More testing here about the coherent text that has to be found, find upper elements if p doesn't mention classes. \n",
    "# or merge everything than clean up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "eAhNl6kbCjHj",
    "outputId": "16506629-352b-4909-9b93-602d025bd233"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58612e45effab1e47df9a86b14dfae85</td>\n",
       "      <td>Discover more from The Generalist\\nLife in a K...</td>\n",
       "      <td>22376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115b59fc3f0d7b148482545adb1a8038</td>\n",
       "      <td>Google DeepMind researchers have discovered 2....</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab122d29aed97045e0cc1ea77bdef44</td>\n",
       "      <td>The Responsible AI Institute\\nNavigating Organ...</td>\n",
       "      <td>13194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b7b3c515859db4c0f6537824019cb7b</td>\n",
       "      <td>PANAMA CITY, Oct 31 (Reuters) – The Panama Can...</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338c551fe29e9fb73aa8d412dc77788e</td>\n",
       "      <td>By Rishad Tobaccowala\\nDecades ago, the Book o...</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>d89d7cc690ceaaafaecc9f40ff8230c5</td>\n",
       "      <td>My kids and I just played D&amp;D with ChatGPT4 as...</td>\n",
       "      <td>34489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>de8ad50911f7ef9e91749296d5638e43</td>\n",
       "      <td>Access Check\\nOur systems have detected unusua...</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     58612e45effab1e47df9a86b14dfae85   \n",
       "1     115b59fc3f0d7b148482545adb1a8038   \n",
       "2     fab122d29aed97045e0cc1ea77bdef44   \n",
       "3     8b7b3c515859db4c0f6537824019cb7b   \n",
       "4     338c551fe29e9fb73aa8d412dc77788e   \n",
       "...                                ...   \n",
       "1593  e8b7faf708568f9f39abe04b778c4631   \n",
       "1594  b79a2baa87b68283198416791b93bce4   \n",
       "1595  d89d7cc690ceaaafaecc9f40ff8230c5   \n",
       "1596  69637dcd83c48ebde0610a61a27b1989   \n",
       "1597  de8ad50911f7ef9e91749296d5638e43   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     Discover more from The Generalist\\nLife in a K...  22376  \n",
       "1     Google DeepMind researchers have discovered 2....   3950  \n",
       "2     The Responsible AI Institute\\nNavigating Organ...  13194  \n",
       "3     PANAMA CITY, Oct 31 (Reuters) – The Panama Can...   2049  \n",
       "4     By Rishad Tobaccowala\\nDecades ago, the Book o...   5082  \n",
       "...                                                 ...    ...  \n",
       "1593  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1594  The U.S. government has restricted sales of Nv...   2125  \n",
       "1595  My kids and I just played D&D with ChatGPT4 as...  34489  \n",
       "1596  The newest Kindle is the first truly new Kindl...   6249  \n",
       "1597  Access Check\\nOur systems have detected unusua...    457  \n",
       "\n",
       "[1598 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('articles.parquet.gzip')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "S6yT9zwZCmZM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58612e45effab1e47df9a86b14dfae85</td>\n",
       "      <td>Discover more from The Generalist\\nLife in a K...</td>\n",
       "      <td>22376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115b59fc3f0d7b148482545adb1a8038</td>\n",
       "      <td>Google DeepMind researchers have discovered 2....</td>\n",
       "      <td>3950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab122d29aed97045e0cc1ea77bdef44</td>\n",
       "      <td>The Responsible AI Institute\\nNavigating Organ...</td>\n",
       "      <td>13194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b7b3c515859db4c0f6537824019cb7b</td>\n",
       "      <td>PANAMA CITY, Oct 31 (Reuters) – The Panama Can...</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338c551fe29e9fb73aa8d412dc77788e</td>\n",
       "      <td>By Rishad Tobaccowala\\nDecades ago, the Book o...</td>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>3fbb11d6e949d1e662aa6a146bb6cda0</td>\n",
       "      <td>China’s growing number of insomniacs are turni...</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>d89d7cc690ceaaafaecc9f40ff8230c5</td>\n",
       "      <td>My kids and I just played D&amp;D with ChatGPT4 as...</td>\n",
       "      <td>34489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     58612e45effab1e47df9a86b14dfae85   \n",
       "1     115b59fc3f0d7b148482545adb1a8038   \n",
       "2     fab122d29aed97045e0cc1ea77bdef44   \n",
       "3     8b7b3c515859db4c0f6537824019cb7b   \n",
       "4     338c551fe29e9fb73aa8d412dc77788e   \n",
       "...                                ...   \n",
       "1592  3fbb11d6e949d1e662aa6a146bb6cda0   \n",
       "1593  e8b7faf708568f9f39abe04b778c4631   \n",
       "1594  b79a2baa87b68283198416791b93bce4   \n",
       "1595  d89d7cc690ceaaafaecc9f40ff8230c5   \n",
       "1596  69637dcd83c48ebde0610a61a27b1989   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     Discover more from The Generalist\\nLife in a K...  22376  \n",
       "1     Google DeepMind researchers have discovered 2....   3950  \n",
       "2     The Responsible AI Institute\\nNavigating Organ...  13194  \n",
       "3     PANAMA CITY, Oct 31 (Reuters) – The Panama Can...   2049  \n",
       "4     By Rishad Tobaccowala\\nDecades ago, the Book o...   5082  \n",
       "...                                                 ...    ...  \n",
       "1592  China’s growing number of insomniacs are turni...   2859  \n",
       "1593  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1594  The U.S. government has restricted sales of Nv...   2125  \n",
       "1595  My kids and I just played D&D with ChatGPT4 as...  34489  \n",
       "1596  The newest Kindle is the first truly new Kindl...   6249  \n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing unaccessible articles\n",
    "df = df[~(df['content'] == \"Please switch to a supported browser to continue using twitter.com. You can see a list of supported browsers in our Help Center.\\nHelp Center\\nTerms of Service\\nPrivacy Policy\\nCookie Policy\\nImprint\\nAds info\\n© 2022 Twitter, Inc.\")]\n",
    "df = df[df.LEN >= 1500]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "2F4lQyQ8C2-6",
    "outputId": "f462f9e6-d89a-4f1d-ac6f-daadebd0005c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11612.282031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20382.649288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1505.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>496896.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LEN\n",
       "count    1280.000000\n",
       "mean    11612.282031\n",
       "std     20382.649288\n",
       "min      1505.000000\n",
       "25%      3761.000000\n",
       "50%      6830.000000\n",
       "75%     12885.000000\n",
       "max    496896.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD7XlA9GPOwn",
    "outputId": "cba21fd0-86e1-4d91-a84f-9312450d518c"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unusual file processing time, aborting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m tf_idf_vect \u001b[38;5;241m=\u001b[39m TfidfVectorizer(lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                         stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                         ngram_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     12\u001b[0m                         tokenizer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Fit and Transfrom Text Data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m X_train_counts \u001b[38;5;241m=\u001b[39m \u001b[43mtf_idf_vect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Check Shape of Count Vector\u001b[39;00m\n\u001b[1;32m     18\u001b[0m X_train_counts\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2079\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2073\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2074\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2075\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2076\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2077\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2078\u001b[0m )\n\u001b[0;32m-> 2079\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1359\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_words_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limit_features(\n\u001b[1;32m   1356\u001b[0m         X, vocabulary, max_doc_count, min_doc_count, max_features\n\u001b[1;32m   1357\u001b[0m     )\n\u001b[1;32m   1358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1359\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary_ \u001b[38;5;241m=\u001b[39m vocabulary\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1142\u001b[0m, in \u001b[0;36mCountVectorizer._sort_features\u001b[0;34m(self, X, vocabulary)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sort_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, vocabulary):\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;124;03m\"\"\"Sort features by name\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m    Returns a reordered matrix and modifies the vocabulary in place\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1142\u001b[0m     sorted_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     map_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(sorted_features), dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m new_val, (term, old_val) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_features):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/trafilatura/core.py:978\u001b[0m, in \u001b[0;36mtimeout_handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeout_handler\u001b[39m(signum, frame):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;124;03m'''Raise a timeout exception to handle rare malicious files'''\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munusual file processing time, aborting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unusual file processing time, aborting"
     ]
    }
   ],
   "source": [
    "# TF-IDF Feature Generation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Initialize regex tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# # Vectorize document using TF-IDF\n",
    "tf_idf_vect = TfidfVectorizer(lowercase=True,\n",
    "                        stop_words='english',\n",
    "                        ngram_range = (1,2),\n",
    "                        tokenizer = tokenizer.tokenize)\n",
    "\n",
    "# Fit and Transfrom Text Data\n",
    "X_train_counts = tf_idf_vect.fit_transform(df['content'])\n",
    "\n",
    "# Check Shape of Count Vector\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h84TuTLcPj8a",
    "outputId": "d7fb2ddf-1270-4d8f-b843-4894c47af982"
   },
   "outputs": [],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnlSHztpPjV8"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create Kmeans object and fit it to the training data \n",
    "kmeans = KMeans(n_clusters=10).fit(X_train_counts)\n",
    "\n",
    "# Get the labels using KMeans\n",
    "pred_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwYEKEkbQPoa"
   },
   "outputs": [],
   "source": [
    "# Import WordCloud and STOPWORDS\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "def word_cloud(text,wc_title,wc_file_name='wordcloud.jpeg'):\n",
    "    # Create stopword list\n",
    "    stopword_list = set(STOPWORDS) \n",
    "\n",
    "    # Create WordCloud \n",
    "    word_cloud = WordCloud(width = 800, height = 500, \n",
    "                           background_color ='white', \n",
    "                           stopwords = stopword_list, \n",
    "                           min_font_size = 14).generate(text) \n",
    "\n",
    "    # Set wordcloud figure size\n",
    "    plt.figure(figsize = (8, 6)) \n",
    "    \n",
    "    # Set title for word cloud\n",
    "    plt.title(wc_title)\n",
    "    \n",
    "    # Show image\n",
    "    plt.imshow(word_cloud) \n",
    "\n",
    "    # Remove Axis\n",
    "    plt.axis(\"off\")  \n",
    "\n",
    "    # save word cloud\n",
    "    # plt.savefig(wc_file_name,bbox_inches='tight')\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5tqLF7gePy8k",
    "outputId": "21d14f18-dd15-46e8-9f2e-6508702549d7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_df=pd.DataFrame({\"text\":df['content'],\"labels\":pred_labels})\n",
    "\n",
    "\n",
    "for i in new_df.labels.unique():\n",
    "    new_new_df=new_df[new_df.labels==i]\n",
    "    text=\"\".join(new_new_df.text.tolist())\n",
    "    word_cloud(text,f\"group {i}\",f'{i}.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfoGIIlWRLmc"
   },
   "outputs": [],
   "source": [
    "# new_df includes the category for errord ones as well.\n",
    "\n",
    "# No context is given, so the group name is default to the group number.\n",
    "\n",
    "# We can use the common words found in each group to formulate a title?\n",
    "new_df.to_csv('grouped_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ETpJY7IpPN63",
    "outputId": "8e6c28d8-ddc4-4830-930b-1060132061e3"
   },
   "outputs": [],
   "source": [
    "new_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
