{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import OAI\n",
    "\n",
    "%load_ext autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP1 = \"Acting as a Futurist, process the following text as a signal in a TABLE, first column a short 5–7 word summary of the signal, second column what kind of change is this (from what to what) 5–10 word summary, third column what might be different in 10 years time 5–10 word summary, fourth column What’s one driving force, or motivation, behind this change? 5–10 word summary:\\n\\n\"\n",
    "\n",
    "STEP2 = \"Process the following text, and give back only the top 10 most relevant keywords for the text, as a Python list (looking like KEYWORDS = ['keyword1', 'keyword2']). Then, on a new line, provide a list of the top three themes or categories the text belongs to (looking like THEMES = ['theme1', 'theme2']). On another new line, add a paragraph starting with 'Summary:'  which  summarizes the text in 4 to 5 sentences. \\n\\n\"\n",
    "\n",
    "STEP3 = \"Process the following text, and give this text a title, which should not be longer than 6 words, in the form 'TITLE: title of the article'.\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d07a9512bded6c5e9871608ec5edefec</td>\n",
       "      <td>How to craft better prompts. Four reasons we t...</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30353a701a13370e93f7369cc6b68c0b</td>\n",
       "      <td>Transnational security investigator Abdelkader...</td>\n",
       "      <td>22079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e35595ab3cf32e4dadb80ef02604e4ee</td>\n",
       "      <td>VUCA\\nVUCA is an acronym based on the leadersh...</td>\n",
       "      <td>20093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1fd0845ff9239d74ce3f089d10cb2f61</td>\n",
       "      <td>Pi Pico Rx - A crystal radio for the digital a...</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>183f62ed162708e41c35b609767f0667</td>\n",
       "      <td>The Rise of Connector Roles in Data Science\\nC...</td>\n",
       "      <td>2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>edbb7336dfb26098bcc966ca17c074b9</td>\n",
       "      <td>It was time to consider calling it a night. Sh...</td>\n",
       "      <td>15656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>3fbb11d6e949d1e662aa6a146bb6cda0</td>\n",
       "      <td>China’s growing number of insomniacs are turni...</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>I would say my efficiency is up ~20% since sta...</td>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>The U.S. government has restricted sales of Nv...</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>The newest Kindle is the first truly new Kindl...</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1342 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0     d07a9512bded6c5e9871608ec5edefec   \n",
       "2     30353a701a13370e93f7369cc6b68c0b   \n",
       "3     e35595ab3cf32e4dadb80ef02604e4ee   \n",
       "4     1fd0845ff9239d74ce3f089d10cb2f61   \n",
       "8     183f62ed162708e41c35b609767f0667   \n",
       "...                                ...   \n",
       "1784  edbb7336dfb26098bcc966ca17c074b9   \n",
       "1785  3fbb11d6e949d1e662aa6a146bb6cda0   \n",
       "1786  e8b7faf708568f9f39abe04b778c4631   \n",
       "1787  b79a2baa87b68283198416791b93bce4   \n",
       "1789  69637dcd83c48ebde0610a61a27b1989   \n",
       "\n",
       "                                                content    LEN  \n",
       "0     How to craft better prompts. Four reasons we t...   1877  \n",
       "2     Transnational security investigator Abdelkader...  22079  \n",
       "3     VUCA\\nVUCA is an acronym based on the leadersh...  20093  \n",
       "4     Pi Pico Rx - A crystal radio for the digital a...   1863  \n",
       "8     The Rise of Connector Roles in Data Science\\nC...   2910  \n",
       "...                                                 ...    ...  \n",
       "1784  It was time to consider calling it a night. Sh...  15656  \n",
       "1785  China’s growing number of insomniacs are turni...   2859  \n",
       "1786  I would say my efficiency is up ~20% since sta...  14337  \n",
       "1787  The U.S. government has restricted sales of Nv...   2125  \n",
       "1789  The newest Kindle is the first truly new Kindl...   6249  \n",
       "\n",
       "[1342 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('articles.parquet.gzip')\n",
    "df = df[(df.LEN > 1500) & (df.LEN < 30000)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = OAI.Helper(\"local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:34 --> 02/13/2024, 09:50:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:37 --> 02/13/2024, 09:50:39\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:40 --> 02/13/2024, 09:50:41\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:41 --> 02/13/2024, 09:50:42\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:43 --> 02/13/2024, 09:50:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:46 --> 02/13/2024, 09:50:47\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:47 --> 02/13/2024, 09:50:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:53 --> 02/13/2024, 09:50:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:56 --> 02/13/2024, 09:50:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:50:58 --> 02/13/2024, 09:51:03\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:03 --> 02/13/2024, 09:51:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:07 --> 02/13/2024, 09:51:08\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:09 --> 02/13/2024, 09:51:13\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:13 --> 02/13/2024, 09:51:17\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:17 --> 02/13/2024, 09:51:18\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:18 --> 02/13/2024, 09:51:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:20 --> 02/13/2024, 09:51:22\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:22 --> 02/13/2024, 09:51:23\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:23 --> 02/13/2024, 09:51:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:26 --> 02/13/2024, 09:51:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:30 --> 02/13/2024, 09:51:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:31 --> 02/13/2024, 09:51:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:32 --> 02/13/2024, 09:51:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:35 --> 02/13/2024, 09:51:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:37 --> 02/13/2024, 09:51:40\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:40 --> 02/13/2024, 09:51:43\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:44 --> 02/13/2024, 09:51:44\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:44 --> 02/13/2024, 09:51:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:48 --> 02/13/2024, 09:51:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:51 --> 02/13/2024, 09:51:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:52 --> 02/13/2024, 09:51:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:51:58 --> 02/13/2024, 09:52:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:01 --> 02/13/2024, 09:52:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:02 --> 02/13/2024, 09:52:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:04 --> 02/13/2024, 09:52:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:07 --> 02/13/2024, 09:52:09\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:09 --> 02/13/2024, 09:52:10\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:10 --> 02/13/2024, 09:52:14\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:14 --> 02/13/2024, 09:52:14\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:15 --> 02/13/2024, 09:52:16\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:16 --> 02/13/2024, 09:52:19\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:19 --> 02/13/2024, 09:52:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:20 --> 02/13/2024, 09:52:27\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:27 --> 02/13/2024, 09:52:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:30 --> 02/13/2024, 09:52:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:31 --> 02/13/2024, 09:52:34\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:35 --> 02/13/2024, 09:52:38\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:39 --> 02/13/2024, 09:52:39\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:39 --> 02/13/2024, 09:52:41\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:41 --> 02/13/2024, 09:52:44\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:44 --> 02/13/2024, 09:52:45\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:45 --> 02/13/2024, 09:52:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:48 --> 02/13/2024, 09:52:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:51 --> 02/13/2024, 09:52:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:51 --> 02/13/2024, 09:52:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:53 --> 02/13/2024, 09:52:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:58 --> 02/13/2024, 09:52:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:52:59 --> 02/13/2024, 09:53:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:02 --> 02/13/2024, 09:53:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:04 --> 02/13/2024, 09:53:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:05 --> 02/13/2024, 09:53:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:07 --> 02/13/2024, 09:53:09\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:09 --> 02/13/2024, 09:53:10\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:10 --> 02/13/2024, 09:53:14\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:14 --> 02/13/2024, 09:53:18\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:18 --> 02/13/2024, 09:53:19\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:19 --> 02/13/2024, 09:53:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:27 --> 02/13/2024, 09:53:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:28 --> 02/13/2024, 09:53:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:29 --> 02/13/2024, 09:53:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:32 --> 02/13/2024, 09:53:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:35 --> 02/13/2024, 09:53:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:36 --> 02/13/2024, 09:53:39\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:39 --> 02/13/2024, 09:53:41\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:42 --> 02/13/2024, 09:53:42\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:42 --> 02/13/2024, 09:53:43\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:44 --> 02/13/2024, 09:53:47\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:47 --> 02/13/2024, 09:53:47\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:48 --> 02/13/2024, 09:53:49\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:50 --> 02/13/2024, 09:53:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:53 --> 02/13/2024, 09:53:54\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:54 --> 02/13/2024, 09:53:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:55 --> 02/13/2024, 09:53:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:53:59 --> 02/13/2024, 09:54:00\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:00 --> 02/13/2024, 09:54:03\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:04 --> 02/13/2024, 09:54:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:07 --> 02/13/2024, 09:54:08\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:09 --> 02/13/2024, 09:54:09\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:10 --> 02/13/2024, 09:54:12\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:13 --> 02/13/2024, 09:54:13\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:13 --> 02/13/2024, 09:54:16\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:16 --> 02/13/2024, 09:54:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:20 --> 02/13/2024, 09:54:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:21 --> 02/13/2024, 09:54:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:25 --> 02/13/2024, 09:54:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:28 --> 02/13/2024, 09:54:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:29 --> 02/13/2024, 09:54:33\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:33 --> 02/13/2024, 09:54:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:36 --> 02/13/2024, 09:54:37\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:37 --> 02/13/2024, 09:54:38\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:39 --> 02/13/2024, 09:54:42\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:42 --> 02/13/2024, 09:54:43\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:43 --> 02/13/2024, 09:54:47\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:48 --> 02/13/2024, 09:54:50\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:50 --> 02/13/2024, 09:54:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:51 --> 02/13/2024, 09:54:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:56 --> 02/13/2024, 09:54:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:54:59 --> 02/13/2024, 09:55:00\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:00 --> 02/13/2024, 09:55:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:01 --> 02/13/2024, 09:55:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:04 --> 02/13/2024, 09:55:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:05 --> 02/13/2024, 09:55:06\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:06 --> 02/13/2024, 09:55:09\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:09 --> 02/13/2024, 09:55:09\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:10 --> 02/13/2024, 09:55:11\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:11 --> 02/13/2024, 09:55:14\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:14 --> 02/13/2024, 09:55:14\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:15 --> 02/13/2024, 09:55:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:20 --> 02/13/2024, 09:55:23\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:24 --> 02/13/2024, 09:55:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:24 --> 02/13/2024, 09:55:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:28 --> 02/13/2024, 09:55:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:31 --> 02/13/2024, 09:55:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:32 --> 02/13/2024, 09:55:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:35 --> 02/13/2024, 09:55:38\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:39 --> 02/13/2024, 09:55:39\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:39 --> 02/13/2024, 09:55:42\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:42 --> 02/13/2024, 09:55:45\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:45 --> 02/13/2024, 09:55:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:46 --> 02/13/2024, 09:55:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:48 --> 02/13/2024, 09:55:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:52 --> 02/13/2024, 09:55:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:55:53 --> 02/13/2024, 09:56:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:02 --> 02/13/2024, 09:56:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:05 --> 02/13/2024, 09:56:06\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:06 --> 02/13/2024, 09:56:09\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:09 --> 02/13/2024, 09:56:12\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:12 --> 02/13/2024, 09:56:13\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:13 --> 02/13/2024, 09:56:16\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:16 --> 02/13/2024, 09:56:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:20 --> 02/13/2024, 09:56:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:21 --> 02/13/2024, 09:56:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:26 --> 02/13/2024, 09:56:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:31 --> 02/13/2024, 09:56:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:32 --> 02/13/2024, 09:56:33\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:33 --> 02/13/2024, 09:56:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 02/13/2024, 09:56:36 --> 02/13/2024, 09:56:37\n"
     ]
    }
   ],
   "source": [
    "for ix, row in df.sample(len(df)).iterrows():\n",
    "    ID, txt = row.file_name, row.content\n",
    "    CACHE1 = \".cache/\"+str(ID)\n",
    "    CACHE2 = \".cache_keywords/\"+str(ID)\n",
    "    CACHE3 = \".cache_title/\"+str(ID)\n",
    "    #print(row.file_name)\n",
    "    if ix < 100000:\n",
    "        if not os.path.isfile(CACHE1):\n",
    "            table = h.ask(STEP1,txt,src=\"localSeedsStep1\")\n",
    "            with open(CACHE1, 'w', encoding='utf-8') as f:\n",
    "                f.write(table)\n",
    "        if not os.path.isfile(CACHE2):\n",
    "            table = h.ask(STEP2,txt,src=\"localSeedsStep2\")\n",
    "            with open(CACHE2, 'w', encoding='utf-8') as f:\n",
    "                f.write(table)\n",
    "        if not os.path.isfile(CACHE3):\n",
    "            table = h.ask(STEP3,txt,src=\"localSeedsStep3\")\n",
    "            with open(CACHE3, 'w', encoding='utf-8') as f:\n",
    "                f.write(table)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def txtRead(filename):\n",
    "    with io.open(filename,'r',encoding='utf8') as f:\n",
    "        txt= f.read()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = list(glob.glob(\".cache_title/*\"))\n",
    "\n",
    "allSeeds = []\n",
    "for seed in SEEDS: \n",
    "    try:\n",
    "        ID = seed.split(\"/\")[-1]\n",
    "        txt = txtRead(seed) \n",
    "        txt = txt.replace(\"\\n\\n\",\"\\n\")\n",
    "        SUMMARY = txt.replace(\"TITLE:\",\"\").split(\"\\n\")[0].strip()\n",
    "        allSeeds.append([ID,SUMMARY])\n",
    "    except:\n",
    "        print(\"Error with:\",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc291c4e68ac16cdef2b1a424f29ef20</td>\n",
       "      <td>Co-Intelligence: Navigating the AI Revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea74b217d36ec570bb432fb5aa679090</td>\n",
       "      <td>The Impact of AI on Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d07a9512bded6c5e9871608ec5edefec</td>\n",
       "      <td>Crafting Better Prompts for Improved Results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>841546c0efc4c82f0aabc545a47a09e1</td>\n",
       "      <td>Researchers Uncover Backdoor in Encrypted Radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f6637d1fa0e3fe0e1e94bea8b3338ef9</td>\n",
       "      <td>Hack-a-Sat: Researchers Launch Sandbox Satelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>e8b7faf708568f9f39abe04b778c4631</td>\n",
       "      <td>The Impact of ChatGPT on Efficiency and Inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>f1011f7f464bfcb22dcb75731bd0090f</td>\n",
       "      <td>Advancing GPT Models through Prompting Strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>b9d91aca816a4b049d4583a774f886a2</td>\n",
       "      <td>The Ancient Agricultural Secret of Amazonian D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>b79a2baa87b68283198416791b93bce4</td>\n",
       "      <td>US Restricts Nvidia GPU Sales to Thwart China'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>69637dcd83c48ebde0610a61a27b1989</td>\n",
       "      <td>Amazon Unveils Kindle Scribe, a Tablet-like Eb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1342 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   src  \\\n",
       "0     cc291c4e68ac16cdef2b1a424f29ef20   \n",
       "1     ea74b217d36ec570bb432fb5aa679090   \n",
       "2     d07a9512bded6c5e9871608ec5edefec   \n",
       "3     841546c0efc4c82f0aabc545a47a09e1   \n",
       "4     f6637d1fa0e3fe0e1e94bea8b3338ef9   \n",
       "...                                ...   \n",
       "1337  e8b7faf708568f9f39abe04b778c4631   \n",
       "1338  f1011f7f464bfcb22dcb75731bd0090f   \n",
       "1339  b9d91aca816a4b049d4583a774f886a2   \n",
       "1340  b79a2baa87b68283198416791b93bce4   \n",
       "1341  69637dcd83c48ebde0610a61a27b1989   \n",
       "\n",
       "                                                  title  \n",
       "0         Co-Intelligence: Navigating the AI Revolution  \n",
       "1                         The Impact of AI on Education  \n",
       "2          Crafting Better Prompts for Improved Results  \n",
       "3     Researchers Uncover Backdoor in Encrypted Radi...  \n",
       "4     Hack-a-Sat: Researchers Launch Sandbox Satelli...  \n",
       "...                                                 ...  \n",
       "1337  The Impact of ChatGPT on Efficiency and Inform...  \n",
       "1338  Advancing GPT Models through Prompting Strategies  \n",
       "1339  The Ancient Agricultural Secret of Amazonian D...  \n",
       "1340  US Restricts Nvidia GPU Sales to Thwart China'...  \n",
       "1341  Amazon Unveils Kindle Scribe, a Tablet-like Eb...  \n",
       "\n",
       "[1342 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDTitle = pd.DataFrame(allSeeds)\n",
    "DDTitle.columns = [\"src\",\"title\"]\n",
    "DDTitle.to_parquet(\"titles.parquet.gzip\",compression='gzip')\n",
    "DDTitle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
