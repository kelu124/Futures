{"error": {"message": "This model's maximum context length is 128000 tokens. However, your messages resulted in 181648 tokens (181489 in the messages, 159 in the functions). Please reduce the length of the messages or functions.", "type": "invalid_request_error", "param": "messages", "code": "context_length_exceeded"}}