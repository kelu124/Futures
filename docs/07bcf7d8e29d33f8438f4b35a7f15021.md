# __Human Motion Diffusion Model (MDM): A Generative Approach for Natural and Expressive Human Motion__, from ([20221002](https://kghosh.substack.com/p/20221002).)

__[External link](https://guytevet.github.io/mdm-page/)__



## Summary

Natural and expressive human motion generation is a challenging task in computer animation. Current generative solutions are either low-quality or limited in expressiveness. Diffusion models, such as the Motion Diffusion Model (MDM), show promise in the human motion domain but are resource hungry and hard to control. MDM is a transformer-based generative model that predicts the sample rather than the noise in each diffusion step. It incorporates geometric losses for accurate motion generation and achieves state-of-the-art results on leading benchmarks for text-to-motion and action-to-motion tasks. The MDM framework allows for different forms of conditioning and demonstrates superior performance in a classifier-free manner.

## Keywords

* human motion generation
* computer animation
* challenging task
* generative solutions
* diffusion models
* Motion Diffusion Model (MDM)
* transformer-based
* geometric losses
* text-to-motion
* action-to-motion

## Themes

* human motion generation
* generative models
* motion diffusion

## Signals

| Signal                                         | Change                                          | 10y horizon                                                             | Driving force                                               |
|:-----------------------------------------------|:------------------------------------------------|:------------------------------------------------------------------------|:------------------------------------------------------------|
| Natural and expressive human motion generation | Improvement in quality and expressiveness       | More realistic and diverse human motion generation                      | Desire for more realistic computer animation                |
| Diffusion models for human motion generation   | Resource hungry and hard to control             | More efficient and controllable diffusion models                        | Need for more efficient and controllable generative models  |
| MDM framework for motion generation            | Generic design enabling different conditioning  | More versatile and adaptable motion generation models                   | Desire for flexible and customizable motion generation      |
| Text-to-motion task                            | Generating motion from text prompts             | Improved motion generation based on textual descriptions                | Advancement in text-based motion synthesis                  |
| Action-to-motion task                          | Generating motion from action classes           | Improved motion generation based on action inputs                       | Advancement in action-based motion synthesis                |
| Completion and editing of motion               | Filling in gaps and editing specific body parts | More accurate and semantically consistent motion completion and editing | Desire for precise and controlled motion editing techniques |

## Closest

* [The Impact of Generative AI on Artists and the Need for Data Rights](858dac884c8fe7dfa6fc0c2cf093e97f)
* [Future of Generative AI Agents](e1baf6b4cdd1160dd2264fe6fd2e24ab)
* [The Impact of AI on Architecture](1f02642f54cf28611a00e4c83c1d428f)
* [Stable Diffusion Public Release](09e12f5c07382efea39163ed3274098a)
* [Creating and Destroying Value with Generative AI](15d4ec180189ca1739398f516844cefb)