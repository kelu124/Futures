# __Exploring the Use of LLMs as Knowledge Graph Stores Through Fine-Tuning Techniques__, from ([15507.0](https://kghosh.substack.com/p/15507.0).)

__[External link](https://betterprogramming.pub/large-language-model-knowledge-graph-store-yes-by-fine-tuning-llm-with-kg-f88b556959e6)__



## Keywords

* G
* P
* T
* ,
* k
* n
* o
* w
* l
* e
* d
* g
* e
*  
* g
* r
* a
* p
* h
* ,
* L
* L
* M
* ,
* f
* i
* n
* e
* -
* t
* u
* n
* i
* n
* g
* ,
* O
* p
* e
* n
* A
* I
* ,
* S
* P
* A
* R
* Q
* L

## Themes

* l
* a
* r
* g
* e
*  
* l
* a
* n
* g
* u
* a
* g
* e
*  
* m
* o
* d
* e
* l
* ,
* k
* n
* o
* w
* l
* e
* d
* g
* e
*  
* g
* r
* a
* p
* h
* ,
* f
* i
* n
* e
* -
* t
* u
* n
* i
* n
* g

## Other

* Category: technology
* Type: blog post

## Summary

The article discusses the potential of using Large Language Models (LLMs) as knowledge graph stores through fine-tuning. It contrasts the limitations of prompting with serialized knowledge graphs and emphasizes the need for fine-tuning to enable LLMs to answer complex questions accurately. Two case studies are presented: a flowsheet model of a process plant and a genealogical model of the Kennedys. The fine-tuning process involves creating prompt-completion pairs from the RDF graph edges, which helps the model perform better on queries related to the data. The findings highlight the effectiveness of fine-tuning for knowledge graph integration, the challenge of overfitting, and the importance of optimizing serialization for cost-effective training. Overall, the article suggests that knowledge graphs are valuable for preparing LLMs for structured data tasks, while further research is needed on optimizing these processes.

## Signals

| name                              | description                                                                                   | change                                                                                         | 10-year                                                                                                           | driving-force                                                                                         |   relevancy |
|:----------------------------------|:----------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------|------------:|
| LLM as Knowledge Graph Store      | Exploring the potential of using LLMs as effective knowledge graph stores.                    | Shifting from conventional data storage to integrating LLMs as knowledge graph stores.         | Widespread adoption of LLMs for dynamic knowledge graph storage and retrieval across industries.                  | Increasing demand for intelligent data interaction and query capabilities in various applications.    |           4 |
| Fine-Tuning with Knowledge Graphs | Using knowledge graphs to fine-tune LLMs for better query responses.                          | Moving from basic LLM functionality to specialized, domain-specific knowledge retrieval.       | Significant improvement in the accuracy and contextual relevance of AI-generated responses in specialized fields. | The need for precise and context-aware information retrieval in complex domains.                      |           5 |
| Serialization of Knowledge Graphs | The process of transforming knowledge graphs into a serialized format for LLM training.       | Transition from manually curated data to automated serialization for LLM fine-tuning.          | Streamlined data preparation processes leading to faster and more efficient LLM deployment.                       | Technological advancements in data processing and efficiency optimization.                            |           4 |
| Path Query Capabilities           | Enhancing LLMs to perform path queries within knowledge graphs.                               | From simple question answering to complex relational queries using knowledge graphs.           | LLMs capable of understanding intricate relationships and providing comprehensive answers.                        | The growing complexity of data relationships in various fields requiring advanced query capabilities. |           3 |
| Cost Reduction in LLM Training    | Identifying methods to reduce the costs associated with training LLMs using knowledge graphs. | Shifting from expensive training processes to more cost-effective methods using existing data. | Lower barriers to entry for organizations to utilize advanced LLMs in their operations.                           | Need for cost-effective AI solutions in business and research sectors.                                |           4 |