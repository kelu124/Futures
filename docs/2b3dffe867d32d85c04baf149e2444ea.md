# __The AI Ethics Revolution: A Timeline__, from ([20230408](https://kghosh.substack.com/p/20230408).)

__[External link](https://medium.com/women-in-ai-ethics/the-ai-ethics-revolution-a-timeline-276593eef416)__



## Summary

The text highlights the contributions of women in the field of AI and computing, debunking the myth of genius men in Silicon Valley as the sole drivers of AI advancements. It emphasizes the need for diversity and recognition of the work done by women and marginalized communities. The timeline spans from the 1800s to the present, showcasing key milestones and research papers that have shaped the field of AI ethics. The themes of AI ethics, contributions of women in computing, and gender bias in AI algorithms emerge as prominent topics. The text underscores the importance of documenting and recognizing the sacrifices and contributions made by individuals in this field.

## Keywords

* AI Ethics Revolution
* genius men
* Silicon Valley
* contributions of women
* world of computing
* Ada Lovelace
* first computer program
* Joan Clarke
* cryptology skills
* western allies
* Katherine Johnson
* racial segregation
* mathematical genius
* American into space
* powerful and wealthy men
* future existential risks
* humanity safe
* recklessly developed
* deployed AI
* 100 Brilliant Women in AI Ethics
* diverse voices
* recent developments
* document their key contributions
* their sacrifices
* media-frenzy
* published in 2018
* yearly recognition
* developments
* peddlers of AI hype
* Cynthia Dwork
* Algorithms of Differential Privacy
* meaningful definition of privacy
* Danielle Citron
* formalized safeguards
* fairness and accuracy
* predictive algorithms
* Julia Angwin
* ProPublica team
* racial disparities
* sentencing recommendations
* Cathy O’Neil
* Weapons of Math Destruction
* public awareness
* societal harms of algorithms
* Mar Hicks
* Programmed Inequality
* discrimination against women
* AI Now 2017 Report
* emerging challenges
* benefits of AI
* risks of AI
* Lina Khan
* Amazon’s Antitrust Paradox
* antitrust and competition policy
* Timnit Gebru
* Joy Buolamwini
* Gender Shades
* accuracy disparities
* facial recognition systems
* Margaret Mitchell
* Inioluwa Deborah Raji
* Model Cards for Model Reporting
* responsible democratization of machine learning
* Google protests
* women-led walkout
* retaliation for their role in worker protests
* Lucy Suchman
* Lilly Irani
* Project Maven
* international treaty prohibiting autonomous weapons systems
* Carole Cadwalladr
* Facebook–Cambridge Analytica data scandal
* Safiya Umoja Noble
* Algorithms of Oppression
* Virginia Eubanks
* Automating Inequality
* Joy Buolamwini
* limitations of facial recognition technology
* moratorium prohibiting law enforcement use
* Large image datasets
* racist and misogynistic labels
* IBM’s first CEO of color
* getting out of the facial recognition business
* Facebook Oversight Board
* Real Facebook Oversight Board
* Sasha Costanza-Chock
* Design Justice
* Sasha Luccioni
* Machine Learning Emissions Calculator
* carbon impact of machine learning processes
* Google fired Timnit Gebru
* Dangers of Stochastic Parrots
* risks associated with large machine learning models
* Abebe Birhane
* Vinay Prabhu
* image datasets
* racist and offensive content
* Amazon halted police use
* Facebook’s algorithm amplified misinformation
* Silenced No More Act
* protection for workers who speak out
* Blueprint for an AI Bill of Rights
* demanding change to Facebook’s algorithm
* Hilke Schellmann
* gender bias in AI algorithms
* Stochastic Parrots
* regulatory efforts
* transparency
* accountability
* meaningful work in this space
* social media platforms
* spreadsheet of relevant AI/tech ethics books

## Themes

* AI Ethics
* Contributions of Women in Computing
* Gender Bias in AI Algorithms

## Signals

| Signal                                                    | Change                                                                  | 10y horizon                                                                                  | Driving force                                                                        |
|:----------------------------------------------------------|:------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------|
| Recognition of women's contributions to AI                | From overlooking women's contributions to recognizing their importance  | More visibility and recognition of women's contributions in AI                               | Desire for inclusivity and diversity                                                 |
| Growing awareness of the harms of AI                      | From ignorance and indifference to concern and action                   | Increased efforts to keep humanity safe from AI harm                                         | Concern for the reckless development and deployment of AI                            |
| Publication of "100 Brilliant Women in AI Ethics" list    | From underrepresentation to recognition of diverse voices               | Continued recognition and documentation of contributions by women in AI ethics               | Desire to highlight the work of women in the field                                   |
| Research on privacy and algorithmic fairness              | From lack of rigorous definitions to meaningful safeguards              | Improved definitions, algorithms, and safeguards to protect privacy                          | Need for robust and mathematically rigorous privacy protections                      |
| Uncovering racial disparities in algorithms               | From hidden effects to awareness of racial bias                         | Increased efforts to ensure fairness and accuracy of predictive algorithms                   | Recognition of the need to address racial disparities in algorithms                  |
| Research on historical discrimination in computing        | From unknown history to documented discrimination                       | Greater awareness of discriminatory practices in the history of computing                    | Uncovering and addressing historical discrimination in the field                     |
| Challenges and recommendations for AI benefits and risks  | From emerging challenges to shared benefits and mitigated risks         | Increased efforts to ensure broad sharing of AI benefits and identify and mitigate risks     | Desire for AI benefits to be shared broadly and risks to be identified and mitigated |
| Research on accuracy disparities in gender classification | From biased gender classification to improved accuracy                  | Improved accuracy in commercial facial recognition systems for women and dark-skinned people | Need for intersectional accuracy in gender classification                            |
| Introduction of "Model Cards for Model Reporting"         | From lack of transparency to responsible democratization of AI          | Increased transparency and responsible democratization of AI technology                      | Desire for increased transparency and responsible use of AI technology               |
| Protests and demands for workplace equality in tech       | From workplace inequality to demands for equality and accountability    | Increased efforts for workplace equality, accountability, and fair treatment                 | Desire for workplace equality and fair treatment in the tech industry                |
| Exposing data scandals and impacts of algorithms          | From hidden data scandals to increased awareness of algorithmic impacts | Increased awareness of data scandals and impacts of algorithms on society                    | Need for ethical data practices and fair algorithmic impacts                         |
| Testimony on limitations of facial recognition technology | From unchecked use to awareness and calls for regulation                | Increased awareness and calls for regulation of facial recognition technology                | Desire for regulation and limitations on facial recognition technology               |
| Uncovering biased content and labels in datasets          | From biased datasets to critical examination of dataset development     | Reflexive interventions and critical examination of dataset development                      | Need for critical examination and improvement of dataset development                 |
| Appointments and additions to policy planning offices     | From lack of diverse perspectives to inclusion of diverse voices        | Inclusion of diverse perspectives in policy planning offices                                 | Desire for diverse perspectives in policy-making                                     |
| Warnings about relying on AI for policy solutions         | From unchecked reliance on AI to caution about its use                  | Caution about relying on AI as a policy solution                                             | Recognition of the limitations and risks of relying on AI                            |
| Whistleblower testimony on algorithmic amplification      | From unchecked algorithmic amplification to public exposure of harms    | Increased awareness of algorithmic amplification and its harms                               | Desire for safeguards and accountability in algorithmic systems                      |
| Protection for workers speaking out about harassment      | From silenced workers to protection for whistleblowers                  | Protection for workers speaking out about harassment and discrimination                      | Need for protection of workers and accountability for harassment                     |
| Release of AI Bill of Rights blueprint                    | From lack of AI rights to proposed AI Bill of Rights                    | Proposed AI Bill of Rights for protection and accountability                                 | Desire for protection and accountability in AI development and deployment            |
| Demand for fundamental change to Facebook's algorithm     | From unchallenged algorithm to demand for user safety                   | Demand for changes to Facebook's algorithm prioritizing user safety                          | Desire for algorithmic changes to prioritize user safety                             |
| Investigation of gender bias in social media algorithms   | From hidden gender bias to awareness and exposure                       | Increased awareness of gender bias in social media algorithms                                | Need for fair and unbiased algorithms in social media platforms                      |

## Closest

* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [Evaluating GPT Startups: The Three-Hills Model](d1df6602870d6b0ed820af0e9ab76a80)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)
* [The AI Ethics Revolution: A Timeline](2b3dffe867d32d85c04baf149e2444ea)