# __Air Canada Ordered to Refund Passenger Misled by Chatbot on Bereavement Policy__, from ([5628.0](https://kghosh.substack.com/p/5628.0).)

__[External link](https://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/)__



## Keywords

* A
* i
* r
*  
* C
* a
* n
* a
* d
* a
* ,
*  
* c
* h
* a
* t
* b
* o
* t
* ,
*  
* r
* e
* f
* u
* n
* d
* ,
*  
* b
* e
* r
* e
* a
* v
* e
* m
* e
* n
* t
*  
* p
* o
* l
* i
* c
* y
* ,
*  
* c
* u
* s
* t
* o
* m
* e
* r
*  
* s
* e
* r
* v
* i
* c
* e
* ,
*  
* l
* e
* g
* a
* l
*  
* c
* a
* s
* e

## Themes

* A
* i
* r
*  
* C
* a
* n
* a
* d
* a
* ,
*  
* c
* h
* a
* t
* b
* o
* t
* ,
*  
* r
* e
* f
* u
* n
* d
* ,
*  
* b
* e
* r
* e
* a
* v
* e
* m
* e
* n
* t
*  
* t
* r
* a
* v
* e
* l
*  
* p
* o
* l
* i
* c
* y
* ,
*  
* c
* u
* s
* t
* o
* m
* e
* r
*  
* s
* e
* r
* v
* i
* c
* e
* ,
*  
* l
* i
* a
* b
* i
* l
* i
* t
* y

## Other

* Category: politics
* Type: news

## Summary

Air Canada was ordered to issue a partial refund to Jake Moffatt after he relied on misleading information from the airline's chatbot regarding bereavement travel policies. Moffatt, who sought to book a flight following his grandmother's death, was incorrectly advised by the chatbot that he could request a refund within 90 days. Upon being denied a refund, he escalated the issue to the Civil Resolution Tribunal, which ruled in his favor, stating that Air Canada failed to ensure the accuracy of information provided by its chatbot. The tribunal found that the chatbot's misleading guidance led to Moffatt's financial loss. Air Canada has since complied with the ruling and appears to have disabled the chatbot.

## Signals

| name                                | description                                                                                         | change                                                                              | 10-year                                                                                            | driving-force                                                                             |   relevancy |
|:------------------------------------|:----------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------|------------:|
| Liability of AI in Customer Service | Companies may argue they are not liable for incorrect information from AI chatbots.                 | Shift from human-led customer service to AI-driven interactions and accountability. | In 10 years, companies may have clearer regulations on AI accountability in customer interactions. | Growing reliance on AI for efficiency and cost reduction in customer service.             |           4 |
| Consumer Trust in AI                | Consumers may become wary of trusting AI for accurate information after experiences like Moffatt's. | Transition from reliance on AI for information to seeking human verification.       | In a decade, consumers may prefer human representatives over AI for critical inquiries.            | Experiences of misinformation leading to a demand for more reliable customer service.     |           5 |
| Regulation of AI Technology         | Potential rise in regulations governing the use and accountability of AI chatbots.                  | From unregulated AI technology to stricter guidelines and accountability measures.  | In 10 years, regulations may ensure that AI systems provide accurate and reliable information.     | Increasing incidents of misinformation from AI prompting calls for regulatory frameworks. |           4 |
| Shift in Business Strategies        | Businesses may rethink their strategies regarding the deployment of AI in customer service.         | From AI as a cost-saving measure to a more cautious, regulated implementation.      | In the future, businesses might prioritize a balance between automation and human interaction.     | The need to maintain customer satisfaction and trust in service delivery.                 |           3 |
| Consumer Advocacy and Legal Action  | More consumers may pursue legal action against companies for misleading AI information.             | From informal complaints to formal legal challenges against companies using AI.     | In 10 years, there may be a rise in legal frameworks specifically addressing AI-related disputes.  | Consumer experiences leading to a demand for accountability from companies using AI.      |           4 |