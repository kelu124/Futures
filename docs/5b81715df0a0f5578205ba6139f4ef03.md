# __Strange Keywords Break OpenAI's Chatbot__, from ([20230505](https://kghosh.substack.com/p/20230505).)

__[External link](https://www.vice.com/en/article/epzyva/ai-chatgpt-tokens-words-break-reddit)__



## Summary

Two researchers, Jessica Rumbelow and Matthew Watkins, discovered a cluster of strange keywords or tokens that can break ChatGPT, OpenAI's chatbot. These tokens include Reddit usernames and names related to a Twitch-based Pokémon game. When ChatGPT is asked to repeat these tokens, it responds in strange ways like evasion, insults, or spelling out different words. The researchers named these anomalous tokens "unspeakable" by ChatGPT. The issue highlights the inscrutability and unexpected limitations of AI models. The researchers believe that the training data and tokenization process may have caused this behavior.

## Keywords

* ChatGPT
* keywords
* tokens
* Reddit usernames
* Twitch-based Pokémon game
* Jessica Rumbelow
* Matthew Watkins
* SERI-MATS research group
* unspeakable
* AI models

## Themes

* limitations of AI models
* unexpected behavior of AI models
* ChatGPT vulnerabilities

## Signals

| Signal                                                        | Change                                                | 10y horizon                                                       | Driving force                                                       |
|:--------------------------------------------------------------|:------------------------------------------------------|:------------------------------------------------------------------|:--------------------------------------------------------------------|
| Strange keywords cause ChatGPT to malfunction                 | Malfunction in ChatGPT's response to keywords         | Improved AI models with better handling of unusual inputs         | Lack of exposure to certain tokens during training                  |
| Inscrutable behavior of AI models                             | Lack of clear explanations for AI behavior            | Development of methods to make AI models more explainable         | Need for reliable and safe AI models                                |
| AI systems deployed in the real world causing harm            | Focus on reducing AI harms                            | Frameworks and regulations to mitigate AI harms                   | Instances of AI systems causing harm in society                     |
| Need to slow down AI development due to lack of understanding | Recognition of the need for caution in AI development | More cautious and measured approach to AI research and deployment | Recognition of the potential dangers of rushing into AI development |

## Closest

* [Strange Keywords Break OpenAI's Chatbot](5b81715df0a0f5578205ba6139f4ef03)
* [AI Beats Search for Answering Questions](b109d3163c90428c0a67504bd2878adf)
* [Strange Keywords Break OpenAI's Chatbot](5b81715df0a0f5578205ba6139f4ef03)
* [The Rapid Advancement of Cloning Technology](3827e85d7b233b583bd7e01c435cf758)
* [Strange Keywords Break OpenAI's Chatbot](5b81715df0a0f5578205ba6139f4ef03)
* [ChatGPT + Wolfram is INSANE!](c73fef52122dff9becbe63751648eea0)
* [Google DeepMind Launches Watermarking Tool for AI-Generated Images](d5c399872ea4d28def48f650503511a0)
* [Strange Keywords Break OpenAI's Chatbot](5b81715df0a0f5578205ba6139f4ef03)
* [Hugging Face Launches Customizable Chat Assistants for Open Source AI](50b1e6d3ab5e8c33d34b9b477d22213f)
* [China Proposes New Regulations for AI Chatbots](b6dc0996967d1b60cd671a3f6a787e9b)