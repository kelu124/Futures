# __Nightshade: A New Tool for Artists to Combat Generative AI Exploitation__, (from page [20231029](https://kghosh.substack.com/p/20231029).)

__[External link](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/)__



## Keywords

* Nightshade
* generative AI
* artists
* data poisoning
* copyright infringement
* machine learning models
* Glaze

## Themes

* data poisoning
* generative AI
* copyright
* artists rights
* machine learning

## Other

* Category: technology
* Type: news

## Summary

A new tool named Nightshade enables artists to subtly alter their artwork before posting online, potentially disrupting AI models that scrape their work without permission. By making invisible changes to image pixels, Nightshade can corrupt the training data of generative AI models like DALL-E and Midjourney, leading to chaotic outputs. Developed by a team led by Ben Zhao at the University of Chicago, the tool aims to empower artists against unauthorized use of their art. Nightshade, which will be open-source, complements another tool called Glaze, allowing artists to mask their styles. The researchers stress the importance of addressing security vulnerabilities in AI models, as these tools could deter companies from misusing artists' rights. Artists express hope that Nightshade will prompt AI companies to respect copyright and provide fair compensation for their work.

## Signals

| name                                  | description                                                                         | change                                                                                        | 10-year                                                                                                           | driving-force                                                                                     |   relevancy |
|:--------------------------------------|:------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------|------------:|
| Nightshade Tool                       | A tool for artists to poison AI training data to protect their work.                | Shift from artists being passive victims to active participants in the AI training process.   | Artists could gain more control over their intellectual property and leverage technology to protect their rights. | The increasing use of artists' work without consent by AI companies.                              |           4 |
| Glaze Tool                            | A tool that masks artists' styles to prevent AI companies from scraping their work. | Transition from artists losing control over their styles to actively protecting them.         | Artists may be able to maintain their unique styles while sharing their work online.                              | The need for artists to safeguard their unique artistic identities in the digital realm.          |           4 |
| Data Poisoning as a Defense Mechanism | Using data poisoning to disrupt AI models trained on artist works.                  | Artists moving from traditional copyright protections to active data manipulation strategies. | Potentially fewer AI-generated works derived from copyrighted material, leading to more original creations.       | The ongoing legal battles between artists and AI companies over copyright issues.                 |           5 |
| Increased Artist Empowerment          | Artists feel more confident sharing their work due to new protective tools.         | Shift from fear of exploitation to empowerment through technological defenses.                | A more vibrant artistic community online, where artists feel secure in sharing their work.                        | The rising awareness and activism among artists regarding their rights in the age of AI.          |           4 |
| Potential for Malicious Use of Tools  | Risk of data poisoning techniques being misused for harmful purposes.               | Concerns over the ethical implications of defensive tools becoming offensive weapons.         | Stricter regulations may emerge around the use of AI tools and data manipulation.                                 | The dual-use nature of powerful technologies in the hands of individuals with varying intentions. |           3 |

## Behaviors

| name                                       | description                                                                                                    |   relevancy |
|:-------------------------------------------|:---------------------------------------------------------------------------------------------------------------|------------:|
| Data Poisoning as a Defense Mechanism      | Artists are using tools like Nightshade to intentionally alter their work to disrupt AI training processes.    |           5 |
| Empowerment of Artists in the AI Ecosystem | Artists are gaining confidence and tools to protect their intellectual property against unauthorized AI usage. |           5 |
| Open Source Collaboration                  | The decision to make Nightshade open source encourages community-driven adaptations and improvements.          |           4 |
| Vulnerability Awareness in AI Models       | Recognition of vulnerabilities in generative AI models prompts discussions on the need for robust defenses.    |           4 |
| Shift in Power Dynamics                    | The development of countermeasures against AI scraping is shifting power dynamics back toward artists.         |           5 |
| Innovative Copyright Protection Strategies | Artists are adopting innovative strategies to safeguard their creative works in the digital landscape.         |           5 |
| AI Companies Reassessing Usage Policies    | Companies are being pushed to reconsider their policies on using artists' works for training AI models.        |           4 |

## Technologies

| name           | description                                                                                                     |   relevancy |
|:---------------|:----------------------------------------------------------------------------------------------------------------|------------:|
| Nightshade     | A data poisoning tool that alters images to disrupt AI training data, damaging image-generating AI models.      |           5 |
| Glaze          | A tool that masks artists' personal styles to prevent their work from being scraped by AI companies.            |           4 |
| Generative AI  | AI capable of generating images or text from prompts, often trained on vast datasets scraped from the internet. |           5 |
| Interactive AI | Future AI systems that engage with users in real-time, moving beyond generative capabilities.                   |           4 |

## Issues

| name                                  | description                                                                                                                                      |   relevancy |
|:--------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Data Poisoning in AI Training         | The emergence of tools like Nightshade that allow artists to poison training data raises concerns about AI model integrity.                      |           5 |
| Artist Copyright and AI Ethics        | The ongoing struggle of artists to protect their work from unauthorized use by AI companies highlights ethical issues in AI development.         |           5 |
| AI Model Security Vulnerabilities     | The potential for data poisoning attacks on generative AI models indicates significant security risks in AI technologies.                        |           4 |
| Artist Empowerment through Technology | Tools like Nightshade and Glaze symbolize a shift in power dynamics, giving artists more control over their work in the digital age.             |           4 |
| Legal and Regulatory Framework for AI | The increasing number of lawsuits against AI companies by artists indicates a need for clearer legal frameworks regarding AI training practices. |           4 |
| Trust and Reliability in AI Models    | As AI models grow more powerful, concerns about their reliability and the impact of poisoned data on their outputs become more pressing.         |           4 |