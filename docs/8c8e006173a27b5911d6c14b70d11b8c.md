# __Nightshade Tool Receives Surprising Response__, from ([20240218](https://kghosh.substack.com/p/20240218).)

__[External link](https://venturebeat.com/ai/ai-poisoning-tool-nightshade-received-250000-downloads-in-5-days-beyond-anything-we-imagined/)__



## Summary

Nightshade, a new tool developed by computer science researchers at the University of Chicago, has gained significant traction with 250,000 downloads in just five days since its release. The tool is designed to disrupt AI models that scrape and train on artists' works without consent. Nightshade "poisons" generative AI image models by altering artworks on a pixel level, making them appear to contain different content. The creators also developed Glaze, a tool that prevents AI models from learning an artist's signature style. The team plans to release a combined version of Glaze and Nightshade in the future.

## Keywords

* Nightshade
* downloads
* artists
* AI models
* University of Chicago
* generative AI image models
* Glaze
* The Glaze Project
* computer science researchers
* OpenAI

## Themes

* Artificial Intelligence
* Copyright Protection
* Computer Science

## Signals

| Signal                                               | Change                                                                   | 10y horizon                                         | Driving force                                               |
|:-----------------------------------------------------|:-------------------------------------------------------------------------|:----------------------------------------------------|:------------------------------------------------------------|
| Nightshade receives 250,000 downloads in 5 days      | From low adoption to high adoption of Nightshade tool                    | More artists using Nightshade to protect their work | Artists' desire to protect their work from unauthorized use |
| Nightshade alters artworks to disrupt AI models      | From AI models training on unlicensed data to increased cost of training | Increased licensing of images from creators         | Make licensing images from creators a viable alternative    |
| Glaze/Nightshade team plans to release combined tool | From separate defensive and offensive tools to combined tool             | Comprehensive tests done to ensure no surprises     | Need to carefully test combined tool to avoid surprises     |
| Artists using both Glaze and Nightshade              | From using one tool to using two tools                                   | Protecting style while disrupting AI model training | Desire to protect style while disrupting AI model training  |
| Possibility of open-source version of Nightshade     | From closed-source to open-source Nightshade                             | More flexibility and customization for users        | More time required to develop different versions            |

## Closest

* [New Tool Nightshade Allows Artists to Fight Back Against Generative AI](737fd00bafc163f8b17f187f41d6567a)
* [Kudurru: A Tool to Protect Artists from AI Image Generators](bc433d7cb21513ab55af7f1198e0fbb6)
* [Data Poisoning and Artificial Intelligence in Social Networks](4cff2e8843b64411a60c8c80faab4c9e)
* [Google Revolutionizes Consumer Image Capture](a60e6bcdb17f08219630a0dfff0760f9)
* [Google DeepMind Launches Watermarking Tool for AI-Generated Images](d5c399872ea4d28def48f650503511a0)