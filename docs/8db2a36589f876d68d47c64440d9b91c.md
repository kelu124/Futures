# __Enterprise Risks of Data Leaks Through Generative AI Applications: Insights and Recommendations__, (from page [20250309](https://kghosh.substack.com/p/20250309).)

__[External link](https://www.csoonline.com/article/3819170/nearly-10-of-employee-gen-ai-prompts-include-sensitive-data.html)__



## Keywords

* enterprise users
* generative ai apps
* data leaks
* sensitive data
* CISOs
* IT approval
* AI strategies
* employee training

## Themes

* generative ai
* data leakage
* enterprise security
* compliance
* employee training

## Other

* Category: technology
* Type: news

## Summary

A report by Harmonic reveals that enterprise users are leaking sensitive data through both authorized and unauthorized generative AI applications. 8.5% of employee prompts to AI tools included confidential information, with customer data being the most common (46%). Legal and employee data made up significant portions as well. The challenge for Chief Information Security Officers (CISOs) is heightened by the use of shadow and semi-shadow AI, which comprises free consumer tools and unapproved paid applications. Experts suggest that CISOs need to enforce policies limiting the use of sensitive data in AI prompts while ensuring employees have access to proper tools. The rapid adoption of generative AI poses risks not only regarding data leakage but also the ingestion of flawed data. A comprehensive AI strategy is thus critical for organizations to mitigate vulnerabilities and protect sensitive information.

## Signals

| name                              | description                                                                                 | change                                                                                         | 10-year                                                                                                | driving-force                                                                                          |   relevancy |
|:----------------------------------|:--------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------|------------:|
| Unauthorized AI Usage             | Enterprise employees frequently use unauthorized generative AI tools for work tasks.        | Transitioning from sanctioned AI tools to unauthorized applications for productivity.          | A possible increase in data breaches and legal issues due to misuse of generative AI tools.            | Employee dissatisfaction with available corporate tools driving them to use unauthorized applications. |           4 |
| Shadow AI Problem                 | Emerging use of semi-shadow AI tools launched by business leaders without IT approval.      | Shift towards less controlled AI tools in the workplace, complicating data protection efforts. | Widespread use of semi-shadow AI could lead to significant corporate governance challenges.            | Pressure on executives to enhance productivity leading to non-compliant tool usage.                    |           5 |
| Data Leakage Awareness            | Increased recognition of sensitive data leakage through generative AI tools among firms.    | From unawareness to a proactive stance on managing data leakage risks.                         | Enterprises may adopt stricter data governance policies and technologies to curb leaks.                | Growing legal and compliance risks associated with data leaks weighing on corporate strategies.        |           4 |
| Marketplace for AI Training Data  | Increased interest in how generative AI apps handle user data, especially under free tiers. | From trust in app providers to skepticism about data handling practices.                       | Potential emergence of a regulated marketplace for AI training data handling to ensure transparency.   | Consumer and enterprise demand for accountability over how sensitive data is managed by AI systems.    |           3 |
| Need for Robust AI Strategies     | Fast-paced AI adoption necessitating better strategies and policies from enterprises.       | Shifting from reactive to proactive strategies for AI governance and risk management.          | Organizations may implement comprehensive AI governance frameworks to manage risks effectively.        | The urgency to mitigate risks associated with rapid AI innovations and user adoption.                  |           5 |
| Generative AI Training Techniques | Growing emphasis on training employees to use AI tools without revealing sensitive data.    | Moving from unrestricted AI use to cautious, trained interactions with AI systems.             | Widespread adoption of refined training practices could lead to safer AI engagement across industries. | Recognition of the importance of protecting sensitive information during AI interactions.              |           4 |
| CISO Strategic Challenges         | Chief Information Security Officers face challenges in controlling generative AI usage.     | From traditional security measures to adapting strategies aligned with AI advancements.        | CISOs may evolve into strategic partners for AI innovation within organizations.                       | The necessity to balance innovation with data security in an increasingly AI-integrated workplace.     |           5 |
| Rise of AI as a Risk              | Generative AI introduces dual-risk of data outflow and bad data feeding into enterprises.   | From viewing AI tools solely as a benefit to recognizing inherent risks.                       | Enterprises may develop dual-risk management systems to address outflows and inflows of data.          | Emerging understanding of the dual nature of AI systems impacting business operations.                 |           4 |

## Concerns

| name                             | description                                                                                                                              |   relevancy |
|:---------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Corporate Data Leakage           | The ongoing leakage of sensitive corporate data through both authorized and unauthorized generative AI applications poses serious risks. |           5 |
| Employee Misuse of AI Tools      | Employees may resort to unauthorized AI applications to expedite processes, compromising data security and compliance.                   |           4 |
| Shadow IT Risks                  | The use of shadow or semi-shadow AI applications without IT approval can lead to significant data security vulnerabilities.              |           5 |
| Legal Consequences of Data Leaks | Leaking sensitive information can jeopardize legal protections, especially for trade secrets, increasing litigation risks.               |           5 |
| Inadequate IT Support            | Failure of IT departments to provide adequate tools leads employees to use unapproved AI solutions, increasing data risks.               |           4 |
| Monitoring Inefficacies          | Current monitoring frameworks are inadequate to prevent data leakage through generative AI, necessitating new strategies.                |           4 |
| Bad Data Influx                  | Inaccurate or flawed data generated by AI systems can adversely impact corporate decision-making processes.                              |           4 |

## Behaviors

| name                            | description                                                                                                                                            |   relevancy |
|:--------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Data Leakage Awareness          | Employees increasingly recognize the risks of sharing sensitive data with generative AI tools, yet many inadvertently continue to do so.               |           4 |
| Shadow AI Utilization           | A rise in the use of unauthorized or semi-unauthorized generative AI applications, often for productivity or experimentation, despite potential risks. |           5 |
| IT and Business Unit Disconnect | A growing gap between the tools provided by IT and the tools employees seek, leading to unauthorized AI usage.                                         |           4 |
| Demand for AI Training          | A growing acknowledgment of the need for training employees on effective use of AI tools without compromising sensitive data.                          |           4 |
| Holistic AI Strategies          | Organizations are recognizing the need for comprehensive AI strategies that integrate risk management and employee empowerment.                        |           5 |
| Sensitivity to Data Quality     | Concern over both sensitive data leakage and the introduction of flawed data from generative AI tools is becoming more prevalent.                      |           4 |
| New Governance Models for AI    | Organizations are beginning to understand that traditional governance and control mechanisms are inadequate for managing AI-related risks.             |           5 |

## Technologies

| description                                                                                                           |   relevancy | src                              |
|:----------------------------------------------------------------------------------------------------------------------|------------:|:---------------------------------|
| AI systems that generate content, including text and images, based on prompts, presenting risks of data leakage.      |           5 | 8db2a36589f876d68d47c64440d9b91c |
| Unauthorized and semi-unauthorized generative AI applications used by employees, often leading to data privacy risks. |           5 | 8db2a36589f876d68d47c64440d9b91c |
| Innovative strategies and practices to secure sensitive information while using generative AI tools.                  |           4 | 8db2a36589f876d68d47c64440d9b91c |
| Large models that process language-based tasks, impacting data security through inappropriate data handling.          |           5 | 8db2a36589f876d68d47c64440d9b91c |
| Tools intended to oversee and manage AI data use to prevent leaks and misuse, requiring improvement.                  |           4 | 8db2a36589f876d68d47c64440d9b91c |

## Issues

| name                                       | description                                                                                                                          |   relevancy |
|:-------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Generative AI Data Leakage                 | Increased risk of sensitive corporate data being leaked through the use of generative AI apps by employees.                          |           5 |
| Unauthorized and Semi-Shadow AI Use        | Growth of shadow AI and semi-shadow AI, where employees use unapproved AI tools due to a lack of available resources from IT.        |           4 |
| Legal Risks from Trade Secrets             | Potential loss of legal protections for trade secrets when employees interact with generative AI that could expose proprietary data. |           5 |
| Ineffectiveness of Traditional IT Controls | Current monitoring and control mechanisms are failing as employees find ways to utilize generative AI without oversight.             |           4 |
| Data Quality and Integrity Concerns        | Risks associated with flawed data entering enterprises from generative AI tools, impacting corporate analysis and decision-making.   |           4 |
| Need for Comprehensive AI Strategies       | Enterprises must develop clear AI strategies to reduce risks associated with generative AI and improve employee guidance.            |           5 |