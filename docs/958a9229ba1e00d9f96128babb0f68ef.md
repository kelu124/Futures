# __Python Advent Calendar: Day 5__, from ([20221217](https://kghosh.substack.com/p/20221217).)

__[External link](https://py-advent-calendar.beehiiv.com/p/day-5-cache-me-if-you-can)__



## Summary

This article discusses the concept of object caching and focuses on the joblib library in Python. Object caching is a technique used to store frequently accessed data in temporary memory, improving the efficiency of programs. The joblib library offers features like caching and memoization for numpy arrays, easy parallelization, and serialization of complex objects. The article also mentions the functools.cache and functools.lru_cache decorators in Python's functools module, which are used for caching function calls. It provides examples of using joblib for memoization and parallelization, along with steps to perform serialization using joblib. However, it also highlights the security concerns associated with deserialization and suggests using other storage solutions for long-term storage.

## Keywords

* object caching
* joblib
* Python Advent Calendar
* boltons library
* numpy arrays
* parallelisation
* serialisation
* functools.cache
* LRU cache
* numpy arrays

## Themes

* Caching and memoization
* Parallelization
* Serialisation

## Signals

| Signal                                      | Change                                         | 10y horizon                                                    | Driving force                                                    |
|:--------------------------------------------|:-----------------------------------------------|:---------------------------------------------------------------|:-----------------------------------------------------------------|
| Caching and memoization libraries in Python | Adoption of caching and memoization techniques | More efficient and optimized caching in Python                 | Increasing need for faster computation and optimized performance |
| Parallelization libraries in Python         | Adoption of parallelization techniques         | Faster processing and execution of parallelizable tasks        | Need for faster processing and efficient use of resources        |
| Serialization libraries in Python           | Adoption of serialization techniques           | Efficient conversion of Python objects for storage and sharing | Improved storage and sharing of large data objects               |

## Closest

* [Harnessing the Power of Knowledge Graphs](69aa55d97023850224f4426e6782bb8b)
* [Large Language Models in OSINT Workflow](5cf4407dc6fa3889e047c658e27c4ccf)
* [Understanding AI Use Cases Simplified](3950528dc54ed7a01f67c9532587674a)
* [Mapping the Mind of a Large Language Model](0d67efe985265da6b082c9d80437e1c4)
* [Fine-tuning LLMs with LoRA for Digital Twin Creation](82ac82f66582103565f188f377f7af9f)