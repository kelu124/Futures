# __Limitations of LLMs and Overcoming Them__, from ([20230616](https://kghosh.substack.com/p/20230616).)

__[External link](https://medium.com/neo4j/knowledge-graphs-llms-fine-tuning-vs-retrieval-augmented-generation-30e875d63a35)__



## Summary

This blog post discusses the limitations of Large Language Models (LLMs), such as the knowledge cutoff and the occurrence of hallucinations. To overcome these limitations, two approaches are explored: fine-tuning and retrieval-augmented generation. Fine-tuning involves the supervised training phase, where question-answer pairs are used to optimize the performance of the LLM. However, fine-tuning does not fully solve the knowledge cutoff issue or eliminate hallucinations. The retrieval-augmented approach uses external information to supplement the LLM's internal knowledge, resulting in advantages such as source-citing, minimal hallucinations, and ease of updating information. However, it relies on an intelligent search tool and access to the user's knowledge base. The blog post concludes by highlighting the ongoing development of the NaLLM project and inviting readers to explore the project's GitHub repository.

## Keywords

* LLMs
* knowledge cutoff
* fine-tuning
* retrieval-augmented generation
* limitations
* internal knowledge
* hallucinations
* supervised training
* question-answer pairs
* retrieval-augmented approach

## Themes

* Limitations of LLMs
* Fine-tuning and retrieval-augmented generation
* Updating and expanding LLM knowledge

## Signals

| Signal                            | Change                                                                | 10y horizon                                                      | Driving force                                      |
|:----------------------------------|:----------------------------------------------------------------------|:-----------------------------------------------------------------|:---------------------------------------------------|
| Limitations of LLMs               | From reliance on internal knowledge to external information retrieval | Improved access to up-to-date and validated information          | Need for accurate and reliable information         |
| Knowledge cutoff problem          | From limited knowledge to updated and expanded knowledge              | LLMs with updated and expanded knowledge                         | Need for current and relevant information          |
| Inaccurate information generation | From inaccurate information to more accurate results                  | Improved verification and fact-checking of LLM-generated answers | Need for reliable and trustworthy information      |
| Fine-tuning LLMs                  | From general LLM performance to customized and optimized LLMs         | Fine-tuned LLMs for specific tasks and updated knowledge         | Optimization and customization of LLM performance  |
| Retrieval-augmented generation    | From internal knowledge reliance to external information retrieval    | Improved access to relevant and up-to-date information           | Enhanced information retrieval and personalization |

## Closest

* [The Rise of LLMs in Defense Content Analysis](6335d1cfa75abf9650361efd7b529149)
* [Unleashing Creativity with SCAMPER Method](0e850e13ca65ce51de13cd4e0ec85861)
* [Limitations of LLMs and Overcoming Them](9fd8c7460fe2d17a54694de66ebd64ca)
* [The Future of Strategic Decision-Making](c474eac8117547a89cac2c805652df9c)
* [Integrating ChatGPT with Internal Knowledge Management](977ac6628e9192d07524905819496121)
* [The Transactional Nature of Modern Life](a5c0ba498382a4edc0f2bf0d9653ad16)
* [The Enshittening of Knowledge: ChatGPT and its Implications](182bea68661560af4b5ef5728107212b)
* [The Power of Expert Prompts](52ec2cf0aebdc7af56249f1702652ebe)
* [Limitations of LLMs and Overcoming Them](9fd8c7460fe2d17a54694de66ebd64ca)
* [Backdooring a summarizerbot to shape opinion](4d1abdf7e702b559c6ccff847ce4d8d0)