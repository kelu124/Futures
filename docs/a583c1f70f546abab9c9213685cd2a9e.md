# __OpenAI Faces GDPR Compliance Challenges Over ChatGPT's Inaccurate Data Handling__, (from page [20240512](https://kghosh.substack.com/p/20240512).)

__[External link](https://noyb.eu/en/chatgpt-provides-false-information-about-people-and-openai-cant-correct-it?utm_source=ADSA&utm_medium=email&utm_campaign=badeb8dd9d-EMAIL_CAMPAIGN_2022_10_04_06_04_COPY_01&utm_term=0_5401c7226a-badeb8dd9d-453685084)__



## Keywords

* GDPR
* OpenAI
* ChatGPT
* data protection
* inaccuracies
* generative AI
* access rights

## Themes

* GDPR
* OpenAI
* data protection
* inaccuracies in AI
* generative AI

## Other

* Category: technology
* Type: news

## Summary

OpenAI has been criticized for its ChatGPT model's inability to provide accurate information or comply with EU GDPR regulations regarding personal data. Despite acknowledging that factual accuracy is a challenge, OpenAI has refused to correct incorrect data about individuals or disclose data sources. This has led to a complaint filed by noyb with the Austrian Data Protection Authority, highlighting the conflict between AI capabilities and legal obligations. The complaint emphasizes that inaccurate data about individuals can have serious consequences, and calls for an investigation into OpenAI's data processing practices and compliance with GDPR. The case reflects ongoing scrutiny of generative AI tools by European privacy authorities.

## Signals

| name                                 | description                                                                                  | change                                                                                                      | 10-year                                                                                                        | driving-force                                                                         |   relevancy |
|:-------------------------------------|:---------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------|------------:|
| Inaccurate AI Information Processing | OpenAI admits it cannot correct misinformation generated by ChatGPT.                         | Shift from reliance on AI for accurate personal data to a need for human verification.                      | In 10 years, AI systems may require mandatory human oversight to ensure data accuracy.                         | Growing concern over data privacy and the need for compliance with laws like GDPR.    |           5 |
| Regulatory Scrutiny of AI Tools      | European privacy watchdogs have begun investigating generative AI tools post-ChatGPT launch. | Increased regulatory oversight from reactive measures to proactive compliance requirements.                 | In 10 years, AI companies might need to undergo regular audits to ensure compliance with data protection laws. | Rising public demand for accountability and transparency in AI technologies.          |           4 |
| Public Figures Misrepresented by AI  | ChatGPT incorrectly provides information about a public figure's birthday.                   | Transition from trust in AI-generated data to skepticism about its reliability.                             | In 10 years, mechanisms may be established to verify AI-generated information about individuals.               | Growing awareness of the potential harm caused by misinformation in public contexts.  |           4 |
| GDPR Non-Compliance by AI Companies  | OpenAI's refusal to comply with GDPR requests raises concerns about data rights.             | Shift from technology companies being seen as compliant to facing legal accountability for data processing. | In 10 years, companies may face severe penalties for non-compliance with data protection regulations.          | Legal frameworks evolving to adapt to new technologies and protect individual rights. |           5 |
| Rise of Data Protection Complaints   | Noyb filed a complaint against OpenAI regarding data processing violations.                  | Transition from informal user feedback to formal legal actions against AI companies.                        | In 10 years, a rise in legal frameworks could lead to a surge in similar complaints against AI entities.       | Increasing awareness of consumer rights and data protection issues among the public.  |           4 |

## Concerns

| name                                 | description                                                                                                                                     |   relevancy |
|:-------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Inaccurate Information Dissemination | Generative AI like ChatGPT often produces false information, leading to harmful consequences, especially when concerning personal data.         |           5 |
| Non-compliance with GDPR             | OpenAI's inability to comply with GDPR requirements on data accuracy and individual rights poses significant legal and ethical risks.           |           5 |
| Data Privacy Violations              | The failure to provide users access to their data or correct inaccuracies raises serious concerns about individual privacy rights under EU law. |           4 |
| Lack of Transparency                 | OpenAI's inability to disclose data sources creates trust issues and undermines user confidence in the technology.                              |           4 |
| Regulatory Challenges                | Rapid advancements in AI outpace existing regulations, leading to enforcement challenges and potential legal loopholes for companies.           |           4 |
| Hallucination Phenomenon             | AI systems creating false narratives can mislead users, especially when treated as authoritative sources.                                       |           4 |

## Behaviors

| name                                        | description                                                                                                                                                            |   relevancy |
|:--------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Demand for Transparency in AI Data Usage    | Individuals are increasingly demanding transparency from AI companies regarding data sources, accuracy, and processing methods to ensure compliance with privacy laws. |           5 |
| Legal Accountability for AI Systems         | Regulatory bodies are holding AI companies accountable for adherence to data protection laws, emphasizing the need for compliance in AI-generated information.         |           5 |
| Public Awareness of AI Limitations          | The public is becoming more aware of the limitations of AI, particularly regarding factual accuracy and the potential risks of misinformation.                         |           4 |
| Increased Regulatory Scrutiny               | There is a growing trend of regulatory scrutiny on AI technologies, with authorities actively investigating compliance with data protection regulations.               |           5 |
| Rights to Data Rectification and Access     | Individuals are asserting their rights under GDPR to correct and access personal data held by AI systems, pushing for better compliance mechanisms.                    |           4 |
| Ethical Use of AI in Personal Data Handling | There is an emerging expectation for ethical standards in how AI tools handle personal data, stressing the importance of accuracy and transparency.                    |           5 |

## Technologies

| name                                    | description                                                                                                                                               |   relevancy |
|:----------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Generative AI                           | Generative AI refers to algorithms that can generate new content, such as text or images, based on training data, but may produce inaccurate information. |           4 |
| Large Language Models (LLMs)            | Large Language Models are advanced AI systems capable of understanding and generating human-like text, but they struggle with factual accuracy.           |           4 |
| Data Protection Compliance Technologies | Technologies that ensure data processing complies with regulations like GDPR, focusing on accuracy and transparency of personal data.                     |           5 |
| AI Hallucination Mitigation Techniques  | Techniques aimed at reducing the tendency of AI systems to produce inaccurate or fabricated information, especially in sensitive areas.                   |           4 |
| AI Transparency Solutions               | Tools designed to enhance transparency in AI decision-making processes, ensuring users understand data sources and accuracy.                              |           5 |

## Issues

| name                                        | description                                                                                                                                        |   relevancy |
|:--------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------|------------:|
| Inaccuracy in AI-generated personal data    | The inability of AI models like ChatGPT to provide accurate information about individuals raises significant compliance issues with GDPR.          |           5 |
| Challenges of AI compliance with GDPR       | Generative AI tools face difficulties in meeting legal requirements for data accuracy and user rights under GDPR.                                  |           5 |
| Data protection authorities' response to AI | The evolving role of data protection authorities in regulating AI and ensuring compliance with privacy laws is becoming increasingly important.    |           4 |
| Public trust in AI technologies             | The frequent inaccuracies and lack of accountability in AI-generated information may erode public trust in these technologies.                     |           4 |
| Regulatory frameworks for AI                | There is a growing need for clear regulatory frameworks to govern the development and deployment of generative AI technologies.                    |           4 |
| Impact of AI hallucination on individuals   | The phenomenon of AI hallucination poses serious risks when generating information about individuals, potentially leading to harmful consequences. |           5 |
| Legal accountability of AI companies        | The question of legal accountability for inaccuracies in AI outputs and the responsibilities of companies like OpenAI is gaining prominence.       |           5 |