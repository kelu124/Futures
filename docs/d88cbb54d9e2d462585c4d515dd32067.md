# __Best Practices for AI Transparency: Deepfake and Chatbot Requirements__, from ([20240428](https://kghosh.substack.com/p/20240428).)

__[External link](https://www.law.kuleuven.be/citip/blog/emerging-best-practices-for-deepfake-and-chatbot-transparency-under-the-eu-ai-act/?utm_source=substack&utm_medium=email)__



## Summary

The blog discusses the policy prototyping project conducted by the Knowledge Centre Data & Society on the transparency requirements under the EU AI Act. It focuses on the best practices emerging from the project regarding deepfake and chatbot transparency. The project tested the requirements by collecting stakeholder feedback and developing prototype disclaimers and decision-making processes. The feedback led to the identification of three best practices, which include ensuring accessibility, providing the appropriate amount of information, and tailoring disclaimers to the target audience. The blog also highlights areas for further improvement and testing, such as fine-tuning the decision-making processes and incorporating considerations for applicable exceptions. Overall, the project offers promising approaches for complying with the transparency requirements of the EU AI Act.

## Keywords

* transparency requirements
* EU AI Act
* deepfake
* chatbot
* IFUs
* disclaimers
* policy prototyping project
* stakeholder feedback
* best practices
* accessibility

## Themes

* AI transparency
* EU regulations
* deepfake and chatbot transparency

## Signals

| Signal                                                  | Change                                                     | 10y horizon                                                                | Driving force                                                    |
|:--------------------------------------------------------|:-----------------------------------------------------------|:---------------------------------------------------------------------------|:-----------------------------------------------------------------|
| EU AI Act transparency requirements prototyping project | Testing transparency requirements for AI systems           | Improved transparency and accountability for AI systems                    | Building trust and ensuring accountability in AI systems         |
| Best practices for deepfake and chatbot transparency    | Accessibility, information, and target audience adaptation | Disclaimers adapted for diverse audience, layered approach to transparency | Meeting diverse user needs and preferences in AI interactions    |
| Areas for further improvement and testing               | Fine-tuning decision-making, testing new requirements      | More refined transparency requirements, personalized transparency          | Adapting transparency to specific use cases and individual needs |

## Closest

* [Compliance of Foundation Model Providers with EU AI Act](b39cd180dcfb9a92e51a09e5dcb0a0f4)
* [EU Parliament Approves Artificial Intelligence Act to Ensure Safety and Compliance](620cdc3041430333c4c479a471f67fdb)
* [EU Ambassadors Approve Comprehensive AI Rulebook](09558bc92bd7eb77706cfae4499f7d05)
* [Challenges and Concerns in AI Deployment](382e9ebc1e518ee49e541da1e6b5f8af)
* [Landmark Legislation: MEPs Endorse Rules for Artificial Intelligence](550199f663e5e26f2824e80f55126c56)