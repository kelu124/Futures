# __Family Almost Scammed in Voice Impersonation Scam__, from ([20240210](https://kghosh.substack.com/p/20240210).)

__[External link](https://www.malwarebytes.com/blog/news/2024/01/ai-used-to-fake-voices-of-loved-ones-in-ive-been-in-an-accident-scams)__



## Summary

Scammers are using tactics such as faking emergency situations, like car accidents or unexpected hospitalizations, to spread panic and trick their victims. The advancement of Artificial Intelligence (AI) has made it easier for scammers to convincingly fake the voice of a loved one in distress. The FBI has received numerous complaints about these types of scams, known as "grandparent scams," resulting in significant financial losses. To avoid falling victim to scams like these, individuals should avoid sharing too much personal information, avoid answering calls from unknown or private numbers, verify the caller's telephone number, and never provide financial or personal information over the phone. It is important to notify the police immediately if such a call is received and to seek protection for personal information through tools like Malwarebytes Identity Theft Protection.

## Keywords

* scam
* car accident
* hurt
* pregnant woman
* emergency situation
* AI
* voice
* criminals
* grandparent scams
* avoid scams

## Themes

* Scams
* Artificial Intelligence
* Identity Theft

## Signals

| Signal                                | Change                                  | 10y horizon                                                         | Driving force                                                     |
|:--------------------------------------|:----------------------------------------|:--------------------------------------------------------------------|:------------------------------------------------------------------|
| Increase in AI-powered voice scamming | From traditional scamming techniques    | Scammers can convincingly fake the voice of a loved one in distress | Scammers spreading panic and exploiting emotional vulnerabilities |
| Advancements in AI technology         | From manual social engineering          | Scammers can easily and convincingly fake voices with AI tools      | Criminals seeking to manipulate and deceive victims               |
| Precautions against voice scams       | From lack of awareness and preparedness | People become more cautious and informed about voice scams          | Rising awareness about the prevalence and tactics of voice scams  |

## Closest

* [AI Voice Simulators Enable Scammers to Exploit Vulnerable Individuals](0a49a5c0770b63ff41a4b19b66e478b1)
* [FBI Warns of Tech Support Scams Using Shipping Companies](49e0af19d90eda0f809a16b24ee8cbee)
* [Finance worker conned into paying $25 million in deepfake scam](d58f865ef4ddbe1ee773770b8910a10b)
* [How I Got Scammed: And Why AI Will Make It Worse](6bca129462382d090b52faf72fe48e3d)