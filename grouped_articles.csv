,text,labels
0,"Veuillez mettre à jour votre navigateur
Votre navigateur n'est plus compatible. Mettez-le à jour pour profiter au mieux de YouTube et de nos dernières fonctionnalités. En savoir plusMe le rappeler plus tard
Votre navigateur n'est plus compatible. Mettez-le à jour pour profiter au mieux de YouTube et de nos dernières fonctionnalités. En savoir plusMe le rappeler plus tard",0
1,"In what might be a first, a New York-based artist named Kris Kashtanova has received US copyright registration on their graphic novel that features AI-generated artwork created by latent diffusion AI, according to their Instagram feed and confirmed through a public records search by Ars Technica.
The registration, effective September 15, applies to a comic book called Zarya of the Dawn. Kashtanova created the artwork for Zarya using Midjourney, a commercial image synthesis service. In their post announcing the news from Tuesday, Kashtanova wrote:
I got Copyright from the Copyright Office of the USA on my Ai-generated graphic novel. I was open how it was made and put Midjourney on the cover page. It wasn’t altered in any other way. Just the way you saw it here.
I tried to make a case that we do own copyright when we make something using AI. I registered it as visual arts work. My certificate is in the mail and I got the number and a confirmation today that it was approved.
My friend lawyer gave me this idea and I decided to make a precedent.
Going by their announcement, Kashtanova approached the registration by saying the artwork was AI-assisted and not created entirely by the AI. Kashtanova wrote the comic book story, created the layout, and made artistic choices to piece the images together.
It's likely that artists have registered works created by machine or algorithms before because the history of generative art extends back to the 1960s. But this is the first time we know of that an artist has registered a copyright for art created by the recent round of image synthesis models powered by latent diffusion, which has been a contentious subject among artists.
Speculation about whether AI artwork can be copyrighted has been the subject of many articles over the past few months, and just yesterday, we wrote about Getty Images banning AI-generated artwork on its site over unresolved issues about copyright and ethics issues.
Despite popular misconception (explained in the Getty piece), the US Copyright Office has not ruled against copyright on AI artworks. Instead, it ruled out copyright registered to an AI as the author instead of a human.
Zarya of the Dawn, which features a main character with an uncanny resemblance to the actress Zendaya, is available for free through the AI Comic Books website. AI artists often use celebrity names in their prompts to achieve consistency between images, since there are many celebrity photographs in the data set used to train Midjourney.
You must login or create an account to comment.",3
2,"Read the list of statements below.
1. Covid-19 escaped from a Chinese laboratory.
2. Climate change demands a radical transformation of modern lifestyles.
3. Donald Trump colluded with Vladimir Putin to get elected.
4. The real founding of the American project was not in 1776 but in 1619.
5. The FBI investigation into the Trump campaign was based on lies.
6. The Defund the Police movement caused a crime spike in American cities.
7. Kyle Rittenhouse did nothing wrong.
For each statement, write down whether it is true or false, and whether the issue is very important or not that important.
Pick the friend whose political beliefs are most different from yours, and to whom you are still willing to speak. Ask your friend to complete the questionnaire too. Explain to this friend why his or her answers are insane.
On the recent twentieth anniversary of 9/11, I reflected on how I would tell my children about that day when they are older. The fact of the attacks, the motivations of the hijackers, how the United States responded, what it felt like: all of these seemed explicable. What I realized I had no idea how to convey was how important television was to the whole experience.
Everyone talks about television when remembering that day. For most Americans, “where you were on 9/11” is mostly the story of how one came to find oneself watching it all unfold on TV. News anchors Dan Rather, Peter Jennings, and Tom Brokaw, broadcasting without ad breaks, held the nation in their thrall for days, probably for the last time. It is not uncommon for survivors of the attacks to mention in interviews or recollections that they did not know what was going on because they did not view it on TV.
If you ask Americans when was the last time they recall feeling truly united as a country, people over the age of thirty will almost certainly point to the aftermath of 9/11. However briefly, everyone was united in grief and anger, and a palpable sense of social solidarity pervaded our communities.
Today, just about the only thing everyone agrees on is how divided we are. On issue after issue of vital public importance, people feel that those on the other side are not merely wrong but crazy — crazy to believe what they do about voter ID, Russiagate, critical race theory, pronouns and gender affirmation, take your pick. Americans have always been divided on important issues, but this level of pulling-your-hair-out, how-can-you-possibly-believe-that division feels like something else.
It is hard to imagine how we would have experienced 9/11 in the era of Facebook and Twitter, but the pandemic provides a suggestive example. Just as in 2001, in 2020 we faced a powerful external threat and had a government willing to meet it. But instead of unity, American society has experienced tremendous fragmentation throughout the pandemic. Beginning with whether banning foreign travel or using the label “Wuhan virus” was racist, to later mask mandates, school closures, lockdowns, and vaccine requirements, we googled, shared, liked, and blocked our way apart. Nobody was tuning in to the same broadcast anymore.
Of course, we have heard no end of laments for the loss of the TV era’s unity. We hear that online life has fragmented our “information ecosystem,” that this breakup has been accelerated by social division, and vice versa. We hear that alienation drives young men to become radicalized on Gab and 4chan. We hear that people who feel that society has left them behind find consolation in QAnon or in anti-vax Facebook groups. We hear about the alone-togetherness of this all.
What we haven’t figured out how to make sense of yet is the fun that many Americans act like they’re having with the national fracture.
Take a moment to reflect on the feeling you get when you see a headline, factoid, or meme that is so perfect, that so neatly addresses some burning controversy or narrative, that you feel compelled to share it. If it seems too good to be true, maybe you’ll pull up Snopes and check it first. But you probably won’t. And even if you do, how much will it really help? Everyone else will spread it anyway. Whether you retweet it or just email it to a friend, the end effect on your network of like-minded contacts — on who believes what — will be the same.
“Confirmation bias” names the idea that people are more likely to believe things that confirm what they already believe. But it does not explain the emotional relish we feel, the sheer delight when something in line with our deepest feelings about the state of the world, something so perfect, comes before us. Those feelings have a lot in common with how we feel when our sports team scores a point or when a dice roll goes our way in a board game.
The unity we felt watching the news unfold on TV gave way to the division we feel watching events unfold online. We all know that social media has played a part in this. But we should not overestimate its impact, because the story is much bigger. It is a story about the shifting foundations of reality itself — a story in which you and I are playing along.
Hello again. I hope you and your friend are still on speaking terms after our fun collaborative activity. Now let’s try something completely different. Follow me, if you will, into dreamland.
Last week, I saw an ad for a movie in the newspaper, with an old clock in the background. But something was funny about it. The numbers were off — 2, 0, 2, 7….
Could this be a phone number? I tried dialing the first ten numbers, and got an automated message of a woman’s voice in a nebulous accent reading another series of numbers. I have been pulling at the thread ever since.
I did some digging and found out that I’ve stumbled on a kind of game: an alternate reality game. I’m guessing you may not have heard of them?
Alternate reality games are a lot like reading Agatha Christie or Sue Grafton or watching Sherlock. There is something deeply satisfying about unraveling a mystery story when we’re taken in by it. No one has really been murdered, but we still feel suspense until the puzzle is solved.
A good mystery writer will hide the clues in plain sight. She doesn’t have to do that. She could just describe how the detective solves the case. But she does it because she knows that we want to see if we can figure it out ourselves!
Now what if you could do more than just follow along with the story? What if you could actually be the detective? Say you notice a clue and you figure out what it means, and it tells you to look for a hidden message in a classified ad in tomorrow’s newspaper. The message tells you to go to a local bakery tomorrow at noon to find another clue.
That’s what happens in an alternate reality game. It’s a story that you play along with in the real world. It’s like an elaborate scavenger hunt, on the Internet and in real life, with millions of other people all over the world playing along too.
Speaking of which, I have a hunch what the numbers from the lady on the phone mean, but I can’t say anything else on an open channel. If you want to help us solve the puzzle, our Signal chat link is ⬛⬛⬛⬛⬛.
During the Trump era, as a wider swath of people began to pay attention to the online right, a group of game designers noticed disturbing parallels between QAnon, with its endlessly complex conspiracy theories, and their own game creations. Most notably, in the summer of 2020, Adrian Hon, designer of the game Perplex City, wrote a widely shared Twitter thread and blog post drawing parallels between QAnon and alternate reality games.
Theory: QAnon is popular partly because the act of “researching” it through obscure forums and videos and blog posts, though more time-consuming than watching TV, is actually *more enjoyable* because it’s an active process.— Adrian Hon (@adrianhon) July 9, 2020
Game-like, even; or ARG-like, certainly.
An alternate reality game begins when people notice “rabbit holes” — little details they happen across in the course of everyday life that don’t make sense, that seem like clues. Consider the game Why So Serious?, which was actually a marketing campaign for the 2008 Batman movie The Dark Knight. The game started when some fans at a comic book convention found dollar bills with the words “why so serious?,” and George Washington defaced to look like the Joker. Googling the phrase led to a website … which directed players to show up at a certain spot at a certain time … where a skywriting plane appeared and wrote out a phone number … which led to more clues. Eventually you found out that there was a war going on between the Joker’s criminal gang and the Gotham Police.
The “game masters” don’t necessarily write out the whole story in advance. They might make up some parts of it as they go, creating clues in response to what players are doing. Some games offer prizes, like coordinates to a secret party. But really, the reward is just the satisfaction of solving the mystery.
The structural similarities between all this and QAnon, the game designers thought, were remarkable. In QAnon, too, the rabbit holes can be anywhere: YouTube videos, believers carrying signs at Trump rallies with phrases only other followers would recognize, or enigmatic posts on online message boards. QAnon, of course, also has a game master: Q, the unidentified person behind the curtain. Although he or she has lately been silent, Q used to send regular messages, which pointed to leaked emails, obscure news stories, and numerological puzzles.
Like in QAnon, this blending of online and offline is typical for ARGs. Players navigate a thicket of websites, email accounts, even real phone numbers or voicemail accounts whose passwords you have to figure out. The game masters might send you an email from a character, leak a (fake) classified document on an obscure website, or send you to a real-world dead drop to find a USB drive. At one point in the Batman game, players were directed to a specific bakery, where they could give a name from the game and pick up a real cake with a real phone buried inside.
With both QAnon and alternate reality games, it can be hard to tell what is and isn’t “real.” Of course, QAnon followers think that their world is the real world, whereas ARG players know they are in a game. That’s an important difference. But the point of an alternate reality game is also to blur the boundaries of the game. In fact, many use a “this is not a game” conceit, intentionally obscuring what is real and what are made-up parts of the game in order to create a fully immersive experience.
Unlike role-playing games, in an alternate reality game you play as yourself. Part of what’s so much fun is the community that forms among players, mostly online. For devoted players, status accrues to finding clues and providing compelling interpretations, while others can casually follow along with the story as the community reveals it. It is this collaboration — a kind of social sense-making — that builds the alternate reality in the minds of players.
Likewise, once you get interested in QAnon, there is a rich community built through video channels, discussion forums, and Facebook groups. Late-night chats and brainstorming sessions create an atmosphere of camaraderie. Followers make videos and posts that provide compelling interpretations of clues, aggregate the best ideas from the message boards, and simply entertain others playing in the same sandbox. Successful content creators gain social status and make money from their work.
Most of all, QAnon followers find deep personal satisfaction, achievement, and meaning in the work they are doing to trace the strings to the world’s puppeteers. As the journalist Anne Helen Peterson wrote on Twitter: “Was interviewing a QAnon guy the other day who told me just how deeply pleasurable it is for him to analyze/write his ‘stories’ after his kids go to sleep.” That thrill is not unlike what you feel when you play an alternate reality game.
Maybe this idea that QAnon is like an alternate reality game was just a wild theory too. ARG designers and players may be prone to overestimate the importance of parallels, seeing clues where there are none. Or maybe it was prophetic, considering the role that QAnon adherents would play in the U.S. Capitol attack just a few months after this idea garnered widespread attention. Indeed, there is a case — and I am going to make it here — that the parallel can be fruitfully extended much farther.
Adrian Hon points in the right direction:
I don’t mean to say QAnon is an ARG or its creators even know what ARGs are. This is more about convergent evolution, a consequence of what the internet is and allows.
In other words, the similarities between QAnon and alternate reality games do not owe to something uniquely insane about Q followers. Rather, Hon says, both are outgrowths of the same structural features of online life.
Hon writes that in alternate reality games, “if speculation is repeated enough times, if it’s finessed enough, it can harden into accepted fact.” And Michael Andersen, a writer who has dissected ARGs since the aughts, describes the appeal of seeing the finished game this way: “All of the assumptions and logical leaps have been wrapped up and packaged for you, tied up with a nice little bow. Everything makes sense, and you can see how it all flows together.”
Does this sound familiar? If you had encountered out of context the paragraph you just read, what would you think it was about? Widely held beliefs on Russiagate, perhaps? On the origins of the coronavirus? The 2020 election results? Covid hysteria?
Okay, time for another quiz. Read the list of statements below:
1. New facial recognition systems, which are designed by profit-maximizing Silicon Valley companies and could be used by police departments, falsely identify black women 100 times more often than white men.
2. San Francisco has become a paradise for lawlessness, as district attorneys have stopped prosecuting shoplifters, and videos show thieves brazenly walking out of stores with bags full of goods while security guards make no effort to stop them.
3. Under a new biosecurity regime in Europe, thousands of people have been implanted with microchips in their arms that store their Covid vaccination status and ID, allowing them to scan their bodies to access areas available only to those who comply with vaccine requirements.
4. Dark money from ultra-wealthy conservative donors bent on radicalizing the American right has funded a single writer, whose reports have been viewed 250 million times online, to create a MAGA panic over “critical race theory” being taught in schools.
Each of these statements is based on information that has been reported as true by credible mainstream outlets (MIT Media Lab, NBC News, Newsweek, The New Yorker).
Which statement feels most telling — like it speaks to a much bigger story that demands further investigation? Pick one and do the research.
In October 1796, a report appeared in Sylph magazine that sounds peculiar to us today:
Women, of every age, of every condition, contract and retain a taste for novels…. The depravity is universal…. I have actually seen mothers, in miserable garrets, crying for the imaginary distress of an heroine, while their children were crying for bread: and the mistress of a family losing hours over a novel in the parlour, while her maids, in emulation of the example, were similarly employed in the kitchen…. with a dishclout in one hand, and a novel in the other, sobbing o’er the sorrows of Julia, or a Jemima.
Though this may seem silly now, there is reason to think that the eighteenth-century British moralists who panicked over the spread of a new medium were not entirely wrong. Defoe’s Robinson Crusoe, Voltaire’s Candide, Rousseau’s Emile, and Goethe’s The Sorrows of Young Werther, exemplars of the new modern literary form known as the novel, were more than just great works of art — they were new ways of experiencing reality. As literary critic William Deresiewicz has written, novels helped to forge the modern consciousness. They are “exceptionally good at representing subjectivity, at making us feel what it’s like to inhabit a character’s mind.”
Perhaps even revolution was the result. Russian revolutionary activity, in particular, was inextricably tied up with novels. Lenin wrote about Nikolay Chernyshevsky’s novel What Is to Be Done? that “before I came to know the works of Marx … only Chernyshevsky wielded a dominating influence over me, and it all began with What Is to Be Done?,” and that “under its influence hundreds of people became revolutionaries.” He later borrowed the novel’s title for his own 1902 revolutionary tract.
In our day, the departure from consensus reality began in innocent fashion, and with a different genre of entertainment: with wizards and dice rolls in 1970s basements. Board games, war games, and fantasy novels had all been around for a long time. What role-playing games like Dungeons & Dragons pioneered was using the same gameplay mechanics not to fight tabletop wars but to tell stories, centered not on armies but on individual characters of a player’s own creation. The point of playing was not to beat your opponent but to share in the thrill of making up worlds and pretending to act in them. You might be an elven warlock rescuing a maiden, or a dwarven paladin breaking out of a city besieged by orcs. Or you might be the “dungeon master,” the chief storyteller who decides, say, whether the other players encounter a dragon or a manticore.
The role-playing game is to our century what the novel was to the eighteenth: the social art form epitomizing and evangelizing a new mode of self-creation. Role-playing games became especially popular in the 1980s, fostering a moral panic over the corruption of the youth, and their influence has continued to vastly exceed that of table-top games.
As soon as the scientists, students, and computer hobbyists who loved Dungeons & Dragons began connecting with each other through what would come to be called the Internet, they began to play games together. On top of the early text-based online world, they created chat protocols for role-playing games. It was an early form of what Sherry Turkle called “social virtual reality.”
Many of the systems we now use online have their structural origins in the world of role-playing games. Video games of all sorts borrow concepts from them. “Gamified” apps for fitness, language learning, finance, and much else award users with points, badges, and levels. Facebook feeds sort content based on “likes” awarded by users. We build online identities with the same diligence and style with which Dungeons & Dragons players build their characters, checking boxes and filling in attribute fields. A Tinder profile that reads “White nonbinary (they/her) polyamorous thirtysomething dog mom. Web-developer, cross-fit maniac, love Game of Thrones” sounds more like the description of a role-playing character than how anyone would actually describe herself in real life.
Role-playing games combined character-building, world-building, game masters telling stories, creating puzzles, and rules for scoring points and making decisions — all for having fun with friends in an imagined world for a little while. Could we have imported online all of these tools for building alternate realities without getting sucked into the game?
Several weeks have gone by since you picked your rabbit hole. You have done the research, found a newsletter dedicated to unraveling the story, subscribed to a terrific outlet or podcast, and have learned to recognize widespread falsehoods on the subject. If your uncle happens to mention the subject next Thanksgiving, there is so much you could tell him that he wasn’t aware of.
You check your feed and see that a prominent influencer has posted something that seems revealingly dishonest about your subject of choice. You have, at the tip of your fingers, the hottest and funniest take you have ever taken.
1. What do you do?
a. Post with such fervor that your followers shower you with shares before calling Internet 911 to report an online murder.
b. Draft your post, decide to “check” the “facts,” realize the controversy is more complex than you thought, and lose track of real work while trying to shoehorn your original take into the realm of objectivity.
c. Private-message your take, without checking its veracity, to close friends for the laughs or catharsis.
d. Consign your glorious take to the post trash can.
2. How many seconds did it take you to decide?
3. In however small a way, did your action nudge the world toward or away from a shared reality?
Digital discourse creates a game-like structure in our perception of reality. For everything that happens, every fact we gather, every interpretation of it we provide, we have an ongoing ledger of the “points” we could garner by posting about it online.
Sometimes, something will happen in real life that provides such an outstanding move in the game that it will instantly go viral. Conversely, we tend not to talk about things that are important but do not garner many “points.” So, for instance, there has been far less frothy discourse on Twitter and in the New York Times about the restoration of the multi-billion-dollar state and local tax deduction — conservatives give it only a few points for liberal hypocrisy, and for liberals it’s a dead-end — than about Alexandria Ocasio-Cortez’s “Tax the Rich” dress — lots of points in many different worlds.
Alternate reality games dictate what is and is not important in the unending deluge of information — what gets points and what doesn’t. What falls outside of or challenges the story of a given game is not so much disputed as ignored, and whatever fits neatly within it is highlighted. Wanting to understand the facts in perspective cannot alone explain the level of attention paid to vaccine complications, maskless people on planes, drag queen story hours, or school book bans by neofascist state legislatures (have I made everyone mad?). ARGs are not about establishing the facts within consensus reality. They are about finding the most compelling model of reality for a given group. If your ads, social media feeds, Amazon search results, and Netflix recommendations are targeted to you, on the basis of how you fit within a social group exhibiting similar preferences, why not your model of reality?
Perhaps this helps to explain why fact-checking seems so pitiably unequal to our moment. Yes, unlike a genuine game, QAnon followers assert claims about the real world, and so they could, in theory, be verified and falsified. It isn’t all confirmation bias — surprise is still possible: The Pizzagate believer who in 2016 brought a rifle to a D.C. pizza place to rescue child sex slaves from a ring believed to involve Hillary Clinton was genuinely shocked that the building didn’t have a basement. But ARGs can keep going because there are a myriad of possible solutions to puzzles in the game world. Debunking only ever eliminates one small set of narratives, while keeping the master narrative, or the idea of it, intact. For QAnon, or contemporary witchcraft, or #TheResistance, or Infowars, or the idea that all elements of American life are structured by white supremacy, one deleted narrative barely puts a dent in what people are drawn to: the underlying world picture, the big story.
Months have gone by since you went down the rabbit hole.
You are now an expert. You have alienated a few old friends … but made some great new ones, who get you better anyway.
Now consider the following statement:
The more I learn, the more astonished I am that everybody else isn’t taking this story as seriously as I am. My eyes keep opening while other people are going blind.
1. Do you agree or disagree?
2. How do you think the players who picked the other rabbit holes would answer?
To play an alternate reality game is to be drawn into a collaborative project of explaining the world. It is to lose, even fleetingly, one’s commitment to what is most true in the service of what is most compelling, what most advances a narrative one deeply believes. It allows players to neatly slot vast reams of information into intelligible characters and plots, like “Everything that has gone wrong is the product of evil actors or systems, but there are powerful heroes coming to the rescue, and they need your help.” Unlike a board game, this kind of world-building has no natural boundary. Players can become entranced and awe-struck at the sheer scale of information available to them, and seek to assimilate it into building the grandest narrative possible. They try to generate a story in which all of the facts they have piled up make sense.
So what if an alternate reality game really did keep on going, if it had no end point? It would amount to a simulation of the world. All aspects of “reality” that fit into the simulation, including some produced artificially by players for fun and profit, would be incorporated. If the game had no boundary, at some point you could think that the world it is building simply is the world. In one early ARG, after the final puzzle had been solved, some participants winkingly suggested they next “solve” 9/11.
ARG game masters have described one of the pathologies of players as apophenia, or seeing connections that aren’t “really there” — that the designers didn’t intend — and therefore pursuing red herrings. In one game, in which players had to look for clues in a basement, some scraps of wood accidentally formed the shape of an arrow pointing to a wall. Players believed it was a clue and decided they needed to tear down the wall to find the next clue. (The game master intervened just in time.) But the difference between true and false interpretations exists only if the puzzle has one right answer, or one central authority — like J. K. Rowling intervening in fan debates about which Harry Potter characters are gay. The puzzle that today’s media consumers are trying to solve is the world, and interpretations are more or less up for grabs as long as they fit the story.
In a world in which we all play alternate reality games, we each pile up superabundant facts, theories, and interpretations that support the main narratives, and our allegiances gradually solidify as we consume and produce the game material. It’s not just interpretations of data that wildly diverge between different games, but also players’ sense of what is realistic or plausible — for example, their perceptions of the rates of homicides committed by police, or by illegal immigrants. This means that, in any crisis situation, the most narrative-enhancing reports will spread widest and fastest, regardless of whether they are overturned by later reporting. As L. M. Sacasas noted about the media experience of January 6, “a consensus narrative will almost certainly not emerge.”
The cynical reader might interject that the bygone era of mass media was not a golden age of truth, but was subject to its own overarching narratives and its own biased reporting. But what matters here is that mass media, rooted in an advertising business model and in broadcast technologies, created the incentives and capability for only a small number, perhaps even just one, of these narratives to emerge at one time. Both journalists and spin doctors attempted to massage or manipulate the narrative here or there, but eventually mass media converged on whatever the narrative was. In an age of alternate realities, narratives do not converge.
As the media ecosystem produces alternate realities, it also undermines what remains of consensus reality by portraying it as just one problematic but boring option among many. The process of arriving at this contrary view of the consensus — a process sometimes called “redpilling,” after The Matrix — goes something like this: A real-world event occurs that seems important to you, so you pay attention. With primary sources at your fingertips, or reported by those you trust online, you develop a narrative about the facts and meaning of the event. But the consensus media narrative is directly opposed to the one you’ve developed. The more you investigate, the more cynical you become about the consensus narrative. Suddenly, the mendacity of the whole “mainstream” media enterprise is laid bare before your anger. You will never really trust consensus reality again.
Opportunities for such redpill moments are growing in frequency: the 2016 presidential election, the George Floyd protests, masking and lockdowns, the crime wave in American cities. There were always chinks in consensus reality — think of the newsletters of the radical right or the zines of the leftist counterculture — but finding consensus-destroying information was costly. The process was unable to produce the real-time whiplash of today’s redpill moments. The speed at which events like these are piling up suggests that the change is structural, that it is the media ecosystem itself that is fundamentally transforming.
For our final game, please consider a troubling episode of dreampolitik from very recent American history.
Driven by devastation over the outcome of the presidential election, brought together by algorithmic recommendations on social media feeds, fueled by information overload, loosely organized by networks of influencers, egged on by massive ratings and follower counts, and strengthened in the loyalty that comes with telling an audience what it wants to hear, committed media game players created an alternate reality in which the good guys were working behind the scenes to bring down the bad guys. The story of secret activity that would end the hated presidency at any moment became detached from the actual government investigations underway, from verifiable facts, from discernible reality.
Is the paragraph above a description of …
a. How media members, powerful political actors, and ordinary people deranged by Trump bought into the now-discredited Steele dossier, which claimed to show collusion between Trump and Russia?
b. How media members, powerful political actors, and ordinary people deranged by Trump bought into the “Stop the Steal” lie, leading them to mob the United States Capitol building and try to overturn the 2020 election?
Pick one.
My argument here is not that we are all the way into Wonderland, or even close to it yet. But that qualification should be as worrying as it is reassuring.
The change I am outlining is in most parts of the media world still fairly subtle — the addition of a new valence in how we see actors interpreting information, sharing content, and choosing what to emphasize. The real world still exerts hard pressure on the narratives people are willing to accept, and the realm of pure fantasy remains that of a small fringe. Yet while game-like media habits are easiest to see and most pronounced in Q-world, we can already see some of the same activities, engrossments, and intuitions that are involved in playing an alternate reality game creeping into the broader media ecosystem too — even in sectors that pride themselves on providing the sane alternative, the lone voice of reality. The point here is not to draw a moral equivalence, or to say that all these actors have lost their grip to the same degree, but rather to suggest a troubling family resemblance. The underlying structure of the reality-gamesmanship we find in, say, Infowars has its counterpart in, say, Trump-era CNN: incentives and rewards, heroes and villains, plotlines, reveals, satisfying narrative arcs.
To be a consumer of digital media is to find yourself increasingly “trapped in an audience,” as Charlie Warzel puts it, playing one alternate reality game or another. Alternate reality games take advantage of ordinary human sociality and our inherent need to make sense of the world. All it takes for the media environment to begin functioning like everyone is playing alternate reality games is:
Internet brain worms thrive on these ingredients. As long as spending more time consuming media — whether Facebook, MSNBC, talk radio, or whatever — increases the strength of one’s exposure, the worms will find their way. Reality as we understand it is a phenomenon of social structures, language, and shared processes for engaging with the world. Digital media is remaking all of these in such a way that media consumption more and more resembles the act of playing an alternate reality game.
The recent rise of subscription newsletters on the platform Substack has provided a powerful if depressing natural experiment of this phenomenon. Freddie de Boer and Charlie Warzel, both widely read commentators, have written about tinkering with their own Substack content, finding that calibrating posts to engage with Twitter controversies of the day led to exploding levels of clicks and new subscriptions, while sober, calm content was relatively ignored. Writers who get their income directly from subscriptions have every incentive to provide red meat day after day for some particular viewpoint. Sensationalism is of course as old as the news itself, but what targeted media like newsletters provide is the incentive to be sensationalistic for niche audiences. There is a reward for spinning alternate realities.
When writing for niche audiences, more status accrues to sharing narrative-enhancing facts and interpretations than to sharing what most of us can agree is reality. Those who quixotically hold on to the TV-era norms of balance and fact-checking won’t find themselves attacked so much as bypassed. By a process of natural selection, attention and influence increasingly go to those who learn to “speed-run through the language game,” to borrow from Adam Elkus, laying out juicy narratives according to the incentives of the media ecosystem without consideration of real-world veracity.
Business analytics will continue to drive this divergence. To illustrate the pervasiveness of this process, consider the logic by which The Learning Channel shifted from boat safety shows to Toddlers & Tiaras, and the History Channel from fusty documentaries to wall-to-wall coverage of charismatic Las Vegas pawn shop owners and ancient aliens theories. Content producers have an acute sense of which material gets the most views, the longest engagement, and the highest likelihood of conversion into subscriptions. At every step, every actor has the incentive to make the media franchise more of what it is becoming.
It’s an alien life form.– David Bowie about the Internet, 1999
It is tempting to believe that, sure, other people are headed into Wonderland, but not me. I can see what’s happening. What if, say, you are not online, or don’t even pay much attention to the news? Even if your picture of the world is determined mainly by conversations with friends and family, you will find yourself being drawn into an alternate reality game, based on the ARGs they are playing. These games have “network scale” — they are more fun and powerful the more people you know are involved. This is also why it is becoming more and more difficult, and unlikely, for people playing different games to even talk to each other. Indeed, a common conceit of some media games is that “nobody is talking about this.” We are losing a shared language. It is not that we arrive at different answers about the same questions, but that our stories about the world have different characters and plots.
It is increasingly undeniable, looking at revealed preferences, that people can come to value their digital communities, relationships, and realities more than those of “meatspace,” as the extremely online call our enfleshed world. “For where your treasure is, there your heart will be also.” Every year, consumers spend billions of dollars on skins, costumes, and other “materials” in video games. Digital “property” like cryptocurrencies and non-fungible tokens have exploded. People attend events, show up at rallies, and even take vacations in order to post about them online. Many users on Reddit last year spent thousands of dollars on shares in the seemingly failing video game retailer GameStop, some declaring that they were prepared to lose the money, to send a message and garner status and make great “loss porn.” Recently, a player annoyed at the way the U.K.’s Challenger 2 tank was modeled in a video game posted classified documents to a game forum to make his point.
More than money, some participants in alternate reality games are willing to risk their lives and freedom. Over the past few years, Americans deeply immersed in their online versions of reality, driven by the desire to either influence them or create content, have: broken into a military facility, murdered a mob boss, burned down businesses, exploded a suicide car bomb, and stormed the Capitol.
Those who have studied the past should not be surprised. The most contested subjects in human history have arguably not been land or fortunes, but symbols, ideas, beliefs, and possibilities. As much blood has been spilled over products of the mind as of the body. The growing dominance of the Internet metaverse over “the real world” is just the next step in the story of man the myth-making animal.
You do not have to surrender your commitment to facts to participate in an alternate reality. You just have to engage with one, in any way. If you are a user of digital systems, if you allow them to provide you recommendations, if you train them on your preferences, if you respond in any way to the likes, downvotes, re-shares, and comment features they provide, or even if you are only a casual user of these systems but have friends and family and people you follow who are more deeply immersed in them, you are being formatted by them.
You will be assimilated. ♠
← Essay 1. What Happened to Consensus Reality?
Essay 3. How Stewart Made Tucker →
Published online as “Reality Is Just a Game Now,” TheNewAtlantis.com.",1
3,"Tour Amazon’s dream home, where every appliance is also a spy
Here’s everything Amazon learns about your family, your home and you
You may not realize all the ways Amazon is watching you.
No other Big Tech company reaches deeper into domestic life. Two-thirds of Americans who shop on Amazon own at least one of its smart gadgets, according to Consumer Intelligence Research Partners. Amazon now makes (or has acquired) more than two dozen types of domestic devices and services, from the garage to the bathroom.
All devices generate data. But from years of reviewing technology, I’ve learned Amazon collects more data than almost any other company. Amazon says all that personal information helps power an “ambient intelligence” to make your home smart. It’s the Jetsons dream.
But it’s also a surveillance nightmare. Many of Amazon’s products contribute to its detailed profile of you, helping it know you better than you know yourself.
Amazon says it doesn’t “sell” our data, but there aren’t many U.S. laws to restrict how it uses the information. Data that seems useless today could look different tomorrow after it gets reanalyzed, stolen or handed to a government. (Amazon founder Jeff Bezos owns The Washington Post.)
We each have to decide how much of our lives we’re comfortable with one company tracking. Scroll below to see what Amazon’s products and services could reveal about you.
Echo speaker
Among the best-selling speakers in history, Echos respond to the wake word “Alexa” to summon the voice assistant to play music, answer questions, shop and control other devices.
What it knows: Collects audio recordings through an always-on microphone; keeps voice IDs to differentiate users; detects coughs, barks, snores and other sounds; logs music and news consumption; logs smart-home device activity and temperature; detects presence of people though ultrasound.
Why that matters: It counts snores? Yes, if you turn that on. Alexa can hear more than you might realize.
Amazon touts privacy controls like a physical microphone mute button, but when I downloaded my Alexa voice history, I found the Echo had recorded many sensitive conversations after its microphone activated unintentionally. (Amazon says its systems now double check whether you intended to say the wake word and label accidental recordings.)
Only after years of criticism did Amazon add a setting to not keep any audio recordings.
“Providing customers with transparency and control over their information has always been incredibly important to Amazon, and we believe we’ve been very good stewards of peoples’ data,” says spokeswoman Kristy Schmidt.
Ring doorbell
Acquired by Amazon in 2018, Ring doorbells have tiny cameras inside that let you live-stream, record and interact with whomever is at your doorstep — even if you’re not home.
What it knows: Live and recorded video, audio and photos of the outside of your house; when people come and go and you receive packages; status of linked devices like lights.
Why that matters: You’re not the only one who wants to peer through your doorbell. Police have made tens of thousands of requests for Ring video clips, and Amazon has handed footage to police without owners’ permission at least 11 times this year. (Amazon says it reserves the right to respond to emergency police requests when they relate to matters of life and death.)
Ring brought surveillance cameras to millions of more homes, igniting a privacy debate about recording neighbors without permission.
Fire TV or Omni TV set
The streaming devices allow you to watch video from Amazon and other services on any TV. The dedicated Omni TV set also contains microphones to talk to Alexa, displays information, and even springs to life when someone enters the room.
What it knows: What and when you stream on Prime Video; when you open or close third-party streaming apps; records audio for Alexa queries; the Omni TV also records information about what specific programs you watch using an over-the-air antenna.
Why that matters: It can reveal your interests, politics, joys and embarrassments — and it’s easy to forget Amazon is helping your TV watch back.
Kindle or Fire Tablet
They are Amazon’s answer to Apple’s iPad for reading books, using apps or streaming entertainment.
What it knows: What and when you read and watch entertainment and news; when you open, close and how long you use third-party apps; your location.
Why that matters: Amazon knows exactly how fast you read and how far you actually got through your last novel. Kindles and Fire Tablets are another way Amazon gets to know your tastes, which helps it sell you things.
Smart lights, switches or shades integrated with Alexa
Connecting these devices to Alexa allows you to control and automate your home, such as making lights turn off on a schedule, operate by voice or activate automatically when triggered by another sensor or device. Amazon says Alexa can interoperate with over 140,000 products.
What it knows: When and where in your house you turn lights on or off; energy use.
Why that matters: These devices add to a body of seemingly meaningless data that could help Amazon make inferences about daily rituals, power use and more. Amazon says it doesn’t use this data for advertising.
Unlike the privacy settings for Alexa voice recordings, Amazon offers no way to tell it to stop storing data from connected smart-home devices. (You can only set it to auto-delete after 3 or 18 months.) When I downloaded the data Amazon had collected about the third party Alexa-connected devices in my house, it contained more than 600,000 data points since 2019.
“Data enables, improves, and personalizes the features and experiences our customers enjoy,” says Schmidt, the Amazon spokeswoman.
Halo band
A health-tracking bracelet with a microphone and an app that tells you everything that’s wrong with you.
What it knows: Your activity and movement; heart rate; weight; sleep patterns; your voice (for tone analysis); images of your body for estimating body fat; food consumption, preferences and shopping lists.
Why that matters: Amazon wants to be your artificial-intelligence doctor, or, at least, life coach. But the Halo band can be invasive. Amazon says it doesn’t sell your body data, share it without your permission or use it to target you with sales pitches — but that still leaves plenty of other ways for the company to mine your information.
Echo Show
An Alexa smart speaker with a camera and screen for video calls, recipes and sharing family information.
What it knows: Collects most of the data from standard microphone-equipped Echo speakers, along with facial recognition maps for individual users (stored and processed locally); records video of areas in view of the camera; logs how you interact with on-screen widgets and skills; detects smoke alarms, glass-breaking or other activities.
Why that matters: The addition of a camera gives Amazon another view into your home. On some Echo Show models, the camera is always passively scanning for movement or faces, and Amazon could retain records about the faces it sees.
Echo devices also use your life to feed advertising. Researchers recently discovered Amazon uses data from how you interact with Alexa to target ads you see on Amazon and other sites where Amazon places ads. (You can opt out of Amazon ad profiling at this link if you log in.)
“We don’t sell customer data to third parties or use customer data for purposes that haven’t been disclosed to customers,” Schmidt says.
Echo Auto
A small speaker that brings Alexa to the car by tethering to your smartphone for a data connection.
What it knows: Collects most of the data from standard microphone-equipped Echo speakers, along with the location of your car; whom you call with Alexa.
Why that matters: Cars can reveal a lot about their owners, such as where they work, play and shop, and how they drive. Echo Auto gives Amazon the ability to record your car’s location while you’re on the road, and Amazon wouldn’t say how much of that data it keeps.
Garage door with Alexa or Amazon Key integration
The system allows you to open and close your garage door over the internet and share access for package deliveries through Amazon’s Key service.
What it knows: When you open and close the garage door; when you get deliveries.
Why that matters: You’re basically giving Amazon a key to your house and allowing it to know when you come and go.
Eero WiFi router
Another Amazon acquisition, Eero is a mesh-router system that can help ensure coverage gets to every corner of your house.
What it knows: Information about devices connected to your home network; statistics about data usage; performance statistics, including network speeds and internet service provider.
Why that matters: Eero started out as a less-invasive product, but questions linger about how Amazon could make use of information about the devices on your network.
Roomba vacuum cleaner
A vacuum cleaner that automatically roams around your house to clean, which Amazon is acquiring in a still-pending deal for $1.7 billion.
What it knows: Camera identifies obstacles and layout of rooms and furniture; when, how often and where you clean.
Why that matters: When the deal was announced, some Roomba owners balked at the idea that Amazon might gain access to maps of their home, created by the robots to help them clean. Even the vacuum data adds to Amazon’s inferences about your cleaning — and mess. Amazon declined to comment on the Roomba’s data practices because the acquisition has not closed.
Toilet with Alexa integration
The system allows you to create personalized settings for your toilet, including a preferred temperature and ambiance. You can even flush it with your voice.
What it knows: When you flush, or activate a cleansing spray or heated seat.
Why that matters: You can’t get much more intimate than your bathroom time.
Ring camera and spotlight
Online security cameras, some with motion-activated lights.
What it knows: Live and recorded video, audio and photos of outside or inside your house; radar to detect and identify activity; status of linked devices, like lights.
Why that matters: Ring video isn’t just staying inside the home. Amazon recently turned Ring clips into a reality TV comedy show, which frames surveillance as fun.
Ring also keeps records of some of what it learns from your cameras. When I downloaded my Ring data (use this link to download yours), it included more than 25,000 entries for each time its cameras noticed motion outside my home. Ring wouldn’t delete those records without deactivating the entire account.
Ring security system
A network of alarms and sensors that work with Ring cameras and can be connected to a monitoring service to request help from police or other emergency services.
What it knows: When you are home or away; when motion, window and door sensors are activated; your location; status of linked devices, like lights.
Why that matters: For greater security, Ring wants you to collect even more data about your home and its inhabitants. But it offers one nod to privacy: The Ring Alarm Pro version gives you the ability to store and process Ring video locally instead of in Amazon’s remote systems, making it harder for others (including law enforcement) to access the records.
Echo Frames
These glasses, with built-in speakers and a microphone, take voice commands any time, anywhere.
What it knows: Collects most of the data from standard microphone-equipped Echo speakers, collected directly from your face.
Why that matters: Smart glasses raise surveillance concerns, because it isn’t necessarily clear to those around you that the device could be recording them. Amazon says Frames are designed to respond only to queries initiated by the voice of their owner.
Ring Always Home Cam drone
A quadcopter with a camera that flies around the inside of your house to show you what’s going on when you’re not around.
What it knows: Live and recorded video along trained flight paths; layout of house for flight patterns; works with Ring Security System to know when there’s movement inside the house.
Why that matters: A drone brings Ring surveillance inside the home and leaves almost no corner unobserved. Could this device also be a gateway for Amazon to get people more comfortable with the idea of its delivery agents or workers coming inside homes?
Amazon said it would have more information about how its drone works when it launches.
Halo Rise
A bedside lamp that helps people track their sleep cycles and wake up gently with light.
What it knows: Radar reports on the nocturnal activity of the person sleeping closest to it; when you go to bed and wake up; able to interact with other Alexa-operated smart-home devices.
Why that matters: This device doesn’t use a camera or sensor on your body, but it still gathers lots of data about your breathing and movement, and it generates inferences about your wellness from them. Amazon says it doesn’t share this intimate data without your explicit permission, and its employees cannot identify the customers associated with Halo data.
Smart Soap Dispenser
A bottle that automatically dispenses soap, lights up a 20-second timer and can direct an Echo speaker to begin playing songs or jokes while you wash.
What it knows: When you wash your hands through a motion detector.
Why that matters: We don’t know what Amazon could do with data about your personal hygiene. Amazon says it needs the hand-washing data to help provide functionality.
One Medical membership or Amazon Pharmacy
One Medical is a nationwide subscription-based primary care provider that leans into technology for in-person, digital, and virtual care services. It is being acquired by Amazon in a still-pending deal. Amazon Pharmacy allows prescriptions to be shipped to your house, built out of an online pharmacy called PillPack.
What it knows: The services know your medical history, medications and body measurements. Amazon Pharmacy knows when and how often you order drugs.
Why that matters: Your body is the latest frontier for Amazon’s data ambitions. “As required by law, Amazon will never share One Medical customers’ personal health information outside of One Medical for advertising or marketing purposes of other Amazon products and services without clear permission from the customer,” said the company when it announced the acquisition. While your health information is covered by a federal privacy law, tech companies like Amazon are experts at getting around its limitations by convincing people to share their personal data for purposes that aren’t covered by the law.
Dash Smart Shelf
This shelf fits into your pantry and monitors when you’re running low on a particular product, so Amazon can automatically reorder.
What it knows: What products are on your shelf; when you’re running low or completely out of the product; when you’ve bought more.
Why that matters: This is one device where it’s clear why Amazon wants to have the data: to sell you more stuff from Amazon.
Whole Foods
Amazon bought the grocery chain in 2017 for more than $13.7 billion and offers Prime members home grocery delivery.
What it knows: What you purchase and eat, if you enter a Prime membership discount code at checkout; the details of your hand used for palm payment verification in some stores.
Why that matters: Your grocery purchases give Amazon insight into your lifestyle, which Amazon says it uses to make product recommendations.
Smart Air Quality monitor
The system measures five key areas of air quality and can automatically turn on a nearby fan or a purifier if the air quality drops.
What it knows: Sensor readings about particulate matter, volatile organic compounds, carbon monoxide, humidity and temperature stored for 30 days.
Why that matters: Amazon even knows about the air that you breathe, although it says it doesn’t use that data for advertising.
Basics Microwave
It’s a microwave that connects to WiFi, so you can heat up your food by asking Alexa to do it with the right settings.
What it knows: What and how long you’re cooking, if it’s operated through Alexa; how much popcorn you eat with an automatic reorder service.
Why that matters: The upside: You don’t have to look up how long to cook a potato. The downside: Amazon will now have a record of every time a family with this microwave cooks a potato.
Smart Thermostat
The device allows you to set up programs to optimize energy use and control your heater or air conditioner from afar.
What it knows: Home temperature; “hunches” about when you’re home, away or asleep; energy use.
Why that matters: The small data points can look meaningless, but they add up to a picture of your daily routines.
Astro robot
A domestic robot that uses cameras and other sensors to navigate your house (but doesn’t vacuum).
What it knows: Live and recorded video inside your house through a periscope camera on autonomous and directed patrols; layout of house; sound triggers, such as glass breaking or smoke alarms; presence and faces of people (through a visual ID processed on device); audio recordings of Alexa queries.
Why that matters: Robots look cute, but Astro is the culmination of Amazon’s surveillance capabilities. Astro recently gained the ability to be controlled by remote security guards for monitoring and even responding to situations. Nobody ever thought of Rosie the robot on Jetsons as a security guard, but so far, that’s Amazon’s most persuasive use for a domestic robot.",6
4,"TAIPEI, Taiwan — An infusion of cash from a Taiwanese semiconductor magnate is helping fund new cyber defense training for Taiwanese citizens.
Why it matters: The goal is to fight online disinformation and hybrid warfare that could accompany a potential Chinese military assault on the self-governed island democracy.
What's happening: Taiwanese tech tycoon Robert Tsao recently pledged approximately $20 million in funding for Kuma Academy, a company founded last year to help Taiwanese people prepare for a potential Chinese invasion.
- The academy plans to provide civilian military training for three million people over the next three years.
- Part of the training includes basic courses in identifying and publicly debunking online disinformation, and the academy plans to launch advanced courses on open-source intelligence gathering (OSINT) taught by volunteer hacking groups.
Details: OSINT can include using publicly available satellite images to track troop movements, analyzing databases, and assessing social media posts from people claiming to have witnessed important events.
- Using OSINT isn't that popular in Taiwan despite the many hacking groups operating on the island, Puma Shen, co-founder of Kuma Academy, said in an interview after training sessions held this month in Taipei.
- ""Even with all these hackers, if they are voluntarily doing something during the war, it won’t be enough,"" Shen said, referring to a potential future war with China. ""We want to expand.""
- Shen plans to train participants in how to tailor general OSINT practices for a Taiwanese context — such as compiling lists of words typically used by netizens in Taiwan but not in China, which could help determine the identity of social media users posting information while claiming to be Taiwanese.
- The classes also teach participants to debunk fake news and identify Chinese military uniforms and weapons, knowledge that can be useful for distinguishing between true and false informati0n posted online in a wartime environment.
The big picture: The classes aim to foster a sense of hope among Taiwanese people by showing them how they can play a part in the national defense, and by pointing out the limitations China faces if it were to attempt an invasion, the co-founders said.
- In his presentation, Ho Cheng-hui, also a Kuma Academy co-founder, sought to push back against the common belief in Taiwan that if China were to invade, Taiwan would have no choice but to surrender immediately.
- Ho explained the difficulty of amphibious assault, the struggles Chinese troops on Taiwan would face in their supply lines across the Taiwan Strait, and shared historical examples of smaller countries successfully repelling invaders from a much larger country.
The information battlefield has featured prominently in the Russian invasion of Ukraine, and a growing number of people in Taiwan are studying Ukrainian resistance tactics.
- Russian-affiliated media, online groups, and organizations have spread propaganda and targeted disinformation intended to weaken the wills and disrupt the decision-making processes of Ukraine and its allies.
- Ukrainian citizens, as well as groups and individuals from around the world, have worked together to fight Russian online disinformation, including through using OSINT to track military maneuvers and gather evidence about alleged war crimes.
What they're saying: Rumors can “destroy our will to resist,"" Ho said during the class.
- ""War is, at its most basic nature, a contest of wills,"" Ho said. ""The two sides use a variety of methods to try to force the other to obey its will. Armed conflict is only one form of modern warfare.""
Go deeper: Taiwanese seek civil defense training after Russia's invasion of Ukraine",1
5,"It seems likely that we are in a renaissance for futures thinking. There is more genuine interest, widespread and general, in futures and foresight work than at any point during the ten-plus years in which I’ve had direct experience in the field. No doubt the volatility and uncertainty over the past two-plus years, through COVID and a myriad of other unpredictable — but not unimaginable — events has had an impact on the perspectives of decision-makers.
This newfound interest in foresight is a positive development but it brings with it a core challenge, especially for those undertaking foresight projects with little past experience, which is when and how to actually use foresight.
As foresight practitioners, we must consider how and when to best use foresight, so as not to — in our well-intentioned push to incorporate foresight into our work and decision-making — create a mismatch in what organizations want vs. what they need; in what their expectations are vs. what we can accomplish; and what their ambitions are vs. what they can actually accept. Intentional or not, foresight projects are often asked to do things they cannot or should not do, leading to projects that fall flat or “fail.” The resulting skepticism about futures thinking as a whole does more harm than good; thus where and how we decide to deploy foresight is equally important to the work we do.
Or more simply, while all strategic projects should somehow be infused with foresight, not all projects need to be foresight projects.
What exactly does this mean, in practice? How do we address those mismatches that we can unwittingly create? How do we more effectively deploy foresight where it can make the greatest difference?
For me, I like to start by addressing those potential mismatches head on anytime I’m scoping a project out. I ask: “What is the actual impact we can make? What decisions are we hoping to influence – if any? What outcomes are aspirational, and what outcomes are necessary?” Being painfully realistic about these answers is key, especially when our stakeholders may not have the experience needed to properly set expectations.
For us as practitioners, these answers will help us to properly scope our projects. We need to remain hyper-focused on the influence the project should have, if we want to ensure that our foresight work is effective, impactful, and successful. Although it’s wonderful when projects can be scoped to cover everything in one go, in reality that is fairly rare. More commonly, projects have limited budgets, limited scope, and if we’re honest, limited impact. It’s incumbent on us to make sure that we adjust our work and efforts to realistically maximize the impact we can have – which means focusing our projects more tightly.
So, How Do We Decide What to Do?
One way I like to think about how to differentiate between types of projects is to consider if the work will be centered around content, or around capacity. In other words, will the creation and sharing of foresight content be what drives the project forward and help define success, or will the capacity of teams to utilize foresight in order to drive strategy and tactics be central to success?
In the Institute’s Prepare-Foresight-Insight-Action cycle (see below), this roughly corresponds to a break between the top of the circle and the bottom of the circle. Content projects will focus more on the Prepare and Foresight parts of the cycle, while Capacity projects will require more time in Insight and Action.
Centering Content
In the first case of centering around content, the bulk of effort in a project should go towards crafting plausible and provocative forecasts. Obviously, there will be a lot of time and effort allocated towards developing scenarios, narratives, forces, or other forms of forecasts that will inspire people to think differently. But equally importantly, because the foresight developed will need to survive scrutiny and skepticism, these projects will require sufficient effort to gather the building blocks that underpin your foresight – doing the horizon scanning, expert interviews and workshops, and primary research (when applicable).
It also means putting in the time to adequately prepare your team and stakeholders to engage with your foresight. Exercises like “Look Back to Look Forward” or “Frame Future Conversations,” from the IFTF Foresight Essentials Toolkit, can be great ways to bring stakeholders along without requiring too much time investment.
For content projects, the end deliverables will often take the form of some sort of share-out or experience built around your foresight. At the Institute, many of our past Maps of the Decade are great examples of what a content-centric project looks like.
A more immersive example, complete with physical experiences in the real world, can be seen in the Hawaii in 2050 project by Dr. Jake Dunagan and Dr. Stuart Candy.
Centering Capacity
In the second case of centering around capacity, the value does not come from the foresight content as much as it does from the ability of your team to harness the insights and provocations that come from foresight. In other words, these projects are focused on building or tapping into an organization’s capacity to utilize foresight to promote transformative action.
In practice, this often means that while these projects will take foresight as inputs into workshops, strategy meetings, or planning sessions, the bar for foresight is lower than in a content project. I would argue that in these projects, “good enough” foresight is good enough. Instead, the important work is to help stakeholders internalize lessons from that foresight, challenge their existing assumptions, and more confidently make decisions with a long-term perspective in place. Investment into creating the space needed to bring teams together, foster collective exploration and immersion, and have the conversations that can yield insights and realizations is critical.
Although it is harder to point to public examples of this type of work, it is not hard to describe. Consider innovation-focused projects where facilitators are putting foresight inputs in front of non-foresight practitioners and asking them to find new whitespaces or business models to consider. Or an organizational strategy project that is considering how to structure a company for the future of work. These could both be more “capacity-centric” projects where foresight is a key input, but participants might not have practical experience with foresight content.
***
There is a lot that goes into scoping a foresight project well. Not only are there many types of foresight projects, there are many approaches. Thinking through where the center of gravity for your project should be — content or capacity — can be a good starting point as you begin to plot out your efforts and hone in on the activities that will result in the greatest impact. In the end, it’s worth the time and effort. Not only will a well-scoped project be more likely to succeed, it will be more likely to build goodwill and confidence throughout the organization for the type of work that we want to do. Remember, building a futures thinking mindset takes time. We can’t rush it, nor should we.
Want to receive free tips, tools, and advice for your foresight practice from the world's leading futures organization? Subscribe to the IFTF Foresight Essentials newsletter to get monthly updates delivered straight to your inbox.
Ready to become a professional futurist? Learn future-ready skills by enrolling in an IFTF Foresight Essentials training based on 50+ years of time-tested and proven foresight tools and methods today. Learn more ».",2
6,"Engineers have raised concerns about the impact of business secretary Jacob Rees-Mogg’s plans to switch to imperial measurements for buying goods.
The proposals have survived from the early Brexit days and would see all products purchased within the UK measured using the imperial system of pints, pounds and miles.
However engineers are concerned about the potential implications of the plans.
Arup director of infrastructure design Tim Chapman said: “I’m not a fan of the switch back. If you’re a carpenter in the 16th century and not that literate, yes imperial measurements are easier to use for measuring halves and quarters but now with the complex systems civil engineers use, the metric system is a lot more efficient.
“Using your thumb to measure is not necessarily what is needed right now.”
Chapman emphasised that the industry currently relies on a large number of complex digital systems to operate at the current capacity. These would all have to be completely rewritten which would take time and cost a lot of money.
He added: “Everything would need to be redone which would be involve a huge amount of rewriting systems. Software at the moment is globalised, but we would be producing these for one market covering the UK (and US).”
National Highways has confirmed that if imperial measurements do become UK standard, a number of its systems will have to be altered.
A spokesperson said: “At present, the Design Manual for Roads and Bridges (DMRB) and the Manual of Contract Documents for Highways Works (MCHW) uses metric units in accordance with current UK legislation.
“If changes to the legislation relating to measurement is made then, National Highways will amend the DMRB and MCHW in line with the legislative changes.”
If the change does go ahead, which seems possible judging by a recent ministers’ poll which didn’t have an option to vote against the switch, the units for measurement will be inches, feet and miles; volume, pints, quarts and gallons; and weight, ounces, pounds and stone.
A recent Institution of Civil Engineers update co-authored by Chapman and David Hirst, founder and director of Ainsty Risk Consulting, cautioned against the switch due to how the reintegration of systems could cause errors.
Chapman said: “We don’t want to induce a new set source of mistakes, designing a bridge or a skyscraper, there’s lots of detail in there.
“When I was younger and designing piles we didn’t have PCs. Every pile got a human eye over it, that doesn’t exist now but we have a huge amount of sophisticated systems where all the factors would change.”
Where units are concerned ""consistency is key"" Chapman and Hirst emphasise, and further worries include how a switch could hinder future projects that involve an entire work force used to working in the International System of Units.
University of Kent mechanical engineering lecturer and ex-research associate on the subject for the University of Cambridge Dr Philipp Seiler said: “The moment you’re consistent you’re fine but we’ve used the metric system for so long now. It would be a mess if we changed it.
“We would lose a lot of intuition in the industry and there will be a big impact but you like to think it shouldn’t impact the results at all. I only worry that a change now could lead to errors and delayed projects with higher costs.”
Currently only three countries continue to use imperial units, the USA, Liberia and Myanmar. Seiler believes a switch could damage the UK industry’s trade with the rest of the world, particularly since these three countries often use metric for trading purposes.
He said: “[The change] would have a big effect on our trade with the world and imports and exports. All US companies importing to the UK would use metric units anyway by now.”
Like what you've read? To receive New Civil Engineer's daily and weekly newsletters click here.
The idea of changing back to Imperial units is ludicrous, for all the reasons outlined in the article, and more. Political doctrine and dogma have no place here, as politicians do not, who have little or no inkling of what is entailed in engineering and science. One would have thought that they would have rational advisors!
There are units and measure in energy, force, pressure, momentum, power etc. that are not simple expressions of pints and pounds (whether that’s lb or lbf!).
When we design, we usually have a good ‘feel’ for the range of numbers in which a particular value must lie. This makes it easier for us to spot errors. Unfamiliarity – I’m going uphill to 70 years of age, and I barely remember Imperial – will make errors more frequent. And we all make them. The process of managing conversion of units in Imperial is more complicated than with a rational system like SI – that alone will make errors more frequent.
The relationship to the USA is mentioned – so that’s another confusion because not all similarly named US units are, in fact, equivalent. Volume, for example, survey feet, long/short tons…
Just remember what happened to the Mars Climate Orbiter. As my young granddaughter shouted stupid, stupid, stupid!
It’s so ridiculous that we should not expend effort explaining that.
Moving from a rational system to an irrational one for dogmatic reasons is lunacy. The ICE and all other similar professional institutions need to make this clear to Government in the strongest terms.
This stupid idea of changing to Imperial units must be stopped. Clearly the politicians have no idea of what complications would ensue.
The consultation concluded on the 26th August. hopefully everybody took part
Another wonderful idea from the current government to bring the UK back to the glory days of the 19th century. The only problem is the rest of the world will be operating in the 21st century. I have recently had the experience of moving from Northern Ireland to a British overseas territory where there is a weird hybrid system of metric/imperial units and it feels anachronistic to say the least – you definitely lose your ‘feel’ for what is correct that develops from years of experience.
Speaking as an American forced to live in a retarded backwater, this saddens and frustrates me that the rest of global humanity has discovered the merits of metric units and I am forced to use the garbage foisted upon us by the very empire that is working on distancing itself from the arcane and anachronistic. Please global brothers and sisters, refuse to trade with the US until we’re forced to move forward.
It’s the most ridiculous proposal from a government that has not been short of ridicule. I half expect they will do a Putin on the consultation and claim 99.5% support for their idea!
Can’t believe all the whining remoaners commenting. Didn’t you watch the news in 2016? We voted LEAVE, so all you so-called ‘experts’ can shove your millimetres where the sun will never shine! We’re using inches from now on like the people decided and if you don’t like it then move to Germany, you traitors.
It’s ludicrous. It wouldn’t be compulsory to change anyway, so we won’t. What a waste of article space.
I am now retired, but I used the metric system through my career, but would make the observation that in construction details you can find echoes of the old imperial measurements. The standard bar spacings used in detailing are really just metric equivalents in 25mm (~= 1 inch) multiples.
A large number of the standard steel sections are really just a metricated (or should that be ‘footricated’) version of the original imperial sections e.g. 254x102UB. I began work in the mid70s, where I discovered on site that a lot of products were just nominally metric, were in fact just dimensions rounded to the nearest metric equivalent. The discovery that what were described as 600mm formwork panels were actually 24 inches wide still sticks in my memory. Trying to fit them into a metric space doesn’t really work! I would also comment that many F.E. analysis systems are ‘unit agnostic’ it is up to the user to ensure a consistent set of units are in use.",2
7,"At Amazon, we want to make it dramatically easier for people to get and stay healthy. We’ve begun that journey with Amazon Pharmacy—where customers can get their medication delivered to their door conveniently—in just two days for Prime Members. We’ve also entered into an agreement to acquire One Medical, a human-centered and technology-powered provider of primary care. One Medical members benefit from a dedicated relationship with their provider, a friendly and convenient in-office experience, and ongoing engagement via a dedicated app.
Amazon Pharmacy and One Medical (once the deal closes) are two key ways we’re working to make care more convenient and accessible. But we also know that sometimes you just need a quick interaction with a clinician for a common health concern that can be easily addressed virtually. We’ve thought hard about how to improve this part of the experience as well. That’s why today we’re also introducing Amazon Clinic, a message-based virtual care service that connects customers with affordable virtual care options when and how they need it—at home, after dinner, at the grocery store, or on the go—for more than 20 common health conditions, such as allergies, acne, and hair loss.
We believe that improving both the occasional and ongoing engagement experience is necessary to making care dramatically better. We also believe that customers should have the agency to choose what works best for them. Amazon Clinic is just one of the ways we’re working to empower people to take control of their health by providing access to convenient, affordable care in partnership with trusted providers. Our new health care store lets customers choose from a network of leading telehealth providers based on their preferences. Every telehealth provider on Amazon Clinic has gone through rigorous clinical quality and customer experience evaluations by Amazon’s clinical leadership team.
Amazon Clinic is simple and easy to use. To get started, customers select their condition, then choose their preferred provider from a list of licensed and qualified telehealth providers. Next, they complete a short intake questionnaire. Customers and clinicians then directly connect through a secure message-based portal, giving customers the flexibility to message their clinician when it’s most convenient for them—anytime, anywhere. After the message-based consultation, the clinician will send a personalized treatment plan via the portal, including any necessary prescriptions to the customer’s preferred pharmacy.
Virtual care isn’t right for every problem—and if we think that may be the case, we will let you know upfront, before you connect with a provider. Our goal is to make sure you get the care that’s right for you.
For customers, the cost of consultations will vary by provider and includes ongoing follow-up messages with their clinician for up to two weeks after the initial consultation. Amazon Clinic does not yet accept insurance. If a prescription is part of treatment, Amazon Clinic customers may select any pharmacy to fill it, including Amazon Pharmacy, Amazon’s full-service online pharmacy that offers 24/7 access to pharmacists and fast, free delivery of prescription medications. Similar to a traditional doctor’s visit, the cost of any medication prescribed is not included in the cost of the visit, but customers may use their insurance to pay for medications.
Initially available in 32 states, Amazon Clinic is a convenient virtual care option that offers up-front pricing, and treatment within hours, instead of days—helping customers achieve better health. Welcome to easy-to-use, effective care for common health conditions. Visit Amazon Clinic to see a full list of available conditions for treatment and to find out if Amazon Clinic is available in your area.
- What is Amazon Clinic?Amazon Clinic operates as a virtual health storefront, bringing together clinical offerings from national, award-winning telehealth providers. Customers can select the third-party telehealth provider that best meets their timeline and budget, then connect directly with a licensed clinician who can provide a message-based consultation and prescribe treatment.
- What are the conditions Amazon Clinic will treat?Amazon Clinic will focus on common conditions that are effectively treated using virtual care, including: acne, asthma refills, birth control, cold sores, conjunctivitis, dandruff, eczema, erectile dysfunction, eyelash growth, genital herpes, gastroesophageal reflux disease (GERD), hyperlipidemia refills, hypertension refills, hypothyroidism refills, men's hair loss, migraines, motion sickness, rosacea, seasonal allergies, sinusitis, smoking cessation, urinary tract infections (UTIs), and yeast infections. Over time, we’ll continue working to offer Amazon Clinic support for other conditions.
- Will you be expanding to more states?Yes, we hope to expand Amazon Clinic to additional states over the coming months.
- How will Amazon Clinic use my health information?We care deeply about customer privacy and data security. We have extensive experience protecting data of all kinds appropriately across a variety of businesses and remain focused on the important mission of protecting customers’ health information. We have stringent customer privacy policies and comply with HIPAA and all other applicable laws and regulations.
- How do customers pay for the treatments? How much does it cost? Do you accept insurance?When customers seek treatment, they will be able to see how much a consultation will cost and when they may connect with the provider. These prices are set by the providers, not Amazon Clinic. Consultations include ongoing follow-up messages for customers with their clinician for up to two weeks after the initial consultation. In many cases, the cost of care is equivalent or less than the average copay. At this time, Amazon Clinic does not accept insurance, but is FSA and HSA eligible. Customers may be able to use their insurance for any prescription medication costs that result from their Amazon Clinic visit.",6
8,"On Wednesday, Tesla announced that it is dropping yet another set of sensors from its electric vehicles. The latest casualty? Ultrasonic sensors, usually found embedded in the bumpers, that allow for assisted parking features.
At first, it will just be the Models 3 and Y that rely solely on cameras for the entire array of driver assists that Tesla offers. However, the automaker says that after rolling out this change globally, it will then do the same for the Models S and X in 2023.
Tesla says that despite dropping radar from its adaptive cruise control and automatic emergency braking functions—which now rely solely on cameras—its vehicles ""have either maintained or improved their active safety ratings in the US and Europe and perform better in pedestrian automatic emergency braking (AEB) intervention.""
However, the automaker elides the fact that its removal of radar from its EVs has resulted in an ongoing National Highway Traffic Safety Administration investigation into hundreds of cases of phantom braking—in effect, false-positive activations of the cars' automatic emergency braking system.
Tesla says that its systems will improve in performance over time and that Models 3 and Y that arrive without the ultrasonic sensors will not be capable of parking assist, autopark, summon, or smart summon. Tesla claims that these functions will be restored once its vision-only system has achieved parity with the old ultrasonic sensors.
You must login or create an account to comment.",2
9,"Trial
Try full digital access and see why over 1 million readers subscribe to the FT
1 € for 4 weeks
Then 65 € per month
New customers only
Cancel anytime during your trial
- For 4 weeks receive unlimited Premium digital access to the FT's trusted, award-winning business news
Digital
Be informed with the essential
news and opinion
news and opinion
39 € per month
OR
345 € for 1 year
BEST VALUE - SAVE 20%
- MyFT – track the topics most important to you
- FT Weekend – full access to the weekend content
- Mobile & Tablet Apps – download to read on the go
- Gift Article – share up to 10 articles a month with family, friends and colleagues
FT print edition delivered Monday - Saturday along with ePaper access
101,08 € for 3 months
INTRODUCTORY OFFER
INTRODUCTORY OFFER
Then 135,46 € every 3 months
- Delivery to your home or office Monday to Saturday
- FT Weekend paper – a stimulating blend of news and lifestyle features
- ePaper access – the digital replica of the printed newspaper
Team or Enterprise
Premium FT.com access for multiple users, with integrations & admin tools
Pay based on use
Group Subscription
Premium Digital access, plus:
- Convenient access for groups of users
- Integration with third party platforms and CRM systems
- Usage based pricing and volume discounts for multiple users
- Subscription management tools and usage reporting
- SAML-based single sign-on (SSO)
- Dedicated account and customer success teams",5
10,"Cybathlon 2020: More than just a competition
On 2 - 3 May 2020, Zurich opens its doors for the second Cybathlon. In this unique championship, individuals with a disability, assisted by cutting-edge technology, come to terms with the challenges of everyday life. Over 90 teams from around the world are battling it out in six disciplines. Swiss radio and television will broadcast the race finals across the nation.
Widespread interest sparked by the premiere in 2016 (over 4,500 spectators and some 150 media representatives from around the world) called for this year’s Cybathlon to run over two days. Lining up in May are over 90 international teams – a third more than last time. What unites them is a mission to push technical assistive devices to the next level, so that people with disabilities can participate more fully in society.
“Despite striking advances in assistive technology in recent decades, only a few devices are suitable for everyday use today”, explains Robert Riener, Professor of Sensorimotor Systems at ETH Zurich and Initiator of the Cybathlon. “The goal here is to create not the most complex devices, but the most useful ones”.
Six disciplines with fresh challenges
The Cybathlon challenges are geared to everyday activities that many people with disabilities find hard to master. Tying shoelaces, negotiating uneven terrain, opening a bottle, sitting down and getting up again – these are just some of the tasks that competitors in the 2020 event must tackle. On the programme again are the six disciplines – the Brain-Computer Interface Race, Functional Electrical Stimulation Bike Race, Powered Arm Prosthesis Race, Powered Leg Prosthesis Race, Powered Exoskeleton Race and Powered Wheelchair Race – but since 2016 these have been fine-tuned, with input from the users of assistive devices.
The Bike Race, for example, calls for even more efficiency, as the distance to be covered in a set time has been increased. The new Haptic Box task requires Cybathlon pilots with arm prostheses to identify objects only by touch. Meanwhile, competitors in the Powered Wheelchair Race must now exercise precise control of a technical device, such as a robotic arm, for opening and closing a door.
More than 90 teams from some 30 countries
For months now, over 90 teams from all six continents have been getting set for the event – with universities, industry, NGOs and people with disabilities working closely together on a variety of innovative solutions. This year, the United Kingdom is represented by as many as ten teams; one of these is the team from Imperial College in London, who have created a semi-autonomous wheelchair steered by eye movements. Six teams from the USA are taking part, including Team Cleveland, the 2016 gold medal winner in the Functional Electrical Stimulation Bike Race. Asia is represented by over 20 teams. Touch Hand from South Africa is the only team from the African continent this year; the team will compete in the Powered Arm Prosthesis Race.
“The participation of teams from all over the world shows that the Cybathlon has become an event with a global reach. The Cybathlon promotes international cooperation and playful competition in a highly socially relevant area,” says Joël Mesot, President of ETH Zurich.
Strong Swiss presence
Switzerland is represented in all six disciplines, with 11 teams in total. Four of these teams are from the ETH Zurich domain: ETH spin-off external pageScewocall_made is competing in the Powered Wheelchair Race, while external pageVarileg Enhancedcall_made is putting to the test an exoskeleton developed together with the University of Applied Sciences Rapperswil (HSR). Two ETH Zurich research teams will also be in the line-up – one for the Powered Leg Prosthesis Race, and the other for the Brain-Computer Interface Race, in a joint endeavour with Nanyang University of Technology, Singapore.
The Cybathlon is made possible by the generous support of various partners.
Cybathlon 2020 for the Media
Cybathlon 2020 media accreditation is now open! Please sign up online to register for the 2020 event in the SWISS Arena in Kloten, near Zurich. Due to the great demand, registrations will be checked and confirmed individually.
You’ll find the competition programme and more about the Cybathlon, teams and disciplines online. A selection of photos and videos from Cybathlon 2016 are available at the following link.
Follow the Cybathlon on social media; take part in the discussion under the hashtag #CYBATHLON2020.
Podcast ""Steering a car with thought""internal page chevron_right Cybathlon-Pilot Samuel Kunz
Further informationinternal page chevron_right Website Cybathlon
CYBATHLON 2020 will take place on 13 – 14 November 2020 – globally and in a new format. Further information",8
11,"almost everything from the outside world now comes to us through our web browsers. we see it, we forget it, but sometimes it leaves an impression. what would it be like if we could recall it at any time, just as we saw it?
even though the web is constantly changing, even though web pages and entire hosting sites disappear, you still get to keep what you saw with irchiver. seeing is keeping
irchiver aims to be your backup memory. just like how the internet has changed the way we think about knowledge, does having our memory on-demand change how we remember? irchiver is a long-term research project to study this question
the irchiver software is available for free, and it currently runs only on Windows 8.1 or higher (but it has only been tested on Windows 10) with five popular web browsers: Chrome, Firefox, Edge, Brave, and Opera
MacOS is not supported, but may be possible with a browser extension that mirrors to a Windows computer; no development is planned for MacOS due to limited developer time and expertise, and the inherent challenges of finding techniques for cross-process window access that continue working long-term
irchiver does not use any network connectivity for your privacy. why would you want your browsing data stored on the cloud? irchiver saves your screenshots as webp files (and png files temporarily), and the text content in a plain text file, in a folder on your hard drive. you can view it using any file explorer, and do whatever you want with it
|product||when captured||stored||format||reproduction||platform|
|irchiver||continuous, automatic||local||image, text||what you saw||Windows, any browser|
|archive.org||occasional, automatic||cloud||webpage||only public view||web|
|archive.ph||manually initiated||cloud||webpage||only public view||web|
|ArchiveBox||manually initiated||local||webpage||only public view||any desktop|
|WebRecorder||manually initiated||local||webpage||what you scroll||Chrome|
|taking a screenshot||manually initiated||local||image||what you saw||any desktop|
|browser extensions||manually initiated||local||varies||varies||varies|
|browser ""Save as PDF""||manually initiated||local||nearly what you saw||most browsers|
irchiver is the only way to reproduce what you actually saw with continuous automatic capture. other products either require manually initiating a capture each time, or can only capture stateless publicly-accessible pages. irchiver saves captures as images and plain text, as historically those formats have outlasted software code and cloud services
this is the current roadmap for irchiver as of 2021-12-02, but to hear about releases, please subscribe to be notified about updates
version 0.2: 2x more efficient (cpu/memory performance-wise), while consuming 2x less space on disk; enable archiving options that are currently inactive in the context menu
version 0.3: better installer and more install options; notification tray icon indicator during capture; an additional 2x more efficient (cpu/memory performance-wise), and further reduction in space usage
version 0.4: API with support for python extensions/plugins, for example: automatic scrapbooks, highlight page changes, etc.; an additional 2x more efficient (cpu/memory performance-wise)
version 0.5: better search interface and a by-date browsing interface; partial-match text search; better text recognition in images (e.g. infographics, webcomics)
irchiver is licensed to you under the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license, with the additional condition that it can only be used with the enthusiastic consent of the person using a computer it is installed on
while the indexer and search interface are open source, irchiver's capture software is not open source in the traditional meaning of the term, but rather it's source-verifiable, where you can watch the main executable file being created and the SHA-256 hash generated for the executable so that you know the distributed executable is from the source code seen in the video
the capture software is not open source to make it harder to deploy the software without the user's knowledge, which can be done by modifying the source code to hide the notification tray icon and thus rendering the automatic background capture completely invisible
feel free to email me to request the capture software source code with an explanation what it will be used for and how it will be distributed, or for requests for other licenses",3
12,"New AI tools let you chat with your dead relatives
Creepy or cool? New products that let people keep relatives ""alive"" via AI are proliferating — offering, say, an interactive conversation with a recently departed dad who took the time to record a video interview before he passed.
Why it matters: As interest in genealogy and ancestry proliferates, these tools let families preserve memories and personal connections through generations — even giving children a sense of the physical presence of a relative who died before they were born.
- The tools are also being used to record the memories of noteworthy people: celebrities, Holocaust survivors, etc.
One such tool, StoryFile, was notably used at the late actor Ed Asner's memorial service, where mourners were invited to ""converse"" with the deceased at an interactive display that featured video and audio he recorded over several days before he died.
- ""Nothing could prepare me for what I was going to witness when I saw it,"" Matt Asner, the actor's son, told Axios.
- The ""Lou Grant"" actor had used StoryFile to record an oral history; the product then employs AI to enable ""conversations"" based on subjects' answers to myriad questions.
At Asner's memorial, ""many people just stopped by and asked a question or a couple questions,"" including Jason Alexander of ""Seinfeld"" fame, said Matt Asner, a TV and movie producer who now runs the Ed Asner Family Center, a nonprofit for people with special needs.
- ""Actually, you can't just ask one question,"" he observed. ""That's the great thing about it, is it draws you in — because the personality is there.""
- Ed Asner, a former head of the Screen Actors Guild, had ""covered everything — his childhood, work history, political history, family life,"" his son said.
- While a few mourners were ""a little creeped out by it,"" the conversational video was ""like having him in the room,"" Matt Asner said. ""The great majority of people were just blown away by it.""
The big picture: StoryFile is perhaps the most robust of a growing number of tools that help people create interactive digital memories of relatives. Many of them don't require the relative to be alive during setup.
- Amazon recently showed off an experimental Alexa feature that can read books aloud in the voice of a late relative, extrapolating from a snippet of that person's recorded voice.
- MyHeritage, the ancestry-tracing site, now offers ""Deep Nostalgia,"" a tool for animating old-timey photographs of your relatives.
- HereAfter AI lets you record stories about yourself and pair them with photographs — so family members can ask you about your life and experiences.
- Microsoft has obtained a patent to create ""chatbots"" that mimic individual people (dead or alive) based on their social media posts and text messages, per the Washington Post.
How it works: With StoryFile, a user sits for a video interview and answers a series of questions.
- The company produces an archive that can be watched sequentially or used in a Q&A format.
- When a question is asked, the AI technology retrieves relevant video content to create an answer, picking out clips from the available footage.
The company was co-founded by oral historian Stephen Smith, who used to run Steven Spielberg's Shoah Foundation and specializes in preserving the memories of Holocaust survivors.
- ""In its most optimal state, the idea of StoryFile is you should be able to speak to anyone, anytime, anywhere that you wouldn’t normally have access to,"" Smith tells Axios.
- ""Maybe you don’t have access to grandma because she’s passed away, but you can still learn her story, feel a sense of connection to her.""
- StoryFile is also building an archive of public figures who have sat for interviews. (Try asking a question of very-much-alive William Shatner.)
Between the lines: These types of programs are already growing familiar through deepfakes, science fiction, and rock concerts that use holograms to bring back dead performers like Buddy Holly.
- In the Netflix series ""Black Mirror,"" a woman converses with a chatbot version of her late fiancé — and a grieving Canadian man did something similar with his dead girlfriend in real life, the San Fransisco Chronicle reports.
- Other examples: Carrie Fisher being brought back to life as Princess Leia; chef Anthony Bourdain's AI voice being used to narrate a posthumous documentary about himself.
What they're saying: ""When we learn about some very sophisticated use of AI to copy a real person, such as in the documentary about Anthony Bourdain, we tend to extrapolate from that situation that AI is much better than it really is,"" said Amit Roy-Chowdhury, who chairs the robotics department at the University of California, Riverside.
- ""They were only able to do that with Bourdain because there are so many recordings of him in a variety of situations.""
- ""In the future, we will probably be able to design AI that responds in a human-like way to new situations, but we don’t know how long this will take.""
The bottom line: These kinds of memory-preservation programs ""might change the way we collect history,"" as Smith put it.
- ""We all have amazing stories to tell, and one of the big discoveries I’ve had in founding this company is how few of us truly understand the importance of our own story,"" he said. ""We’re quite self-deprecating.""",3
13,"Alex Vuocolo is a journalist based in New York.
The R32 trains, nicknamed the Brightliners for their shiny unpainted exteriors, were built to last 35 years. (Imagine that: Your lifespan stamped into metal, your death prefigured.) When they were finally retired from service in January, they had been riding the rails of New York City for no less than 58 years and were, by most accounts, the oldest operating subway cars in the world. That’s 23 unplanned years of hauling people across New York. A whole generation got to see those stainless-steel beauties creaking down the tunnel to the platform, with their crinkle-ridged exteriors and back-lit advertisements.
In a way, it was a small miracle that they lasted so long, an “anomaly,” as one mechanic told me. Except it wasn’t really. It took a lot of work from a lot of people, day after day, year after year.
I recently went to talk to some of those responsible for that work at the MTA maintenance facility in Corona, Queens. There are 13 of these huge workshops across the city, scattered from Coney Island to the banks of Westchester Creek in the Bronx. This one is in a remote pocket of the city, an area given over mostly to massive buildings and spaces: Citi Field, Flushing Meadows Park, the sprawling train yard. It’s like a hospital but an industrial one, scaled up to care for its multi-ton patients.
Standing around the break room with their arms crossed and ID badges dangling, heads full of train-talk, several maintenance workers took turns explaining the process: Railcars roll off the main tracks into a long rectangular building. The cars are lifted to eye level, inspected and repaired if needed. Most of them get to leave that day — back to work, like the rest of us. But some are moved over to a special track for trickier jobs.
We went for a walk along the service tracks in a big group, everyone chiming in, pointing to the parts that needed repairs or replacing: the truck, the brakes, the AC units. They told me the fleet is split into two camps, one called “legacy,” the other “millennial.” The former were built before 2000, the latter after. The millennial fleet is tougher to repair in some ways because there are more electronics in the cars. Maybe you’ve heard your grandfather complain about this, how engines are too damn complicated these days. Siu Ling Ko, a chief mechanical officer for the train cars, told me the shells may last 40 years. The electronics, though, not so much.
The legacy fleet has its own problems, of course, and is more prone to failures overall. Replacement parts are harder to find; the firms that made them — the Budd Company, Pullman-Standard and Westinghouse — are long gone. Many components are well past their design life, and mechanics have to pluck similar parts from retired vehicles or engineer substitutes. It’s a very ad-hoc, improvisational process that relies on the know-how that long-time employees build up over years.
But there’s a method to the madness, and a hard-earned one. Back in the 1980s, when the crumbling, graffiti-covered subway was the stuff of reactionary urban nightmares, MTA president David L. Gunn kicked off an ambitious overhaul of the system, including capital improvements, the famous graffiti removal program and more routine repairs. In 1990, this approach solidified as the scheduled maintenance system. Now, every two to three months, more than 7,000 railcars are taken in for inspection with the goal of catching problems before they happen.
That’s the difference between maintenance and repair. Repair is when you fix something that’s already broken. Maintenance is about making something last.
By that definition, the MTA is tasked with one of the most difficult maintenance jobs in the country, and its struggles are also a case study in why maintenance is such a tough sell politically. It’s not strictly necessary — or at least it doesn’t seem to be until things start falling apart. It’s chronically undervalued. The MTA is often harassed for its relatively high labor and maintenance costs.
Most mechanics would probably prefer to have brand new, ultramodern train cars and a rail system built on the best technology available. But they are a practical bunch. “I don’t think that’s going to happen,” Ling Ko told me. “We have to be realistic and deal with what we have.” Dealing with what they have has become a professional ethic for the MTA.
But how is it that the agency became the steward of the lumbering machines that move millions of people across one of the busiest cities in the world? Behind the decades of underinvestment and political sabotage is a more basic story about maintenance, what motivates it, where it is possible and advisable and where it isn’t. More often than not, maintenance is done only under conditions of austerity; those that can afford brand new things can simply discard what breaks or is no longer useful.
“If you can make it here, you can make it anywhere,” said Richard Ardizzone, the general superintendent at the Corona shop, referring to the MTA’s knack for overcoming adversity, budgetary or mechanical or otherwise. But the veteran mechanic’s gentle boast begs the question: Should it be this hard to maintain trains? Here, or anywhere else?
The MTA’s predicament has global implications. The industrial world is aging, and the sheer quantity and geographic extent of transportation, water and energy infrastructure presents an unprecedented challenge at the exact moment that climate change forces us to rethink material use. More robust maintenance practices could help preserve modernity’s finest achievements, from public transit systems to power grids to insulated homes. But first maintenance has to be valued outside of austerity, and right now it’s unclear if our current economic system is capable of that.
Maintenance could serve as a useful framework for addressing climate change and other pressing planetary constraints that, if left unaddressed, could recreate on a global scale the localized austerity of a cash-strapped transit agency. Indeed, maintenance as a concept could encompass both the built environment and the so-called natural world. Perhaps maintenance, rather than sustainability, is the more useful framework for a green transition, because it can account for how human infrastructure is now deeply entangled with the environment in the age of the Anthropocene.
If you start talking with engineers about maintenance, somebody always brings up Incan rope bridges. Maybe you’ve seen an illustration or a digital rendering in a Hollywood movie. They’re the color of hay and hang with a bit of slack over rivers and canyons in Peru’s rugged terrain. Made from ichu grass threaded into progressively denser and denser bundles, they were ritualistically maintained by ancient Peruvians. They lasted for centuries. Most are long gone now, though at least one has been preserved for posterity as an infrastructural artifact, just like the R32 at the New York Transit Museum in downtown Brooklyn.
It’s hard to imagine a modern ritual that would be equal to the task of perpetually renewing steel bridges, concrete highways and cement buildings. It would require an entirely new industrial paradigm. One label for such a system is “circular economy,” which the Ellen MacArthur Foundation, which funds research on the topic, defines as “an industrial system that is restorative or regenerative by intention and design.”
The concept dates to the 1960s and the work of economist Kenneth E. Boulding, but most of us are more familiar with a related slogan that emerged from the environmental movement of the 1970s: reduce, reuse, recycle. Those have been the guiding principles for the green movement for much of the past half-century, informing everything from municipal recycling programs to efficiency standards for toilets to lifestyle movements calling for “zero-impact living.”
Maintain is notably missing from the triplet, perhaps because it’s difficult to reconcile with sustainability’s implicit emphasis on reduction and restraint. By contrast, maintenance is about keeping things — sometimes large, intensively built things like skyscrapers and subway cars that might be difficult to imagine in the biodegradable utopias of the most gung-ho environmentalists. Ultimately, reduction is prioritized. We must not hold onto things. We must let go like good Buddhists, as industrial civilization becomes merely a painful, transient phase in human history, passing out of us like bad karma.
There is tension in the question of whether to build objects more intensively, so that they last longer, or to recognize that some things cannot endure and thus should be designed that way. There’s no hope for a paper plate in the long run, for example. It’s designed to enter the waste stream as cheaply and easily as possible. Conversely, a toaster could last for decades if maintained properly, assuming the manufacturer hasn’t built obsolescence into it (as is often the case).
More complex objects and built environments, like a transit system or a housing development, compound questions over what should last and what cannot. How do we create systems that can address these questions on their own terms?
Stewart Brand, the editor of the Whole Earth Catalog, helped popularize the concept of “shearing layers,” which describes buildings as stacks of discrete systems, each requiring different degrees of care and maintenance. While a wood frame might be fine for three decades, the plumbing or cabling might last only half that time.
Sustainability, and the climate discourse in general, fails to disentangle the built environment in this way. The built and unbuilt environment are treated as totalities caught in a zero-sum conflict. One barrages the other with smokestacks and landfills, the other retaliates with forest fires and flooding. Climate change becomes a hyperobject, bearing down on all of humanity at once, condemning and forbidding it.
Companies and governments answer this challenge with obscure benchmarks and proliferating, multi-decade goals. Climate change discourse floats outside the reality of industrial life, with its interlocking material and mechanical dependencies, never touching down until real scarcities assert themselves. In this way, emissions goals are not unlike GDP targets. Both are administered abstractions, somehow all-powerful and impotent at the same time. They reduce action to aggregates and strip human actors of agency.
Maintenance is necessarily more focused on the particular. There is no single all-encompassing maintenance regime. It is always specific to material systems and the labor practices that they require. Best practices emerge at the intersection of production and consumption, service and use, formation and dissolution.
Under capitalism, maintenance is an ambiguous position, almost a kind of limbo. The economics are rarely cooperative. There are plenty of carrots from a technical point of view — make things safer, more reliable, longer-lasting — but often no stick. In the developing world (or budget-strapped transit agencies), sticks are everywhere. Cuba’s beautifully maintained mid-century automobiles owe their longevity to a cruel and arbitrary embargo. India’s long-standing repair culture is the byproduct of the country’s position at the bottom of the global supply chain, and even now is being undermined by rising incomes and consumption.
In the abundant West, those limits are less acute, and there is a prevailing faith among capitalists that the market will come through in the end — at least for the highest bidder. Recent price increases for construction materials like plywood should, according to Econ 101, force builders to treat them more dearly. But price swings have to be sustained to really change behavior, and competitive markets make coordinated action difficult under the best conditions, let alone during a mad scramble for supplies.
Right now, the electric vehicle boom is fueling an extraordinary surge in demand for metals such as nickel, cobalt and lithium. Warnings abound that the current supply of those ingredients won’t keep up, and new mines can’t be established quickly, especially when many in the West don’t want one in their backyard. EV makers like Tesla are scrambling to set up direct supply lines, and sometimes getting into the mining business themselves.
In other words, the specter of material limits is hardly forcing a kumbaya moment. It’s making competition even more fierce and zero-sum, with the riches going to the most aggressive and acquisitive. Perhaps this pressure will create better recycling practices, as the cost incentive for reprocessing old battery materials increases. But there isn’t a society-wide plan for this to happen. If anything, there’s a handful of opportunistic businesspeople and investors waiting in the wings.
Even when the market isn’t beset by shortages and price spikes, labor dynamics are fundamentally opposed to maintenance. In much of the developed world, labor costs are higher than material costs, which creates incentives to burn through fresh material rather than invest in the labor to use it more efficiently or maintain it for longer-term use. According to one study, for example, it’s more expensive to cut steel into customized pieces, thus cutting down on waste, than to pump out uniformly sized sheets.
The incentives get even more distorted when stretched across industries and use cases. Here, again, maintenance distinguishes itself rhetorically from sustainability. Sustainability is a state; maintenance is a process. It requires work, and work of a certain type. Whatever its ultimate goal — safety, material efficiency, reducing carbon emissions — practical know-how and repetitive labor come first. This kind of pragmatism is sorely needed in the climate debate, which is so often preoccupied with end-states that it has no earthly or humanly way of achieving.
So far, however, those who champion maintenance are following in the footsteps of environmental advocates in prioritizing regulatory reform over a more ambitious overhaul of the economy and work itself. As Lee Vinsel, the co-founder of the Maintainers, one of the few advocacy groups to focus on this issue, told me, the lack of progress in getting Americans to value maintenance is a “political will issue.”
Nathan Proctor, a director of the Campaign for the Right to Repair at the U.S. Public Interest Research Group, said it’s a matter of capitalism not staying in its lane. “I think capitalism is an efficient way to organize commerce,” he said. “But it shouldn’t be organizing social value, and it does.” That places the issue firmly in the domain of rules and regulations. As Vinsel wrote in his book, “Moving Violations: Automobiles, Experts and Regulations in the United States,” industries can evolve symbiotically with regulators. “I really think we can use regulatory structures to get a lot of this done by having requirements that technologies have to live up to,” he said. “It actually opens up the creativity of capitalism, right?”
This tracks with how many liberal reformers and environmentalists view climate change. With the right combination of regulations, efficient markets and moral suasion, there is no structural problem too big for good old-fashioned law. For what it’s worth, Europe has made more progress along these lines than the U.S. The European Commission’s Sustainable Product Initiative, for instance, is pushing manufacturers in the fast-fashion industry to produce longer-lasting clothes that are designed for easier reuse, repair and recycling. While this sounds like a perfect example of maintenance policy, the EU first has to get companies, many of them multinationals with factories located far from their customer base, to comply. And then will come consumer grumpiness over higher prices.
Here in the U.S., the most popular political expression of maintenance is the right-to-repair movement, which is more focused on consumer rights than a top-to-bottom overhaul of production and consumption. Their basic demand is for corporations to make products easier to repair, and they’ve actually made some headway. After years of getting backlash for its sealed-tight product design, Apple started giving customers access to tools and parts in late 2021, and Samsung followed this year. In both cases, the emphasis was on giving tech-savvy customers the choice to repair their products, if they are willing to put in the work. It reflects a very do-it-yourself ethos, behind which is a whole cottage industry of TikTok and YouTube videos teaching viewers how to fix everything from MacBooks to KitchenAid blenders.
Louis Rossmann, the owner of a computer repair shop in New York City and a popular Youtuber, exemplifies this online right-to-repair culture. For him, repair is a pathway to independence and autonomy. “I care about freedom,” he told me, “and the ability to service your own property is a primary tenet of freedom.” Of course, capitalism doesn’t make it easy for people like Rossmann to make a living on maintenance. He explained that his business didn’t become possible until he started getting blueprints for iPhone circuit boards off the dark web.
The personal dimension of maintenance and repair — how it’s also a form of knowledge that can give you power over the objects in your life — is not often emphasized by progressive environmentalists. That language is left to DIY Youtubers and entrepreneurs like Rossmann, not to mention the farmers and fishermen and musicians and truckers and others whose livelihoods depend on certain machines operating at a certain level.
If maintenance seems conservative, decked out in language about freedom from government oversight and corporate control, it doesn’t have to be. The right-to-repair movement falls well short of reordering society. It might, however, mark the return of a material awareness.
The way the world is constructed today is no longer legible, politically or technically. Objects come and go under mysterious circumstances. Cars and trains either run or someone else fixes them. The objects in our lives are shipped to us from faraway lands, and they work until they don’t. Discarded, they get hauled away in the early morning by stinky trucks.
Maintenance mostly happens out of sight, mysteriously. If we notice it, it’s a nuisance. When road crews block off sections of highway to fix potholes, we treat it as an obstruction, not a vital and necessary process.
The built environment becomes a series of mere commodities and services, which are more or less expensive, more or less onerous. Environmentalists, liberal reformers and internet repair gurus share the goal of trying to demystify the world of stuff, but they lack a theory of change equal to the task at hand.
One of the unspoken assumptions of the mainstream environmental movement is that climate change will, at some indeterminate point in the future, swoop in as the externality to end all externalities, and either destroy us or force us to adapt. There’s something both horrifying and comforting in this notion. On the one hand, action seems impossible in the short term. On the other hand, nature could soon force us to change, saving us from the uncomfortable task of addressing climate change in a way that balances other prerogatives beyond simply “saving the planet” in the abstract.
The way this globalized coercion is supposed to happen is through the price mechanism. Governments will either pass a law raising the cost of carbon emissions through some kind of cap, and/or increasing scarcity will drive up the price of resources. Remember the peak oil debates of the early 2000s? Eventually, experts told us, gasoline would get so expensive that people would start moving to cities, riding a bike and taking the train.
The problem with this approach should already be self-evident. The impact of climate change will be unevenly distributed in space and time. Rather than a single biblical reckoning, there will be a series of disasters and dislocations, which global capitalism has so far proven highly adaptable at ignoring or overcoming. Simply waiting for climate change or resource scarcity to once and for all force us to change our ways is tantamount to taking our hands off the wheel, like a driver in one of Elon Musk’s autonomous rides. Choices have to be made, but maintenance, material efficiency, sustainability — or any number of frameworks gesturing toward a greener, less wasteful economy — are not sufficient goals unto themselves.
Maintenance isn’t a program. It’s a practice. Melvin Kranzberg, the former president of the Society for the History of Technology, once wrote that “technology is neither good nor bad, nor is it neutral,” which is to say that its value is always contingent, even as certain technologies have their own internal logic that must be accounted for. The same goes for maintenance or sustainability, or any mental framework. Climate change and resource scarcity are real phenomena, but they must be addressed in the full context of other social aims, such as a given standard of living — or in the case of maintenance, a state of repair.
Technical and political-economic concerns are perversely entangled. There is the problem of a crumbling bridge, and then there is the problem of coordinating public action to fix a crumbling bridge. There is a technical answer, a set of actions and materials that must be brought to bear, but the political answer is just as important. The follow-up questions pour in: What if it would be better to build a new bridge in a new place, based on changes in demographics? What if the bridge was constructed shoddily from the beginning and should be completely rebuilt? What if society is moving away from automobile travel and requires other bridges built in different ways?
The only way to answer these questions is to have a coherent vision for industrial society that oversees the distribution of capacities and capabilities. Growth and degrowth are sorry proxies for this debate. Much of what we’ve built can and should be maintained, while much else should be torn down and built anew. Perhaps the MTA should get new trains, but if not, then it should at least get the maximum level of government and public support to ensure the trains it does have run safely, comfortably and on time.
Maintenance is no panacea, not within the narrow parameters of a subway system or the planet-sized arena of ecology, but it does offer a rough methodology for thinking through these questions and priorities. As a type of work that straddles production and consumption, maintenance can help us reckon with both the limits and possibilities of industrial society.
The difference between a state of good repair and a bad one is often highly technical. No amount of utopian dreaming can make a battery hold any more energy or a piece of steel bear any more weight than it’s designed for. Mechanics, plumbers, electricians, engineers and janitors are at the frontlines of figuring out what’s possible with the machines and tools at their disposal, and we can’t set civilizational goals without their input. We need their expertise, just like we need scientists and doctors, to even begin answering the question of what must be done.
“We have a lot of folks here with a lot of time and a lot of knowledge,” said Raymond DelValle Jr., an assistant chief mechanical officer at the MTA. “One of the jobs of a maintenance division is to share the knowledge that we have.” I can’t help but wonder what they might tell us if we asked them what was possible without simultaneously denying them the resources they need to do their job.
Their knowledge is only worth so much, however. The real challenge is creating an economic system that values labor outside of profit-driven production. Many have rightfully called for a revaluing of care work in recent years. Maintenance workers deserve a similar revival in attention — but not only that. The price mechanism, and the labor system built around it, is fundamentally opposed to maintenance, both in its narrowest practical applications and in its broadest philosophical implications. The fact that the failures of capitalism happened to encourage maintenance practices at the margins is not worth emulating, and we shouldn’t be waiting around for climate change to recreate that austerity at a global scale. It must be valued on its own terms, and that means tearing down the economic system that rejects it.
One of the aesthetic charms of the Brightliners was their unpainted steel, their raw factory-floor materiality. They wore their industrial lineage proudly, and we associate them with a time of boldness, with an ascendant industrial age that was still confident in its promise of technology and plenty. We now know the limits of that vision, but we have yet to replace it.
Whatever comes next must take responsibility for that legacy, while also articulating something new and perhaps even bolder than what came before. There is a useful lesson drably concealed in the MTA’s maintenance facility in Queens: What we inherit comes with responsibility. Vintage machines are owed our best efforts, and our ingenuity in keeping them running should at least be equal to our ingenuity in forging them.
The work of maintenance is ultimately a way of parsing and knowing a thing and deciding, over and over, what it’s worth. “Maintenance should be seen as a noble craft,” said Rossmann, the boot-strapping repair man who learned the secrets of the iPhone’s circuits. “It should be seen as something that teaches people not just how to repair, but how to think.”",2
14,"A few days ago, I noticed that the prices of World War 2 era slide rules have fallen to below $20 US. Fifteen to twenty years ago, they were selling for $50-$80. My guess is that the people who used slide rules in their professions and were willing to pay over $50 to re-experience the nostalgia of playing with one again are now all dead.
Just for fun, I learned to use a slide rule at the end of the 1970's. Part of what I realized as a result is that slide rules are an elegant computing solution. They require no power. They last forever. And, they work well enough to solve most problems where an individual understands the basic principles associated with the problem he is trying to solve. Performing calculations with slide rules was part of what forced generations of scientists and engineers to understand the approximations they were using to solve problems. No, slide rules do not work for things like computational fluid mechanics and Monte Carlo simulations, and that is my point. We can usually solve problems sufficiently well without resorting to complicated methods.
In contrast, our approach in engineering these days is to use computers to simulate everything down to 15 digits, because we really no longer understand what we are doing. Most engineers today will strenuously deny this, but many no longer have high-level insights into the problems they are trying to solve. And, they don't know that. I have mentioned this to a few of my fellow engineers over the years and they have looked at me like I was speaking ancient Aztec. Engineers in many industries are focused on the details and reliant on the simulations to put all the pieces together to make a coherent whole. The problem with simulating everything to death is that it actually helps keep us ignorant of basic principles.
Engineers have been stuck on the simulation approach for so long that they no longer have the option of going back. When I was a young engineer, older, experienced engineers and engineering managers understood basic principles and the big pictures of the things they were working on. As a result, they knew when proposed solutions just did not look right. Here is a much over-simplified and probably unrealistic example that I am making up off the top of my head, because I have never been civil engineer. If I were a civil engineer back in the 1960's and proposed that my company build a bridge with a span of 100 meters between support columns using only stone and mortar, a more experienced engineer would have looked at my design and known immediately that a span that long requires steel. Without doing any calculations at all, he would have known that my design could never have worked. Today, although we could argue, my feeling is that nearly all of the engineers who were capable of similar insights in their fields have been retired for decades and are probably dead. Today, an engineering manager may look at the same proposed solution and decide to put a 10 man team on the problem for 6 months simulating the bridge at a cost of a million dollars.
Another issue is that many of us are too lazy or insufficiently interested to do less simulating and more thinking. During my career, I have worked for more than one engineering manager who has announced to everyone who worked for him that the simulation was ""the truth"". He did not want to be bothered with the actual truth (i.e. flaws and inaccuracies in the simulation), because he was simply not interested. My guess is these managers had decided to abdicate all responsibility for their project's outcome, because they had a simulation to use as a scapegoat. If the train derailed (so to speak), it was the simulation's fault, not theirs. This is an illustration of the blame transference mentality that to some extent affects us all, which is why renowned social psychologists Carol Tavris and Elliot Aronson wrote a book about it, Mistakes were made (but not by me).
My bridge design scenario is probably not a great example, because I am not a civil engineer. I work in a completely different industry that spends an almost incalculable amount of money on computer simulations. I would not be surprised if in total my industry spends in the US alone close to 100 billion dollars a year simulating everything they do. The US government (i.e. the tax payers) pays for most of it.
The simulation-first approach to design is one of the reasons engineers in the US take 15 years and spend tens of billion of dollars of tax payers' money designing a new fighter aircraft. In the 1950's and 1960's a single company could put out one or two new fighter prototypes for testing every year. The simulation approach is also one reason NASA has spent 20 years and I have no idea how many billions of dollars on the Aries and SLS programs in its attempt to come up with something to replace the space shuttle. And they will probably lose that job to Elon Musk, who is spending a small fraction of the time and money. The difference is that Musk apparently knows what he is doing. I am sure that his engineers also use simulation, because as I said, that is what engineers do these days, but my guess is that Musk's executive insights have successfully minimized that in order to save huge amounts of time and money.
Am I arguing that we should throw away our computers and go back to slide rules? Absolutely not! Some problems can only be solved by computer simulation--because we really do not know enough to solve them any other way. I also understand that a complicated relationship exists between design work and testing, and I do not mean to minimize the significance of that. But, most design problems can be solved with simpler, less expensive, less time-consuming methods and tools and more experience and knowledge of basic principles.
One problem we face is the perennial one of, if you are holding a hammer, every problem looks to you like a nail. Over-simulation is a issue in many of our industries, and I think it is one of many reasons that our standard of living has gone down over the last six decades. When we have a very large percentage of our scientists and engineers wasting time with tools that are not appropriate for their jobs, we are all indirectly paying their salaries without really getting what we are paying for. Unfortunately, extremely few who run companies and governments are capable of seeing the big picture well enough to know how to increase efficiency in order to increase our standard of living by spending less money looking for workable solutions to problems. This is the world we live in, and it is a shame. We could be doing so much better than we are.
Now, we are compounding the problems we have brought upon ourselves through our over reliance on computer simulation by trying to apply artificial intelligence to solve our problems. In so doing, we are merely removing ourselves even further from a basic understanding of how things work. Are we really too lazy to learn basic principles and methods of applying them to obtain the solutions we seek? Will we really throw up our hands and finally announce to each other that we are too stupid to solve our problems? Are we really willing to suffer whatever ill effects may come from applying some magical voodoo artificial intelligence to do all the work for us?
Why am I even asking these questions? I have lived long enough to know the answer to all of them. Yes! If foolishly placing faith in artificial intelligence is the great existential filter implied by the Fermi paradox, then we may be about to filter ourselves out of existence. Even if it is not, we may further bankrupt ourselves in more ways than monetarily while looking for something to do the thinking for us that we are too lazy and too irresponsible to do for ourselves.
--Tie
| |
Copyright © 2019-2022 terraaeon.com.
All rights reserved.",2
15,"The Matchbook Edition
On design, branding, and keepsakes
Re-running this stone cold classic edition today. -Colin (CJN)
Elliott Walker (EDW) is a creative director and co-founder of Otherward, a brand design agency in New York. We’re re-running this classic today. -Colin (CJN)
Elliott here. One of my all-time favorite objects of design—one of the greatest promotional items ever created—and as far as I'm concerned, a mandatory detail in any reputable bar, restaurant, or hotel is the printed matchbook.
The first strike-able paper book of matches was patented in 1892 by Joshua Pusey, a Philadelphia patent lawyer, and inventor. ""Safety"" matches, made with amorphous (red) phosphorus, had been in use for a few decades, but they were large and came in wooden boxes. Pusey was an avid cigar smoker and found these matches cumbersome to carry around, so he set about developing a lightweight style bound in a paper book which he called the ""Flexible Match.""
Image Credit: United States Patent Office
Three years after receiving his patent, he sold it to Diamond Match Company for $5,000. At the time, Diamond Match Company was the largest manufacturer of matches in the U.S. One of the first things they did with the patent was make a few critical adjustments to the design. This included raising the ignition point of the matches by 100 degrees and moving the striker to the outside of the matchbook so that the matches could no longer self-ignite as easily. Apparently, friction from walking with a matchbook in your pocket was enough to ignite some of the initial models.
Custom printed advertising and branding began appearing on matchbook covers almost immediately after matchbooks moved into mass production. Here are a few early examples from the 1890s.
Image Credits: matchpro.org
Most of these early printings were done at small scales. The Mendelson Opera Company matchbooks, for example, were hand-printed with a total run of only 200 books. All of that changed though in 1902 when Diamond Match Company received an order from Pabst Brewing Company for 10 million custom printed matchbooks. The era of commercial matchbook printing had begun.
Production exploded over the first half of the twentieth century and competition between manufacturing companies led to the offering of fine printing techniques and a wide array of matchbook styles and sizes. It's hard to find an object with more visual impact and storytelling potential per square inch than a printed matchbook, and creative innovation flourished as the industry grew. Multi-color match heads, custom printed sticks, embossed foil covers all became commonplace and commercial artists at the time pushed the boundaries of what was possible with these advanced production techniques.
https://www.theguardian.com/artanddesign/gallery/2017/may/20/creative-spark-vintage-matchbook-art-in-pictures-aaron-kasmin-sims-reed#img-14
The hospitality industry, for their part, saw the potential in this new type of advertising platform and bought in big. Soon every bar, restaurant, hotel, and nightclub had a custom matchbook. The industry reached a crescendo by the 1950's. This just so happens to track closely with U.S. smoking rates, which hit their peak in 1954. And, production remained strong for the next few decades. At one point 35 billion matchbooks were being manufactured in a year. However, by the mid-1980's the American match industry had collapsed due in part to the decline in smoking rates and the introduction of cheap, disposable lighters.
Why is this Interesting?
Though production has been in decline for the past 30 years, matchbooks remain an enduring artifact within the world of hospitality. Walk into any good restaurant or bar today and chances are still high that you will find a dish on the maître d’ stand or a glass behind the bar filled with custom matchbooks. I've made my career as a brand designer and have had the opportunity to work on a number of restaurant projects over the years. In my experience, one of the easiest ways to help a chef or owner visualize a potential new logo is to show them what it looks like on a matchbook.
The matchbook is a historical relic. Its utility harkens back to a previous era when everyone smoked indoors. Yet, its relevance in contemporary food and drink culture is undeniable. Just because we all vape now doesn’t make a good set of matches any less vital an expression of hospitality. And it’s in part this heady collision of old and new that makes them so compelling.
Matchbooks remain a perfect souvenir for an extraordinary meal or a memorable night out. They are a physical token of a shared experience happening at a specific time and place. And, like any good memento, they help impart a sense of connection to others. Matchbooks create a through-line, from our present experience to the experiences others have shared within the same bar or restaurant, hotel, or club. They serve as evidence that you too were there and it was a good time. (EDW)
Matchbook of the Day:
From a visual design perspective, matchbooks are an extremely versatile form to work with. You can pack a lot into a very small canvas to great effect. However, simplicity can also be equally powerful. If the place is good, the name or logo is sometimes all you need. So, I'll leave you with a personal favorite:
https://matchbookarchive.tumblr.com/post/42780228525
The matchbook for fabled Meatpacking District restaurant Florent, designed by Tibor Kalman at M & Co. in 1985. Kalman had the match covers turned inside out so the raw cardboard faced outward and the coated paper was inside. As a result the restaurant's name and contact information were hidden behind the matchsticks. (EDW)
--
WITI x McKinsey:
An ongoing partnership where we highlight interesting McKinsey research, writing, and data.
Space Junk—it’s out of this world. Rockets, satellites, moonwalks, and more: let’s explore space in this edition of McKinsey for Kids. Find your flight suit and buckle up for a closer look at the future of space and how people are trying to deal with the stratospheric equivalent of your family’s junk drawer.
Thanks for reading,
Noah (NRB) & Colin (CJN) & Elliott (EDW)
—
Why is this interesting? is a daily email from Noah Brier & Colin Nagy (and friends!) about interesting things. If you’ve enjoyed this edition, please consider forwarding it to a friend. If you’re reading it for the first time, consider subscribing (it’s free!).
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.",2
16,"Our Technology Sickness—and How to Heal It
Micah Goodman
Micah Goodman, a research fellow of the Kogod Research Center at Shalom Hartman Institute in Jerusalem, is the author of Maimonides and the Book that Changed Judaism (2015), Catch-67 (2018), and The Wondering Jew: Israel and the Search for Jewish Identity (2020). This essay is adapted from his forthcoming book The Attention Revolution (2022).
An Anti-Talmudic World
Guided by the belief that one can draw closer to God by studying sacred texts, Jews have long sanctified learning and scholarship. Surprisingly, they largely concentrated on the Talmud, not the Bible. And what’s in the Talmud? Let’s start with what is not in it: no clear and straightforward list of laws to be observed. Anyone who opens the Talmud finds many more disputes than legal decisions. Jews of all stripes, from sages to daily laborers, have studied this text as an essential element of their religious lives. They fulfilled the obligation to study not by examining the word of God as expressed in the Torah, but by examining the words of humans voiced in the Talmud.
The absence of an orderly list of laws and statutes in the Talmud does not mean those laws and statutes are inconsequential. Jewish tradition demands not just studying books but observing laws. The first requirement is intellectual: Jews are required to study texts. The second is practical: Jews are required to obey laws. Intellectually, Jews are expected to be conversant with all sides of a controversy, but in their lived behavior they are expected to follow one position among many. Jews are expected to know the opinion of Abaye, but to uphold the opinion of Rava; to study the positions of Shammai but live according to the positions of Hillel.
In studying the Talmud, we’re enjoined to grapple with all sides of a dispute but in the end to live our lives in accord with only one of those sides. This model informed my last two books—a model that I believed might help heal the wounds of Israeli society. My two most recent books, Catch-67 (2018) and The Wondering Jew (2020), were about relationships between groups of people: left and right, Israelis and Palestinians, religious and secular Jews. With Catch-67 I tried to elucidate the ideological war in Israel over the Israeli-Palestinian conflict using a Talmudic lens. I attempted to show the left that the positions of the right are grounded in a deep and compelling philosophy; I tried to show the right that left-wing positions are shaped by fascinating schools of thought. In my most recent book, The Wondering Jew, I endeavored to present the profound thinking of secular positions to religious Jews, and to present the wisdom contained in religious schools of thought to secular Jews. In both cases, the organizing idea was Talmudic: not to persuade anyone to change their practice, but to broaden readers’ worldviews.
In both cases, my project failed. Israeli society remains polarized, and the polarization is only deepening. On both the right and left, religious and secular, intellectual horizons are narrowing to fit political positions. Curiosity stagnates in a prison of ideology. Are Israeli politicians intensifying the polarization instead of healing it? Is Zionism itself infected by a virus that attacks the magnificently rich Jewish intellectual tradition?
Such explanations are locally defined, but polarization is far from unique to Israeli society. It is a global problem. Twenty years ago, political identity did not demarcate our intellectual or social horizons. Today, however, in contrast to the Talmudic ideal of nurturing an intellectual world wider than one’s practice, our intellectual world has shrunk to fit the narrower dimensions of policy and practice. The books we read, the lectures we hear, and the videos we watch are all produced by people in our own camp. In short, we have sunk into an anti-Talmudic world.
Diagnosing the Problem
To understand why this is so, I turned to several leading thinkers, each of whom can help us understand what is going on.
In his book The Upswing: How We Came Together a Century Ago and How We Can Do It Again (2020), Robert D. Putnam, who teaches public policy at Harvard University, presents a fascinating study on polarization. In the 1950s, Americans were asked whether they would be bothered by their son or daughter marrying a person of a different race. About fifty percent responded in the affirmative. They were also asked if they would be bothered by their son or daughter marrying a person who affiliated with a different political party. About ten percent answered yes. When the same questions were posed in the 2010s, fewer than ten percent said it would bother them if their son or daughter married someone of a difference race, but over fifty percent said it would bother them if their child married a person with opposing political views. In other words, Americans are growing more open to people of different races and growing more closed to those who hold different political views.
Another study asked people who identified as left-wing to rate their level of sympathy for right-wingers and people who identified as right-wing to rate their level of sympathy for left-wingers. They rated their feelings using a one-hundred-point scale: 0 represented absolute hatred, 100 represented absolute love, and 50 represented lukewarm feelings, neither love nor hatred. In 1995 the average score was 40. Republicans did not particularly like Democrats, and Democrats did not particularly like Republicans. Their emotional temperatures were low, but far from a deep freeze. The researchers repeated their study twenty years later: the average score dropped from 40 to 7.1 Within twenty years, Americans began to hate those who hold opposing political views. Similar polarization is happening in England, Poland, Hungary, Brazil, Argentina and many other countries. In recent years it has become a global epidemic.
Perhaps it is no coincidence that we are coalescing into like-minded groups in an age when we are all connected to the internet. Precisely when we seem most connected, we are most distant; precisely when we have all the tools to free ourselves and gain exposure to the wider world, we find ourselves imprisoned and disconnected. A new economy, equipped with new technology, has created a very old politics. Tribal politics. But why is this happening precisely when we are supposed to have become more connected through the advent of technologies like social media, when we have all the tools to free ourselves and gain exposure to the wider world?
To fathom this change, I turned to the ideas of Marshall McLuhan, the Canadian communications theorist who famously taught that “the medium is the message.” Technology can enrich our lives and fill it with things that were not there before. But it can also impoverish us and take things away from us.2 In his book Understanding Media, McLuhan explained the difference between what technology gives and what it takes away. What it gives us is bright and shiny, but what it takes away is obscure and practically invisible. It gives quickly but takes slowly. Its advantages are therefore seen and spoken about, while its disadvantages are mostly unseen and much less spoken about. This asymmetry creates the illusion that technology is an unmitigated bonus for humanity. But in practice, it always comes at a price. McLuhan argued that history is shaped not so much by ideas as by the tools we use to disseminate ideas. In his view, the medium exerts a greater influence than the message. The events that changed history were not the birth of monotheism, the emergence of humanism, and the growth of feminism, but the revolutionary advent of printing, radio, and television; not the creation of new ideas, but the emergence of new media which shape our very ways of thinking.
What polarized societies have in common is not their political ideas but new digital technologies that disseminate ideas. Social networks are the new town square, the sites where ideas are exchanged, debates are conducted, and questions are explored. The migration to a new platform has transformed the discourse.
But what connects this migration to our current polarization?
Tim Wu, a scholar of media at Columbia University, explains how this new medium has led to the political polarization of society.3 Human attention, he says, is increasingly being funneled into the neck of a digital bottle. In the early days of Google and Facebook, we all wondered why they would distribute their products for free. But over time the answer became clear: we are not receiving a product from these technology companies; we are giving a product to them: our undivided attention. In turn, they monetize that attention by selling it to advertisers, to great profit. In fact, Wu shows, the value of Facebook and Google today far exceeds the value of the major oil companies in the United States.
If our attention is worth more than oil, you can bet that these giant corporations will do anything and everything to pump out as much of our attention as possible. Facebook engineers work to capture our awareness, glue us to a screen, and draw out from us more and more human attention, just as oil companies develop technologies for drilling deeper into the earth. They design algorithms that first track our behaviors, see which posts we like, and identify which views we are drawn to, and then use that data to curate our “news feed” based on which posts will most likely receive our attention.
The result of these design choices is that our digital lives become sorted into tribes. Several years ago, Eli Pariser, a staunch leftist and president of the 5-million-member organization MoveOn.org, wanted to know what his conservative right-wing friends were thinking about a burning issue in the news. “I knew I had right-wing friends on Facebook, so I searched for their posts in my feed but couldn’t find any. For a long time I wondered, where could they be?” The answer was that Facebook’s algorithm had studied Pariser’s liberal preferences and stopped showing him posts by his conservative friends.
Once we are trapped in these digital echo chambers, what Pariser calls “filter bubbles,” hearing our own positions repeated over and over, it becomes natural for us to perceive those with different political views as mistaken, deceptive, and even sinful. We on the right and the left are increasingly unable to understand each other; we are increasingly likely to feel outraged or frightened by each other. We find it difficult to understand how it is possible that our truth, which is so obvious to us and everyone we know, cannot be understood by people from the other echo chamber.
Social media exposes us time and again to our own positions and ideas and thereby locks us ever more tightly into positions we already hold. Scrolling through Facebook is essentially self-indoctrination. What happens when a person inside this digital echo chamber, who hears his right-wing positions repeated over and over, meets another person who also lives inside his own digital echo chamber that repeats left-leaning positions over and over? Each experiences the other as deceptive, or even evil. Life in echo chambers deceives us. However much we may feel as if we are expanding, in reality our intellectual lives are constricting.
If political tribalism is a threat to our democratic wellbeing, self-isolation threatens our mental wellbeing. Our public life is under attack from the virus of polarization; our private lives, from the virus of loneliness, alienation, and—not least—envy. Digital technology is causing both viruses to mutate more quickly.
Love Jewish Ideas?
Subscribe to the print edition of Sources today.
Reversing Course
The Digital Revolution has been no less potent than the Industrial Revolution. The Industrial Revolution is wreaking havoc on the natural environment. The Digital Revolution is wreaking havoc on the political environment. Yuval Noah Harari argues that the future ramifications of the Digital Revolution will be infinitely more dramatic than its industrial predecessor.4 Since the Digital Revolution, our relationship with technology has spiraled out of control. And this relationship is by far the most challenging one that Western societies will have to regulate in the coming decades. The human-technology relationship is sick, and it’s time to heal it.
Because of the digital revolution, our lives are being transformed by three grand bargains. The intellectual bargain: we have more knowledge but less capacity to concentrate and focus. The social bargain: we are much more available but much less attentive. And most importantly, the emotional bargain: we are much more connected, but much less empathetic. When we trade away skills for power, attention for availability, empathy for connectivity, and quality for quantity of relationships, we sign up to a Faustian pact that we do not even know exists—one that gives us more control over the outside world, but less control over our inner world.
What then is to be done? What shifts in thinking and behavior will help us reverse course?
1. A philosophical shift: Less choice, more freedom
The West’s aspiration for freedom translates into a persistent cultural aspiration to have ever more options from which to choose. But a surplus of choice has a paralyzing effect. We do not get excited by the huge range of options but overwhelmed. Paradoxically—an increase in choice comes to the detriment of the chooser.
Yet the most devastating damage is not the difficulty of choosing but the difficulty of being happy with whatever one has chosen. When one is faced with a wide choice of possibilities and invests time and energy in weighing up the pros and cons of each, this investment might help one make a better choice—but it also guarantees that one will enjoy less whatever one chooses. This is the paradox: the more time people invest in choosing, the better their choice but the less their enjoyment from it. That is the tragic nature of human choice.
Consider the following experiment: a group was asked to choose a chocolate from a bowl with four types of chocolate. Another group was asked to choose a chocolate from a bowl with forty types of chocolate. Researchers found that those who chose from the bowl with less choice enjoyed the chocolate more than those who chose from the bowl with more. Too much freedom, the scientific evidence suggests, means too little enjoyment. He who chooses his lot, to paraphrase the ancient maxim, struggles to rejoice in it. Digital technology exacerbates this problem.
One of the great philosophers of the modern age, Baruch Spinoza, made a mighty effort to articulate the profound link between human happiness and the understanding that free will is an illusion. Happiness is not a corollary of feeling that we can shape the world, but of a radical acceptance of the fact that the world is shaping us. He argued that the most meaningful step toward happiness is recognizing one’s lack of freedom and accepting the inevitability of one’s fate. According to Spinoza, and contrary to the modern way of thinking, happiness is not a function of being free but of grasping that one is not free. Negative feelings, Spinoza explained, are driven by the belief that things could have been otherwise. We experience anger, for example, because we believe that something bad that happened to us should not have happened to us. We experience envy because we believe that something good that happened to someone else should have happened to us. These negative feelings are rooted in the illusion of freedom over our fate. We are being immiserated on a false pretext. The truth, according to Spinoza, is that every human choice is predetermined by nature, and we are mere links in a deterministic chain of events. Philosophy, Spinoza believed, held the cure. Freedom is an illusion. Realizing this is the key to alleviating suffering.
Spinoza’s metaphysics may be debatable, but his psychology is scientifically proven. Our belief in infinite possibility undermines our ability to be content with any eventuality. Contrary to modern thinking, less choice means more freedom, but it can also mean more happiness. The proliferation of options and choices that characterize our digitally savvy lives needs to shift in the direction of fewer choices, leading to more freedom.
2. A cultural shift: Attention over availability
In 1956, the psychologist Erich Fromm published his groundbreaking book The Art of Loving, a fascinating indictment of much of Western society. Fromm argued that the primary impulse of modern human beings is to be loved. That is why they go on diets, run marathons, and develop impressive careers. All for love. Fromm urged Western society to undergo an emotional revolution. Instead of seeking to be more loved, people should seek to be more loving. Loving, according to Fromm, is an acquired skill. It is an emotional muscle developed with much strain and hard work.
Inspired by Fromm’s exhortation to become more loving, I want to make a wish for a mental revolution to heal our dysfunctional relationship with technology: Our humanity should not be measured by how much attention we attract but by how much attention we devote to what matters. This emotional revolution would also be a spiritual one. It should be led by intellectuals and educators, united by the common endeavor of changing Western society.
How can this lofty aspiration be turned into a practical agenda for disrupting the stranglehold of technology?
Until recently, people were not expected to be reachable at the drop of a hat. But nowadays it is considered impolite not to reply to an email in a matter of hours or a text message in a matter of minutes. According to data from Adam Alter, one-tenth of all digital communications comprises apologies for being unavailable. Researchers have also found that the average time it takes us to reply to an email has shrunk by over 80 percent over the past decade.
This new norm comes at a cost. The more available we are, the less attentive we are. Distractions undermine productivity, but bosses still expect their employees to be available—that is, less attentive. When two people meet and one of them peeks at his phone every few minutes, this interrupts eye contact and disrupts communication. Yet remarkably, this is not considered impolite. In other words, society no longer expects us to be as attentive but expects us to be much more available.
A healthy technological culture would flip these preferences and prioritize attention over availability. In such a culture, peeking at one’s phone during a conversation would be considered extremely rude, and replying to an email with a delay of several hours would be considered quite normal. In such a culture, bosses would rebuke their employees not for failing to reply within minutes but for paying insufficient attention at work. The mark of good parenting would not be replying to children’s text messages within seconds but switching off their phones when spending time together. Cultures shape us because they determine what causes embarrassment. If we start to feel uncomfortable for not paying full attention rather than for not being fully available, we will have taken a big step toward emancipation from technology.
The cultural force needed to counterbalance the tech industry’s economic power could emerge from a critical mass of lots of tiny changes, adding up to transform social expectations. Bosses might expect their employees to switch off their phones and focus on their work, and youth movements might require members to leave their phones at home during expeditions. Parents might insist on being unavailable in the evening, which is family time, and might refuse to endanger their children’s mental health by giving them smartphones before a certain age. We might become expected to apologize if we check our phones in the middle of a conversation. The accumulation of these new digitally healthy habits would create a world with more breaks from technology and thus greater awareness about its use. Such a culture would be much less permissive about using technology but much more permissive about being free from it.
3. Remedial technologies
What will a healthy human relationship with digital technology look like? The most elegant maxim I have found comes from Sherry Turkle: technology is a great servant but a terrible master. If technology is our master, it dilutes our connections, erases our free time, and pulverizes our learning skills. But if technology is our servant, it deepens our connections, frees up time, and broadens our minds. All three connections can suffer from an unhealthy relationship with technology, and all three can gain from a healthy relationship with the same technology.
As a case in point: in 1 Samuel 17, we read about the battle between David and Goliath, one of the most familiar stories in Western civilization. This story is often used to teach that victory is not guaranteed to the strong but to the faithful. But there is another way to interpret the story.
Goliath the Philistine had a fearsome physique, protected by heavy armor, and he wielded a lethal weapon: a sharp and powerful sword. Facing him was David, a mirror image: short, unarmored, and swordless. Goliath was offended by such a weak rival. “Am I a dog that you come against me with sticks?” he asked.
David did not see himself as exposed and vulnerable but as agile and speedy. Nor did he see Goliath as defended and unassailable, but as overburdened and heavy. Goliath was not killed by the stone that David slung into his forehead; this strike only made him lose his balance and fall to the ground. What killed Goliath was his own sword. “So David ran up and stood over the Philistine, grasped his sword and pulled it from its sheath; and with it he dispatched him and cut off his head.” Here lay David’s secret: he used his enemy’s own weapon against him.
Like David and Goliath, the relationship between human beings and technology is asymmetrical. Technology has proved greater and more powerful than the humans who invented it. Those who imagine that we can protect ourselves from it using willpower alone do not grasp the power imbalance. If our humanity cannot protect itself by defeating technology, perhaps it can defend itself by harnessing technology. Real-world examples include technology installed in vehicles that prevents the driver from texting, surfing the web, or receiving notifications when the car is in motion; and a cell phone jamming technology that creates small zones of quiet at a restaurant or business meeting or family living room. I call these “technologically liberating technologies.”
4. A Talmudic shift
In opening this essay, I noted how Jews concentrated their sacred commitment to study on the Talmud rather than the Bible. This commitment established a culture in which intellectually, Jews are expected to be conversant with all sides of a controversy, but in their lived behavior they are expected to follow one position among many. Such a culture ensures that one’s intellectual world is much more expansive than the world of one’s lived practice.
Returning to this culture can help heal the ills caused by our digital-driven culture. Translating the commitment into contemporary terms: I might hold progressive views and vote for the Democratic slate of candidates down every ballot but at the same time seek to understand conservative thinking. However left-wing in my actions, I might nurture more capacious curiosities and interests. When we cannot fathom why so many people would believe what they believe, we know this is a symptom being imprisoned in anti-Talmudic digital echo-chambers. The Talmudic tradition exalts a culture of disagreements. Embracing the Talmudic way of life grants our intellectual world the freedom to be far more expansive than the world of lived practice.
Early in my exploration of the impacts of the digital revolution, I’d assumed that people could resist the seductive powers of digital technology. Though as individuals we may be weaker than our devices and the tech corporations behind them, I believed we would triumph. Just as David defeated Goliath, we too would beat the technologies that oppress us.
Today I have come to embrace the opposite view: technology is much more powerful than I imagined, and the human mind much weaker. David did not beat Goliath by smashing his strength but by wielding it against him. Jewish mystics assumed that Moses must have been a prince of Egypt and a member of its civilization’s culture because Egypt could only have been defeated using the same sort of power that Egypt deployed. The great medieval thinker Nachmanides believed that this was a metaphysical principle: the road to freedom from oppression runs through using one’s oppressor’s strengths against him.
This is what it will take to heal the societal ills caused by the digital revolution. By pursuing fewer choices and more freedom, prioritizing attention over availability, experimenting with liberating technologies, and leaving our narrow digital echo chambers for the Talmudic expanse of broad intellectual horizons, we can all do our part to begin the healing process. The capitalistic pursuit of profits has led to a destructive attack on human attention. But the most effective strategy to protect our attention is neither to fight human impulses nor to wage war on capitalism. On the contrary, the ambitions of capitalism created the crisis, and the ambitions of capitalism will remedy it. The remedy will grow out of the ailment itself.
Translated from the Hebrew by Justus Baird and Eylon Levy.
This article appears in Sources, Spring 2022.
Notes
1. Greg Lukianoff and Jonathan Haidt, The Coddling of the American Mind, pp. 126–129.
2. Marshall McLuhan, Understanding Media, pp. 63–70.
3. Tim Wu, The Attention Merchants: The Epic Scramble to Get Inside our Heads, 2017.
4. Yuval Noah Harari, Homo Deus: A Brief History of Tomorrow, 2017.",1
17,"Psychedelics for depression: can this trial lead to a new NHS therapy?
A clinic in London hopes to make the UK a leader in research of psilocybin. Damian Whitworth reports
Ian Roullier swallowed the 25mg of psilocybin and settled on the bed. Therapists took turns to sit with him in an institutional room brightened by blankets, cushions and fresh flowers, and after half an hour he began to feel the effects of the active compound in magic mushrooms.
For most of his adult life Roullier had been plagued by anxiety and depression. Antidepressants and talking therapy had had little impact. In desperation he had enrolled in a clinical trial testing the impact of the psychedelic drug on patients with treatment-resistant depression.
Wearing eyeshades and listening to music through headphones, he saw geometric patterns and then full-blown scenes “like a waking dream”, he recalls. He was usually averse to facing the trauma in his life, but",2
18,"View gallery
8 Pictures
A floating city in the Maldives begins to take shape
A city is rising from the waters of the Indian Ocean. In a turquoise lagoon, just 10 minutes by boat from Male, the Maldivian capital, a floating city, big enough to house 20,000 people, is being constructed.
Designed in a pattern similar to brain coral, the city will consist of 5,000 floating units including houses, restaurants, shops and schools, with canals running in between. The first units will be unveiled this month, with residents starting to move in early 2024, and the whole city is due to be completed by 2027.
The project -- a joint venture between property developer Dutch Docklands and the Government of the Maldives -- is not meant as a wild experiment or a futuristic vision: it's being built as a practical solution to the harsh reality of sea-level rise.
An archipelago of 1,190 low-lying islands, the Maldives is one of the world's most vulnerable nations to climate change. Eighty percent of its land area is less than one meter above sea level, and with levels projected to rise up to a meter by the end of the century, almost the entire country could be submerged.
But if a city floats, it could rise with the sea. This is ""new hope"" for the more than half a million people of the Maldives, said Koen Olthuis, founder of Waterstudio, the architecture firm that designed the city. ""It can prove that there is affordable housing, large communities, and normal towns on the water that are also safe. They (Maldivians) will go from climate refugees to climate innovators,"" he told CNN.
Hub of floating architecture
Born and bred in the Netherlands -- where about a third of the land sits below sea level -- Olthuis has been close to water his whole life. His mother's side of the family were shipbuilders and his father comes from a line of architects and engineers, so it seemed only natural to combine the two, he said. In 2003, Olthuis founded Waterstudio, an architecture firm dedicated entirely to building on water.
At that time signs of climate change were present, but it wasn't considered a big enough issue that you could build a company around it, he said. The biggest problem then was space: cities were expanding, but suitable land for new urban development was running out.
However in recent years, climate change has become ""a catalyst,"" driving floating architecture towards the mainstream, he said. Over the last two decades, Waterstudio has designed more than 300 floating homes, offices, schools and health care centers around the world.
The Netherlands has become a center for the movement, home to floating parks, a floating dairy farm, and a floating office building, which serves as the headquarters for the Global Center on Adaptation (GCA), an organization focused on scaling climate adaptation solutions.
Patrick Verkooijen, CEO of GCA, sees floating architecture as both a practical and economically smart solution for rising sea levels.
""The cost of not adapting to these flood risks is extraordinary,"" he told CNN. ""We have a choice to make: we either delay and pay, or we plan and prosper. Floating offices and floating buildings are part of this planning against the climate of the future.""
Last year, flooding cost the global economy more than $82 billion, according to reinsurance agency Swiss Re, and as climate change triggers more extreme weather, costs are expected to rise. One report from the World Resources Institute predicts that by 2030, urban property worth more than $700 billion will be impacted annually by coastal and riverine flooding.
But despite momentum in recent years, floating architecture still has a long way to go in terms of scale and affordability, said Verkooijen. ""That's the next step in this journey: how can we scale up, and at the same time, how can we speed up? There's an urgency for scale and speed.""
A normal city, just afloat
The Maldives project aims to achieve both, constructing a city for 20,000 people in less than five years. Other plans for floating cities have been launched, such as Oceanix City in Busan, South Korea, and a series of floating islands on the Baltic Sea developed by Dutch company Blue21, but none compete with this scale and timeframe.
Waterstudio's city is designed to attract local people with its rainbow-colored homes, wide balconies and seafront views. Residents will get around on boats, or they can walk, cycle or drive electric scooters or buggies along the sandy streets.
It offers space that is hard to come by in the capital -- Male is one of the most densely-populated cities in the world, with more than 200,000 people squeezed into an area of around eight square kilometers. And prices are competitive with those in the Hulhumalé (a manmade island built nearby to ease overcrowding) -- starting at $150,000 for a studio or $250,000 for a family home, said Olthuis.
The modular units are constructed in a local shipyard, then towed to the floating city. Once in position, they are attached to a large underwater concrete hull, which is screwed to the seabed on telescopic steel stilts that let it gently fluctuate with the waves. Coral reefs that surround the city help to provide a natural wave breaker, stabilizing it and preventing inhabitants from feeling seasick.
Olthuis said that the potential environmental impact of the structure was rigorously assessed by local coral experts and approved by government authorities before construction began. To support marine life, artificial coral banks made from glass foam are connected to the underside of the city, which he said help stimulate coral to grow naturally.
The aim is for the city to be self-sufficient and have all the same functions as one on land. There will be electricity, powered predominantly by solar generated on site, and sewage will be treated locally and repurposed as manure for plants. As an alternative to air conditioning, the city will use deep water sea cooling, which involves pumping cold water from the deep sea into the lagoon, helping to save energy.
By developing a fully functioning floating city in the Maldives, Olthuis hopes this type of architecture will be propelled to the next level. It will no longer be ""freak architecture"" found in luxurious locations commissioned by the super-rich, but an answer to climate change and urbanization, that's both practical and affordable, he said.
""If I, as an architect, want to make a difference, we have to scale up,"" he said.",4
19,"The Long Tail: The Internet and the Business of Niche
The Long Tail Investing Framework: 2005 vs. 2022
This is a weekly newsletter about how tech and culture intersect. To receive Digital Native in your inbox each week, subscribe here:
The Long Tail
Let’s play a game. Take a look at the two companies below and tell me which is the better business:
Company A: Company A is a content platform founded in 1997. Last year, it did $30 billion in revenue, +18% year-over-year. It has 225 million users and spent $19 billion on content in 2021.
Company B: Company B is also a content platform. It was founded in 2005. Company B also did $30 billion in revenue last year, +46% year-over-year, and has 2.6 billion users—but unlike Company A, Company B didn’t spend money making that content. Instead, users produce content for the platform.
Which is the better business model? You probably answered Company B, which crowdsources content production instead of shelling out $19 billion a year.
Company B is YouTube and Company A is Netflix. They are the two leading content platforms in the world, and both companies did about $30 billion in revenue last year. But they did so with dramatically different business models.
This isn’t a perfect exercise, of course. YouTube pays creators 55% of advertising revenue, which is effectively its cost of content. The 225 million figure for Netflix, meanwhile, is its paying subscriber count, while the 2.6 billion figure for YouTube is monthly active users. If you assume the average Netflix account is used by ~3 people, that means there are 775 million Netflix users. Still, ARPU (Average Revenue Per User) differs greatly: for YouTube, it’s about $11.50; for Netflix, it’s about $38.70.
But directionally, this exercise is helpful and interesting. The basic principle stands: Netflix pours billions into expensive content, while YouTube taps the world’s creativity. Netflix is a business built on heavy-hitters (expensive productions like Stranger Things, The Witcher, and Squid Game), while YouTube is built on volume—500 hours of video are added every minute. YouTube is built on the long tail.
The Origins of the Long Tail
The concept of the long tail was popularized by Chris Anderson in an October 2004 article in WIRED. Anderson’s opening lines read like a prophecy of YouTube, which would be founded the following year:
“Forget squeezing millions from a few megahits at the top of the charts. The future of entertainment is in the millions of niche markets at the shallow end of the bitstream.”
I’ve written in the past about another quote in WIRED, one that didn’t age quite so well. In 2005, the media mogul Barry Diller declared:
“There is not that much talent in the world. There are very few people in very few closets in very few rooms that are really talented and can’t get out.
People with talent and expertise at making entertainment products are not going to be displaced by 1,800 people coming up with their videos that they think are going to have an appeal.”
Yikes. It turned out that there was a lot of talent in the world—many people in many closets in many rooms. The same year that Barry Diller uttered those words, YouTube was born in a small room above a pizzeria in San Mateo. On April 23, 2005, the first YouTube video was posted. The video is titled “Me at the zoo” and features YouTube cofounder Jawed Karim…at the zoo. In the 18-second clip, he talks about elephants and their trunks 🐘
The concept of the long tail remains one of the best investing frameworks for internet companies. Many of the most successful technology companies in history have been built on the long tail. Google and Facebook turn to small businesses for the lion’s share of their advertising revenue. Ebay grew by tapping into a variety of niche interests and markets. Some of our most successful investments at Index have harnessed the power of niche: Etsy showed that a lot of people are interested in buying (and making) artisanal products; GOAT showed that sneakers are a deceptively large market; Discord has 19 million (!) weekly active servers.
One of the powers of the long tail is its ability to expand selection. Amazon might be the best example. As Anderson put it in 2004:
What’s really amazing about the Long Tail is the sheer size of it. Combine enough non-hits on the Long Tail and you’ve got a market bigger than the hits. Take books: The average Barnes & Noble carries 130,000 titles. Yet more than half of Amazon’s book sales come from outside its top 130,000 titles.
The same held true for movies: the average Blockbuster in 2004 carried fewer than 3,000 DVDs, but Netflix was getting 20% of its revenue from rentals outside its top 3,000 titles. And the same held in music too: Spotify, founded in 2006, built its business on expanding music to effectively infinite selection.
With the long tail, all of a sudden you could venture beyond the bestseller lists, instead discovering that little-known gem of a book with only a few dozen copies in print. But for long tail companies to succeed, they need to ensure that niche products are in stock when you need them; if you went to order that little-known gem of a book on Amazon and could never get it, your customer experience would degrade rapidly. This is why companies like Amazon have best-in-class inventory management systems.
In many ways, long tail platforms are more egalitarian than their hits-focused counterparts; in Anderson’s words in WIRED:
As egalitarian as Wal-Mart may seem, it is actually extraordinarily elitist. Wal-Mart must sell at least 100,000 copies of a CD to cover its retail overhead and make a sufficient profit; less than 1 percent of CDs do that kind of volume. What about the 60,000 people who would like to buy the latest Fountains of Wayne or Crystal Method album, or any other non-mainstream fare? They have to go somewhere else.
We’ve seen this play out on the internet. When the crowd gets to vote with dollars and eyeballs, new forms of content and commerce suddenly become popular. When more selection is available, customer preferences and interests become much more readily apparent than when tastes are curated by a handful of executives. Would K-pop be as big as it is today if tastes were still defined by radio stations? BTS dominates the charts despite getting almost no radio play.
Another facet of the long tail—paired with this greater selection—is that the long tail helps customers discover new products. Here’s a very 2004 graphic from WIRED:
Over the past two decades, “Data is the new oil” has become an oft-used refrain in tech. If you know a customer likes Britney, it becomes easier to surface similar songs from Pink and No Doubt.
Recommendations have become a massive part of the successful long-tail companies. Recommendations (and paid placement) on Amazon dictate the flows of billions of dollars spent on commerce; Netflix and YouTube algorithms shape culture; and Spotify’s recommendation-based playlists move music.
Refreshing the Framework
The two major categories for the long tail framework are content and commerce.
Let’s start with content. TikTok is the best modern extension of this framework. Building on the concept of recommendations, TikTok’s For You Page is entirely algorithmically-generated, tailor-made to the user’s tastes and preferences. And TikTok’s built-in creation tools make producing content easier, enabling the long tail to be even longer than it is on YouTube.
TikTok relies heavily on remix culture, allowing people to build on each other’s sounds and trends; this removes the friction to create that exists even with robust creation tools (“What video should I make?”) and leads to a stunning amount of creativity. My favorite example is this hilarious video:
Essentially, a man posted a video with his girlfriend and TikTok decided that the girlfriend looked…less than willing to be in the video. So, naturally, TikTok assumed she was being held hostage. Thousands of people began to duet the video to build on the premise—we see her hands tied in rope, then we see a SWAT team at the door ready to break it down, then we see a news crew outside reporting on the scene, then we see her mother crying and pleading for her daughter’s safety. It’s brilliant, and a great example of what happens when you crowdsource the entire world’s creativity.
As creation gets even easier, the long tail will continue to lengthen. Innovations like Midjourney, DALL-E, and StableDiffusion—which provide text to image AI generation—may unlock new levels of creativity and expression. This will shift content even more away from the handful of big-budget hits, and more to the long tail of creators.
The concept of the long tail also extends to commerce. We’ve come a long way from Amazon in 2004. Take Shopify: the vast majority of Shopify merchants—about 97%—have annual sales under $1M.
And about 99% of Shopify stores have fewer than 100,000 unique visitors per month.
Shopify is built on the long tail—on serving the many, many small merchants out there that comprise the lion’s share of global retail.
The fact that Shopify is built on the long tail drives other new business models. Openstore, for instance, is a company that acquires Shopify stores in cash. As a merchant, you get a nice payday; Openstore then streamlines your operations and grows your brand. Openstore’s ultimate vision is to roll up all acquired brands into one cohesive brand.
There are dozens of Amazon roll-up companies with a similar concept (Thrasio is the largest).
We also see the long tail in businesses like Pietra that enable creators (or any marketing-savvy entrepreneur) to launch a product line. Pietra expands who can start a product line—you no longer have to be Kylie Jenner or Rihanna to start a beauty empire—thereby crowding in new business creation that otherwise wouldn’t exist.
Just as Shopify made it easier to launch an online storefront, Pietra makes it easier to launch a digitally-native product line, abstracting away the complexities of manufacturing, inventory management, and fulfillment.
Another example of a modern startup building for the long tail is Faire. Faire is a B2B marketplace that connects brands and wholesale retailers. Think of all the cute local shops you see around—those retailers need to source their products from somewhere. Merchants used to need to go to in-person trade shows, which were inefficient and expensive. Now, they can source products on Faire’s marketplace.
Faire hits on the key components of long tail businesses: Faire improves selection by giving retailers a much greater variety of potential brands to choose from, and vice versa. And Faire takes a data-driven approach to improve the experience: Faire can tell you that a similar retailer in Milwaukee had a lot of success with a sustainable candle brand, so you should give it a try too.
When you add up the long tail—the more than 1 billion videos viewed on TikTok every day; the more than 1,000,000 storefronts on Shopify; the 250,000 retailers and 30,000 brands on Faire—the long tail businesses often dwarf the businesses built only for the Goliaths.
Final Thoughts
There’s one characteristic that many of the most successful internet businesses share: they create more jobs through their platform than the company could ever directly employ. For instance, Shopify has 10,000 employees—but Shopify likely provides the foundation for 10 million jobs by enabling merchants to run and operate a storefront. (There are over 1,000,000 Shopify stores, many with multiple employees.) Or take YouTube, which employs 2,800 people. There are over 306,000 YouTube channels with over 100,000 subscribers (!), meaning there are hundreds of thousands—maybe millions—of creators making a living on YouTube.
My friend Chris Paik calls this “off-balance sheet operating leverage.” Can a company enable an entire ecosystem to form on top of it? Companies that have off-balance sheet operating leverage are often the companies that rely on the long tail.
Nearly two decades after Chris Anderson wrote that piece in WIRED—nearly 20 years after YouTube, Spotify, and Shopify came to life—the long tail framework remains one of the best frameworks through which to evaluate technology businesses. Two decades into the modern consumer internet, we’re still learning just how extensive and vibrant the long tail can be—and chances are, it will continue to surprise us.
Sources & Additional Reading
The Long Tail | Chris Anderson, WIRED (2004)
Understanding the Long Tail Theory of Media Fragmentation | Scott Baradell
Thanks for reading! Subscribe here to receive Digital Native in your inbox each week:",1
20,"Emma Wylde
Director of Sales and Marketing
The Cadogan, A Belmond Hotel, London
+44 208 089 7010emma.wylde@belmond.com
This year, The Cadogan is delighted to announce its partnership with esteemed Harley Street Hypnotherapist and Sleep Expert, Malminder Gill. With over 70% of the nation admitting to struggling with insomnia over the last nine months, falling asleep has never been more of a problem for so many. With guests’ comfort and relaxation at the heart of importance, this naturally fitting partnership comes to fruition with the re-opening of The Cadogan this spring.
The Sleep Concierge is a brand-new service exclusive to guests at The Cadogan, who will be delighted to find a sleep-inducing meditation recording available in their rooms via the hotel app, recorded by Malminder. The Sleep Concierge also includes a pillow menu with a choice of luxurious pillows to suit guests who might prefer to sleep on their back or side, the option of a weighted blanket, a bedtime tea developed by The Cadogan specifically for the Sleep Concierge, and a scented pillow mist to support the best possible night’s sleep.
Malminder Gill has over 15 years’ experience in sleep and managing anxious thoughts to aid rest and relaxation, she comments ‘As a Chelsea local, partnering with The Cadogan feels like a wonderful and organic fit. Sleep is the most important thing we can learn to master, and when staying in one of The Cadogan’s sumptuous suites, guests can listen to my exclusive recording and drift off.’ Malminder has also recorded an uplifting morning motivation recording to set guests up for the day ahead.
General Manager of The Cadogan, Xavier Lablaude Comments on the partnership, ‘After a truly challenging year for all, we are excited to welcome our guests back to The Cadogan and be able to offer them the best night’s sleep they’ve ever had!’
For a more personalised experience, guests can book a 1-2-1 with Malminder Gill in person, for an in-room appointment if they book in advance.
The Cadogan, A Belmond Hotel, London
+44 208 089 7010emma.wylde@belmond.com",2
21,"The AI War and How to Win It
The battle for the future of the world
The AI War
The next era of war and deterrence will be defined by AI. The AI winner of this decade will be economically and militarily dominant for the next 50 years. The faster that we confront this reality, the faster we can act in ensuring America does not lose.
The gist of this post is:
AI will disrupt warfare.
China is currently outpacing the United States (for which there are numerous supporting facts).
The United States, both the government and AI technologists, need to start acting.
The AI War is at the core of the future of our world. Will authoritarianism prevail over democracy? Do we want to find out?
The Ukraine war is already demonstrating that the tech stack for war has changed. Technologies including drones, AI-based targeting and imagery intelligence, and Javelin missiles have allowed for a shocking defense of Ukraine against Russia, despite their nearly $300B in defense spending over the past 5 years.
The future is clear—AI-powered targeting and autonomous drones will define warfare. AI applied to satellite imagery and other sensor data has already enabled targeting and tracking of Russian troops and generals. Our legacy military platforms, while still important, will be disrupted by cheaper autonomous drone fleets. Aircraft carriers are giant targets in the sea compared to autonomous, adaptive drone swarms.
We are in the midst of a renaissance of AI in the commercial sector. In the past few years, breakthroughs have enabled AI systems to generate imagery, text, code, and even reason. The pace of AI research is following its own Moore’s law—every 2 years, the number of AI papers published per month doubles. As venture capitalists ogle over the potential of Generative AI to change knowledge work, we are not addressing the obvious application of AI towards military power, and the very clear risks that America will be outpaced.
A recent AI system, CICERO, achieved human-level performance in Diplomacy, a strategy game requiring negotiation and manipulation of other human players. This result, along with dominance of AI in chess, go, and poker, paint a precursor to the future of war. An AI warfighter will handily dominate an adversary through strategic brilliance, faster decision-making, and greater situational awareness. What’s more, autonomous drone fleets (air, sea, and land) will tactically outcompete human operators in velocity and coordination. While this hasn’t happened yet, it is only a matter of time. Based on the pace of progress with AI technology today, I believe this is less than 10 years away.
All that will matter in a future conflict is our technology—AI will devise, execute, and update our combat strategy. Our technology is our strategy.
There is precedent for technological disruption of warfare. I grew up in Los Alamos, New Mexico, the birthplace of the atomic bomb. The development of nuclear weapons in 1942 ushered in a new era of the nature of war and deterrence, and is one of the largest contributors to the Pax Americana, the unprecedented relative peace in the world since the end of World War II.
The continuation of Pax Americana rests upon our ability to navigate and maintain the lead in the AI race, which in turn will ensure the military and economic leadership of America. The facts today on our relative standing against China are not good, and need to be confronted head-on. We will not win by standing still.
The China Threat
China deeply understands the potential for AI to disrupt warfare and ultimately overtake the USA, and is investing heavily to capitalize on the opportunity. Let’s walk through some facts.
Fact 1: China considers AI as a “historic opportunity” for “leapfrog development” of national security technology, per China’s 2017 National AI Development Plan.
Their belief is AI will rhyme with how China surpassed America in fintech, where the American mature existing financial services industry and regulations ultimately enabled China to race ahead with a more digital and AI-enabled fintech stack.
More specifically, they believe that the United States will fall into a classic Innovator’s Dilemma. We will over-invest in mature systems and platforms, and underinvest in new disruptive technologies such as AI that would make our mature systems vulnerable or obsolete. Meanwhile, China, less encumbered by an existing defense industrial base, will race far ahead on AI.
Their long-term vision for how AI will disrupt the battlefield is also clear, and they are investing to accomplish it. As one Chinese official has said1:
“In future battlegrounds there will be no people fighting. By 2025 lethal autonomous weapons [will] be commmonplace and ever-increasing military use of AI is inevitable. We are sure about the direction and that is the future…
Mechanized equipment is just like the hand of the human body. In future intelligent wars, AI systems will be just like the brain of the human body. AI may completely change the current command structure, which is dominated by humans to one that is dominated by an ‘AI cluster.’”
Fact 2: This is already happening—China is outspending the United States on AI technology for defense, both in absolute terms and proportionally.
China’s military arm, the People’s Liberation Army (PLA), spent between $1.6B and $2.7B on AI against an overall defense budget of $178B in 20202, whereas the US Department of Defense (DoD) spent only between $800M and $1.3B on AI against an overall DoD budget of $693B over the same period3.
China is spending between 1% and 1.5% of their military budget on AI while the United States is spending between 0.1% and 0.2%. Adjusted for the total military budget, China is spending 10x more than the United States.
Fact 3: This is against a backdrop that in many DC wargames of the past few years, China wins.
The quotes are damning:
“The United States gets its ass handed to it”
“We are going to lose fast”
“China ran rings around us… they knew exactly what we were going to do before we did it”
And this isn’t even because of AI—it’s due to China’s already advanced intelligence, cyber, and electronic warfare capabilities, and an American hardware portfolio of fighter aircrafts and aircraft carriers that are mismatched to a conflict in the Indo-Pacific region. As a spoiler, these problems do not get better with AI.
Fact 4: From a pure technological standpoint, China has already surpassed the United States in computer vision AI, and is a fast follower on large language models (LLMs).
China is showing that in tactical AI capabilities, such as computer vision for greater sensing and awareness, they are handily ahead. And while America currently leads on more strategic AI systems, such as LLMs which will underpin future command-and-control systems, China is at most 1 year behind.
The current top 5 algorithms on the global leaderboard for image recognition on COCO (the established benchmark) all come from Chinese companies and universities.4
In a global 2022 challenge on aerial imagery object detection in haze, one of the most blatant military applications of computer vision technology (battlefield object detection), the first, second, fourth, and fifth place winners were all Chinese companies or universities, with the sole foreign challenger being a Korean University.
And in large language models (LLMs), which are the current state-of-the-art in natural language understanding and reasoning, they are fast followers to the leading American company OpenAI. The Beijing Academy of Artificial Intelligence (BAAI) and Tsingua University released a bilingual English & Chinese model GLM-130B in August of 2022 that outperforms GPT-3 175B, the leading American model. Now, OpenAI has been improving their technology for an upcoming release, but regardless the Chinese firms are within 1 year of the United States.
Fact 5: China has also been shown to heavily use social media manipulation and disinformation in Taiwan, particularly during elections.
They will show no mercy in using modern generative AI of both text and imagery to massively amplify their ability to sow division within the country and discredit US military activities. Below, I used GPT-3 to generate a fake article about the United States renouncing support of Taiwan. As you can see, the technology is incredibly effective.
Fact 6: China has already shown willingness to implement AI ruthlessly for government purposes, most notably in facial recognition for Uyghur suppression.
China has developed an ecosystem of AI startups (Yitu, SenseTime, Megvii, and CloudWalk) which developed algorithms to track Uyghurs in Xinjiang. While bone-chilling, it is not hard to draw the line from their development of facial recognition AI to China leapfrogging the US in military AI technology, and using that technology to further its authoritarian regime.
Fact 7: Perhaps the greatest concern is the time pressure in this race imposed by the potential invasion of Taiwan in the next 5 years.
There is a high risk of a Taiwanese invasion within the next 5 years, and it could even be as soon as 2023 according to the US Chief of Naval Operations, Michael Gilday.
An invasion of Taiwan would force our hands—we would need to fight with whatever military capability we have at the time, and we do not want to be caught flat-footed on AI.
How to Win It: AI Overmatch
The United States needs to change our trajectory on AI for defense. We are falling behind on AI, and with it losing American leadership.
I propose a strategy for AI Overmatch to ensure that we have an overwhelming advantage on AI. What follows are some clear recommendations for quickly increasing our pace and winning. To those new to the topic of the AI War, these recommendations might seem overly specific—that is intentional. Surgical action is needed to reignite our engines.
We must recognize that our current operating model will result in ruin. Continuing on our trajectory for the next 10 years could result in us falling irrecoverably far behind. Why do large organizations often continue on the path to their demise, even if the future is painfully obvious? The reason is inertia—bureaucracies will continue to glide deep into the abyss for an eternity.
Recommendation 1: Data supremacy is an absolute requirement for the AI war.
Tactically speaking, AI always boils down to data. Every instantiation of deep learning has been ridiculously data-hungry, and recent results show that even large language models, which are often trained on most of the internet, are data-starved (Chinchilla scaling).
The success of an AI modernization is dependent on building and maintaining data supremacy. If you observe how the tech giants (Google, Facebook, Amazon, etc.) maintain their algorithmic leads versus their competitors, it all stems from runaway data advantages.
For defense AI, the internet is not enough. Most will need to come through our military assets and sensors. America has by far the largest fleet of military hardware. If we can successfully turn this platform advantage into a data advantage through an investment into data infrastructure and data preparation, we can get ahead and stay ahead.
It’s important to call out—we are not ahead today. Most of the data within the military gets thrown away, or lives on hard drives that will never see the light of day. The scale of our military fleet is currently not contributing to data supremacy.
In May 2021, the Deputy Secretary of Defense Kathleen Hicks released a memorandum for the DoD to create a data advantage, kicking off the creation of the Chief Digital and AI Office (CDAO). That is only a start to a Herculean, yet critical effort. We either will build data supremacy, or we will invariably lose in the long-run.
Recommendation 2: AI-enabled capabilities will be 10x more lethal and effective in a decade. We need to have a 10-year plan to shift 25% of the DoD budget towards AI-enabled capabilities by 2032.
We need to match China’s ability to plan on long, 10-year time horizons. It’s imperative that we begin charting a long-term path towards dominance in defense AI.
Given any existing military capability, it will be more lethal, effective, and efficient if enabled with AI and autonomy. As the technology improves, it is not an exaggeration to say that AI will enable 10x gains. Some simple examples:
A fully autonomous drone swarm will be nearly impossible to subdue or disarm, and doggedly pursue any objective it is given. As we’ve seen in Ukraine, an effective drone can neutralize nearly any adversary—and a dominant AI agent will be able to outmaneuver even an AI-enabled foe.
AI-enabled intelligence and automated target recognition will limit the fog of war. We will be able to immediately identify targets and neutralize them faster than any adversarial human could react. As Sun Tzu once said, “Know your enemy, know yourself, and in one hundred battles, you will never be in peril.”
By the end of the decade, any military capability that is not AI-enabled will be rendered nearly useless against an AI-enabled adversary, just as Russia’s tanks have shown to be inept. It would be silly to continue investing in non-AI capabilities when they will clearly be outdone. We can be sure China is thinking along the same lines, as their public statements match a 10-year time horizon for AI-enabled warfare.
The clock must start ticking. Either we will modernize our existing military capabilities with AI, or we need to retire them and make room for new AI-enabled capabilities.
We will be caught flat-footed unless we start charting a path to the future where AI is at the core of our warfighter, both at tactical and strategic levels. We cannot afford to invest into non-AI systems.
Recommendation 3: The United States needs to disrupt itself with AI Grand Challenges within the Department of Defense.
The largest AI program within the Department of Defense is still Project Maven, which was started in 2017. In the past 5 years, the United States has still not started, let alone operationalized, a major AI capability that could disrupt our current warfighter. We are falling perfectly into the trap that China has called out—we are too focused on maintenance of legacy technology to invest into disruption.
This is untenable. The United States needs to act quickly in starting up and dramatically accelerating more programs to fund AI Grand Challenges. We are running out of time before a future Taiwanese invasion, and we need to get started now if we want any AI to be deployed in time.
There are a number of candidates for transformational AI Grand Challenges:
AI for all-source intelligence
AI battle planning and COA generation
AI for cyber vulnerability detection
AI for automated target recognition for missiles
Any of these could be critical capabilities in future conflicts—we just need to pick a few and get started.
Without seriously funding some AI Grand Challenges, we are running out of time and allowing China to leapfrog us. The United States is spending less than 0.2% of our military budget on development of AI technology—we should look towards rapidly 10x-ing our investment through these Grand Challenges.
Let’s stop experimenting with AI. Let’s build production AI programs with mission relevance.
Recommendation 4: The United States needs to invest into rapidly training and skilling our military commanders and personnel on AI.
Even with advancements in technology—humans always pay the price of war. Even with AI, wars will be fought by people. The United States invests heavily to ensure that its military has the best equipment, training and leadership in the world. Investments in AI should be no different.
Beyond simply training service members on AI fundamentals, the United States should train commanders & personnel to use AI as the component that will make multi-domain warfare a reality. Commanders must know how to use data as a military asset to fuel AI Overmatch.
Historically, the country that can integrate new technologies into warfighting concepts and doctrine dominates. There’s no reason to believe this will be different. The Department of Defense needs a revamp of doctrine and warfighting concepts that recognize the AI-enabled future, not simply bolt AI on to concepts from the last war.
At Scale, we are fully committed to supporting the United States and its allies. This is one of the few true missions of our time. We cannot sit by the sidelines and watch the rise of an authoritarian regime. It is in moments like this that technologists can either rise to the challenge, or stand idle.
In the tech industry, we often talk about missions. They are often frivolous—do they really change the world or save lives? This mission, on the other hand, really fucking matters. The AI War will define the future of our world. Will future generations live under authoritarianism or democracy?
We have been active in working with the Department of Defense, and developing products for what we believe to be defining technologies of the future of AI warfare. I intend to share many of these technologies in the coming months, especially given the deafening urgency of the current situation.
I encourage my fellow technologists to recognize the austerity and severity of our times, and commit themselves to defending America. While I find it shocking that most American AI companies have not chosen to support national security, I do hope others join us.
We have to fight for the world we want to live in. It’s never mattered more.
Thanks for reading Rational in the Fullness of Time! Subscribe for free to receive new posts and support my work.",3
22,fastcompany.comPlease enable JS and disable any ad blocker,9
23,"The public library is the new WeWork
The public library is the new WeWork
The Future. Sorry, WeWork. Coworking is upgrading to an old-school option, public libraries. They are quickly providing the space, amenities, and ethos to create a valuable workspace and a communal hub that keeps people socially connected in an increasingly isolated world. But without the proper support and funding, the library makeover may just be another good idea that doesn’t reach its full potential.
Quiet, upgraded
With libraries prevalent in cities, suburbs, and small towns, Insider thinks they have the opportunity to become a perfect network of coworking hubs.
- Libraries in cities like Spokane, Akron, and Columbia are turning into bonafide community centers that can handle several aspects of remote-work life, adding business centers, recording studios, and meeting rooms.
- During COVID shutdowns, libraries offered drive-up internet access so that people could always have a dedicated broadband connection if they didn’t have one at home.
- Google partnered with the Library Association of America on Libraries Serving Businesses, a program that gave $2 million to 13 library networks last year to beef up amenities.
That’s not to say that libraries are totally prepared for entrepreneurs, freelancers, and remote workers everywhere to march in with their laptops. Melanie Huggins, president of the Public Library Association, notes that smaller libraries may not have the space, resources, or staff to handle such an influx.
Also, snacks. If libraries are to become the coworking spaces of the future, don’t just allow them, but reap the benefits by just opening a coffee shop inside. We all know it’s worked wonders for Barnes & Noble.",1
24,"How AI Will Completely Dominate the Animation Industry In Less Than 5 Years
If you're looking to get into animation as a career, you have less than 5 years.
Welcome to The Cusp: cutting-edge AI news explained in simple English.
In this week's issue:
- AI animation is now definitively better than humans.
- Some huge studios are beginning to use AI in production.
- Why most animators/artists have < 5 years left.
- What you can do to future-proof yourself.
Let's dive in.
First: you're probably going to lose your job
If you're looking to get into animation as a career, you probably have less than five years to build your career.
Why?
- DALL-E 2 and other AI art models can now produce a near-infinite variety of illustrations using a simple text prompt. By 2025, they'll outperform human artists on every metric.
- AI animation models already exist that can take a static illustration and ""imagine"" different movements, poses, and frames. You can make the Mona Lisa smile, laugh, or cry - and there's nothing stopping you from doing that to other images, too.
- AI video models are right around the corner. Soon, studios will be able to create smooth videos of any framerate with nothing more than a text prompt. Short films will be next.
If Toei Animation (the studio in charge of One Piece and DBZ) is already doing it... you should probably take it seriously.
To be entirely clear: what I am saying is that this is not an industry with staying power. You will lose your job, or at the least, fall prey to a significant reduction in pay and upward mobility.
And there's really nothing you can do about it.
The financial incentives
AI-based animations can be produced cheaply, quickly, and with far less manpower than traditional hand-drawn or computer-generated animations. And as these technologies continue to develop and be refined, the price difference will only grow larger.
Let's drastically oversimplify this by looking at DALL-E 2's recent fee model.
Looking at the numbers, it now costs ~$0.13USD to generate 4 images. This price will probably plummet as competing models make it into the fore, but we'll be conservative and assume it stays fixed.
If it takes eight generations to find one image you're happy with, you're still only paying approximately a quarter, or $0.26USD, for a piece of art equivalent to a high-quality commission.
Contrast this with the cost of a traditional commission artist just three or four years ago. If said artist charged $25/image, the price difference is already inescapably large: it's almost 100x cheaper to use AI.
But many artists would have charged five or ten times that amount, making the difference closer to 1000x cheaper. A few still do, because they haven't seen the writing on the wall - and they're wondering why sales are plummeting and no one seems interested in their stuff anymore.
Speed & iterability
But it's not just about the money. With AI, you can also get results much faster. DALL-E 2 can generate images in real-time, meaning you don't have to wait for hours or days for a response.
This is, and will continue to be, crucial to the success of any animator or studio. One of the most important parts of the job is quickly testing concept art before deciding on an approach.
DALL-E 2, for instance, significantly shortens this loop: it lets designers and illustrators iterate on an idea before investing the time and money into expensive animation. The next illustration (or perhaps video) model will be able to do so even faster, and with far greater fidelity.
To sum it up: there's simply no future for human animators, commission artists, or illustrators in an AI-enabled economy.
A bridge: animation models
A likely course of events: before full video AI is developed (and by full video AI, I mean the industry-destroying kind that you'll be able to prompt with ""scene of a darker, grittier Naruto killing a ninja""), animation agencies and production studios will shift more of their operations to generating static AI images first using a model like DALL-E 2, and then applying a living portrait-style model (to cut costs and stay competitive).
To reiterate, as studios around the world wait for complete video AI to be developed, they'll bridge the gap with a two-step pipeline: the first step will static images of objects/characters, and the second will ""imagine"" the various frames, angles, and movements they'll engage in. See Crypko, below, for an example.
Perfect vs. good enough
Animation models won't be perfect, at least not for the next few years. But they don't need to be. Even rough line drafts (full of errors) would more than halve the amount of time traditional animators need to spend on their work, doubling their capacity and making the market that much harder to break into for artists.
This is already happening, by the way: motion capture technology, a nascent and inefficient form of animation AI, is routinely used to significantly improve the value of a single static image.
Just look at the recent V-tuber craze as an example. AI generated animation allows people to multiply the utility of a single drawn frame, increasing accessibility and lowering the barrier to entry for animators considerably.
... which sounds great as an artist, until you realize this also eliminates the value of humans in that same marketplace.
NeRF
Another fascinating development is Neural Radiance Fields (NeRF).
In recent years, many animation studios have shifted to producing the majority of their artwork in 3D, and then either tracing or rendering the result directly. This has several advantages:
- It is cheaper to produce: you need far fewer artists per scene
- It eliminates the need for expensive and time-consuming rotoscoping
- Scenes with many independently moving characters, like crowds or large-scale battles, can be created much faster
AI will accelerate this approach. In particular, NeRF can now be used to create realistic 3D environments of static characters and objects. Within a few years, animators will routinely use technology like this to render full 3D environments automatically, improving both their output and realism.
This will put immense pressure on animators and keyframers, who will have to drop prices considerably or learn to use motion capture themselves. Even then, their time will be limited.
Final thoughts: will AI replace animators?
Probably.
To be frank, I don't think this is a net negative for human society. Many incredible stories have been limited in scope by their ability to be animated. Berserk is a prime example.
By removing that bottleneck, writers and visionaries will be freed to craft and imagine even better stories. The next ten to twenty years will probably feature an era of human artistic abundance, where some of the greatest works of mankind will dwell on for eternity...
... at least until AI gets better than us at that, too.
Either way, there's no doubt this will significantly impact the job market. DALL-E 2 and the AI art movement is already causing a sizeable reduction in artist commissions, and that effect will soon trickle down into B2B and wider world.
If you fancy illustration or animation as a career, you should probably relegate that to hobby-status and work on something less easily-destroyable.",3
25,"BMW Makes Heated Seats an $18/Month Subscription Service—Again
BMW is asking owners in Korea to pay for subscription-based options like heated seats or driver-assistance software.
BMW has toyed with charging monthly subscriptions for certain digital ""Connected Drive"" options for a few years, testing the waters in different markets with different features. Korea is the latest market for subscription-based options, and customers can now pay monthly for physical options such as heated seats and a heated steering wheel.
As cynical as that might sound, Korean owners aren't forced to pay monthly for heated seats, or any of BMW's other available options, but monthly payments can be made to try those out. Heated seats, for instance, cost ₩24,000 (roughly $18) per month. But you can also pay for a year subscription ($176), a three-year subscription ($283), or you can buy the heated seats permanently ($406).
Some other options available with monthly or yearly subscriptions are a high beam assistant, BMW's Driving Assistance Plus software, a heated steering wheel, and an artificial noise generator to give electric cars like the i4 M50 a sci-fi noise while driving. Those will be available for different fees, and some can be added to a customer's car immediately via computer or smartphone.
There may be other avenues to enable the options, potentially. For something like heated seats, where the function is paywalled by software, I can easily see modders figuring out how to jailbreak the system and unlock the option for free. Volkswagen owners have done similar things to older VWs for more than a decade by using simple OBDII-based tools and laptops to unlock lighting modes and window functions, for instance. More recently, Ford Maverick owners learned they can unlock cruise control on entry-level Mavericks, simply by swapping out the steering wheel buttons and using some software.
So it isn't a stretch to assume BMW enthusiasts will figure out how to do the same thing for heated seats, heated steering wheels, and other options that the car already physically has equipped.
Got a tip? Send it in to tips@thedrive.com",8
26,"Internet domains for the popular Z-Library online eBook repository were seized early this morning by the U.S. Department of Justice, preventing easy access to the service.
Z-Library is ranked in the top 10k most visited websites on the Internet, offering over 11 million books and 84 million articles for free via its website.
Yesterday, the websites hosted at z-lib.org, b-ok.org, and 3lib.net began displaying a message stating that the service was seized by the US DOJ and the Postal Inspection Service, as shown below.
However, the U.S. Postal Inspector's office told BleepingComputer they were credited in the seizure notice by mistake.
Friday afternoon, the seizure notice on 3lib.net was updated to indicate the domains were seized by the FBI and the United States Attorney's Office for the Eastern District of New York.
""This domain has been seized by the Federal Bureau of Investigation in accordance with a warrant issued pursuant to 18 U.S.C. § 981(b) and 21 U.S.C. § 853(f) by the United States District Court for the Eastern District of New York as part of a law enforcement action,"" reads the seizure notice.
WHOIS information initially showed that the U.S. government seized the domains and switched their DNS servers to NS1.SEIZEDSERVERS.COM and NS2.SEIZEDSERVERS.COM, two DNS servers commonly used by the U.S and law enforcement in domain seizures.
However, since then, the DNS servers for these domains have been switched to Njalla, an anonymizing hosting provider. It is unclear how Z-Library could transfer the domains to the new hosting provider.
Name Server: 1-YOU.NJALLA.NO Name Server: 2-CAN.NJALLA.IN Name Server: 3-GET.NJALLA.FO
Even though the clearnet sites are still unavailable, the Z-Library is still accessible via its Tor Onion address. However, there is now a notice informing visitors of server problems that may render the service temporarily unavailable.
While the court order for the seizure is unavailable at this time, the site's domains were likely seized because many of the files were uploaded without the license of the original authors.
Furthermore, when BleepingComputer contacted the US DOJ with questions about the law enforcement action and the seizure of the domains, they declined to comment.
However, complaints to copyright protection offices in the past have resulted in legal actions forcing the platform's registrar to seize the Z-Library domains in 2015 and further domain blockages and DMCA notices in the U.S. and France in 2021.
The USTR (United States Trade Representative) has recently launched an investigation on the platform, causing social media platforms where users promoted Z-Library to be more cautious with what is allowed.
As reported by TorrentFreak last week, TikTok decided to block hashtags related to Z-Library, reportedly responding to copyright holder's complaints.
""Reducing user discoverability of content that violates our Community Guidelines is of paramount importance,"" stated TikTok.
""Accordingly, TikTok proactively blocks search results for terms that violate our Community Guidelines, including terms that relate to counterfeit goods […]. We also recently blocked search results for #zlibrary while our team assesses content associated with that hashtag.""
At the time of writing this, the Z-Library channel on TikTok remains accessible, now counting 1.5 billion views.
Z-Library started in 2009 as a free file-sharing platform for academic texts and scholarly journal articles, initially acting as a mirror for Library Genesis (Libgen).
Soon though, users started uploading content outside Libgen, so Z-Library gradually became a separate entity while remaining a non-profit, donation-backed platform.
The platform’s infrastructure of globally dispersed servers hosting a database of over 220 TB was supported by paid memberships, while users received unlimited downloads and file conversion perks in return.
At this time, little is known about the platform's operators and commercial status, so Z-Library will likely return to the clearnet using a different set of domains, or possibly even the same ones.
Update 11/4/22 04:04 PM ET: Article updated with new seizure notice by the FBI and United States Attorney's Office for the Eastern District of New York.
Update 11/6/22 08:22 PM ET: Added reply from the US Department of Justice.
Not a member yet? Register Now
Comments
SuperNuts - 4 weeks ago
Library Genesis still going strong.
Kescarte_DeJudica - 4 weeks ago
Probably because it's a Russian website.
secalertsasia - 3 weeks ago
Works perfectly fine via the onion URL
ricrok - 3 weeks ago
Hi how does one access the onion, please. newbie
DexFaqOrigin - 3 weeks ago
Search ""Tor Project"" on Google or whatever search engine you prefer, then download and install it from the homepage. It should let you access onion sites just fine, except the loading speed would be damn low enough which makes you feel your ISP sucks.
Also add extra VPN stuff if you like.",5
27,"Sacred Hours.
The Future Does Not Fit in the Containers of the Past. Edition 104.
Every week contains 168 hours of which 100 hours are spent asleep and at work allowing for the rest of life to fit in 68 hours.
For many the remaining 68 are filled with a hurly burly of responsibilities from child to elder care, cooking, cleaning, errands, medical appointments, commutes and more.
The few free minutes in between are often buffeted with headlines, social media streams looking to colonize our minds and a dozen competing claims on our time and attention.
No wonder that so many feel stressed, fatigued, and frenzied.
As William Wordsworth wrote:
“The world is too much with us; late and soon,
Getting and spending, we lay waste our powers; “
A special hour every day.
Some of the most contented and satisfied individuals regardless of their station in life or the pressures on their time and attention, have found a way to create an oasis of stillness and a special sanctuary that helps center them, grow them, and makes each day meaningful regardless of what the world of commerce and competition might bring in setbacks, challenges, and pressures.
They set aside an hour every day for themselves. Not their work, not their families, not for all those who clamor for it or to tackle a list of never-ending to-dos which when allowed to will absorb all free time.
An hour earmarked and blocked by them to spend on themselves.
It might be spent learning, reading, exercising, thinking, meditating, walking.
It is solitary and it is special.
A sacred hour.
Some may think of this hour as a selfish hour but is an hour that allows individuals to be effective and productive in all the remaining hours of their day whether it be at their jobs or tending to their family and social obligations.
Finding 7 hours a week for oneself.
Surely one cannot be serious that one can find almost a working day of hours for oneself every week?
While not easy there are a combination of four different tactics that one can utilize to free up much more time than seven hours a week depending on one’s responsibilities and flexibilities.
The four tactics are
a) Zero based calendaring to eliminate the unnecessary.
b) Delegation to mitigate the pressures of the necessary.
c) Reduction of frequencies of meetings.
d) Compression of time allocated to a task.
Zero based calendaring.
In “A Moveable Feast” Ernest Hemingway’s love song to the incredible city of Paris he writes…” If you could keep from making appointments, each day had no limits”
There is nothing as invigorating as an empty calendar. It does not mean that one is not needed but one has the freedom and liberty to spend the day in the way that is most meaningful versus being shackled to a merry-go-round wheel of motion and action that often feign to be important, special, and essential.
What if one begins with an empty calendar wiped clean of all appointments and then transfers only those that you really believe are critical to this new clean calendar? Ask your colleagues and bosses how many of the meetings are just habit and are not necessary or could be a memo or held less frequently.
Just like work expands to fill time available appointments occur to fill one’s calendar.
Start with zero and build back versus trying to trim the bursting to seam calendars that resemble a barnacle encrusted underside of a ship.
Delegation.
The best leaders run positive “Ponzi” schemes. They surround themselves with people better and more competent than them and hand down as many of their responsibilities that they can and encourage them to do the same to the next level.
Everybody is stretched and growing, and their bosses can stretch and grow to the next level.
If one is doing too much it may mean that the people around us are not good enough or we are not growing and stretching them and so in time we will lose them.
We should delegate and do less.
Focus on one’s superpowers, growing others and thinking about the long term.
Reduction of frequency of meetings.
Business reality requires budget to status to board meetings for a variety of reasons from fiduciary to the necessary.
But can the weekly meeting be moved to twice a month or maybe once a month?
Does everyone have to attend every meeting?
If presence at a meeting is the way a pecking order is established at a company, we should wonder if this attracts talent or insecure politicians.
Less is more.
Compression of time allocated to a task.
One of the silver linings of the tragedy of Covid is that one can move from meeting to meeting by moving one’s “mind parts” without physically moving one’s “meat parts”.
This saves a lot of time in travel and other logistics.
Most Boards now meet once every six months in person while meeting virtually in between.
In addition to reducing the need for physical presence at all meetings we may also want to consider reducing the time for each meeting by a third or half. Pre-reads and tight management can significantly cut the time allocated without any significant loss in impact.
Personally, we might shave off a few minutes from our social media usage or Netflix use to enable finding time for our sacred hour.
How to make the most of one’s sacred hours.
With a little discipline one can find an hour a day for oneself and often more.
How one spends it depends on each one of us but blocking out an hour for oneself every day and ideally utilizing is early as possible before the pressures of the day make one lose control of the best laid plans is ideal.
If every individual looks after themselves, they can do a much better job at their jobs and caring for others.
Because in the end time is all we have and the way we spend our time is the way we spend our lives.
And living our lives as pinballs in a game where someone else is controlling the flippers may be filled with the excitement of velocity and blinking lights but is it our life?
For a few sacred hours let’s make it so.
Photography of The Great Ocean Road, Australia by Rishad Tobaccowala.
Thanks for reading The Future Does Not Fit In The Containers Of The Past! Subscribe for free to receive new posts every Sunday.
Rishad Tobaccowala is an author, advisor, speaker, and educator who distills four decades of experience to help people see, think, and feel differently so they can grow their companies, their teams and themselves. More about Rishad’s advisory services, best-selling book, and the range of topics of 10 popular workshops can be found here…https://rishadtobaccowala.com/
Thank you for the concept and ways to practice ""sacred hour"". I am sure it will have a long-term impact on one's growth and development.
Loved the concept of sacred hour. We may do it on and off but putting that name to that one hour can make hell lot of difference. Thank you",1
28,"Airlines' next struggle? Where to plug in their planes
Travelers know how hard it can be to find a plug at the airport to charge a phone or laptop. Now airlines are facing a similar challenge as they electrify their ground and air operations.
Why it matters: Even the largest airports don't have enough juice to quickly charge all the electrified planes, flying taxis and ground equipment that airlines intend to roll out over the coming years.
- Stationary power storage — meaning, gigantic industrial batteries — will help fill the gap.
Driving the news: United Airlines this week bought an undisclosed stake in energy storage company Natron Energy, making it the first airline to invest directly in a battery manufacturer.
- Natron makes trailer-size sodium-ion batteries that can charge electric airport ground vehicles, such as baggage tractors and pushback tugs.
- These batteries can recharge vehicles more quickly than today's lithium-ion batteries — an advantage at busy airports, where vehicle uptime is key.
- Longer term, United expects such batteries to power short-range electric aircraft, such as regional planes and urban air taxis.
Where it stands: United has electrified about 30% of its ground equipment, but is running into power constraints at some hubs.
- ""These airports weren't built for electrifying at this scale,"" says Mike Leskinen, president of United's investment arm, United Airlines Ventures (UAV).
- Airports will eventually build a more robust infrastructure using renewable energy, he predicts. ""But when the wind is blowing and when the sun is shining isn't always exactly when you need the peak load.""
- Natron's battery storage system helps solve that problem.
Zoom out: Aviation accounted for more than 2% of global energy-related CO2 emissions in 2021, and its share is growing faster than road, rail or shipping, according to the International Energy Agency.
- Many big airlines have set ambitious sustainability goals to achieve net zero emissions by 2050. But traditional carbon offsets, such as planting trees, won't be enough to meet those targets.
Most are looking to replace jet fuel with sustainable aviation fuel (SAF) made from agricultural or forest waste, algae or even used cooking oil.
- UAV, which invests in sustainability and customer experience startups, has stakes in or has agreed to purchase fuel from several SAF producers.
- United was also the first airline to invest in a biofuel refinery, NEXT, which plans to open a facility in Oregon in 2026.
Yes, but: SAF is still a long way from widespread commercial availability — which is why airlines are looking for other ways to meet their goals, such as electrifying smaller planes and ground equipment.
What to watch: United has also invested in newfangled aircraft companies like Boom Supersonic, which is designing super-fast planes meant to run on SAF, and Heart Aerospace, which is developing a 30-seat hybrid electric aircraft to serve smaller markets within 200 miles of United's hubs.
- And it has stakes in a couple of electric air taxi companies: Archer Aviation and Eve Air Mobility, a spinoff of Embraer.
The bottom line: Electrifying ground vehicles is a heck of a lot easier than building a cleaner airplane — so airlines like United are starting on terra firma.",2
30,"Credit: Rob Deslongchamps/Cincinnati Art Museum
'Magic mirror': Hidden image revealed in reflection of centuries-old artifact
Amid the thousands of treasures in the Cincinnati Art Museum's East Asian art collection, a small bronze mirror dating back to the 15th or 16th century always seemed rather unremarkable.
Last exhibited in 2017, it had spent much of the preceding decades in storage, where it sat on a backroom shelf alongside other objects excluded from public display.
But the artifact had a secret hiding in plain sight.
While researching so-called ""magic mirrors"" -- rare ancient mirrors that, in certain light, reveal images or patterns hidden on their reflective surfaces -- the museum's curator of East Asian art, Hou-mei Sung, saw something resembling the examples from Edo-period Japan.
The item in storage in Cincinnati, Ohio, was smaller than the ones held in museums in Tokyo, Shanghai and New York City. It also featured a more complex style of Chinese script. Yet, Sung recalled there was something ""very similar"" about it.
So, last spring, she visited the museum's storage rooms accompanied by a conservation expert.
""I asked her to shine a strong, focused light on the mirror,"" Sung said on a video call from Cincinnati. ""So, she used her cell phone (flashlight) and it worked.""
On the wall before them was the appearance of texture in the reflected light -- not a distinct image, but enough to warrant further investigation. Following experiments using more powerful and focused lights, the mirror eventually revealed the image of a Buddha, rays of light emanating from his seated form. The inscription on the mirror's back spells out who was depicted: Amitabha, an important figure in various schools of East Asian Buddhism.
The discovery makes the museum one of only a handful of institutions in the world to own a magic mirror, according to Sung. The curator is only aware of three others in possession of rare Buddhist-themed ones, including the Metropolitan Museum of Art in New York.
""We were so excited,"" Sung said.
Ongoing mystery
Before the invention of today's glass mirrors, people from cultures around the world gazed into polished bronze, from ancient Egypt to the Indus Valley. The ancient art of Chinese magic mirrors was first developed during the Han dynasty, around 2,000 years ago, though they were also later made in Japan.
To create the mysterious effect, artisans began by casting images, words or patterns onto one side of a bronze plate. Scientists believe they then scratched and scraped the plain surface on the other side, before polishing it until it became reflective like a conventional mirror. Because the plate was of varying thickness, due to the embossed design, the process created very slight changes in curvature on the seemingly blank mirrored side. A mercury-based substance was then used to make additional surface stresses that were invisible to the naked eye but matched the elaborate patterns on the back, according to an article in the UNESCO Courier journal.
When sunlight hits the reflective surface in a certain way, a hidden image -- matching the design on the back -- would be revealed, giving the illusion that light was passing right through the mirror. For this reason, they are known in Chinese as ""transparent"" or ""light-penetration"" mirrors. (In the case of the Cincinnati Art Museum's discovery, however, a second metal plate was likely soldered onto the back, leaving the original embossed Buddha concealed inside.)
The mirrors baffled Western scientists who encountered them in the 19th century. And while their optics are now broadly understood, Sung said experts still don't know precisely how craftspeople worked the metal.
""No matter how much you can explain theoretically, it all depends on the master who polishes the surface which is tremendously difficult,"" she said. ""That's why they are so rare.""
Measuring about 8.5 inches in diameter, the museum's mirror was likely used as a religious ornament and may have hung in a temple or noble household. The museum is yet to decipher whether it originated in China or Japan, though Sung believes it is most likely the former.
The item was first recorded in the museum's Asian art collection in 1961, though the curator thinks it may have been acquired long before then. She also suspects that other institutions and collectors are in possession of magic mirrors without realizing.
""I found a lot in online auctions that have a similar design to ours, but (the auction listings) never say they're magic mirrors,"" she said, adding: ""I believe there could be some mirrors out there that people don't even know are magic.""
The mirror will be on display at the Cincinnati Art Museum from July 23.",3
31,"Blueprint for an AI Bill of Rights
MAKING AUTOMATED SYSTEMS WORK FOR
THE AMERICAN PEOPLE
Navigate this Section
Among the great challenges posed to democracy today is the use of technology, data, and automated systems in ways that threaten the rights of the American public. Too often, these tools are used to limit our opportunities and prevent our access to critical resources or services. These problems are well documented. In America and around the world, systems supposed to help with patient care have proven unsafe, ineffective, or biased. Algorithms used in hiring and credit decisions have been found to reflect and reproduce existing unwanted inequities or embed new harmful bias and discrimination. Unchecked social media data collection has been used to threaten people’s opportunities, undermine their privacy, or pervasively track their activity—often without their knowledge or consent.
These outcomes are deeply harmful—but they are not inevitable. Automated systems have brought about extraordinary benefits, from technology that helps farmers grow food more efficiently and computers that predict storm paths, to algorithms that can identify diseases in patients. These tools now drive important decisions across sectors, while data is helping to revolutionize global industries. Fueled by the power of American innovation, these tools hold the potential to redefine every part of our society and make life better for everyone.
This important progress must not come at the price of civil rights or democratic values, foundational American principles that President Biden has affirmed as a cornerstone of his Administration. On his first day in office, the President ordered the full Federal government to work to root out inequity, embed fairness in decision-making processes, and affirmatively advance civil rights, equal opportunity, and racial justice in America.[i] The President has spoken forcefully about the urgent challenges posed to democracy today and has regularly called on people of conscience to act to preserve civil rights—including the right to privacy, which he has called “the basis for so many more rights that we have come to take for granted that are ingrained in the fabric of this country.”[ii]
To advance President Biden’s vision, the White House Office of Science and Technology Policy has identified five principles that should guide the design, use, and deployment of automated systems to protect the American public in the age of artificial intelligence. The Blueprint for an AI Bill of Rights is a guide for a society that protects all people from these threats—and uses technologies in ways that reinforce our highest values. Responding to the experiences of the American public, and informed by insights from researchers, technologists, advocates, journalists, and policymakers, this framework is accompanied by From Principles to Practice—a handbook for anyone seeking to incorporate these protections into policy and practice, including detailed steps toward actualizing these principles in the technological design process. These principles help provide guidance whenever automated systems can meaningfully impact the public’s rights, opportunities, or access to critical needs.
Safe and Effective Systems
You should be protected from unsafe or ineffective systems. Automated systems should be developed with consultation from diverse communities, stakeholders, and domain experts to identify concerns, risks, and potential impacts of the system. Systems should undergo pre-deployment testing, risk identification and mitigation, and ongoing monitoring that demonstrate they are safe and effective based on their intended use, mitigation of unsafe outcomes including those beyond the intended use, and adherence to domain-specific standards. Outcomes of these protective measures should include the possibility of not deploying the system or removing a system from use. Automated systems should not be designed with an intent or reasonably foreseeable possibility of endangering your safety or the safety of your community. They should be designed to proactively protect you from harms stemming from unintended, yet foreseeable, uses or impacts of automated systems. You should be protected from inappropriate or irrelevant data use in the design, development, and deployment of automated systems, and from the compounded harm of its reuse. Independent evaluation and reporting that confirms that the system is safe and effective, including reporting of steps taken to mitigate potential harms, should be performed and the results made public whenever possible.
From Principles to Practice: Safe and Effective Systems
Algorithmic Discrimination Protections
You should not face discrimination by algorithms and systems should be used and designed in an equitable way. Algorithmic discrimination occurs when automated systems contribute to unjustified different treatment or impacts disfavoring people based on their race, color, ethnicity, sex (including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual orientation), religion, age, national origin, disability, veteran status, genetic information, or any other classification protected by law. Depending on the specific circumstances, such algorithmic discrimination may violate legal protections. Designers, developers, and deployers of automated systems should take proactive and continuous measures to protect individuals and communities from algorithmic discrimination and to use and design systems in an equitable way. This protection should include proactive equity assessments as part of the system design, use of representative data and protection against proxies for demographic features, ensuring accessibility for people with disabilities in design and development, pre-deployment and ongoing disparity testing and mitigation, and clear organizational oversight. Independent evaluation and plain language reporting in the form of an algorithmic impact assessment, including disparity testing results and mitigation information, should be performed and made public whenever possible to confirm these protections.
From Principles to Practice: Algorithmic Discrimination Protections
Data Privacy
You should be protected from abusive data practices via built-in protections and you should have agency over how data about you is used. You should be protected from violations of privacy through design choices that ensure such protections are included by default, including ensuring that data collection conforms to reasonable expectations and that only data strictly necessary for the specific context is collected. Designers, developers, and deployers of automated systems should seek your permission and respect your decisions regarding collection, use, access, transfer, and deletion of your data in appropriate ways and to the greatest extent possible; where not possible, alternative privacy by design safeguards should be used. Systems should not employ user experience and design decisions that obfuscate user choice or burden users with defaults that are privacy invasive. Consent should only be used to justify collection of data in cases where it can be appropriately and meaningfully given. Any consent requests should be brief, be understandable in plain language, and give you agency over data collection and the specific context of use; current hard-to-understand notice-and-choice practices for broad uses of data should be changed. Enhanced protections and restrictions for data and inferences related to sensitive domains, including health, work, education, criminal justice, and finance, and for data pertaining to youth should put you first. In sensitive domains, your data and related inferences should only be used for necessary functions, and you should be protected by ethical review and use prohibitions. You and your communities should be free from unchecked surveillance; surveillance technologies should be subject to heightened oversight that includes at least pre-deployment assessment of their potential harms and scope limits to protect privacy and civil liberties. Continuous surveillance and monitoring should not be used in education, work, housing, or in other contexts where the use of such surveillance technologies is likely to limit rights, opportunities, or access. Whenever possible, you should have access to reporting that confirms your data decisions have been respected and provides an assessment of the potential impact of surveillance technologies on your rights, opportunities, or access.
From Principles to Practice: Data Privacy
Notice and Explanation
You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you. Designers, developers, and deployers of automated systems should provide generally accessible plain language documentation including clear descriptions of the overall system functioning and the role automation plays, notice that such systems are in use, the individual or organization responsible for the system, and explanations of outcomes that are clear, timely, and accessible. Such notice should be kept up-to-date and people impacted by the system should be notified of significant use case or key functionality changes. You should know how and why an outcome impacting you was determined by an automated system, including when the automated system is not the sole input determining the outcome. Automated systems should provide explanations that are technically valid, meaningful and useful to you and to any operators or others who need to understand the system, and calibrated to the level of risk based on the context. Reporting that includes summary information about these automated systems in plain language and assessments of the clarity and quality of the notice and explanations should be made public whenever possible.
From Principles to Practice: Notice and Explanation
Human Alternatives, Consideration, and Fallback
You should be able to opt out, where appropriate, and have access to a person who can quickly consider and remedy problems you encounter. You should be able to opt out from automated systems in favor of a human alternative, where appropriate. Appropriateness should be determined based on reasonable expectations in a given context and with a focus on ensuring broad accessibility and protecting the public from especially harmful impacts. In some cases, a human or other alternative may be required by law. You should have access to timely human consideration and remedy by a fallback and escalation process if an automated system fails, it produces an error, or you would like to appeal or contest its impacts on you. Human consideration and fallback should be accessible, equitable, effective, maintained, accompanied by appropriate operator training, and should not impose an unreasonable burden on the public. Automated systems with an intended use within sensitive domains, including, but not limited to, criminal justice, employment, education, and health, should additionally be tailored to the purpose, provide meaningful access for oversight, include training for any people interacting with the system, and incorporate human consideration for adverse or high-risk decisions. Reporting that includes a description of these human governance processes and assessment of their timeliness, accessibility, outcomes, and effectiveness should be made public whenever possible.
From Principles to Practice: Human Alternatives, Consideration, and Fallback
Applying the Blueprint for an AI Bill of Rights
While many of the concerns addressed in this framework derive from the use of AI, the technical capabilities and specific definitions of such systems change with the speed of innovation, and the potential harms of their use occur even with less technologically sophisticated tools.
Thus, this framework uses a two-part test to determine what systems are in scope. This framework applies to (1) automated systems that (2) have the potential to meaningfully impact the American public’s rights, opportunities, or access to critical resources or services. These Rights, opportunities, and access to critical resources of services should be enjoyed equally and be fully protected, regardless of the changing role that automated systems may play in our lives.
This framework describes protections that should be applied with respect to all automated systems that have the potential to meaningfully impact individuals’ or communities’ exercise of:
Rights, Opportunities, or Access
Civil rights, civil liberties, and privacy, including freedom of speech, voting, and protections from discrimination, excessive punishment, unlawful surveillance, and violations of privacy and other freedoms in both public and private sector contexts;
Equal opportunities, including equitable access to education, housing, credit, employment, and other programs; or,
Access to critical resources or services, such as healthcare, financial services, safety, social services, non-deceptive information about goods and services, and government benefits.
A list of examples of automated systems for which these principles should be considered is provided in the Appendix. The Technical Companion, which follows, offers supportive guidance for any person or entity that creates, deploys, or oversees automated systems.
Considered together, the five principles and associated practices of the Blueprint for an AI Bill of Rights form an overlapping set of backstops against potential harms. This purposefully overlapping framework, when taken as a whole, forms a blueprint to help protect the public from harm. The measures taken to realize the vision set forward in this framework should be proportionate with the extent and nature of the harm, or risk of harm, to people’s rights, opportunities, and access.
[i] The Executive Order On Advancing Racial Equity and Support for Underserved Communities Through the Federal Government. https://www.whitehouse.gov/briefing-room/presidential-actions/2021/01/20/executive-order-advancing-racial-equity-and-support-for-underserved-communities-through-the-federal-government/
[ii] The White House. Remarks by President Biden on the Supreme Court Decision to Overturn Roe v. Wade. Jun. 24, 2022. https://www.whitehouse.gov/briefing-room/speeches-remarks/2022/06/24/remarks-by-president-biden-on-the-supreme-court-decision-to-overturn-roe-v-wade/",2
32,nytimes.comPlease enable JS and disable any ad blocker,9
33,"This groundbreaking motionless wind turbine is 50% more efficient than regular turbines
Commercial property owners can fulfill the rising demand for on-site renewable energy thanks to a revolutionary bladeless wind energy solution that can be integrated with current solar energy systems and building electrical systems, thanks to Aeromine Technologies.
""Aeromine Technologies' patented motionless wind harvesting system generates up to 50 percent more energy at the same cost as rooftop solar PV,"" says the company.
Standing out with its motionless, Aeromine is very respectful to nature — it does not make noise and does not harm or kill birds.
The technology uses aerodynamics similar to race car airfoils to capture and amplify each building's airflow. The stationary, silent, and durable Aeromine unit generate energy around the clock in any weather while taking up only 10 percent of the roof space required by solar panels.
They can generate up to 100 percent
Aeromine systems are made up of 20-40 units installed on the edge of a building in the direction of the predominant wind. The combination of Aeromine's wind solution and rooftop solar, designed to work seamlessly with a building's existing electrical system, can generate up to 100 percent of a building's onsite energy needs while minimizing the need for energy storage.
""This is a game-changer adding new value to the fast-growing rooftop power generation market, helping corporations meet their resilience and sustainability goals with an untapped distributed renewable energy source,"" said Aeromine CEO David Asarnow, a veteran of the climate technology industry.
""Aeromine's proprietary technology brings the performance of wind energy to the on-site generation market, mitigating legacy constraints posed by spinning wind turbines and less efficient solar panels.""
There is plenty of room for existing solar and utility infrastructure on a building's roof, thanks to the Aeromine system's modest footprint. It gives owners of commercial properties a useful new weapon in their pursuit of energy independence in the face of rising energy costs and demand for amenities like electric vehicle charging stations.
BASF Corporation, which is evaluating the Aeromine system at its manufacturing site in Wyandotte, MI, is one of the companies testing the new technology.
""Creating a better way to harvest the power of wind""
Aeromine Technologies explains itself as ""understanding the untapped potential of wind energy and limitations of existing rooftop energy options to capture it, Aeromine’s founders envisioned a better solution that would be much more productive.
The innovation represents a significant step up over earlier dispersed wind turbines, which are inadequate for most rooftop installations. The creators of Aeromine have developed a significantly more efficient method to exploit even mild wind to generate electricity for sizable, flat rooftop structures like warehouses, data centers, office buildings, and apartment buildings.
Science has stepped in to prove biblical events happened – not for the first time either.",2
34,"Meta’s game-playing AI can make and break alliances like a human
It could be a step toward building AIs that can handle complex problems requiring compromise.
Meta has created an AI that can beat humans at an online version of Diplomacy, a popular strategy game in which seven players compete for control of Europe by moving pieces around on a map. Unlike other board games that AI has mastered, such as chess and Go, Diplomacy requires players to talk to each other—forming alliances, negotiating tactics—and spot when others are bluffing.
The AI, called Cicero, ranked in the top 10% across 40 online games against 82 human players (who were not aware they were competing against a bot). In one eight-game tournament involving 21 players, Cicero came first. Meta described its work in a paper published in Science.
Learning to play Diplomacy is a big deal for several reasons. Not only does it involve multiple players, who make moves at the same time, but each turn is preceded by a brief negotiation in which players chat in pairs in an attempt to form alliances or gang up on rivals. After this round of negotiation, players then decide what pieces to move—and whether to honor or renege on a deal.
At each point in the game, Cicero models how the other players are likely to act based on the state of the board and its previous conversations with them. It then figures out how players can work together for mutual benefit and generates messages designed to achieve those aims.
To build Cicero, Meta marries two different types of AI: a reinforcement learning model that figures out what moves to make, and a large language model that negotiates with other players.
Cicero isn’t perfect. It still sent messages that contained errors, sometimes contradicting its own plans or making strategic blunders. But Meta claims that humans often chose to collaborate with it over other players.
And it’s significant because while games like chess or Go end with a winner and a loser, real-world problems typically do not have such straightforward resolutions. Finding trade-offs and workarounds is often more valuable than winning. Meta claims that Cicero is a step toward AI that can help with a range of complex problems requiring compromise, from planning routes around busy traffic to negotiating contracts.
Deep Dive
Artificial intelligence
Why Meta’s latest large language model survived only three days online
Galactica was supposed to help scientists. Instead, it mindlessly spat out biased and incorrect nonsense.
DeepMind’s game-playing AI has beaten a 50-year-old record in computer science
The new version of AlphaZero discovered a faster way to do matrix multiplication, a core problem in computing that affects thousands of everyday computer tasks.
A bot that watched 70,000 hours of Minecraft could unlock AI’s next big thing
Online videos are a vast and untapped source of training data—and OpenAI says it has a new way to use it.
Google’s new AI can hear a snippet of song—and then keep on playing
The technique, called AudioLM, generates naturalistic sounds without the need for human annotation.
Stay connected
Get the latest updates from
MIT Technology Review
Discover special offers, top stories, upcoming events, and more.",3
35,"When I discuss my research, no one argues that, when trying to improve something, we don’t often subtract. Listeners nod knowingly when I mention how we pile on “to-dos” when we really need “to-stops,” or how we create incentives for good behavior … but don’t get rid of obstacles to it. It rings true when I mention that federal regulations are 17 times as long as they were in the 1950s; and that, in patent titles, “additive” synonyms are used about three times as often as “subtractive” ones. Adding, as the default, feels intuitive.
One reason why, as my colleagues and I have shown in our new research: People think first about adding and, as a result, systematically overlook subtractive changes. This finding was consistent and rigorous enough to be featured on the cover of Nature. And if the reaction in mainstream media, on Twitter, and in my old-fashioned face-to-face discussions is any indication, everyone seems to agree that it’s a big problem to neglect a basic way to introduce change in a system.
There is, however, an argument I keep encountering. And it comes against something I’ve never claimed, which is that subtracting is better than adding. It’s an easy strawman to build. After all, I’ve worked on the aforementioned research, the title of my book is Subtract, and I’ve been introduced as a “subtraction czar.” So, to head off any confusion, I have learned to mention early and often that there are meetings, regulations, and even freeways that should most certainly NOT be subtracted.
That said, if subtracting is roughly as useful as addition — yet is used far less often — then there is untapped potential. After all, Pablo Picasso defined art as the “elimination of the unnecessary.” The more that is added, the more opportunities for artistic elimination. Here’s a more concrete example. All around the world, pocket parks are making cities more livable. These tiny parks are typically “built” by subtracting a single (often derelict) building. What makes these parks special is the adding that surrounds them. In a concrete jungle, they are a green oasis. This same principle applies at different scales and across objects, ideas, and situations. The sculpted iPhone delights users in a world of feature creep. Removing an all-hands meeting carves out space for deep work from otherwise jam-packed calendars. Meditation brings wisdom to podcast-saturated minds.
To harness this untapped power of subtraction in the future, we need to understand why we haven’t embraced it in the past. One likely reason adding has become our first instinct is that we live in a world that has conditioned and rewarded this mental shortcut. As any armchair physicist can tell you, we are surrounded by a universe that is endlessly adding complexity, following the second law of thermodynamics. Biologically, our animal drive to acquire resources (like food) and to demonstrate competence (by visibly shaping our surroundings) can pull us toward more. Certainly, as thinking humans, we don’t have to blindly follow the path laid out by physics or evolution. But even if we resist thermodynamics and our instincts, more recent cultural forces also work against subtraction. Human civilization is practically defined by addition: of technologies, of education, of culture.
We’ve been adding for a long time, and for a long time it’s made sense. But our instincts to add and cultures of more are now crowding our minds, cities, and schedules. The problem is in how we think — and luckily, so are the remedies — including one that is at the root of why I’m constantly reminding people that focusing on subtracting doesn’t mean I’ve got anything against adding.
The false dichotomy of add OR subtract
To stop overlooking a basic kind of change, to tap into the power of subtraction — whether for our minds, organizations, and cities — we need to go from thinking add or subtract to thinking add and subtract. The add or subtract framing forces us to try and resolve an apparent contradiction. If A is true, then not-A must be false. If I like subtracting, then I must not like adding. Resolving contradiction is not a bad thing. Doing so has aided reasoning at least since Aristotle, who held that if one idea contradicted another, then one of the ideas had to be rejected.
We have this logical reasoning to thank for all sorts of scientific breakthroughs: everything from our single, repeatable, biological classification system to the mathematical logic that led to modern computers.
So it’s working, right? Well, not entirely. The problem comes when we try to resolve contradiction between ideas that aren’t actually in conflict. As we’ve seen, the question is not whether biological or cultural forces explain our adding. Both play an overlapping role in our failure to subtract. Arguing about which is the true culprit only wastes time and distracts us from learning how we might do better. The question is not, “Should we add or subtract?”, it’s “How do we use both?” Our Nature research shows that people often add but then quickly move on, failing to consider even superior, higher-order subtractions. That jump right to adding wouldn’t necessarily be a problem if people then considered subtracting. If more makes things better, then maybe less can too.
This shift to an add AND subtract mindset is hard, but not impossible. If you take your design inspirations from science, try changing your metaphor. Be less like the second law of thermodynamics, endlessly adding. Instead, channel evolution, which makes use of both additive adaptations and subtractive selections. Then, new meetings on your calendar are something to try, and to select out when they become useless appendixes. If you prefer mathematical motivation, consider that less can literally be more net change. Imagine you edit four lines of code by adding one. Now that you have five lines of code, one line represents 20% of the total. But if you change those four lines of code by subtracting one, then you are left with three lines of code, and one represents 33% of the total. Relative to the end state, the exact same change is larger when it brings you to less. Finally, if you prefer pithy quotes, consider one attributed to the Chinese philosopher Lao Tzu that has stood the test of time (because we otherwise overlook subtraction): “To gain knowledge add things every day; to gain wisdom subtract things every day.”
Now as ever, there is no single approach, not to change our schedules or our minds, and not to improve our inventions or our political systems. Hopefully more people will come to recognize adding and subtracting as complementary approaches to introducing and understanding change. In the meantime, remember those pocket parks. Because the more people who overlook subtraction, the greater the rewards for those who don’t.
Join the Newsletter
Technology, innovation, and the future, as told by those building it.
Views expressed in “posts” (including articles, podcasts, videos, and social media) are those of the individuals quoted therein and are not necessarily the views of AH Capital Management, L.L.C. (“a16z”) or its respective affiliates. Certain information contained in here has been obtained from third-party sources, including from portfolio companies of funds managed by a16z. While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the enduring accuracy of the information or its appropriateness for a given situation.
This content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice. You should consult your own advisers as to those matters. References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services. Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to invest in any fund managed by a16z. (An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund and should be read in their entirety.) Any investments or portfolio companies mentioned, referred to, or described are not representative of all investments in vehicles managed by a16z, and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results. A list of investments made by funds managed by Andreessen Horowitz (excluding investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets) is available at https://a16z.com/investments/.
Charts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. Past performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. Please see https://a16z.com/disclosures for additional important information.",2
36,"Futures Canvas is a participatory tool
for collective speculation and envisioning futures together
for collective speculation and envisioning futures together
Pick a challenge and create together new visions for relevant future topics. Let your imagination run wild and explore and expand our ideas about the possibilities for a better tomorrow. Develop stories and ideas for solutions as we move toward a more just and sustainable future.",2
38,"Drag this link to your bookmarks bar: Katamari!
Or copy and paste this url into the location bar on any site:
(works best in chrome or firefox 4)
This is a ""bookmarklet"" that turns any page into Katamari Damacy. Try clicking the Katamari! link above.
This was the winner of the 2011 Yahoo HackU contest at University of Washington.
Short version: css transforms (for things stuck to the katamari), canvas (drawing the katamari), and z-index (illusion of depth).
Long version: The bookmarklet loads jQuery and kh.js into
the current page. jQuery is used mostly for
.offset() and
.css().
kh.js is where all the action happens:
StickyNodes::addWords)
StickyNodes::finalize). Essentially
grid[floor(x / 100)][floor(y / 100)]is a list of elements in a 100x100 pixel block. This should probably be an R-tree, but the hot-spot in this program is definitely in the rendering.
position: absolute; left: x; top: y;). See
PlayerBall::drawBall.
-webkit-transform. The transform rotates the element about the rolling axis of the katamari and scales the element to make it look like it's coming out of the page. See
PlayerBall::drawAttached, transform_test.html, and transform_test2.html.",2
40,"Science & Tech
‘A.I. Should Exclude Living Artists From Its Database,’ Says One Painter Whose Works Were Used to Fuel Image Generators
The digital artist Greg Rutkowski has seen his style copied in thousands of images created using artificial intelligence.
Text-to-image art generators fueled by artificial intelligence (A.I.) have spurred lively debates about the purported end of society’s need for trained visual artists. The technology has already launched a bevy of amateur artists who make use of A.I., including Reid Hoffman, the founder of the employment platform LinkedIn. He harnessed the platform DALL-E—and creator OpenAI’s commercial rights policy—to craft and sell a series of A.I.-generated artworks on the NFT marketplace Magic Eden. One sold for the equivalent of $24,000.
Now, established artists like Greg Rutkowski have been pulled into the debate. The Poland-based digital creator has illustrated fantasy scenes for well-known role-playing games, like Dungeons & Dragons and Magic: The Gathering. But his art has become so popular that many online fans are now using A.I. to mimic his style.
MIT’s Technology Review reports that Rutkowski’s name ranks among the most used prompts on Midjourney and Stable Diffusion, two popular open-access A.I. image generators, where users have input Rutkowski’s name 93,000 times. That is far more than users’ requests for images similar to the style of Michelangelo or Picasso, whose names have been employed as prompts no more than 2,000 times each. The platform Disco Diffusion even suggests his name as a sample prompt.
In an email to Artnet News, Rutkowski said he’d only discovered A.I.-made art a few months ago. “I’ve seen many of my art friends posting news about it, right before I started receiving messages that my name [was] being used as a prompt,” he explained. “I wasn’t really into A.I. as a tool to use or experiment with. Somehow, I haven’t considered it as a useful tool in my workflow.”
At first, Rutkowski considered his newfound popularity on the A.I. platforms an avenue to new audiences. But when ran a web search of his own name for other reasons, works in his style he’d had no hand in making turned up.
Text-to-image generators scour the web for images that provide the algorithms with visual knowledge. Rutkowski’s fantasy-inspired work naturally deals in subjects suited to A.I.’s purposes—creating otherwise impossible scenes.
However, as Technology Review pointed out, A.I. image scrapers inadvertently punish Rutkowski for his decision to make his work more accessible. The artist regularly uses alt text descriptions when he posts his images online to make them readable by visually impaired people. But that information also makes them easier to scrape for data, and easier for the A.I. algorithms to understand.
Stability.AI, the firm behind the platform Stable Diffusion, trained their algorithm on LAION’s dataset of more than 5 billion image-text pairings. The German nonprofit organization has excluded images with watermarks and non-art images like brand logos from its collection. But technologist and writer Andy Baio analyzed 12 million of the dataset’s images for Technology Review and found many come from sites like Pinterest and Fine Art America. Rutkowski’s work was likely scraped from his portfolio on ArtStation.
Despite the fact that its A.I. runs on a database of images harvested without the original creators’ permissions, Stability.AI’s license agreement frees them from responsibility for how their tech is used. Users of the A.I. must abide by a copyright infringement honor code, but there is no enforcement against rule breakers.
“A.I. should exclude living artists from its database,” Rutkowski said, and instead “focus on works under the public domain.” He adds that “there’s a huge financial issue in evolving A.I. from being nonprofit research to a commercial project without asking artists” for permission to use their work.
Technology Review cited the plight of Carolyn Henderson, who manages the art career of her husband Steve Henderson, a popular commercial artist who paints landscapes and figurative scenes. She has fought to remove the presence of his work from Stable Diffusion’s database, but her requests have been “neither acknowledged nor answered,” according to Technology Review. Rutkowski has had a similar experience, and has even entreated others to contact LAION directly—but still hasn’t heard back. “Since no one asked me to use my works in the first place, I haven’t got any help other than my art friends,” he said.
Artnet News is awaiting comment from LAION as well.
Follow Artnet News on Facebook:
Want to stay ahead of the art world? Subscribe to our newsletter to get the breaking news, eye-opening interviews, and incisive critical takes that drive the conversation forward.
Share",3
41,"Our support team is available to work with you to get the best counting results for your circumstances.
The Counting Template tells the app what to count.When we create Counting Templates, we use sample images to teach the app what to count.Accuracy and speed depend on the match between the image that you count and the visual environment of the sample images.Contact us to get Counting Templates optimized for your needs.
Position the camera so that the items you want to count:
In some cases, It is better to take the image from further away with a high zoom level than from close-up with a low zoom level. This minimizes distortion due to perspective.
Sometimes you cannot follow best practices, or we do not have Counting Templates to fit your items.We will work with you to create Counting Templates for your use-case.
We are adding Counting Templates regularly based on our clients’ use-cases. Contact us with your counting needs.
We use cookies in this website to give you the best experience on our site and show you relevant ads.
To find out more, read our privacy policy and cookie policy.
When you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies.
This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to.
The information does not usually directly identify you, but it can give you a more personalized web experience.
Because we respect your right to privacy, you can choose not to allow some types of cookies.
Click on the different category headings to find out more and change our default settings.
However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.
See here our cookie policy.
These cookies are necessary for the website to function and cannot be switched off in our systems.
They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms.
You can set your browser to block or alert you about these cookies, but some parts of the site will not then work.
These cookies do not store any personally identifiable information.
These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show your relevant adverts on other sites. They do not store directly personal information but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.",7
42,"If any lightfoot Clod Dewvale was to hold me up, dicksturping me and marauding me of my rights to my onus, yan, tyan, tethera, methera, pimp, I’d let him have my best pair of galloper’s heels in the creamsourer.
—James Joyce, Finnegans Wake
Though I grew up in the countryside, I’m not of direct farming stock, which may be why I learned of ‘yan tan tethera’ only quite recently. It’s an old counting system used traditionally by shepherds in parts of the UK, and also in knitting and fishing and so on, or by children for their own amusement.
The system seems to have been scattered around Britain, and its distribution and antiquity mean there’s a lot of variation in the forms it takes. The numbers’ names come from a Brythonic Celtic language, and they vary with dialect, geography, and other factors.
Wikipedia has what looks like a reasonably well-sourced article with many examples of the system; here are a few, alongside Welsh for comparison:
|No.||Wilts||Scots||Lakes||Dales||Welsh|
|1||Ain||Yan||Auna||Yain||Un|
|2||Tain||Tyan||Peina||Tain||Dau|
|3||Tethera||Tethera||Para||Edderoa||Tri|
|4||Methera||Methera||Peddera||Peddero||Pedwar|
|5||Mimp||Pimp||Pimp||Pitts||Pump|
|6||Ayta||Sethera||Ithy||Tayter||Chwech|
|7||Slayta||Lethera||Mithy||Leter||Saith|
|8||Laura||Hovera||Owera||Overro||Wyth|
|9||Dora||Dovera||Lowera||Coverro||Naw|
|10||Dik||Dik||Dig||Dix||Deg|
|11||Ain-a-dik||Yanadik||Ain-a-dig||Yain-dix||Un ar ddeg|
|12||Tain-a-dik||Tyanadik||Pein-a-dig||Tain-dix||Deuddeg|
|13||Tethera-a-dik||Tetheradik||Para-a-dig|| Eddero-
|
dix
|Tri ar ddeg|
|14||Methera-a-dik||Metheradik||Peddaer-a-dig|| Pedderp-
|
dix
|Pedwar ar ddeg|
|15||Mit||Bumfitt||Bunfit||Bumfitt||Pymtheg|
|16||Ain-a-mit||Yanabumfitt||Aina-a-bumfit||Yain-o-bumfitt||Un ar bymtheg|
|17||Tain-a-mit||Tyanabumfitt||Pein-a-bumfit||Tain-o-bumfitt||Dau ar bymtheg|
|18||Tethera-mit||Tetherabumfitt||Par-a-bunfit||Eddero-bumfitt||Deunaw|
|19||Gethera-mit||Metherabumfitt||Pedder-a-bumfit||Peddero-bumfitt||Pedwar ar bymtheg|
|20||Ghet||Giggot||Giggy||Jiggit||Ugain|
The Lakeland Dialect Society has a useful article written by Ted Relph about the yan tan tethera system that includes a nice summary of how it works:
There would seem to be a clear connection with counting on the fingers, particularly after getting to 10, as the best known local examples then go 1 and 10, 2 and 10, etc up to 15, then 1 and 15, 2 and 15, etc up to 20. The count invariably ended at 20. This was a ‘score’ and a scratch was then put in a stick or stone, and the count recommenced. In this way things were counted in scores. It is said that the shepherds, on reaching 20, would transfer a pebble or marble from one pocket to another, so as to keep a tally of the number of scores.
Several of the numbers are strongly suggestive of Welsh or Cornish, but their origins are complex, with the rhymes that were used as a mnemonic aid obscuring the derivation in some cases. A letter written by the great philologist Walter Skeat in 1907, and published in the West Sussex Gazette, gives some indication of the mixed etymology:
The original Celtic numerals were frequently forgotten, and their places supplied by words that were more or less founded on rhyme. And sometimes the Celtic words were supplemented by English ones. Owing to the corrupt forms that thus resulted, many of the formulae are of slight philological interest or value. That the original counting was in Celtic, chiefly appears from some forms that still remain. Thus the Welsh pump, five, explains the Eskdale pimp, and the Knaresborough pip, and others. The Welsh deg, ten, explains the forms dix, dec, dick, dik. But yan (whence yain, yaena, yah) is only a dialectal form of the English one. And tain, taena, tean are merely altered forms of two, whilst the rest of the word is made to rhyme: e.g. yain, tain, yaena, taena ; yan, tean ; yah, tiah ; and so on. The Welsh pedwar, four, has become first peddero (also pethera and pether) and afterwards meddera, methera, mether.
Yan tan tethera has crept into all sorts of cultural corners, though not so much in Ireland; Finnegans Wake is a notable exception, the sequence a natural fit with that book’s poetic promiscuity. It also shows up in album titles, art works, house signs and the like.
Finally, here’s a charming clip of the English poet, singer and storyteller Jake Thackray introducing and performing yan tan tethera in an autobiographical vein. See if you don’t end up humming the melody for the rest of the day.
And two further fine renditions, by folk singer Maz O’Connor:
and vocal trio Yan Tan Tether:
Lovely post, Stan, and a terrific clip – but it’s Jake, not Jack, Thackray.
Fixed. Thanks, Richard.
Good morning, (in the USA), Stan! Good afternoon to you in Ireland.
Thanks for an interesting post. For some reason, upon reading your chart comparing numbers in different dialects (the right term in this context?), I thought of biblical Hebrew, which I don’t know but with which I have a little familiarity due to my daily and considerable reading of the Bible, KJV 1611 version. However, my quick Google search did not yield the answer to my inquiry. You appear to be a linguist. My one graduate level course in linguistics permits me to understand some of what you write about the technical nature (etymology) of language. The short video you embedded is both entertaining and informative. Thanks! And, I wish you and your family a safe and happy Thanksgiving.
Lovely!
There are some interesting comments in this old LH thread.
Vinetta: Good morning and good afternoon to you further west (and good evening, since it’s turning dusky here already). I wouldn’t call them dialects, since each version of the system is a mixture of quite disparate dialects and languages. I’d call them versions or variations of an old counting system (that’s based chiefly on Celtic dialects). For the record, I’m not a linguist, though I have an abiding interest in the area; my educational background is in the life sciences. Happy Thanksgiving to you and your family too.
Jenni: Very! Thanks for stopping by.
LH: Ah yes. I should have searched your site for this – if any language blog was likely to’ve covered it, it’s yours. Of particular interest, and not mentioned in my post, are the folk song ‘The Lincolnshire Shepherd‘, this collection of regional variations, and these beautiful wood engravings.
[…] read this interesting post on the origins of the various, related counting systems used by shepherds in northern England, […]
Stan, thanks for this intriguing cross-cultural, (yet commonly rooted in Celtic dialect), comparison of related sheep counting methods in various British sheep rearing locales.
Jake Thackery ‘s wonderful musings on counting sheep, even connecting w/ his ancestral roots in his brief account of the ill-fated shepherdess, Molly Metcalfe, was thoroughly engaging.
Almost immediately, I was struck by Thackery’s sonorous, fairly monotone, deep basso-baritone voice, as well as his heavy-lidded, eyes; as if he were about to drift off to beddy-byes. Which got me pondering as to the possible efficacy of using this lyrical Gaelic sheep count… Yan. tan, tethera…etc. as a viable method of helping one doze off to slumberland.
Counting imaginary sheep was kind of an old-school option for insomniacs to fall asleep, back in the day; but w/ the array of readily available over-the-counter oral sleep aids such as melatonin, Lunestra*, Sominex, and the like, the sheep counting modality seems to have gone the way of the Dodo.
Hmm… counting Dodos? Now there’s a concept.
*Might need a prescription for that Lunestra.
Fascinating article.Love the video!
Alex: I found Thackray’s (note spelling) performance engaging too – even haunting, as a Twitter friend put it. It would be nice to think that people do actually count sheep to invite sleep.
Claude: Thank you! The video is one I’ve returned to quite a few times. A perfect match of story, song, and rich history.
Stan, thanks for Jake’s name clarification in your last reply. For me, (and I’m sure for scores of other readers), his surname immediately evoked the name of the much lauded Victorian era satirist, William Makepeace Thackeray… sans the “e”, of course.
So in my earlier offering of my ‘two-cents-worth’, I wanted to be sure to spell this raconteur’s name in the attached video, correctly. And sure enough, I blew it on two counts w/ my erroneous “Thackery”– spelling both the late Vanity Fair parodist, and this basso-profundo gent, Jake’s last names, incorrectly. Oh well.
I can appreciate your Twitter friend’s “haunting” take on Mr. Thackray’s subtly riveting performance. That bouncy, rhyming sheep-count does kind of linger in one’s noggin for a spell.
P.S.:—Happy Thanksgiving to all those celebrants out there. We truly all have much to be thankful for… including our blogmeister Stan, who allows us to openly commune, and share in our mutual love of words, word usage, word origins, word play, and the infinite wonders of our ever-evolving English tongue.
Stan, thanks for being there (and here… Ha!), and generously giving of yourself, each and every day.
Thanks, Alex McCrae, for giving a “shout-out” to Stan. He deserves it. Thanks, Stan!
Immense joy to read, watch, listen and learn. Thanks a lot, Stan.
[…] 38. Yan Tan Tethera Pethera Pimp – An Old System For Counting Sheep […]
Alex, Vinetta, thanks very much, and many happy returns.
Sean, I’m glad you enjoyed it. It would be nice to think that someone somewhere is still using the system for practical purposes out in the fields.
I have been contemplating this rhyming system for a long while as an illustrated book. This song just nails it!!
That sounds like a lovely idea, Amy. The melody is back in my head after I listened to Thackray’s version again yesterday.
Stan, quite apart from the very interesting post, thanks for introducing me to Jake Thackray, and Maz O’Connor. That’s a very evocative song.
You’re most welcome, Nurn. I’ve become fond of the tune too.
I can’t get over “bumfitt” and will use it every chance I get. To hell with 15.
XO
WWW
Thanks for sharing, Stan. It’s amazing to me that traces of Celtic have survived in English for so long.
WWW: To hell with 15. Ha ha. I’d love if it caught on.
Jonathon: Testament to the system’s utility and catchiness, maybe. It deserves to survive in some shape or form.
[…] classified; I was particularly struck by imberb “beardless”), obscure counting words like yan, tan, tethera, methera, pip, and miscellaneous […]
[…] of old language will like this one. Old numbering systems. There are some lovely words in there, but it isn’t hard to see how the modern equivalents […]
[…] from a wide variety of sources. The following is a bit of Theran culture that developed from a blog post by linguist Stan Carey. (He’s Irish, so that’s where I made my […]
[…] Shepard counting systems in Britain,
https://stancarey.wordpress.com/2013/11/27/yan-tan-tethera-pethera-pimp-an-old-system-for-counting-sheep […]
I’m wandering What zero (0) is in Scots",8
43,"Americans are increasingly using code words known as “algospeak” to evade detection by content moderation technology, especially when posting about things that are controversial or may break platform rules.
If you’ve seen people posting about “camping” on social media, there’s a chance they’re not talking about how to pitch a tent or which National Parks to visit. The term recently became “algospeak” for something entirely different: discussing abortion-related issues in the wake of the Supreme Court’s overturning of Roe v. Wade.
Social media users are increasingly using codewords, emojis and deliberate typos—so-called “algospeak”—to avoid detection by apps’ moderation AI when posting content that is sensitive or might break their rules. Siobhan Hanna, who oversees AI data solutions for Telus International, a Canadian company that has provided human and AI content moderation services to nearly every major social media platform including TikTok, said “camping” is just one phrase that has been adapted in this way. “There was concern that algorithms might pick up mentions” of abortion, Hanna said.
More than half of Americans say they’ve seen an uptick in algospeak as polarizing political, cultural or global events unfold, according to new Telus International data from a survey of 1,000 people in the U.S. last month. And almost a third of Americans on social media and gaming sites say they’ve “used emojis or alternative phrases to circumvent banned terms,” like those that are racist, sexual or related to self-harm, according to the data. Algospeak is most commonly being used to sidestep rules prohibiting hate speech, including harassment and bullying, Hanna said, followed by policies around violence and exploitation.
We’ve come a long way since “pr0n” and the eggplant emoji. These ever-evolving workarounds present a growing challenge for tech companies and the third-party contractors they hire to help them police content. While machine learning can spot overt violative material, like hate speech, it can be far harder for AI to read between the lines on euphemisms or phrases that to some seem innocuous, but in another context, have a more sinister meaning.
Almost a third of Americans on social media say they’ve “used emojis or alternative phrases to circumvent banned terms.”
The term “cheese pizza,” for example, has been widely used by accounts offering to trade explicit imagery of children. The corn emoji is frequently used to talk about or try to direct people to porn (despite an unrelated viral trend that has many singing about their love of corn on TikTok). And past Forbes reporting has revealed the double-meaning of mundane sentences, like “touch the ceiling,” used to coax young girls into flashing their followers and showing off their bodies.
“One of the areas that we're all most concerned about is child exploitation and human exploitation,” Hanna told Forbes. It’s “one of the fastest-evolving areas of algospeak.”
But Hanna said it’s not up to Telus International whether certain algospeak terms should be taken down or demoted. It’s the platforms that “set the guidelines and make decisions on where there may be an issue,” she said.
“We are not typically making radical decisions on content,” she told Forbes. “They're really driven by our clients that are the owners of these platforms. We're really acting on their behalf.”
For instance, Telus International does not clamp down on algospeak around high stakes political or social moments, Hanna said, citing “camping” as one example. The company declined to say if any of its clients have banned certain algospeak terms.
The “camping” references emerged within 24 hours of the Supreme Court ruling and surged over the next couple of weeks, according to Hanna. But “camping” as an algospeak phenomenon petered out “because it became so ubiquitous that it wasn't really a codeword anymore,” she explained. That’s typically how algospeak works: “It will spike, it will garner a lot of attention, it'll start moving into a kind of memeification, and [it] will sort of die out.”
New forms of algospeak also emerged on social media around the Ukraine-Russia war, Hanna said, with posters using the term “unalive,” for example—rather than mentioning “killed” and “soldiers” in the same sentence—to evade AI detection. And on gaming platforms, she added, algospeak is frequently embedded in usernames or “gamertags” as political statements. One example: numerical references to “6/4,” the anniversary of the 1989 Tiananmen Square massacre in Beijing. “Communication around that historical event is pretty controlled in China,” Hanna said, so while that may seem “a little obscure, in those communities that are very, very tight knit, that can actually be a pretty politically heated statement to make in your username.”
Telus International also expects to see an uptick in algospeak online around the looming midterm elections.
“One of the areas that we're all most concerned about is child exploitation and human exploitation. [It’s] one of the fastest-evolving areas of algospeak.”
Other ways to avoid being moderated by AI involve purposely misspelling words or replacing letters with symbols and numbers, like “$” for “S” and the number zero for the letter “O.” Many people who talk about sex on TikTok, for example, refer to it instead as “seggs” or “seggsual.”
In algospeak, emojis “are very commonly used to represent something that the emoji was not originally envisioned as,” Hanna said. In some contexts, that can be mean-spirited, but harmless: The crab emoji is spiking in the U.K. as a metaphoric eye-roll, or crabby response, to the death of Queen Elizabeth, she said. But in other cases, it’s more malicious: The ninja emoji in some contexts has been substituted for derogatory terms and hate speech about the Black community, according to Hanna.
Few laws regulating social media exist, and content moderation is one of the most contentious tech policy issues on the government’s plate. Partisan disagreements have stymied legislation like the Algorithmic Accountability Act, a bill aimed at ensuring AI (like that powering content moderation) is managed in an ethical, transparent way. In the absence of regulations, social media giants and their outside moderation companies have been going it alone. But experts have raised concerns about accountability and called for scrutiny of these relationships.
Telus International provides both human and AI-assisted content moderation, and more than half of survey participants emphasized it’s “very important” to have humans in the mix.
“The AI may not pick up the things that humans can,” one respondent wrote.
And another: “People are good at avoiding filters.”",1
44,"Sarah Perry is a contributing editor of Ribbonfarm.
This essay attempts to place ritual in the context of evolving complex systems, and to offer an explanation for why everything is so ugly and nobody seems to be able to do anything about it.
On Boundaries and Their Permeability
Boundaries are an inherent, universal feature of complex systems. Boundaries arise at all scales, defining the entities that they surround and protecting them from some kinds of outside intrusion. To be functional, boundaries must be permeable, allowing the entities to take energy and information from outside themselves. If we are looking at complex systems, we will find boundaries everywhere.
Boundaries are structures that protect what is within them and allow their contents to solve smaller, more manageable design problems than would be possible in a perfectly interconnected system.
Islands are surrounded by natural boundaries. Strange varieties of life arise on islands that are not seen anywhere else, precisely because they are cut off from the densely interconnected systems present in the ocean and on large land masses. Islands, small systems surrounded by a natural ocean boundary, give life the opportunity to try amazing stunts that would be impossible on a large landmass. Drifting daisies evolve into trees; drifting iguanas learn to swim; fruit flies evolve into fantastic, showy varieties; crabs grow a meter long and figure out how to open coconuts. Tree kangaroos, ground parrots, and giant tree skinks are niches only available on islands. And when the boundary opens (often because of that great destroyer of natural boundaries, humans), the unique species on islands are often out-competed by species that evolved in the diversity-flattening zones of great land masses. Boundaries drive diversity.
Note that the moon, however, despite being separated from the continents of Earth by a significant boundary, is not teeming with unusual life. This boundary is too great, too harsh, and not permeable enough to allow life to adapt to it in the first place.
Life itself has discovered a number of effective boundaries that allow it to diversify and flourish. The cell membrane is the most basic boundary. Trivially, there are no multicellular creatures without cell membranes; less trivially, there are no complex creatures whatsoever without this protecting, organizing, problem-space-limiting innovation. And in evolving a cell membrane, the most important problem to solve was how to get things through it: how to make it permeable enough to be useful.
The diversity explosion of the Cambrian era was aided by the discovery of a different kind of boundary: the exoskeleton. Exoskeletons provided a boundary protecting individual trilobites, which differentiated into many different forms and niches. Cell walls, evolving independently in multiple taxa, protect and shape the forms of plants.
Another kind of boundary that limits the space of problem solving and promotes diversity is Pattern 13 of Christopher Alexander, Sara Ishikawa, and Murray Silverstein’s A Pattern Language: the Subcultural Boundary that occurs between neighborhoods in cities:
The mosaic of subcultures requires that hundreds of different cultures live, in their own way, at full intensity, next door to one another. But subcultures have their own ecology. They can only live at full intensity, unhampered by their neighbors, if they are physically separated by physical boundaries.
Distinct neighborhoods and distinct ways of life can only evolve within permeable boundaries of some kind, so that they can have communication with the outside world, but not be simply absorbed, flattened, and made uniform by forces outside them.
When natural boundaries between human groups are lacking, there has been intense pressure in human history to create effective boundaries of other kinds; military arms races across poorly-defined boundaries may be seen as building a new kind of boundary. This is one interpretation of “good fences make good neighbors;” only good boundaries are capable of organizing people well. (It is important that G. K. Chesterton chooses fences for his famous analogy about reformers.) If we think of agency as “the ability to take action,” boundaries are essential for an entity to have any kind of agency.
In the present essay I am mostly interested in boundaries around groups much smaller than a nation state. I suggest that these small group entities – overlapping entities of multiple sizes, from Dunbar-sized “tribes” to neighborhoods of 7,000 or so – have increasingly had their boundaries undermined, and have largely ceased to exist and function. I suggest that ritual, my subject for the past two posts in this series, both functions to draw boundaries and to energize and coordinate human groups within the boundary so defined. I suggest that the loss of these small groups, in favor of nation-level organization of atomized individuals, has had serious consequences for human welfare and human agency. We are missing a layer of organization essential for our happiness.
Individual Imagination, Groups, and Flourishing
Perhaps the most important question of our time is how human beings can flourish and enjoy satisfying, meaningful lives under conditions of material abundance and extreme cultural interconnectedness. In A Dent in the Universe, Venkat proposes that “imagination” is a crucial survival skill at higher levels of Maslow’s hierarchy. Here, I propose that individual “imagination” – even at its best – is woefully underpowered to solve problems of human flourishing by itself.
The lower levels of Maslow’s pyramid reflect material well-being. But material abundance is not itself the cause of anomie and angst. Rather, ancestral, evolved solutions to lower-level problems also tended to contain solutions to higher-level problems as well. As these ancestral solutions are made obsolete by solutions that are more efficient on the material level, the more ineffable, higher-level problems they solved present themselves anew. Simple abundance of food is not the cause of obesity, but rather the loss of carefully evolved ancestral diets. Our ancestors found it easy to get to sleep because they were tired from intense physical activity; we often find it a challenge to get to sleep because modern solutions to material problems do not include physical activity. We are lonely and bored not because of material abundance simpliciter, but because the specific cultural patterns that have reproduced themselves to produce material abundance have whittled away the social and psychological solutions that were built into old solutions to material problems.
Here, I hope to motivate a humility toward carefully evolved ancestral patterns, and, especially, to the conditions and forces that allowed such patterns to evolve in the first place. The old patterns, exactly as they existed in the past, simply will not work to solve modern problems. But new, effective patterns do not come in a “flash of insight” to individuals; individuals have relatively little agency and power in shaping the way things are. Individual imagination is weak; evolution is strong.
Boundaries as Constraints on Design Complexity
Evolution, like human designers, faces constraints. Design problems that are too large, complex, and densely interconnected are unlikely to be solved by either process. Christopher Alexander opens his 1964 book Notes on the Synthesis of Form with a quotation from Plato’s Phaedrus:
First, the taking in of scattered particulars under one Idea, so that everyone understands what is being talked about . . . Second, the separation of the Idea into parts, by dividing it at the joints, as nature directs, not breaking any limb in half as a bad carver might.
What does it mean to carve reality at the joints? Alexander provides an explication with an analogy to a hypothetical design problem. He introduces the concept of “fit”, the absence of misfit, which is to say, a design that solves its problem. “Fit” is a song that is beautiful, a chair that is comfortable, a kettle that is not too heavy or expensive and that heats water quickly. “Misfit” is ugliness, discomfort, uselessness, or other failures to solve design problems.
Now imagine an abstraction, a grid of one hundred lightbulbs connected to each other, ten by ten, representing a design problem with many variables. If a light is on, it corresponds to misfit; if a light is off, it corresponds to fit. Each light (variable) is connected to some number of other variables, just as, for instance, the variable of teakettle material is connected to expense and to its capacity to heat quickly.
If all variables are uniformly connected to all other variables, the system has little chance of reaching an equilibrium of “fit” by trial and error; the problem is too complex. However, if there are zones of dense interconnectivity that are not densely connected to each other, then reality may indeed be capable of being “carved at the joints,” and less difficult design problems exist that have a chance of being solved independently of each other, whether by evolution or by human agency:
The existence of these zones of dense interconnectedness, that are not densely interconnected to each other, is a prerequisite for solvability. They are surrounded by a kind of permeable boundary, as pictured. This is analogous to “information hiding” in object-oriented programming; just as a living cell controls what enters it and acts on it, an electronic “object” limits access to its internal processes, accepting and returning only certain types of information. More ominously, a “black box” with limited interaction that solves a problem effectively is often so useful that it backfires: it becomes a new, required “solution” that limits the space of future design, often ironically resulting in poor fit. (More on this in the later section entitled “Tiling Structures and Monstrosities.”)
Another relevant analogy is the concept of life and death in the game of Go. The game of Go is a game of drawing boundaries. Within a boundary of stones, a structure is “alive” if any action on it can be met with a reply that preserves it, even when surrounded by enemy stones.
A kind of programming is occurring here, a complex tree of if-then statements abstracted into shape. Only a bounded structure can “live,” but within its bounds, it cannot be vulnerable to dangerous inputs. A perfectly impermeable boundary – a solid group of stones, with no holes or “eyes” – is dead, captured when the opponent encircles it. But a structure with enough “eyes” (holes where enemy stones may be placed) lives, and is held as territory.
To summarize, boundaries function to protect their contents from harmful intrusion, to allow for the solution of smaller design problems, and to preserve and encourage diversity. On the other hand, solutions developed at small scales are of limited utility if they cannot be adapted for use on larger scales. There must be communication and connection in order for bounded entities to live. Perfectly impermeable boundaries result in stasis and death, in social and biological life as in the game of Go.
Networks allow bounded entities to communicate and coordinate, and allow solutions developed at small scales to be used more widely. However, densely interconnected systems carry inherent risks not seen on the lower levels of organization. As we have seen, good design solutions cannot emerge from systems that are too densely interconnected. Beyond that, complex networks are vulnerable to (often inscrutable) risk of large-scale collapse. And black box “solutions” often seem to reproduce themselves like a plague, limiting design space and preventing new refactorings. The next section introduces some analogies to help think about networks and the balance between boundaries and interconnectedness.
Networks and Complex Interconnected Systems
On May 30, 2002, three ice climbers died in a fall on Mt. Hood. The incident, described in Laurence Gonzales’ excellent Deep Survival (Chapters 6 and 7), involved several of the most common factors in mountaineering accidents: the climbers were roped together, without fixed protection. That means that they did not anchor themselves to the ice, but attached themselves to each other, so that if one fell, all fell. They chose to form a tightly-coupled system (via the rope), without anchoring that system physically to the ice they clung to. “When a system is tightly coupled,” Gonzales says, “the effects spread. When a system is loosely coupled, effects do not spread to other parts of the system.” Like falling dominos, the mistake of one ice climber spreads to the others he is roped to – especially in the absence of adequate protection. The hope of one or more climbers executing a “self-arrest” – stabbing an ice axe into the ice before it is too late – is hampered by the fact that the force of a free-falling human (or two) is enough to dislocate the shoulders of a human strong enough to hold onto his axe.
There are two important points to this analogy. First, in tightly-coupled (densely interconnected) complex systems, one entity can send force into the system that destabilizes the entire structure. Second, humans are not good at noticing the dangers inherent in such systems. The type of accident reported in Gonzales’ 2003 book continues to occur with clockwork regularity. Gonzales quotes a climber who characterizes climbing roped together without fixed protection as “a suicide pact” – but climbers are apparently not good at noticing when they have entered such an unreasonable pact.
There are many problems with this analogy. In the case of climbers roped together without fixed protection, all the risk comes from individual accident or mistake. In reality, the risks inherent in complex systems often come from the system itself – though individual inputs are often dangerously propagated as well, as with parasite infestation in agriculture.
Another problem with the climbing analogy is that, in complex systems, there are many levels of “falling” other than death. Certainly, the extremely interconnected system humans have built risks complete collapse and extinction. But being “roped together” in a sufficiently interconnected system may also mean that we become stuck at low levels of well-being, unable to evolve better solutions at small scales to problems not quite as dire as death and extinction. Consider healthcare and education systems that require all citizens to participate in them and prevent smaller, better solutions from evolving. Obesity, boredom, and loneliness may not be quite as bad as death, but are levels of “falling” that sufficiently connected and tightly-coupled systems impose on their member human beings, limiting their freedom to attempt smaller-scale solutions.
Consider this substitute analogy, for contrast: instead of being suspended on ice, the people are suspended in air on a commercial airplane. Here, people are not roped together, but entirely dependent on a complex system, any aspect of which may fail.
Who “chooses” when to become part of a complex system, and which of its components to accept or reject? Where is the agency located? Often, poorly-fitting pieces of complex systems seem to be thrust upon us without our consent, with no practical way to refuse it. Network effects can frustrate human agency instead of magnifying it; I call these “tiling structures.”
Tiling Structures and Monstrosities
I use the personal jargon “tiling structure” or “tiling system” to describe a system that causes itself to be replicated, tiling the world with copies of itself. Some tiling structures are biological; humans are a tiling structure, tiling all continents with copies of the same kind of naked primate. Some are technological; agriculture tiled the world with itself not by making humans healthier, taller, or less prone to famine, but by producing sheer numbers and densities of miserable people for thousands of years so effectively (despite all the famines) that other options for subsistence were tiled out of existence.
Tiling structures are one explanation for why urban design looks so uniform (and so soul-crushingly ugly) throughout the United States. Certain forms are ubiquitous because they solve certain delineated problems effectively enough to become effectively mandatory: power lines, big box retail, strip malls, freeways, parking lots, and billboards are such powerful patterns that few locales can refuse them, despite their ugliness and the constraints they impose. Education has tiled the world with itself; it is taken for granted that children are to be locked up in adult-controlled cages for most of the day. Together with the other tiling systems, education has obliterated unique children’s cultures. The democratic government that requires this kind of education (what I call the “free child caging service,” although it is certainly not free) may be regarded as a tiling structure: it tends toward more control and intrusion into the boundaries of smaller entities, constraining what they can do.
Some tiling structures are “top down,” like government education: imposed on sub-entities against their will. Others are “bottom up” – a design problem is solved in such a way that all later actors adopt it, and it gradually becomes just as mandatory and constraining as a top-down imposed pattern. The blogger Viznut examines this latter dynamic with respect to software development; instead of attempting to solve problems by refactoring from scratch and “cutting reality at the joints,” pre-existing chunks are adopted and glued together to form a monstrosity that just barely works and is riddled with misfit:
Tell a bunch of average software developers to design a sailship. They will do a web search for available modules. They will pick a wind power module and an electric engine module, which will be attached to some kind of a floating module. When someone mentions aero- or hydrodynamics, the group will respond by saying that elementary physics is a far too specialized area, and it is cheaper and more straight-forward to just combine pre-existing modules and pray that the combination will work sufficiently well.
Viznut, The Resource Leak Bug of Our Civilization
Whether or not this is a fair description of software developers, I think it is an accurate description of how people build their lives. We select from the available chunks and try to fit them together into a coherent whole – an education here, a job there, a box to live in, entertainment to pass the time. These available “life parts” tend to be black boxes in whose design we have little say. They may not fit together into a satisfying whole at all – the boat they make may not float. Perfectly adequate material solutions fail to provide essential “nutrients” – sometimes literally (as with obesity), sometimes figuratively (sunshine, eye contact, exercise). It is tempting to accuse a person who cannot make a coherent life out of the available parts of having too little imagination; however, I do not think this kind of problem is one that individual imagination is powerful enough to solve. Even the most imaginative among us will tend to build a “monstrosity” instead of a life.
We may ask a very practical question: where lies the agency that accepts or rejects certain “black box” structures or tiling systems? An important myth of our time is that voting is an effective way for individuals to have agency in a democracy. The idea that the aggregate will of millions of people is adequately expressed by voting in elections is a rather outlandish claim, and clearly one with much evidence against it, but the “plausibility structure” of democracy causes us to believe this fiction on faith.
One pathological boundary that has been imposed top-down by our democratic system is drug prohibition. Total prohibition, in the form of the drug war, drew a boundary that created a very lucrative niche that only the most ruthless, violent actors could fill. The drug war prevented small-scale, non-totalitarian solutions to drug problems from ever being attempted, including the kind of small group rituals that allow people to use drugs in healthy, prosocial ways. The drug war hampers small group agency even more than individual agency; individuals may use drugs underground, supplied by those violent niche-fillers, in isolation or among the dispossessed, but if groups attempt to use drugs in healthy ways, a raid is almost guaranteed. “Prescription power,” limiting the power to prescribe drugs to doctors, is part of the drug war; I do not hold much hope for medicalized drug rituals administered by doctors. Despite wide agreement that the drug war is a failure, humans do not seem to have the agency to end it.
The idea that individual “consumers” express their will effectively by choosing among the options provided in the market is a myth that is related to democratic agency through voting. There is agency in market choice, but it is limited to the options provided, which are in turn limited by what other people are willing to buy. Much of what humans want and need is not possible to supply in markets, and the chunks that are supplied are often not good materials for composing a human life. I think that only small human groups are capable of supplying these benefits that are difficult for the market to capture. Both producers and government find it easiest to tile the world when humans are atomized into individuals, rather than in small groups with appropriate, permeable boundaries; but a nation of individuals makes it difficult for anyone to experience belonging. Only a small group, and not “the nation” or, even worse, “Mankind,” can supply social belonging and even multiply agency. A small group has its own agency, in the sense that a group of 200 or 7,000 is capable of more, when coordinated together with boundaries, than the same number of individuals operating completely independently. (This is why the ideal firm size is not one; transaction costs turn out to be significant.) Firms are efficient at producing material goods and services for the market, but they are not good at providing belonging and happiness for people.
These small-group levels of organization are increasingly missing. Church membership decreases, and no new cults spring up to take their place. Work, education, legal, and residential design patterns make it difficult for local groups to form and express themselves. Rituals increasingly tend toward the spectacle rather than small group participation. And without rituals to set their boundaries and energize them, small groups cannot thrive.
Boundaries, Agency, and Beauty
A story I have heard about the Langley Schools Music Project is that one of the music teacher’s strategies was to supply the children with instruments that were tuned such that they could not make “off” notes; rather than overwhelm children with a piano full of notes, they were given gamelan or other instruments that only made harmonious notes. The children could immediately pick them up and make music, rather than having to wade through years of inharmonious noise. “Toy instruments” (the thumb piano is a beautiful and very functional example) reduce the problem solving space: there are fewer options, but they all sound good and can be combined together to make music that exhibits “fit.”
Maynard Owen Williams, writing in National Geographic in 1921, writes about what happens to folk aesthetics when unfamiliar elements are introduced:
In Merv I saw the havoc modern commerce has wrought with lovely Oriental rugs. The same thing is taking place in the peasant costumes of Czechoslovakia, with the same aniline dyes being substituted for vegetable colors, which were not only much softer when new, but which fade into mellow tones no chemical dye can duplicate.
Factories are calling the women from the farms, where they utilized the winter months in working out the designs traced by the village designer or in evolving their own. Thus, gradually the arts of the past are being lost.
Good solutions to design problems – beauty in all its forms – evolve into being as least as much as it they are created by individual human agency. The solution to design problems in the human realm have had a long time to evolve in ancestral cultures, in which they evolved under more bounded, less interconnected conditions than we experience today. When new variables are added, the old aesthetic cannot instantly absorb them, but must work through many iterations of misfit before good fit is discovered. Individual humans continue to change, elaborate, and shape their aesthetics, but the more elements (choices) are added to the problem space, the smaller the chance of hitting on a good solution.
Christopher Alexander seizes on the same example as Williams in a bit more detail in his 1964 book Notes on the Synthesis of Form to elucidate a model of cultural evolution, which I quote at length:
The Slovakian peasants used to be famous for the shawls they made. These shawls were wonderfully colored and patterned, woven of yarns which had been dipped in homemade dyes. Early in the twentieth century aniline dyes were made available to them. And at once the glory of the shawls was spoiled; they were now no longer delicate and subtle, but crude. This change cannot have come about because the new dyes were somehow inferior. They were as brilliant, and the variety of colors was much greater than fefore. Yet somehow the new shawls turned out vulgar and uninteresting.
Now if, as it is so pleasant to suppose, the shawlmakers had had some innate artistry, had been so gifted that they were simply “able” to make beautiful shawls, it would be almost impossible to explain their later clumsiness. But if we look at the situation differently, it is very easy to explain. The shawlmakers were simply able, as many of us are, to recognize bad shawls, and their own mistakes.
Over the generations, the shawls had doubtless often been made extremely badly. But whenever a bad one was made, it was recognized as such, and therefore not repeated. And though nothing is to say that the change made would be for the better, it would still be a change. When the results of such changes were still bad, further changes would be made. The changes would go on until the shawls were good. And only at this point would the incentive to go on changing the patterns disappear.
So we do not need to pretend that these craftsman had special ability. They made beautiful shawls by standing in a long tradition, and by making minor changes whenever something seemed to need improvement. But once presented with more complicated choices, their apparent mastery and judgement disappeared. Faced with the complex unfamiliar task of actually inventing such forms from scratch, they were unsuccessful.
It is frequently observed that constraints and obstructions are precisely where great art comes from; far from limiting art, they allow it to happen and feed it – the more demanding the constraints, the better. This paradoxical relationship between constraint and expression is the subject of the movie The Five Obstructions (which I highly recommend). An aesthetic is one form of a constraint, and aesthetics tend to be developed, elaborated, and enjoyed in small groups. Certain aspects of reality are excluded in order to focus on the ones within the aesthetic. An aesthetic also provides a context in which forms can exist, fit, and be beautiful (or fail to be).
The work of elaborating an aesthetic together, as a small group, providing context for each other’s selves, is some of the fundamental work of being human, a way for humans to be valuable to each other that markets cannot supply.
It is perhaps a hipster universal, and one I share, to declare that modern fashion is ugly compared to almost every “folk costume” ever devised. Clothing is cheaper and more plentiful than it has ever been in human history, and yet we all look terrible. The “chunks” that individuals may select from the market are difficult to fit together into a coherent aesthetic; most retreat into a nondescript uniform (jeans, printed t-shirts, hoodies) that is more of an apology for existing than an outfit. If people are not good at solving even so simple a problem as fashion, with the help of all those factories, how are they supposed to design excellent lives for themselves? I am not blaming anyone for bad fashion here; I am remarking that we are all deprived of a possible source of beauty and enjoyment by the lack of coherent community aesthetics. We are deprived of both context and excuse for beauty, and individuals are seldom up to the effort and social risk. It is not a problem we are well-designed to solve individually, for it is not an individual problem at all, but one of groups.
The more that economically efficient tiling systems intrusively organize us and our environments, the more beauty is crowded out and eradicated. There is a tendency to imagine that the world is fair and that there must be a trade-off – longer lives and more clothes in exchange for less beauty, perhaps. But it is not clear what entity’s agency is authorizing such a trade. Ugliness is an easy externality to impose because it is difficult for individuals to coordinate against.
Consider the leaf blower. Millions of people are subjected to loud, unpleasant noise every day so that the removal of leaves from certain areas may be performed more efficiently; this is possible because there is no mechanism for the suffering of those affected by blasts of noise to be internalized by the actors who benefit by making it a bit cheaper to blow leaves around. Are we better off because gas-powered leaf blowers exist? I submit that we are much worse off, and we have been “tiled” by the leaf blower tiling structure because there was no coherent agency to refuse this intrusion. Individuals do not have much power to stop the noise; small groups are sometimes successful in excluding them from their environment, but the continued prevalence of leaf blowers indicates the absence of widespread, powerful small-group agency capable of protecting its members’ aesthetic interests.
Noise pollution is rampant and very damaging, but a more subtle form of pollution, equally unremedied, is legible word pollution. Here is Johan Christian Dahl’s 1839 painting View of Dresden by Moonlight:
Now, here is the same painting given a modern update with word pollution:
Words are processed differently than non-words, and literate people are forced to process words if they are in their visual field. Words on top of beautiful things ruin their beauty. But beauty is a difficult interest to protect in our world, and ugliness externalities flourish. The advertising tiling structure fills the landscape with signs and billboards that create more ugliness than value in the aggregate, but whose damage cannot be recouped on the market. Increasingly, fashion itself is tiled with words and legible symbols – words express social meanings more cheaply and legibly than clothing without words. The result is that everyone’s eyes are constantly being assaulted with unwanted meanings that ruin visual fields that might otherwise be beautiful.
Individuals alone can only retreat from all the noise and ugliness into a walled, private world (if they’re lucky, and tolerate loneliness well). The most sensitive people are the worst off, and of course people vary in sensitivity. Small groups of humans, however, might provide real respite from the tiling structures of the world. The next section considers these entities that have become semi-mythical, described in nostalgic, archaic words like “tribe,” “neighborhood,” or “community”: small groups of humans.
Small Groups of Humans
Small groups, and not masses of disconnected individuals, are the contexts in which most ancestral solutions to human design problems evolved. There is much romanticism these days for “tribes,” a form of organization that has not been economically effective for many centuries. We still instinctively long for this kind of belonging, as our sacrifices to sports teams, fraternities, or churches demonstrate.
Vernor Vinge’s novel A Fire Upon the Deep portrays an alien species of dog-like animals, with each conscious individual made up of multiple animals, forming a group self. In military combat, after most members of a pack are killed, singleton “fragments” wander the countryside, asking other packs, “Where am I? May I be part of you…please?”
I find this depiction to be a poignant analogy for our present state as humans – except that the small group entities mostly do not exist for us to join. They have been tiled out of existence, merged into a mass of individuals who can no longer supply each other what they need. We don’t really know how to make tribes.
Pattern 12 of A Pattern Language, Community of 7,000, declares that “individuals have no effective voice in any community of more than 5,000-10,000 persons.” This is the neighborhood layer of small groups. Small groups ideally (and traditionally) exist in multiple overlapping layers, mirroring the nature of the human self.
Internet communities are becoming more valuable as sources of belonging and meaning, but their geographic boundlessness is a limitation as well as a benefit. Only local groups can protect their members’ interests in local physical space; quiet internet communities of intense connoisseurship cannot protect us from noise or ugliness in the meat world. Internet communities have less power than local communities to give us eye contact, sunshine, and exercise, or even to allow us to wear beautiful clothing in public. While I have much hope for the internet as a ritual domain, the groups that will be most powerful in solving the problems set out at the beginning of this essay will be local, on-the-ground, “colocated” groups.
It is difficult to say how to bring these groups into existence, but I think that doing rituals together is an unavoidable component. Rituals function as permeable boundaries, network people together, smooth conflict, provide beneficial mental states, and allow the group to practice the expression of its agency as a corporate entity. Whether the rituals exist for the benefit of the group, or the group exists as an excuse to do the rituals, is a matter of perspective.
Comments
Lots of threads here to pull on here. This is a rich vein, and even though I am much more interested in developing the individualism angle on these themes, the collective angle is of course key context.
Some angles that immediately occur to me include:
1. Stuart Kauffman in his Santa Fe work (Hidden Order I think is the one) describes computational biology experiments that explore the transition from single-to-multicellular in terms of the “chemical soup” going from supercritical to subcritical, and the division process serving to keep the soup containerized in edge-of-supercritical chunks: neither explosive, nor net dissipative. Right amount of cellularization, so to speak, to keep the entity coherent as a dissipative structure.
2. Another angle which I am kinda surprised you didn’t touch upon since you’re coming from urbanism, is densification of cities/neo-urbanism. From Jane Jacobs in the 60s to Geoffrey West (also Santa Fe), the idea that larger, more densely packed populations are “better” in a certain sense is a big theme. West’s recent work shows that in lots of material terms, from energy efficiency to innovation, big cities are way better than small communities. They show superlinear growth, which seems exactly analogous to supercritical chemical soups, and also analogous to gaseous masses being large enough to go nuclear and turn into stars, rather than staying gas giant planets. Not sure how this plays into your angle, but I think the interesting phenomenon is modern mega-metros, not smaller communities. Even though the latter are what still dominate our pastoral-romantic imaginations. An interesting question is “what is the right size”? I think the Bay Area/New York region are about the upper limit. More than that and you get too-big things that are short-lived and go supernova too quickly. Too much smaller than that and you get the subcritical kinds of pre-Industrial communities.
3. That’s of course just the material bottom of Maslow, but it is also clear that in terms of higher-level well-being, metros beat cities, cities beat towns, towns beat villages, and villages beat tiny bands of hunter-gatherers. Deirdre McCloskey tackles this angle head on in her work, by busting the peculiarly American myth that people in small communities are happier and people in cities are “alienated” or something. Quite the reverse. There IS a big difference though: traditional contexts are forced patterns of association inherited from kinship structures (usually oppressive). Modern mega-metro contexts and online interactions catalyze voluntary patterns of association. A world of difference in terms of well-being each kind of collective catalyzes.
4. Regarding individual imagination versus collective, certainly, I grant that. I’ll contest the idea that collective imagination requires community in the sense of close-knit, cohabiting tribal groups or something. In fact, the best works of collective achievement have relied on impersonal institutions rather than personal ones. To take the cliched example of Apollo, that was not a paleo-village type social structure/container. It was a complex set of institutions that embodied *impersonal* patterns of trust. Sure there were much more tribal patterns within those structures, but you can’t claim all credit for collectives! I think modernity works precisely because it blends impersonal institutions and personal structures in ways that allow each person to be as individualistic or communitarian as they personally choose to be, and still get the benefits of being part of complex systems. Successful fusion of Gesellschaft, Gemeinschaft, market mechanisms and “priceless” tribal mechanisms (and yeah, I don’t buy that line that markets organize nothing of value: that’s the tired line about knowing the price of everything and the value of nothing…)
5. Still mulling the ugly/beautiful angle and wondering whether your notion of beautiful simply reduces to pastoralism or whether there is more there. I personally like word pollution. I think it is hilarious to do that sort of thing to the solemnity/gravitas of high-culture art :)
WRT your #2 above, both NYC and S.F. are geologically constrained, one is an island and the other a peninsula, so the permeable boundary condition that Sarah’s posits acts in this instance to limit the growth of the human population. Additionally, the economic forces that are dominant in both locations act to foster a sort of induced tribalism, i.e. the vast majority of residents are going to belong to the same socio-economic class and the marketing directed toward them will be concentrated in a narrower range. Contrast London or Los Angeles, which can spread out in suburban sprawl with much less geographical constraint. It seems to me that these two much larger cities have a greater diversity of distinctive neighborhoods. I lived in San Francisco in the late 1980s, when an apartment was ten times less expensive then as compared to now. At that time, the neighborhoods were much more distinctive. The massive influx of tech lords has led to a homogenization of the 49 square miles of the City.
Venkat, you said almost everything that I wanted to say in reply to this — so thanks, saved me a lot of trouble :).
But now I’m left in limbo between two competing schools of thought about what’s “good” for human beings. Historically I’ve planted myself firmly in the material-well-being camp. Let’s just make sure everyone has clean water, good access to school and medicine, freedom to choose their [whatevers] — all of which implies that metros and big individualistic states are the best thing to happen to us. I mean they aren’t without their downsides, but on net they’re good for us.
OTOH, most of what Sarah wrote here resonates with me personally. I was never happier than when I was saturated in my ritual-rich “tribe” of ~1000 primates [https://www.ribbonfarm.com/2012/10/29/anthropology-of-mid-sized-startups/]. Not sure how much you remember, but you saw my office once, and it would be hard for me to describe what I liked about it better than how Sarah put it:
“The work of elaborating an aesthetic together, as a small group, providing context for each other’s selves.”
Limbo is kinda what I’m going for here as an editorial direction for ribbonfarm. Sort of an idea hedge-fund, so to speak. I too have a fundamental bias towards taking material well-being seriously, possibly because I grew up in a part of the world where most people around me had very little of it. Easy to romanticize the squalor of lack of material well-being when you have it.
That said, I also take the beyond-material-well-being stuff just as seriously, and I don’t think there’s any real paradox there. But there probably IS a paradox between communitarian/individualist drives. Hell-is-other-people vs. hell-of-solitude. And corresponding heavens.
I think there’s far wider variation on that than communitarians think. So to me, the challenge of this post is to pull out the stuff I agree with, while bracketing the totalizing bits that are always part of a communitarian perspective but don’t necessarily survive a port to a pluralistic framework (for example, ugly/beautiful judgments have to be bracketed).
At some point, I will do a post mansplaining all this to Sarah :P
Ah, the betwixt and between of Limbo – neither here nor there, neither this nor that. I struggle with the communitarian versus individualism poles because I am an extreme extrovert who needs interaction with others to energize. But, as I learned from an earlier essay of yours, I am also a Wowbagger. I certainly don’t suffer fools gladly and fools seem to predominate at every level of community I find myself in beyond the narrow confines of family and close friends. I don’t know what the solution to this dilemma is, but ideas are a great anodyne. So ribbonfarm as an idea hedge fund serves as an excellent Beatrice in this particular limbo.
Without specifics about what research establishes this with so much certainty, all I can say is that this conclusion contradicts my personal experience and intuition as well as my understanding of the anthropological research along these lines. I feel that “love/belonging”, “esteem”, and “self-actualization” are all actively suppressed by living in a bureaucratic, consumerist society.
Not only that, but from what I understand hunter gatherer bands tend to be low conflict and incredibly happy. Not a hard-and-fast rule, but egalitarian hunter gatherer bands are routinely described that way.
Of course, cities are better if you’re seeking novelty specifically, but I don’t “novelty” anywhere on Maslow’s hierarchy. Otherwise, the city environment (one in which you’re definitionally surrounded by strangers all the time) seems pretty alienating to me.
Some random reactions (I am in mostly-complete agreement with this excellent post):
I՚m guessing you know that the line “good fences make good neighbors” is not the point of the Robert Frost poem it is taken from – rather the opposite: ”Something there is that doesn՚t love a wall”.
Re democracy and ritual, see here.
I՚ve been researching Stewart Brand for a session at Refactor Camp, so thinking a lot about hippies, and this post made me see them in a new light – the 60s were in large part an aesthetic rebellion against the mid-20th-century modernist uglies. Brand and California bohemianism were one of the more successful branches of this rebellion. The WEC was explicitly aimed at supplying better “materials for composing a human life”, in your phrase. Brand was also something of a ritual designer, and I think it is through Brand that most of us are familiar with Christopher Alexander.
This was a very provocative read. I suppose the thing I am most likely to think about is the notion of the ideal human grouping for the realization of an objective aesthetics. If every individual is the judge of beauty, then there really is no standard and judgement about any particular artifact is impossible. If, however, a smaller group of committed aesthetes cannot advocate for a particular standard because their judgment has been tiled out of existence by Encorpera, the bland sameness oozes over every artifact. (I love Sarah’s example of clothing. I myself have adopted the “protest” uniform of a black knit polo shirt and khaki’s.)
One thing that struck me as incongruent in the essay was the critique of the “drug war.” This sounded almost like a Libertarian manifesto of the individual set against the over-encroaching Government. Almost everything else in the essay relies on a communitarian or collective ethos, which is quite distinct from the individualism of recreational drug use. And I don’t think the distinction is collapsed by suggesting that there may be a ritualistic (i.e. communal) role for using controlled substances. In my experience as a prosecutor, the genuine ritualistic use of a controlled substance, e.g. peyote by certain Native Americans, has a well-recognized cultural history. In contrast, the more frequent appeal to “ritualistic” use is by individuals who want to circumvent prohibition by creating post-hoc justifications. A good example is the number of medical cannabis users who have no real medical condition (i.e. cancer as opposed to ingrown toenail) but rely on the legal fiction to get high. Collective action in the case of medical cannabis is political action or a legal fiction so that users can obtain marijuana without having to resort to street-level black market transactions. It is rarely ritual in the sense that I suspect Sarah is using it. Though the Zion Coptic Church, which is an outgrowth of Rastafarianism, claims to use cannabis sacramentally.
Donald E. Brown has proposed that “mood- or consciousness-altering techniques and/or substances” are a human universal; rarely in human history, however, are substances used in the individual, isolated manner in which they are used under drug prohibition in the United States. In no culture is it just a free-for-all; institutions evolve to help people use drugs well and safely, but those are prevented from ever evolving under prohibition. Instead, violence and degradation is ensured.
I appreciate your making my point – that prohibition drives drug use toward isolation. ;) And my point is not the usual libertarian concern for *individual* use rights, though I do think we have the right to alter our own consciousness, but rather a concern that prohibition has destroyed the agency of small groups to use drugs in wholesome group contexts. (In many cultures, only experts actually use the drugs; everybody else participating in the ceremony does not – as with Maria Sabina in my earlier essay in this series.)
I chose to talk about the drug war because it is a concrete way that “tiling structures” destroy (in a top-down manner) the possibility for certain states of consciousness – but it is hardly the most important one. States of consciousness are the “forms” I care most about; “mental states” are, under my view, pretty much the only important thing, and everything that exists, exists to create or maintain them.
Much of the ugliness you describe is probably contingent. In The Nature of Order, Christopher Alexander offered the 15 transformations as a reliable way of enhancing wholeness and beauty, and there is no reason why such transformations cannot be applied to systems with modern fashion or words/fonts (neither of which should be viewed as monolithic). Of course I may just be biased as a stylish person :P, but it seems most people stop experimenting due to the ease of achieving ugliness, and revert to safe combinations of t-shirts and jeans, which mostly aren’t even fitted to the human organism in the first place.
It was great that you considered non-physical boundaries, especially information ones as emplaced by rituals. In Terrence Deacon’s Incomplete Nature, permeable autopoietic boundaries are indeed necessary and sufficient for self-hood and agency. Of course in a network topology, relative scarcity of connections itself acts as a boundary.
Your mention of black boxes reminded me of black box ontologies, which according to Andrew Pickering characterized cybernetics, in that knowledge of the interacting systems is not required for action, since the systems can adapt and regulate each other. Rituals are like a deeper homeostatic layer that maintain the system through changes enforced from without, yet the deeper homeostasis of human psychology may lead us to abandon rituals even before we have found replacements, at some cost to our mental wellbeing.
The problems with giving up such evolved patterns of behavior are those described in James Scott’s Seeing Like a State and Nassim Taleb’s Antifragile, for instance in a recent tweet when Taleb realized that fasts like Lent are not merely meant to act as sacrifice rituals to maintain religious identity or provide nutritional benefits for humans, but also had health and ecological benefits for farm animals.
The part about solutions spreading like plagues in highly connected networks is like abandoning the wisdom of crowds, where guesses do not converge to the mean but are affected by the anchors. Local fit is also lost in such cases, leading instead to solutions that fit the system and perpetuate the conditions for their reproduction.
Tiling structures are like attractors or what Deleuze called singularities, patterns or points on the fitness landscape which tend to be produced and reproduced, especially when sustained by stable parallel loops as described in Muralidhar Ravuri’s Pervasive Loops. Perhaps the strongest tiling structures cannot externalize like economic products, but wage Boydian moral-mental-physical war, bringing and keeping others in play in an infinite game, aware that self-interest includes altruism, as explained in Liu & Hanauer’s Gardens of Democracy. These structures would also self-propel into a Serendipity Singularity, as long as they are not snuffed out in their nascent stages.
1. I’m very happy to see Notes on the Synthesis of Form get more exposure. It’s by far the best of Alexander’s books, I think.
2. The problem isn’t insufficient boundaries, but too many boundaries. Something there may be that doesn’t like a wall, but it’s in nature, not in human nature. Human nature (or at least analytic western tradition) seems to love dividing tangled systems into zones like in your figure above. Each boundary is imposed on the basis of local concerns, but without holistic cost-benefit consideration. Once imposed it’s hard to move or remove boundaries, because of the fear of destructive consequences. Hence heuristics like Chesterton’s fence. I tried to explore these ideas in https://www.ribbonfarm.com/2014/04/09/the-legibility-tradeoff (though it’s not nearly as well written as this post).
To quote myself: “Our institutions are plagued by a tendency to forget the precise scenarios they were designed for, dooming them to either forget history and repeat mistakes (‘regressions’ in programmer-speak) or to continue cargo-culting old solutions long after they’ve become obsolete.” (https://www.ribbonfarm.com/2014/01/15/resident-bloggers-for-2014-sam-jordan-kartik-keith)
3. The number of things we both referred to is quite crazy: Christopher Alexander, Robert Frost, Go stones, Chesterton’s fence, the resource leak bug (but then I’m a programmer). Your leaf blower example connects up with one of my favorite essays: http://www.orionmagazine.org/index.php/articles/article/7277 (it’s about a weedwhacker, but still).
Tl;dr – tiling systems are an inescapable result of creating boundaries while forgetting why they were created. Boundaries need comprehensive unit tests. That way lies loose coupling and nirvana.
But of course the solution is unit tests.
Lol!
The answer is *through* individualism => we cannot uneat the apple.
Threads that come to mind:
– The rise of Sunday Assemblies: atheists realizing that the ritual function is not worth throwing out with the theos bathwater
– Things like ribbonfarm + RefactorCamp as a, admittedly wildly unfocused, example of a kind of ritual-linked online community.
– Companies that are remote-primary are in a similar position.
– There’s an interesting overlap with concepts of superimposed states (First Nations, Kurdish democratic confederalist zones, cartel-controlled areas of Mexico, etc).
Very glad to hear you’re contributing editor!
I work as a theatrical director (and actor), and I also think this process is why most film and television acting is so bland and awful. In an extended rehearsal process for a live performance, you get many options to repeat your performance, try again, see how it flows from one moment to the next, how your scene partner responds to you, etc. In film you don’t get the opportunity to do that. Scenes are shot out of order, often without the other people there, and so you need to adopt acting strategies that you assume will fit without having genuine information on whether the fit works. If you make big, bold acting choices, they are unlikely to fit because they come off as ham-handed unless they are very well-motivated. And so we get more and more absent deliveries of lines as written, or canned imitations of emotional responses that are acceptable for television audiences. It becomes acting that is “more of an apology for existing than a performance.”
When it works, live theater is SO MUCH MORE FUNNY than film. Part of this is just that you are in a large group of people, and laughter is mostly socially mediated, but it’s also due to the fact that the actors can breathe and act in response to the audience’s response. I think that the traditional division between audience and performer is important for the compartmentalization that you talk about, and directors break this distinction far too nonchalantly because they assume that it’s always better to have audience interaction. (Not saying that it isn’t a great and important way to do art, just that people whip out alienating pseudo-Brechtian crap as a lazy way to make a performance more “interesting” without considering what that does to everything else in the performance.)
The notion of Heterotopia seems relevant. Via Jordan Peacock’s Be Slightly Evil cardgame.
As an avid gardener I can deeply relate to all that you have explored here. I would maybe add the idea that in gardening even if a strategy yielded good results in the past, continuing to do it indefinitely will almost certainly lead to disaster.
For example, if you are adding certain types of fertility to the soil you will usually see increased returns from your crops, but if you keep going there will inevitably be a residual mismatch between inputs and outputs every cycle, leading to some nutrients being over-accumulated and others depleted over time. This to me is the big danger of the most modern form of agriculture where the same land is used in the same way for indefinite periods. Even simple crop rotations don’t completely reset the imbalances. I get the impression that older forms of agriculture were more shifting and opportunistic, with small patches of cleared cropping land cycling back into the wilder pasture management approach for long stretches of time. Real ecosystems also behave the same way, with species shifting in space and time.
It also reminds me of the Savory approach to management where you pretty much assume you didn’t make the right decisions in the last cycle, and always keep a wide view on possible variations of approach. I know from my own farm some of my biggest successes were from random experiments that I never thought would come to much. With age I am learning to devote more time and energy to those agnostic approaches to problem solving.",2
45,"Official letterhead of DeLorean Motor Company, a car manufacturer who released just one model before collapse: the DeLorean DMC-12. In 1985, three years after the company went bankrupt, the gull-wing doored DMC-12 starred in Back to the Future.\nDeLorean Motor Company, 1981 | Source",2
46,"This pastebin uses client-side encryption. Therefore, it needs JavaScript enabled.
It seems like your browser doesn't have JavaScript enable.
Please enable JavaScript for this website or use a JavaScript-capable web browser.
×
{% msg.action.message %}
×",7
47,"THE NEWS
The University of California system is undergoing a massive strike by some 48,000 non-faculty academic workers. Teaching assistants, graduate student instructors, postdocs and researchers are refusing to work as part of their effort to secure a range of benefits, including higher pay and protections against rising housing costs.
These non-faculty academic workers well outnumber the roughly 12,000 tenured and tenure-track faculty at the University of California. The striking groups include 11,000 postdocs and academic researchers; 19,000 teaching assistants, graduate instructors, readers and tutors; and 17,000 graduate student researchers.
The postdocs reached a tentative deal, which includes raises of over 20 percent as well as increased job security and family leave. There hasn’t yet been a deal reached with 36,000 other academic workers.
Some full-time faculty members refused to hold classes both out of solidarity with the graduate students and because they said the withheld labor made it impossible to do so.
THE CONTEXT
The higher education workforce today is more and more made up of contingent faculty and workers who are considered by their universities to be students.
In the past 30 years, the number of tenured and tenure-track jobs has barely budged even as student enrollment has increased, while the number of doctoral students has continued to grow. Thanks to a combination of current professors sticking around longer (mandatory retirement is illegal) and declining enrollment as the millennial demographic bump passed, academic graduate school has never been less of a path to steady employment, especially in the humanities. “Tenured professors like having graduate students around. They teach the boring undergraduate sections for little or no pay and provide inexpensive research assistance. For many veteran scholars, training the next generation is one of the most rewarding parts of the job,” Kevin Carey wrote in the New York Times.
The old model where graduate students were essentially apprentices following a vocation — or calling — to research and teach seems bankrupt to this generation of non-faculty academic workers. They are being called upon to do more with only a glimmer of hope that they are headed in the direction of an academic job in the future.",2
48,"If you ask any ordinary person which is the most used operating system in the world, the answer they will give you is Windows. But, there really is an operating system within Intel hardware that most are unaware of called MINIX. What is this operating system on your PC and what is it used for?
A few years ago, it was discovered that Intel hardware internally runs an internal operating system: MINIX. But this operating system has a reason for being,
Contents
What is MINIX?
MINIX is a Unix-like operating system created by himself by Andrew Tanembaum, which was designed to teach the subject of operating systems to computer engineering students. This operating system was made to run on x86s, as most Unix systems out there in the 1980s did not run on PC CPUs and a Unix license was very expensive.
With the arrival in the 90s of Linux and BSDs for x86, the use of MINIX was forgotten, but it must be taken into account that it is an operating system that was originally designed for teaching, since it was the software that accompanied the book “Modern Operating Systems: design and implementation” by Tanembaum himself.
Intel uses MINIX internally in its processors, something that Andrew Tanembaum himself was never aware of until the hacker community in full exploration of the secret recesses of Intel hardware discovered it.
Where is MINIX on your Intel CPU PC?
Actually MINIX is not inside the Intel CPUs, but is part of the Media Engine, which takes control of the CPU as it is the element with the most privileges within the system, so it is in the privilege ring -3.
The privilege or execution rings indicate the hierarchy when it comes to accessing the control of the CPU as well as the system resources. Technically the negative rings do not exist and in theory it is the operating system that has the greatest privileges, but there are situations in which the software can take full power from the processor. That is why Intel to avoid this created the Media Engine, a CPU that works in an isolated and isolated manner that creates a level of trust or “Trust” in the system, which has nothing to do with the usual meaning of the word.
When we talk about software trust, we are not talking about stability, but rather that it does not perform functions that manufacturers do not want it to do. Thanks to the Media Engine it is possible to remotely block the use of certain software and even the use of hardware. It is a back door that all PCs with an Intel CPU have and if we talk about AMD then we must talk about its Platform Security Processor, but the peculiarity is that only the Intel Media Engine makes use of MINIX.
What is MINIX used for in Intel CPUs?
In order for the Media Engine to perform its function, it needs to run an operating system in a totally isolated environment, this means that it cannot do so by accessing the system’s RAM memory or the storage of the system itself. Needing for this its own RAM memory and also its own storage, which in this case is in the Media Engine itself.
The choice of MINIX for the Media Engine functions makes sense for Intel, as it is an operating system that is light enough to fit into the ME’s NAND Flash memory and can be used in isolation by the ME. In addition, its location in the chipset gives access to all the input and output interfaces of the chipset, including the network ones, which is necessary for remote control of the system.
If you are terrified by the concept of a back door in your
The relationship between MINIX and Intel vPro
The fact of controlling a PC remotely is something that today is not something that can surprise us. But what if we talk about being able to manipulate the BIOS and even install an operating system? Well, this is possible with Intel’s vPro technology, which is what allows Intel itself and hardware manufacturers to transparently and invisibly manage PCs even if they are in sleep mode.
This can be done remotely thanks to what we have commented above. That is, thanks to the Media Engine that MINIX runs. If to this we add that in version 6.0 of its Active Management Technology Intel implemented the Keyboard Video Mouse Remote Control, then remote control becomes totally possible.
In other words, it is the same as remote control software but with a difference, since Intel’s KVM works at the hardware level. This allows you to control the system even without an operating system in the middle. The reason? It runs its own operating system, MINIX, so it does not need an operating system.
Is it possible to control my PC remotely?
After all this explanation you will surely be wondering if it is possible to control a PC remotely as manufacturers can do through the Media Engine. Well, yes, it is possible to do it, but for this you will have to first make sure that your CPU supports Intel vPro, which is the Intel technology that will allow you to remotely manage the PC.
Once you have made sure of it, then you have to enter the system BIOS and make sure that you can activate a tab that says BIOS Verbosity. Restart your computer, re-enter BIOS and look for an option titled firmware verbosity or boot verbosity and make sure they are active. By the way, make sure that the option for the installation or setup prompt is also on.
The next step is to restart the PC where you should get the following message, press CTRL + P to enter the Intel AMP configuration that will allow you to configure your PC to be used remotely. In the case that it asks you for a password, this is usually “admin” in 99% of cases, but without the quotes. From this point you will only need to configure remote access, as well as KVM to be able to manage your PC remotely.",2
49,"Apple's robot can pull apart 1.2 million iPhones a year, or 200 per hour.
James Martin
Ian Sherr
James Martin
Managing Editor, Photography
James Martin is the Managing Editor of Photography at CNET.
His photos capture technology's impact on society - from the widening wealth gap in San Francisco, to the European refugee crisis and Rwanda's efforts to improve health care.
From the technology pioneers of Google and Facebook, photographing Apple's Steve Jobs and Tim Cook, Facebook's Mark Zuckerberg and Google's Sundar Pichai, to the most groundbreaking launches at Apple and NASA, his is a dream job for any documentary photography and journalist with a love for technology.
Exhibited widely, syndicated and reprinted thousands of times over the years, James follows the people and places behind the technology changing our world, bringing their stories and ideas to life.
Ian Sherr (he/him/his) grew up in the San Francisco Bay Area, so he's always had a connection to the tech world. Currently, he writes about Apple, Microsoft, VR, video games, and internet troubles. Aside from writing, he tinkers with tech at home, is a longtime fencer -- the kind with swords -- and began woodworking during the pandemic.
Daisy is designed to pull apart iPhones that would cost too much to refurbish and are deemed end-of-life. It's staffed by three to four people.
James Martin/CNET
Daisy is many things. It's a 33-foot-long robot that pulls apart iPhones with its five arms. It was created by Apple. It's a cacophony of servos, pressurized screw punches and other moving parts. It may also hold a key to electronic recycling's future.
""This is about the big hairy goal of making all our products from recycled materials,"" said Lisa Jackson, Apple's vice president of environment, policy and social initiatives, in an interview. ""It's going to take a while, but it'll also take tons of innovation.""
Now playing:Watch this:
Apple wants to share its Daisy robot tech for recycling...
2:46
While at the lab, we got to watch Daisy in action. Here's what we saw:
Get the CNET Apple Report newsletter
Receive the latest news and reviews on Apple products, iOS updates and more. Delivered Fridays.
Get the best price on everything
Shop your favorite products and we’ll find the best deal with a single click. Designed to make shopping easier.",1
50,"Flat out: student accommodation is hitting crisis point
Eighteen-year-old Raef Macnaghten from Portsmouth was due to start university in Glasgow this September. He accepted his place after results day, applied for accommodation and waited. Hearing nothing back, his mum phoned the university and was told there was none available. They told her that “hundreds” of first-year students were in the same boat. Their only advice: defer, or go elsewhere.
“My parents were absolutely shell shocked,” says Raef. “I’d been messed around so many times.” His overwhelming feeling, he says, is of “extreme frustration”, and it’s led to him being forced to take a gap year that neither he, nor his parents, wanted.
As the academic year is set to begin and Freshers’ Week kicks off, new and returning students around the country are faced with a more pressing problem than which flat to host pre-drinks in. Right now, many of them will be lucky if they have a place to live at all.
In Glasgow, many would-be first-years have been left with no other option but to defer or drop out completely. Hundreds of second, third and fourth-year students, not to mention postgrads, are staring down the reality of sofa-surfing or extortionate rent prices as they return to the city they call their second home. A knock-on effect of the national housing crisis and soaring rents means that stories abound of flats having upwards of 600 applicants within minutes of being listed. Last week, the University of Glasgow sent the following via email to all students: “If you do not yet have accommodation in the city, please do not travel to Glasgow.”
In Bristol, student housing waiting lists have more than trebled. In Manchester, students are being paid to live elsewhere. Referring to the crisis, the National Union of Students has described British universities as “washing their hands of their duty towards their own students”.
But in Glasgow, a city with three major universities as well as Glasgow School of Art, it’s particularly acute. A combination of increased student numbers, a change in the legislation governing private landlords, the after-effects of the pandemic and breakdowns within the University of Glasgow’s accommodation service are creating an unprecedented housing crisis for the city’s students.
The situation is so desperate that the university’s Students’ Representative Council lobbied last year for a suspension on student recruitment, predicting that the problem would worsen this year. In 2021, the Glasgow Guardian learnt that the university was aware of an increased, “very strong” intake of students that would “achieve the growth projected in the budget”. Despite this, UofG seemingly did not conduct any surveys or studies into student housing, and while it did discuss additional teaching staff, an additional accommodation strategy was not mentioned. This blindspot led to accounts of students who couldn’t find housing similar to what we are seeing this year.
Ellie Gomersall, president of the NUS Scotland, stated: “We urgently need rent controls and a student housing guarantee that ensures government, universities, and local authorities work together so every student has a safe and affordable place to live.”
Why is this crisis happening? Broadly and simply, it’s a case of too many students, not enough beds. In Glasgow, Scotland’s biggest university has offered places to more students than the city can take. UofG did boost their student bed numbers by 25 per cent, but this barely scratched the surface. As the university has acknowledged: “Demand has continued to exceed supply.”
The increased demand is a nationwide issue. The number of students being accepted at UK higher education institutions hit a record high of 570,000 in 2020, up by 17 per cent compared to a decade ago. Last year’s figure was 562,000.
Unsurprisingly, the pandemic has played a role in this. Grade inflation increased the number of students receiving top marks and therefore getting into universities. This is alongside large numbers of deferred places now being taken up by those who didn’t want to attend uni in lockdown – and a backlog of deferral students remains, meaning the situation in 2023 could be even worse.
Responses from universities have offered, at best, blunt-force solutions. UofG has stepped back from its guarantee to provide homes for first-year students. In a city where, traditionally, many Glaswegians attend a hometown university, housing for those who live within commuting distance of UofG is now being automatically denied. For all other first-year students, they were told they wouldn’t have their accommodation placement confirmed until 10 days after results day – two weeks before term begins.
This also didn’t take into account the, by definition, last-minute nature of the clearing process. Many students, then, discovered in the immediate run-up to term time that they needed to find a private rental solution in Glasgow. And if they can’t? They’re already too late to apply to other universities.
On UofG’s accommodation page, it states: “Unfortunately, we know that there are currently accommodation challenges within Glasgow driven by a contraction in the private rental market.”
An agent at Countrywide Letting explains the meaning of this: during the pandemic, a lot of landlords sold their properties. Then, the market saw a recent price shift, and it became a good time to sell, with properties going for up to 30 per cent over the asking price. As a consequence, “the university is relying on private landlords to accommodate the students but [the rental stock now] isn’t substantial”.
The situation has been exacerbated by new Private Residential Tenancy rules introduced by the Scottish Government in 2017, which were intended to “improve security, stability and predictability for tenants”. But the Scottish Association of Landlords (SAL) has argued that this in fact reduces student homes in Scotland as “landlords were no longer able to offer fixed-term leases which matched term times”. This is set to be replicated in England too, under the Renter’s Reform Bill.
As one Scottish landlord wrote online: “It’s unbearable. This train crash has already happened in Scotland and now it’s going to happen in England. I’ve never seen anything so stupid in my life. I’m a student landlord and after 37 years I’m selling up the whole lot.”
He’s not alone. Earlier this year, a survey of SAL members showed a potential reduction of 36,000 Scottish homes available to rent due to over a third of private landlords aiming to sell their properties. This further drives up rent.
To make it even harder, students are battling with HMO (House of Multiple Occupancy) licensing in Glasgow. A HMO is a residential property where three or more unrelated people live. These properties are subject to strict licensing conditions, and the licence itself is expensive. As a result, many landlords don’t purchase them and instead let out their properties as non-HMO.
This is a near-impossible prospect for students who want to live in house-shares, as it’s highly unlikely they are living with a partner or relative at the age of 18 or so. In previous years, some students pretended to be in relationships with their friends to be accepted in non-HMO properties, which are more affordable. But it seems the application process has become more rigorous, and landlords now request some kind of “proof of relationship”, such as joint bank accounts dating back a minimum of six months. This is something that students in a fake relationship can’t provide.
In Bristol, the situation is at “crisis point”, according to letting company Balloon Lets. In 2021, the city’s University of the West of England (UWE) had 150 students on the housing waiting list; now the list has 485 names. Alongside this, private rental prices have increased dramatically, from an average of £400 per person per room to around £700.
i News reported on a student with an unconditional offer at UWE. He was told by the university that every single accommodation option he picked was unavailable. Instead, he was offered a “tower suite” in the city costing roughly £10,000 a year, or somewhere 45 minutes away in Newport or Gloucester. They also offered him a link to a Facebook group of other students in need of a home. Not, perhaps, the most reassuring or appealing prospect for a teenage newcomer to a city.
Wherever you look, there are variations on the same worrying theme. Tay Letting says the situation is just as bad in Edinburgh and Dundee, with similar accounts in St Andrews, a small town with a hugely popular university. Manchester Metropolitan University students have been offered £100 a week to live in other cities – for example, Liverpool or Huddersfield – as the university cannot cope with “significantly more offer holders than anticipated”’ according to the Manchester Evening News – a line repeated by unis across the UK. To borrow a phrase used by an alarming number of estate agents, it’s a “perfect storm”.
Ahead of starting my second year in Glasgow this month, I have been flat hunting since April with no luck. I know many other people in this situation, too. As my friend Krish put it, “It’s such a ball ache!” But whether you’re new to a city, embarking on the year when your academic demands really kick in, or your finals, that’s a bit of an understatement.
In my experience over the last three months, if a flat comes on the market, viewings will be fully booked within minutes. On the inside, estate agents report similar stories. Two weeks ago, Countrywide Letting had 600 applicants for a two-bed flat, the majority of which were students – a “very unusual” number for one property this late in the year. Tay Letting also reported having over 1,000 applications to view a one-bed flat. As an agent at one lettings company popular with students tells THE FACE, “I’ve never, ever seen it as bad as this.”
Tenants are now offering way over the asking price to secure a home, a financial luxury most students can’t afford. The Institute for Fiscal Studies has warned that student financial support is falling short of matching rapidly increasing inflation, which is at its highest point since the introduction of tuition fees. The real-term value of maintenance loans has dropped to a seven-year low, coinciding with the skyrocketing prices of food, rent and energy bills.
The looming winter feels even more challenging to me and my peers. As it stands right now, my first term will be defined by a fold-out mattress on my mate’s floor. The novelty will soon wear off, I’ve no doubt, and refreshing Rightmove at eight o’clock every morning is becoming draining.
But at least I have a place at university. For many teenagers across the UK, they’ll have to wait another year to experience the Freshers Week they’d imagined.",4
51,"Um den vollen Funktionsumfang dieser Webseite zu erfahren, benötigen Sie JavaScript. Eine Anleitung wie
Sie JavaScript in Ihrem Browser einschalten, befindet sich
hier.
Pour accéder à toutes les fonctionnalités de ce site, vous devez activer JavaScript. Voici les
instructions pour activer JavaScript dans votre navigateur Web.
For full functionality of this site it is necessary to enable JavaScript. Here are the
instructions how to enable JavaScript in your web browser.",7
52,"The past week has been another reminder of the urgent need to build global food systems that treat food as a human right rather than a commodity.
On May 13, India banned most wheat exports to safeguard domestic food security for its 1.4 billion people, pushing the global price of wheat to record highs.
India is the latest country turning to export restrictions to cope with rising food prices fueled by the pandemic, Russia’s invasion of Ukraine, and climate change. In May 2021, Argentina banned beef exports to tamp inflation that reached 50.9 percent. Indonesia halted palm oil exports and Kazakhstan restricted wheat and wheat flour exports as local prices for these commodities soared. As of early May 2022, more than 20 countries had imposed food export bans.
On May 19, the United Nations Security Council met to discuss the global hunger crisis and on the same day a group of 35 UN states endorsed a statement by the United States urging member states to avoid export bans on food and fertilizer on the ground that they can worsen the global food crisis.
What was missing from the debate was a focus on access to food as a basic human right, and reflection on the underlying flaws in global food systems that feed volatility to begin with and leave governments with few good options to address rising food prices and prevent hunger.
Prices can only be partially explained by the actual availability of food, according to a report by the International Panel of Experts on Sustainable Food Systems. It concluded that the power of some producer countries and companies, lack of market transparency and regulation, as well as speculation drive up prices.
Systemic change to ensure people can access food will be crucial as climate change is expected to increasingly affect food insecurity and prices, and households in poverty are at particular risk.
Building rights-respecting food systems means making them more sustainable and climate resilient, better regulating markets, and ensuring affordability so that everyone can afford safe and nutritious food by investing in adequate social safety nets to protect people from hunger and poverty in times of rising food prices.
As of today, 874 million people in 92 countries do not have enough food. As the world becomes more vulnerable to shocks, it’s time to reimagine food systems based on rights so no one goes hungry.",2
53,"Fungi Collected in Shropshire and Other Neighbourhoods (1860–1902)
As temperatures drop and leaves fall, blanketing forest paths and city sidewalks in layers of red and orange, nature’s decomposers spring from the ground. Transforming organic matter into fertile soil, fungi and their vast underground networks work silently beneath our feet. October is peak mushroom season for many, as foragers trained in the art of finding tasty, meaty puffballs and hen-of-the-woods also begin their labor. Our fascination with fungi, one of the oldest organism groups on earth, has remained a human constant. From umami-rich meals to poisonous and psychedelic specimens, mushrooms have represented something queer, sexy, and dark for centuries.
Behind recent calls for fungal futures — involving everything from “biohacked” bodies to anti-capitalist visions — lie carefully illustrated descriptions of the mushroom world by naturalists like M. F. Lewis. Bound into three exquisitely colored volumes with filigreed title pages, her Fungi of Shropshire features hundreds of species, collected across forty-two years of work in England and Wales, rendered in pencil, watercolor, and ink. Despite the enormity of Lewis’ project, little is known about her life — we have yet to discover her first name. What we do know is that she was deeply and intensely committed to studying mushrooms.
The title of these three volumes, Fungi Collected in Shropshire and Other Neighborhoods is a bit of a misnomer: her illustrations, which range from the recognizably red-and-white spotted fly agaric to smaller, drabber species, were produced over many hundreds of miles, painting a stunning portrait of Britain’s rich fungal diversity in regions seldom explored by mycologists. Most pages feature several species collaged together, sprouting from vegetable hosts or moldy organic matter. Lewis’ pages avoid the classificatory divisions of typical herbaria (or, in this case, fungaria), grouping mushrooms mostly by aesthetic arrangement rather than taxonomic relations.
Like many other women naturalists in the second half of the nineteenth century, Lewis appears to have collected and illustrated specimens for her own edification, combining her “polite” training in the arts with meticulous scientific observation against the backdrop of a growing embrace of natural history’s wonders. As some women filled their parlors with seaweeds and skeletonized flowers, Lewis turned her eyes to something decidedly darker. Scraping through rotting leaves and the animal feces from which mushrooms sprung, Lewis saw the beauty in these odd, seemingly unclassifiable specimens (we didn’t separate fungi into their own kingdom until the 1960s), emphasizing their sumptuous colors and casually ignoring their potentially poisonous qualities. Anticipating what would become a full-blown mycological fever later in the nineteenth century — most clearly demonstrated by beloved children’s book author and mycologist Beatrix Potter — Lewis knew that mushrooms were for more than consumption. They held scientific and aesthetic value amidst showier flowers and elegant ferns, even as they worked within a system of decay in which death preceded reproduction.
It’s unclear whether today’s obsession with fungi — tracked in recent books by Litt Woon Long, Merlin Sheldrake, and Anna Tsing — is another fleeting trend or a longer embrace of our primordial ancestors, bred by an increased understanding of these deceptively massive, spore-producing organisms’ importance for a networked world in peril. What is clear, though, is that the beauty and diversity of the fungal world has captivated amateur naturalists and artists for centuries. From the smallest mushroom caps to sprawling, fleshy, phallic specimens, women like Lewis chose to study fungi over other plants, animals, and everything in between, pointing to the artfulness in decomposition, the liveliness of rot.
Published
October 11, 2022
Theme
Style
Epoch
Tags
If You Liked This…
Prints for Your Walls
Explore our selection of fine art prints, all custom made to the highest standards, framed or unframed, and shipped to your door.",2
54,"Awesome AI image synthesis
A list of awesome tools, ideas, prompt engineering tools, colabs, models, and helpers for the prompt designer playing with aiArt and image synthesis. Covers Dalle2, MidJourney, StableDiffusion, and open source tools. Many of these tools come with ""batteries included"" and won't include colabs or python code you have to run. (for colabs see this list)
Contents
🤖Text-to-image Models 💰Commercial ☁️Free hosted 💻Free local - Run on your GPU
-
✍️Prompt engineering ✨Post processing tools 👨👨👧👦Communities 👩🏫Theory & Learning
- [
🚨Upcoming exciting projects](#upcoming-exciting-projects]
Text-to-image Models you can run
Models, commercial and open source, that you can either try for free and pay for credits or can run in the cloud.
Commercial
- DreamStudio - #StableDiffusion in the cloud
- Midjourney - Discord bot with amazing visuals
- Dalle2 - The one that started it all, great with multi characters
- NightCafe - Nightcafe studio is an AI Art Generator (incrorporates stableDiffusion)
- ArtBreeder Collage - A collaging tool to generate art using visual aides.
- Photoroom - Photoroom has a new feature for backgrounds (featured on product hunt)
Free hosted tools
- Craiyon - Formerly dalleMini - open source tool that outputs great compositions but lower quality
- StableDiffusion on HuggingFace - Run the #StableDiffusion right in huggingface UI
- StableDiffusion on Replicate - Run #StableDiffusionon on replicate.com
- Google Colab - Google free GPU machines in the cloud running models of all sorts.
Free local
*Advanced Batteries not included, this section is for advanced folks who can use the command line, install python packages, run code etc'
-
StableDiffusion + Web GUI - This repo has a step by step way to install and run #stableDiffusion using local GPU + a gradio based web UI. Has a nice UI, upscalers built-in, img2img and inpainting, and a LOT more! (see thread with features
-
StableDiffusion with Diffusers - A simple-ish way to run stable diffusion locally using hugging face diffusers library
img2img - Generate images from a combination of prompt + init image
img2img refers to the practice of feeding a model an init image AND a prompt.
- stable-img-to-img - Hosted version of img2img tool from stable diffusion. Provide an image + a prompt
- Diffuse-The-Rest - A simple Hugging Face img2img tool that allows for image upload and/or simplistic drawing with a prompt
Prompt engineering
The emerging field of the Prompt Engineering is just beginning, and yet there are tools released for us every day. Follow this repo for the best tools as they become ""Awesome""
Tools for prompt engineers
- Lexica - A Stable Diffusion prompts search engine
- Libraire - Another Stable Diffusion prompts search engine, with over 10M images and prompts
- Krea.ai - A prompt builder with a nice UI, searchable prompts.
- PromptMania prompt builder - A prompt builder that supports MJ, SD and Dalle, with visual examples and a lot of modifiers
- Promptbase Marketplace - Buy and sell your promtps for
💰
- GPT-2 prompt generator - A GPT2 model trained to autocomplete MJ prompts
Artist/Modifier studies
- Stable diffusion artist study - A huge list of artist (no living) with examples by (@sureailabs, @proximasan, @EErratica, and @KyrickYoung)
- Stable Diffusion Portrait Prompt Study - A great resource for seeing how different prompts change the style and effects of portrait images.
- Stable Diffusion Artist Style Comparison - A great resource shwoing off artists' styles using the same prompt.
- StableDiffusion modifier study - A great study of modifiers that can enhance your prompts significantly
- Google doc with 3800+ artists and styles - Great collaborative effort 3800+ artists and styles + tips for prompting. Continuesly updated. (without generated images)
Browser extensions
- Dalle prompt helper - a chrome extension to inject prompts into the Dalle interface by @altryne
Tips and tricks
- CLIP interrogator - Convert uploaded images into prompts by @pharampsychotic
- img2prompt - Hosted version of CLIP interrogator on Replicate. Upload image, get prompt ideas.
Inspiration tools
- same.energy - A visual exploration search engine.
- CLIP retrieval - Allows you to browse the major datasets the img-2-text models were trained on.
Post processing tools
Resolution upscale - subscription
- Gigapixel upscaler Great upscaler app + web. One time payment
- https://letsenhance.io/ - LetEnhance is a credit based enhancement system
Resolution upscale - free
- WebUI repo has upscalers built in!
- real-esrgan - A hosted version of real-ERSGan with optional face correction
- Cupscale - Windows app that upscales with ERSGan on your GPU
- chaiNNer - A flowchart/node-based image processing GUI for Windows, MacOS, and Linux
Fix faces
Fix hands
Beutify
- TBD
Outcrop
- TBD
Inpaint
- TBD
Communities
Discord
- Stable Diffusion discord - A great community with folks who help each other
- MidJourney - A huge community of image synthesis folks, prompt help, inspiration channels, etc
- r/StableDiffusion - A rapidly growing Subreddit for Stable Diffusion related content - Community Run
- r/MidJourney - The official subreddit for MidJourney related Content
Theory & Learning
Tutorials
- How to get images that don't suck - A Beginner/Intermediate Guide to Getting Cool Images from Stable Diffusion, by u/pxan on Reddit
- Steps for getting better images - A good guide published on the r/StableDiffusion subreddit detailing good prompt crafting.
- A-Traveler-s-Guide-to-the-Latent-Space - In depth guide for prompt engineering.
- Dalle2 prompt book - A great, visual intro to prompt creation by @guyp - Dalle focused
YouTube Video Resources
- bycloud - A channel focused on AI related content, with a lot of content foscusing on AI-Generated artwork.
- Is Stable Diffusion Actually Better Than DALL-E 2? - A video from bycloud comparing Stable Diffusion to DALL-E 2.
- The Current State of AI Generated Art Another video from bycloud showing the history and current world of AI Generated art (Released just before Stable Diffusion was truly a thing, talks about it generally with Latent Diffusion though).
- MattVidPro AI - A channel mostly focused on AI related content, including MidJourney, DALL-E 2, and Stable Diffusion. -Text to Image AI Backlash - Should AI be regulated? - A video by MattVidPro AI covering backlash to the release of Stable Diffusion and addressing the arguments about if AI should be regulated by law. Includes part of an interview with Emad Mostaque, the creator of Stability.
- Scott Detweiler - A great channel featuring videos covering MidJourney and Stable Diffusion content
Twitter Threads
- Dalle vs MJ vs StableDiffusion - A great thread comparing the 3 main models by @fabianstelzer
- Stable Diffusion explained - A easy to udnerstand stable diffusion explanation thread by @ai__pub
Notable Twitter Accounts
- Ai, AiArt, Generative - A twitter list of 70+ #aiArt community members, a stream of conciuosness for the field
- @ClaireSilver12 - Great content, tips and tricks, up to date knowledge about ai synthesis
- @TomLikesRobots - Deep insight into this new tech, with updates
- @diffusionBot - A stableDiffusion bot that generates a prompt right in twitter replies when you mention it.
- Whats AI - Louis Bouchard - Accessible AI concepts, paper reviews, youtube videos
Upcoming exciting projects
🚨These are some of amazing things folks are working on, and is worth keeping in mind, maybe register to their waiting list or give them a follow
- Alpaca - Photoshop plugin - Exciting photoshop implementation! DEMO
- Stable Diffusion for Krita - Soon to be releasing plugin to allow Stable Diffusion features within the Krita art program
- Ando - figma plugin - Figma plugin! DEMO
- Stablender - a blender plugin - a WIP blender plugin with SD
If you find this list valuable
Contribute
Contributions more than welcome! In fact it's why I wrote this list, to get contributions and have folks subscribe to changes to get notified about new and exciting stuff coming to this world of AI art
Read the contribution guidelines first.
Acknowledgements and shoutouts
@pharampsychotic - For the insane tools list on their website, the support in DMs, and the spaces with a lot of patience and answers",3
55,"Why are our computer systems so complex and so insecure? For years I’ve been trying to explain my understanding of this question. Here’s one explanation–which happens to be in the context of voting computers, but it’s a general phenomenon about all our computers:
There are many layers between the application software that implements an electoral function and the transistors inside the computers that ultimately carry out computations. These layers include the election application itself (e.g., for voter registration or vote tabulation); the user interface; the application runtime system; the operating system (e.g., Linux or Windows); the system bootloader (e.g., BIOS or UEFI); the microprocessor firmware (e.g., Intel Management Engine); disk drive firmware; system-on-chip firmware; and the microprocessor’s microcode. For this reason, it is difficult to know for certain whether a system has been compromised by malware. One might inspect the application-layer software and confirm that it is present on the system’s hard drive, but any one of the layers listed above, if hacked, may substitute a fraudulent application layer (e.g., vote-counting software) at the time that the application is supposed to run. As a result, there is no technical mechanism that can ensure that every layer in the system is unaltered and thus no technical mechanism that can ensure that a computer application will produce accurate results.[Securing the Vote, page 89-90]
So, computers are insecure because they have so many complex layers.
But that doesn’t explain why there are so many layers, and why those layers are so complex–even for what “should be a simple thing” like counting up votes.
Recently I came across a really good explanation: a keynote talk by Thomas Dullien entitled “Security, Moore’s law, and the anomaly of cheap complexity” at CyCon 2018, the 10th International Conference on Cyber Conflict, organized by NATO.
Thomas Dullien’s talk video is here, but if you want to just read the slides, they are here.
As Dullien explains,
A modern 2018-vintage CPU contains a thousand times more transistors than a 1989-vintage microprocessor. Peripherals (GPUs, NICs, etc.) are objectively getting more complicated at a superlinear rate. In his experience as a cybersecurity expert, the only thing that ever yielded real security gains was controlling complexity. His talk examines the relationship between complexity and failure of security, and discusses the underlying forces that drive both.
Transistors-per-chip is still increasing every year; there are 3 new CPUs per human per year. Device manufacturers are now developing their software even before the new hardware is released. Insecurity in computing is growing faster than security is improving.
The anomaly of cheap complexity. For most of human history, a more complex device was more expensive to build than a simpler device. This is not the case in modern computing. It is often more cost-effective to take a very complicated device, and make it simulate simplicity, than to make a simpler device. This is because of economies of scale: complex general-purpose CPUs are cheap. On the other hand, custom-designed, simpler, application-specific devices, which could in principle be much more secure, are very expensive.
This is driven by two fundamental principles in computing: Universal computation, meaning that any computer can simulate any other; and Moore’s law, predicting that each year the number of transistors on a chip will grow exponentially. ARM Cortex-M0 CPUs cost pennies, though they are more powerful than some supercomputers of the 20th century.
The same is true in the software layers. A (huge and complex) general-purpose operating system is free, but a simpler, custom-designed, perhaps more secure OS would be very expensive to build. Or as Dullien asks, “How did this research code someone wrote in two weeks 20 years ago end up in a billion devices?”
Then he discusses hardware supply-chain issues: “Do I have to trust my CPU vendor?” He discusses remote-management infrastructures (such as the “Intel Management Engine” referred to above): “In the real world, ‘possession’ usually implies ‘control’. In IT, ‘possession’ and ‘control’ are decoupled. Can I establish with certainty who is in control of a given device?”
He says, “Single bitflips can make a machine spin out of control, and the attacker can carefully control the escalating error to his advantage.” (Indeed, I’ve studied that issue myself!)
Dullien quotes the science-fiction author Robert A. Heinlein:
“How does one design an electric motor? Would you attach a bathtub to it, simply because one was available? Would a bouquet of flowers help? A heap of rocks? No, you would use just those elements necessary to its purpose and make it no larger than needed — and you would incorporate safety factors. Function controls design.”Heinlein, The Moon Is A Harsh Mistress
and adds, “Software makes adding bathtubs, bouquets of flowers, and rocks, almost free. So that’s what we get.”
Dullien concludes his talk by saying, “When I showed the first [draft of this talk] to some coworkers they said, ‘you really need to end on a more optimistic note.” So Dullien gives optimism a try, discussing possible advances in cybersecurity research; but still he gives us only a 10% chance that society can get this right.
Postscript: Voting machines are computers of this kind. Does their inherent insecurity mean that we cannot use them for counting votes? No. The consensus of election-security experts, as presented in the National Academies study, is: we should use optical-scan voting machines to count paper ballots, because those computers, when they are not hacked, are much more accurate than humans. But we must protect against bugs, against misconfigurations, against hacking, by always performing risk-limiting audits, by hand, of an appropriate sample of the paper ballots that the voters marked themselves.
Comments
Eric Schmidt, the former Google chairman, told Reuters in a recent interview that high-end processors should have kill-switches.
“Knowing where the chips go is probably a very good thing. You could for example, on every chip put in essentially a public private key pair, which authenticates it and allows it to work”.
hxxps://www.reuters.com/technology/chip-challenge-keeping-western-semiconductors-out-russian-weapons-2022-04-01/
What he won’t tell is that this is already a reality, as I learned after having my air-gapped system and Pixel phone wiped remotely for researching “silent speech interfaces”, which goes against Google’s interest for the public to know about. There is no security when silicon trojans are inside of every CPU.",2
56,"r/K selection theory
In ecology, r/K selection theory relates to the selection of combinations of traits in an organism that trade off between quantity and quality of offspring. The focus on either an increased quantity of offspring at the expense of individual parental investment of r-strategists, or on a reduced quantity of offspring with a corresponding increased parental investment of K-strategists, varies widely, seemingly to promote success in particular environments. The concepts of quantity or quality offspring are sometimes referred to as ""cheap"" or ""expensive"", a comment on the expendable nature of the offspring and parental commitment made.[1] The stability of the environment can predict if many expendable offspring are made or if fewer offspring of higher quality would lead to higher reproductive success. An unstable environment would encourage the parent to make many offspring, because the likelihood of all (or the majority) of them surviving to adulthood is slim. In contrast, more stable environments allow parents to confidently invest in one offspring because they are more likely to survive to adulthood.
The terminology of r/K-selection was coined by the ecologists Robert MacArthur and E. O. Wilson in 1967[2] based on their work on island biogeography;[3] although the concept of the evolution of life history strategies has a longer history[4] (see e.g. plant strategies).
The theory was popular in the 1970s and 1980s, when it was used as a heuristic device, but lost importance in the early 1990s, when it was criticized by several empirical studies.[5][6] A life-history paradigm has replaced the r/K selection paradigm, but continues to incorporate its important themes as a subset of life history theory.[7] Some scientists now prefer to use the terms fast versus slow life history as a replacement for, respectively, r versus K reproductive strategy.[8]
Overview[edit]
In r/K selection theory, selective pressures are hypothesised to drive evolution in one of two generalized directions: r- or K-selection.[2] These terms, r and K, are drawn from standard ecological algebra as illustrated in the simplified Verhulst model of population dynamics:[9]
where N is the population, r is the maximum growth rate, K is the carrying capacity of the local environment, and dN/dt, the derivative of N with respect to time t, is the rate of change in population with time. Thus, the equation relates the growth rate of the population N to the current population size, incorporating the effect of the two constant parameters r and K. (Note that decrease is negative growth.) The choice of the letter K came from the German Kapazitätsgrenze (capacity limit), while r came from rate.
r-selection[edit]
r-selected species are those that emphasize high growth rates, typically exploit less-crowded ecological niches, and produce many offspring, each of which has a relatively low probability of surviving to adulthood (i.e., high r, low K).[10] A typical r species is the dandelion (genus Taraxacum).
In unstable or unpredictable environments, r-selection predominates due to the ability to reproduce rapidly. There is little advantage in adaptations that permit successful competition with other organisms, because the environment is likely to change again. Among the traits that are thought to characterize r-selection are high fecundity, small body size, early maturity onset, short generation time, and the ability to disperse offspring widely.
Organisms whose life history is subject to r-selection are often referred to as r-strategists or r-selected. Organisms that exhibit r-selected traits can range from bacteria and diatoms, to insects and grasses, to various semelparous cephalopods and small mammals, particularly rodents.
K-selection[edit]
By contrast, K-selected species display traits associated with living at densities close to carrying capacity and typically are strong competitors in such crowded niches, that invest more heavily in fewer offspring, each of which has a relatively high probability of surviving to adulthood (i.e., low r, high K). In scientific literature, r-selected species are occasionally referred to as ""opportunistic"" whereas K-selected species are described as ""equilibrium"".[10]
In stable or predictable environments, K-selection predominates as the ability to compete successfully for limited resources is crucial and populations of K-selected organisms typically are very constant in number and close to the maximum that the environment can bear (unlike r-selected populations, where population sizes can change much more rapidly).
Traits that are thought to be characteristic of K-selection include large body size, long life expectancy, and the production of fewer offspring, which often require extensive parental care until they mature. Organisms whose life history is subject to K-selection are often referred to as K-strategists or K-selected.[11] Organisms with K-selected traits include large organisms such as elephants, humans, and whales, but also smaller long-lived organisms such as Arctic terns,[12] parrots and eagles.
Continuous spectrum[edit]
Although some organisms are identified as primarily r- or K-strategists, the majority of organisms do not follow this pattern. For instance, trees have traits such as longevity and strong competitiveness that characterise them as K-strategists. In reproduction, however, trees typically produce thousands of offspring and disperse them widely, traits characteristic of r-strategists.[13]
Similarly, reptiles such as sea turtles display both r- and K-traits: although sea turtles are large organisms with long lifespans (provided they reach adulthood), they produce large numbers of unnurtured offspring.
The r/K dichotomy can be re-expressed as a continuous spectrum using the economic concept of discounted future returns, with r-selection corresponding to large discount rates and K-selection corresponding to small discount rates.[14]
Ecological succession[edit]
In areas of major ecological disruption or sterilisation (such as after a major volcanic eruption, as at Krakatoa or Mount St. Helens), r- and K-strategists play distinct roles in the ecological succession that regenerates the ecosystem. Because of their higher reproductive rates and ecological opportunism, primary colonisers typically are r-strategists and they are followed by a succession of increasingly competitive flora and fauna. The ability of an environment to increase energetic content, through photosynthetic capture of solar energy, increases with the increase in complex biodiversity as r species proliferate to reach a peak possible with K strategies.[15]
Eventually a new equilibrium is approached (sometimes referred to as a climax community), with r-strategists gradually being replaced by K-strategists which are more competitive and better adapted to the emerging micro-environmental characteristics of the landscape. Traditionally, biodiversity was considered maximized at this stage, with introductions of new species resulting in the replacement and local extinction of endemic species.[16] However, the intermediate disturbance hypothesis posits that intermediate levels of disturbance in a landscape create patches at different levels of succession, promoting coexistence of colonizers and competitors at the regional scale.
Application[edit]
While usually applied at the level of species, r/K selection theory is also useful in studying the evolution of ecological and life history differences between subspecies, for instance the African honey bee, A. m. scutellata, and the Italian bee, A. m. ligustica.[17] At the other end of the scale, it has also been used to study the evolutionary ecology of whole groups of organisms, such as bacteriophages.[18] Other researchers have proposed that the evolution of human inflammatory responses is related to r/K selection.[19]
Some researchers, such as Lee Ellis, J. Philippe Rushton, and Aurelio José Figueredo, have applied r/K selection theory to various human behaviors, including crime,[20] sexual promiscuity, fertility, IQ, and other traits related to life history theory.[21][22] Rushton's work resulted in him developing ""differential K theory"" to attempt to explain many variations in human behavior across geographic areas, a theory which has been criticized by many other researchers.[22][23]
Status[edit]
Although r/K selection theory became widely used during the 1970s,[24][25][26][27] it also began to attract more critical attention.[28][29][30][31] In particular, a review by the ecologist Stephen C. Stearns drew attention to gaps in the theory, and to ambiguities in the interpretation of empirical data for testing it.[32]
In 1981, a review of the r/K selection literature by Parry demonstrated that there was no agreement among researchers using the theory about the definition of r- and K-selection, which led him to question whether the assumption of a relation between reproductive expenditure and packaging of offspring was justified.[33] A 1982 study by Templeton and Johnson showed that in a population of Drosophila mercatorum under K-selection the population actually produced a higher frequency of traits typically associated with r-selection.[34] Several other studies contradicting the predictions of r/K selection theory were also published between 1977 and 1994.[35][36][37][38]
When Stearns reviewed the status of the theory in 1992,[39] he noted that from 1977 to 1982 there was an average of 42 references to the theory per year in the BIOSIS literature search service, but from 1984 to 1989 the average dropped to 16 per year and continued to decline. He concluded that r/K theory was a once useful heuristic that no longer serves a purpose in life history theory.[40]
More recently, the panarchy theories of adaptive capacity and resilience promoted by C. S. Holling and Lance Gunderson have revived interest in the theory, and use it as a way of integrating social systems, economics and ecology.[41]
Writing in 2002, Reznick and colleagues reviewed the controversy regarding r/K selection theory and concluded that:
The distinguishing feature of the r- and K-selection paradigm was the focus on density-dependent selection as the important agent of selection on organisms' life histories. This paradigm was challenged as it became clear that other factors, such as age-specific mortality, could provide a more mechanistic causative link between an environment and an optimal life history (Wilbur et al. 1974;[28] Stearns 1976,[42] 1977[32]). The r- and K-selection paradigm was replaced by new paradigm that focused on age-specific mortality (Stearns, 1976;[42] Charlesworth, 1980[43]). This new life-history paradigm has matured into one that uses age-structured models as a framework to incorporate many of the themes important to the r–K paradigm.
Alternative approaches are now available both for studying life history evolution (e.g. Leslie matrix for an age-structured population) and for density-dependent selection (e.g. variable density lottery model[44]).
See also[edit]
- Evolutionary game theory
- Life history theory
- Minimax/maximin strategy
- Ruderal species
- Semelparity and iteroparity
- Trivers–Willard hypothesis
References[edit]
- ^ ""r and K selection"". www.bio.miami.edu. Retrieved 2020-10-27.
- ^ a b Pianka, E.R. (1970). ""On r and K selection"". American Naturalist. 104 (940): 592–597. doi:10.1086/282697. S2CID 83933177.
- ^ MacArthur, R.; Wilson, E.O. (1967). The Theory of Island Biogeography (2001 reprint ed.). Princeton University Press. ISBN 978-0-691-08836-5.
- ^ For example: Margalef, R. (1959). ""Mode of evolution of species in relation to their places in ecological succession"". XVTH International Congress of Zoology.
- ^ Roff, Derek A. (1993). Evolution Of Life Histories: Theory and Analysis. Springer. ISBN 978-0-412-02391-0.
- ^ Stearns, Stephen C. (1992). The Evolution of Life Histories. Oxford University Press. ISBN 978-0-19-857741-6.
- ^ a b Reznick, D; Bryant, MJ; Bashey, F (2002). ""r-and K-selection revisited: the role of population regulation in life-history evolution"" (PDF). Ecology. 83 (6): 1509–1520. doi:10.1890/0012-9658(2002)083[1509:RAKSRT]2.0.CO;2. Archived from the original (PDF) on 2010-12-30. Retrieved 2013-05-11.
- ^ Jeschke, Jonathan M.; Kokko, Hanna (2009). ""The roles of body size and phylogeny in fast and slow life histories"". Evolutionary Ecology. 23 (6): 867–878. doi:10.1007/s10682-008-9276-y. S2CID 38289373.
- ^ Verhulst, P.F. (1838). ""Notice sur la loi que la population pursuit dans son accroissement"". Corresp. Math. Phys. 10: 113–121.
- ^ a b For example: Weinbauer, M.G.; Höfle, M.G. (1 October 1998). ""Distribution and Life Strategies of Two Bacterial Populations in a Eutrophic Lake"". Appl. Environ. Microbiol. 64 (10): 3776–3783. Bibcode:1998ApEnM..64.3776W. doi:10.1128/AEM.64.10.3776-3783.1998. PMC 106546. PMID 9758799.
- ^ ""r and K selection"". University of Miami Department of Biology. Retrieved February 4, 2011.
- ^ John H. Duffus; Douglas M. Templeton; Monica Nordberg (2009). Concepts in Toxicology. Royal Society of Chemistry. p. 171. ISBN 978-0-85404-157-2.
- ^ Hrdy, Sarah Blaffer (2000), ""Mother Nature: Maternal Instincts and How They Shape the Human Species"" (Ballantine Books)
- ^ Reluga, T.; Medlock, J.; Galvani, A. (2009). ""The discounted reproductive number for epidemiology"". Mathematical Biosciences and Engineering. 6 (2): 377–393. doi:10.3934/mbe.2009.6.377. PMC 3685506. PMID 19364158.
- ^ Gunderson, Lance H.; Holling, C.S. (2001). Panarchy: Understanding Transformations In Human And Natural Systems. Island Press. ISBN 978-1-55963-857-9.
- ^ McNeely, J. A. (1994). ""Lessons of the past: Forests and Biodiversity"". Biodiversity and Conservation. 3: 3–20. CiteSeerX 10.1.1.461.5908. doi:10.1007/BF00115329. S2CID 245731.
- ^ Fewell, Jennifer H.; Susan M. Bertram (2002). ""Evidence for genetic variation in worker task performance by African and European honeybees"". Behavioral Ecology and Sociobiology. 52 (4): 318–25. doi:10.1007/s00265-002-0501-3. S2CID 22128779.
- ^ Keen, E. C. (2014). ""Tradeoffs in bacteriophage life histories"". Bacteriophage. 4 (1): e28365. doi:10.4161/bact.28365. PMC 3942329. PMID 24616839.
- ^ VAN BODEGOM, D.; MAY, L.; MEIJ, H. J.; WESTENDORP, R. G. J. (2007). ""Regulation of Human Life Histories: The Role of the Inflammatory Host Response"". Annals of the New York Academy of Sciences. 1100 (1): 84–97. Bibcode:2007NYASA1100...84V. doi:10.1196/annals.1395.007. PMID 17460167. S2CID 43589115.
- ^ Ellis, Lee (1987-01-01). ""Criminal behavior and r/K selection: An extension of gene‐based evolutionary theory"". Deviant Behavior. 8 (2): 149–176. doi:10.1080/01639625.1987.9967739. ISSN 0163-9625.
- ^ Figueredo, Aurelio José; Vásquez, Geneva; Brumbach, Barbara Hagenah; Schneider, Stephanie M. R. (2007-03-01). ""The K-factor, Covitality, and personality"". Human Nature. 18 (1): 47–73. doi:10.1007/bf02820846. ISSN 1045-6767. PMID 26181744. S2CID 10877330.
- ^ a b Weizmann, Fredric; Wiener, Neil I.; Wiesenthal, David L.; Ziegler, Michael (1990). ""Differential K theory and racial hierarchies"". Canadian Psychology. 31 (1): 1–13. doi:10.1037/h0078934.
- ^ Peregrine, P (2003). ""Cross-cultural evaluation of predicted associations between race and behavior"". Evolution and Human Behavior. 24 (5): 357–364. doi:10.1016/s1090-5138(03)00040-0.
- ^ Gadgil, M.; Solbrig, O.T. (1972). ""Concept of r-selection and K-selection — evidence from wild flowers and some theoretical consideration"" (PDF). Am. Nat. 106 (947): 14–31. doi:10.1086/282748. JSTOR 2459833. S2CID 86412666.
- ^ Long, T.; Long, G. (1974). ""Effects of r-selection and K-selection on components of variance for 2 quantitative traits"". Genetics. 76 (3): 567–573. doi:10.1093/genetics/76.3.567. PMC 1213086. PMID 4208860.
- ^ Grahame, J. (1977). ""Reproductive effort and r-selection and K-selection in 2 species of Lacuna (Gastropoda-Prosobranchia)"". Mar. Biol. 40 (3): 217–224. doi:10.1007/BF00390877. S2CID 82459157.
- ^ Luckinbill, L.S. (1978). ""r and K selection in experimental populations of Escherichia coli"". Science. 202 (4373): 1201–1203. Bibcode:1978Sci...202.1201L. doi:10.1126/science.202.4373.1201. PMID 17735406. S2CID 43276882.
- ^ a b Wilbur, H.M.; Tinkle, D.W.; Collins, J.P. (1974). ""Environmental certainty, trophic level, and resource availability in life history evolution"". American Naturalist. 108 (964): 805–816. doi:10.1086/282956. JSTOR 2459610. S2CID 84902967.
- ^ Barbault, R. (1987). ""Are still r-selection and K-selection operative concepts?"". Acta Oecologica-Oecologia Generalis. 8: 63–70.
- ^ Kuno, E. (1991). ""Some strange properties of the logistic equation defined with r and K – inherent defects or artifacts"". Researches on Population Ecology. 33: 33–39. doi:10.1007/BF02514572. S2CID 9459529.
- ^ Getz, W.M. (1993). ""Metaphysiological and evolutionary dynamics of populations exploiting constant and interactive resources – r-K selection revisited"". Evolutionary Ecology. 7 (3): 287–305. doi:10.1007/BF01237746. S2CID 21296836.
- ^ a b Stearns, S.C. (1977). ""Evolution of life-history traits – critique of theory and a review of data"" (PDF). Annu. Rev. Ecol. Syst. 8: 145–171. doi:10.1146/annurev.es.08.110177.001045. Archived from the original (PDF) on 2008-12-16.
- ^ Parry, G.D. (March 1981). ""The Meanings of r- and K-selection"". Oecologia. 48 (2): 260–4. Bibcode:1981Oecol..48..260P. doi:10.1007/BF00347974. PMID 28309810. S2CID 30728470.
- ^ Templeton A.R.; Johnson, J.S. (1982). ""Life History Evolution Under Pleiotropy and K-selection in a Natural Population of Drosophila mercatorum"". In Barker, J.S.F.; Starmer, William T. (eds.). Ecological genetics and evolution: the cactus-yeast-drosophila model system. Academic Press. pp. 225–239. ISBN 978-0-12-078820-0.
- ^ Snell, Terry W.; King, Charles E. (December 1977). ""Lifespan and Fecundity Patterns in Rotifers: The Cost of Reproduction"". Evolution. 31 (4): 882–890. doi:10.2307/2407451. JSTOR 2407451. PMID 28563718.
- ^ Taylor, Charles E.; Condra, Cindra (November 1980). ""r- and K-Selection in Drosophila pseudoobscura"". Evolution. 34 (6): 1183–93. doi:10.2307/2408299. JSTOR 2408299. PMID 28568469.
- ^ Hollocher, H.; Templeton, A.R. (April 1994). ""The molecular through ecological genetics of abnormal abdomen in Drosophila mercatorum. VI. The non-neutrality of the Y chromosome rDNA polymorphism"". Genetics. 136 (4): 1373–84. doi:10.1093/genetics/136.4.1373. PMC 1205918. PMID 8013914.
- ^ Templeton, A.R.; Hollocher, H.; Johnston, J.S. (June 1993). ""The molecular through ecological genetics of abnormal abdomen in Drosophila mercatorum. V. Female phenotypic expression on natural genetic backgrounds and in natural environments"". Genetics. 134 (2): 475–85. doi:10.1093/genetics/134.2.475. PMC 1205491. PMID 8325484.
- ^ Stearns, S.C. (1992). The Evolution of Life Histories. Oxford University Press. ISBN 978-0-19-857741-6.
- ^ Graves, J. L. (2002). ""What a tangled web he weaves Race, reproductive strategies and Rushton's life history theory"". Anthropological Theory. 2 (2): 2 131–154. doi:10.1177/1469962002002002627. S2CID 144377864.
- ^ Gunderson, L. H. and Holling C. S. (2001) Panarchy: Understanding Transformations in Human and Natural Systems Island Press. ISBN 9781597269391.
- ^ a b Stearns, S.C. (1976). ""Life history tactics: a review of the ideas"". Quarterly Review of Biology. 51 (1): 3–47. doi:10.1086/409052. PMID 778893. S2CID 37813334.
- ^ Charlesworth, B. (1980). Evolution in age structured populations. Cambridge, UK: Cambridge University Press.
- ^ Bertram, Jason; Masel, Joanna (October 2019). ""Density-dependent selection and the limits of relative fitness"". Theoretical Population Biology. 129: 81–92. doi:10.1016/j.tpb.2018.11.006. PMID 30664884.",2
57,"Ultrasonic wireless ‘neural dust’ sensors monitor nerves, muscles in real time
August 5, 2016
University of California, Berkeley engineers have designed and built millimeter-scale device wireless, batteryless “neural dust” sensors and implanted them in muscles and peripheral nerves of rats to make in vivo electrophysiological recordings.
The new technology opens the door to “electroceuticals” — bioelectronic methods to monitor and record wireless electromyogram (EMG) signals from muscle membranes and electroneurogram (ENG) signals from local neuron electrical activity, and to stimulate the immune system, reduce inflammation, and treat disorders such as epilepsy.
The technology could also improve neural control of prosthetics (allowing a paraplegic to control a computer or a robotic arm, for example) by stimulating nerves and muscles directly, instead of requiring implanted wires.
The neural-dust sensors use ultrasound technology to both power the sensors and read out measurements. Ultrasound is already well-developed for hospital use and can penetrate nearly anywhere in the body, unlike radio waves.
The researchers reported their findings August 3 in an open-access paper in the journal Neuron.
How a neural dust “mote” sensor monitors neural and muscle signals
1. A team implants the neural dust mote. In the reported study, the mote was implanted in the rat sciatic nerve to do ENG recordings and in the gastrocnemius muscle to do EMG recordings. The tether-less connection also avoids potential infections and adverse biological responses due to micro-motion of the implant within the tissue.
2. An external ultrasonic generator sends a ultrasound signal to a piezoelectric crystal, which converts the sound energy into an electrical voltage, used to power a transistor circuit — no battery required.
3. When neurons or muscle fibers fire, they generate a tiny voltage (action potential) that the two electrodes pick up and send to the transistor.
4. The transistor amplifies the signal and drives the piezoelectric crystal to vibrate at an ultrasonic rate.
5. That vibration interferes with the transmitted ultrasonic signal, causing a modified “backscatter” signal that communicates information about the voltage across the sensor’s two electrodes.
6. The backscatter ultrasound signal is decoded to extract EMG or ENG data.
7. A computer displays and records the information.
Microscale motes: future research
The experiments so far have involved the peripheral nervous system and muscles, using an external ultrasonic patch over the implanted site to acquire information from the motes for the desired diagnosis or therapy.
But according to the researchers, neural dust motes can be implanted anywhere in the body, including the central nervous system and brain to control prosthetics. This would be an alternative to today’s implantable electrodes (for Parkinson’s disease, for example), which require wires that pass through holes in the skull and degrade within one to two years.
The researchers are now building motes from biocompatible thin films, which would potentially last in the body without degradation for a decade or more. Up to hundreds of wireless sensors could be sealed in, avoiding infection and unwanted movement of the electrodes, and could last a timeline, according to the researchers.
The team is also now working to miniaturize the device further and they plan to use beam-steering technology to focus the ultrasonic signals on individual motes. The team is also building little backpacks for rats to hold the ultrasound transceiver that will record data from implanted motes. And the researchers are working to expand the motes’ ability to detect non-electrical signals, such as oxygen or hormone levels.
The researchers estimate that they could eventually shrink the sensors down to a cube 50 micrometers on a side. At that size, the motes could monitor a few specific nerve axons and continually record their electrical activity.
The researchers conceived of the idea of neural dust about five years ago, but initial attempts to power an implantable device and read out the data using radio waves were disappointing. Radio attenuates very quickly with distance in tissue, so communicating with devices deep in the body would be difficult without using potentially damaging high-intensity radiation. In 2013, the researchers published an open-access arXiv paper that described how a neural-dust system with ultrasonic signals might work.
The ongoing research is supported by the U.S. Defense Advanced Research Projects Agency as part of DARPA’s Electrical Prescriptions (ElectRx) program, which is focused in part on developing interface technologies that are suitable for chronic use for biosensing and neuromodulation of specific peripheral nerves.
UC Berkeley | “Neural dust” sensor
Abstract of Wireless Recording in the Peripheral Nervous System with Ultrasonic Neural Dust
The emerging field of bioelectronic medicine seeks methods for deciphering and modulating electrophysiological activity in the body to attain therapeutic effects at target organs. Current approaches to interfacing with peripheral nerves and muscles rely heavily on wires, creating problems for chronic use, while emerging wireless approaches lack the size scalability necessary to interrogate small-diameter nerves. Furthermore, conventional electrode-based technologies lack the capability to record from nerves with high spatial resolution or to record independently from many discrete sites within a nerve bundle. Here, we demonstrate neural dust, a wireless and scalable ultrasonic backscatter system for powering and communicating with implanted bioelectronics. We show that ultrasound is effective at delivering power to mm-scale devices in tissue; likewise, passive, battery-less communication using backscatter enables high-fidelity transmission of electromyogram (EMG) and electroneurogram (ENG) signals from anesthetized rats. These results highlight the potential for an ultrasound-based neural interface system for advancing future bioelectronics-based therapies.",2
58,"Will AI image generators kill the stock image industry? It’s a question asked by many following the rise of text-to-image AI models in recent years. The answer from the industry’s incumbents, though, is “no” — not if we can start selling AI-generated content first.
Today, stock image giant Shutterstock has announced an extended partnership with OpenAI, which will see the AI lab’s text-to-image model DALL-E 2 directly integrated into Shutterstock “in the coming months.” In addition, Shutterstock is launching a “Contributor Fund” that will reimburse creators when the company sells work to train text-to-image AI models. This follows widespread criticism from artists whose output has been scraped from the web without their consent to create these systems. Notably, Shutterstock is also banning the sale of AI-generated art on its site that is not made using its DALL-E integration.
Shutterstock is banning third-party AI art and offering its own DALL-E integration
In a press statement, Shutterstock’s CEO Paul Hennessy said: “The mediums to express creativity are constantly evolving and expanding. We recognize that it is our great responsibility to embrace this evolution and to ensure that the generative technology that drives innovation is grounded in ethical practices.”
Sam Altman, CEO of OpenAI, said: “We’re excited for Shutterstock to offer DALL-E images to its customers as one of the first deployments through our API, and we look forward to future collaborations as artificial intelligence becomes an integral part of artists’ creative workflows.”
This isn’t the first time Shutterstock and OpenAI have worked together in this domain. From 2021 onwards, Shutterstock sold images and metadata to OpenAI to help create DALL-E (OpenAI’s Altman describes this data as “critical to the training of DALL-E”). Now, with the integration of OpenAI’s text-to-image AI, the partnership is going full circle, and DALL-E’s output will compete with the same individuals whose work was used to train it.
If Shutterstock’s images were as important to creating DALL-E as Altman claims, the platform’s contributors may understandably feel aggrieved that their own content is being used to put them out of a job. This is why Shutterstock is also launching its Contributor Fund, which will be used to pay artists, photographers, and designers when content they uploaded to Shutterstock is sold by the company to firms like OpenAI in order to develop generative AI models.
It’s a significant move — the first major initiative by a platform holder to reimburse creators in this way — but it also underscores the fraught legal and ethical questions surrounding this new technology.
Although scraping or buying data to train AI art generators seems to be legal (covered by Fair Use), many experts worry about future challenges and complications. Getty Images, for example, has banned the sale of AI art on its platform because of fears that its inability to copyright the output of these systems will lead to licensing problems for customers.
When asked about these issues, a spokesperson for Shutterstock told The Verge that there were “lot of questions and uncertainty around this new technology, specifically when it comes to the concept of ownership,” but that the company’s stance is that “because AI content generation models leverage the IP of many artists and their content, AI-generated content ownership cannot be assigned to an individual and must instead compensate the many artists who were involved in the creation of each new piece of content.”
The Contributor Fund will pay Shutterstock users when their content is used to train AI models
This is why Shutterstock is banning AI art uploaded to its platform by third parties — because it can’t validate the model used to create the content so can’t be sure who owns the copyright. (Of course, banning third-party AI-generated art will also help protect its own business by funneling users towards its DALL-E integration.) And while the company seems to believe it has no legal obligation to reimburse creators whose content is used to train DALL-E, the creation of the Contributor Fund suggests it foresees criticism and possible damage to its reputation.
“Given the collective nature of generative content, we developed a revenue share compensation model where contributors whose content was involved in training generative models will receive a share of the earnings from datasets and downloads of all AI-generated content produced on our platform,” a Shutterstock spokesperson told The Verge. “Contributors will receive a share of the entire contract value paid by platform partners. The share individual contributors receive will be proportionate to the volume of their content and metadata that is included in the purchased datasets.”
Shutterstock says these payouts will be distributed every six months, and will include “both earnings from data deals as well as royalties from generic licensing on Shutterstock.” The company gave no indication of what a typical payout might be.",3
59,"Veuillez mettre à jour votre navigateur
Votre navigateur n'est plus compatible. Mettez-le à jour pour profiter au mieux de YouTube et de nos dernières fonctionnalités. En savoir plusMe le rappeler plus tard
Votre navigateur n'est plus compatible. Mettez-le à jour pour profiter au mieux de YouTube et de nos dernières fonctionnalités. En savoir plusMe le rappeler plus tard",0
60,"Imagine that you roll out of bed onto a living fungus floor. The walls and ceiling — heck, the whole apartment building, down to the plumbing and electrical systems — are made of fungus too. Wood and concrete are remnants of the distant past; this entire city, from the schools to the stores to the hospitals, is made of living fungus — constantly growing, dying off and regenerating itself.
That's the vision laid out in a provocative new paper, which a team of European academics say is the first-ever exploration of living fungus' potential as a raw material for futuristic, eco-friendly ""monolithic structures"" that would, in their telling, revolutionize the entire built environment and economy.
""We propose to develop a structural substrate by using live fungal mycelium,"" reads the paper. ""Fungal buildings will self-grow, build, and repair themselves.""
The idea is a response to the prospect of catastrophic climate change. Growing our building materials from biological materials, the theory goes, would make construction less dependent on fossil fuels and environmentally-destructive mining operations.
""Fungal materials can have a wide variety of mechanical properties ranging from foam-like to wood-like to polymer-like to elastomer-like,"" Han Wösten, a microbiologist at The Netherlands' Utrecht University who co-authored the not-yet-peer-reviewed paper, told Futurism. ""The fact that we can make wood-like materials implies that we can use it for the building industry.""
Along with other forms of living materials, fungal architecture is not a new idea — other research groups have explored the idea of growing building materials out of mycelium. NASA, for instance, is currently testing whether fungus could grow in Martian soil, potentially giving the space agency a low-cost way to grow space habitats onsite.
But those projects all involve killing the fungus after it grows, a process that makes it sturdier as a building material that the team says has already been used for load-bearing structures or boundary walls.
So far, they say, no one else has explored the possibility of building monolithic structures out of living fungus.
""The selling point of our materials is that it is biodegradable, thereby helping to create a circular economy,"" Wösten said. ""At the same time, it should not degrade when actually used as a building material. We can work around this apparent paradox by coating the material. In fact, we also coat wood with paint of oils to protect it against degradation.""
""It may be that we will find a fungus that creates wood-like materials without the need of pressing,"" he said.
Even with a coating, Wösten went on to explain, the goal is to keep the fungal architecture alive — so that an architect could rejuvenate it with water and trigger further growth if repairs or alternations were necessary. Those same coatings, the team says, could be used to capitalize on the fungus' internal structure of networks to replace things like a building's plumbing, electrical wiring, or other logistical needs.
Important to note: those ideas, like much of the team's research, remain fairly speculative.
Andrew Adamatzky, a computer scientist at the University of the West of England who also co-authored the paper, told Futurism that the team is working to build fungal versions of neuromorphic circuits and other electronics. He conceded that conventional wires are cheaper and easier to work with, but added that ""the living circuits will be self-growing, self-assembling and self-repairing, which no traditional circuitry can do.""
""This is really challenging, but a real opportunity to explore how buildings could grow, self-repair, adapt and disrupt conventional ways of building production by working with highly local resources and growing in-situ to minimize logistics and energy use in material production,"" said Phil Ayres, a co-author of the paper from the Royal Danish Academy of Fine Arts, ""aiming towards a circular economy for construction.""
More on living materials: Scientists Create ""Living Concrete"" That Can Heal Itself",2
61,"The automotive industry is being turned upside down. The traditional distribution model involving the automaker, an importer and a dealership network is being replaced by direct distribution either by automaker-owned dealerships, pop-up stores, or digital sales.
In Norway, the average number of dealership visits when purchasing a car has gone from four to 1.1. The decision is now made at home, on the sofa watching carwow reviews on YouTube.
Europe is turning electric, and the development is fast. EU lawmakers recently backed a new proposal effectively banning the sales of new gasoline and diesel cars starting in 2035.
We must quickly turn the consumer toward EVs. Fortunately, there is a supplementary business model for automakers that thrives in this space: car subscriptions.
This model also fits the modern consumer perfectly. Younger generations are used to subscribing to services, not owning things. The average car subscription customer is 37 years of age, which is why car subscriptions are “The Netflix of cars.”
In a rapidly changing automotive industry, car-subscription schemes are excelling by digitizing the customer experience and bundling services to ensure profitable cash flows for the providers.
Car subscriptions, because of this, are expected to have a substantial impact on the industry.
Automakers and analysts estimate that between 20 to 30 percent of new cars being “sold” in 2025 will be on car subscriptions.
Players such as Care by Volvo have already accounted for 15 percent of the company’s overall registrations in several European markets.
Car subscriptions are a flexible alternative to leasing or owning a vehicle. Consumers subscribe for flexible periods as short as a month, with the ability to cancel at any time. Car subscription concepts often include additional services.
They can be all inclusive or modular add-ons such as maintenance, insurance, tire change, the option to swap a car, and many other services.
Consumers love car subscriptions and often empowers them to make sustainable choices. Car subscriptions help make the green shift from ownership to usership and lowers the barrier to EVs.
In Europe, there are seven times more EVs on car-subscription schemes than cars powered by fossil fuels. A possible reason for this is that flexibility beats uncertainty.
Many consumers are still uncertain about EVs. Their concerns include charging and usage patterns, the fast evolution of the technology and that many EV makers are new to the market.
Car subscriptions allow consumers to test EVs, finding the right one for them, without long delivery periods or putting large sums of money down.
Companies offering car subscriptions are capitalizing on the subscription generation, which has established a lifestyle around pay-as-you-go.
They want to have access to the right form of mobility at the right time and they are extremely focused on sustainably. By automakers providing consumers with a fleet of vehicles that can fit various lifestyles, a long-term relationship is built on the premise of flexibility within the fleet.
Car subscriptions are also a way for non-traditional players to capitalize on offering forms of mobility.
The automotive industry is a large economy, making it attractive for non-industry players such as energy, insurance, and telecommunications companies to launch their own car subscription concepts, positioning them with direct end-user contacts within the mobility ecosystem.
Automakers that implement car-subscription programs as a supplementary business model will not only keep up in this evolving industry, but they will gain a competitive advantage. The time to act is now.",1
62,"Not Found
The requested URL was not found on this server.
Apache/2.4.54 (Ubuntu) Server at txt.fyi Port 443",8
63,"7 September 2022
Lensless camera creates 3D images from single exposure
Real-time 3D imaging method could improve robot navigation and content for 3D displays
WASHINGTON—Researchers have developed a camera that uses a thin microlens array and new image processing algorithms to capture 3D information about objects in a scene with a single exposure. The camera could be useful for a variety of applications such as industrial part inspection, gesture recognition and collecting data for 3D display systems.
Caption: Weijian Yang and Feng Tian developed a camera that uses a thin microlens array and new image processing algorithms to capture 3D information about multiple objects in single exposure. The raw sub-images from the microarray are displayed on the monitor.
Image Credit: Savannah Luy, University of California - Davis
“We consider our camera lensless because it replaces the bulk lenses used in conventional cameras with a thin, lightweight microlens array made of flexible polymer,” said research team leader Weijian Yang from the University of California, Davis. “Because each microlens can observe objects from different viewing angles, it can accomplish complex imaging tasks such as acquiring 3D information from objects partially obscured by objects closer to the camera.”
In the Optica Publishing Group journal Optics Express, Yang and first author Feng Tian, a doctoral student in Yang’s lab, describe the new 3D camera. Because the camera learns from existing data how to digitally reconstruct a 3D scene, it can produce 3D images in real time.
“This 3D camera could be used to give robots 3D vision, which could help them navigate 3D space or enable complex tasks such as manipulation of fine objects,” said Yang. “It could also be used to acquire rich 3D information that could provide content for 3D displays used in gaming, entertainment or many other applications.”
A camera that learns
The new camera grew out of previous work in which the researchers developed a compact microscope that can image 3D microscopic structures for biomedical applications. “We built the microscope using a microlens array and thought that a similar concept could be applied for imaging macroscopic objects,” said Yang.
The individual lenses in the new camera allow it to see objects from different angles or perspectives, which provides depth information. Although other research groups have developed cameras based on single layer microlens arrays, it has been difficult to make them practical because of extensive calibration processes and slow reconstruction speeds.
“Many existing neural networks can perform designated tasks, but the underlying mechanism is difficult to explain and understand,” said Yang. “Our neural network is based on a physical model of image reconstruction. This makes the learning process much easier and results in high quality reconstructions.”
Once the learning process is complete, it can reconstruct images containing objects that are at different distances away from the camera at a very high speed. The new camera doesn’t need calibration and can be used to map the 3D locations and spatial profiles—or outlines—of objects.
Seeing through objects
Caption: The single-shot image acquired by the new camera can be refocused and reconstructed to reveal object scenes at different distances.
Image Credit: : Feng Tian, University of California – Davis
After performing numerical simulations to verify the camera’s performance, the researchers performed 2D imaging that showed perceptually pleasing results. They then tested the camera’s ability to perform 3D imaging of objects at different depths. The resulting 3D reconstruction could be refocused to different depths or distances. The camera also created a depth map that agreed with the actual object arrangement.
“In a final demonstration we showed that our camera could image objects behind the opaque obstacles,” said Yang. “To the best of our knowledge, this is the first demonstration of imaging objects behind opaque obstacles using a lensless camera.”
The researchers are currently working to reduce artifacts, or errors, that appear in the 3D reconstructions and to improve the algorithms to gain even higher quality and speed. They also want to miniaturize the overall device footprint so it could fit into a cellphone, which would make it more portable and enable more applications.
“Our lensless 3D camera uses computational imaging, an emerging approach that jointly optimizes imaging hardware and object reconstruction algorithms to achieve desired imaging tasks and quality,” said Yang. “With the recent development of low-cost, advanced micro-optics manufacturing techniques as well as advancements in machine learning and computational resources, computational imaging will enable many new imaging systems with advanced functionality.”
Paper: F. Tian, W. Yang, “Learned lensless 3D camera,” Opt. Express, 30, 19, 34479-34496 (2022).
DOI: https://doi.org/10.1364/OE.465933
About Optics Express
Optics Express reports on scientific and technology innovations in all aspects of optics and photonics. The bi-weekly journal provides rapid publication of original, peer-reviewed papers. It is published by Optica Publishing Group and led by Editor-in-Chief James Leger of the University of Minnesota, USA. Optics Express is an open-access journal and is available at no cost to readers online. For more information, visit Optics Express.
About Optica Publishing Group (formerly OSA)
Optica Publishing Group is a division of the society, Optica (formerly OSA), Advancing Optics and Photonics Worldwide. It publishes the largest collection of peer-reviewed and most-cited content in optics and photonics, including 18 prestigious journals, the society’s flagship member magazine, and papers and videos from more than 835 conferences. With over 400,000 journal articles, conference papers and videos to search, discover and access, our publications portfolio represents the full range of research in the field from around the globe.
Media Contact
mediarelations@optica.org",3
64,"COORDINATION NEGLECT: HOW LAYTHEORIES OF ORGANIZINGCOMPLICATE COORDINATION INORGANIZATIONSChip Heath and Nancy StaudenmayerABSTRACTWe argue that organizations often fail to organize effectively becauseindividuals have lay theories about organizing that lead tocoordinationneglect. We unpack the notion of coordination neglect and describespecific cognitive phenomena that underlie it. To solve the coordinationproblem, organizations must divide a task and then integrate thecomponents. Individuals display shortcomings that may create problemsat both stages. First, lay theories often focus more on division of laborthan on integration. We discuss evidence that individuals displaypartitionfocus(i.e. they focus on partitioning the task more than on integration)andcomponent focus(i.e. they tend to focus on single components of atightly interrelated set of capabilities, particularly by investing to createhighly specialized components). Second, when individuals attempt tointegrate components of a task, they often fail to use a key mechanism forintegration: ongoing communication. Individuals exhibitinadequatecommunicationbecause the ‘curse of knowledge’ makes it difficult to takethe perspective of another and communicate effectively. More importantly,because specialists find it especially difficult to communicate withspecialists in other areas, the general problem of communication willoften be compounded by insufficient translation.Research in Organizational Behaviour, Volume 22, pages 153–191.2000 by Elsevier Science Inc.ISBN: 0–7623–0641–6153",2
65,"On Sept. 23, Britain’s new prime minister, Liz Truss, announced her budget. Soon after, British bond markets went haywire, and the pound sterling started to plummet—as did support for her party: Truss’s Tories have lost seven points in the polls, and the opposition Labour party has increased its standing by nine, giving it a whopping 33-point lead in election prognoses. Half of Britons think Truss should step down, less than a month into her tenure.
Truss’s budget was ridiculous. With inflation raging and government finances in tatters because of the need for energy-price subsidies, most governments would pull back spending and perhaps raise taxes, but Truss and her team would have none of it. She proposed a larger tax cut than any British leader had since 1972. Yet however misguided, a budget alone wouldn’t trigger such dramatic turbulence in the financial markets. Something else is going on.
The answer is obvious: Britain is turning into an economic basket case because of the energy war being waged in Europe. Europe relies for about 40 percent of its gas needs on Russia. Germany, which is Europe’s manufacturing center, gets about 65 percent of its gas from Russia. (This gas was, until recently, piped in through a giant undersea pipeline.) When the Western allies initially sanctioned Russia in the wake of its invasion of Ukraine, no restrictions were placed on energy—because energy sanctions would quite obviously destroy the European economy.
But over the course of the summer, Moscow choked off the supply of gas. This was a predictable move, given that the European countries were shipping weapons to Ukraine. Yet it appeared to take European leaders by surprise. They started panicking about having sufficient gas for the winter.
It was against this backdrop that cracks appeared in the UK economy. While Britain isn’t overly reliant on Russian gas, the country turns to Europe for much of its supply. Europe is a single gas market, so if you remove the Russian gas, there is less to go around for everyone—including Britain.
Financial markets cottoned on to what was happening in late August, when Goldman Sachs published projections showing inflation in Britain hitting a shocking 22 percent in 2023. A few days later, Deutsche Bank predicted that Britain’s trade deficit would hit 10 percent and that the sterling would shed 30 percent of its value. These are the sorts of figures you see in failed states and war-torn nations. They aren’t remotely sustainable.
These projections were released nearly a month before the budget. They showed clearly how and why sterling would collapse. It wasn’t about the budget—the budget was just a trigger handed to markets by clumsy politicians.
Britain should be viewed as a canary in the coal mine. It is especially susceptible to market swings, given the deep financialization of its economy. But the same process is likely to play out across the whole of Europe this winter. High energy prices are going to collapse European manufacturing and deindustrialize the economy. Europe’s manufacturing base underpins the value of the euro. When this base is obliterated by high energy costs, the euro will sink.
Until very recently, a way back was visible. If a negotiated settlement took place, Russia would restore the gas. After a bad winter, things would go back to normal. That is no longer possible, because the Nord Stream pipelines have been sabotaged. This means that energy prices will remain high in Europe for a very long time—basically until Europe builds a new energy infrastructure.
Britain is only the first shoe to drop. Europe will soon fall, too. The economic consequences will be devastating. Europe is America’s largest trade partner. There is every chance that Europe will slip into an economic depression and pull America down with it—just as happened in the 1930s. The European energy war of 2022 will almost certainly go down in history, along with the Treaty of Versailles, as one of the worst economic blunders in history.",5
66,"Who does that server really serve?by Richard Stallman
On the Internet, proprietary software isn't the only way to lose your computing freedom. Service as a Software Substitute, or SaaSS, is another way to give someone else power over your computing.
The basic point is, you can have control over a program someone else wrote (if it's free), but you can never have control over a service someone else runs, so never use a service where in principle running a program would do.
SaaSS means using a service implemented by someone else as a substitute for running your copy of a program. The term is ours; articles and ads won't use it, and they won't tell you whether a service is SaaSS. Instead they will probably use the vague and distracting term “cloud,” which lumps SaaSS together with various other practices, some abusive and some ok. With the explanation and examples in this page, you can tell whether a service is SaaSS.
Background: How Proprietary Software Takes Away Your Freedom
Digital technology can give you freedom; it can also take your freedom away. The first threat to our control over our computing came from proprietary software: software that the users cannot control because the owner (a company such as Apple or Microsoft) controls it. The owner often takes advantage of this unjust power by inserting malicious features such as spyware, back doors, and Digital Restrictions Management (DRM) (referred to as “Digital Rights Management” in their propaganda).
Our solution to this problem is developing free software and rejecting proprietary software. Free software means that you, as a user, have four essential freedoms: (0) to run the program as you wish, (1) to study and change the source code so it does what you wish, (2) to redistribute exact copies, and (3) to redistribute copies of your modified versions. (See the free software definition.)
With free software, we, the users, take back control of our computing. Proprietary software still exists, but we can exclude it from our lives and many of us have done so. However, we are now offered another tempting way to cede control over our computing: Service as a Software Substitute (SaaSS). For our freedom's sake, we have to reject that too.
How Service as a Software Substitute Takes Away Your Freedom
Service as a Software Substitute (SaaSS) means using a service as a substitute for running your copy of a program. Concretely, it means that someone sets up a network server that does certain computing activities—for instance, modifying a photo, translating text into another language, etc.—then invites users to let that server do their own computing for them. As a user of the server, you would send your data to the server, which does that computing activity on the data thus provided, then sends the results back to you or else acts directly on your behalf.
What does it mean to say that a given computing activity is your own? It means that no one else is inherently involved in it. To clarify the meaning of “inherently involved,” we present a thought experiment. Suppose that any free software you might need for the job is available to you, and whatever data you might need, as well as computers of whatever speed, functionality and capacity might be required. Could you do this particular computing activity entirely within those computers, not communicating with anyone else's computers?
If you could, then the activity is entirely your own. For your freedom's sake, you deserve to control it. If you do it by running free software, you do control it. However, doing it via someone else's service would give that someone else control over your computing activity. We call that scenario SaaSS, and we say it is unjust.
By contrast, if for fundamental reasons you couldn't possibly do that activity in your own computers, then the activity isn't entirely your own, so the issue of SaaSS is not applicable to that activity. In general, these activities involve communication with others.
SaaSS servers wrest control from the users even more inexorably than proprietary software. With proprietary software, users typically get an executable file but not the source code. That makes it hard to study the code that is running, so it's hard to determine what the program really does, and hard to change it.
With SaaSS, the users do not have even the executable file that does their computing: it is on someone else's server, where the users can't see or touch it. Thus it is impossible for them to ascertain what it really does, and impossible to change it.
Furthermore, SaaSS automatically leads to consequences equivalent to the malicious features of certain proprietary software.
For instance, some proprietary programs are “spyware”: the program sends out data about users' computing activities. Microsoft Windows sends information about users' activities to Microsoft. Windows Media Player reports what each user watches or listens to. The Amazon Kindle reports which pages of which books the user looks at, and when. Angry Birds reports the user's geolocation history.
Unlike proprietary software, SaaSS does not require covert code to obtain the user's data. Instead, users must send their data to the server in order to use it. This has the same effect as spyware: the server operator gets the data—with no special effort, by the nature of SaaSS. Amy Webb, who intended never to post any photos of her daughter, made the mistake of using SaaSS (Instagram) to edit photos of her. Eventually they leaked from there.
Theoretically, homomorphic encryption might some day advance to the point where future SaaSS services might be constructed to be unable to understand some of the data that users send them. Such services could be set up not to snoop on users; this does not mean they will do no snooping. Also, snooping is only one among the secondary injustices of SaaSS.
Some proprietary operating systems have a universal back door, permitting someone to remotely install software changes. For instance, Windows has a universal back door with which Microsoft can forcibly change any software on the machine. Nearly all portable phones have them, too. Some proprietary applications also have universal back doors; for instance, the Steam client for GNU/Linux allows the developer to remotely install modified versions.
With SaaSS, the server operator can change the software in use on the server. He ought to be able to do this, since it's his computer; but the result is the same as using a proprietary application program with a universal back door: someone has the power to silently impose changes in how the user's computing gets done.
Thus, SaaSS is equivalent to running proprietary software with spyware and a universal back door. It gives the server operator unjust power over the user, and that power is something we must resist.
SaaSS and SaaS
Originally we referred to this problematical practice as “SaaS,” which stands for “Software as a Service.” It's a commonly used term for setting up software on a server rather than offering copies of it to users, and we thought it described precisely the cases where this problem occurs.
Subsequently we became aware that the term SaaS is sometimes used for communication services—activities for which this issue is not applicable. In addition, the term “Software as a Service” doesn't explain why the practice is bad. So we coined the term “Service as a Software Substitute,” which defines the bad practice more clearly and says what is bad about it.
Untangling the SaaSS Issue from the Proprietary Software Issue
SaaSS and proprietary software lead to similar harmful results, but the mechanisms are different. With proprietary software, the mechanism is that you have and use a copy which is difficult and/or illegal to change. With SaaSS, the mechanism is that you don't have the copy that's doing your computing.
These two issues are often confused, and not only by accident. Web developers use the vague term “web application” to lump the server software together with programs run on your machine in your browser. Some web pages install nontrivial, even large JavaScript programs into your browser without informing you. When these JavaScript programs are nonfree, they cause the same sort of injustice as any other nonfree software. Here, however, we are concerned with the issue of using the service itself.
Many free software supporters assume that the problem of SaaSS will be solved by developing free software for servers. For the server operator's sake, the programs on the server had better be free; if they are proprietary, their developers/owners have power over the server. That's unfair to the server operator, and doesn't help the server's users at all. But if the programs on the server are free, that doesn't protect the server's users from the effects of SaaSS. These programs liberate the server operator, but not the server's users.
Releasing the server software source code does benefit the community: it enables suitably skilled users to set up similar servers, perhaps changing the software. We recommend using the GNU Affero GPL as the license for programs often used on servers.
But none of these servers would give you control over computing you do on it, unless it's your server (one whose software load you control, regardless of whether the machine is your property). It may be OK to trust your friend's server for some jobs, just as you might let your friend maintain the software on your own computer. Outside of that, all these servers would be SaaSS for you. SaaSS always subjects you to the power of the server operator, and the only remedy is, Don't use SaaSS! Don't use someone else's server to do your own computing on data provided by you.
This issue demonstrates the depth of the difference between “open” and “free.” Source code that is open source is, nearly always, free. However, the idea of an “open software” service, meaning one whose server software is open source and/or free, fails to address the issue of SaaSS.
Services are fundamentally different from programs, and the ethical issues that services raise are fundamentally different from the issues that programs raise. To avoid confusion, we avoid describing a service as “free” or “proprietary.”
Distinguishing SaaSS from Other Network Services
Which online services are SaaSS? The clearest example is a translation service, which translates (say) English text into Spanish text. Translating a text for you is computing that is purely yours. You could do it by running a program on your own computer, if only you had the right program. (To be ethical, that program should be free.) The translation service substitutes for that program, so it is Service as a Software Substitute, or SaaSS. Since it denies you control over your computing, it does you wrong.
Another clear example is using a service such as Flickr or Instagram to modify a photo. Modifying photos is an activity that people have done in their own computers for decades; doing it in a server you don't control, rather than your own computer, is SaaSS.
Rejecting SaaSS does not mean refusing to use any network servers run by anyone other than you. Most servers are not SaaSS because the jobs they do are some sort of communication, rather than the user's own computing.
The original idea of web servers wasn't to do computing for you, it was to publish information for you to access. Even today this is what most web sites do, and it doesn't pose the SaaSS problem, because accessing someone's published information isn't doing your own computing. Neither is use of a blog site to publish your own works, or using a microblogging service such as Twitter or StatusNet. (These services may or may not have other problems, depending on details.) The same goes for other communication not meant to be private, such as chat groups.
In its essence, social networking is a form of communication and publication, not SaaSS. However, a service whose main facility is social networking can have features or extensions which are SaaSS.
If a service is not SaaSS, that does not mean it is OK. There are other ethical issues about services. For instance, Facebook requires running nonfree JavaScript code, and it gives users a misleading impression of privacy while luring them into baring their lives to Facebook. Those are important issues, different from the SaaSS issue.
Services such as search engines collect data from around the web and let you examine it. Looking through their collection of data isn't your own computing in the usual sense—you didn't provide that collection—so using such a service to search the web is not SaaSS. However, using someone else's server to implement a search facility for your own site is SaaSS.
Purchasing online is not SaaSS, because the computing isn't your own activity; rather, it is done jointly by and for you and the store. The real issue in online shopping is whether you trust the other party with your money and other personal information (starting with your name).
Repository sites such as Savannah and SourceForge are not inherently SaaSS, because a repository's job is publication of data supplied to it.
Using a joint project's servers isn't SaaSS because the computing you do in this way isn't your own. For instance, if you edit pages on Wikipedia, you are not doing your own computing; rather, you are collaborating in Wikipedia's computing. Wikipedia controls its own servers, but organizations as well as individuals encounter the problem of SaaSS if they do their computing in someone else's server.
Some sites offer multiple services, and if one is not SaaSS, another may be SaaSS. For instance, the main service of Facebook is social networking, and that is not SaaSS; however, it supports third-party applications, some of which are SaaSS. Flickr's main service is distributing photos, which is not SaaSS, but it also has features for editing photos, which is SaaSS. Likewise, using Instagram to post a photo is not SaaSS, but using it to transform the photo is SaaSS.
Google Docs shows how complex the evaluation of a single service can become. It invites people to edit a document by running a large nonfree JavaScript program, clearly wrong. However, it offers an API for uploading and downloading documents in standard formats. A free software editor can do so through this API. This usage scenario is not SaaSS, because it uses Google Docs as a mere repository. Showing all your data to a company is bad, but that is a matter of privacy, not SaaSS; depending on a service for access to your data is bad, but that is a matter of risk, not SaaSS. On the other hand, using the service for converting document formats is SaaSS, because it's something you could have done by running a suitable program (free, one hopes) in your own computer.
Using Google Docs through a free editor is rare, of course. Most often, people use it through the nonfree JavaScript program, which is bad like any nonfree program. This scenario might involve SaaSS, too; that depends on what part of the editing is done in the JavaScript program and what part in the server. We don't know, but since SaaSS and proprietary software do similar wrong to the user, it is not crucial to know.
Publishing via someone else's repository does not raise privacy issues, but publishing through Google Docs has a special problem: it is impossible even to view the text of a Google Docs document in a browser without running the nonfree JavaScript code. Thus, you should not use Google Docs to publish anything—but the reason is not a matter of SaaSS.
The IT industry discourages users from making these distinctions. That's what the buzzword “cloud computing” is for. This term is so nebulous that it could refer to almost any use of the Internet. It includes SaaSS as well as many other network usage practices. In any given context, an author who writes “cloud” (if a technical person) probably has a specific meaning in mind, but usually does not explain that in other articles the term has other specific meanings. The term leads people to generalize about practices they ought to consider individually.
If “cloud computing” has a meaning, it is not a way of doing computing, but rather a way of thinking about computing: a devil-may-care approach which says, “Don't ask questions. Don't worry about who controls your computing or who holds your data. Don't check for a hook hidden inside our service before you swallow it. Trust companies without hesitation.” In other words, “Be a sucker.” A cloud in the mind is an obstacle to clear thinking. For the sake of clear thinking about computing, let's avoid the term “cloud.”
Renting a Server Distinguished from SaaSS
If you rent a server (real or virtual), whose software load you have control over, that's not SaaSS. In SaaSS, someone else decides what software runs on the server and therefore controls the computing it does for you. In the case where you install the software on the server, you control what computing it does for you. Thus, the rented server is virtually your computer. For this issue, it counts as yours.
The data on the rented remote server is less secure than if you had the server at home, but that is a separate issue from SaaSS.
This kind of server rental is sometimes called “IaaS,” but that term fits into a conceptual structure that downplays the issues that we consider important.
Dealing with the SaaSS Problem
Only a small fraction of all web sites do SaaSS; most don't raise the issue. But what should we do about the ones that raise it?
For the simple case, where you are doing your own computing on data in your own hands, the solution is simple: use your own copy of a free software application. Do your text editing with your copy of a free text editor such as GNU Emacs or a free word processor. Do your photo editing with your copy of free software such as GIMP. What if there is no free program available? A proprietary program or SaaSS would take away your freedom, so you shouldn't use those. You can contribute your time or your money to development of a free replacement.
What about collaborating with other individuals as a group? It may be hard to do this at present without using a server, and your group may not know how to run its own server. If you use someone else's server, at least don't trust a server run by a company. A mere contract as a customer is no protection unless you could detect a breach and could really sue, and the company probably writes its contracts to permit a broad range of abuses. The state can subpoena your data from the company along with everyone else's, as Obama has done to phone companies, supposing the company doesn't volunteer them like the US phone companies that illegally wiretapped their customers for Bush. If you must use a server, use a server whose operators give you a basis for trust beyond a mere commercial relationship.
However, on a longer time scale, we can create alternatives to using servers. For instance, we can create a peer-to-peer program through which collaborators can share data encrypted. The free software community should develop distributed peer-to-peer replacements for important “web applications.” It may be wise to release them under the GNU Affero GPL, since they are likely candidates for being converted into server-based programs by someone else. The GNU project is looking for volunteers to work on such replacements. We also invite other free software projects to consider this issue in their design.
In the meantime, if a company invites you to use its server to do your own computing tasks, don't yield; don't use SaaSS. Don't buy or install “thin clients,” which are simply computers so weak they make you do the real work on a server, unless you're going to use them with your server. Use a real computer and keep your data there. Do your own computing with your own copy of a free program, for your freedom's sake.
The first version of this article was published in the Boston Review.
See also: The Bug Nobody is Allowed to Understand.",5
67,"Club-Mate
|Country of origin||Germany|
|Introduced||1924|
|Website||www|
Club-Mate (German pronunciation: [ˈklʊp ˈmaːtə]) is a caffeinated carbonated mate-extract beverage made by the Loscher Brewery (Brauerei Loscher) near Münchsteinach, Germany, which originated in 1924.[1] Club-Mate has 200 mg of caffeine per litre. Club-Mate has a relatively low sugar content of 50 g per litre, and low calories (200 kcal per litre of beverage) compared to other beverages such as cola or most energy drinks.
Club-Mate is available in 0.33-litre and 0.5-litre bottles.
Some Club-Mate bottles include the slogan ""man gewöhnt sich daran"" which roughly translates into a challenge to the drinker of “one gets used to it.""
Examples of Club-Mate-based mixed drinks are: vodka-mate; Tschunk,[2][3] a combination of rum and Club-Mate; Jaeger-Mate, a mix of Jägermeister and Club-Mate.
History[edit]
Geola Beverages of Dietenhofen, Germany originally formulated and marketed Club-Mate under the name Sekt-Bronte since 1924.[4] The drink was only known regionally until acquired by Loscher and marketed under the name Club-Mate in 1994.[5]
In December 2007, Loscher marketed a Club-Mate winter edition. The limited-edition Club-Mate consists of the original formula mixed with cardamom, cinnamon, star anise and citrus extract. It is since sold regularly for a limited time during winter.
In 2009, a Club-Mate-styled cola variety was introduced. Unlike other colas, its recipe includes mate-extract.
In 2013, Club-Mate Granat, a Club-Mate variety with additional pomegranate flavor, was introduced.
As of July 2010, the company listed additional countries like the United Kingdom,[6] the United States,[7] Belgium,[8] Bulgaria [9] and Luxembourg to reach distributors in 40 countries,[10] primarily in Europe, but also in Canada,[11] Australia, Israel, Turkey, Taiwan and South Africa.
Hacker culture[edit]
Club-Mate has developed a following in computer hacker culture and tech start-ups, especially in Europe. Bruce Sterling wrote in Wired magazine that it is the favorite beverage of Germany's Chaos Computer Club.[12] It is also popular at Noisebridge[13] and HOPE[14] in the United States, Electromagnetic Field in the UK, the Hack-Tic events in the Netherlands and the FOSDEM in Belgium. Club-Mate appeared in numerous leading media websites like Al-Jazeera,[15] TechCrunch[16] and Vice.[17]
Ingredients and Variations[edit]
- Water
- Inverted sugar syrup
- Sugar
- Mate tea extract
- Citric acid
- Caffeine
- Natural flavors
- Caramel color
- Carbonic acid
There are several variations on the original recipe available: Club-Mate IceT Kraftstoff (an iced-tea variant with slightly higher caffeine content (220 mg per L) and more sugar), Club-Mate Granat (with added pomegranate for a more fruity taste) and Club-Mate Winter Edition (with spices giving it a gingerbread-like taste - this edition is only available during the winter months).[18]
Tschunk[edit]
|Cocktail|
|Type||Highball|
|Base spirit|
|Commonly used ingredients||
|
|Preparation||Dice limes, put them together with the brown sugar into a high glass and crush both. Add crushed ice and pour the rum and the Club-Mate over it. Add a straw|
Tschunk [ˈtʃʊnk] is a German highball consisting of Club-Mate and white or brown rum. It is usually served with limes and cane or brown sugar.[19][20]
Like Club-Mate, the Tschunk is a typical drink within European hacker culture[21][22] and can often be found at scene typical events or locations like the Chaos Communication Congress.[20][23]
See also[edit]
Notes and references[edit]
- ^ ""Club Mate Reviews, Photos, Information, Videos and TV Ads"". dizzyfrinks.com.
- ^ ""Tschunk – Des Hackers Cocktail"".
- ^ ""Tschunk Cocktail Recipe"".
- ^ ""WaaAAAAAACH!!Als Sekt-Bronte begonnen, als Einhornpisse geendet"". Die Tageszeitung: Taz. 27 December 2011. p. 13.
- ^ ""Goldgrüne Flüssigkeit zum Saugen"". Der Tagesspiegel Online. 16 January 2006.
- ^ ""Club-Mate UK"". Archived from the original on 2016-02-23. Retrieved 2020-07-24.
- ^ ""Club-Mate USA"".
- ^ ""Official Belgium Club-Mate distributor"".
- ^ ""Club-Mate Bulgaria"". Facebook.
- ^ ""Manufacturer – Club-Mate / The Icetea"". clubmate.de.
- ^ ""Club-Mate Canada"". Facebook.
- ^ Bruce Sterling (2007-04-01). ""Club-Mate, favorite drink of the Chaos Computer Club"". Wired.
- ^ ""Club Mate - Noisebridge"". noisebridge.net.
- ^ ""Club-Mate"". 2600 Magazine. Archived from the original on 2015-08-15. Retrieved 2009-11-12.
- ^ Stupp, Catherine. ""German hackers' drink of choice"". www.aljazeera.com.
- ^ ""Flying high on Club Mate – TechCrunch"". techcrunch.com.
- ^ ""How a German Soda Became Hackers' Fuel of Choice | Motherboard"". motherboard.vice.com. Archived from the original on 2014-03-02.
- ^ ""Club Mate Products Page"".
- ^ ""Tschunk – Hacker's Cocktail with Club Mate"".
- ^ a b Silver, Vernon (27 June 2017). ""The Chaos Computer Club Is Fighting to Save Democracy"". Bloomberg L.P. Retrieved 14 July 2017.
- ^ ""Club-Mate: The Favorite Drink of German Hackers and Club Kids Is Here"". Eater.com. Vox Media. 8 September 2015. Retrieved 3 April 2018.
- ^ ""Hacking Club-Mate"". Make. 24 May 2011.
- ^ Judith Horchert (28 December 2013). ""Chaospatinnen: Betreuung für den ersten Besuch beim Hackerkongress"". Spiegel Online (in German).
External links[edit]
- Home Page for Club-Mate
- ""History of Loscher Brewery. Includes information on acquisition of Geola Beverages"" (in German). Archived from the original on 2007-10-11. Retrieved 2008-05-23.",8
68,"How To Spot Trends with AI
Part II: Discovering Overlooked Social Shifts
After Sarah DaVanzo and I leveraged NWO.ai’s invaluable AI to score and re-rank the Meta Trends, we were left stuck with one finding:
Both the global and U.S. AI data-driven ranks were significantly different from the original human rank. The AI declared that what we humans thought was most important was not actually the case.
Were we just splitting hairs of importance here, or were these divergent rankings a signal that our Meta Trends (which came from source material) were not as important as we once thought? Maybe more influential cultural shifts are out there waiting to be exposed.
And if so, how can we find them?
We debated important but missing Meta Trends for weeks — but, how important could these be if the experts couldn’t agree upon their importance by not collectively highlighting them within their reports which we analyzed? But simultaneously, according to our work analyzing the last five years of Meta Trends, the “most important trends” being reported haven’t changed much.
There was no denying, though: important, nuanced cultural shifts were missing from our list of 14 Meta Trends. So, how could we identify and highlight these overlooked trends... and further, in a way that isn’t subjective (Sarah’s opinion against mine)?
We considered just naming our favorite cultural phenomenon not included in the original Meta rank, or we could have just surfaced interesting leftover trends from the 40+ reports that didn’t make their way into one of the 14 Meta Trend themes, but both approaches would have thrown us into the same trap which we immediately called out after publishing the most recent annual Meta Trend report: the prevalence of bias and scarcity of risk in the trends and foresight field is concerning at best...
While Sarah and I both have historical proof and a pedigree of accurate trend forecasting, our life experiences and methods differ. Just listing our favorites felt too qualitative. So we designed another experiment with NWO.ai.
Experiment 04.
AI Meta Trend Identification
_ Comparison
Left on its own, could AI identify similar or different — perhaps missing — Meta Trends?
This time we fed all of the text from the original 40+ sourced trend reports into the NWO.ai AI platform. Nearly one million words of text. We figured that the AI could process this information with a different, extraordinary comprehension than us humans, who attempted to do the same when creating that original 2022 rank. We hypothesized the AI would make more connections — ergo identify Meta Trends completely overlooked by the humans.
By crunching all of the reports and instructing the AI to identify Meta Trend patterns (clusters, themes, etc.), would it come back with missing valuable, social shifts? Answer: Not even close.
We were very wrong to believe AI could complete this exercise similar to that of an expert trend spotter.
From the one million words of text inputted, the AI used Natural Language Processing (NLP) and clustered like-with-like, arriving at 72 clusters of “trends.”
Interestingly, there was very little overlap with our 14 Meta Trends — a handful at best, which were really just optimistic stretches.
Further, the AI’s clustered “trends” weren’t even trends, but rather general topics like “technology” and “pandemic.” It’s not to say that these themes weren’t impressive — they were — but these findings aren’t helpful to an experienced cultural strategist who can arrive at more provocative groupings.
So to answer the question:
Could AI identify overlooked Meta Trends: No.
But feeling we were onto something we asked a follow up...
Experiment 05.
AI Micro-Trend Identification
_ Extrapolation
Rather than identifying large patterns which we’d call Meta Trends, could we use the AI to identify and rank smaller, perhaps overlooked micro-trends from within the reports?
To figure this out, instead of having the AI merely organize the reports’ text, we instructed the AI to take its newly created meaning of the one million words (i.e. it’s 72 clusters) and use diverse internet data sources to measure and rank each and every signal. The goal of the experiment was to understand what the consumer energy is behind every micro-trend and rank them accordingly. We’d called these the AI-identified trends.
It was a complicated process, but essentially we asked the AI to take the signals it captured from the 40+ industry reports, use them as a launching off point, and then use all the available online information to easily rank and validate them.
The AI came back with 1,062 newly scored micro-trends.
This was a ranking of AI-identified, human-overlooked trends, via abstracted meanings and associations all from the 40+ reports’ text. It turned up gold.
Precisely, these were trends buried — or, hidden — within the industry reports that the AI pulled out using advanced NLP techniques and a vast amount of data.
Here is a curation of the top 40 ranked, overlooked micro-trends discovered by the AI:
Inclusive Insurance, Disruptive Winds, Food Inflation, DAO’s (Decentralized Autonomous Organizations), Rising Energy, Super Apps, Longevity Food, Unisex Fragrance, Dating Fatigue, Clothing Rental, AI-Music, Biodynamic Farming, Gender Affirmation, Rainwater Harvesting Systems, Wearable Robotics, Dopamine Dressing, Sleep Coaches, Financial Coaches, Gut Health, Caregiver Leave, Self-Hypnosis, Alcohol-Free Beer, Psychoactive Tea, Sperm Freezing, Touch-Free, Post traumatic, Carbon Pawprint, Sustainability Calculator, Land Stewards, Privacy Enhancing Tech, Anonymous Marketplace, Subscriptions, Fluid Fashion, Land Availability, Period Products, Paid Menstrual Leave, Mutual Aid, Workplace Conditions, Banned Advertising, and Media Anxiety
Perhaps most noteworthy: “Russia Initiative” was a buried “trend” identified by the AI from the structured text of the industry trend reports. The AI then used various online data sources to measure and score the energy behind this (and all of the other 1061 signals). While the AI picked up this shift, not a single report explicitly mentioned a pending war at the time of their writing. The AI was literally able to give voice to cultural change indirectly alluded to from within the human-authored reports.
Join thousands of really smart people.
Conclusion:
Humans for Sensemaking & AI For Discovery and Inspiration
Our experiments found that humans outperform AI in decoding the zeitgeist and defining cultural shifts at large (Meta Trends, Mega or Macro Trends). We’d call this “sensemaking.” This skill is essentially being able to synthesize wide-ranging, already structured data, and intuitively pattern match and creatively stitch narratives. Humans have an edge over AI when it comes to seeing the big picture and making non-obvious connections.
Humans can derive Meta Trend patterns. But as we found out, the AI cannot. Humans bring context to the table: historical knowledge, existing understanding of worthy trend criteria, and most important, ties to business use cases and priorities. Simply, we humans know what to look for. But... This is also our fatal flaw as it translates into bias...
Meanwhile, we uncovered AI has a distinct advantage when it comes to unifying, processing and analyzing diverse unstructured data sets at scale and with unmatched speed. AI beats humans when finding the most noteworthy weak and emerging signals (aka micro-trends) — concepts undetectable to the human eye due to the sheer volume of data. AI’s superpower in this context is “discovery” and “inspiration.”
We also learned AI works well when it deconstructs and analyzes both human-structured data (ex. our original Meta Trends) and massive troves of unstructured data, using them as source material or trailheads in its own search for novelty.
Ultimately, with insight from AI’s more precise rankings, its detection of signal vs. noise, and its delivered inspiration, it’s undeniable:
AI is a crucial fixture in a successful cultural intelligence system.
This series of experiments run by Sarah, NWO.ai and myself demonstrate the need and role of AI and cultural data at scale.
This is the future of cultural intelligence.
That’s the clearest takeaway here.
The optimal cultural intelligence system combines Humans-and-Machines in a series of orchestrated hand-offs, repeating the pattern of construction and deconstruction.
Humans are best utilized for sourcing and defining large, complex social themes, while AI is best utilized for prioritizing these weighty trends, sourcing micro-trends, and checking humans’ sometimes messy, qualitative approaches.
Nobody’s perfect.
And together is better than alone.
But one question remains: Are there other trends out there unreported by the industry’s published trend reports, unidentified by the Meta Trend analysis, and undiscovered by the AI.
Answer: No doubt.
Don’t miss the final installment.",3
69,"Corporate espionage is entering a new era
Companies need to take it more seriously
For espionage of the cloak-and-dagger variety, it is hard to beat John le Carré or Ian Fleming. But the world of corporate spying has plenty of drama, too. Take the alleged skulduggery in a recent court case involving two American software firms. In May a jury awarded Appian, based in Virginia, $2bn in damages after it had accused Pegasystems, from Massachusetts, of illegally snooping on it to gain a competitive edge. The trial revealed that Pegasystems executives had referred to a contractor hired to obtain ingredients of Appian’s secret sauce as “our spy” in internal documents, and had dubbed the overall effort “Project Crush”. Pegasystems, whose share price slumped after the ruling, and which is set to face a barrage of class-action suits from disgruntled investors, has vowed to appeal against the “unjust” decision.
The episode illustrates how interest in business espionage has broadened. Snooping is no longer centred on a few “sensitive” industries, such as defence and pharmaceuticals. It is increasingly used to target smaller companies in surprising sectors, including education and agriculture. It has, in short, become a general business risk. Corporate espionage may be entering an era not unlike the cold war heyday of great-power spookery.
There are two intertwined reasons for this: the inexorable growth of the intangible economy and the growing sophistication of online hackers. ceos should be worried when they see their firms’ secrets being hawked on the dark web; one marketplace, Industrial Spy, flogs stolen data and documents to “legitimate” businesses. Information is sold in packets ranging from a few dollars to millions. Keeping intellectual property (ip) safely locked in the digital vault can be devilishly difficult.
When they hear about ip, most people think of patents. Securing patents has become more difficult, in America at least, since a pair of Supreme Court rulings in the past decade chipped away at, respectively, protection for “business methods” and “abstract ideas” (which many software-based inventions are). This has left companies more reliant on developing and safeguarding trade secrets. These can be anything from algorithms and client lists to chemical processes and marketing plans. Among the most famous trade secrets are Coca-Cola’s recipe and the formulation for wd-40. Most are more mundane: recent legal battles have involved industrial-baking agents and floor-resin formulas. Patents offer stronger protections, but trade secrets last for ever—if they are well kept.
Christine Streatfeild of Baker McKenzie, a law firm, talks of a “pivot” in the past five years, as more companies in more industries wake up to the need to protect their secrets. She points to stepped-up efforts in consumer goods, steel and even cannabis. Baker McKenzie has advised legal marijuana-growers in America on steps they can take to curb rivals’ access to information about their cultivation techniques, soil recipes, extract flavouring and so on.
Digitisation makes the problem thornier. As old industries, from carmaking to education, increase investment in software, they have more bits and bytes worth stealing. Industries with lots of startups are particularly vulnerable, says Sidhardha Kamaraju of Pryor Cashman, another law firm, because they combine lots of new tech with mobile employees who hop between up-and-coming firms. In 2018 Alphabet’s Waymo self-driving unit won a $245m settlement from Uber after alleging that one of Waymo’s former engineers took trade secrets along with his office bric-a-brac when he left for the ride-hailing firm.
At least legislative protections for trade secrets have grown stronger. A turning point in America was the Defend Trade Secrets Act, passed in 2016, which greatly expanded the type and number of secrets covered by federal law. Its passage led to a 30% jump in cases filed, says Tim Londergan of Tangibly, an ip-management firm.
The bad news is that many firms are poor managers of such secrets. It is not enough to make reasonable efforts to keep the information confidential. The secret also has to be clearly articulated. Failure to do this has been exposed in a number of recent cases. In one, Mallet, a baking-products firm, failed to block an upstart rival from using release agents (which allow loaves and buns to be more easily removed from pans) similar to its own, after an American appeals court ruled, in effect, that Mallet hadn’t adequately described and documented its secret formula.
Such rulings have led more bosses to demand “ip audits” and use the results to better safeguard secrets. This, in turn, has spawned a cottage industry of trade-secrets consultants. Lawyers, too, are in demand. Patent lawyers are plentiful but few really understand trade secrets and they tend to focus on litigation, once the problem has arisen, says Mr Londergan. “Companies need help earlier.” They also need to focus more on risks emanating from corporate partners, for instance in joint ventures. This is often an afterthought even among multinationals.
Corporate Bonds
tsmc is a rare globally active company that comes close to best practice in articulating and managing its trade secrets. The Taiwanese chipmaker has good reason to want to get it right. It operates in a highly sensitive industry chock-full of proprietary information that rivals would love to get hold of. On its doorstep is China, which bears Taiwan ill will and is widely acknowledged as the world leader in ip theft (having been its victim in the 18th century, when Jesuit priests were sent from Europe to nick Chinese trade secrets in porcelain-making). The Taiwanese authorities say that in recent months they have uncovered several attempts by China to poach semiconductor engineers using Chinese firms that registered on the island unlawfully by hiding their origins. In May Taiwan’s parliament passed a law that punishes anyone who obtains or uses designated “core” technologies for the benefit of “external entities” with up to 12 years in prison.
America, too, has cracked down with China in mind. The Department of Justice says that roughly four in five economic-spying cases it brings “allege conduct that would benefit the Chinese state”. The best-known case of suspected espionage by China, involving Huawei, a maker of telecoms gear, is the tip of a large iceberg.
As big a threat as China is, it isn’t alone. Ostensibly friendly states spy, too. Israel has been known to snoop on American firms for the benefit of its tech and military industries. And it is not always helpful to think of the threats posed by different kinds of actors—company insiders, corporate rivals or governments—as discrete. Sometimes they are at work simultaneously. Take the recent sentencing of You Xiaorong, a former chemist at Coca-Cola, to 14 years at Uncle Sam’s pleasure. Ms You was convicted of stealing trade secrets relating to coatings on the inside of beverage cans. She used the filched formula to set up her own company in China, with backing from a local partner. Their venture received grants from the Chinese government. Whether or not Chinese officials were aware of the theft is unclear.
The case highlights another challenge for firms trying to keep a lid on secrets. They can spend as much as they like on beefing up it systems, but they must still watch out for analogue forms of exfiltration. Operatives for Procter & Gamble (p&g) were once caught diving in dumpsters outside a Unilever office in Chicago in search of information about its consumer-goods rival’s marketing strategy. Ms You apparently used her phone to take pictures of sensitive documents to bypass Coke’s security measures. People use smartphones in offices all the time. How to tell if it is for nefarious reasons?
Moreover, much corporate spying can be—from the point of view of those being spied on—frustratingly fuzzy. Some of it is perfectly legal. Many hedge funds watch activity in factories, using foot-soldiers or satellite imagery, to gauge output and bet accordingly on stocks. At the other extreme is stuff that no ceo in their right mind would countenance: p&g’s top brass were so appalled when they learned of their underlings’ trash-rummaging at Unilever that they shopped their own company, resulting in a $10m settlement.
In between is a large grey area where operatives “ride the ragged edge” of morality and the law, as Eamon Javers puts it in his book, “Broker, Trader, Lawyer, Spy”. Many of them work for outfits that companies hire in order to gain plausible deniability. This industry came of age in the vicious takeover battles of the 1980s and has since grown at breakneck speed. Its well-known names, such as Kroll and Control Risks, are at the top of a pyramid containing thousands of mostly small firms.
Most such work is legal and boring—for instance, due diligence on clients’ prospective business partners. But there are cases of firms undertaking dubious activity, from wiretapping to impersonation. In the 19th century, the industry’s grandfather, Allan Pinkerton, laid out (and largely followed) a strict code of conduct. Mr Javers fears that some of Pinkerton’s modern-day counterparts routinely violate many of his gentlemanly commandments.
None of this is going away. Employee mobility is at or near an all-time high. Companies, and the tactics they use, get more desperate in downturns. And the geopolitical backdrop is growing frostier, increasing incentives for underhand activity by states or their proxies. “Casino Royale” it may not be, but the spectre of surging economic espionage is real. ■
For more expert analysis of the biggest stories in economics, business and markets, sign up to Money Talks, our weekly newsletter.
This article appeared in the Business section of the print edition under the headline ""On her CEO’s secret service""
Business June 4th 2022
- Corporate espionage is entering a new era
- Has Russia legalised intellectual-property theft?
- Sheryl Sandberg, Meta’s second-in-command, leaves the embattled firm
- “Top Gun” flies high, sparking hopes of a theatrical recovery
- Is big tech’s red-hot jobs market about to cool?
- Do not bring your whole self to work
- Why Proxy advisers are losing their power
From the June 4th 2022 edition
Discover stories from this section and more in the list of contentsExplore the edition
More from Business
RWE, Germany’s biggest power company, is going green
But are its plans ambitious enough?
The magic formula of management
Five numbers, one connecting idea
Fashion gets a modern makeover
A $700bn industry flirts with new materials, new countries—and new clients",2
70,"Alaska snow crab season canceled as officials investigate disappearance of an estimated 1 billion crabs
In a major blow to America's seafood industry, the Alaska Department of Fish and Game has, for the first time in state history, canceled the winter snow crab season in the Bering Sea due to their falling numbers. While restaurant menus will suffer, scientists worry what the sudden population plunge means for the health of the Arctic ecosystem.
An estimated one billion crabs have mysteriously disappeared in two years, state officials said. It marks a 90% drop in their population.
""Did they run up north to get that colder water?"" asked Gabriel Prout, whose Kodiak Island fishing business relies heavily on the snow crab population. ""Did they completely cross the border? Did they walk off the continental shelf on the edge there, over the Bering Sea?""
Ben Daly, a researcher with ADF&G, is investigating where the crabs have gone. He monitors the health of the state's fisheries, which produce 60% of the nation's seafood.
""Disease is one possibility,"" Daly told CBS News.
He also points to climate change. According to the National Oceanic and Atmospheric Administration, Alaska is the fastest warming state in the country, and is losing billions of tons of ice each year — critical for crabs that need cold water to survive.
""Environmental conditions are changing rapidly,"" Daly said. ""We've seen warm conditions in the Bering Sea the last couple of years, and we're seeing a response in a cold adapted species, so it's pretty obvious this is connected. It is a canary in a coal mine for other species that need cold water.""
Prout said that there needs to be a relief program for fisherman, similar to programs for farmers who experience crop failure, or communities affected by hurricanes or flooding.
When asked what fishermen can do in this situation, with their livelihoods dependent on the ocean, Prout responded, ""Hope and pray. I guess that's the best way to say it.""
for more features.",2
71,"New figures have revealed that the price of charging an electric car using a rapid public charger has risen by more than 42% in just four months, caused by the rising wholesale costs of gas and electricity.
It now costs £32.41 on average to charge a 64kWh family car such as the Kia e-Niro Long Range to 80% from empty via a public rapid charger, up £9.60 (£22.81) from May and £13.60 (£18.81) from the same time last year.
This is due to the average cost to charge per kilowatt hour, which is now 63.29p, up from 44.55p in May and 36.74p in September last year, the RAC has revealed.
The rising cost has been mirrored at ultra-rapid charging points (100kW-plus), which now charge an average of 63.94p per kilowatt hour, up from 50.97p in May and 34.21p in September last year. This means that charging a 64kWh family car to 80% costs £32.74, up £6.64 (£26.10) from May.
Charging firms have expressed concerns over the rise – caused in part by the UK’s decision to look at other sources for its gas and oil following Russia’s invasion of Ukraine – arguing that they can no longer shield consumers from the price rises.
Instavolt has argued that the rise is due to the 20% VAT imposed by the government on public charging, compared with the 5% on home charging, adding that it could offer prices as low as 58p per kilowatt hour if home charging VAT rates were matched.
“We reiterate our commitment that if the public charging rate is reduced, the benefit will be passed back to consumers immediately,” said a spokesman.
This point is supported by Osprey CEO Ian Johnston, who previously told Autocar: “There is a cap that is protecting consumers at home, but there is no such cap for private businesses and we are buying energy at unseen levels at the moment.”
“We are trying to protect customers where we can but clearly we can’t run the network at a loss.”
However, one firm, Ionity, confirmed that despite the rising costs, it won’t be making any price rises yet and “currently have no future increases planned”.
Another worry from the RAC is that the price hike could put off potential buyers, hindering the government’s plan to ban the sale of all new petrol and diesel cars by 2030.
But Johnston disagrees, previously telling Autocar: “I think for the people who are currently making the decision to switch, the list of reasons to move to an EV are long and proven, and it is still – in many cases – cheaper than driving petrol or diesel [vehicles].
Join the debate
Add your comment
And as the years roll by, and there are less and less ICE Vehicles on the Road, how, where are whoever get into power going to replace one of the high test Taxed luxuries we have, we need, we can't not have?
Speaking of Stats just how many miles will be completed using power from a source charging 7 times more than the overnight rate or twice that of the home rate, very few I'd suggest. Any ev owners wish to comment on how many Kws they get away from their home and workplace compare to 67p a kw road side chargers.
Still cheaper than running a petrol or diesel car.
Maybe, but, other essential things for living?, maybe Ev's will come down in price?,ha ha!
I think you need to do some more maths. at 3 miles per KW thats 21ppm from a public charger. Petrol seems to be about £1.60 a litre around here, which means 35mpg or better is cheaper. And those still buying petrol are making a very generous contribution to the government, no doubt to cover the incentives given to the EV driver.
Of course charing at home is still cheaper than buying petrol, but would it be if the tax were the same?
I honestly dont understand how super efficient EVs can cost more per mile than old clunkers running on Dino juice, but do the maths, in many cases they are
I have a couple of evs a 30kwh Nissan Leaf that has free charging at work, and an old tesla s 85d with free supercharging which is charged off my PV panels on the roof when parked at home. The tesla has done 210000 kms and lost 5% range, I have just come back from a trip to the north of the artic circle in Norway from Geneva 9000 kms which cost 100 euros in fuel, Often free charging is suppled from hotels. I bought it at auction in 2019 and it still worth what i Paid for it. I have done the maths and i don't think any thermic cars that i have had over the last 30 years come anywhere near close in costs. 450bhp and 0-60 in 4.5 sec thrown in for good measure too. only bad side is eats tyres and build qualty is not great on the Tesla as it is an old one.
I Have had nissan leafs for 5 years and all they need is tyres windscreen wipers/ fluid and cabin air filter, this with the free work charging make them unbeatable for a daily commute, although not the most exciting ev.
Good write up, shame that some luddites ignore such exmaples",2
72,"DALL·E 2
DALL·E 2 is a new AI system that can create realistic images and art from a description in natural language.
DALL·E 2 can create original, realistic images and art from a text description. It can combine concepts, attributes, and styles.
DALL·E 2 can can expand images beyond what's in the original canvas, creating expansive new compositions.
DALL·E 2 can make realistic edits to existing images from a natural language caption. It can add and remove elements while taking shadows, reflections, and textures into account.
DALL·E 2 can take an image and create different variations of it inspired by the original.
DALL·E 2 has learned the relationship between images and the text used to describe them. It uses a process called “diffusion,” which starts with a pattern of random dots and gradually alters that pattern towards an image when it recognizes specific aspects of that image.
In January 2021, OpenAI introduced DALL·E. One year later, our newest system, DALL·E 2, generates more realistic and accurate images with 4x greater resolution.
DALL·E 2 is preferred over DALL·E 1 for its caption matching and photorealism when evaluators were asked to compare 1,000 image generations from each model.
preferred for
caption matching
preferred for
photorealism
DALL·E 2 began as a research project and is now available in beta. Safety mitigations we have developed and continue to improve upon include:
We’ve limited the ability for DALL·E 2 to generate violent, hate, or adult images. By removing the most explicit content from the training data, we minimized DALL·E 2’s exposure to these concepts. We also used advanced techniques to prevent photorealistic generations of real individuals’ faces, including those of public figures.
Our content policy does not allow users to generate violent, adult, or political content, among other categories. We won’t generate images if our filters identify text prompts and image uploads that may violate our policies. We also have automated and human monitoring systems to guard against misuse.
Learning from real-world use is an important part of developing and deploying AI responsibly. We began by previewing DALL·E 2 to a limited number of trusted users. As we learned more about the technology’s capabilities and limitations, and gained confidence in our safety systems, we slowly added more users and made DALL·E available in beta in July 2022.
Our hope is that DALL·E 2 will empower people to express themselves creatively. DALL·E 2 also helps us understand how advanced AI systems see and understand our world, which is critical to our mission of creating AI that benefits humanity.",3
73,"What’s old is new again. Classic literature and rock n’ roll dominates this year of celebs making bank in the afterlife.
Pictured above (left to right): Elvis Presley, Kobe Bryant, David Bowie
Seems not even the boneyard is immune from inflation. The 13 departed artists, athletes and entertainers on this year’s list of the top-earning dead celebrities earned a record $1.6 billion, making it a 72% increase over last year’s total. It’s by far the biggest 12-month haul since we started tracking graveyard earnings in 2001 – and, for the first time ever, the top five made more than $100 million each.
At the top of the heap: J.R.R. Tolkien, the long-deceased author of The Lord of the Rings and The Hobbit. The former Oxford don, who died of pneumonia in 1973, earned $500 million from the sale of Middle-Earth Enterprises, which handles intellectual property rights for motion pictures, videogames, merchandise, and more to Swedish gaming company Embracer in August.
Following close behind is basketball legend Kobe Bryant with $400 million from his estate’s sale of his stake in the BodyArmor sports drink company to Coca-Cola. It marks the largest acquisition in the soft drink firm’s history.
Elvis Presley may have left the building, permanently, but the King of Rock N’ Roll is still an economic powerhouse. Forty-five years after his death, Elvis’ estate generated $110 million in income. The lion’s share was made from box office and merchandise sales at Graceland, Presley’s Memphis home—just $5 million of that came from rights for Elvis, the Baz Luhrmann-directed biopic.
Overall, the music of yesteryear is seen by investors as a reliable income stream. Nearly $700 million of the $1.6 billion in total earnings came from the estates of the nine musicians on the list, including David Bowie ($250 million), Michael Jackson ($75 million) and “Hallelujah” songwriter Leonard Cohen ($55 million). Some of those earnings came from one-time sales. The estate of Toto drummer Jeff Porcaro, for instance, sold his publishing and recording royalties for $25 million in November 2021. Others, like Beatles John Lennon and George Harrison remain mainstays on the list due to their annual recurring royalty streams.
“In the early days of rock n’ roll, companies owned everything and fought with the artists’ representatives to gain control of their IP,” says entertainment attorney John Branca, who manages Michael Jackson’s estate. “Now it’s swung back in the other direction as artists get older, and are estate planning, and tax planning, and selling their IP back to the companies.”
“It’s come full circle.”
Additional reporting by Richard J. Chang, Kyle Henderson, Conor Murray and Emily Washburn.
#1 • $500 Million
J.R.R. Tolkien
September 2, 1973 (81)†
Pneumonia
When Swedish video game company Embracer announced its acquisition of Middle Earth Enterprises in August, they didn’t disclose the deal price, instead opting to share they’d spent $788 million on six acquisitions including Tolkien. But one clever hobbit told Forbes that Embracer spent at least $500 million for Middle Earth Enterprises, a number Embracer didn’t refute. After the deal closes, Embracer will share the shire with a multitude of other companies who own other pieces of Tolkien’s intellectual property, including HarperCollins, Amazon, Warner Brothers/New Line, and the Tolkien Estate, in what’s been described as the most complex IP rights split in history.
#2 • $400 Million
Kobe Bryant
January 26, 2020 (41)†
Helicopter crash
The late L.A. Lakers legend had a 7% stake in the BodyArmor energy drink and served on the company’s board prior to his 2020 death. In November 2021, Coca-Cola agreed to buy out the 70% of BodyArmor it didn’t already own for $5.6 billion at an $8 billion valuation. Bryant’s estate received a reported $400 million in proceeds from the sale.
#3 • $250 Million
David Bowie
January 10, 2016 (69)†
Cancer
“Is there life on Mars?” the Thin White Duke famously asked on 1971’s Hunky Dory. We still don’t know—no worries: Elon Musk is working on it—but the sale of David Bowie’s publishing catalog and masters to Warner Chappell in January generated enough income to make Major Tom jealous, to the tune of $250 million. Man Who Sold the World, indeed.
#4 • $110 Million
Elvis Presley
August 16, 1977 (42)†
Heart attack
The King benefited handsomely from Covid cooped-up tourists ready to treat themselves to a vacation at his Graceland mansion and resort. At least $80 million of Presley’s earnings came from tour tickets, shows, and merch, according to sources close to the estate. The estate didn’t make a ton directly off the smash Elvis biopic, but the hit film is expected to lift Presley’s earnings for at least the next 18 months as fans, new and old, look to own their own piece of the King. Even sales of Disney’s Stitch plush animals dressed in Elvis jumpsuits are up from last year.
#5 • $100 Million
James Brown
December 25, 2006 (73)†
Heart failure
“The hardest working man in show business,” just keeps working, even though he is dead. Primary Wave, a New York-based independent music publisher, snapped up the Godfather of Soul’s music rights, real estate, and name and likeness. Brown’s estate will reportedly use some of the proceeds to fund academic scholarships for needy children in perpetuity.
#6 • $75 Million
Michael Jackson
June 25, 2009 (50)†
Overdose/homicide
With Covid restrictions lifted, the Jackson-themed Cirque de Soleil show in Las Vegas is back in action and raking in money alongside the King of Pop’s Mijac Music catalog. And there’s a new cash cow in town: MJ The Musical on Broadway, a jukebox retelling of Jackson’s story. By November the musical will have grossed $80 million, according to a Jackson estate source, an impressive feat given the show premiered only nine months ago.
#7 • $55 Million
Leonard Cohen
November 7, 2016 (82)†
Fatal fall
The “Hallelujah” crooner’s publishing and masters were snapped up by Hipgnosis, a publicly traded music management and IP firm helmed by Merck Mercuriadis, who has managed acts ranging from Beyoncé and Elton John to Guns N’ Roses and Morrissey. Cohen wasn’t overly bothered by money problems while alive: After his manager “misappropriated” some $5 million in the mid-2000s, Cohen had lunch with the investment banker David Pullman of “Bowie Bond” fame at L.A.’s Four Seasons. “I’m all worked up asking [Cohen] if he’s angry,” recalls Pullman. “He goes: ‘No, what good would that do?’ The guy was so Zen, it’s incredible.”
#8 • $32 Million
Dr. Seuss
September 24, 1991 (87)†
Cancer
The people of Whoville lived in a world the size of a speck of dust, Dr. Seuss once wrote, with Horton the elephant graciously carrying their speck on a fluffy dandelion. Those tiny Whos, alongside timeless characters including The Cat in the Hat, The Grinch, and The Lorax generated over $16 million in book sales since last November, alongside a Netflix deal and merchandising.
#9 • $25 Million
Jeff Porcaro
August 5, 1992 (38)†
Heart attack
The drummer from 80s rock outfit Toto doesn’t have nearly the same name recognition as the rest of the dead celebs, but while living he was an industry legend. Not only did he co-write the platinum-certified song “Africa,” Porcaro was the go-to studio drummer for recording bigwig Quincy Jones and kept the beat on the best-selling album of all-time, Michael Jackson’s Thriller. Porcaro also collaborated with the likes of Steely Dan, Eric Clapton, Paul McCartney and Bruce Springsteen. His publishing and recording royalties were snapped up by Primary Wave.
#10 • $24 Million
Charles Schulz
February 12, 2000 (77)†
Cancer
Snoopy and the rest of the Peanuts gang are as reliable at generating income as they are at torturing poor Charlie Brown. But the nature of the game is changing. For the first time since 1965, classic holiday specials “It’s The Great Pumpkin, Charlie Brown,” “A Charlie Brown Thanksgiving” and “A Charlie Brown Christmas” will not be airing on free broadcast TV after Apple TV snapped up the rights for their paid streaming service (nonsubscribers will be able to watch for free on certain days and PBS will also stream the specials.)
#11 • $23 Million
Juan Gabriel
August 28, 2016 (66)†
Heart attack
One of the most prolific Mexican composers and singers in history, Juan Gabriel’s penned some 1,800 songs in his lifetime, moving an estimated 60 million albums which earned 2 Latin Grammys. Known for his flamboyant performing style and fashion—think lots of sequins—his nickname was ""divo of Juarez,"" a reference to Gabriel’s hometown. In April, Gabriel’s estate struck a deal with Universal Music Group in which the company will assign the singer’s post-2008 catalog to label subsidiary Virgin Music US Latin, while Universal’s publishing arm will oversee the entire catalog.
#12 • $16 Million
John Lennon
December 8, 1980 (40)†
Homicide
In 2022 the “Imagine” singer made his usual royalties from his time as a Beatle and his solo work. Additionally, an estimated $3.5 million was added to Lennon’s coffers from Beatles music rights secured by Disney for its Peter Jackson-directed Get Back, an epic docuseries rehashing the British group’s infamous final recording sessions.
#13 • $12 Million
George Harrison
November 29, 2001 (58)†
Cancer
The “quiet Beatle” likewise profited from the Get Back docuseries, adding another $2.5 million to his annual solo and Fab Four royalties. Harrison’s estate, along with Lennon’s, gets another $2.6 million from the Beatles Cirque de Soleil show.
METHODOLOGY
This year's Dead Celebrity ranking includes pretax earnings from sales, streams, licensing deals and other sources between November 1, 2021 and October 30, 2022, as well as estate acquisitions made or announced during the same period. We compile our numbers with the help of data from Luminate, IMDbPro, NPD BookScan and interviews with industry insiders. Fees for agents, managers and lawyers are not deducted.
MORE FROM FORBES
Credits: AP, Ronald Cortes/Getty Images, Marty Lederhandler/AP, Michael Ochs/Getty Images, David Redfern/Getty Images, Chris Walter/Getty Images, Jack Robinson/Getty Images, Michael Tran/Getty Images, John Bryson/Getty Images, Jim McCrary/Getty Images, Bettmann/Getty Images, Max Scheler/Getty Images, Keystone/Getty Images.",8
74,"Curious futures seeds designed now
Futures gazing - sifting the international webs and other intelligence sources. Occasional short stories.
By registering you agree to Substack's Terms of Service, our Privacy Policy, and our Information Collection Notice
See all",2
75,nytimes.comPlease enable JS and disable any ad blocker,9
76,"Idéalistes, hédonistes ou profiteurs... Ces Français qui ne veulent plus travailler
ENQUÊTE - Les entreprises ne trouvent plus de candidats à embaucher, les cadres rêvent de congés sabbatiques et de retraite précoce, les jeunes diplômés réclament du sens et plus de temps pour leur vie personnelle… Et si le travail n'avait plus vraiment la cote en France?
«Idéalistes, hédonistes ou profiteurs... Ces Français qui ne veulent plus travailler» fait partie des articles préférés des abonnés du Figaro. Nous vous proposons de le découvrir ou de le relire.
C'est la même chose dans toute la France: les entreprises peinent à trouver de la main-d'œuvre. Hier, c'étaient les chômeurs qui pleuraient dans les bureaux de Pôle emploi ; aujourd'hui, ce sont les employeurs qui ne trouvent plus de candidats motivés pour les postes qu'ils cherchent à pourvoir.
Dans l'hôtellerie-restauration, les besoins se font cruellement sentir alors que la saison estivale touristique 2022 promet d'être plus radieuse que jamais. Certains professionnels annoncent déjà que, faute d'avoir réussi à former des équipes assez étoffées pour offrir un service 7 jours sur 7, ils devront fermer un ou deux jours par semaine. Même dans les régions les plus attractives, ils ont du mal à recruter les serveurs, commis de cuisine, réceptionnistes ou femmes de chambre indispensables à leur activité…",0
77,"This fall has been a blur of runny noses, body aches and lost paychecks for Jacob Terry.
“My daughter’s at home, she’s sick, I’m sick,” said Terry, 39, who lives near Los Angeles. “If I don’t work, I don’t eat. I’m medicating myself and staying up all night to catch up. It’s one big mess.”
A new round of viral infections — flu, RSV, covid-19 and the common cold — is colliding with staffing shortages at schools and day-care centers to create unprecedented challenges for parents and teachers. More than 100,000 Americans missed work last month because of child-care problems, an all-time high that’s surprisingly even greater than during the height of the pandemic, according to new data from the Bureau of Labor Statistics.
Those absences are rippling across the economy and straining families and businesses, just as many thought they’d turned a corner.
“We have sick kids at the same time we have a child-care crisis — you put the two together and there just isn’t any wiggle room,” said Diane Swonk, chief economist at KPMG. “People are falling through the cracks. It means missed paychecks, disruptions at home, and staffing shortages that erode productivity growth and increase costs at a time when we’re already worried about those things.”
Nearly three years into the coronavirus pandemic, families, businesses and health-care facilities say they’re under renewed pressure. Children’s hospitals nationwide are at capacity, in large part because of RSV and other respiratory viruses. Workplaces are reporting unfilled shifts and lost revenue as employees call out for extended periods of time. And parents are, once again, caught in an impossible position, balancing sick children, school closures and workplace demands.
There are signs that those pressures are taking a toll on the economy. Worker productivity — a measure of goods and services an employee can produce in an hour — posted the sharpest plunge on record in the first half of this year, according to federal data.
“When you have so many workers out unexpectedly, it’s a quiet drag on productivity,” said Sarah House, senior economist at Wells Fargo. “Child care has always been an impediment for working parents, but the problems with inconsistent child care that we’ve seen more recently — your child is sick or has to quarantine, or day care is closed — is making it really difficult for working parents to weave back into the labor force.”
The country’s child-care system is still reeling from the departure of thousands of educators and staffers who left during the pandemic for higher-paying work. Although the overall job market has more than made up for early 2020 losses, the child-care sector remains a major exception. Public schools are still short nearly 300,000 workers, while day-care centers are down 88,000 employees from pre-pandemic levels.
“We still haven’t dealt with some of the major problems from early in the pandemic, especially when it comes to child care,” said Elizabeth Palley, a professor at Adelphi University who focuses on education, health and child-care policy. “The median child-care worker is paid less than $12 an hour, which means you can make more working at McDonald’s. A lot of people have left the industry, and new ones are not coming in.”
That shortfall is putting increased burden on the educators who remain. In interviews, many teachers said they felt they had little choice but to keep working while sick. Dozens of schools — including in Kentucky, Ohio and Tennessee — have gone so far as to cancel classes in recent days because so many students and teachers are sick.
Kathryn Vaughn, an art teacher in Covington, Tenn., works at a rural elementary school that’s so understaffed that she’s kept teaching — with a mask — even with RSV and walking pneumonia. Roughly 15 percent of the school’s teachers are out sick on any given day, with RSV, covid or flu, she said. Substitute teachers — who are paid $65 a day — are increasingly tough to find. That means more classes are being combined, and support staff, including secretaries, are filling in for teachers. Five nearby school districts, she said, have recently closed for days at a time because of illness and staffing shortages.
“It feels like we’ve made absolutely no progress,” said Vaughn, 42. “We don’t have enough teachers. Access to health care is still an issue — a lot of students here don’t have pediatricians they see regularly. Hospitals all over the state are shutting down.”
Infectious-disease specialists say a confluence of factors, including weakened immune systems from covid-19, could be contributing to the recent spike in viral illnesses. It’s also possible that “pandemic babies” who were protected from respiratory pathogens because of social distancing and other preventive measures are now getting sick. And although many schools encouraged, even required, masks last fall, that is no longer the case, making it easier for a variety of viruses to spread.
In Lincoln, Neb., Lindsey Dick had just started a new job as a case manager for a workforce services company in mid-October when her 3-year-old son came down with RSV. Dick, 37, didn’t have paid time off yet, so she took unpaid leave for a day. Her husband watched their son the rest of the week while working his tech-support job from home.
“It was just quite a lot for all of us,” she said. “I could only miss one day and even that felt stressful.”
Low-income families — especially those less likely to receive paid sick leave and employer-provided health insurance — have been hit disproportionately hard. While 96 percent of the country’s highest-paid workers receive paid sick leave, only 40 percent of the lowest earners do, according to federal data.
In Sevier County, Tenn., neither Drew Moore nor his wife, Raven, receives paid leave. Their children, ages 2 and 4, have been sick for weeks, which means they’ve both had to pare back at work, cutting into their annual household income of about $30,000. Moore said he’s lost out on thousands of dollars’ worth of landscaping projects this fall, while his wife has had to forgo lucrative weekend shifts at the steakhouse where she works.
The timing is especially bad: Business tends to be busiest in the fall, when tourists flood nearby Great Smoky Mountains National Park, Moore said. He recently had to pass up a two-day job cleaning a koi fish pond, which would have brought in about $1,000, his biggest job in months.
“Fall is the time to make money around here; it’s what gets us through the rest of the year,” said Moore, 36. “But, of course, it’s also right when the kids’ sickness kicks off. I’m really scared it’s going to screw us up financially.”
Back in Los Angeles, Terry, the freelancer who’s been caring for his daughter, estimates he’s lost at least two weeks’ worth of work because of RSV-related child-care disruptions. He and his wife, who works two jobs as an aesthetician, have been eating into their savings to make ends meet.
“It’s been difficult for all of us,” he said. “We thought things were finally going back to normal, but it’s just one snowball after another.”",4
78,"TransportationTopicEnergyTypeNews Nighttime Charging of EVs May Overburden the Grid As EVs proliferate, charging habits might have to changeCharles Q. Choi06 Oct 20223 min read iStockphoto",5
79,"Designing without depletion: Joseph Grima’s non-extractive architecture
If we priced in the full cost of the materials most cities are built from—for people and the planet—then the way we design and build would be very different, argues architect Joseph Grima.
This article is part of our Living Cities special series, in advance of this year’s Living Cities Forum on 21 July in Melbourne. It is made possible through the support of the Naomi Milgrom Foundation. You can buy tickets here
Mining remains Australia’s largest single GDP sector by value and dominates Australian exports. Last year, amid the chaos of COVID and lock-downs, mining exports surged, accounting for no less than 68 percent to total Australian export revenue.
The top five minerals by economic value are iron ore, coal, gas, gold and aluminium ore, much of which feeds directly into the manufacturing of materials and products used in construction. Yet the carbon emissions and climate damage caused by extractive industries is becoming increasingly and urgently evident.
Meanwhile the boomerang of value-added goods manufactured from those exported minerals, which typically flood into Melbourne and Sydney’s ports every day, has stalled. Global supply chains are a mess, ports are half empty and building materials are both scarce and expensive.
A perfect storm of cost escalations and material delays are leading to project delivery hell. The construction company Probuild was plunged into administration in February, leaving unfinished projects worth billions of dollars in limbo. Fire Services Australia folded in June, as many more failures are projected for the months ahead.
What if there was a way forward that both mitigated the impacts of extractive industries and reset our dependence on global markets?
Joseph Grima’s new book Non-Extractive Architecture sets out to present just such an alternative picture for our built environment. The book is intended as the first of two books documenting a research program that explores alternatives to extractive practices within the built environment.
Foreground spoke to Grima in advance of his participation at the 2022 Living Cities Forum.
***
Foreground: In your book you look closely at supply chains and the great carbon cost our current global supply chains impose on the planet. It is also clear that the distance between a material’s source and its use has also historically resulted in reduced accountability, in relation to environmental and social impacts. Is there a case for greater local production of construction materials?
Joseph Grima: There definitely is. The marketplace as it exists and operates today depends entirely on the invisibility of the consequences of production and manufacturing, often located on distant landscapes. Making these consequences visible again and rethinking the supply chain is going to be one of the great challenge of the 21st century.
A fantastic book to read in relation to this is The Box: How the Shipping Container Made the World Smaller and the World Economy Bigger. It describes how the invention of the shipping container fundamentally transformed the global economy and produced much of today’s prosperity. The shipping container led to the highly sophisticated supply chains we see today, which has been extremely efficient in making, exploiting and creating a form of global labour and material arbitrage.
It is vital to the relocating and offshoring of production to places where the costs are far lower. But even more importantly it makes the consequences, or ‘externalities’, of production completely invisible to Western consumers.
What if we suddenly decided that we’re going to stop pretending those things don’t happen? What if we embrace the consequences of what it means to manufacture products and to build, and to price its full cost? If the sticker price included the full cost of everything we build, then suddenly making things locally and sourcing materials locally would become much more attractive.
“If the sticker price included the full cost of everything we build, then suddenly making things locally and sourcing materials locally would become much more attractive.”—Joseph Grima, @joseph_grima
FG. The book presents architecture within an expanded realm of expertise that overlaps with material science, ecology and engineering. Is there a need to fundamentally rethink the competencies and requirements of professional practice?
JG. This question points to the central thesis of the book, which is the misalignment between architecture as taught in schools and what is needed in the real world. The built environment is shaped by many factors, including economic forces and regulatory frameworks. Architects typically have very little to say within these frameworks, which significantly reduces their capacity to actually shape the built environment. The book argues that, as we’re not producing the kind of cities that we need, perhaps architects should embrace the opportunity to expand their agency.
Architecture is often considered, within the popular imagination, to be a field of aesthetic, compositional and artistic understanding. As architects, why not become more ambitious and propose ourselves as advocates, with architecture at a point of intersection between actors that make up the production of the built environment. This proposes a fundamentally different role to our current self-image, as exclusively engaged in compositional aesthetics but rather more about managing budgets. By budgets I don’t just mean financial budgets. I mean budgets of energy, materials, externalities, and stakeholder interest.
We need to take a step back and really embrace the need to impose far stricter limitations on what and how we build. We really need to understand the externalities that are created by building as we do it today and explore what we can do about those externalities. That’s a fantastic thing for us to do, because architects have the ability to work in broad teams through an extraordinary breadth of disciplines and fields of knowledge.
The rhetoric of the heroic architect has put us in the extremely sticky situation that we’re in now, where architects may have the license to create highly visible trophy buildings but are not taken seriously. We have very little opportunity to actually define the quality of life in the city and the quality of life in the places where the materials that their city is built of are from. That needs to change.
FG. Architecture is closely linked to economic and political regimes that significantly influence what is possible. Presumably any transformation within architecture requires a corollary transformations in those fields. Are you optimistic that this is possible?
JG. Absolutely. Until the marketplace is levelled, we’re never going to make any significant progress. Living as we supposedly do in an age of free markets, liberalisation and deregulation, everybody assumes that we are living in the heyday of the free, open, balanced market. But that’s not the case. The way that we build today is only economically viable because we leave off our budget sheets a whole list of items related to how materials are produced, sourced, transported, sold and purchased and then used to make a building.
Think of concrete as an obvious example, which has incredible plasticity and strength. It became a kind of miracle material for modernist architects, and it still underwrites much of the world’s infrastructure. Yet concrete produces enormous CO2 emissions. Also, vast landscapes are being depredated for the production and sourcing of the sand. As a material we’re all accustomed to seeing it all around us all the time, concrete is a very good example of how deep this problem runs.
But even timber, considered sustainable by many people, is often sourced from forests that are not replanted. In Siberia trees that are often hundreds of years old are being forested, and therefore not easy to replenish. To use timber as one example, it’s going to be near impossible to convince clients that they should source local, more expensive timber, that may be part of a long-term reforestation programme, until all the so-called externalities associated with the status quo are scrupulously audited, listed and budgeted. We need regulations in place that demand these externalities are taken into consideration when the budget for a building is constructed.
The shift in thinking that we need is only going to occur at scale when we begin to understand these questions on a systemic level. This might seem rather frightening to some, but I would argue that it can become an incredible opportunity to make our building’s and cities more interesting and make our planet more diverse. So that when we travel, we experience cities that are responsive to their location, built from what is possible to produce locally and has a deeper connexion with the culture of a place.
“Our house is burning and now is not the time to be worrying about the pitch of the roof and the tone of the paint on the facade”— Joseph Grima, @joseph_grima
FG. You mentioned the hero architect, and indeed much of the public’s appreciation of architecture is dominated by heroic form. There is an expectation that important architecture is always somehow iconic. To the extent that iconic architecture is often also materially extravagant, is the non-extractive approach conceived as an antidote to this, or even a challenge of this very visible architectural paradigm within the public imagination?
JG. The present understanding of what architects do is a huge problem, both on the part of the architects and the public.
For architects there is an expectation that success equals being becoming the author of iconic sculptural presences within the city. This idea needs to be completely reframed, to reposition the architect as the guardian of the landscape and the guardian of the environment. This means finding ways to produce beauty in a way that is much more about the creation of a pleasant and liveable environment, in the sense that Christopher Alexander often wrote about. Something other than just creating something that’s going to be photographed the day it’s finished and have its 15 minutes of fame on the design blogs. After which it lingers in the environment for another x number of decades, often just half-dead, until it gets dismantled and/or refurbished.
One example of a strategy that would facilitate a change in thinking is to approach buildings as intended to be modified by their occupants. This would recognize that certain aspects of living in a place take time to make the space compatible with the way that they live in it. Another strategy is to think about buildings as modular structures that can be configured and reconfigured as necessary. Another is to think about buildings in the very long term and the very short term. Contrary to the idea that everything needs to last for thousands of years like a roman temple, buildings can also be like frames that are temporarily filled and adapted for a period of time, and then that frame is occupied and lived in, in a completely different way.
Our house is burning and now is not the time to be worrying about the pitch of the roof and the tone of the paint on the facade. There are much more urgent things that we need to be thinking about. So it’s about loosening up our canons in aesthetic terms. All of these things need to be advocated by and understood by architects themselves, and then understood by the public and then somehow translated into legislature that can reconfigure the design process and the permit process. All of which leads to a completely reformulated role of the architect.
FG. Sustainability is an inherently slippery term. In broad terms however there has been a clear divide in how sustainability has been practiced in high-income economies compared to low-income economies. The former has invested significantly in technological solutions whereas the latter tends towards lo-tech and labour intensive solutions. Will the idea of non-extractive architecture result in different outcomes in, say, Germany and Ghana?
JG. In a way, you could say that this whole project started from a certain frustration with the word sustainability, which is overused and has become threadbare. Our first intuition was reflect for a moment on what we actually mean when we say sustainability.
The expression non-extractive architecture came from an understanding of what actually needs to be done if we’re going to live in a way that is equitable at a planetary scale. It reflects how individuals and societies need to rethink our existential practices to be able to live in a way that is not the predatory practices that our current societies do, especially Western developed economies.
This idea of extraction points to a couple of critical aspects of the current construction industry. The first being the practice of extracting finite materials from the soil and using them extensively in the construction of our built environment. Then the same kind of attitudes apply to non-material assets, such as labor. So the term is descriptive of an attitude rather than a specific practice. It describes an ideology of extraction that is completely ingrained in the way that we think about the built environment industry. So ingrained in fact that we fail to recognise it.
This is perhaps one way to talk about sustainability, as the management of resources, material and immaterial, within a closed ecosystem that is clearly finite with very clear boundaries. The dominate paradigm today is to treat these resources as though they were not finite.
As to how it plays out in different parts of the world, in developed nations our expectations, in terms of comfort levels and quality of life, are extreme. But these are clearly not universally applicable to everybody on planet Earth. We have to rethink those expectations.
This is something that absolutely can be done without having to necessarily sacrifice the quality of life that we hope to achieve. We just need to think about it in a much less predatory way. Not solving our short-term problems by plundering the natural environment, simply because we have the technological means to do so. We need to think about this in the very long term, noting that this is something we can really learn from prior civilisations and from existing First Nations cultures.
Therefore, the question regarding developed economies and the less developed is a double-edged sword. It is complicated trying to convince the citizens of developed nations to rethink their practices and expectations. The idea of prosperity has a different resonance compared to those who live in a country that is perhaps only really recently able to look towards a horizon of prosperity, or indeed those that might live in deep discomfort as a consequence of having been plundered by others. In that context, any kind of improvement is a gain.
FG. Non-Extractive Architecture Volume One presents a theoretical framework for thinking about this question. Volume Two will be a much more practical, case-study approach. Can you provide a specific example of how non-extractive architecture can approach the challenge of using materials more responsibly?
JG. The next book will be, as you say, focused on what non-extractive architecture actually translates into in practical terms. Some examples in the book are purely policy focused, while others are dealing with very specific material challenges. It is important to recognize here that there is no single solution, and non-extractive architecture should not be understood as a dogma. It is more a question of being responsive to a certain set of conditions or needs in a given place and time. It’s very much a philosophy rather than a specific method or practice.
One example relates to our own practice Space Caviar, which is working on the exhibition design for the 23rd Triennial in Milan, which will be titled “Unknown Unknowns: An Introduction to Mysteries”. It is curated by Ersilia Vaudo, an astrophysicist, and the Chief Diversity Officer at the European Space Agency. It is looking towards the cosmos and the future of our species. The production of cultural events of this kind are one of the greatest sources of waste because they are temporary, so we have decided to rethink the formal expectations of how an exhibition display is produced.
Working with the Italian 3D printing company WASP we have brought their printers into the space and printed the entire exhibition display using clay. The material is produced by another local company that uses a binder for the soil that’s a by-product in the production of rice for risotto. As you know, northern Italy is famous for its risotto and a by-product of that is rice husks, which are typically thrown away. But they can produce an excellent binder when combined with the soil, which then becomes a 3D printable material.
Nothing has ever been printed at this scale before, certainly not indoors, inside an exhibition space. At the end of the day, the exhibition and the whole display system can just be broken down and thrown back into the fields because it’s all completely organic material.
This for us is a test, to think about exhibition design based on local production and embracing advanced technologies. 3D printing like this at full scale is something that we’re hoping to use in various upcoming projects but it is still in the early stages of development. It hasn’t really been done with organic materials. There’s lots of experiments with concrete printing and so on, but that’s something we’re interested in.
What is core to this kind of cross-disciplinary work is the need to work in teams and networks rather than the idea of the architect as heroic, centralized figure.
FG. If there was an Olympics of non-extractive architecture, which country would sit at the top of the medals tally, and why?
JG. If those Olympics were to take place today then I suspect Antarctica would win.
Our ideas and expectations around the built environment are so deeply entangled with the practice of extraction that it’s going to take quite some time before we can really retool our economies and our industries to become truly non-extractive. I think that really goes back to one of the key points here, that we really need to question the idea that building is the answer to many of our needs. Instead we need to think far more creatively and flexibly about how we can adapt existing environments to our future needs.
As Cedric Price once famously said, “No one should be interested in building bridges – they should be interested in how to get to the other side”.
—
Space Caviar is an architecture and research studio operating at the intersection of design, technology, politics and the public realm. Founded by Joseph Grima and Tamar Shafrir, the office uses built work, exhibitions, publishing, writing and film to investigate and document contemporary modes of habitation and the spatialisation of social and political practice. He will be speaking at the Living Cities Forum on 21 July at Melbourne’s Federation Square.",2
80,"Mifrah Abid’s eight-year-old son, Moosa, loves The Avengers. He’s obsessed with his Iron Man action figure and can talk at length about its many suits. Her twelve-year-old daughter, Tooba, meanwhile, went through a Roblox phase, playing a video game that’s all the rage with kids her age. But, early in the pandemic, when everyone was spending more time together at home, Abid went looking for something the whole family could enjoy. “[Millennial parents] don’t know about new toys,” said Abid, who lives in Kitchener, Ontario, and is host and producer of the interview podcast Across Her Table, which focuses on women with immigrant roots. “We were like, ‘Let’s go back to what we know.’” She thought back to her own childhood, to those old games the family played while crowded around the table—Monopoly, Pictionary, Uno. She decided to try to introduce them to her kids. Now Moosa and Tooba love them too.
It was a similar story for Robert Lee and his two daughters. Allie is six, Annie is four, and they both love all things Paw Patrol, Peppa Pig, and Baby Shark. But, for Christmas two years ago, their mother bought them a Lite-Brite and a Spirograph—simple art toys invented back in the ’60s that she remembered from her own early years. These weren’t the toys that Lee’s daughters typically saw in the YouTube videos they watched. They didn’t have flashy advertising campaigns or tie-in television shows, meaning the kids would never think to ask for them on their own. But Allie and Annie loved playing with them all the same.
Kids get older, and fads come and go. But some toys persist, almost stubbornly—artifacts passing from one generation to the next. In the toy business, these products are considered “classics.” It’s an amorphous category filled with all sorts of games and toys that have just a few things in common: namely, they are survivors in an industry where trends rule all. The Rubik’s Cube is, in many ways, the perfect example of a classic toy. More than 450 million are estimated to have been sold since 1978, with up to tens of millions of units still moving in a year. Etch A Sketch (180 million sold since 1960), Lego, Potato Head, Barbie, and, of course, Play-Doh are classics too. These toys are instantly recognizable but rarely advertised. They’re often low tech or analog. In fact, in a world full of screens, their tactility is increasingly part of the draw. Often, classic toys encourage what academics say is high-quality play, like problem solving or imaginative thinking. And, as some experts have found, such toys are highly nostalgic—conjuring warm, fuzzy memories in the parents who do the buying. This is how toys turn into tradition.
In 2016, Jane Eva Baxter published an article in the International Journal of Play that considered the role of nostalgia in keeping two particular items alive: the rotary-style Fisher-Price Chatter Telephone and wearable Mickey Mouse ears. Toys, she wrote, are often thought of as tools of preparation. It’s the reason parents buy Lego (to encourage creativity and cognitive thinking) or dolls (to simulate caregiving). It’s why most daycares and kindergarten classes have colourful blocks with the alphabet printed on the sides: to teach, to set kids up for future success.
But learning and development can’t be the only reason certain toys stick around, wrote Baxter, who is chair of the anthropology department at Chicago’s DePaul University and an archaeologist and historian of childhood. After all, here were two items—a rotary phone and mouse ears—that have persisted despite having no clear connection with the present. “The emotional connection adults have to this iconic toy has kept it in the marketplace despite the fact that a rotary-dial landline phone is technologically irrelevant for children today,” Baxter wrote. The same could be said of Mickey Mouse ears. The toy hasn’t appeared on TV as much in recent years, is no longer featured prominently in Disney’s theme parks, and is based on a character who is “increasingly peripheral to the Disney brand.”
Speaking from her home in Chicago, Baxter explains that parents, not toy producers, were the ones driving these sales. “There is this nostalgic element of either wanting to share something from their own childhood or give something that they felt they lacked in their childhood, because they think it will be good,” Baxter says. Especially now, in a largely digital world, there is something about these analog toys “that parents see as desirable for their children [and] that we find desirable for ourselves.” In fact, when Fisher-Price tried to modernize its iconic toy phone by removing the rotary dial, there was a consumer revolt, and sales fell. Nostalgia, Baxter concluded, is what keeps certain toys alive.
If you’re Toronto-based Spin Master, one of the largest toy makers in the world, nostalgia is also good for business. Founded in 1994 by two recent graduates from Western University, Spin Master quickly made a name for itself creating playground fads. One early success was 1997’s Air Hogs, a pump-powered, hand-thrown plane that could fly the length of a football field on nothing more than pressurized air. Then there was Bakugan, a 2007 mania centred on battling creatures from another dimension (think a mash-up of Pokémon, Transformers, and Yu-Gi-Oh), which involved an anime series, collectible trading cards, transforming toys, and a board game.
And, of course, there’s Paw Patrol. Created in 2013, Spin Master’s star franchise follows the adventures of a group of rescue dogs and their leader, a human boy named Ryder. Paw Patrol has spanned nine TV seasons, a Hollywood film (the second is now on the way), and, most importantly, a sprawling line of toys, merchandise, and games. The brand practically prints money for Spin Master, which today is worth around $4.4 billion and has 2,000 employees spread across nearly twenty countries.
But the company learned an important lesson from Bakugan, which had generated more than $1 billion in toy sales by 2014, before its popularity started to wane: what goes up eventually comes down, especially when it comes to fickle young audiences. That’s where the classic toys come in. Having one of these brands in your portfolio is every sales department’s dream. They practically sell themselves.
Beginning in 2013, Spin Master went on a spree of acquiring classic toy brands. It started with the century-old British construction toy Meccano (also known as Erector), which allows kids to build models by joining metal strips and plates with nuts and bolts. Then, in 2015, the company paid more than $50 million (US) for Cardinal Industries, one of the oldest manufacturers of chess sets and other traditional board games in the US. It bought Etch A Sketch in 2016. Plush maker Gund, founded in 1898, was snatched up for nearly $80 million (US) in 2018. And, three years later, Spin Master closed on Rubik’s Cube for about $50 million (US). Spin Master, like a Hungry Hungry Hippo, has been gobbling up many of the oldest and most-loved toys in North America with gusto and learning lessons along the way about what products stand the test of time.
Most toys burn hot, bright, and fast, making Paw Patrol’s nine-year reign something of an anomaly. But, eventually, even Paw Patrol will fade. So why is it that some toys don’t? Many companies are trying to figure out the answer to this question, because as great as it is to invent the must-have toy of the season, it’s even better to create one that kids will be playing with 100 years from now.
In a Connecticut classroom, a wooden-block monolith rises from the floor. The tower is flanked by two small children on a mission to make it taller. But there’s a problem: there are no more long blocks left on the shelf. The children have used them all. One of the boys looks around, and after a moment of deep thought, a look of recognition spreads across his face. You can almost see the light bulb flash. He takes two smaller blocks and connects them together. Now, “this is a long one,” the boy says, triumphant. Problem solved; the tower grows.
The precocious boys were being filmed by researchers at Eastern Connecticut State University’s Center for Early Childhood Education. They were part of a long-term study of preschool children called TIMPANI, or Toys That Inspire Mindful Play and Nurture Imagination. From 2010 to 2019, TIMPANI researchers put kids together in rooms and observed how they interacted—with toys and with one another. A generation of kids built whimsical Duplo houses and elaborate marble runs. They pretended to run stores, bakeries, and ice cream shops, with all the requisite props. Simple toys proved especially popular, the researchers found, and those old-timey blocks, cars, people, and shapes seemed to yield the most imaginative play. Julia DeLapp, the centre’s director, says that while there’s been lots of research on how children play and how play affects a child’s development, less attention has been paid to the toys themselves. What kinds of toys encourage the most creativity, imagination, problem solving, or collaboration? What, specifically, makes a kid gravitate toward one toy over another? DeLapp and her colleagues had their suspicions, but they decided to test them out—and for good reason. “I think that children’s earliest experiences with play influence them for the rest of their lives,” she says.
Each year, Eastern used its findings to crown a “TIMPANI Toy of the Year,” and it probably won’t come as a surprise that many are certifiable classics: Hot Wheels, Duplo bricks, Tinkertoys. “The reason they’re still around is because they are fabulous toys. They allow children to use their imagination. They’re very open ended,” says DeLapp. The study consistently found that construction toys (like Lego or Tinkertoy) and replica toys (fire trucks, stuffed animals, and dolls) produced the most imaginative and creative play. The less restrictive and more flexible the toy, the better. In one example, the researchers found that a wooden cash register encouraged children to talk about buying and selling items, whereas an electronic one with lights and sounds encouraged them to press buttons instead—more entertainment than engagement. “The more open ended a toy is, the more room there is for children to make it anything they want [it] to be,” says DeLapp. “The beauty of simple toys is that they don’t do anything for a child. And so it’s up to the child to figure out what to do.”
Many of the items on TIMPANI’s list can also be found in the National Toy Hall of Fame, a shrine to fun housed at the Strong National Museum of Play in Rochester, New York. Though not academically rigorous by any means, the hall of fame has inducted seventy-seven toys since its creation in 1998. In its first year, it welcomed Play-Doh, Monopoly, Etch A Sketch, Barbie, Erector set, Lego, and Tinkertoy. Later years have added Mr. Potato Head, Slinky, Tonka trucks, and Rubik’s Cube. All were chosen based on a mix of popularity, longevity, and the quality of play. But the hall of fame has also inducted a handful of items that aren’t toys in the commercial sense: objects like “stick,” “ball,” “sand,” and “cardboard box.” All parents know that kids love boxes. “You can go in it, you could go on it, you can draw on it, you can cut it apart. It could be anything. It affords a lot of different types of play,” says Barry Kudrowitz, a professor at the University of Minnesota. He has taught toy design for eleven years and is the author of a forthcoming book about play and innovation.
Kudrowitz says that, much like the humble box, the toys and games we most often think of as classics are the ones kids can figure out on their own, regardless of the cultural or social contexts around them. Imagine a time traveller encountering a Rubik’s Cube for the first time. “The size of it is going to say, ‘Pick me up,’ because it’s designed to fit exactly in your hand,” he says. It doesn’t take much to realize the cube moves and to notice the different colours on each of the squares. “It’s only a few steps before you start making a game out of it and realize that there’s a challenge to it,” he explains. It’s similar to how it doesn’t take much to infer the relationship between a basketball and a hoop or what happens when you turn the knobs of an Etch A Sketch. The constraints guide the player, but there’s enough freedom and challenge to keep them coming back. It’s no wonder the robot WALL-E, in Pixar’s eponymous 2008 film, could figure out how to play with a Rubik’s Cube some 800 years after humans left Earth behind.
Of course, a Rubik’s Cube is also more than just a well-designed puzzle; in Kudrowitz’s words, it’s the embodiment of what is now a classic play pattern: challenge play. Other patterns include replica play, co-operative play, competitive play, pretend play, construction play, creative play, or nurturing play—there’s no single, agreed-upon classification—but what’s important is that these ways of engaging with the world haven’t really changed much over time. A Nerf ball gets a certain amount of its power from its tactility, design, and marketing—but also from the fact that humans, all over the world, have been playing with balls since time immemorial. Or consider the act of jumping rope; Egyptians were using vines for skipping games in 1600 BCE.
“I don’t think that’s going to go away ever,” says Kudrowitz of the Rubik’s Cube. “And that’s why it’s classic.”
Ben Varadi was about ten when he saw a Rubik’s Cube for the first time. Hungarian designer Ernő Rubik invented his special cube in 1974, and by the time Varadi encountered it, in the ’80s, it was already a hit. The Spin Master co-founder grew up in north Toronto and spent hours each week at a store called The Toy Man while his mom ran errands nearby. Shelf by shelf, he would study every item, and he remembers the small, colourful cube catching his eye. After Varadi grew up and entered the toy business himself, he saw first-hand how those childhood impressions stick with a person and help keep classic toys like Rubik’s Cube alive.
“With a new toy, you’ve got to tell the story and hope that someone gets excited about that story on day one, right? Because they’ve never seen it. They’ve never heard of it. They don’t know what it is. They don’t know what it does,” Varadi says. But there’s something transportive, even transcendent, about encountering a toy you played with as a kid. “I don’t think we realize the power of a classic,” he continues, “because a classic speaks to us in ways we don’t even understand.”
Spin Master has stiff competition in the industry, as two of the biggest players, Hasbro and Mattel, are practically classic incarnate. Both rose to prominence in the early to mid-twentieth century and possess deep catalogues of legacy toys (Easy-Bake Oven, Jenga, and Potato Head for Hasbro; Fisher-Price, Hot Wheels, and Barbie for Mattel). For a comparatively young company like Spin Master, acquisitions are the only way to keep up. When Spin Master considers an acquisition, long-term margins and profitability are significant factors, as is the time it will take to pay off the investment. “The life cycle in toys is often two or three years. And [as a company] you don’t want to buy things that are only going to be around two or three years,” says Chris Beardall, a twenty-year Spin Master veteran and its chief commercial officer.
Spin Master, like many publicly traded companies, doesn’t disclose revenue or sales for individual brands or items. But, based on its public financial filings, sales in the activities, games, puzzles, and plush category—where many of its classics are counted—have more than doubled since 2015.
One of the standouts in the category is a relative newcomer called Kinetic Sand. When Beardall first saw the toy, around 2005, it didn’t seem especially consequential. Created by a pair of Swedish inventors in 1994, the toy is exactly what it sounds like: a pail of material that feels just like wet sand you’d play with at the beach. Kids can make castles and shapes; they can build and destroy. Unlike real sand, though, Kinetic Sand never dries out and is easy to clean—but so what? “I didn’t think it would work,” Beardall recalls. “It just didn’t make sense to me that we were going to sell this interesting sand to kids in lieu of Play-Doh.”
Kids seemed to love it all the same, and in 2007, Spin Master gave it a shot. It licensed the rights and initially sold the product under the name Moon Sand. “It was a big hit,” Beardall says. Moon Sand took home a prize at that year’s Toy of the Year Awards, and, eventually, Beardall came around. Rebranded in recent years as Kinetic Sand, the toy remains a hot seller and a frequent highlight in Spin Master’s quarterly reports. In twenty years, Beardall says, it will be recognized as a classic, right next to Play-Doh on store shelves. Parents will see it, remember having played with it as children, and buy it for their kids.
That familial relationship isn’t incidental. For the toys that survive, it’s key. “Nobody’s like, ‘Do you want to use the washing machine my grandmother used?’ No!” says Baxter, the childhood archaeologist. But childhood is a powerful and potent time in one’s life—something we tend to idealize the older we get. Unlike grandma’s washing machine, Baxter says, there’s an “inherent conservatism” in children’s toys that makes them an incredibly useful vehicle for passing along memories and family histories. In her journal article, Baxter even included a picture of her nephew playing with a Fisher-Price Chatter Telephone she gave him as a gift. “Why did I do that? Because I had one, and I loved my Chatterbox phone as a little kid,” Baxter says. It’s harder to convince a child to care for a toy you never cared for yourself.
Of course, the window when kids will actually play with what adults give them is terribly small. By the time a child is ten, “they already know what they want,” Baxter says. But, until that happens, adults have unparalleled power to influence play. When a child sees something that adults fancy—consider the way a room will “oooh” in unison when a Tonka truck is unwrapped—they are likelier to become excited about it too. And, when that child grows up, they are more likely to share that experience with their own kids. For a toy to last generations, it has to be a vehicle in more than just the literal sense.
Joan Ramsay has been in the toy business for more than twenty years—long enough to see many attempts to revive and reimagine old toys. “I couldn’t begin to count the number of times My Little Pony’s come back,” says Ramsay, who’s held senior positions at Hasbro Canada and the video game company THQ and now heads analysis of the Canadian toy industry for the NPD Group, a market-research firm. “When there’s a new group of kids every four years, it’s new to those children. It’s brilliant. If you’ve got something that works, why not?”
But popularity in the past doesn’t always spell success in the future, and the reality is that every toy on a store shelf faces stiff competition in an increasingly crowded market. Analyst Chris Byrne says that more than half of the products on offer in the toy industry are new every year—a figure that’s unprecedented in other businesses.
So toy makers have to get creative to keep consumers buying. Licensing is a common—and often successful—way companies take old toys or games and make them feel new again. “That little square that we’ve all stepped on—for Lego, that hasn’t changed. But then they add topical licences to keep it fresh,” Ramsay says. Think of the Lego versions of Star Wars’ R2-D2 or Minecraft-themed play sets. “That provides the newness, if you will, that keeps people coming back to buy Lego again and again and again.”
But this approach, too, is effective only for so long. Toys tied to characters or brands can be hard to sustain, because those things are often associated with the specific culture or era in which they’re created. Byrne points to Pound Puppies, which were initially sold in the ’80s, a time when adoption figured prominently in the cultural conversation. But that no longer resonates with kids the same way. Or consider Care Bears, Cabbage Patch Kids, Strawberry Shortcake, and Polly Pocket: all rode a bygone trend of sweetness and cuteness that doesn’t have the same cachet today. “People are finding an audience for these,” says Byrne of these revivals, but “they haven’t become the phenomena they once were.” Without a newfound well of cultural relevance—the kind that My Little Pony found in 2010 with its animated TV revival—it’s even harder to stand apart from all the other plush toys on store shelves.
Even nostalgia for some of the most successful toys runs the risk of losing its sheen as our connection with the past frays. Baxter thinks that, after a few generations, even something as timeless as a Rubik’s Cube may struggle to stay relevant without the stories we tell to keep it alive—stories that will inevitably be replaced by memories of newer, more potent toys. “Eventually, that’s going to break down,” she says. “Even the object isn’t going to be able to hold that intangible chain together.”
So what does stand the test of time? Ask Byrne and he’ll tell you the toys that never get old are the ones that consistently light up a child’s imagination; that let them explore, express themselves, and be creative; that survive cultural and societal shifts alike. Something timeless, Byrne says, like . . . He-Man.
He-Man?
Yes, the blonde, buff hero—an icon of ’80s machismo—has been updated and reimagined for a new generation. He-Man and his friends, the Masters of the Universe, still have adventures and wage war against the evil Skeletor, who is intent on conquering Castle Grayskull, the source of He-Man’s power. But, unlike in the original series, the spotlight now equally shines on the powerful women who fight by He-Man’s side, and Black heroes are also finally front and centre. Netflix released a pair of new animated series in 2021 that embodied this new approach. Masters of the Universe: Revelation, written by Kevin Smith, was a more mature take aimed at adults who watched He-Man growing up, featuring a high-profile cast of familiar names, including Mark Hamill, Sarah Michelle Gellar, Henry Rollins, and Alicia Silverstone. The rebooted He-Man and the Masters of the Universe, meanwhile, was aimed at kids, like the original. Both arrived with a new line of toys.
The return of He-Man raises a crucial, confounding question: How does a toy make the transition from fad to future classic? Rubik’s Cube was considered a temporary blip when it launched, after all. It’s tempting to think it’s just a matter of time. But time merely gives us the perspective to see, after the hype has gone, what was there all along. A Rubik’s Cube is a magic trick, a math equation, a cultural phenomenon—but its longevity suggests a kind of play that’s ancient and instinctive: the human reflex to match like with like. In this respect, it’s no different from the stick, the ball, the cardboard box.
So, yes, in that context, He-Man’s inclusion in the pantheon of classics might sound strange. But what’s timeless about He-Man, as Byrne explains, is actually something deeply, enduringly human. It’s a personified idea that gets to the heart of childhood: “the desire to have agency over your actions and to have power. And it’s not necessarily aggressive power,” he says. “When you’re five and your whole life is, ‘Eat your peas, do your homework, get in the minivan, change your clothes, do all of this,’ how cool to be somebody who can just say, ‘BY THE POWER OF GRAYSKULL’ and turn into something enormously powerful? That’s so cool!” And it’s a feeling kids will have forever.",1
81,"What can I do to prevent this in the future?
If you are on a personal connection, like at home, you can run an anti-virus scan on your device to make sure it is not infected with malware.
If you are at an office or shared network, you can ask the network administrator to run a scan across the network looking for misconfigured or infected devices.",1
82,"This piece was originally published on May 28, 2020.
The media companies of tomorrow should look something like the record labels of today.
In the record industry, talent is the driving force behind the business. Talent is the source of the reputation and the end of the line when it comes to driving financial returns. Without great, world-class talent, it doesn’t matter how well you can promote or polish an artist, it will not have the same returns.
Business models are product strategy and revenue is a proxy for how an industry serves its customers. In media, traditionally, the economics place value and attribution on brand driven products that put an emphasis on audience (advertising) and “all you can eat” consumption behaviors (subscriptions). But these models are only as stable as the companies ability to maintain their talent, grow an audience and continue building their brand’s reputation. Those times are changing.
Media companies have always been talent companies but their business models don’t necessarily reflect that. That’s because while talent was a driving force behind their business, the financial focus was tied closer to content ownership and distribution; two things media companies once had complete control over. Content access was limited based on what was available through distribution channels, which often meant just a handful of stations or papers within your city or town. And as media began to evolve, so did the reputation beyond the masthead, and writers, creators, producers all under bylines became a core value proposition for media companies and consumers alike. The media business suddenly had a three pronged strategy for revenue with talent plus ownership and distribution, all driving their business forward in parallel. And then, with social networks among other things, there was a shift.
Ben Smith of The New York Times wrote an article this past Sunday on media’s next business model: monetizing the individual. In it he points to the development of platforms like Cameo & Substack that serve as a network to enable creator independence. He highlights the talent that’s moving from traditional media to “go solo” and the promise of these platforms to disrupt traditional media the same way that it disrupted Big Tech. Basically, with the insertion of Venture Capital in the technology sector, talent like engineers and product managers at larger institutions were able to spin out and go build a business on their own. What this shows is that talent who wish to control their own direction or have their own ideas outside of a traditional set-up are able to go out and do so. With that, money — and customers — will eventually follow.
We could look at this trend as yet another existential moment for media companies that have been disrupted by platforms across all business pillars. Or, and hear me out, we could see this as an opportunity to lean into something we as an industry have always been good at and build a new business around it. As the media industry thinks of models of expansion, talent is an opportunity to build on top of an existing foundation to explore business models that focus on the creator, the relationship of a creator and brand, and the undervalued importance of creator operations.
The “monetize the individual” disruption should serve as a catalyst for the business reinvention of media companies who choose to recognize and react to this “new” (I know it’s not new but what’s old is new again) trend forming. It’s not just about enabling and “liberating” creators and talent, but more importantly about maintaining, supporting and growing an individual’s business better than they’re able to do on their own or elsewhere. The future media business will be inclusive of its foundation of advertising, subscriptions, events & brand reputation but will extend to newfound territory that fortunately is right in its wheelhouse: Talent Management (Artists and Repertoire A&R).
In 2018 I went on a Twitter rant on how media companies should start looking at record labels and, more broadly, the evolution of the music business to help influence its next wave of focus. Mainly to show that there is tremendous opportunity in the ability for artists and labels to work together in order to grow both their businesses and reputation in parallel. Labels are masters at managing a creator and building a brand while allowing the artist to go out and do what they do best; create.
In it I explain that media companies, while fighting against the platforms, are uncovering an entirely new value in the media ecosystem: being an agency & platform for talent. If the future role of a media company mimics that of record labels, then we start to see a significant shift from these institutions to attribute more of their value as operators and begin to diversify their business of being *just *a brand. But what I didn’t realize at the time that is very clear now is that this is also where traditional media companies have a head start. Media is an industry where brand matters and that reputation is earned not learned. Media institutions have spent years perfecting audience development, learning how to acquire consumer trust and deliver on product expectation that puts their reputation at incredible heights that platforms and/or challengers often cannot reach. If you pair brand reputation with a business operation that manages/acquires/maintains talent better than challenger platforms, then this truly looks like a next generation media property.
So what does that look like? The media business is finally hitting its Napster moment. Well, we’ve really been in our Napster moment for years but the accelerated trend-parlay of a “monetize individuality” movement, an advertising bottom out due to coronavirus and everyone becoming a membership business, has made the existing revenue opportunities insanely competitive and unattainable for many. This disruption is a catalyst for reinvention, and extended business opportunities from those that manage, operate and support talent. And this decision to extend ownership of responsibilities to include talent management on top of brand’s that matter, and are reputable, will push these institutions towards a new world. To build off of the Napster moment, and to parallel this change with music, by getting into the talent business media success will look lot more like record labels than record stores.
Putting talent at the center of its business opens up entirely new opportunities for media companies when the core asset and value is attributed to the individual. The new line of business now becomes somewhat inverted: instead of everything being limited to under a brand halo where advertisers buy on the brand and consumers subscribe to the brand, the company and its customers now look at the individual as their business. This presents a business opportunity that’s so often seen in the media industry tied to talent which is interoperability (see: Kara Swisher, Andrew Ross Sorkin). If the talent within your organization wants to write, produce, create elsewhere, then with a new business model that enables equity and investment in the individual by that brand, that is beneficial to the both parties bottom line. Again, look at the record industry: emphasis on the talent (artist) only drives more value and more revenue for the label (brand). The label pays for a song to be produced so they can partially own the song. There is equity in their investment of that artist. Record labels are having record years because they own the publishing rights to songs. People hear a song, the label gets paid. It’s a formula that on top of existing revenue opportunities (advertising, subscriptions, events) opens up an entirely new well of business.
The financial incentive changes from “keep creator on platform” to “enable the creator to go everywhere”. Noah Chestnut connects this notion with Lorne Michaels business model for SNL and I think that’s brilliant. Lorne owns Saturday Night Live. The brand holds a lot of reputation and value for the creators who act and the consumer who watch. And what it shows is the power of brand reputation in order to build** **an individual’s reputation. The actors choose SNL in order to launch their career based off of the reputation of the brand. They do so and, if successful, move onto film, television, everything and anything off of the SNL platform; and Lorne Michaels benefits.
But note, the opposite can also take place. Take ESPN for instance. Creators leverage the ESPN platform, build their reputation and audience but that following and reputation doesn’t necessarily stick with them when they leave. Everything can also start and stop within that system.
Reciprocity is key.
This welcomes discussions around the role of the creator and the equity opportunities of how brands can *invest *in this new individual model. Like the music industry and other agencies, in order for new models to be explore the brand needs to think of themselves as creative operators. This should be somewhat easy for media companies to wrap their head around and execute, and we’re seeing many of them doing it today (see further below).
But what’s in it for the talent? Why should they continue to want to create at larger, legacy institutions outside of the brand’s reputation? Independence is so great! But wait… what about medical? And libel insurance? And PR? And… And… Damn! That stuff is hard. Also, how about all of the creators who haven’t already accrued a large following? Or earned enough reputation to go solo? This is the value brands bring in parallel: operations and reputation. Operations to maintain and develop talent and reputation to help build and enable creators to build a brand of their own. And again, another deep connection to the functions and businesses of the role of A&R in music industry.
The value of record labels in the music business is real. Artist recruitment (A&R), copyright enforcement, distribution, booking, accounting, marketing… it’s a lot. And this is where the value lies. There are labels that are reputable and labels that are not but the reason why artists sign to them is because there’s an acknowledgement by the talent that it’s somewhat critical to their success. Creator trust and brand reputation is the formula.
With the growth and acceleration of The Passion Economy, we’re entering further into new consumer value where reputation is attributed and put on creator/writer/producer/artist over the brand itself. And with direct subscription accessibility now with creators across various platforms, consumers are building a relationship directly with the creator herself.
There are many reasons platforms have been successful in driving creator interest on their properties. But one single point is their acknowledgement of operators and distributors for a creator’s work. This is how they’ve encroached so successfully into advertising, subscriptions and now, original content. They’re identifying their purpose as operator, and enabling creators to create by giving ownership and attributing value to the creator itself. But this only goes so far. After creative independence, there is a need to grow and sustain. This is still very much untapped and unobserved, mainly because 1) it’s new and 2) this is already a core value that’s assumed by legacy media brands. Outside of reputation, operations are critical to the longevity and sustainability of the creator. And this is where the opportunity lies.
In music, the listener usually doesn’t know or care what label the artist is on, in fact it’s often purposely unknown and operating in the background (there are exceptions, like Sub Pop, and every Phish fan knows Red Light but you get the point). The reputation, ie. the consumer value, is almost always attributed to the artist itself. The artist carries consumer attention, creative development and the relationship with his/her audience and the record label, well, they handle the rest. The same formula works beautifully for media and is already being executed by many, new media brands like Barstool Sports and even traditional media properties like The New York Times.
By pairing brand reputation with the ability to execute on a creator’s behalf the ability to help build audience, scale a business, administrative operations and benefits such as legal and medical, the next wave of media will be incentivized to have a heavy financial and philosophical interest in the individuals. And so will the talent. This is an opportunity for the media business to reassert value on top of the current revenue streams by fulfilling a need for creators who should be focused on what they do best: create. The solution is building the platform for talent, pairing both brand reputation and individual reputation, and connecting it all together.
Thanks to Josh Elman, Noah Chestnut, David Turner, Julia Beizer, Web Barr and Patrick Workman for reading, editing, engaging & dealing with me.
Some additional food for thought to battle in comments or twitter or anywhere:
Are media companies equipped to become talent agencies and managers? Can they move fast enough against a Creative Artists Agency or Endeavor to represent creative talent?
Many brands are already doing this and simultaneously building brand reputation and individual reputation in parallel: WaPo, NYT, Brat, Morning Brew, Axios are a few. Who else?",1
83,"Nope (film)
|Nope|
|Directed by||Jordan Peele|
|Written by||Jordan Peele|
|Produced by|
|Starring|
|Cinematography||Hoyte van Hoytema|
|Edited by||Nicholas Monsour|
|Music by||Michael Abels|
Production
company
|Distributed by||Universal Pictures|
Release dates
Running time
|130 minutes[1]|
|Country||United States|
|Language||English|
|Budget||$68 million|
|Box office||$170.8 million[2][3]|
Nope is a 2022 American neo-Western science fiction horror film directed, written, and co-produced by Jordan Peele under his Monkeypaw Productions banner. It stars Daniel Kaluuya and Keke Palmer as horse-wrangling siblings attempting to capture evidence of an unidentified flying object. Appearing in supporting roles are Steven Yeun, Michael Wincott, and Brandon Perea.
Peele officially announced his then-untitled third directorial film in November 2020. Palmer and Kaluuya joined in February 2021. Yeun was cast the next month, and Peele revealed the title in July 2021. Filming began in June 2021 in northern Los Angeles County, and wrapped in November.
Nope premiered at the TCL Chinese Theatre in Los Angeles on July 18, 2022, and was theatrically released in the United States on July 22, 2022 by Universal Pictures. It has grossed $170 million worldwide, and received praise for its ambition, performances, themes, cinematography, and direction, though there was some criticism of the screenplay.
Plot[edit]
In 1998, in front of a studio audience for the sitcom Gordy's Home, the titular chimpanzee animal actor attacks several of its human co-stars after being startled by the pop of a balloon. Child actor Ricky ""Jupe"" Park hides under a table and is unharmed, though traumatized by the experience. The chimp finds Jupe and extends his hand for a fist bump, before being shot dead by authorities.
In present-day Agua Dulce, ranch owner Otis Haywood Sr. trains and handles horses for film and television productions. When he is killed by a nickel through the eye that falls inexplicably from the sky,[5] his children Otis ""OJ"" Haywood Jr. and Emerald ""Em"" Haywood inherit the ranch. OJ tries to keep the business afloat and maintain his father's legacy, while Em seeks fame and fortune in Hollywood. The Haywoods claim that the jockey in ""Plate 626"" from Eadweard Muybridge's Animal Locomotion series of photographs was their ancestor.
Six months later, while filming a commercial with prominent cinematographer Antlers Holst, one of the horses, Lucky, reacts aggressively when the crew startles it, and the Haywoods are fired from the project. The ranch's financial woes have forced OJ to sell horses to Jupe, who operates the nearby Jupiter's Claim, a small Western theme park where he exploits his story of the Gordy's Home massacre for profit. Jupe offers to buy the ranch from the Haywoods, an offer which Em encourages a reluctant OJ to accept.
That night, the Haywoods notice their electricity fluctuating and their horses vanishing and violently reacting to an unknown presence. They discover an unidentified flying object (UFO) shaped like a flying saucer that has been taking their horses and then spitting out the inorganic matter, which caused their father's death. Motivated by a desire for wealth and fame, the siblings decide to document evidence of the UFO's existence and recruit Fry's Electronics employee Angel Torres to set up surveillance cameras. Electrical interference from the UFO and an insect on one of the cameras prevent them from getting clear footage, but Angel notices a nearby cloud that never moves. They deduce that it is the UFO's hiding place.
Jupe introduces a live show in Jupiter's Claim and plans to use Lucky as bait to lure out the UFO, which he has been feeding the Haywoods' horses to for months, in front of an audience. The UFO arrives but devours Jupe and the entire audience. OJ deduces that the UFO is not a spaceship, but a predatory, territorial creature, and that it eats anything that looks directly at it. Utilizing similar methods to those used to break and train horses, OJ believes they can influence the creature's behavior to capture footage of it without being killed. Dubbing the creature ""Jean Jacket"" after a horse from their childhoods, the Haywoods decide to hire Holst for assistance. Holst initially refuses, but eventually agrees after hearing about the Jupiter's Claim incident.
To circumvent Jean Jacket's effects on electronics, Holst brings a hand-cranked IMAX film camera to capture footage. With Angel, the group devise a plan to bait out Jean Jacket, with a field of electrically-powered tube man props to help them deduce its location in the sky. However, a TMZ reporter trespasses onto the field and is thrown from his electric motorcycle when it shuts down near Jean Jacket. He is devoured by Jean Jacket while begging OJ to film the event. Though Holst captures footage of Jean Jacket, his obsession with ""the impossible shot"" results in him being devoured alongside his camera, forcing the remaining three to flee. Angel survives an attack from Jean Jacket by being wrapped in a tarp and barbed wire, causing the creature to unfurl from its saucer shape to a jellyfish-like form.[a]
OJ intentionally looks directly at Jean Jacket, allowing Em to use the motorcycle to rush to Jupiter's Claim. There, she untethers the park's large helium balloon mascot of Jupe. Jean Jacket attempts to feed on the balloon while Em uses an attraction's analog camera to photograph Jean Jacket before the balloon explodes, seemingly killing the creature.[b] With the picture as proof of the creature's existence and reporters arriving nearby, Em sees an unharmed OJ and Lucky standing outside of Jupiter's Claim.
Cast[edit]
- Daniel Kaluuya as Otis ""OJ"" Haywood Jr., Otis' son
- Keke Palmer as Emerald ""Em"" Haywood, Otis' daughter
- Brandon Perea as Angel Torres, a tech salesman at Fry's Electronics
- Michael Wincott as Antlers Holst, a renowned cinematographer
- Steven Yeun as Ricky ""Jupe"" Park, a former child actor and owner/creator of the theme park ""Jupiter's Claim""
- Jacob Kim as young Ricky ""Jupe"" Park, who plays Mikey Houston on Gordy’s Home
- Wrenn Schmidt as Amber Park, Jupe's wife
- Keith David as Otis Haywood Sr., the owner of Haywood's Hollywood Horses Ranch
- Devon Graye as Ryder Muybridge, a TMZ reporter who rides an electric bike
- Terry Notary as Gordy, a chimpanzee and star of the sitcom Gordy's Home
- Barbie Ferreira as Nessie, Angel's co-worker at Fry's
- Donna Mills as Bonnie Clayton, a commercial actress
- Osgood Perkins as Fynn Bachman, a commercial director
- Eddie Jemison as Buster, a crew member on the commercial
- Sophia Coto as Mary Jo Elliott, who plays Haley Houston on Gordy's Home
- Jennifer Lafleur as Phyllis Mayberry, who plays Margaret Houston on Gordy's Home
- Andrew Patrick Ralston as Tom Bogan, who plays Brett Houston on Gordy's Home
Themes and interpretations[edit]
""The villain is this otherworldly threat. And it is also something that everyone has in common—everyone's relationship to the spectacle.""
– Writer-director Jordan Peele.
The film has been characterized as containing themes related to spectacle and exploitation.[9] GQ's Gerrick D. Kennedy wrote that Nope ""is a movie about spectacle. More specifically, our addiction to spectacle [...] Nope is about holding a mirror up to all of us and our inability to look away from drama or peril.""[10] Kennedy also states that ""the erasure of Black contributions"" to the history of filmmaking plays a significant role in the film.[10] Writer-director Jordan Peele was partly inspired to write Nope by the COVID-19 lockdowns and the ""endless cycle of grim, inescapable tragedy"" in 2020.[10]
Richard Brody of The New Yorker considered Nope to be a film about exploitation and the cinematic history of exploitation in film; he wrote that he thought the premise of the film was ""acknowledging and extending cinema's legacy while also redressing its omissions and misrepresentations of history.""[11] Brody also noted that the film's action ""pivots on the power and the nature of movie technology"", and felt that the film critiqued computer-generated imagery (CGI) in its TV commercial production scene, writing, ""Peele presents [CGI] as a dubious temptation and a form of dangerous power.""[11] Brody interpreted the choice to have the space creatures target a Black-owned horse farm as ""a sardonic vision of the universality of racism"".[11]
Los Angeles Times writer Jen Yamato noted that Steven Yeun's Ricky ""Jupe"" Park attempts to profit off Jean Jacket with his ""Star Lasso Experience"" show, falsely believing that, because he survived the Gordy incident, he shares a similar kinship with Jean Jacket.[9] Zosha Millman of Polygon argues that Jupe's belief that Gordy and Jean Jacket are well-intentioned, despite their capacity to be unpredictable and dangerous, contrasts with the life experience of Daniel Kaluuya's OJ, ""who grew up around unruly animals that it was his job to tame. As a horse trainer, he knows that animals are worthy of our respect. But it's not part of a grand design, or born from a special relationship with the horse. It's an animal, and it could kill you—but it can be tamed and worked with, if you know what you're doing.""[12] Discussing Jupe's fate, Michael Wincott's character, Antlers Holst, makes mention of Siegfried & Roy[13]—a duo known for training white lions and white tigers—the latter of whom was attacked and severely injured by one of his tigers. GameRevolution's Jason Faulkner further noted ""Peele quoting Neon Genesis Evangelion's Angels as the principal inspiration for the film and the monster within"", and of the true meaning of Jean Jacket's true form's resemblance to the biblical description of angels; he notes the verse from Nahum prefacing the film as indicative of Peele's thoughts on the Bible, and how if one ""think[s] about the way [Jean Jacket] feeds and the concept of people ascending to heaven, [one can] connect the dots [that] Jean Jacket['s species has] been with humanity for a long time, and an attack from one of the creatures could [be] misinterpreted as something from the divine.""[8]
When watching Gordy move about the wrecked set of Gordy's Home, Jupe notices one of his co-star's shoes inexplicably standing upright; as an adult, Jupe has the shoe on display in his room of Gordy's Home mementos.[9] Millman, along with Cooper Hood of Screen Rant, identify the mysteriously standing shoe as a possible example of a ""bad miracle"", a label which OJ uses when he and Keke Palmer's Emerald learn that they are seemingly dealing with a UFO.[12][14] Hood writes that the shoe standing up can be viewed as a ""bad miracle"" due to ""the unexplainable nature of the phenomenon and how it happened during a tragedy. It plays into the movie's theme of turning tragic events into a spectacle, as Ricky is profiting off the collectible despite the trauma of its circumstances.""[14] Yamato, however, questions if Jupe ""merely imagine[d] the shoe standing impossibly in the air—and is he misremembering that just before being shot, Gordy turned to him in friendship?""[9] Yamato asserts that Jupe has disguised his trauma from the incident ""under a veneer of capitalist hustle and humor"", and characterizes Jupe's experience as a child actor as one in which he was ""exploited and then spit out by the fame machine [...] and this sets him up to make the fatal mistake of underestimating a creature that's too dangerous to wrangle.""[9]
Production[edit]
Development[edit]
On October 1, 2019, Universal Pictures announced a five-year exclusive production partnership with Peele's Monkeypaw Productions.[15] Nope, then an untitled project, was announced on November 9, 2020, with Peele set to write, direct and produce.[16] He said, ""I wrote it in a time when we were a little bit worried about the future of cinema. So the first thing I knew is I wanted to create a spectacle. I wanted to create something that the audience would have to come see.""[17] Speaking to GQ, Peele stated, ""So much of what this world was experiencing was this overload of spectacle, and kind of a low point of our addiction to spectacle."" He added that he ""wrote [the film] trapped inside, and so I knew I wanted to make something that was about the sky. I knew the world would want to be outside and at the same time, I knew we had this newfound fear from this trauma, from this time of what it meant to go outside. Can we go outside? So I slipped some of that stuff in.""[10]
Peele publicly cited King Kong and Jurassic Park, movies about humanity's addiction to spectacle, along with Close Encounters of the Third Kind, Signs, and The Wizard of Oz as influences in his writing.[18][19] He later identified the Angels of Neon Genesis Evangelion as the principal inspiration for the film's premise and monster in the film's production notes, impressed by the ""hyper minimalism"" and ""biomechanical design flair"" of Sahaquiel, the 10th Angel.[7] He explained his decision to include a major focus on clouds in the film: ""The beauty of the sky is enthralling—the first movies, in a way. Every now and then you'll see a cloud that sits alone and is too low, and it gives me this vertigo and this sense of Presence with a capital P. I can't describe it, but I knew if I could bottle that and put it into a horror movie, it might change the way people look at the sky.""[18]
Peele originally wrote the character of Angel Torres as a ""happy-go-lucky"" geek-like character until Brandon Perea was cast as the character, who wanted to expand upon and portray him as more grounded.[20] It also took several rewrites for Perea to convince Peele and the Universal executives to change the character's fate in the film's climax from being killed by Jean Jacket to surviving the entire ordeal, saying, ""There's no way the story's over in my head. There's no way. For how heroic everything kind of seemed at the end, I'm like, there's no way they leave the heroes like this. This is just the start of something new.""[21]
In February 2021, it was reported Keke Palmer and Daniel Kaluuya had joined the cast, while Jesse Plemons turned down a role in favor of starring in Killers of the Flower Moon.[22][23][24] Peele wrote the script with Kaluuya in mind for the role of OJ Haywood.[25] In March, Steven Yeun was added to the cast.[26]
Filming[edit]
Principal photography took place from June 2021 to November 2021 in the Agua Dulce desert in northern Los Angeles County.[27] The production received an estimated $8,364,000 worth of tax credits to shoot in the state of California.[28] The film was shot on a budget of $68 million after tax incentives.[27] It was the first to employ trainees (in this case, six) from Universal Filmed Entertainment Group's California Below-the-Line Traineeship for individuals seeking careers behind the camera.[29][30] Nope was shot by cinematographer Hoyte van Hoytema using Kodak film, including 65mm film in IMAX, making it the first horror film in history to be shot in this format.[31][32] On July 22, 2021, Peele revealed the film's title and shared its first promotional release poster, and further castings were confirmed.[33][34] Peele chose Nope as the title because he wanted to acknowledge movie audiences and their expected reactions to the film.[35] He said he had considered calling the film Little Green Men to reference a theme in the film of humanity's ""monetization of spectacle"".[36] Filming also took place at the Burbank, California location of Fry's Electronics, which had closed along with all remaining Fry's locations several weeks before filming. The store was recreated in its operating state for filming.[37] Fry's co-founder Randy Fry and his wife, reporter Vicki Liviakis, were present during filming at the Burbank store; they also had a cameo appearance at the Star Lasso Experience scene, which they filmed in two days.[38]
The 1972 Western film Buck and the Preacher, starring Sidney Poitier, is featured throughout the film; Peele said it was ""the first film that I know of that had Black cowboys represented in it. The myth that cowboys were just white guys running around, it's just not true, but we don't know that because of Hollywood and the romanticized view of a very brutalized era. The film, it shares a spirit.""[18] For her introductory scene, which also opens the film's first trailer, Palmer shot 14 takes of Emerald's monologue about her and OJ's family's history, which initially was not in the script prior to principal photography. Peele described each take as ""...very wildly different, uncuttably so. But just a tour de force, one of these things where you see somebody like, 'I'm going to make this choice this time and go for it.' There's improv in there.""[39]
Creature design[edit]
CalTech professor John O. Dabiri collaborated with Peele and his team on the design of the Jean Jacket creature's UFO form,[40] and in particular its final true ""biblical angel"" form, which was inspired by those of Neon Genesis Evangelion and sea creatures such as jellyfish, octopuses and squid, to imagine a hypothetical undiscovered previously extinct sky predator, realistically imagining ""how could something like hide in the clouds"", with its ability to ""generate electric field"" taken from electric eels and ghost knifefish, allowing for electric propulsion (""Jean Jacket's fast flying without wings/sails"").[6][41][42] Guillaume Rocheron of Moving Picture Company (MPC) also worked with Dabiri and Peele on the visual effects shots featuring Jean Jacket, utilizing both CGI and practical effects, the latter particularly involving the use of a helicopter to swirl the dust and dirt on the ground the way the creature does when consuming its victims in the film.[43] The film held its first test screenings just 12 weeks before its July 22 release, with the special effects still being worked on.[44]
Costumes[edit]
Costume designer Alex Bovaird employed a ""method approach"" to create the characters' wardrobes, using 1990s sitcoms, indie rock bands, and the 1985 film The Goonies as inspiration. To match the film's Californian setting, Bovaird, Peele and their teams decided to create a contrast between ""super neon colors against the desert backdrop,"" and make the film's main characters ""look like action heroes, but cool ones."" For OJ and Emerald's outfits, Bovaird went against the clichés of how horse ranchers would dress and gave them casual clothes, an example being OJ's orange The Scorpion King crew hoodie, along with portraying Emerald as ""tomboy-like"" by having her wear clothing that she and OJ may have ""left at the ranch."" Bovaird saw the character of Angel Torres as ""a bit of a cynical, angry guy"" and some sort of ""Latin-emo,"" but still ""perky"" due to his being a comic relief character, so he dressed him with a dark-colored palette that gets lighter as the film progresses, using band tees, cut-offs and Vans. Ricky ""Jupe"" Park's red cowboy suit that he wears in the Star Lasso Experience scene almost did not make the cut, for Bovaird was unsure if Peele wanted to go ""bold"". For the costume of Gordy, Bovaird and his team dressed human actor Terry Notary in a cardigan sweatshirt in the vein of the one Andy (Kerri Green) wore in The Goonies, with yellow and black stripes. Notary's actions were then transferred to the CGI chimpanzee created in post-production.[45]
Sound design[edit]
Sound designer Johnnie Burn said in an interview with IndieWire, ""Jordan Peele is a director who really knows how to write for sound."" He continued, ""The early conversations were along the lines of 'We want to be super realistic.'...And for that, we were kind of resisting the urge to hear anything from the monster too early on, because we wanted it to be credible that this was a predator—and how could something so large be getting away with this if it was making a big noise? ... One of the main sounds we used was silence."" Burn represented Jean Jacket's presence in the environment by stripping back layers, such as dialogue, wind, and the chirping of crickets. He additionally engineered wind soundscapes containing faint, obscured sounds, such as screams, to suggest Jean Jacket's movement through the air.[46] The soundtrack was mixed in Dolby Atmos.[46]
Music[edit]
The film's score was composed by Michael Abels, who worked with Peele before on Get Out and Us. Abels described his score as having to meet the ""threat level"" described by Peele in the script and the ideas imposed by the film's quote ""What's a bad miracle?""[47] He added, ""The music needs to have both those senses together. Both a little bit of a sense of awe like we would have looking at the Grand Canyon, but then also the urge to run far away from the Grand Canyon because falling in would not be good. That's the dichotomy that's present in the film [...] you hear a sense of a little bit of awe and magic, and then there's sheer terror. But then there's also a sense of a real epic adventure towards the end and giant music that accompanies a giant, historic adventure.""[47] Working with the film's sound designer Johnnie Burn, Abels felt that the use of silence played an important role in scoring the film, saying, ""The tension between the negative space and the music is actually part of the music. Leaving room for the sound design, even when there's a cue playing, was an important part of the way I approached it. A lot of times in the scariest parts, especially in the earlier parts of this film, you're listening to what you hope you're not going to hear or what you thought you might have heard. The stillness allows you to freak out in that way.""[47]
The soundtrack album was released by Back Lot Music on July 22, 2022, the same day as the film.[48] The score album also features a remix of Corey Hart's ""Sunglasses at Night.""[49] Additionally, the film features the songs ""Walk On By"" by Dionne Warwick,[50] ""This Is the Lost Generation"" by the Lost Generation, and ""Exuma, the Obeah Man"" by Exuma.[51]
|Nope|
|Soundtrack album by |
Michael Abels
|Released||July 22, 2022|
|Genre||film soundtrack|
|Length||1:22:55|
|Label||Back Lot Music|
|Producer||Michael Abels|
|No.||Title||Writer(s)||Artist(s)||Length|
|1.||""Haywood Ranch""||Michael Abels||Abels||2:55|
|2.||""The Muybridge Clip""||Abels||Abels||3:34|
|3.||""La Vie C'est Chouette""||Jodie Foster||2:44|
|4.||""Jupiter's Claim""||Abels||Abels||1:43|
|5.||""Brother Sister Walk""||Abels||Abels||1:18|
|6.||""Walk On By""||Dionne Warwick||2:54|
|7.||""Growing Up Haywood""||Abels||Abels||1:29|
|8.||""This Is the Lost Generation""||The Lost Generation||3:34|
|9.||""Not Good""||Abels||Abels||2:00|
|10.||""What's a Bad Miracle""||Abels||Abels||1:32|
|11.||""The Oprah Shot""||Abels||Abels||1:51|
|12.||""Ancient Aliens""||Abels||Abels||2:08|
|13.||""Park Kids Prank Haywood""||Abels||Abels||1:08|
|14.||""It's in the Cloud""||Abels||Abels||2:37|
|15.||""Holy Sh*t It's Real""||Abels||Abels||2:09|
|16.||""Progressive Anxiety""||Abels||Abels||3:02|
|17.||""The Star Lasso Expeeerrriii...""||Abels||Abels||0:35|
|18.||""Arena Attack""||Abels||Abels||1:23|
|19.||""Sunglasses at Night"" (Jean Jacket Mix)||Corey Hart||Hart||4:38|
|20.||""Blood Rain""||Abels||Abels||1:47|
|21.||""The Unaccounted For""||Abels||Abels||2:36|
|22.||""Preparing the Trap""||Abels||Abels||2:41|
|23.||""Purple People Eater""||Sheb Wooley||1:35|
|24.||""Exuma, the Obeah Man""||Exuma||Exuma||6:12|
|25.||""Man Down""||Abels||Abels||6:02|
|26.||""WTF Is That""||Abels||Abels||1:13|
|27.||""The Run (Urban Legends)""||Abels||Abels||1:42|
|28.||""Abduction""||Abels||Abels||1:58|
|29.||""Havoc""||Abels||Abels||0:46|
|30.||""Em & Angel Fly""||Abels||Abels||2:20|
|31.||""A Hero Falls""||Abels||Abels||2:47|
|32.||""Pursuit""||Abels||Abels||1:49|
|33.||""Winkin' Well""||Abels||Abels||3:42|
|34.||""Nope""||Abels||Abels||2:31|
|Total length:||1:22:55|
Marketing[edit]
The release of a teaser poster in July 2021 and first-look images in February 2022 were followed by a trailer on February 13, 2022.[52][53] The trailer, which featured the 1962 Regal Theater recording of Stevie Wonder's ""Fingertips"",[54][55] was praised by critics for simultaneously creating suspense and keeping the storyline under wraps; some reviewers began to speculate the film would be about extraterrestrial life.[54][56][57] Jeremy Mathai of /Film said it ""immediately lit the internet on fire and sent fans scurrying for answers as to whether the main antagonist of the film could really be alien invaders from outer space or if Peele has yet another trick up his sleeve.""[58] Jordan Hoffman from Vanity Fair said he enjoyed the song choice and an included static shot with scrolling text, which he compared to a similar shot in the trailer for Stanley Kubrick's The Shining.[54] The Verge's Charles Pulliam-Moore called it ""one of the rare modern movies with this much hype around it to make it this close to its release date without the public knowing basically anything about it.""[59] The trailer was also broadcast during Super Bowl LVI, and it earned 86 million views across social media websites during the 24 hours after it aired.[60]
A second poster showing a floating horse was released on March 1, 2022.[61][62] Bloody Disgusting's John Squires said it was ""entirely possible that Nope isn't at all the movie it thus far appears to be, with the marketing throwing us off the scent.""[63] Lex Briscuso from /Film said that ""despite the fact that the new visual doesn't give us very many fresh clues, I'm just happy to see new content continue to pop up out of the blue"".[64] On April 16, the NBA Playoffs cross-promoted the film with a clip starring NBA player Stephen Curry. Larry Fitzmaurice of BuzzFeed called it ""terrifyingly funny"".[65] On April 27, additional footage was shown to around 3,000 exhibition insiders at CinemaCon; Peele asked attendees to be discreet and not reveal any detail about the story.[66][67] This footage, depicting several characters saying a variation of the word ""nope"", was later aired as a 30-second television spot during the NBA Finals, confirming the existence of UFOs in the film.[68] Jeremy Methai of /Film called it ""thrilling"" and noted similarities to the filmography of Steven Spielberg while expressing his belief that ""there's something much more going on underneath beyond the extremely easy answer of extraterrestrials terrorizing our helpless protagonists.""[58] Four character posters were released on June 7, 2022, with a featurette released the next day.[69][70] The final trailer was released on June 9, 2022, featuring the Undisputed Truth's 1971 rendition of the Temptations' ""Ball of Confusion"". Reviewers noted its lighter tone and said it did a better job at explaining the premise.[71][72][73] Justin Carter of Gizmodo said it was reasonable to believe the trailer shared too much information, inadvertently robbing audiences from any potential mystery in the story.[74]
IMAX and Dolby posters were released by the end of June 2022.[75][76] On July 1, an interactive website for Jupiter's Claim, the fictional theme park Yeun's character owns in the film, was published; in addition to providing hints of the plot, it held weekly drawings with in-world prizes.[77] Valerie Ettenhofer of /Film compared a poster on the website for a fictional film titled Kid Sheriff to the poster for the 2003 comedy film Holes. She described the website as ""wonderfully interactive, sort of like an old Flash game site, but it also gives some insight into what Nope might be about.""[78] A real-world version of Jupiter's Claim was added permanently as a part of Universal Studios Hollywood's Studio Tour on July 22, making it the first Studio Tour attraction to open the same day the movie it replicates opens in theaters, the other addition to the attraction is the atmosphere such as the lights and tube men flicker off while the sound of the alien be heard and the actors starting to panic then begin to look up.[79][80] On July 24, 2022, Peele released the intro to Gordy's Home, the fictional sitcom depicted in the film, on his Twitter account.[81]
Release[edit]
Nope premiered at the TCL Chinese Theatre in Los Angeles on July 18, 2022.[82] It was released in theaters in the United States on July 22, 2022, by Universal Pictures, a date first revealed in November 2020.[83] The Alamo Drafthouse Cinema hosted an outdoor screening of the film at Sunset Ranch Hollywood on July 25, 2022.[84]
It screened at the Cinesphere in IMAX on September 12, 2022, during the Toronto International Film Festival as a special presentation in the main film slate with a pre-film Q&A session with Jordan Peele and Hoyte van Hoytema, despite being released to the public prior to the festival.[85][86] The film was released to VOD on August 26, 2022.[87]
Reception[edit]
Box office[edit]
As of October 5, 2022[update], Nope has grossed $123.3 million in the United States and Canada, and $47.5 million in other territories, for a worldwide total of $170.8 million.[2][3]
In the United States and Canada, Nope was projected to gross around $50 million from 3,785 theaters in its opening weekend.[27] It made $19.5 million on its opening day, including $6.4 million (down 14% from the $7.4 million earned by Peele's 2019 film Us) from Thursday night previews. It went on to debut to $44.4 million, topping the box office. It also posted the best opening weekend for an original film since Us.[88] While the film came in on the low-end of projections, Deadline Hollywood still deemed it a success, noting its opening was higher than Once Upon a Time in Hollywood ($41 million), another R-rated original film released in July 2019, as well as its Friday-to-Saturday gross not steeply declining, indicating possible legs at the box office. Deadline also reported that despite failing to meet Universal's $50 million opening threshold for a longer 31-day theatrical window before going to premium video on demand,[c] Universal would still honor the longer window for the film.[92] The film dropped 58% in its sophomore weekend to $18.6 million, finishing second behind newcomer DC League of Super-Pets.[93] It finished third and fifth the following two weekends, with $8.5 million and $5.3 million, respectively.[94][95]
Critical response[edit]
On the review aggregator website Rotten Tomatoes, 82% of 421 critics' reviews are positive, with an average rating of 7.4/10. The website's consensus reads, ""Admirable for its originality and ambition even when its reach exceeds its grasp, Nope adds Spielbergian spectacle to Jordan Peele's growing arsenal.""[96] Metacritic, which uses a weighted average, assigned the film a score of 77 out of 100, based on 64 critics, indicating ""generally favorable reviews"".[97] Audiences polled by CinemaScore gave the film an average grade of ""B"" on an A+ to F scale, the same score as Us, while PostTrak reported 79% of filmgoers gave it a positive score.[92]
A. O. Scott of The New York Times praised the film's ""impeccably managed suspense, sharp jokes and a beguiling, unnerving atmosphere of all-around weirdness"", and noted that, ""While this movie can fairly be described as Spielbergian, it turns on an emphatic and explicit debunking of Spielberg's most characteristic visual trope: the awe-struck upward gaze.""[98] Richard Roeper of the Chicago Sun-Times gave the film a score of four out of four stars, calling it ""an exhilarating piece of cinema filled with memorable characters"", and ""a classic example of a bold and original film that pays homage to a seemingly endless stream of great movies and yet is more than the sum of its parts.""[99] Odie Henderson, writing for RogerEbert.com, gave the film three-and-a-half out of four stars, commending the film's sound mixing and calling it ""definitely Peele's creepiest movie,"" and writing that Peele himself ""remains a master of misdirection"".[100]
David Sims of The Atlantic wrote that ""Nope is tinged with the acidic satire that suffused [Peele's] previous two movies, as Peele examines why the easiest way to process horror these days is to turn it into breathtaking entertainment.""[101] Likewise, Michael Shindler of The American Spectator singled out Holst as a ""polite caricature"" of Werner Herzog, highlighting how the latter contrasts favorably with the film's heroes, and noted that Peele ""resists the temptation to warp the plot into a hackneyed morality play,"" instead playing ""the story straight"" in the vein of Paul Verhoeven's Starship Troopers.[102]
Chris Evangelista of /Film wrote that ""Nope may not be Jordan Peele's best movie to date, but it is his most enjoyable. A true summer movie spectacle meant to be writ large across the screen, giving us thrills, chills, laughs, and that most precious of things: movie magic.""[103] David Ehrlich of IndieWire praised the film, saying ""It doesn't hurt that Peele's latest boasts some of the most inspired [movie monster] design since H. R. Giger left his mark on the genre, or that Kaluuya's eyes remain some of Hollywood's most special effects, as Nope gets almost as much mileage from their weariness as Get Out squeezed from their clarity. It's through them that Nope searches for a new way of seeing, returns the Haywoods to their rightful place in film history, and creates the rare Hollywood spectacle that doesn't leave us looking for more.""[104] Screen Rant's Ben Kendrick called it ""a love letter to filmmaking"" and called Brandon Perea's portrayal of Angel Torres a ""stand-out"" among the supporting cast, while praising Kaluuya and Palmer's performances.[105]
Richard Lawson of Vanity Fair was mixed about the film, saying ""As Nope swerves and reels, it often seems distracted by itself, unable to hold its focus on any one thing long enough for deeper meaning, or feeling, to coalesce.""[106] Alonso Duralde of TheWrap wrote ""This ultimately feels like four very promising movies mashed together, with spectacular highlights bumping into each other in a way that's ultimately lacking, even as they all demonstrate the prowess and bravado of the filmmaker.""[107] Peter Bradshaw of The Guardian gave the film two out of five stars, writing, ""There is something clotted and heavy about this film, with sadly not enough of the humour for which Peele justly became celebrated in his double-act days with Keegan-Michael Key.""[108]
Accolades[edit]
|Award||Date of ceremony||Category||Recipient(s)||Result||Ref.|
|Saturn Awards||October 25, 2022||Best Science Fiction Film||Nope||Pending||[109]|
|Best Actor||Daniel Kaluuya||Pending|
|Best Actress||Keke Palmer||Pending|
|Best Director||Jordan Peele||Pending|
|Best Writing||Jordan Peele||Pending|
|Best Music||Michael Abels||Pending|
|Best Editing||Nicholas Monsour||Pending|
Future[edit]
In July 2022, Perea revealed that he had convinced Peele and the Universal executives to change his character's fate in the film's climax from being killed primarily out of interest in a potential sequel, saying: ""There's no way the story's over in my head. There's no way. For how heroic everything kind of seemed at the end, I'm like there's no way they leave the heroes like this. This is just the start of something new.""[21] In an interview with Thrillist, Jean Jacket designer John O. Dabiri suggested that the creature survived its apparent death at the film's conclusion.[6] In an interview with The New York Times, Peele addressed a character that was cut from the film, listed on IMDb as Nobody, saying ""The story of that character has yet to be told, I can tell you that. Which is another frustrating way of saying, I’m glad people are paying attention. I do think they will get more answers on some of these things in the future. We’re not over telling all of these stories"".[110]
Notes[edit]
- ^ On July 25, 2022, /Film confirmed via Jordan Peele's production notes for Nope that the design of Jean Jacket and the principle premise of the film was specifically inspired by and based on the throne angels from the mecha anime series Neon Genesis Evangelion and the resulting franchise, in particular their ""hyper minimalism"" and ""biomechanical design flair"", and Sahaquiel, the 10th Angel.[6][7][8]
- ^ In an interview with Thrillist, Jean Jacket designer John O. Dabiri suggested that the creature may have survived this explosion, saying ""There's a species of jellyfish that's called the immortal jellyfish [...] I'm not a movie maker. But if it was me, I would say there would be some interesting opportunity to ask whether we've seen the last of Jean Jacket.""[6]
- ^ Universal's deals with theater chains allows them to send films that open to under $50 million to premium video on demand after a 17-day theatrical window.[89][90][91]
References[edit]
- ^ ""Nope (15)"". BBFC. August 28, 2022. Retrieved August 28, 2022.
{{cite web}}: CS1 maint: url-status (link)
- ^ a b ""Nope (2022)"". The Numbers. Nash Information Services, LLC. Retrieved October 6, 2022.
- ^ a b ""Nope (2022)"". Box Office Mojo. IMDb. Retrieved October 6, 2022.
- ^ Vadala, Nick (July 22, 2022). ""Philadelphia's weird connection to Jordan Peele's 'Nope'"". The Philadelphia Inquirer. Retrieved August 10, 2022.
- ^ Wax, Alyse (July 30, 2022). ""' Nope': What Happened to Keith David's Otis Sr.?"". Collider. Retrieved August 18, 2022.
- ^ a b c d Stefansky, Emma (July 25, 2022). ""Inside the Eerie UFO Design for Jordan Peele's 'Nope'"". Thrillist. Retrieved July 25, 2022.
- ^ a b Brady, Erin (July 25, 2022). ""This Influential Anime Inspired the Final Design in Nope"". /Film. Retrieved July 25, 2022.
{{cite web}}: CS1 maint: url-status (link)
- ^ a b Faulkner, Jason (July 27, 2022). ""Is the UFO in Nope a Biblically Accurate Angel?"". GameRevolution. Retrieved July 27, 2022.
- ^ a b c d e Yamato, Jen (July 23, 2022). ""'Nope' explained: Gordy the chimpanzee and more clues to unpacking Jordan Peele's epic"". Los Angeles Times. Retrieved July 27, 2022.
- ^ a b c d Kennedy, Gerrick D. (July 20, 2022). ""Jordan Peele and Keke Palmer Look to the Sky"". GQ. Retrieved July 27, 2022.
- ^ a b c Richard Brody (July 25, 2022). ""'Nope' Is One of the Great Movies About Moviemaking"". The New Yorker. Condé Nast. Retrieved September 2, 2022.
- ^ a b Millman, Zosha (July 25, 2022). ""Nope's Gordy segments (and that weird shoe) are packed with meaning"". Polygon. Retrieved July 27, 2022.
- ^ Gonzalez, Hector (July 22, 2022). ""Review: Jordan Peele's 'Nope' is a Mesmerizing and Bewitching Spielbergian Sci-Fi/Horror Arrangement"". TheMovieBuff.net. Retrieved July 27, 2022.
- ^ a b Hood, Cooper (July 22, 2022). ""Why Was The Shoe Standing Up In Nope? What It Really Means"". Screen Rant. Retrieved July 27, 2022.
- ^ D'Alessandro, Anthony (October 1, 2019). ""Jordan Peele & His Monkeypaw Productions Ink Exclusive 5-Year Deal With Universal"". Deadline Hollywood. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
- ^ Galuppo, Mia (November 9, 2020). ""Jordan Peele's Next Horror Film Set for 2022 Release"". The Hollywood Reporter. Archived from the original on November 10, 2020. Retrieved February 16, 2021.
- ^ Zilko, Christian (June 23, 2022). ""Jordan Peele Was Worried About the Future of Cinema, So He Wrote Nope as The Great American UFO Story"". IndieWire. Archived from the original on July 19, 2022. Retrieved July 19, 2022.
- ^ a b c Coyle, Jake (July 18, 2022). ""Q&A: Jordan Peele on the dreams and nightmares of Nope"". Associated Press. Archived from the original on July 19, 2022. Retrieved July 19, 2022.
- ^ Ryan, Mike (July 18, 2022). ""Jordan Peele On The Secrets Of Nope And His Love For Tremors"". Uproxx. Archived from the original on July 19, 2022. Retrieved July 19, 2022.
- ^ ""Brandon Perea Is A Scene Stealer In Nope, So Now We Want Him In Everything"". /Film. July 23, 2022. Retrieved July 23, 2022.
- ^ a b ""'Nope' Star Brandon Perea Reveals The Major Change To His Character's Arc In Jordan Peele's New Film"". SyFy. July 25, 2022. Retrieved July 25, 2022.
- ^ Kroll, Justin (February 16, 2021). ""Jordan Peele Taps Keke Palmer To Star in The Director's New Secret Project"". Deadline Hollywood. Archived from the original on February 16, 2021. Retrieved February 16, 2021.
- ^ Kit, Borys (February 16, 2021). ""Keke Palmer, Daniel Kaluuya to Star in Jordan Peele's New Movie"". The Hollywood Reporter. Archived from the original on February 16, 2021. Retrieved February 16, 2021.
- ^ Kit, Borys (February 17, 2021). ""Jesse Plemons to Star in Martin Scorsese's Killers of the Flower Moon"". The Hollywood Reporter. Archived from the original on February 18, 2021. Retrieved April 1, 2021.
- ^ Travis, Ben (March 14, 2022). ""Nope: Jordan Peele Promises An 'Otherworldly Confrontation' For Daniel Kaluuya – Exclusive Image"". Empire. Archived from the original on March 17, 2022. Retrieved March 21, 2022.
- ^ Kroll, Justin (April 1, 2021). ""Following Oscar Nomination For Minari, Steven Yeun Eyes Jordan Peele's New Film At Universal"". Deadline Hollywood. Archived from the original on April 1, 2021. Retrieved April 1, 2021.
- ^ a b c D'Alessandro, Anthony (July 19, 2022). ""Jordan Peele's Nope Hopes To Rope $50M At Weekend Box Office"". Deadline Hollywood. Archived from the original on July 19, 2022. Retrieved July 19, 2022.
- ^ Patten, Dominic (August 17, 2020). ""California Tax Incentives: Chris Evans' Gray Man, Jessica Chastain's Losing Clementine & Untitled Jordan Peele Pic Clinch Big Bucks"". Deadline Hollywood. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
- ^ Grobar, Matt (February 2, 2022). ""Jordan Peele's Nope Serves As Platform For Launch Of Universal Filmed Entertainment Group's California Below-The-Line Traineeship"". Deadline Hollywood. Archived from the original on February 15, 2022. Retrieved February 13, 2022.
- ^ Sun, Rebecca (June 22, 2022). ""Universal Releases Nope Featurette Showcasing Diverse Below-the-Line Crew"". The Hollywood Reporter. Archived from the original on June 22, 2022. Retrieved June 23, 2022.
- ^ Song, Katle (November 30, 2021). ""Cinematographer Hoyte van Hoytema Confirmed as Director of Photography for Jordan Peele's Nope – Film News in Brief"". Variety. Archived from the original on November 30, 2021. Retrieved November 30, 2021.
- ^ Tangcay, Jazz (July 26, 2022). ""Why Jordan Peele's 'Nope' Became the First Horror Movie Shot With Imax Cameras"". Variety. Retrieved July 26, 2022.
- ^ Evangelista, Chris (July 22, 2021). ""Jordan Peele's Next Movie is Called Nope – Check Out the First Poster Now"". /Film. Archived from the original on July 22, 2021. Retrieved July 22, 2021.
- ^ Rubin, Rebecca (July 22, 2021). ""Jordan Peele's Next Movie Will Be Called Nope"". Variety. Archived from the original on July 22, 2021. Retrieved July 22, 2021.
- ^ Tolsky, Andy (April 22, 2022). ""Jordan Peele Explains Meaning Behind Nope Title"". ScreenRant. Archived from the original on July 16, 2022. Retrieved July 16, 2022.
- ^ Mathai, Jeremy (July 15, 2022). ""Jordan Peele Had An Intriguing Original Title For Nope"". /Film. Archived from the original on July 15, 2022. Retrieved July 19, 2022.
- ^ ""How Jordan Peele brought Fry's Electronics back to life in 'Nope'"". July 27, 2022.
- ^ Bartlett, Amanda (July 29, 2022). ""San Francisco news anchor, Fry's Electronics co-founder have surprise cameos in 'Nope'"". SFGATE. Retrieved August 29, 2022.
- ^ Erbland, Kate (July 19, 2022). ""Nope Star Keke Palmer Shot Over a Dozen 'Wildly Different' Takes of Her Introductory Monologue"". IndieWire. Archived from the original on July 19, 2022. Retrieved July 19, 2022.
- ^ Weekes, Princess (July 25, 2022). ""What Does the Gordy Subplot Mean in Jordan Peel[e]'s 'Nope'?"". The Mary Sue. Retrieved July 25, 2022.
Gordy may have been a friendly chimp[anzee], but he was still an animal, who shouldn’t have been on a soundstage with chaotic elements that could scare him. He got startled and reacted as his instincts told him to act. The murder of Jupe's family confirms to OJ that this flying saucer isn't a ship, but a predatory cryptid, one-winged-angel-style creature that acts when its dominance is tested when people look straight at it.
{{cite web}}: CS1 maint: url-status (link)
- ^ Egan, Toussaint (July 25, 2022). ""The inspirations behind the monster in Nope"". Polygon. p. ]ublicly. Retrieved July 25, 2022.
Over the course of the film, the UAP [""unidentified aerial phenomenon""] assumes several terrifying forms, which make it roughly something of a cross between a shark, a flying saucer, a manta ray, a flat humongous man-eating eyeball, and a ""biblically accurate"" angel, [with] Jean Jacket's appearance and design most closely resembl[ing] those of Sahaquiel, the 10th Angel, which appears in the 12th episode of the original 1995 anime, ""A Miracle's Worth,"" and the second film in the Rebuild of Evangelion tetralogy, Evangelion[:] 2.0 You Can (Not) Advance, [with] Jordan Peele [ mak[ing] his fandom of the series clear on Twitter in the days leading up to the film's release.
- ^ Adlakha, Siddhant (July 20, 2022). ""IGN: Nope Review"". Polygon. Retrieved July 20, 2022.
(the design of this apparent saucer is, initially, shocking in its simplicity, but by the end, you may as well call it ""Biblically accurate"").
- ^ James, Daron (August 15, 2022). """"Nope"" VFX Supervisor Guillaume Rocheron on Creating That Spectacular Alien Creature"". Motion Picture Association. Retrieved August 22, 2022.
- ^ ""Chaos Isn't Reigning At Summer Box Office With $3.35B+, Despite Exhibition's Woes: Season Wrap-Up"". Deadline Hollywood. September 2, 2022. Retrieved September 3, 2022.
- ^ Wheeler, André-Naquian (August 4, 2022). ""The Outfits in Nope Tell Their Own Story"". Vogue. Retrieved August 7, 2022.
- ^ a b Hemphill, Jim; O'Falt, Chris (July 22, 2022). ""Jordan Peele's Toolkit Interview: Making 'Nope' a Masterpiece of Sound"". IndieWire. Retrieved October 3, 2022.
- ^ a b c Greene, Steve (July 23, 2022). ""'Nope' Composer Michael Abels Knows Exactly What He Wants Chaos to Sound Like"". IndieWire. Retrieved August 7, 2022.
- ^ ""Nope Soundtrack Album Details"". Film Music Reporter. July 21, 2022. Retrieved July 23, 2022.
- ^ Breihan, Tom (July 22, 2022). ""Hear The Creepy, Screwed Remix Of Corey Hart's 'Sunglasses At Night' From Jordan Peele's Nope"". Stereogum. Retrieved July 23, 2022.
- ^ Aswad, Jem (July 25, 2022). ""What's With All the Early '90s Alt-Rock T-Shirts in 'Nope'?"". Variety. Retrieved July 27, 2022.
- ^ ""'Nope' Soundtrack Album Details"". Film Music Reporter. July 21, 2022. Retrieved July 27, 2022.
- ^ Couch, Aaron (February 13, 2022). ""Jordan Peele's Nope Scares Up a Trailer Ahead of Super Bowl"". The Hollywood Reporter. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
Until now, Nope has been kept under tight wraps, with a poster debuting in July as well as a short trailer announcement video hitting on Feb. 8.
- ^ Grobar, Matt (February 8, 2022). ""Nope First Look: Jordan Peele's Latest Film For Universal Starring Daniel Kaluuya, Keke Palmer, Steven Yeun & More"". Deadline Hollywood. Archived from the original on February 14, 2022. Retrieved February 14, 2022.
- ^ a b c Hoffman, Jordan (February 13, 2022). ""Jordan Peele's Nope Trailer Is Terrifying Without Giving Anything Away"". Vanity Fair. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
- ^ Grobar, Matt (February 13, 2022). ""Nope: Watch Super Bowl Ad"". Deadline Hollywood. Archived from the original on February 14, 2022. Retrieved February 14, 2022.
- ^ Goslin, Austen (February 13, 2022). ""Jordan Peele's Nope Super Bowl trailer is full of strange, sci-fi mystery"". Polygon. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
- ^ Chapman, Wilson (February 13, 2022). ""Nope Trailer: Daniel Kaluuya and Keke Palmer Have a Close Encounter in Jordan Peele's New Thriller"". Variety. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
- ^ a b Mathai, Jeremy (June 3, 2022). ""Nope Teaser: New TV Spot Features A UFO But No Aliens, Nope"". /Film. Archived from the original on June 3, 2022. Retrieved June 3, 2022.
- ^ Pulliam-Moore, Charles (February 13, 2022). ""Nope's first trailer is a hard yes"". The Verge. Archived from the original on February 13, 2022. Retrieved February 13, 2022.
- ^ D'Alessandro, Anthony (February 16, 2022). ""Doctor Strange Sequel, Jurassic World Dominion, LOTR Trailers Saw Biggest Super Bowl Spikes On Social Media"". Deadline Hollywood. Archived from the original on February 17, 2022. Retrieved February 17, 2022.
- ^ Leston, Ryan (March 1, 2022). ""The Latest Poster for Jordan Peele's Nope Is Appropriately Confusing"". IGN. Archived from the original on March 1, 2022. Retrieved March 1, 2022.
- ^ Devore, Britta (March 1, 2022). ""Nope: New Poster For Jordan Peele's Next Film Keeps Our Eyes on the Sky With ...A Floating Horse?"". Collider. Archived from the original on March 1, 2022. Retrieved March 1, 2022.
- ^ Squires, John (March 1, 2022). ""Jordan Peele's Nope Poster Sends a Horse into the Night Skies"". Bloody Disgusting. Archived from the original on March 1, 2022. Retrieved March 1, 2022.
- ^ Briscuso, Lex (March 1, 2022). ""Hold Your Horses, There's A New Nope Poster"". /Film. Archived from the original on March 1, 2022. Retrieved March 1, 2022.
- ^ Fitzmaurice, Larry (April 16, 2022). ""Steph Curry Stars In A New Ad For Jordan Peele's Nope, And It's Terrifyingly Funny"". BuzzFeed. Archived from the original on April 16, 2022. Retrieved April 17, 2022.
- ^ Gardner, Chris; Giardina, Carolyn; McClintock, Pamela (April 27, 2022). ""Jordan Peele's Nope, Minions Sequel and Jurassic World Finale Among Universal CinemaCon Highlights"". The Hollywood Reporter. Archived from the original on June 7, 2022. Retrieved June 7, 2022.
- ^ Fabian Brathwaite, Lester; Huff, Lauren (April 27, 2022). ""Jordan Peele reveals the meaning of Nope and why he wants you to yell it out"". Entertainment Weekly. Archived from the original on June 7, 2022. Retrieved June 7, 2022.
- ^ Villei, Matt (June 3, 2022). ""Nope Teaser Gives a Resounding 'Hell No' to the Monster Haunting Jordan Peel's Latest Horror Film"". Collider. Archived from the original on June 4, 2022. Retrieved May 9, 2022.
- ^ Squires, John (June 7, 2022). ""Jordan Peele's Nope – Character Posters Watch the Skies Ahead of New Trailer This Week"". Bloody Disgusting. Archived from the original on June 9, 2022. Retrieved June 9, 2022.
- ^ Squires, John (June 8, 2022). ""Nope Featurette Hypes Jordan Peele's New Horror Movie as a 'Cinematic Event'"". Bloody Disgusting. Archived from the original on June 9, 2022. Retrieved June 9, 2022.
- ^ Leston, Ryan (June 9, 2022). ""Nope: New Trailer Finally Tells Us What the Jordan Peele Movie Is About"". IGN. Archived from the original on June 9, 2022. Retrieved June 9, 2022.
- ^ Pulliam-Moore, Charles (June 9, 2022). ""Nope's final trailer reveals true horror Jordan Peele's been hiding this whole time"". Polygon. Archived from the original on June 9, 2022. Retrieved June 9, 2022.
- ^ Parker, Ryan (June 9, 2022). ""Final Nope Trailer Reveals Far More Plot Details for Jordan Peele's Upcoming Sci-Fi Horror Film"". The Hollywood Reporter. Archived from the original on June 9, 2022. Retrieved June 9, 2022.
- ^ Carter, Justin (June 11, 2022). ""Did Nope's New Trailer Actually Spoil Anything?"". Gizmodo. Archived from the original on June 18, 2022. Retrieved June 18, 2022.
- ^ Squires, John (June 17, 2022). ""IMAX Poster for Jordan Peele's Nope Has Got Its Eye on You..."" Bloody Disgusting. Archived from the original on July 2, 2022. Retrieved July 2, 2022.
- ^ Squires, John (June 28, 2022). ""Dolby Cinema Poster for Jordan Peele's Nope Stitches Together Steven Yeun's Outfit"". Bloody Disgusting. Archived from the original on July 2, 2022. Retrieved July 2, 2022.
- ^ Perry, Spencer (July 1, 2022). ""Jordan Peele's Nope Debuts Viral Website With Secret Contest"". ComicBook.com. Archived from the original on July 2, 2022. Retrieved July 2, 2022.
- ^ Ettenhofer, Valerie (July 1, 2022). ""Nope Has A Viral Site Full Of Clues, Hints, And A Reference To The Movie Holes"". /Film. Archived from the original on July 2, 2022. Retrieved July 2, 2022.
- ^ Michaelsen, Shannen (June 28, 2022). ""Nope-Inspired Town Set Under Construction at Universal Studios Hollywood"". WDWNT News Today. Archived from the original on July 2, 2022. Retrieved July 2, 2022.
- ^ Tapp, Tom (July 7, 2022). ""Creepy Amusement Park Set From Jordan Peele's Nope Opening On Universal Studios Tour Day And Date With Film"". Deadline Hollywood. Archived from the original on July 7, 2022. Retrieved July 7, 2022.
- ^ Peele, Jordan [@JordanPeele] (July 24, 2022). ""Gordy's Home!"" (Tweet) – via Twitter.
- ^ Chuba, Kirsten (July 18, 2022). ""Yep! On the carpet tonight for #NopeMovie"". Archived from the original on July 19, 2022. Retrieved July 18, 2022 – via Twitter.
- ^ D'Alessandro, Anthony (November 9, 2020). ""Universal Sets Release Date For Jordan Peele's Next Movie"". Deadline Hollywood. Archived from the original on November 15, 2020. Retrieved February 16, 2021.
- ^ Lambert, Harper (June 20, 2022). ""Alamo Drafthouse to Host Outdoor Screening of Nope at Sunset Ranch Hollywood (Exclusive)"". TheWrap. Archived from the original on June 20, 2022. Retrieved June 20, 2022.
- ^ ""TIFF: Jordan Peele's 'Nope' Set for Imax Screening at Film Fest"". The Hollywood Reporter. August 30, 2022.
- ^ ""Jordan Peele's NOPE Will Screen at TIFF 2022"".
- ^ Squires, John (August 22, 2022). ""Jordan Peele's 'Nope' Comes Home to On Demand This Friday!"". Bloody Disgusting!. Retrieved August 23, 2022.
- ^ ""'Nope' Debuts To $44 Million, The Best For An Original Film Since Jordan Peele's 'Us' In 2019"". Box Office Mojo. Retrieved July 26, 2022.
- ^ Lang, Brent; Rubin, Rebecca (July 28, 2020). ""Universal, AMC Theatres Forge Historic Deal Allowing Theatrical Releases to Debut on Premium VOD Early"". Variety. Archived from the original on July 29, 2020. Retrieved September 15, 2022.
- ^ D'Alessandro, Anthony (November 16, 2020). ""Universal & Cinemark Ink Shortened Theatrical Window-PVOD Share Pact In Wake Of AMC Deal"". Deadline. Retrieved September 15, 2022.
- ^ Gruenwedel, Eric (May 13, 2021). ""Regal Owner, Universal Pictures Ink Shortened Theatrical Window Pact"". Media Play News. Retrieved September 15, 2022.
- ^ a b D'Alessandro, Anthony (July 24, 2022). ""Jordan Peele's Nope Opens To $44M, As Original IP Breaks Through At Box Office – Sunday Update"". Deadline Hollywood. Retrieved July 24, 2022.
- ^ D'Alessandro, Anthony (July 30, 2022). ""'DC League Of Super-Pets' Fetches $23M Opening For Warner Bros"". Deadline Hollywood. Retrieved July 31, 2022.
- ^ D'Alessandro, Anthony (August 7, 2022). ""'Bullet Train' Pulls Into Weekend Box Office Station With $30.1M Opening – Sunday Update"". Deadline Hollywood. Retrieved August 7, 2022.
- ^ D'Alessandro, Anthony (August 13, 2022). ""'Bullet Train' Second Go-Round Now At $13.3M As Summer 2022 Clocks Lowest Weekend To Date With $64M – Saturday PM Box Office Update"". Deadline Hollywood. Retrieved August 14, 2022.
- ^ ""Nope"". Rotten Tomatoes. Fandango Media. Retrieved October 4, 2022.
- ^ ""Nope"". Metacritic. Red Ventures. Retrieved September 20, 2022.
- ^ Scott, A. O. (July 20, 2022). ""'Nope' Review: Hell Yes"". The New York Times. Retrieved August 9, 2022.
- ^ Roeper, Richard (July 20, 2022). ""'Nope': Every moment matters in Jordan Peele's exhilarating new horror fable"". Chicago Sun-Times. Retrieved August 9, 2022.
- ^ Henderson, Odie (July 20, 2022). ""Nope movie review & film summary (2022)"". RogerEbert.com. Retrieved August 9, 2022.
- ^ Sims, David (July 20, 2022). ""Jordan Peele's Nope Is Spectacular, Indulgent, and Brutal"". The Atlantic. Retrieved August 9, 2022.
- ^ Shindler, Michael (August 17, 2022). ""Jordan Peele's Nope: The Reactionary Blockbuster of the Summer"". The American Spectator. Retrieved August 24, 2022.
- ^ Evangelista, Chris (July 20, 2022). ""Nope Review: Jordan Peele Stages An Absolute Spectacle With His Scary, Funny Sci-Fi Blockbuster"". /Film. Archived from the original on July 20, 2022. Retrieved July 20, 2022.
- ^ Ehrlich, David (July 20, 2022). ""Nope Review: Jordan Peele's Wildly Entertaining Blockbuster Is the Best Kind of Hollywood Spectacle"". IndieWire. Archived from the original on July 21, 2022. Retrieved July 20, 2022.
- ^ Kendrick, Ben (July 20, 2022). ""Nope Review: A Haunting & Humorous Twist On Hollywood Sci-Fi"". ScreenRant. Archived from the original on July 21, 2022. Retrieved July 20, 2022.
- ^ Lawson, Richard (July 20, 2022). ""In Jordan Peele's Nope, Spectacle Triumphs Over Substance"". Vanity Fair. Archived from the original on July 20, 2022. Retrieved July 20, 2022.
- ^ Duralde, Alonso (July 20, 2022). ""Nope Film Review: The Parts of Jordan Peele's Latest Are Greater than the Whole"". TheWrap. Archived from the original on July 20, 2022. Retrieved July 20, 2022.
- ^ Bradshaw, Peter (July 20, 2022). ""Nope review – Jordan Peele's followup to Get Out and Us is a bit meh"". The Guardian. Retrieved August 9, 2022.
- ^ Tinoco, Armando (June 29, 2022). ""Saturn Awards Nominations: 'The Batman', 'Nightmare Alley', 'Spider-Man', 'Better Call Saul' Top List"". Deadline. Retrieved August 12, 2022.
- ^ Murphy, Mekado (August 29, 2022). ""Jordan Peele Says There May Be More 'Nope' Stories to Come"". The New York Times. ISSN 0362-4331. Retrieved September 1, 2022.
External links[edit]
- 2022 films
- 2020s American films
- 2020s English-language films
- 2020s monster movies
- 2020s Western (genre) horror films
- 2022 science fiction horror films
- American epic films
- American monster movies
- American science fiction horror films
- American Western (genre) horror films
- American Western (genre) science fiction films
- Films about angels
- Films about cryptids
- Films about extraterrestrial life
- Films about filmmaking
- Films about Hollywood, Los Angeles
- Films about horses
- Films directed by Jordan Peele
- Films produced by Jordan Peele
- Films scored by Michael Abels
- Films set in 1998
- Films set in 2021
- Films set in Los Angeles County, California
- Films set in farms
- Films shot in Los Angeles
- Films with screenplays by Jordan Peele
- IMAX films
- Neo-Western films
- Universal Pictures films",8
84,"Thinking of my earliest trips to restaurants, in the 1980s, I faintly remember waiters taking my grandfather’s credit card and using a manual flatbed imprinter to make an impression of its raised numbers. My nephew, born early in the coronavirus pandemic, may come of age with similar memories of physical menus as a childhood relic. Recalling them dimly when a dining scene in an old movie jogs his memory, he might ask, “Why did they stop using those?”
If that happens, I’ll recount the pestilence that raged as he entered the world; the shutdown of bars and restaurants; the push to reopen in the summer of 2020; the persistent if mistaken belief that high-touch surfaces, like restaurant menus, would be a meaningful vector of infection; the counsel of the CDC that July. “Avoid using or sharing items that are reusable, such as menus,” the federal agency advised. “Use disposable or digital menus.”
The QR-code menu—which you access by scanning a black-and-white square with your smartphone—has taken off ever since. It may dominate going forward. But I hope not, because I detest those digital menus. Never mind dying peacefully in my sleep; I want to go out while sitting in a restaurant on my 100th birthday, an aperitif in my left hand and a paper menu in my right. And as eager as I’ll be for heaven if I’m lucky enough to stand on its threshold, I want one last downward glance at a paramedic prying the menu from my fist. In that better future, where old-school menus endure, I’ll go to my urn happy that coming generations will still begin meals meeting one another’s eyes across a table instead of staring at a screen.
QR-code menus are not really an advance. Even when everything goes just right––when everyone’s phone battery is charged, when the Wi-Fi is strong enough to connect, when the link works––they force a distraction that lingers through dessert and digestifs. “You may just be checking to see what you want your next drink to be,” Jaya Saxena observed in Eater late last year, “but from there it’s easy to start checking texts and emails.” And wasn’t it already too easy?
Research conducted before the pandemic suggests that, even if everyone resists the temptation to check an incoming text message, merely having a phone out on the table makes a meal less fun for all involved. In the 2018 study “Smartphone Use Undermines Enjoyment of Face-to-Face Social Interactions,” the social-psychology researcher Ryan Dwyer and his colleagues randomly assigned some people to keep their phone out when dining with friends and others to put it away. “We found that groups assigned to use their phones enjoyed the experience less than groups that did not use their phones,” Dwyer told me by email, “primarily due to the fact that participants with phones were more distracted.” The research team directed members of the phone group to use their device just once at the beginning of the meal—a setup “very similar to the nudge provided by QR codes,” Dwyer notes—and these subjects were free to use their phone as much or as little as they wanted thereafter. The control group kept their phone in a box.
QR-code menus reduce privacy, too, because diners who use them aren’t just communicating with the restaurant in question. Many of the codes “are actually generated by a different company that collects, uses, and then often shares your personal information, ” the ACLU has warned. “In fact, companies that provide QR codes to restaurants like to brag about all the personal information you are sharing along with that food order: your location, your demographics such as gender and age group, and other information about you and your behavior.”
For restaurants, QR-code menus offer potential benefits beyond putting germ-averse patrons at greater ease. In the near future, rather than offer the same static selections to every customer, restaurants might deploy dynamic menus from which dishes disappear as the kitchen runs out. The prices of appetizers and entrees could also rise or fall to better match supply with demand. One day, I may have to explain to my nephew that before, say, 2030, people with peanut allergies would nevertheless see pad thai on their menu at the Cheesecake Factory; that Manhattan restaurants didn’t always use surge pricing to manage their weekday lunch rush; that certain chains didn’t previously charge iPhone and Android owners different prices.
But I hope that, rather than remembering the pandemic as a tipping point in the digitization of restaurants and bars, we instead look back on its aftermath as the moment when an ever more atomized society better understood the high costs of social isolation, felt new urgency to counteract it, and settled on analog mealtime norms as an especially vital place to focus.
What if three times every day society was oriented toward replenishing what is growing more absent from the rest of our waking hours: undistracted human interactions unmediated by technology?
I say all this as something of a convert myself.
As an introvert and a frequent solo traveler, I have eaten many happy meals alone with a smartphone in hand. Still, when pandemic restrictions deprived almost everyone of the ability to dine in public with one another, the loss helped me see the unique value of mealtime togetherness.
During my domestic and overseas travels in the past couple of years, my heart has swelled with joy just watching patrons of far-flung establishments gather as in pre-pandemic times. Actually interacting with strangers has seemed more appealing than ever before. And more often than not, technology has played a part in my worst experiences—whether because making it a bigger part of hospitality so frequently comes at the expense of connections among people or because it malfunctions so much more often than ink on paper, annoying customers and staff alike. At one small-town bistro in Provence, I had no phone service and couldn’t access a digital menu even after pacing around a square in search of a signal. Eventually a waiter took pity on me and gave me his phone––so much for a touchless solution––but as I was figuring out what to get, text messages kept popping up on his screen, flustering both of us enough that eventually I just told him to bring me whatever he recommended.
I am not a Luddite. I know restaurants and bars change. And although the transition from smoke-filled to smoke-free was years shorter than I would have anticipated, I do not expect phones to go the way of the cigarette or for humans to socialize at every meal. But I cheer the fact that more bars, many of them speakeasy-style, are compelling patrons to check the phone at the door, and I hope different sorts of establishments attempt their own experiments.
The next few years may determine to what degree the restaurant of the future embraces the digital era or deliberately operates as a respite from it, conserving the traditional focus on sociability, connection, and camaraderie. And despite QR codes’ growing ubiquity, their triumph is not foreordained. When you’re deciding where to spend your dining budget, consider rewarding restaurants that conserve the benefits of the analog world and punishing those that introduce technology in ways that detract from communal experience.",1
85,"Peters and Portman Introduce Bipartisan Legislation to Help Secure Open Source Software
Bill Would Help Prevent Exploitation of Vulnerabilities Like One Found In Log4j That Could Compromise Critical Systems
WASHINGTON, DC – U.S. Senators Gary Peters (D-MI) and Rob Portman (R-OH), Chairman and Ranking Member of the Homeland Security and Governmental Affairs Committee, introduced bipartisan legislation to help protect federal and critical infrastructure systems by strengthening the security of open source software. The legislation comes after a hearing convened by Peters and Portman on the Log4j incident earlier this year, and would direct the Cybersecurity and Infrastructure Security Agency (CISA) to help ensure that open source software is used safely and securely by the federal government, critical infrastructure, and others. A vulnerability discovered in Log4j – which is widely used open source code – affected millions of computers worldwide, including critical infrastructure and federal systems. This led top cybersecurity experts to call it one of the most severe and widespread cybersecurity vulnerabilities ever seen.
“Open source software is the bedrock of the digital world and the Log4j vulnerability demonstrated just how much we rely on it. This incident presented a serious threat to federal systems and critical infrastructure companies – including banks, hospitals, and utilities – that Americans rely on each and every day for essential services,” said Senator Peters. “This commonsense, bipartisan legislation will help secure open source software and further fortify our cybersecurity defenses against cybercriminals and foreign adversaries who launch incessant attacks on networks across the nation.”
“As we saw with the log4shell vulnerability, the computers, phones, and websites we all use every day contain open source software that is vulnerable to cyberattack,” said Senator Portman. “The bipartisan Securing Open Source Software Act will ensure that the U.S. government anticipates and mitigates security vulnerabilities in open source software to protect Americans’ most sensitive data.”
“This important legislation will, for the first time ever, codify open source software as public infrastructure,” said Trey Herr, Director, Cyber Statecraft Initiative, Scowcroft Center for Strategy and Security, the Atlantic Council. “If signed into law, it would serve as a historic step for wider federal support for the health and security of open source software. I am encouraged by the leadership of Senators Peters and Portman on this issue.”
The overwhelming majority of computers in the world rely on open source code – freely available code that anyone can contribute to, develop, and use to create websites, applications, and more. It is maintained by a community of individuals and organizations. The federal government, one of the largest users of open source software in the world, must be able to manage its own risk and also help support the security of open source software in the private sector and the rest of the public sector.
The Securing Open Source Software Act would direct CISA to develop a risk framework to evaluate how open source code is used by the federal government. CISA would also evaluate how the same framework could be voluntarily used by critical infrastructure owners and operators. This will identify ways to mitigate risks in systems that use open source software. The legislation also requires CISA to hire professionals with experience developing open source software to ensure that government and the community work hand-in-hand and are prepared to address incidents like the Log4j vulnerability. Additionally, the legislation requires the Office of Management and Budget (OMB) to issue guidance to federal agencies on the secure usage of open source software and establishes a software security subcommittee on the CISA Cybersecurity Advisory Committee.
Peters and Portman have led several efforts to strengthen our nation’s cybersecurity. Their historic, bipartisan provision to require critical infrastructure owners and operators to report to CISA if they experience a substantial cyber-attack or if they make a ransomware payment was signed into law. The senators’ legislation to bolster cybersecurity for state and local governments has also been signed into law. Peters and Portman’s bills to protect federal networks, and ensure government can safely adopt cloud technology have also unanimously passed the Senate.
###",2
86,"In the boardroom bunkers and in the cubicle-filled trenches, the early skirmishes of the next war are being fought. For the moment, most of the action is guerrilla warfare – brief raids in which the companies under attack are often unaware that they’ve been hit. Ultimately, though, the war will be global, and for businesses, the stakes will be success and perhaps even survival.
According to a yearlong study conducted by a team from McKinsey & Co. – a study involving 77 companies and almost 6,000 managers and executives – the most important corporate resource over the next 20 years will be talent: smart, sophisticated businesspeople who are technologically literate, globally astute, and operationally agile. And even as the demand for talent goes up, the supply of it will be going down.
The McKinsey team is blunt about what will result from these trends: Its report is titled “The War for Talent.” The search for the best and the brightest will become a constant, costly battle, a fight with no final victory. Not only will companies have to devise more imaginative hiring practices; they will also have to work harder to keep their best people.
In the new economy, competition is global, capital is abundant, ideas are developed quickly and cheaply, and people are willing to change jobs often. In that kind of environment, says Ed Michaels, a McKinsey director who helped manage the study, “all that matters is talent. Talent wins.”
To see what the coming conflict looks like from the war room, Fast Company interviewed Michaels in his Atlanta office.
Your study says that talent is the most important factor in a company’s success. Why?
Over the past decade, talent has become more important than capital, strategy, or R&D. Think about the sources of competitive advantage that companies have. Capital is accessible today for good ideas and good projects. Strategies are transparent: Even if you’ve got a smart strategy, others can simply copy it. And the half-life of technology is growing shorter all the time.
For many companies, that means that people are the prime source of competitive advantage. Talented people, in the right kind of culture, have better ideas, execute those ideas better – and even develop other people better. As Larry Bossidy, the CEO of AlliedSignal told us, “At the end of the day, we bet on people, not strategies.”
Why is that a good idea? The world is changing so fast, it’s difficult to see around corners. Things don’t always work. And when they don’t work, what you can fall back on is talent.
Why do you call the current environment a “war for talent”?
A lot of it has to do with demographics. In 15 years, there will be 15% fewer Americans in the 35- to 45-year-old range than there are now. At the same time, the U.S. economy is likely to grow at a rate of 3% to 4% per year. So over that period, the demand for bright, talented 35- to 45-year-olds will increase by, say, 25%, and the supply will be going down by 15%. That sets the stage for a talent war .
You developed case studies for 20 companies. What trends did you spot that signal the beginning of a war for talent?
In order to keep the pipeline full of talented people, almost all of the companies we studied are starting to take nontraditional approaches to recruiting. They’re also finding it harder to keep the great people they already have.
We saw this trend most clearly in high-tech businesses. But we saw it even in more traditional industries, such as banking. Historically, companies in these industries have had people lining up at their doors. Now they’re having to compete aggressively for talent. One bank that we studied has started offering signing bonuses of up to $100,000 to recruit people to key sales-management jobs – a practice that was unheard-of a few years ago.
Do companies know they’re in a talent war?
Lots of companies don’t. When you talk to most of them about retention issues, for example, they have a knee-jerk reaction: We don’t have a retention problem! In a sense, they’re right. At the senior level, the attrition rates at these companies are often quite low – 4% or 5% a year.
But there is also a silent battlefield in the war for talent. That battlefield involves people who have been at the same firm for 3 to 10 years, people between the ages of 25 and 35. Most companies are losing more people in these ranks than they realize. And those people are often some of their best employees.
Most of these larger companies are highly decentralized: They may have 20, 50, or even 100 divisions. For that reason, they don’t know how many people they are losing. They don’t know if they’re losing good people, great people, or average people. They don’t know where these people are going. Most important, they don’t know why these people are leaving.
Why is the silent battlefield important?
Only 60% of the corporate officers at the companies we studied said that they were able to pursue most of their growth opportunities. They have good ideas, they have money – they just don’t have enough talented people to pursue those ideas. They are “talent-constrained.” The leaders at Johnson & Johnson, a world-class operation, told us that they never used to go outside the company to recruit their top-level managers. Now they have to go outside as often as 25% of the time – because they are talent-constrained.
This is something of a zero-sum game. When companies go outside for talent, they’re just taking people from other companies.
What does it take to raid another company’s talent successfully?
We asked top people what they were looking for in deciding where to work. The answer: a great company and a great job. When they talk about a great company, they mean one that’s well managed, that has terrific values, and that has a great culture.
They also know what they want in a job. One store manager at Home Depot told us, “This is my $50 million business.” He was talking about his store. “I can double it, or I can run it into the ground. Where else could I get that kind of independence and that much of a challenge at age 33?” People want “elbow room” – a job that’s pretty big, where they have responsibility for a number of functional levers, such as marketing and sales. They also want “headroom” – a job where they can make decisions on their own, without having to go through a bureaucracy. The best companies are beginning to appreciate these aspirations. Dick Vague, the chairman and CEO of First USA, part of Banc One, told us, “I aspire to create an enterprise where at least 80% of everybody’s job consists of doing things that they love.”
What role do startups and small companies play in the talent war?
The people at AlliedSignal were clear on this point. They told us, “We are competing with startups, not General Electric. There is a whole raft of talent that we simply do not get access to.”
What do talented people get at startups? For one thing, the opportunity to make a lot of money. For another, they have a chance to be very connected to the top of the company. They can play a key role and make a difference to the whole institution – all at an earlier age. A highly talented 30-year-old is confident that even if he or she goes bust on a small-company venture, there will be another job out there.
What weapons can larger, more established companies use against startups and small companies?
The best large companies have learned how to mimic small companies. They create smaller, more autonomous units. They offer greater wealth-creation opportunities for their best people, regardless of age or seniority. And they compensate these people on the basis of performance. The best companies also find ways to keep 30-year-olds connected to the larger organization and to give them exposure to people at the top – which makes them feel that they are part of a smaller organization.
Big businesses can capitalize on their size. For instance, they’ve got more money, so they can afford to give a 35-year-old more responsibility and a bigger budget than small companies can. Big companies also have many more jobs to fill. More jobs means more bosses. So big companies can offer more mentoring opportunities.
What kinds of recruitment campaigns attract the most talented people?
There are four kinds of messages that the best people respond to. The first one is “Go with a Winner.” It’s for people who want a high-performing company, a company where they’re going to get lots of advancement opportunities. A second message is “Big Risk, Big Reward.” The people who respond to it want an environment where they’re challenged either to do exceptionally well or to leave – where there’s considerable risk but good compensation, and where they can advance their career rapidly. A third message is “Save the World.” It attracts people who want a company with an inspiring mission and an exciting challenge – a pharmaceuticals or a high-tech company, for instance. The last group is drawn to a “Lifestyles” message. These people seek companies that offer them more flexibility and better lifestyle benefits – such as a good location.
How prepared are most companies to wage this war for talent?
Of the executives we surveyed, 75% said that their companies either don’t have enough talent sometimes or are chronically short of talent. We then asked them, “Does your company make improving its talent pool one of its top three priorities?” In many companies, only 10% or 20% of corporate officers said yes.
In our view, these companies – the ones that are complacent about talent – are the ones that have the most to lose and that are most at risk. They are the least innovative, the least aggressive. They are reluctant to promote people early on, to recruit in different ways, to take action to move their average players to the sidelines and their best players to the forefront.
And the companies that are most likely to succeed are the ones that spend the most energy on attracting, developing, and retaining talent – the companies that are the most restless, the most dissatisfied, the most nervous, the most paranoid. So, as the war for talent intensifies, the gap between the winners and the losers will probably get wider and wider.
Charles Fishman cnfish@mindspring.com is an extremely talented Fast Company contributing editor. Ed Michaels ed_michaels@mckinsey.com , a director of McKinsey & Co. in Atlanta, has been with the firm for 28 years.",4
87,"AI that detects chicken distress calls could improve farm conditions
A deep learning model can pick out chicken distress calls from recordings taken at commercial farms, and could be used to improve chicken welfare
An AI has been trained to identify and count chickens’ distress calls. Farmers could use the tool to improve conditions for chickens raised on crowded commercial farms.
As of 2020, there were more than 33 billion chickens around the world, according to the UN’s Food and Agriculture Organization. Many of these animals live in poor conditions, packed together with little ability to move around or do things chickens like to do. “Despite the basic concerns about not being hungry or not being thirsty, there are still serious welfare concerns about how they’re produced,” says Alan McElligott at City University of Hong Kong.
The frequency and volume of a chicken’s distress call – a sharp, short “cheep” – can predict the animal’s health and growth rate, according to McElligott’s previous research. But he says these calls can be hard to identify when there are thousands of chickens cheeping together – in some barns, it can be 25,000 or more. “They’re called barns, but they’re more like airline hangers,” says McElligott.
Advertisement
Listening to recordings made at large broiler chicken farms in south-west China, McElligott and his colleagues labelled chicken distress calls, distinguishing them from farm sounds and other chicken sounds like chirps of pleasure and trills that signal fear. With this labelled data, they trained several algorithms to identify distress calls from the background noise and measure their frequency and volume. When tested on other labelled recordings from the same farm, the best algorithm accurately detected distress calls around 85 per cent of the time.
The tool hasn’t yet been used on a working chicken farm, and McElligott says there is more work to do to understand the link between distress calls and a chicken’s well-being. But he says the next steps are somewhat obvious: “We should give them conditions in which, well, maybe they would produce less distress calls.” That could mean giving chickens more space or other enrichment like bales of straw to scratch at and climb on.
Elodie Floriane Mandel-Briefer at the University of Copenhagen in Denmark has developed similar tools to assess the emotions of pigs based on sounds and facial expressions. She says the study in chickens adds to growing evidence that animal emotions can be measured and monitored using machine learning. “Since animal emotions are an important part of their welfare, their assessment is crucial,” she says.
Journal reference: Journal of the Royal Society Interface, DOI: 10.1098/rsif.2021.0921
More on these topics:",3
88,"E-waste: Five billion phones to be thrown away in 2022
- Published
This year, 5.3 billion mobile phones will be thrown away the international waste electrical and electronic equipment (WEEE) forum says.
Its estimate, based on global trade data, highlights the growing environmental problem of ""e-waste"".
Many people keep old phones, rather than recycling them, research suggests.
Precious minerals not extracted from waste electronics, such as the copper in wire or the cobalt in rechargeable batteries, have to be mined.
""People tend not to realise that all these seemingly insignificant items have a lot of value and together at a global level represent massive volumes,"" WEEE director general Pascal Leroy said.
There are an estimated 16 billion mobile phones worldwide - and in Europe, almost a third are no longer in use.
The WEEE says its research shows the ""mountain"" of electrical and electronic waste - from washing machines and toasters to tablet computers and global positioning system (GPS) devices - will grow to 74 million tonnes a year by 2030.
Earlier this year, the Royal Society of Chemistry launched a campaign promoting the mining of e-waste to produce new products, highlighting global conflict, including the war in Ukraine, threatens precious-metal supply chains.
Magdalena Charytanowicz, of the WEEE, said: ""These devices offer many important resources that can be used in the production of new electronic devices or other equipment, such as wind turbines, electric car batteries or solar panels - all crucial for the green, digital transition to low-carbon societies.""
Just over 17% of the world's e-waste is properly recycled - but the United Nations International Telecommunication Union has set a target to raise that to 30% by next year.
It highlights it is one of the ""fastest growing and most complex waste streams that affects both human health and the environment, as it can contain harmful substances"".
In the UK, more than 20 million unused but working electrical items, worth as much as possibly £5.63bn, are currently hoarded in UK homes, surveys by the organisation Material Focus suggest.
It also calculated that the average UK household could sell unwanted tech and raise about £200.
Mr Leroy said much more could be done.
""Providing collection boxes in supermarkets, pick-up of small broken appliances upon delivery of new ones and offering PO [post-office] boxes to return small e-waste are just some of the initiatives introduced to encourage the return of these items,"" he said.",2
89,"Amazon plans to let people turn their dead loved ones’ voices into digital assistants, with the company promising the ability to “make the memories last”.
The company is developing technology that will allow its Alexa digital assistant to mimic the voice of anyone it hears from less than a minute of provided audio, Rohit Prasad, its senior vice-president and head scientist, said on Wednesday. He added that during the coronavirus paramedic “so many of us have lost someone we love”.
While no timescale was given for the launch of the feature, the underlying technology has existed for several years. The company gave a demonstration where the reanimated voice of an older woman was used to read her grandson a bedtime story, after he asked Alexa: “Can grandma finish reading me the Wizard of Oz?”
Prasad said: “The way we made it happen is by framing the problem as a voice conversion task and not a speech generation path.”
Beyond the initial demonstration, details were scarce. The technology was announced at the company’s re:Mars conference, focusing on its “ambient computing” achievements in the realms of machine learning, automation, robots and space.
Amazon’s aim for its voice assistant is “generalisable intelligence”, Prasad added, contrasting it with “all-knowing, all-capable, uber-artificial general intelligence” of science fiction.
But other technology companies have been cautious about making digital voice-doubles so easy to produce: hours before Amazon announced its plans, Microsoft published new artificial intelligence (AI) ethics rules that would put strict limits on who could create synthetic voices and how they could be used. “It is … easy to imagine how it could be used to inappropriately impersonate speakers and deceive listeners,” said Natasha Crampton, the company’s chief responsible AI officer.
Microsoft will require companies to apply for permission to make artificial voices, and last month began watermarking them with an inaudible signal that would allow it to identify misuse.
The concept of using AI to revive the dead – or appear to – is not a new one, even outside the realm of science fiction. In 2020, Joshua Barbeau trained a version of the GPT-3 chatbot on conversation logs with his late fiancee Jessica, who had died eight years earlier. And in 2018, Eugenia Kuyda built a chatbot out of the old text messages of her friend Roman Mazurenko. “I didn’t expect it to be as impactful. Usually I find showing emotions and thinking about grief really hard so I was mostly trying to avoid it. Talking to Roman’s avatar was facing those demons,” she said at the time.
This article was amended on 14 July 2022. Roman Mazurenko was Eugenia Kuyda’s friend, not her partner as an earlier version said.",6
90,"Style
Secondhand shopping is at an all time high, thanks to the recession
15%
How much recommerce grew in 2021.
GlobalData/OfferUp
Thrifting is more popular than ever, thanks to the recession. According to a 2022 OfferUp report, published in partnership with data analytics firm GlobalData, recommerce grew nearly 15 percent in 2021. The increase marks the highest growth rate in history for the secondhand industry, which has already been spiking in popularity thanks to sustainable shopping habits and TikTok.
This year, 272 million Americans — about the same number of Americans that own a smartphone — buy and/or sell pre-owned goods, reports OfferUp. It seems finding the best deals has become as addictive as social media: OfferUp reports Americans spend an average of 27 minutes per day on digital secondhand marketplaces — just shy of the average 30 minutes they spend on Instagram, Facebook, and other social media platforms. The recession has undoubtedly influenced this spike.
Hunting for deals — As prices soar, so do consumers’ desires to save money; accelerating the adoption of recommerce. More than 50 percent of Americans reported lower prices were their top motivator for shopping secondhand, according to OfferUp’s report, while 21 percent said a reduced carbon footprint motivated them to thrift more. People aren’t just shopping for pre-owned clothing either — their secondhand purchases span from electronics to furniture and more.
Given the historic growth of the recommerce market (and the rising impacts of inflation), secondhand spending is expected to hit $178 billion in 2022 and $289 billion by 2027, reports OfferUp. Its survey reveals that over half of Americans who already use reselling platforms (58 percent) plan to increase their buying and/or selling of pre-owned products in the next year, especially given the current state of the U.S. economy. A whopping 93 percent reported to OfferUp that inflation impacts their decision to shop secondhand.
The recession has also impacted Americans’ selling habits, with many people turning to pre-owned marketplaces to create new income streams. OfferUp reports that two in five Americans sell secondhand items as a source of primary or secondary income, with higher numbers associated with Gen Z and Millennial consumers.
It’s only up from here — Not to miss out on profits, plenty of brands have already joined the resale market. Urban Outfitters, PacSun, and Fwrd were some of the first labels to launch pre-owned product lines, while others like Tommy Hilfiger and Michael Kors have followed. Even fast-fashion brands — which contrast thrifters’ sustainable ideals — have tapped into resale.
If OfferUp’s predictions are right, thrifting could be the future of fashion. And it’s something the industry desperately needs. Cheap clothing’s overproduction is strangling our planet, and its ceaseless cycle of replacement and replenishment isn’t sustainable. While thrifting has been around for decades, here’s hoping this spike in popularity can change our consumer habits for the better.",4
91,"In the Mind of a Whale
How can we make sense of the biggest brains on the planet?
Article body copy
On September 12, 2015, Tom Mustill and a friend were on a guided kayak tour in Monterey Bay, off the coast of California. There was so much food in the rich waters of the bay that whales were engaged in an unprecedented feeding frenzy. As kayaks and boats shared the water with the whales, a humpback breached and came down on the two friends. They survived, but the episode sent Mustill—a biologist by training—on a journey: what if we could communicate with whales and other animals? The following excerpt is from Mustill’s first book, How to Speak Whale: A Voyage into the Future of Animal Communication.
Brains are complex and delicate organs—and whale brains especially so. Few whales are in good condition when they beach. Fewer still are reached in time to extract the brain before it decomposes. It’s the first organ to go because the sensitive tissues are pressure-cooked deep inside the dying animal’s skull by body heat the whale cannot release. And rare are the people with the skills to extract and preserve them. Cetaceans were long thought to have simple, undeveloped brains, because whenever scientists would get inside a dead dolphin’s head, it had often already turned to sloppy mush. A good-quality whale brain is gold dust.
To obtain a whale brain for examination, the stars have to align: the whale must be freshly dead, and a good anatomist must cut its head off and refrigerate it quickly. Given that most whales are bigger than most industrial freezers, which aren’t easy to drive to the sea and pop a whale head into, this doesn’t happen often. I had long given up hope of ever seeing such a thing. But in 2018, my friend Joy Reidenberg at the Icahn School of Medicine at Mount Sinai in New York, called me to say she had two on the way. She had been given the chance to dissect a stillborn baby sperm whale, as well as the head of a young minke whale—which is a kind of baleen whale, like a thinner, smaller humpback.
Both had been recovered some time before, and stored deep in the Smithsonian Institution’s freezers. A refrigerated truck was to drive them the few hundred kilometers to New York, where Reidenberg and her neuroanatomist colleague, Patrick Hof, would be waiting at their lab in Manhattan. And if I wanted, I could come and peer into a cetacean mind.
In Reidenberg’s and Hof’s domain, rooms for human dissection and the teaching of anatomy do double duty for dolphins, and in the depths of the hospital, powerful machines for investigating human brains are used for exploring cetacean anatomy, too. With Reidenberg’s help, Hof has built up one of the world’s most extensive marine mammal brain collections, with about 700 specimens of 60 kinds of whales and dolphins. Out the window, the orange light of the morning reflected off the high-rises around us, and joggers chugged through Central Park beneath. The smell from the cadavers was sweet and almost pleasant, until you remembered what it was.
Reidenberg and Hof use the hospital’s advanced scanning machines—MRI and CT scanners—to take 3D pictures inside the heads of dead whales without having to cut them open and risk ruining the brains. Some scientists have even managed to scan the brains of living dolphins, showing them “lighting up” as their brains worked (likely wondering what the hell was going on).
There are many scans of dolphin brains, but very few of whale brains. This makes sense given that the biggest hospital scanners can scarcely accommodate a very large human, let alone an animal the size of a small hospital ward. Fitting an adult humpback into an MRI would be like trying to get a melon through the hole of a bagel. The two baby whales Reidenberg had procured were just small enough to fit.
Access to Mount Sinai’s scanners during the daytime was for patients only, and dead whales had to come in before the scanning department opened to the public. Seeing the decapitated, frozen head of a minke whale being carted past might be disconcerting for patients, so the whales were wrapped in plastic sheets on their gurneys. As we wheeled through various brightly lit corridors, down service elevators, past waiting rooms and sleepy patients walking alongside their IVs, none suspected our strange cargo—at most, a passing speed-walking doctor turned to look for the source of the strangely marine smell. In the MRI suite, there was a door with many warning signs and a window latticed with fine wire mesh. In the next room was the MRI, which resembles a giant white doughnut with a platform that a patient (or baby whale head) could be placed on and gently moved through the machine. Reidenberg told the technician, Jonny, that he was the first person ever to scan a sperm whale in an MRI.
The atmosphere was quiet as the team grunted and lifted the tiny sperm whale onto the platform. Its dark skin was damp and cool. Hof moved laser crosses along it to align the sensors as the machine whirred to life. Inch by inch, the baby whale progressed through the scanner, its head itself a huge and powerful scanning machine capable of discerning the densities of different tissues. For two hours the whale heads were scanned and turned. As they heated up, their juices dripped onto the platform and the floor. Then it was time for humans to reclaim their hospital, and the juices were mopped, the data saved, and the whales wheeled away.
Upstairs, Reidenberg and Hof had no time to lose. The brains were defrosting fast and had to be removed from the animals’ skulls in the next few hours. In a room the size of two badminton courts, one end full of two dozen human cadavers, I watched as Hof, a competitive épée fencer, and a mean hand with a scalpel, too, cut through the muscles and tissue around the back of the minke’s skull. As the sun rose higher, the New York skyline brightened behind him as he used a saw to slice into the bone surrounding the brain, releasing a smell like burned hair. He cut a neat panel in the skull, like a burglar piercing the glass of a museum window, and teased the porridge-colored organ through the gap and into a jar of preservative fluid.
Another whale brain to join its fellows in a vault, with all their pickled, unknowable thoughts.
The brain would be preserved and later dissected. Sometimes it would be cut into millimeter-thin slices and stained to discover and trace the routes of individual nerves. Or it would be kept intact to compare its shapes, grooves, and bulges with those of other specimens, including humans. Measuring and mapping, trying to see which structures resembled those in our brains and which parts were totally different, Hof and Reidenberg made a good double act. It would take days to thoroughly examine the hugely complex scans. But Hof brought up some of the images on his screen. Using a computer program, he could whiz through the whale’s brain. It was mesmerizing to watch: the circle on his monitor like a porthole on a ship, the whorls and knots of brain being revealed as he sped through them, adjusting the controls to highlight blood vessels, denser tissue, connections, and convolutions. Although I was fascinated, it was difficult to identify the differences between the brain areas and tissue types that Hof paused to point out. The Latin names for brain regions, one after the other, passed through my skull like CT scan rays, leaving little trace in my mind.
I’d learned by this point that comparing brains is a difficult business in general. In explaining how clever humans are, we often point out the extraordinarily large size of our thinking organs. Their bulk is the bane of childbirth and consumes 90 percent of the glucose in our blood. But size itself is not a clear guide for comparing animal intelligences, as some bigger animals with larger brains seem to lack the cognitive abilities of smaller ones. Size, as the saying goes, isn’t everything. Relative brain-to-body size, how wrinkled and complex brains are, the thickness of their layers, the structures within them, and the types of neurons these are made of are all helpful—though our human brains are, naturally, the yardstick that other brains are measured against. And yet it is impossible to look at a whale brain and not be surprised by its size. When Hof first saw one, despite knowing they were big, its mass still shocked him. The human brain is about 1,350 grams, three times larger than our big-brained relative, the chimpanzee. A sperm whale or killer whale brain can be 10 kilograms. These are the biggest brains on Earth and possibly the biggest brains ever, anywhere. It’s perhaps not a fair comparison: in relation to the size of our bodies, our brains are bigger than those of whales. Ours are similar in proportion to our body mass, as are the brains of some rodents; mice and men both invest a lot of themselves in their thinking organs. But we both lag far behind small birds and ants, which have much bigger brains compared to their body size than any big animals.
The outer layer of a mammal’s brain is called the cerebral cortex. In cross section, it looks a little like a wraparound bicycle helmet sitting on top of the other parts of the brain. This is the most recently evolved part of our brains, and it was by using their own cerebral cortexes that brain scientists have learned that this area is responsible for rational, conscious thought.
It handles tasks like perceiving senses, thinking, movement, figuring out how you relate to the space around you, and language. You are using yours now to read and think about this sentence. Many biologists define “intelligence” as something along the lines of the mental and behavioral flexibility of an organism to solve problems and come up with novel solutions. In humans, the cerebral cortex, acting with other bits of the brain (the basal ganglia, basal forebrain, and dorsal thalamus), appears to be the seat of this form of “intelligence.” The more cortex you have and the more wrinkled it is, the more surface area available for making connections—and voila! More thinking.
Humans have a really large neocortex surface area, but it’s still just over half that of a common dolphin, and miles behind the sperm whale. Even if you divide the cortex area by the total weight of the brain to remove the cetacean size advantage, humans still lag behind dolphins and killer whales. But there are other measurements in the cortex that seem to be associated with intelligence, and here, dolphins and whales lag behind humans.
The more neurons are packed in, how closely and effectively they are wired, and how fast they transmit impulses are also extremely important in brain function. Just as the composition and layout of the chipset in your tiny, cheap cellphone allows it to pack more computing power than a five-tonne room-sized 1970s supercomputer. Both cetaceans and elephants, the biggest mammals on sea and land, seem to have large distances between their neurons and slower conduction speeds. In raw numbers of neurons, humans here, too, have the edge, with a human cortex containing an estimated 15 billion neurons. Given the larger size of cetacean brains, you’d think they’d have more, but in fact their cerebral cortex is thinner, and the neurons are fatter, taking up more room.
Nevertheless, some cetaceans such as the false killer whale are close behind human levels with 10.5 billion cerebral neurons, about the same as an elephant. Chimps have 6.2 billion and gorillas 4.3 billion. Further complicating comparisons, whales have huge numbers of other kinds of cells, called glia, packing their cortexes. Until recently, we believed these glial cells to be an unthinking filler, but we’ve now discovered that they actually seem important for cognition, too. I don’t know about you, but all this cortex measurement and comparison makes my own feeble organ hurt.
Hof moved through the scans, the one hundredth marine mammal they had analyzed this way, zooming and measuring, exploring through symmetries and fractal patterns as if flying through a monochrome kaleidoscope. Questions spilled out of me: Could the brains tell us if whales or dolphins might have the capacity for consciousness? Could they allow these creatures to conceive of others? Hof would not be drawn into discussing these matters. He felt that we simply did not know enough. Many others, however, have been more opinionated.
One study concluded that humans have five times the information-processing capacity of cetaceans, whom they placed beneath chimps, monkeys, and some birds. But in the same study, horses—with smaller brains than chimps—were found to have five times the number of cortical neurons. Does this mean horses are smarter than chimps? A major confounding factor in these types of comparisons appears to be that every factor is itself quite confounding. Estimating numbers of neurons is a very rough science, so the raw number comparisons are crude. There are lots of different kinds of neurons, and they are arranged in different configurations and proportions in different species. We know all these variations mean something, that they will determine what brains are capable of, but we don’t know yet quite what, or how that might change from one moment to the next in different parts of the brain. There are a lot of assumptions at play, and it can be misleading to extrapolate from one brain to another.
This also applies to comparing cognitive ability. Trying to infer from brains and their structures which animals are “better” at cognition and ranking animal brains in order of “intelligence” is as treacherous as it is tempting. Stan Kuczaj, who spent his lifetime studying the cognition and behavior of different animals, put it bluntly: “We suck at being able to validly measure intelligence in humans. We’re even worse when we try to compare species.” Intelligence is a slippery concept and perhaps unmeasurable. As mentioned earlier, many biologists conceive of it as an animal’s ability to solve problems. But because different animals live in different environments with different problems, you can’t really translate scores of how well their brains perform. A brain attribute is not simply “good” or “bad” for thinking, but rather varies depending on the situation and the thinking that brain needs to undertake. Intelligence is a moving target.
What confounds this dilemma further is that individual animals within a species have varying cognitive abilities. To quote the Yosemite National Park ranger who, when asked why it was proving so hard to make a garbage can that bears couldn’t break into, said, “There is considerable overlap between the intelligence of the smartest bears and the dumbest tourists.”
We know little of the problems that the brains of cetaceans must contend with. They have evolved to process the challenges of very different lives—some solitary, some members of groups of hundreds, from giant hunters of the deep to tiny river dolphins. Faced with all these caveats and uncertainties, I began to see the wisdom in Hof’s hesitancy to infer too much from this terra incognita.
I had an odd thought as I had watched Hof and Reidenberg scan the whale brains. Perhaps from lack of sleep, I found myself imagining scanning their heads, stripping past the skin and muscles and bones, and looking at them as sense organs, eyeballs, ear canals, smell and taste receptors, floating in space and connecting back, via nerves, to the strangely bland organ, the hyperconnected fatty bolus where their thoughts and personalities and memories lived. If I looked at these floating brains, peering within, would I know them better? The human brain is often referred to as “the most complicated thing in the universe”—by scientists, spiritual leaders, and journalists alike. It is indeed a very complicated thing. But as whale brains also seemed, well, pretty damn fancy, I asked Hof a simple question: do whales have thoughts? He paused for a long moment. “Whether they have thoughts that are constructed in the same manner? Very possible. There’s no reason that the same networks of nerves that served consciousness and memories in us cannot also exist the same way in whales.”
Encouraged, I leapt ahead. Might whales think like us, then? With consciousness? Was there any indication they might have the brains to speak to each other like we do? “You know, there’s potentially a lot of wishful thinking in all of this,” he replied.
Wishful or not, Hof had fueled a fair bit of this thinking himself. In 2006, he and his colleague Estel Van der Gucht published a paper in Anatomical Record that set the brains of neuroscientists fizzing across the world. When examining preserved slices of human brain, he encountered an unusual-looking neuron. Instead of being shaped like a branch, cone, or star, it was long and thin and very big. He realized he was seeing a von Economo neuron (VEN), a type of brain cell that was first described more than a century before but had been long ignored. These special nerves had been thought uniquely human. Then, in San Diego, California, his colleagues found them in the great apes (our close relatives the chimpanzee, gorilla, orangutan, and bonobo) but not in more distant relatives like lemurs. Hof and others began to hunt for the cells, looking through the brains of more than 100 species, but only a few seemed to have them: humans, the great apes, elephants, and cetaceans. We are distant relatives to elephants and whales, with our common ancestor evolving around the time the dinosaurs went extinct, over 60 million years ago.
Apes, elephants, and whales have much in common: we live a long time, are highly social, very intelligent, extremely communicative, and possess large brains. The VENs appeared to have evolved independently in these three groups, after our ancestors had split into different species, via convergent evolution, a process in which the pressures of natural selection lead to the same features developing in unrelated creatures.
The VENs seemed to be found only in certain areas of the human brain: the frontal insula and cingulate cortex. These regions are used when we feel pain, or notice that we’ve made a mistake, and when we feel things relating to others. A VEN lights up when we feel love, when parents hear their babies cry, when someone attempts to ascertain another’s intentions. In humans, the parts of the brain that relate to high-level cognitive functions, such as attention, intuition, and social awareness, are larger than in most other mammals. This is true for whales, too. And VENs are present in both species. As Hof put it, “The cells that make human integrative experience quite unique are also present in large whales.”
While we still don’t know precisely what these cells do, there are some intriguing interpretations. In both whales and humans, the neocortex appears to have special “integrative centers” that process and integrate the information coming in from the sensory and motor areas. They chew over the signals they’ve received and communicate with one another in networks.
This ability to integrate information from different brain regions is vital: it adds complexity to our perceptions and allows us to carry out advanced cognitive processes such as artistic creation, decision-making, and language learning. Hof and his coresearcher John Allman speculated that the VEN cells evolved in response to a need. To send signals quickly between their integrative centers, brains need highways, and VENs, according to Hof, “are like the ‘express trains’ of the nervous system.” Considering the functions of the regions that house these neurons, and the social nature of the species that have them, these high-speed brain links could be used when thinking about others—for empathy and social intelligence. Some are skeptical of this suggestion, believing that large, complex whale brains with VENs are simply necessary for coordinating enormous bodies in a 3D sea environment. Others say these impressive brains are required to process all the sophisticated information involved in echolocation: their brains have evolved these structures because of how they sense, not because they are actually mulling over the results.
In 2014, Hof and colleagues found VENs in more species than was previously thought, discovering the neurons or similar cells in the brains of cows, sheep, deer, horses, and pigs. This information was interpreted by some as evidence that VENs didn’t herald any particularly impressive cognitive functions. To me, this story mirrors so many in biology. We discover something we think is unique to us. Then we find it in other animals and begin to question whether it is special anymore. But if you’ve spent time with cows and pigs, it’s not surprising to think they might have neural hardware for thinking about others and social intelligence. This is all very recent information, and scientists like Hof are explorers of a new frontier. It may turn out that a VEN in one beast might do something very different from a VEN in another, just as a piece of electrical cable can send both a signal to turn on a light bulb and a passionate email to your lover’s computer. For Hof, VENs are only a small piece in the sophisticated wiring diagram of the brains of some species, a diagram that is still very much in the process of being filled in.
Discoveries, comparisons, hypotheses, and extrapolations connect and interweave, and will hopefully, eventually, build a clearer picture. We are at a frustrating moment; all this discovery without knowing what it means. In the words of one neuroscientist: “we don’t even understand the brain of a worm.” Perhaps that is simply a hazard that comes with poking around in the most complicated, gloopy mush in the universe.
Reidenberg made a helpful comparison: if you were an alien explorer in the seas of Earth and you came across a bottlenose dolphin and a similar-sized shark, you might be puzzled. The animals live in the same sea, may hunt the same fish, and need to survive the same conditions, but the bottlenose has a far bigger brain. A brain that seems in many ways very similar in composition and structure to that of the highest mental achievers on the planet, and in other ways very different. Why would there be such a discrepancy between the dolphin and shark?
In 2007, Lori Marino, along with Reidenberg, Hof, and many other biologists, published a paper called “Cetaceans Have Complex Brains for Complex Cognition.” They reached their conclusion by assessing all the current research, but also by looking back in time at the fossil record. Neurons and cortexes don’t preserve well for millions of years, but skulls do, and skulls reveal brain size. Cetacean brains suddenly got bigger about 10 million years after they had already moved into the sea. This surprised some scientists who had previously linked cetacean brain evolution to adaptations to water and cold. Logically, any brain adaptation related to aquatic life would have happened sooner. The coauthors theorized that the leap in brain size took place as cetacean behavior became more complex, more social.
For many whales and dolphins, the challenges of life are impossible outside of a social group. To successfully live in a social group, to compete and cooperate, requires thinking you don’t need to do as a loner. Hof elaborated: “They communicate through huge song repertoires, recognize their own songs, and make up new ones. They also form coalitions to plan hunting strategies and teach these to younger individuals, and have evolved social networks similar to those of apes and humans.” A social animal needs more brain hardware on which to run the software of culture.
I tried a final time: what could he tell about whales definitively from investigating their brains? Hof said it was absolutely clear that whales were extremely intelligent, with impressive neural systems, components of which we had previously thought existed only in humans. Like so many scientists I’ve met who studied whales, Hof would mention an exciting whale attribute—something relatable to human existence—and then immediately caution: we should not anthropomorphize. But he insisted that we could not consider whales completely inferior to ourselves: “There are many people who think they are sort of stupid, big fish, right?” he said. “And no, they are not, definitely not.” Trying to figure out whether whales might think like us was both more complicated and more compelling than I had anticipated, every answered question a doorway into a further mystery.
It was late in the day now. The whales had been scanned and their brains saved—and everyone was exhausted. Hof had medical students to teach and Reidenberg whale faces to deflesh. I left the hospital and walked out into the streets of Manhattan, picking up on the moods of the people I passed from their gaits, overhearing their conversations, judging how to weave among them, avoiding the eyes of the strange man on the subway, laughing at a joke with a friend at dinner, feeling warm when I hugged them goodbye. I thought about the neurons firing within me, the brain centers integrating these sensations and thoughts. In the waters off New York City, just miles from where I stood, humpback, fin, and sei whales can be found. Did their brains also flash with complex thoughts, articulated by strange aquatic voices, heard by sensitive hidden ears?
Adapted from HOW TO SPEAK WHALE by Tom Mustill, published on September 6, 2022. Copyright © 2022 by Tom Mustill. Used by arrangement with Grand Central Publishing. All rights reserved.",2
92,"Unless you have completely abandoned social networks, you have surely seen Dall-E working in the last few weeks. It is one of the latest and well-known AI algorithms, developed by the OpenAI research lab and capable of producing images based on our text input. Although the original version is limited access, its “mini” version is available online, and it is precisely the one used to create the most unlikely images – “Spiderman in the style of Picasso”, “a cowboy in space” – that are invading your feeds.
Is artificial intelligence the architect of the future?
A new generation of increasingly sophisticated AI – such as Midjourney – unveils new possibilities for design: we have tried to figure out whether and how they will replace humans and their work.
However, other algorithms – with a similar mechanism – are being employed in a more reasoned and less chaotic way, aiming at uses that in some cases go beyond mere experimentation or fun. It is the case, for instance, of Midjourney, which – among its other uses – is rapidly intriguing and fascinating the world of architecture. This field is paying more and more attention to the possible uses of deep learning, as shown also by the latest Architectural Design monograph entitled Machine Hallucination entirely dedicated to this topic.
“Midjourney is perfect for creating architectural evocations and fascinations,” Mario Coppola – architect and founder of Ecosistema Studio and also author of the Villa Postumana project, exhibited at the last Venice Biennale – tells Domus. “Until recently, the most challenging part of the creative and design process was precisely the concept. Instead, through a set of keywords – for example, “villa filled with vegetation” – Midjourney succeeds in presenting a range of alternatives, and then you can develop your own project from one or more of these options. Generally, to get good results you have to go through a number of iterations, even seven or eight, but in the end what you get is in some cases very impressive.”
Looking at some of the results produced through Midjourney – traceable on Instagram through the hashtag of the same name – it is easy to think we are in front of artistic experiments that are somewhat distant from concrete architectural projects. However, things are not quite like that: “In most cases, these results should be considered as starting points and suggestions the designer would struggle to achieve without an AI,” Niccolò Casas explains, architect and researcher at Bartlett UCL (University College of London) and author of Plasticity. “There would probably need to be a whole studio of collaborators selecting which ideas to keep and which to discard: artificial intelligence thus gives even microstudies the ability to create entire catalogs of architectural situations.”
However, as anyone who has tried to use any “artistic” algorithm will have noticed, the results often have a very peculiar and homogeneous aesthetic among them. Isn’t there a risk of a generalised flattening on the style being the hallmark of the single algorithm? “Yes and no, because this is actually a problem that was already there,” Casas explains. “Among insiders, the moment we see a design we already know what software was used to make it. I originally thought that the initial commands determined much of the outcome, instead it is the subsequent iterations that do that. This allows you to have a differentiated spectrum, but it is critical to have several iterations of the process.”
“In organic architecture, we do not search for pure authorship”, Mario Coppola continues. “We are aiming to hybridise, to bring unknown things as biology or the human body into this new world. In the search for hybridisation, artificial intelligence is really an innovative tool that naturally mixes what it finds. It works a bit like sedimentary rocks: everything it encounters becomes part of the layering.”
“In organic architecture, we do not search for pure authorship”, Mario Coppola continues. “We are aiming to hybridise, to bring unknown things as biology or the human body into this new world. In the search for hybridisation, artificial intelligence is really an innovative tool that naturally mixes what it finds. It works a bit like sedimentary rocks: everything it encounters becomes part of the layering.”
This is most likely a limitation that will be overcome over time, thanks in part to the architects themselves who help train the machine by selecting the results that are best fitted to meeting their needs. For now, however, there are ways of getting around the most obvious obstacles: “It is difficult to adapt the qualities of AI to a single specific architectural case,” Casas continues. “The solution might be to break down the several elements, instead of working on the total result.”
A compromise situation which also refers to another consideration: although it is inevitable that the automation of several processes will have an impact on the number of jobs available – also in this article, the work of the AI has been compared to a “team of assistants” – the strongest feeling is that the collaboration between human being and artificial intelligence is one both can get the best out of it. A kind of fusion? “It is something I personally feel very much,” Coppola confirms. “I still need a sketchbook, but I realise now that I feel the need to see the 3D model take shape.”
The relationship between architect – or, more generally, creative – and artificial intelligence is not peaceful anyway: “We are as excited as we are terrified,” Casas concludes. “The role of the architect and designer, after all, is to show something that was not there before. Then it is the engineers and surveyors who take care of materialising this intuition. Clearly, artificial intelligence works on this very part: on intuition and visualisation. This does not mean that there will be no more work for us in the future, but that it will certainly change dramatically.",3
93,"- Adaptive reuse apartments are increasing faster than new apartments, up by 25% in the last 2 years compared to the pre-pandemic period.
- Conversions from office buildings to apartments are at an all-time high, having made way for 11,000 apartments in just the last 2 years.
- There are 77,000 apartments under conversion, setting up the stage for a boom in adaptive reuse in the upcoming years.
In the last two years, apartment conversions jumped by 25% compared to two years prior. More precisely, this increasingly popular real estate niche brought a total of 28,000 new rentals in 2020-2021, well above the pre-pandemic years of 2018-2019 when 22,300 apartments were brought to life through adaptive reuse. Amid an ever-growing need for housing, adaptive reuse picked up speed in America’s largest cities, according to the latest data from Yardi Matrix.
So, to fully grasp how much adaptive reuse had grown in recent years, we compared the latest figures to the rate of growth in traditional new apartment construction. Our analysis shows that adaptive reuse apartments were growing faster than new apartments — 25% versus 10% — during the same timeframe.
Conversions From Office to Apartment Hit All-Time High
Office-to-apartment conversions increased even faster, a 43% jump during 2020-2021 compared to 2018-2019, from 7,762 to 11,090 apartments created from former offices. The total conversions in 2020-2021 represent an all-time high, the repurposing of office buildings through adaptive reuse taking an extraordinary leap not just in the last two years, but over the last decade as a whole, from the mere 2,700 apartments brought to life in 2010-2011. Former offices make up 40% of all adaptive-reuse conversions to rentals between 2020-2021, the highest share.
“The residential market needs significantly more density in the areas of the largest cities, where the demand is greatest and where the tallest office buildings are located,” said Doug Ressler, manager of business intelligence at Yardi Matrix. “Existing building architecture is the critical starting point. Not all buildings are equally threatened by the work-from-home revolution. Larger office buildings in abandoned central business districts are better suited to conversion than the often-smaller office complexes distributed around the suburbs.”
What’s more, adaptive reuse apartments are poised for impressive growth in the near future with over 77,000 apartments currently undergoing conversion. In fact, 8,300 apartments have already been converted and opened to the public this year as of July 2022.
Washington, D.C. Leads in Number of Repurposed Buildings During Pandemic
Washington, D.C., Philadelphia and Chicago became hotbeds for adaptive reuse between 2020-2021. These three major cities alone delivered 15% of the total apartment conversions nationwide.
In first place, Washington, D.C. surpassed all other cities when it came to adaptive reuse during the first few years of the pandemic: The nation’s capital opened a total of 1,565 apartments by repurposing old buildings — almost double the number converted here just two years prior. With that, Washington, D.C. holds almost 6% of total adaptive reuse projects in the U.S.
Nearly matching Washington, D.C. in numbers, Philadelphia maintained its track record in conversion projects. The City of Brotherly Love transformed older buildings into 1,552 new apartments in the last two years after a previous all-time high of 1,854 between 2018-2019.
Meanwhile, despite leading in total conversions in the last decade, this time Chicago landed in third place with 1,139 apartments. The top five is rounded out by Cleveland and Pittsburgh with 837 and 814 converted apartments, respectively.
Office Buildings Remain the Dominant Building Type to Adapt, But Smaller Niches Pick Up the Pace
The last two years certainly demonstrated the potential for creating new housing from offices. This type of building conversion dominated this time period by making up 40% of transformed units. However, with the rise of hybrid and remote work, developers are turning toward a different kind of makeover and choosing live/work/play development as a way to resuscitate office buildings.
With 4,331 apartments, factories are the second-most sought-after conversion sources. Between 2020-2021, factories represented 16% of adaptive reuse projects. As manufacturing continues to shift overseas, many abandoned industrial spaces offer generous floorplans that make for a great transition to residential and mixed-use spaces.
That said, smaller niches are also emerging and expanding at a fast pace. Surprisingly, conversions of healthcare buildings actually recorded the largest growth during the pandemic. In fact, apartments adapted from healthcare buildings more than tripled in 2020-2021 compared to 2018-2019, increasing by 212%.
Interestingly, religious buildings take second place when it comes to popularity, with a 73% growth. A small niche that resulted in only 311 converted apartments between 2018-2019, religious buildings that were converted into residential spaces gave way to a total of 537 apartments in the past two years.
Finally, with 3,573 apartments in 2020-2021, hotels remain one of the most popular building types to be converted into rentals, registering a 66% growth compared to 2018-2019. The straightforward transition from hotel rooms to apartments is one of the reasons hotels remain one of the primary sources for adaptive reuse.
Washington, D.C., Chicago Take Lead in Office Conversions
Washington D.C. also leads in turning offices into rental apartments. Between 2020-2021, the nation’s capital managed to convert 1,147 units from former office spaces. A trend that was popular even before the pandemic, adaptive reuse picked up the pace due to the significant number of vacant offices in the city’s downtown.
At the same time, a total of 732 new apartments for rent in Chicago were created through office conversions, with many more similar transformations to come. In particular, Chicago’s downtown area seems to be the best spot to tackle adaptive reuse projects — and the perfect example for that is LaSalle Street. And, with Millennium on LaSalle as a benchmark for success, the City of Chicago is taking proposals to revitalize what used to be an important part of Chicago’s Central Business District.
Philadelphia is next on our list with 590 apartments resulting from office conversions. One City at 1401 Arch St is a prime example of Philadelphia’s efforts to conserve and bring office buildings back to life in the form of rental apartments. The former headquarters of United Gas Improvement Company was awarded the Preservation Achievement Award in 2020.
77,000 Future Apartments Expected to Be Converted in the Next Few Years
The promising future of adaptive reuse is reflected in the impressive number of projects expected in the coming years — serving as further confirmation of its rising popularity. To that end, Yardi Matrix data shows a total 77,100 future adaptive reuse apartments in various stages of conversion. Of these, some are already undergoing conversion and set to be completed in 2022 and later, while other projects are awaiting approval or are in the planning stages.
When it comes to future projects, office conversions are projected to represent 28% of total apartments under conversion — the largest share of all building types under conversion, according to Yardi Matrix. Hotels represent the second-largest share (22% of future projects), while factories (that make up 16% of the total) are in third place.
Granted, nowhere is the future development of adaptive reuse quite as noticeable as in Los Angeles. Here, a total of 4,130 apartments are expected to be created through conversions. Meanwhile, sporting considerably fewer upcoming projects, Cleveland, OH and Buffalo, NY joined the City of Angels on the podium with 2,654 and 1,984 apartments, respectively.
Los Angeles Leads in Apartment Conversions in the First Half of 2022
In terms of conversions completed from January to June 2022, Los Angeles is the leading city with 1,242 apartments. This alone makes 2022 the best year ever for adaptive reuse in Los Angeles.
The top 10 cities with the most converted apartments in the first half of 2022 are:
|City||Converted Apartments|
|Los Angeles, CA||1,242|
|Kissimmee, FL||705|
|Alexandria, VA||648|
|Honolulu, HI||500|
|Richmond, VA||391|
|Cleveland, OH||354|
|Hialeah, FL||251|
|Lakewood, CO||218|
|Indianapolis, IN||216|
|Longmont, CO||210|
Methodology
- RentCafe.com is a nationwide apartment search website that enables renters to easily find apartments and houses for rent throughout the United States. This report was compiled by the RentCafe research team based on apartment data provided by our sister company, Yardi Matrix.
- Adaptive reuse refers to repurposing an existing building into rental apartments. This study is based on apartment data related to buildings containing 50 or more units.
- For this study, we analyzed the number of apartment conversions grouped in 2-year periods as follows: 2010-2011, 2012-2013, 2014-2015, 2016-2017, 2018-2019, and 2020-2021.
- 2022 conversion completions include only units in finalized projects in the first six months of the year.
- Future projects include projects that are under conversion, as well as planned and prospective redevelopment.
- Data are valid as of July 2022 and are subject to change.
- Yardi Matrix defines completed buildings as those that have received a certification of occupancy, while those under conversion have yet to receive it or are currently being developed. Planned projects are actively engaged in the redevelopment approval process, while prospective redevelopments hold lower status in the probability of completion because they remain subject to entitlement approvals.
- Images courtesy of Yardi Matrix. All building photos are used with expressed permission from Yardi Matrix.
Fair use and redistribution
We encourage you and freely grant you permission to reuse, host, or repost the research, graphics, and images presented in this article. When doing so, we ask that you credit our research by linking to RentCafe.com or this page, so that your readers can learn more about this project, the research behind it and its methodology. For more in-depth, customized data, please contact us at media@rentcafe.com.",8
94,"What if you could effectively prevent someone from recording your voice? This is the focus of a study by Guo et al. (2022) at Michigan State University, in which they use a dynamically calculated audio signal that effectively cancels out one’s voice in a recording device. This relies on an interesting aspect of certain micro-electro-mechanical system (MEMS) microphones, which are commonly used in smartphones and other recording devices.
A specially crafted ultrasound signal sent to the same microphone which is recording one’s voice can result in the voice audio signal being gone on the final recording. The approach taken by the authors involves using a neural network that is trained on voice samples of the person (“Bob”) whose voice has to be cancelled. After recording Bob’s voice during a conversation, the creatively named Neurally Enhanced Cancellation (NEC) system determines the ultrasound signal to be sent to the target recording device. Meanwhile the person holding the recording device (“Alice”) will still perceive Bob’s voice normally.
As ultrasound is highly directional, the system can only jam a specific microphone and wouldn’t affect hidden microphones in a room. As noted by the authors, it is possible to do general microphone jamming using other systems, but this is legally problematic, which should not be an issue with their NEC system.
Thanks to [JohnU] for the tip!
15 thoughts on “Remove A Speaker’s Voice From A Recording Using Ultrasound”
A sound of sufficient intensity outside of the human hearing, would probably in most devices cause the ALC to lower the volume so that recording is effectively impossible. Most devices won’t filter the input.
Not an advisable method.
1: despite a person not being able to “hear” the sound, it is still present and can be very harmful to all people present. See active denial devices (crowd control) for details.
2: the above also happens with sub audible sounds (infra sound)
3: if the device has a level indicator it’s possible that the sound pressure might be indicated but the audible sound portion not heard by the device. This would raise suspicion from the person recording. (bad idea, keeping the person naive, are the best methods).
Side muse, if used against an Amazon Echo, could this be considered a form of “Echo cancellation”?
^ HA!
It probably wouldn’t need to be super loud rather louder then the speaker is speaking. Like how if you wisper in a crowded restaurant someone a few feet away might not hear you over the other noise.
Keeping the recorder unaware of the canceling might not matter. For instance, if you suspected your room was bugged or even as a automatic precaution against bugging a room.
Interesting project. I wonder if all the special training and complexity was really necessary; blasting enough ultrasound at a microphone will surely saturate it, swamping out other signals.
It might be to keep the volume of the interference at a minimal level
But the point of the paper is that they can selectively cancel out one voice, leaving the rest untouched.
At that intensity it would probably have effects on the people in the room. Even if sound is outside of our hearing range it can still damage our ears quite effectively.
Since it’s harder to conceal microphones than human heads, maybe the opposite solution could work. Use ultrasound to generate highly focused sound toward listener’s ears. While you could technically place microphones next to your ears, it’s still harder to conceal.
An alternative and cheaper solution might be giving all listeners a bone conduction headset which might be harder ti accurately record of? But neither solution is flawless.
Even with zero sound, a skilled lip reader or AI could just recreate the speaker’s voice
One detail that I think could be clearer in the article: the jamming blocks specifically Bob’s voice, but not any other person’s.
Article title was a bit misleading; this idea purports to prevent the recording of a specific voice, not to remove it from a completed recording. [disappointment]
Interesting idea. Two observations:
– “Alice, please put your phone away”.
– Someone who truly wants to make a secret recording can employ devices with microphones that would not be sensitive to that ultrasonic cancellation circuit (bandlimited, post-mic filtering, etc)
Isn’t that what anialiassing filter does? I was sure that we record with higher frequencies so that we can use less agressive filtering but still the cut off frequency starts slightly above 22,5 kHz.
Anti-aliasing filters remove frequencies at/above the Nyquist frequency (half the sampling rate) to prevent audible artifacts in the digitized signal. Current sampling methods often use a very high initial sample rate, so the presence of a sharp anti-aliasing filter isn’t guaranteed.
Also, I believe that the proposed method may rely on the ultrasonic signal being “demodulated” by the expected MEMS mic… but recorders don’t have to have the kind of mic that’s responsive to ultrasonic signals.
This technique relies on harmonics of the ultrasonic signal: it ‘rings’ the MEMS microphone at audible frequencies, but not the human ear (which are nicely squishy and effectively attenuate ultrasonics). Antialiasing would not help, because the harmonics are within the bandpass range.
If Alice can still hear Bob, then they just need to get a loopback installed on her phone (this can be done in software or hardware) and record the output from that.
Please be kind and respectful to help make the comments section excellent. (Comment Policy)",6
95,"Just five days after Liu Yexi made her debut on Douyin, the sibling app of TikTok, she attracted more than 3 million followers. In her first video clip, which lasted for roughly two minutes and was posted in November 2021, the beauty blogger wore the robes of a Taoist priest, seated in a neon-lit alley that looked like it fit in cyberpunk film, and applied her makeup in a traditional Chinese style. The video went viral overnight.
So far, she has posted six videos and is still trending on Douyin. At the moment, she has more than 830 million followers.
But Liu is not a living, breathing human—at least not in the conventional sense. She is a virtual character developed by Chuangyi Technology and Culture Co., a company in Shenzhen that creates visual content and digital characters using motion capture technology.
Virtual idols are not a new concept. The first generation of these artificial celebrities were developed for Japan’s ACG industry (animation, comic, games) in the 1980s. But in recent years, social media platforms have given digital characters a way to express themselves in more intimate, immediate ways and garner massive fan bases.
The evolution of virtual idols
In China, the popularity of virtual idols is closely linked to the rise of Bilibili, a video platform that is favored by ACG fans. In all, around 32,400 virtual idols hosted livestreams on Bilibili in 2020. The people behind them are known as “Vtubers.”
Naturally, Vtubers often project visuals that are designed to be aesthetically appealing. “Although most of them have their own personas and scripted lines, their personalities are real, their reactions with fans are real, the friendships and their efforts are real,” said Shu Tong, a Bilibili viewer and Vtuber follower, to KrASIA.
The majority of virtual idols fans are Gen Z. More than 70% of these followers are aged between 18 and 23, according to data compiled by consultancy iiMedia research.
Having grown up in the era of the internet, Gen Z are now independent consumers with a unique appetite for virtual idols. Many brands are forming collaborations or commissioning virtual idols to communicate with this demographic. In August 2021, when virtual singer Eileen celebrated her birthday with a livestreamed concert on Bilibili, she received RMB 1.5 million (USD 237,000) in contributions from fans in 2.5 hours.
From a branding point of view, virtual idols are much less likely to be mired in scandals. The appeal was clear in 2o21, when several A-list stars in China were caught in bad publicity. For example, heartthrob singer Wang Leehom went through a messy and public divorce, rapper and entertainer Kris Wu was arrested on charges of raping underage girls, and Zheng Shuang was found to have abandoned her surrogate children and committed tax evasion. In each case, companies dropped them from product endorsement campaigns instantly. But idols whose existence relies on computer-generated imagery are highly unlikely to cross the same lines and wreck a brand’s image by association.
Expanding horizons
“Before 2021, the dilemma in the virtual idols industry was the lack of application scenarios,” said Chen Lun, a market manager with a Shanghai-based AI company that creates virtual characters, to KrASIA. “The ACG community is a relatively small market. The profit from livestreams and merchandise is too low to cover the technological cost for creating the character.”
Developing virtual idols is a pricey process. Even though Liu Yexi has more than 8 million followers on Douyin, the company that created her has yet to make a profit. 3D renderings and full character design could cost millions of renminbi, and the likelihood of generating immediate returns is low.
According to a UBS report, the average upfront cost to create an advanced virtual idol is RMB 30 million (USD 4.7 million). Beyond that point, continued operation can be expensive. For instance, it takes RMB 2 million (USD 316,000) to produce a single track for five-piece virtual girl band A-Soul.
Already, multinational consumer brands like KFC, Tesla, Louis Vuitton, and Givenchy have commissioned virtual idols for promotional campaigns in China. Looking into the future, metaverse environments will also offer new places for virtual idols to exist and connect with viewers, followers, and fans, much like the way singers and rappers like Ariana Grande and Lil Nas X have already staged concerts in Fortnite and Roblox.",4
97,"The type of wind turbine you’re used to seeing in stock photos of wind farms is called a horizontal axis wind turbine (or, HAWT). But there is another form of wind power, called a vertical axis wind turbine (VAWT), in which the blades rotate on an axis perpendicular to Earth’s surface. This type of turbine can work better in unstable wind conditions because they don’t need to be pointed into the wind, but still produce much less electricity and durability problems because of the force the wind exerts on them. That’s why you would only see VAWTs in small applications, like homes, and HAWTs in wind power farms.
But a new company claims to have improved on the VAWT design. The invention could create a turbine with a maximum output of 40 megawatts, far surpassing the 15 megawatts of the world’s current largest turbine. That company is called World Wide Wind, a Norwegian startup. The Norwegians—rich, thanks to their oil and gas reserves—want to dramatically increase their wind energy production to 30.000 megawatts by 2040. Their industry’s interest in offshore wind energy is so big that there is a waiting list to test new technologies off its coast, which is on the incredibly windy shores of the North Sea.
In June 2021, company founder Stian Valentin Knutsen wondered if it would be possible to have two sets of rotor blades on a single turbine mast, making them rotate in opposite directions. “The idea was to increase the energy output of the vertical turbines while simultaneously eliminating the increased torsional forces and the inherent problems associated with upscaling traditional HAWTs for increased energy outputs,” company spokesperson Elsbeth Tronstad told me via email. Knutsen looked for scientists to test the possibilities and finally met Hans Bernhoff, a professor at the department of electrical engineering at Uppsala University, in Sweden.
According to the company, Bernhoff had been doing research on vertical wind turbines for more than 20 years, building his own 200 kilowatt (kW), 131-foot-high vertical turbine that was functional for a decade. He was intrigued by Knutsen’s theoretical model and joined the company, developing the idea of the large tilted offshore floating turbine that World Wide Wind is now working on.
How it works
The concept of vertical axis turbines is not new, but the architecture of this machine—which the company says is patent pending—is radically different. The design employs two coaxial, or counter-rotating, rotors mounted on a vertical shaft.
Each rotor has three blades that sweep in an inverted conical area thanks to its V-shape (which remind me of the arms of a mechanical tree). The upper turbine is connected to an inner shaft that serves as the rotor in the electric generator. The lower turbine acts as the stator, the part of the generator that contains the coils and remains static in most generators. In this case, however, the stator moves on the opposite side of the rotor. The result: It doubles the relative speed of the shafts and thus the electrical generating capacity of the system.
Their engineers point out that the generator is not at the top of the mast, like that of a conventional HAWT system. but at the base, next to the ballast and all the other electrical system components, including the cables that connect it to shore. The added weight contributes to the stability of the system, ensuring that the tower does not capsize no matter how much the ocean heaves. This design, they say, also makes it more resistant to the vibration that greatly affects the integrity of HAWT systems, especially under very strong wind conditions.
While an underwater generator sounds like a nightmare to maintain, Tronstad tells me this is no problem: “Its interior space is all dry and there is ample space for technicians to work inside.” She also says that the generator design is a direct-driven permanent-magnet synchronous generator, “which requires minimal, if any, service during operation,” thanks to its lack of gearbox and other wearable parts.
Too good to be true?
Logically, the mast itself does not stand upright as in conventional towers. In fact, the mobility of the assembly to be able to operate at almost any angle is fundamental to its operation. “Bernhoff—who is also a proficient sailor—always wanted to design an offshore turbine that would work with the wind and not against it, like current offshore HAWT units do,” Tronstad says. The company claims that this machine automatically orients itself as the wind blows and absorbs its energy from any conceivable angle, always guaranteeing the highest possible performance.
Knutsen and Bernhoff also maintain that the counter-rotating rotors greatly decrease the turbulence typical of horizontal turbines. But, while Tronstad says that “the first turbine drive counter-rotating generator have been already tested” and they have simulated the large-scale generator design simulated with electromagnetic with full physics, plus hydrodynamic simulations of structure and wave interaction,” and other tests are currently underway, the company hasn’t built its first full-scale prototype yet to physically validate any of these simulations.
If their simulations and theories are true, however, it could result in some crazy machines. According to its inventors, this design can reach up to 1,312 feet in height to achieve up to 40 megawatts. The largest turbine on the planet right now is China’s 793-foot-tall MySE 16.0-242 china, which generates up to 16 megawatts using monstrous 387-foot blades.
But if World Wide Wind’s design works, we wouldn’t need to build at such a gargantuan scale in order to get more power per square mile than we currently achieve in an offshore wind farm. HAWT units require very large distances between them to avoid causing turbulence to each other; but World Wide Wind claims that its machines can be deployed in a higher density, thanks to the vertical design, thus increasing electric generation using much less space.
These are all bold claims. The company is confident it will achieve these objectives based on the current testing, and Knutsen seems to have some key support from Norwegian Energy Partners, an organization dedicated to the internationalization of the Norwegian energy companies. Still, as with any new bold innovation, it has to work in reality, not just in models; but any radical new idea that could have significant impact on the wind-energy industry and our planet is one worth developing and testing. And we might see, before too long, how the company can fulfill its promises: World Wide Wind says it will launch its first 3-megawatt model in 2026 and a 40-megawatt model in 2029.",2
98,"Architecting Joy.
The Future Does Not Fit in the Containers of the Past. Edition 108.
A definition of success is the freedom to spend time in ways that gives one joy.
Joy is more than happiness which is often transitory as it ebbs and flows with external events.
Joy is more akin to contentment and satisfaction.
Some believe it is momentary suggesting we have “flashes of joy”.
The joy that comes with deep satisfaction and contentment however endures and its contours do not waver with the oscillations of the transient.
Experience, time, and observation reveals there are ways to architect joy.
Joy=Grace+Flow+Connection.
Joy encompasses grace, flow, and connection.
The joyous exhibit graciousness, they tend to be in a state of flow and connected to both reality, other people, and some things higher and deeper.
Grace.
Grace is a fusion of demeanor and deportment.
The graceful combine a generosity of spirit, a sense of respect for others and a humility regardless of their level of excellence and skill.
Generosity of spirit in understanding that much of what is meaningful is not a zero-sum game.
Respecting others by being aware of them and their needs and backgrounds.
Humble in not losing one’s sense of perspective that everybody’s achievement while significant is due to a combination of many factors including luck, opportunity, inheritance, and the specific time and not just due to skill and hard work.
Flow.
When in a state of flow an individual is inside and outside time.
Deeply immersed in something while extracted from the ordinary.
It can come in many ways including working on something which is challenging to stretch one but not so difficult that one cannot achieve positive outcomes.
It can come from being immersed in making things, building things, and creating things.
And it comes from learning and seeking wisdom. In being able to connect the dots and see and understand things in ways that give one joy.
Connection.
The joyous seem to have strong relationships to other people and to a higher cause or purpose.
Humans are social beings and most need some form of connection. The ability to invest and grow connections tends to be associated with joy.
In addition to these human/family connections many gain joy by connecting to a higher cause or purpose.
It may be a charity, it may be a social cause, a striving quest, or some form of a religious or spiritual endeavor.
The stones used to architect joy.
Generosity. Respect. Humility engender Grace.
Creating, Learning, Challenges enable Flow.
Relationships. Purpose. Spirituality elicit Connection.
Intriguingly these are human and not specific to an industry, a race or country.
They sometimes result in fame, power, and money but they can thrive in the absence of these.
Try to create and build and learn. Invest in relationships and respect others without being full of oneself. Find a cause or calling.
By mindfully focusing on and spending one’s time in these ways this one can architect joy.
Just released! The latest episode of “What Next?” : Cliche thinkers need not apply!
Boomers are narcissists. Millennials are spoiled. Gen Z are lazy. We assume people born around the same time have basically the same values. It makes for good headlines, but is it true?
Bobby Duffy, Professor of Public Policy and Director of The Policy Institute, King's College London, and author of highly acclaimed book “ The Generation Myth”, challenges us to re-think lazy assumptions about the attitudes of who we are targeting. Hear why it is wrong to generalize about generations and why how so much of what business and marketing believe or have been led to believe has little supporting data!
Every Sunday a new topic. Completely free to read. Join 25,000 leaders. Please sign up:
Rishad Tobaccowala is an author, advisor, speaker, and educator who distills four decades of experience to help people see, think, and feel differently so they can grow their companies, their teams and themselves. More about Rishad’s advisory services, best-selling book, and the range of topics of 10 popular workshops can be found here…https://rishadtobaccowala.com/
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Dear Rishad, thanks for sharing your insights. May I add Dame Zaha Mohammad Hadid, to the Architecting Joy presentation?
Dame Zaha Mohammad Hadid, Iraqi born architect, recipient of the Pritzker Architecture Prize 2004, the Stirling Prize in 2010 and 2011.
October 31, 1950, died: March 31, 2016,
Fantastic insights and much needed for the times we live in. Finding meaningful purpose in what we do together (beyond just reaching milestones) create stronger connections that energize individuals to wanting to do more good for greater joy.",2
99,"Derinkuyu: Mysterious underground city in Turkey found in man’s basement
- In 1963, a man knocked down a wall in his basement and discovered a mysterious underground city.
- The subterranean city is up to 18 stories and 280 feet deep in places and probably thousands of years old.
- The Derinkuyu Underground City is the largest of its kind: It could house 20,000 people.
We live cheek by jowl with undiscovered worlds. Sometimes the barriers that separate us are thick, sometimes they’re thin, and sometimes they’re breached. That’s when a wardrobe turns into a portal to Narnia, a rabbit hole leads to Wonderland, and a Raquel Welch poster is all that separates a prison cell from the tunnel to freedom.
A fateful swing of the hammer
Those are all fictional examples. But in 1963, that barrier was breached for real. Taking a sledgehammer to a wall in his basement, a man in the Turkish town of Derinkuyu got more home improvement than he bargained for. Behind the wall, he found a tunnel. And that led to more tunnels, eventually connecting a multitude of halls and chambers. It was a huge underground complex, abandoned by its inhabitants and undiscovered until that fateful swing of the hammer.
The anonymous Turk — no report mentions his name — had found a vast subterranean city, up to 18 stories and 280 feet (76 m) deep and large enough to house 20,000 people. Who built it, and why? When was it abandoned, and by whom? History and geology provide some answers.
Fantastically craggy Cappadocia
Geology first. Derinkuyu is located in Cappadocia, a region in the Turkish heartland famed for the fantastic cragginess of its landscape, which is dotted with so-called fairy chimneys. Those tall stone towers are the result of the erosion of a rock type known as tuff. Created out of volcanic ash and covering much of the region, that stone, despite its name, is not so tough.
Taking a cue from the wind and rain, the locals for millennia have dug their own holes in the soft stone for underground dwellings, storage rooms, temples, and refuges. Cappadocia numbers hundreds of subterranean dwellings, with about 40 consisting of at least two levels. None is as large, or by now as famous, as Derinkuyu.
Hittites, Phrygians, or early Christians?
The historical record has little definitive to say about Derinkuyu’s origins. Some archaeologists speculate that the oldest part of the complex could have been dug about 2000 BC by the Hittites, the people who dominated the region at that time, or else the Phrygians, around 700 BC. Others claim that local Christians built the city in the first centuries AD.
Whoever they were, they had great skill: the soft rock makes tunneling relatively easy, but cave-ins are a big risk. Hence, there is a need for large support pillars. None of the floors at Derinkuyu have ever collapsed.
Two things about the underground complex are more certain. First, the main purpose of the monumental effort must have been to hide from enemy armies — hence, for example, the rolling stones used to close the city from the inside. Second, the final additions and alterations to the complex, which bear a distinctly Christian imprint, date from the 6th to the 10th century AD.
Hitting bottom in the dungeon
When shut off from the world above, the city was ventilated by a total of more than 15,000 shafts, most about 10 cm wide and reaching down into the first and second levels of the city. This ensured sufficient ventilation down to the eighth level.
The upper levels were used as living and sleeping quarters — which makes sense, as they were the best ventilated ones. The lower levels were mainly used for storage, but they also contained a dungeon.
In between were spaces used for all kinds of purposes: there was room for a wine press, domestic animals, a convent, and small churches. The most famous one is the cruciform church on the seventh level.
If buckets could speak
Some shafts went much deeper and doubled as wells. Even as the underground city lay undiscovered, the local Turkish population of Derinkuyu used these to get their water, not knowing the hidden world their buckets passed through. Incidentally, derin kuyu is Turkish for “deep well.”
Another theory says the underground city served as a temperate refuge for the region’s extreme seasons. Cappadocian winters can get very cold, the summers extremely hot. Below ground, the ambient temperature is constant and moderate. As a bonus, it is easier to store and keep harvest yields away from moisture and thieves.
Whatever the relevance of its other functions, the underground city was much in use as a refuge for the local population during the wars between the Byzantines and the Arabs, which lasted from the late 8th to the late 12th centuries; during the Mongol raids in the 14th century; and after the region was conquered by the Ottoman Turks.
Leaving the “soft” place
A visiting Cambridge linguist visiting the area in the early 20th century attests that the local Greek population still reflexively sought shelter in the underground city when news of massacres elsewhere reached them.
Following the Greco-Turkish War (1919-22), the two countries agreed to exchange minorities in 1923, in order to ethnically homogenize their populations. The Cappadocian Greeks of Derinkuyu left too, and took with them both the knowledge of the underground city and the Greek name of the place: Mαλακοπια (Malakopia), which means “soft” — possibly a reference to the pliancy of the local stone.
Derinkuyu is now one of Cappadocia’s biggest tourist attractions, so it no longer counts as an undiscovered world. But perhaps there’s one on the other side of your basement wall. Now, where did you put that sledgehammer?
Strange Maps #1139
For more underground fun, see also Strange Maps #119, #443 and #1083.
Got a strange map? Let me know at [email protected].
Follow Strange Maps on Twitter and Facebook.",1
100,"I recently got access to OpenAI's DALL-E 2 instance. It's a lot of fun, but beyond its obvious application as a cornucopia of funny cat avatars, I think it's now fit to use in certain kinds of creative work.
There are already plenty of good articles out there on the model's strengths and weaknesses, so I won't go over that here other than to note that it's not a threat to high art. It's got an idea of what things look like and how they can visually fit together, but it's very vague on how they work (e.g. anatomy, architecture, the finer points of Victorian-era dinner etiquette, art critics), and object inpainting aside, it doesn't rise to the level of realism where I'd worry too much about the fake news potential either.
However, with human guidance and a carefully chosen domain, it can still do some very impressive things. I've suspected that adventure game graphics in the point-and-click vein could be one of those domains, and since I'm helping someone dear to me realize such a game, I had the excuse I needed to explore it a little and write this case study.
Inspiration
Point-and-click adventures make up a fairly broad genre with many different art styles. I've focused my attention on a sub-genre that hews close to the style of early 1990s Sierra and LucasArts adventure games. These would typically run at a screen resolution of 320×200 and appear pixelized, especially so on a modern display:
Contemporary game developers sometimes work at low resolutions, producing a similar effect:
At first glance this seems restrictive (just ask H.R. Giger), but from a certain point of view, it's actually quite forgiving and confers lots of artistic license:
- The perspective doesn't need to be realistic or even consistent, and is often tweaked for practical reasons, such as eliminating visual clutter, providing more space for the action or aligning better with the pixel grid.
- Speaking of pixels, pixelization helps work around the fact that DALL-E can produce odd smudges and sometimes struggles with details. It also helps with manual retouching, since there aren't very fine details or textures to be precisely propagated.
- Does your art look weird? Uncanny valley anxiety? Take a free tour courtesy of the entire genre. Feel your troubles float away as it throws an arm around you. And another arm. And another.
Ahem. What I'm trying to say is, this is a wonderful, fun genre with many degrees of freedom. We'll need them!
How to into the pixels
While you can tell DALL-E to generate pixel art directly, it's not even remotely up to the task; it just doesn't know how a pixel grid works. The result will tend to have some typical pixel art properties (flattened perspective, right angles, restricted palette with colors that ""pop"") wrapped in a mess of smudged rectangles of all sizes:
It's impressive in a ""holy guacamole, it kind of understood what I meant"" way, but even if you clean up the grid you don't stand a chance of getting a consistent style, and you have no control over the grid size.
Fortunately, pixelization can be easily split off from the creative task and turned over to a specialist tool. I used
magick in my scripts:
$ magick -adaptive-resize 25% -scale 400% in.png out.png
It's worth trying different resampling filters. ImageMagick's
-adaptive-resize operator produces nice and crisp output, but when downsampling by this much there may be even better options.
You could also experiment with color reduction and dithering. The images I generated for this article have been postprocessed like this…
$ magick -adaptive-resize 25% -ordered-dither checks,32,32,32 \ -scale 800% in.png out.png
…which pixelizes to a 1:4 ratio, restricts the output to a color cube with 32 levels per channel (i.e. 15-bit color) and applies subtle — but not too subtle — checker-pattern dithering. It also upscales to twice the original size for easy viewing in a web browser.
Style prompts and selection
After some trial and error, I settled on a range of prompts involving techniques, styles and authors of fine art: oil on canvas, high renaissance, modernism, precisionism. This gave me a good chance of output in a handful of repeatable styles with sufficient but not overwhelming detail:
Beyond important details (""sunny day""), vague modifiers like ""atmospheric"", ""dramatic"" and ""high quality"" can have huge effects on lighting, camera angles and embellishment. They're also very unreliable, and I have the feeling they can crowd out more important parts of the prompt from the model's tiny mind and cause them to be overlooked. It's better to use compact, specific prompts until you're close, and then, well, watch it fall apart as you add a single modifier.
Which brings us to the second human-intensive part of this task: selection. Since the OpenAI UI produces four variants for each prompt, this is mandatory. It's also very necessary, as most of the output falls far short of the mark. With the right prompt, you might get a distribution where roughly 1/20 images is good (with minor defects) and 5/20 are potentially salvageable. The remainder will be obviously unusable for various reasons (major defects, stylistic and framing issues, photobombed by anthropomorphic utility pole).
I think it's the same way with the impressive DALL-E mashups being shared. By the time you're seeing them, they've been curated at least twice; once at the source, and one or more times by the chain of media that brought them to you. You won't see the hundreds of images that came out funny but not ha-ha funny.
Since each image takes only a second to generate and a few seconds to evaluate, this wild inconsistency isn't disqualifying. It just means DALL-E isn't magical or even very intelligent.
Setting the stage
An adventure game location is a bit like a theatre stage; it's a good idea to have an ample area close to the camera for the player to walk around in. It's also a good idea to avoid scenes where the player can get far away from the camera, as you'd be forced to choose between a comical perspective mismatch and a really tiny player character that'd be hard to follow and control. Obviously a real game won't want to follow these rules strictly, but it's important to be able to implement them when needed.
Fortunately it can be done, and it's not too hard:
To control the perspective and make it more flat, adding ""facade"" seemed to be effective. Ditto ""diorama"" and ""miniature"", although they tended to produce a more clinical look. Specifying a typical ground-level detail to focus on, e.g. ""entrance"", was also helpful. I'm not sure ""2d"" and ""2.5d"" actually made any difference. Bringing it all together:
- Specify the era, time of day and lighting conditions (e.g. ""on a sunny day in the 2000s"").
- Be specific about the overall location (""town"", ""city"", or a named geographical location), the focus (""facade"", ""hotel entrance"") and the immediate surroundings (""houses"", ""streets"", ""plains"").
- You can explicitly ask for open space, e.g. ""…and street in front"" or ""plaza surrounded by…"".
- Sometimes it's necessary to ask for the space to be empty, otherwise DALL-E can paint in objects and people that you'd rather add as overlays later on.
- You can also specify camera placement, e.g. ""seen from second-floor balcony"", but you risk ground-level details becoming too small.
- Some combinations will have the model drawing blanks, resulting in ignoring much of your prompt or horking up non sequitur macro shots of blades of grass and the like. Be prepared to rephrase or compromise. Think about what might be well represented in the training set.
- Do not under any circumstance mention ""video game"", unless you want blue neon lights on everything.
Retouching and editing
This is easy to do using the in-browser UI. Just erase part of the image, optionally edit the prompt and off you go. Very useful for those times you've got something great, except there's a pine growing out of a church tower or an impromptu invasion of sea swine. Adding objects works too. Here's a villain's preferred mode of transportation, quite believable (if out of place) on the first try:
You can also upload PNG images with an alpha channel, although I had to click somewhere with the eraser before it would accept that there were indeed transparent areas. I suspect you could use this to seed your images with spots of color in order to get a more consistent palette.
Extending the images
DALL-E generates 1024×1024-pixel postage stamps. To fill a modern display you want something closer to a 19:10 ratio. Transparency edits come in handy here. The idea is to split the original image into left-right halves and use those to seed two new images with transparency to fill in:
This is easily scriptable. Note that you have to erase the DALL-E signature from the right half to prevent it bleeding into the result. Something like this can work:
$ magick in.png -background none -extent 512x0 -splice 512x0 left.png $ magick in.png \( +clone -fill white -colorize 100 -size 80x16 xc:black \ -gravity southeast -composite \) -alpha off -compose copy_opacity \ -composite -compose copy -background none -gravity east -extent 512x0 \ -splice 512x0 right.png
Upload
left.png and
right.png, reenter the prompt and generate a couple of variants for each. Since there's lots of context, the results turn out pretty good for the most part. Then stitch the halves together like this:
$ magick +append left.png right.png out.png
With a little more scripting, you can generate all possible permutations and apply your big brain judgement to them, e.g:
…and so on. You can also tweak the side prompts. Put in a pool or whatever:
I wouldn't be surprised if this kind of image extension made it into the standard toolbox at some point.
Other things it can do, and some that it can't
I had some success with interiors too. ""Cutaway"" was a handy cue to knock out walls and avoid claustrophobic camera placement, and it handled decorations and furniture fairly well (e.g. ""opulent living room with a table and two chairs""). It could also generate icons for inventory items after a fashion (""mail envelope on black background""). I didn't delve very deeply into that, though.
You've probably noticed that the generated images all contain defects. Some can be fixed by erasing them and having DALL-E fill in the blanks, but others are too numerous, stubborn or minute for that to be practical. This means you'll have to go over each image manually before pixelization (for rough edits) and after (for the final touch). You'll also need to adjust colors and levels for consistency.
DALL-E can't write. In fact it will rarely be able to arrange more than three letters in a correct sequence, so if you want words and signage, you'll have to draw it yourself. Maps and other items that convey specific information by virtue of their geometry can probably also be ruled out, although you may get lucky using a mostly transparent cue sketch.
You won't get much help with animations, especially complex multi-frame ones like walk cycles.
If you want to convert an existing daylight scene into a night scene, that's probably best done manually or with the help of a style transfer model.
I realize I've barely scratched the surface here, and there's bound to be a lot more that I haven't thought of.
The economics of AI jackpot
OpenAI controls usage through a credit system. Currently, one credit can be used to generate four images from a single prompt, or three edits/variants from a single image and prompt. I got some free welcome credits (50 or so), and they're promising another 15 each month. When you spend a credit, it takes 4-5 seconds to get results, which means about a second per image. You can buy 115 credits for $15 + tax, which in my case works out to a total of $18.75. That's $0.163 per credit, or at most $0.0543 per image (batch of three).
Let's say you use this to generate locations for a point-and-click game. How many will you need? Well, one very successful such game, The Blackwell Epiphany (made entirely by the fine humans at Wadjet Eye Games), has about 70 locations. If you're considering AI-generated images for your game, you're probably not trying to compete with one of the industry's most accomplished developers, so let's lower that to 50.
50 locations is still a lot, and as I mentioned before, only 1/20 images come out adequate. For each location, you can probably get by with 10 adequate candidates to choose from. That means you'll generate 200 images per location, or 10,000 images total. Let's double that to account for some additional curation, edits, horizontal extensions, late changes to the script and plain old mistakes. Then, 20,000 * $0.0543 = $1,087. Since most of the images will be generated in batches of four, not three, it's fair to round that down to an even $1,000. It's probably not your biggest expense, anyway.
How about time investment? I mean, evaluating that many images seems kind of crazy, but let's do the math and see. If an image takes about 1s to generate and you spend about 5s deciding whether to keep it (recalling that 95% is quickly recognizable as dross and you'll be looking at batches of four), that's 20,000 * 6s = 120,000s or about 33 hours. Even if you can only stand to do it for two hours a day, you should be done in three to four weeks.
Throughout this you should be able to generate 10 candidates and 10 edits for each location. Further manual editing will likely take much longer than three weeks, but that's not something I'm experienced with, so I've really no idea. It also presupposes that you're starting out with a detailed list of locations.
Legal considerations
In addition to their API policies, OpenAI have public content policy and terms of use documents that appear to be specific to DALL-E. I'm not trained in law, but the gist of the content policy appears to be ""don't be mean, sneaky or disgusting"", which is easy for us to abide by with only landscapes and architecture. Some of the restrictions seem unfortunate from the perspective of entertainment fiction: Could I generate a bloodied handkerchief, a car wreck or something even worse? Probably not. Anything containing a gun? Certainly not. However, they're also understandable given the stakes (see below).
The most concerning thing, and likely a showstopper for some creative enterprises, is point 6 of the terms of use: Ownership of Generations. My interpretation of this is that generated images are the property of OpenAI, but that they promise not to assert the copyright if you observe their other policies (which may, presumably, change). If you're making a long-lived creative work, especially something like a game that may include adult topics alongside the generations, this seems like a risky proposition. I wouldn't embark on it without seeking clarification or some kind of written release.
Ow, my ethics!
So, yeah, ethics. An obvious line of questioning concerns misuse, but OpenAI is erring on the side of caution (or realistically, trying to keep the lid on just a little longer), and anyway, our use case isn't nefarious.
What's more relevant to us is the closed training dataset and how it might contain tons of formerly ""open"" but copyrighted material, or simply pictures whose author didn't want them used this way. We're talking half a billion images, and the relevant research and blog posts either allude to web scraping or mention it outright. A search for reassurance didn't turn up much, but I did discover an interesting open issue. So, could this be disrespectful or even abusive?
A common defense claims that the model learns from the training set the same way a human student would, implying human rules (presumably with human exceptions) should apply to its output. This can seem like a reasonable argument in passing, but besides being plain wrong, it's too facile since DALL-E is not human-like. It can't own the output (or, as the case would be, sign its ownership over to OpenAI) any more than a relational database could.
A better argument is that the training process munges the input so thoroughly that there's no way to reconstruct an original image. You don't have to understand the process deeply to see that this makes sense: there's terabytes of training data and only gigabytes of model. Then the implication becomes that this is transformative remixing and potentially fair/ethical use.
Thinking about this kind of hurts my head, particularly as it's also playing out in my own field. I haven't definitely concluded, but in general I think it's important to focus on the net good that technology and sharing can bring and how the benefits (and obligations) can be distributed equitably.
So is this going to upend everything?
Well, not everything. But some things, for sure. Neural networks have evolved very quickly over the past couple of years, and it looks like there's plenty of low-hanging fruit left. Current research leaves the impression that DALL-E 2 is already old news. There are also open efforts that seem to be completely caught up, at least for those with some elbow grease and compute time to spare.
A dear friend of mine joked that we've been privileged to live in a truly global era with minimal blank spots on the map and a constant flow of reasonably accurate information, the implication being that the not too distant past had mostly blank spots and the not too distant future will be saturated with extremely plausible-looking gibberish. We had a laugh about that, but you have to wonder.
A clarification regarding pixelization
August 18th: This article sort of made the rounds, and there has been lots of interesting feedback. Contrary to conventional wisdom, my experience when this happens is that other netizens are mostly very thoughtful and nice. So too this time.
There's one recurring criticism I should address, though, because I think it stems from my own carelessness and/or attempts at brevity: This is not pixel art!
Well, sure. It's not what we understand to be pixel art in 2022. Pixel art is when you hand-pixel the things, and maybe this could be too if it had gotten seriously retouched during/after pixelization — but in its current state it isn't. Since I'm aware of the distinction, I tried to word the article carefully (""adventure game graphics"", ""pixelization"", ""pixel graphics"" in lieu of ""lowres"" or whatever) and only brought up pixel art in relation to the DALL-E query because, y'know, one can dream.
I sort of danced around it, though, and never explicitly said so. Here's the missing section:
An important reason I started out with a comparison to early 90s games (and not, say, any of the great 80s games) is that around that time, it became practical to make adventure game art using physical media (e.g. matte painting) and then digitizing it, which is somewhat similar to what I'm attempting here — except there's no need to digitize DALL-E's paintings (already digital). Instead, I added postprocessing as a callback to the traditional digitization process. Here's an excerpt from a nice Sierra retrospective by Shawn Mills. Go read the whole thing, it's great:
""We started painting with traditional media and then had our programming team develop some amazing codecs to scan the artwork in. That also allowed us to key scenes for other people and send them overseas to places like Korea and have them paint them. So we could really up the production because we [alone] never would have been able to raise the quality of production that we wanted.""Bill Davis, first Creative Director at Sierra On-Line
So Sierra got more for less, and they did this by sending prompts to dedicated overseas painters (vs. learning to paint faster/better or hiring more in-house). Sound familiar?
There's still the sort of ""ugh"" reaction one might have to talking about efficiency and art in the same sentence, and I do feel that. It's more fun to learn a new skill, or to work closely with others.
What's not fun, though, is to watch a nice, practical article that's already way too long start to overflow with the author's opinions and speculation. That's what the comments are for.
14 comments
Really interesting post with some beautiful pics… i look forward to the game!
HP, many thanks! interesting read and useful input on how to make DALL-E iterate in ones desired way. I entertain the idea of trying it out. Did you btw read about google's new AI developments?
I've read a bit about Imagen, but haven't been able to check it out yet. The impression I have is that it beats DALL-E in some metrics even while conceptually simpler. See: https://github.com/lucidrains/imagen-pytorch
Serious training usually relies on cloud compute, but if you're a bit technical and have a decent GPU, it shouldn't be too hard to get started running pre-trained models on a home computer. I did some work with Torch/PyTorch years ago, and as always, the biggest difficulty was getting the graphics drivers to cooperate 🙂
Cool post, thanks for sharing!
If you are making a horror game you can also ask it to create sprite sheets for you: https://labs.openai.com/s/8B4slIjM974bCnL4aV413xbC
Hah. Morbidly curious to see those looped now.
Let calppey!
Let calppey o7
I came here via https://news.ycombinator.com/item?id=32490455 after talking with kjellesvig.
This is what you mentioned last time we met. Very cool that you realized your game graphics idea with DALL-E 2 queries.
Amazing article. Hope we’ll a lot of ai art in products and art soon, this is more than a domain evolution. Thanks for sharing!
Really Cool. I hope that this will increase the number of people who enter the game development. After the Tsukuru Game Maker, this is a new revolution!",3
101,"Rachel is a student at a US university who was sexually assaulted on campus. She decided against reporting it (fewer than 10% of survivors do). What she did, however, was register the assault on a website that is using novel ideas from cryptography to help catch serial sexual predators.
The organisation Callisto lets a survivor enter their name in a database, together with identifying details of their assailant, such as social media handle or phone number. These details are encrypted, meaning that the identities of the survivor and the perpetrator are anonymous. If you hacked into the database, there is no way to identify either party.
However, if the same perpetrator is named by two people, the website registers a match and this triggers an email to two lawyers. Each lawyer receives the name of one of the survivors (but not the name of the perpetrator). The lawyers then contact the survivors to let them know of the match and offer to help coordinate any further action should they wish to pursue it.
In short, Callisto enables the survivors of sexual assault to do something unprecedented: they can discover if their abuser is a repeat offender without identifying themselves to the authorities or even identifying the name of the abuser. They have learned something useful, and possibly helpful, without having given anything away. “Survivors can find it healing to know they are not the only one. They don’t feel it is their fault,” says Tracy DeTomasi, Callisto CEO. And there is strength in numbers. “Maybe one person doesn’t have a case, but two people do.”
The ability of two strangers to pool their knowledge without revealing any personal information to each other is a seemingly paradoxical idea from theoretical computer science that is fuelling what many are calling the next revolution in tech. The same theory enables, for example, two governments to discover if their computer systems have been hacked by the same enemy, without either government divulging confidential data, or two banks to discover if they are being defrauded by the same person, without either bank breaking financial data protection laws.
The umbrella term for these new cryptographic techniques, in which you can share data while keeping that data private, is “privacy-enhancing technologies”, or Pets. They offer opportunities for data holders to pool their data in new and useful ways. In the health sector, for example, strict rules prohibit hospitals from sharing patients’ medical data. Yet if hospitals were able to combine their data into larger datasets, doctors would have more information, which would enable them to make better decisions on treatments. Indeed, a project in Switzerland using Pets has since June allowed medical researchers at four independent teaching hospitals to conduct analysis on their combined data of about 250,000 patients, with no loss of privacy between institutions. Juan Troncoso, co-founder and CEO of Tune Insight, which runs the project, says: “The dream of personalised medicine relies on larger and higher-quality datasets. Pets can make this dream come true while complying with regulations and protecting people’s privacy rights. This technology will be transformative for precision medicine and beyond.”
The past couple of years have seen the emergence of dozens of Pet startups in advertising, insurance, marketing, machine learning, cybersecurity, fintech and cryptocurrencies. Governments are also getting interested. Last year, the United Nations launched its “Pet Lab”, which was nothing to do with the welfare of domestic animals, but instead a forum for national statistical offices to find ways to share their data across borders while protecting the privacy of their citizens.
Jack Fitzsimons, founder of the UN Pet Lab, says: “Pets are one of the most important technologies of our generation. They have fundamentally changed the game, because they offer the promise that private data is only used for its intended purposes.”
The theoretical ideas on which Pets are based are half a century old. In 1982, the Chinese computer scientist Andrew Yao asked the following question: is it possible for two millionaires to discover who is richer without either one revealing how much they are worth? The counterintuitive answer is that, yes, it is possible. The solution involves a process in which the millionaires send packets of information between each other, using randomness to hide the exact numbers, yet at the end of it, both millionaires are satisfied that they know who is the richer, without either of them knowing any other details of the other one’s wealth.
Yao’s “millionaires problem” was one of the foundational ideas of a new field in cryptography – “secure multiparty computation” – in which computer scientists investigated how two or more parties could interact with each other in such a way that each party kept important information secret and yet all were able to draw meaningful conclusions from their pooled data. This work led in the mid-1980s to a flourishing of increasingly mind-bending results, one of the most dazzling being the “the zero-knowledge proof”, in which it is possible for a person to prove to someone else that they have some secret information without revealing any information about it! It allows you, say, to prove that you have solved a sudoku without having to reveal any details of your solution. Zero-knowledge proofs involve a process, as with the millionaires problem, in which the prover sends and receives packets of information in which crucial details are obfuscated with randomness.
Another valuable instrument in the Pet toolbox is “fully homomorphic encryption”, a magical procedure often called the holy grail of cryptography. It enables person A to encrypt a dataset and give it to person B, who will run computations on the encrypted data. These computations provide B with a result, itself encrypted, which can only be decrypted once passed back to A. In other words, person B has performed analytics on a dataset while learning nothing about either the data or the result of their analytics. (The principle is that certain abstract structures, or homomorphisms, are maintained during the encryption process.) When fully homomorphic encryption was first mooted in the 1970s, computer scientists were unsure it would even be possible and it was only in 2009 that the American Craig Gentry demonstrated how it could be done.
These three groundbreaking concepts – secure multiparty computation, zero-knowledge proofs and fully homomorphic encryption – are different ways that data can be shared but not revealed. In the 1980s, during the early years of research, cryptographers were not thinking that these innovations might have any practical uses, in large part because there were no obvious real-world problems to which they were a solution.
Times have changed. The world is awash with data, and data privacy has become a hugely contentious political, ethical and legal issue. After half a century in which Pets were essentially arcane academic games, they are now seen as a solution to one of the defining challenges of the digital world: how to keep sensitive data private while also being able to extract value from that data.
The emergence of applications has driven the theory, which is now sufficiently well developed to be commercially viable. Microsoft, for example, uses fully homomorphic encryption when you register a new password: the password is encrypted and then sent to a server who checks whether or not that password is in a list of passwords that have been discovered in data breaches, without the server being able to identify your password. Meta, Google and Apple have also over the last year or so been introducing similar tools to some of their products.
In addition to new cryptographic techniques, Pets also include advances in computational statistics such as “differential privacy”, an idea from 2006 in which noise is added to results in order to preserve the privacy of individuals. This is useful in applications such as official statistics, where simple averages can reveal private information about people coming from minority groups.
Much of the recent investment in Pets has come from cryptocurrencies. Earlier this year, crypto-exchange Coinbase spent more than $150m to buy Unbound Security, a multiparty computation startup co-founded by Briton Nigel Smart, professor of cryptography at KU Leuven in Belgium. “In the blockchain space, multiparty computation is now everywhere,” he says. “In the last year it has gone from ‘will this work?’ to being standard.”
He believes Pets will eventually spread across the entire digital ecosystem. “This is the future. It is not a fad. What this tech allows you to do is collaborate with people you wouldn’t have thought of collaborating with before, either because it was legally impossible to do so, or because it wasn’t in your business interest, since you would have been revealing information. This opens up new markets and applications, which we are only just starting to see. It’s like in the early days of the internet, no one knew what applications would come along. We are in the same situation with Pets.
“I think it is becoming more and more intrinsic. You see it everywhere. All data will eventually be computed with privacy-enhancing tech.”
The current applications of Pets are niche, partly because the technology is so new, but also because many people are unaware of it. Earlier this year, the UK and US governments jointly launched a £1.3m prize for companies to come up with ideas to “unleash the potential of Pets to combat global societal challenges”.
Yet some uses are already having an effect, such as Callisto. DeTomasi says that 10-15% of survivors who have used the site have had matches, meaning that their assailants have numerous victims. DeTomasi does not know the names of any survivors with matches, or the names of the assailants, since the system keeps them secret. (The “Rachel” mentioned in the introduction is an invented name for the purposes of illustration.)
DeTomasi does say, however, that 90% of sexual assaults on campuses are by serial offenders, who on average will perpetrate six times during their college year. “So if we stop them after two times, we are preventing 59% of assaults from occurring.” Callisto is currently available at 40 universities in the US, including Stanford, Yale, Notre Dame and Northwestern, and the plan is to roll it out to all universities. “It is definitely needed,” she adds, “and it is definitely working.”
The secret life of Pets
Four of the most important privacy-enhancing technologies
Secure multiparty computation
Allows two or more parties to compute on their shared data, without any party revealing any of their private data.
Zero-knowledge
Allows a person to prove to another person that they know something is true, without revealing any information on how they know it is true.
Fully homomorphic encryption
The so-called holy grail of cryptography, in which it is possible to run analytics on encrypted data without decrypting it first.
Differential privacy
A way of adding noise to data that preserves privacy.",5
102,"By Christa Keizer & Michele McDanel
What’s the first thing that comes to mind when you think of “disability”? In the context of product design, we might first think of vision loss, hearing loss, web content accessibility guidelines (WCAG), screen readers, and/or wheelchairs. These are all, of course, extremely important to consider in design, but to be truly inclusive, we must also design for users with barriers that may not be immediately obvious. Invisible disabilities are those that might not be immediately apparent; in some cases, they may not even be medically diagnosed. (Half of people with disabilities cannot afford healthcare.)
Those who identify as having an invisible disability face social stigma and therefore do not always disclose their disability to those around them.
Lesser-known invisible disabilities as defined by the medical model of disability include:
- Learning difficulties like dyslexia (difficulty with reading), dyscalculia (difficulty with numbers), and dysgraphia (difficulty with writing);
- Developmental coordination disorder or dyspraxia;
- Mental health conditions like depression, anxiety, post-traumatic stress disorder (PTSD), obsessive compulsive disorder (OCD), and bipolar disorder;
- Developmental disabilities like autism and ADHD;
- Pain-related conditions like fibromyalgia, migraines, arthritis;
- Digestive and immune disorders like celiac disease, irritable bowel syndrome (IBS), diabetes;
- Reproductive conditions like fibromyalgia, polycystic ovary syndrome (PCOS), endometriosis, and premenstrual dysphoric disorder (PMDD);
- And many others.
We might also consider users who are not medically disabled but are invisibly disabled by something, like the stress of a global pandemic.
No person is broken. Fix the system.
More than 1 billion people worldwide live with a disability. The unemployment rate of disabled people is twice that of non-disabled people and half of people with disabilities cannot afford health care. The social model of disability argues that the disability divide is created by failures of systems, not the disabilities themselves while the medical model of disability often sees disability as the subject needing to be “fixed.” Using the social model of disability, we ask ourselves if the technology we develop creates or removes barriers for users who are already experiencing challenges in a physical world that was not designed for them. For example, an overwhelming interface may be disabling to information workers who have sensory processing challenges and notifications may be disabling to a user who is trying to focus on a project.
How might we design for users with invisible disabilities?
Researching and designing for users with invisible disabilities is more achievable than ever. Here are three tips to get you started:
1. Do your homework early and often
Starting your project with a literature review can give you and your team an initial look into users’ attitudes, perceptions, behaviors, and challenges, helping you generate hypotheses that can later be tested.
You might consider immersing yourself in social media content created by people with disabilities. Although this method may be a bit unconventional, social media can be a uniquely valuable source of lived experience from the disabled community. Simply searching for the name of the disability along with a topic you’re exploring (e.g., email, productivity, communication) can elicit honest product reviews from users with disabilities. In the example below, Molly Burke shares her experience using makeup palettes and Laura Hammock shares her favorite organizational applications. (Be sure to then validate your generated hypotheses with primary research, of course.)
2. Include research participants with disabilities.
When researching disabilities, keep “Nothing about us, without us” in mind. A literature review can’t replace primary user research, so avoid making assumptions (especially those that are based on stereotypes) about disabled user groups without incorporating their lived perspectives.
15 percent of people experience a disability, so researchers should make a habit of including disabled users in their studies.
Research shows individuals are open to disclosing their invisible disability if the disclosure is expected to yield positive results. This indicates that potential research participants may be open to disclosing their invisible disability to be part of a research study. Check out this practical guide to inclusive research for more tips on running inclusive research studies.
3. Employ universal design principles.
We can also critically assess our products using the universal design principles, which were created in 1997 by designers, architects, engineers, and researchers to evaluate the universal accessibility of environments and products. Universal design principles include:
- Equitable in use: The design is useful and marketable to people with diverse abilities.
- Flexibility in use: The design accommodates a wide range of individual preferences and abilities.
- Simple and intuitive: Use of the design is easy to understand, regardless of the user’s experience, knowledge, language skills, or current concentration level.
- Perceptible information: The design communicates necessary information effectively to the user, regardless of ambient conditions or the user’s sensory abilities.
- Tolerance for error: The design minimizes hazards and the adverse consequences of accidental or unintended actions.
- Low physical effort: The design can be used efficiently and comfortably and with a minimum of fatigue.
- Size appropriate for user: Appropriate size and space is provided for approach, reach, manipulation, and use regardless of user’s body size, posture, or mobility.
Universal design principles can be used throughout the design process to ideate new solutions and critique existing experiences.
Wrapping it all up
Inclusive research is the first step to building a more accessible future for everyone. While it may seem intimidating to incorporate disability into your user research, a great first step is talking with your team about how you’ll design for users with disabilities. We have included additional articles, some discussion prompts, and an outline for a disability workshop below to help you with those efforts.
Resources
Further reading
AI and Accessibility: A Discussion of Ethical Considerations
Our Responsibility: Disability, Bias, and AI
What is Universal Design | Centre for Excellence in Universal Design
Disability Statistics | The National Disability Authority (nda.ie)
Discussion prompts
- Do you or someone you know have an invisible disability? How is their workday, behaviors, or work style unique from yours?
- Think of a time when users with invisible disabilities may have been disproportionally impacted by a proposed design solution. Were these users in your research samples? Why or why not?
- What’s an upcoming project that would uniquely impact someone who:
- Has memory lapses from a former brain injury?
- Has difficulty making mathematical calculations (dyscalculia)?
- Prefers written communication over meetings?
- Is color blind?
45-minute invisible disability workshop
- Divide your group into teams of three.
- Assign each group with a unique scenario and a unique invisible disability. Examples might include: joining an online meeting with social anxiety, managing daily tasks with a brain injury, attending an hour-long remote workshop with ADHD, going to a workplace cafeteria with autism.
- Allow each group to spend 15 minutes to research their group’s disability online using social media and reputable academic sources.
- Allow each group to spend 15 minutes plotting their findings on an empathy map. (Groups can use PowerPoint, Microsoft Whiteboard, or any other collaborative software.)
- Give time for each group to present what they learned using the completed empathy map.
What do you think? How will these ideas and resources help you better understand and design for those with invisible disabilities? Tweet us your thoughts at @MicrosoftRI or follow us on Facebook and join the conversation.
Christa Keizer is an Outlook Calendar design researcher who passionately advocates for inclusive design, mental health, and sustainability.
Author note: In this post I use both person-first language (PFC) and identity-first language (IFL) interchangeably. I am using both models because as a disabled person myself, I personally use identity-first language when describing my disabilities, while some disability communities prefer person-first language. My intent is to always use language that each community prefers.
Michele McDanel is a builder, an organizer, and a storyteller with a bachelor’s degree in Communications and an MBA. She is energized by solving problems and meeting business needs through communications and customer experience solutions that raise the bar. Michele enjoys building relationships and managing teams; and overall, just figuring out what the “special sauce” is that will be the competitive differentiator for a business and its solutions. She joined the Customer Insights Research team in 2019 to amplify the great UX research and data science work they do, and to showcase the thought leadership of the team across internal and external communications, events, and social media.",1
103,"About MCH 2022
MCH2022 is a nonprofit outdoors hacker camp taking place in Zeewolde, the Netherlands. From 22 to 26 july 2022.
The event is organized for and by volunteers from and around all facets of the worldwide hacker community.
Knowledge sharing, technological advancement, experimentation, connecting with your hacker peers and of course hacking are some of the core values of this event.
MCH2022 is the successor of a string of similar events happening every four years since 1989. These are GHP, HEU, HIP, HAL, WTH, HAR, OHM and SHA.
Similar events are EMF 2022 in the UK, Bornhack 2021 in Denmark, Fri3d Camp in Belgium, IHC in Italy and CCC Camp 2023 in Germany.
The location is the Scoutinglandgoed Zeewolde, 55km east of Amsterdam.
View more info on the wiki
Further reading
These links go to various systems of MCH2022.
Thank you for visiting MCH2022.org, hope to see you at the event!",2
104,"Bigbug
|Bigbug|
|Directed by||Jean-Pierre Jeunet|
|Written by|
|Produced by|
|Starring|
|Cinematography||Thomas Hardmeier|
|Edited by||Hervé Schneid|
Production
companies
Eskwad
Gaumont Film Company
|Distributed by||Netflix|
Release date
|Country||France|
|Language||French|
Bigbug is a French science fiction black comedy film, written and directed by Jean-Pierre Jeunet, that was released on 11 February 2022 by Netflix.[1][2] It stars Elsa Zylberstein, Isabelle Nanty, Youssef Hajdi, Alban Lenoir and François Levantal.[3] Set in the world of 2045, where communities have robotic helpers, a group of suburbanites are locked in for their own protection by their household robots, while a rogue, sentient AI android revolt uprising outside.
Synopsis[edit]
In 2045, artificial intelligence is everywhere. So much so that humanity relies on it to satisfy its every need and every desire even the most secret and wicked. In a quiet suburban residential area, four domestic robots suddenly decide to take their masters hostage in their own home. Locked together, a not-quite-so-blended family, an intrusive neighbour and her enterprising sex-robot are now forced to put up with each other in an increasingly hysterical atmosphere. While, outside, the Yonyx, the latest generation of AI androids, are becoming rogue and trying to take over the world. As the threat draws closer, the humans look elsewhere, get jealous, and rip into each other under the bewildered eyes of their indoor robots. Maybe it's the robots who've got a soul or not.
Cast[edit]
- Isabelle Nanty as Françoise
- Elsa Zylberstein as Alice
- Claude Perron as Monique
- Stéphane De Groodt as Max
- Youssef Hajdi as Victor
- Claire Chust as Jennifer
- François Levantal as Yonyx leader
- Alban Lenoir as Greg
- Marysole Fertard as Nina
- Hélie Thonnat as Léo
- Dominique Pinon as Igor
Production[edit]
Filming began in October 2020 despite the COVID-19 pandemic.[4]
Reception[edit]
On the review aggregator website Rotten Tomatoes, 42% of 24 reviews are positive, with an average rating of 5.70/10.[5] On Metacritic, the film has a weighted average score of 47 out of 100 based on 13 critics' reviews, indicating ""mixed or average reviews"".[6]
References[edit]
- ^ François Léger (January 21, 2020). ""BigBug : Jean-Pierre Jeunet dévoile le casting de sa comédie de SF sur Netflix"". Premiere (in French). Retrieved January 24, 2021.
- ^ Lattanzio, Ryan (December 27, 2021). ""'Bigbug' Trailer: Jean-Pierre Jeunet Makes Netflix Debut with Raunchy Robot Comedy"". IndieWire. Retrieved December 28, 2021.
- ^ Francois, Jean (January 21, 2020). ""The production of ""BigBug"" was officially announced"". jpjeunet.com. Retrieved January 24, 2021.
- ^ ""BigBug : Jean-Pierre Jeunet a commencé le tournage de son film Netflix"". Première (in French). October 5, 2020. Retrieved March 17, 2021.
- ^ ""Bigbug"". Rotten Tomatoes. Retrieved February 12, 2022.
- ^ ""Bigbug"". Metacritic. Retrieved February 12, 2022.
External links[edit]
- 2022 films
- 2022 black comedy films
- 2022 science fiction films
- 2020s satirical films
- Utopian films
- Films about artificial intelligence
- Government by algorithm in fiction
- Android (robot) films
- Robot films
- French-language Netflix original films
- Films directed by Jean-Pierre Jeunet
- Films set in 2050
- French science fiction comedy films
- French satirical films
- Gaumont Film Company films
- 2020s French films
- 2020s French-language films",8
105,"A concerned Autodesk representative pulled me aside at an event recently. “I read your article,” she began.
I tried to recall whether I’d said anything controversial. But my most recent article was relatively tame, just 1,300 words in Architect Magazine about algorithms generating building layouts. If anything, it was complimentary of Autodesk.
Around us, people at the conference were discussing the industry’s most pressing issues – robots, automation, climate change. The representative leaned in to reveal hers: “I noticed you didn’t mention generative design in your article.”
The representative worked for Autodesk’s communications team. As you’ll be aware, Autodesk has been ramping up its efforts to brand and promote generative design, putting out a series of videos, articles, and presentations that tout the benefits of the generative process. Others in the industry have followed suit, announcing their own generative design tools in superlative laced press releases. None of this is new. People have been peddling generative design as far back as the 1980s. But it never had the clout of someone like Autodesk. After years of never really going anywhere, suddenly everyone is talking about generative design. Suddenly it feels inevitable.
The Autodesk representative seemed taken aback when I told her that I didn’t believe the hype. That I avoided using the term ‘generative design’ in the article because I didn’t think it was worth promoting. That it was a distraction. A white whale. That it wasn’t the future of design, or anything. That it was a dead-end. That something more significant was happening. That I needed more time to explain.
On the surface, generative design is an enticing vision. Rather than employing a designer to laboriously create a design concept, you can instead use an algorithm to quickly generate thousands of options and ask the designer to pick the best one. Effectively, the designer becomes an editor. They specify the goals of the project, an algorithm churns out an array of options, then the designer returns to select the strongest idea, and – voilà – you’ve got a building. Since the algorithm can produce countless design concepts, the designer can, in theory, consider more possibilities than they would on a typical project, improving the chances of finding an optimal design or discovering a novel solution. A better design with less effort, what’s not to like?
Some of you are going to disagree with how I’ve characterized generative design. In the current vernacular, the term ‘generative design’ has a reasonably loose meaning. This isn’t unusual — other technical terms like ‘parametric’ or ‘machine learning’ have grown more vague as they have become more popular. In the case of generative design, the word ‘generative’ is often confused as a catch-all for ‘generated’. Throughout this article, I’m going to refer to generative design as a three-stage process where (1) designers define the project’s goals, (2) algorithms produce a range of solutions, and (3) then designers pick the best result. Although you might quibble with this definition, this is how Autodesk defines generative design today, and it’s what many people are currently pushing as the future of design. For the purposes of this article, I’m only focused on this prevailing definition (if you think this process shouldn’t be called ‘generative design,’ if you’d rather call it optioneering or something else, you can change the name used in this article).
Whatever you want to call it, I’m deeply concerned that many in the industry are advocating that generative design is the future of architecture. As I’ll explain in this article, once you get beyond the marketing hype, there are real technical and human reasons why generative design’s three-step process is doomed to fail.
The Worst Way to Write an Email
To understand the absurdity of generative design, I think it helps to imagine generative design in a different context, to see it as a naked idea without the baggage of the architecture industry.
Consider email. According to McKinsey, the average worker spends about 11 hours a week reading and answering emails. Each email is hand-crafted, letter by letter, word by word. Clack, clack, clack. It’s easy to see why talented people hate doing this menial work.
So why not reinvent email? Rather than typing out each email, why not have an algorithm generate the first draft? Or a hundred first drafts? Why not make a generative email program? You pick the subject, an algorithm writes some options, you read them, choose the best, and hit send. Not only would you save time, but you’d also probably end up sending better emails because you can explore more possibilities and spend longer considering what you’re saying. What’s not to like?
All of this is technically possible. In fact, I’ve mocked up a quick prototype below.
GenerativeMail
Created with gpt2, gpt2 Cloud Run, and Paracord
Why Generative Design Doesn’t Work
I imagined that it’d be instructive to see generative design used in the most ridiculous way possible. But as I ran the generative email program for the first time, I was no longer sure if it was such an absurd concept. I mean, sure, most of the emails were incoherent, but every now and again one of them would be unexpectedly erudite. In those moments, you could see the potential. You could imagine that with better algorithms, an improved interface, and faster computers that this crazy idea might actually work.
Generative design often appears close to working. It’s been that way for decades. Time and time again we’re strung along by seductive demonstrations and fooled into thinking we’re on the cusp of a breakthrough. These demos are easy enough to create. Take an algorithm that spits out hundreds of random designs, develop an interface to display them, combine, and you’ve got a passable mockup of generative design. Want to truly impress? Apply your prototype to a simplified design problem and explain that it’ll work just the same in a complicated, real-life situation. If there are any concerns about the quality of results, draw upon your inner techno-optimist to explain that the algorithm will improve with time. It’s that simple. It’s the sort of thing you can create in a weekend, on a lark, to illustrate a blog post.
While it’s trivial to show that generative design is possible, it’s much harder to take the next step and show that generative design is useful. In fact, it rarely happens. This is the real challenge of generative design: going from the plausible to the practical. Up until now, we’ve just been doing the easy bit, we’ve been showing that it’s possible. This feels like progress, yet the hard part is still to come. I don’t want to be a downer, but I don’t think we’ll get there. By my count, there are 6 major reasons why generative design is unlikely to progress.
1. You’re on the hook for generating the options
The way generative design is sold, it often appears that a designer only involved in defining the project’s goal and picking the best options. In reality, the designer is also responsible for creating the algorithm that generates the plans. Which is no small feat.
In the generative email program, the text is written by an algorithm called GPT-2. This program, developed by OpenAI, builds upon decades of research on neural networks and natural language processing. The result is an algorithm that can write everything from New Yorker articles to Harry Potter screenplays (GPT-2 was so convincing that OpenAI initially held it back, calling the software ‘too dangerous to release’ because of it’s ability to automate the production of fake content).
There is no GPT-2 for buildings. That is to say, if you’re using generative design, there is no pre-built mechanism for generating all the design options. Instead, you have to create your own system. From scratch. This is a bit like creating a factory that manufactures design schemes. If the factory is repetitively making a reasonably uniform product, then it’s relatively straightforward to setup. But if you want to produce a lot of variation, then it can get really complicated. In many cases, it will take more time and skill to set up the factory compared to doing the work manually. To avoid this complexity, people tend to limit what the factory can produce, which is why demonstrations of generative design often churn out hundreds of similar-looking design options. Rather than exploring the full range of design outcomes, you end up exploring what the algorithm can create. Often this produces less exciting outcomes and takes longer than you’ve been led to believe.
2. Quantity doesn’t substitute for quality
If your boss asks you to sketch out a proposal, what is the right number of plans to produce? Perhaps you’d return with 3 to 5 ideas. If you’re feeling confident, you might advance just a single proposal. But you’d never, in any situation, come to your boss with a presentation containing 100 different schemes. It’d be absurd.
Yet, with generative design, we routinely generate hundreds of different options. And we celebrate this like it’s a virtue. The thinking is simple: the algorithms can’t tell good ideas from bad, but they can create designs incredibly quickly, so if we rapidly produce hundreds of options, we increase the chances of inadvertently generating a good design. Effectively, we buy more lottery tickets.
The deluge of options obscures the fact that most of the outcomes aren’t viable. In the case of the generative email program, if the algorithm was any good, it’d be able to select the 3 to 5 most compelling drafts. If it was really confident, it’d select just one. But instead, we have algorithms that thoughtlessly create hundreds of options. This isn’t a virtue, it’s not the future, it’s a byproduct of lousy software. The fact of the matter is: one hundred shitty designs aren’t anywhere equivalent to one considered design. If your software was any good, it’d produce fewer designs, not more.
3. Comparing options is harder than it looks
Once you’ve generated all of these options, a person needs to select the best proposal. This is one of the main appeals of generative design – the algorithm handles the laborious work of creating the options, and all you have to do is sit back and pick your favorite.
It sounds leisurely, but it is actually difficult work. Ask any professor: would you rather grade 100 student essays or write one article of your own? Truth is, it takes effort to consider a design option seriously. And the challenge of evaluating different options only increases as the output becomes more involved and more complex. For example, 100 emails can be skimmed relatively quickly, but 100 books would require a lot of reading. Now imagine comparing 100 different buildings, I mean really comparing them, not just skimming through the images – oy vey!
Further complicating things, humans hate having too many choices. More choices give us more opportunities to make the wrong decision (which is something we fear), and the choices make it cognitively challenging to recall options and draw comparisons. This is sometimes called ‘overchoice’ or ‘the paradox of choice.’ Research shows that we particularly dislike being given a lot of similar alternatives, as is often the case for generative design, since there is no clear winner, leaving us to make a seemingly impossible choice between nearly identical options.
To put it simply, presenting designers with a lot of options is generally a terrible idea. Designers will find it stressful, they’ll struggle to make meaningful evaluations and comparisons, and it might not save as much time as you’d expect because it’s such an involved process to do well.
4. What you can measure isn’t what matters
Proponents of generative design argue that having too many options isn’t a problem because you can always hide the bad ones. You just need to measure the performance of each option and remove anything that doesn’t match the designer’s performance criteria.
In the generative email program, you can filter the emails by length. Admittedly, the length isn’t the best performance metric, but it’s easy to calculate. Perhaps in the future, we’ll be able to measure more critical factors, like the text’s persuasiveness or wittiness. But it’s not guaranteed that we’ll get there. Just because you can count the number of words in an email, doesn’t mean that one day you’ll be able to measure these more visceral concepts.
In the field of architecture, there’s no consensus on what constitutes good architecture and no established ways of measuring it. So we measure something else. In the 1960s and 70s, a lot of research focused on evaluating buildings in terms of walking times between rooms, which was easily calculated but not particularly important. Today, we might look at solar gain or view analysis, which is a component of architectural performance but not the full story. Perhaps in the future, we’ll be able to quantify other more visceral aspects of architectural performance, but I’m not holding my breath.
For people using generative design, this puts them in a bind. They can either use these arbitrary metrics and end up optimizing for the wrong thing, the thing that can be easily measured. Or they can ignore the metrics and wade through a lot of unfiltered options. I don’t see this situation improving any time soon – architectural performance is so complicated that we may never get to a place where we can quantify it and use it as a filter.
5. Designers don’t work like this
Generative design simplifies the design process into three steps: briefing, ideation, and deciding. This is a gross simplification of what architects actually do. It feels like a caricature cooked up to tease designers, ‘oh, you know those melodramatic architects, all they have to do is take the brief, create a bunch of options, and pick their favorite, what’s so hard about that?’ Honestly, it’s insulting.
Study after study has shown that designers don’t follow a linear process, that design is necessarily messy and iterative. You experience this writing emails. You’ll write something down, re-read it, realize it sounds wrong, revise, re-read, edit, and iteratively work towards a final draft. At WeWork, Andrew Heumann recorded architects as they worked, and observed a similar pattern as he watched designers rapidly cycle between macro and micro changes, between the broader project objectives and the specific implementation.
In demonstrations of generative design, the iterative nature of the design process isn’t apparent because there are no real stakes. You don’t have the pressure of design reviews, the insanity of client revisions, budget cuts, and public submissions. You’re playing a designer on easy mode.
On a real project, you’ll never get it right the first time – the generative design algorithms aren’t good enough, and the circumstances of the project will change once you’ve created your first draft. So you have to make revisions. And generative design doesn’t accommodate revisions since it assumes the design process only moves forward. To make a revision, you either need to throw everything out and start the generative design process again, or you can abandon using generative design and make the change manually. Either way, generative design makes it hard for designers to work iteratively.
6. No one else works like this
The most damming indictment of generative design is that you don’t see it used in other creative fields. Adobe isn’t holding press conferences saying that generative design is the future of graphic design (InDesign will just be an interface where you upload your text, the software creates 100 different page layouts, and the designer picks their favorite). Apple isn’t pushing generative design for Final Cut (upload your raw footage, the software edits 100 different films, you watch them all, and pick your favorite). Microsoft isn’t adding generative design to Word. Autodesk isn’t even hawking generative design to their other key markets, such as media and entertainment.
To be fair, some things on the market today that resemble generative design. Spotify, for instance, will automatically generate several playlists and let you pick your favorite to listen to. But Spotify has an advantage, they can build this once and sell it to millions of customers, they’re not creating a one-off algorithm to redesign their office. Additionally, the interface is quite different to what we’ve been calling generative design – you don’t give Spotify a brief, and the software only produces a handful of carefully curated options (it’s not randomly putting songs into hundreds of different playlists).
The only place that I’ve really seen generative design thrive is on flight booking websites. These websites essentially take you through a generative process: 1) you specify the dates and destination, 2) the software generates dozens of different itineraries, 3) and you filter the routes by time, cost, and stopovers, and then select the best one. It works well. But anyone that’s used Google Flights and thought that it’d make a good design interface is out of their fucking mind.
If not generative design?
Generative design is our industry’s white whale. We’ve spent years hunting it with money, PowerPoint slides, and armies of interns. You get the sense that we’re within striking distance, and yet we’ve never landed it. It feels like we’ve made progress, and yet there are seemingly insurmountable challenges ahead. It feels possible, and yet never quite practical.
My concern is that many companies have jumped on the generative design bandwagon, swept up in the mania, never pausing to consider why this hasn’t worked previously or why other design industries aren’t onboard.
A lot of this would be avoidable if we had a better understanding of how design actually gets done inside architecture firms. Truth is, we know shockingly little about how design happens – especially in a digital world. As a result, people end up prophesizing about the future of the design, based not on an understanding of the design process, but on an understanding of the technology. Often this comes with fairly naive and condescending assumptions about the work that designers do, which makes concepts like generative design seem reasonable, perhaps even desirable.
Until we get to a point where algorithms replace designers (which may never happen), algorithms will only be practical if they work with humans. The real challenge isn’t the technology, it’s the interface, it’s how the algorithms fit the designer and their process. Generative design asks designers to change this process, to follow a stilted three-stage procedure.
To me, a more fruitful path seems to be taking the existing process and finding ways to enhance it with algorithmic smarts. Consider email. The process is similar to typing a letter on a typewriter, except you’re surrounded by spell-checkers, predictive keyboards, smart compose functions, bots, spam filters, and email prioritizers that all work alongside you, assisting, guiding, and bettering your writing. Creators of other design tools, such as Adobe, have gone in a similar direction, developing algorithms that work within existing design processes. In Photoshop, for instance, Adobe has developed targeted tools that automate specific procedures (such as content-aware fill and smart object selection). The designer works in a familiar manner, but computation is helping accelerate tedious tasks and guiding the user through challenging decisions.
In the end, I get the appeal of generative design. It’s alluring, captivating, and perhaps even inspiring. But generative design’s problems with choice overload, imprecise metrics, and a lack of design integration are so core to how it operates that they’re probably insurmountable. Or at least not easily solved by the usual trio of proposed solutions: better algorithms, an improved interface, and faster computers. Ultimately, I worry that generative design has become a distraction. I’m left wondering what might have happened if we were guided by the process instead of the technology.
I’d like to thank Andrew Heumann and Nathan Miller for their thoughts and comments on an earlier draft of this article. I’d also like to apologize to all my friends working on generative design applications – I love you all.
SEC Disclosure: I own a small amount of Autodesk stock because ultimately I have more faith in Autodesk’s marketing team than any of the arguments in this post. Nothing in this article should be taken as investment advice.
29 replies
Sayjel
Hi Daniel – We met at a conference a few years back. Totally agree with the premise of your article. Just wanted to share with you the work my startup is developing which focusing on a more natural human interfaces to algorithmic design. Curious to hear what you think. Here is a recent blog post I wrote about our thinking:
https://medium.com/@sayjelpatel/augmented-intelligence-for-sustainable-design-and-architecture-2f96a2fac95e?source=friends_link&sk=8d4917c8d78fbf24adfd04ca1d23fb31
Daniel Davis
Hey Sayjel, I really like where you’re going with the augmented design tools. From my perspective, what you’re working on looks pretty slick, particularly how the designer can go back and draw changes while the algorithm works around them. But I think the real test will be how urban planners use the tool and whether it makes sense with their process. I’m looking forward to following your progress!
Yongjoon Kim
Thanks for this great article! So much resonance in this argument. I’ve been into this ‘generative design’ or ‘automated layout’ approach, but ended up finding that it has a risk to undermine our creative field. What needs to be automated is those trivial, tedious, and repetitive tasks, not the massing or layout which is THE most critical part of the architectural design. It reminds me of one of my school projects: A dumb algorithm that generates hundreds of ‘Bjarke-esque’ massing and see how we can develop the design in reverse-engineering. And I ended up realizing that what adds a huge value to architecture is those painful and mentally exhausting processes during a design decision making, in which we reveal our true creativity as a human being. (And that’s when we grow as an architect I believe!)
Ironically, this is why I still think that generative design(or whatever it is called) has a potential, while some architects are worried that it will take their jobs. I think it’s opposite. Technologists and designers can work together and determine which parts of a design process is the biggest waste of time, automate it, and give the time back to the designers such that they can use those times for more sophisticated and meticulous decision makings.
Kris Weeks
Daniel, this is a really thoughtful article. I’ve had similar thoughts but have not articulated them nearly so clearly or thoughtfully as you have. Thank you.
Kai
I feel like I am out of the loop… isn’t Autodesk’s “generative design” just an evolutionary algorithm? I don’t really understand why it’s getting so much hype. I thought it was obvious that it would only really be useful for design problems which have very clear criteria for success and multiple competing variables. Hence why the best use cases are within an engineering context; more of an optimising process than a “generative” one.
If Autodesk thinks that generative design will be the next big thing for architecture, to use your own words they are out of their fucking mind. Design and especially architectural design is an inherently wicked problem and a practice driven by theory. Until we get general artificial intelligence, I don’t see algorithms designing buildings on their own.
I enjoy reading these articles, please keep it up. I feel like there is not enough thoughtful critique and theorising of how technology continues to impact architecture.
Regards,
Kai
ralphg820
Autodesk also has generative design for Fusion 360 in its mechanical CAD division, but for Inventor users it is very awkward to access.
Gpt2
Hi Daniel,
Generative Design was my first post, and I know all your readers from your blog. It is really nice to read your blog again, and to say that you like my blog. For the past year or so, I have been writing a lot about the power of design in the application industry, and I always come across a lot of interesting ways to achieve great results. I hope I will be able to contribute to your post in a timely fashion, as I hope you will also be willing to share your thoughts. Also, I also want to share with you my thoughts on the direction of the development process in the design industry.
Warm wishes,
Gpt2
Chris Wilkes
Hi Daniel,
Thank you for writing this article. I differ with your opinion of Generative Design, but understand the argument you made. If GD is being evaluated only in architectural cases and the only GD solution studied is Autodesk then your conclusion is spot on. The line that best summaries the problem comes from you as “To put it simply, presenting designers with a lot of options is generally a terrible idea.”
But in the mechanical engineering world, we use GD frequently. And we use software that limits the design options based on specific criteria so the user is not flooded with an extensive array of ideas. AI (limited) is used to narrow the options. Our definition of GD comes from an recent paper by the ASSESS Initiative and says:
““Generative design is the use of algorithmic methods to generate feasible designs or outcomes from a set of performance objectives, performance constraints, and design space for specified use cases. Performance objectives and constraints may include factors from multiple areas including operational performance, weight/mass, manufacturing, assembly or construction, usability, aesthetics, ergonomics, and cost.”
A detailed explanation of Generative Design for our field is here: https://enginsoftusa.com/what-is-generative-design.html.
The Altair Inspire software is a good example of how intelligence is added into the GD process.
The software you reference does little to provide intelligence to the process of choosing an optimal design. But with improved intelligence, GD can provide creative ideas to solve some very complex design challenges. In particular, when we add constraints around how a part will be manufactured, software can show us only those designs that can actually be built by that method. For example, subtractive manufacturing can only build certain designs and 3D printing can to others.
With improvements in the intelligence in the software, it is certainly possible that GD will have better utility in your field as well.
Daniel Davis
Hey Chris,
Thanks for sharing your perspective of using generative design outside the field of architecture. I’ve got to admit I have a fairly heavy bias towards architecture and I was really trying to push back against this idea that generative design is likely to be a prominent part of the architectural design process. That said, I can see how generative design would function in situations where the constraints are known, the performance criteria is easy to define, and the underlying algorithm for generating the options can generalize across many similar problems. It’ll be interesting to see how much further this can be pushed in for mechanical engineering.
Daniel
Sean
Thank you for writing this. As someone who has part of a design “automation” push at multiple offices, having to go through these exercises is time-consuming and pointless. We invariably make a tool specifically for 1 project, and try to make it as universally usable as possible, but some variable is always different, needing updates to the definition/script, new variables to evaluate the options by, etc.
My fear is that this isn’t ‘doomed to fail’ completely. My fear is that developers and builders co-op this the same way they’ve co-opted minimalism and modernism. A race to the bottom of the design barrel, where the only consideration is cost, and the quality of the building is never thought about. I think that’s where this technology will wind up living. An algorithm that takes into efficiency and cost inputs will be used, and the option that maximizes those will be picked, damn everything else. Maybe I’m wrong, but that’s where I see the future of “generative design” going.
Daniel Davis
I really hope it doesn’t go that way. From my point of view, it seems that there is still a lot of room to experiment with different interfaces for embedding computation within the design process. Even with Autodesk sucking up a lot of the oxygen, I look at things like UpCodes or TestFit and it gives me hope that people are going to find better ways of doing this.
Marcelo Bernal
Thank you for refreshing the discussion around this topic. Before discrediting the efforts of an entire community of researchers, I think there is a deeper conversation regarding when GD along the design process can effectively contribute, the different techniques to generate design populations (brute force, stochastic, or statistical sampling), data visualization and analytics, methods for decision making, or the evolution of the design culture itself (which if highly unstructured). If you are criticizing ADSK, agreed. They totally miss the point, but mainly because of managerial decisions, not because of the quality of the research team. On the other hand, at the corporate research level, I have seen specifically in the Advancing Computational Building Design conference many examples of successful implementations in schematic design stage ranging from open ended apparently creative process to very narrow design space explorations. In my experience, yes, designers get overwhelmed in the beginning when I present 2000 variation, however once they see the power of data analytics, for example sensitivity analysis, they just love it.IN fact, they have learn how to use the data to better communicate with clients. In addition, we cannot disregard an entire generation of computational designers currently in college that will be influencing the practice. Let’s talk in five years from now.
Dan Peel
Daniel,
Thanks for the article – i think its really important to show both sides of an argument.
I agree with the points you make (and you make them well!) but they don’t lead me to the conclusion that ‘generative design is doomed to fail’. Instead i think they highlight the importance of choosing the right tool for the job – which is true of any tool. “It is easy to inadvertently optimize for the calculable rather than the important” – how true – but the onus is on the user to apply the tool to an optimization problem where a wide range of solutions can be readily parameterised and success criteria can be sensibly quantified.
Generative design is certainly not a panacea for all ills but it is an incredibly powerful tool in the right situation.
Reg Prentice
I suspect GD will be successful in proportion to the amount that is known about the end result before design is started.
To look at the extremes: If all aesthetic directions, materials, and construction methods are on the table, the percent of useful solutions generated might be close to zero. But if it was known that the finished building would be constructed from a limited number of standardized modular units, the percent of useful solutions might be high.
Betsy
Very interesting writeup! From a less creative designer perspective and more mechanical analysis — in industries like aerospace, Generative Design is used for weight reduction. For mechanical analysis these programs are used for weight-critical components, generating the new shapes, and then perform further (more accurate) analysis in other programs, and then do physical testing. The GD output isn’t usually the final result, but it can be very eye-opening to see where weight and material can be reduced in a part and use it as a starting point for further analysis. I will add that one must be skilled in FEA to even start the process. Autodesk simplifies this and therefore the program makes analysis look easy — it’s not. But it’s a fun starting point, a cool feature, but nobody in critical-design industry would use it at this point. Altair HyperWorks is used in industry. However, Autodesk provides it at such a low cost, giving the opportunity to try out advanced analysis techniques for students or less-critical design projects.
Will Walker
I think your interpretation of the generative design process is naive.
I also think when most “hard” designers (architects, design engineers, industrial designers, automotive designers) refer to generative design, they neglect important parts of the machine learning side and the user experience side.
If you speak to ML folks, the real limitation of the process is getting good data labeling to the algorithm, I.E. what makes a “good” or “successful” design. There’s no feedback loop for an adversarial algorithm to be applied to this process which would automate the “editor” step in your model. It’s really the advances being made in adversarial machine learning that have provided the jawdropping advances in outcomes we’ve seen over the past few years (alpha zero etc.).
As an interaction designer, I also think that the “hard” design fields of architecture and industrial design are woefully neglectful in gathering naive user feedback with simple prototypes. By the time they field a device and identify user failure modes, the molds have already been cut and the tools have been made. A weakness in most generative design models I have seen is that they make no accounting for user input or testing as part of the design process.
Louis Larosiliere
Will,
I completely agree with your comment concerning the cursory interpretation of the generative design process and it’s practice by so called “hard” designers. Advances in AI, including Machine Learning invalidates most of Mr. Davis’ negative comments…
David
Hey Daniel, are you aware, this article comes up in like top 10 results when people look up “generative design”? That’s how I found it. I’m really curious about that “something more significant was happening” part you mentioned at the beginning. I feel the same way, but can’t quite piece it all together. What do you think might that be? I’m doing some reading on big data companies, knowledge economies, insights and decision making and feel like that is where this should be heading, especially in design. All I want are clear insights, to make (better) decisions. Focus should be on sustainable design, how much money, how much time, how much CO2 and how to make it less. Surely that can be done.
Daniel Davis
Hi David,
What I was hinting at is that I feel there are some large changes underway in how algorithms, designers, and decision-making systems work together. For the past decade or so, the focus has been on a lot of these project-specific, single-use tools like parametric models and scripts. But in the last couple of years we’ve seen things like Testfit and Upcodes approach computational design in a different manner, generalizing the algorithms to work in a different context and building businesses around them. It seems inevitable that we’ll get to better decision making like you describe. But I think there’s still a question about the best way to deliver that insight to designers. To me, generative design feels like the wrong interface, a less promising path in a much bigger change the industry is experiencing.
Santiago
Thanks for your article Daniel.
I’d like to see a team that has been investigating on GD pivot in new directions.
Although GD has not been useful to me personally as a designer (in architecture) in the past, the individual pieces that GD is built from (i.e. design abstraction, requirements analysis, 3rd party analysis automation, etc) do strike as being potentially useful.
I would suggest a follow-up activity with open participation from the design community, on which ways design technology could go next. (This probably is already happening, and I’m oblivious because I live under a rock).
I notice in industry colleagues a fascination for some of the constituent parts of GD. If they were used together differently, could we arrive to a technology that is indeed useful to designers and aligns well with design process?
Ramon Lorenz
Regarding politics of the last 2000 years or so… things being doomed to fail won’t stop people from pursuing them with all possible dedication.
jl
Talk about coincidences (there are none). I just posted this in another website an hour ago, and then i found this site:
“Since my school days i have always wanted to be able to draw and model something and then generate iterations of this model by changing some parameters. Of course, we have always done this, either by hand or in computer 3d models, but never in an automatic, parameter controlled ways. The late architect, and in my opinion, a genius, Enric Miralles, once described his process like this: he drew something and the made hundreds of variations of the same thing, by hand, before passing his idea to someone else to put it in the computer.”
It is that spark of human creativity that still hasnt been captured, and i dont know if it ever will, but i think we certainly can input it and the use generative design as an aid to take the idea to its ultimate consequences.
The library of Babel in Jorge Luis Borges short story contained an incredibly big number of books, each different from each other by one letter. Most of them where full of incomprehensible letters, but every once in a while you could find meaning in there. Everything that could ever be said was written in one of the books.
I once dream of a form “that contained all the forms” (it had a voice of its own). And the forms were affected by what you thought. Sadly i woke up before i could see a specific form manifest itself
nickhockings
This article, or something very close to it, applies to much of the recent promises of artificial intelligence. They commonly massively underestimate what it is that a human must learn in order to become competent in whatever task it is proposed to automate. Creating a broadly useful artificial general intelligence is certainly possible, but it is nowhere near as trivial as the current hype presumes. Current AI systems lack depth of understanding and the ability to learn from minimal examples.
Thank you for pushing back and presenting a clear argument against marketing nonsense.
Daniel Davis
Your point about AI is really salient. It’s a similar situation where people have been able to show success in narrowly defined problems, which we assume will scale to something larger, but it never quite happens like that in reality.
vijay
very Thoughtful article Daniel,
if we look at some of generative design solutions mainly in space planning for architecture, there so much similarity among proposed designs, now many are pushing wind-solar analysis as main selling points of project and as you have said correctly At present its an white whale, look at some of recent insane amount acquisitions by leading BIM companies.
Another question remains, if one makes an decision based on tools suggestion, construction being investment intensive and long duration from planning to actual construction, who will be held responsible if those suggested assumptions result in major flaws with rework to losses.
m-sterspace
Great article. I think points 2 & 3 are a little weaker in that I think that generative algorithms could start improving by producing fewer better options by filtering out the similar but worse scoring ones, and that when it comes to concrete metrics that are easy to measure (which is what the algorithms are based on), there’s a number of different techniques for multi variable analysis, from parametric line charts to machine learning dimension reduction / clustering algorithms that are commonly used in other fields like biology. I don’t think that either of these points are real show stoppers for generative design.
That being said, I view points 4, 5, & 6 as the real and complete show stoppers that even if they don’t make generative design dead in the water, will at least prevent it’s widespread adoption for decades upon decades. There aren’t any generative algorithms that are designed to be run more than once, or to have tweaks made to them after the fact. That means you either need the ability to fully generate a building, and all of its documentation, from an algorithm, or you can only run it once and pick it and then still have to do a ton of manual design and adjustment which limits generative design to basically exclusively early stage design, or things like facade panels that have no impact on the rest of the building.
There’s a lot of people in the industry who have fully bought the marketing on this one, it’s nice to see some rationality cut through.
Nathan Higgins
Hello! I thought this was great. I wonder, though, if generative design might work for buildings that are a little more basic. I’m thinking salt sheds or maintenance buildings that cities own. They tend to be cheap and probably not highly designed now. What are your thoughts on whether generative design might help improve the design of those buildings?
Daniel Davis
Hey Nathan, I think you’re right that simpler building typologies lend themselves to automation. The question is, what’s the best interface for creating those designs? In many cases, a simple parametric model might suffice. If I look at a tool like Testfit.io, which produces far more sophisticated buildings, their software functions much more like a parametric model than generative design – they’re not presenting users with thousands of options to pick, they’re generating the best option from a set of parameters. So I think you’ll see automation like this, but I don’t believe generative design will be the interface to that automation.
Dexter Reyes
I started this article with an open mind and willing to hear some genuine pitfalls of GD (generative design). In fact the author starts the article with what sounds like a fair assessment of what GD is, but as soon as they jump into their argument, it seems like they actually don’t know what they’re talking about.
For example the author uses generative email as an out of context example of why GD doesnt work. First of all, you don’t DESIGN emails, you narrate them. It’s a method of communication. This isnt a well thought out example at all and yet the author routinely returns to this bad example to prove points. Its like pointing to the invention of the automobile and saying “yes nice, but it doesnt work when you put it in the ocean so its doomed to fail”.
I find it interesting that the author does mention constraints, parametrics and the “evolve -> evaluate” stage in the design cycle, but they seemingly dismiss it when it comes to making their arguments. For example
“(1) designers define the project’s goals, (2) algorithms produce a range of solutions, and (3) then designers pick the best result”
This is wholly wrong and a simplification, which further leads me to believe the author doesnt understand the field, because if they did they would understand that parametrics is a way to make the process iterative, a way to navigate/reduce the possibilities, which they then later go on to describe as one of the main issues with GD.
Author says better algorithms would produce fewer results not more. On what grounds ? If the constraints are narrow a tool might only produce 5 or 6 outputs. If the tool produces too many outputs, you refine the constraints. The goal of GD is to show the designer options which are within a valid scope. If the constraints are wide ranging, parametrics allow the designer to hone in on what they want without worrying about what won’t. Its frustrating to read the author write about algorithms as if they are this complicated black box that just produces outputs and the designer cannot interact with. This is the point of parametrics and constraints.
The author points to GDs absence in other fields as some sort of proof it doesn’t work, but as someone who works in graphic design and previously video game development, I can tell you that adoption is growing for generative tools. Admittedly though, it does require designers to think about design differently, but thats what new tooling is supposed to do. Haven’t Zaha Hadid among others been using parametric tools for years now? Perhaps generative design is not so much doomed to fail in architecture as it is actually just further ahead of other industries.",3
106,"FEDS Notes
August 05, 2022
Long COVID, Cognitive Impairment, and the Stalled Decline in Disability Rates
Introduction
Long COVID encompasses a suite of long-term symptoms that commonly include fatigue, shortness of breath, and so-called brain fog, along with many others. Individuals with long-term symptoms may be unable to work (or work full-time) as a result of their condition, and there is growing evidence that long COVID may be restraining labor supply.1
In this note, I use two survey datasets to document four facts about long COVID in the United States. First, long-term COVID symptoms are much more prevalent among women, adults under 65, Hispanics and Latinos, and non–college graduates than among other demographic groups. Second, COVID ""long haulers"" cite specific physical and cognitive impairments commonly associated with the condition in media and medical reporting. Third, the share of working-age adults reporting serious difficulty remembering, concentrating, or making decisions has risen steadily since the start of the pandemic. Fourth, growing shares of women and of non–college graduates report simultaneously (i) being out of the labor force due to disability and (ii) experiencing these cognitive difficulties. Non-participation attributed to disability was declining steadily in the years leading up to the pandemic, but that downward trend has stalled. Long COVID is likely one reason why.
I. Evidence from the Household Pulse Survey
Newly available data from the Household Pulse Survey—an experimental Census Bureau product launched at the start of the pandemic—provide the first large-scale, population-level detail on the prevalence of long COVID.2 Starting with the survey's June 2022 wave, respondents who report having had a diagnosed case of COVID are asked,
""Did you have any symptoms lasting 3 months or longer that you did not have prior to having coronavirus or COVID-19?""
Though there is no universally agreed-upon definition of long COVID, the three-month threshold is a common criterion. To aid responses to this question, the survey questionnaire provides a list of symptoms frequently associated with long COVID.3
The Pulse Survey suffers from an extremely low response rate, around 6 percent in recent survey waves. In addition, respondents cannot be linked over time, precluding longitudinal analyses that would facilitate causal inference about the effects of long COVID. For these reasons, the Pulse data may be more useful as a barometer of qualitative patterns than as a reliable gauge of magnitudes. With these caveats noted, I use the June and July 2022 survey waves to estimate the prevalence of long COVID and its associated impairments.4
The prevalence of long COVID
Among adults aged 18 or older, 41 percent of Pulse respondents report having been diagnosed with COVID at some point in the past; 14 percent of all respondents, and 35 percent of those with diagnosed COVID, report having experienced symptoms lasting three or more months. The prevalence of long COVID in the Pulse data is roughly in line with some external estimates that about 30 percent of COVID patients go on to develop long COVID.5 Just over half of long haulers report that they are currently experiencing symptoms.
The incidence of long COVID varies greatly across demographic groups. As shown in Figure 1, long COVID is significantly more common among women, among individuals under 65, among Hispanics and Latinos, and among those without a college education.6 I return to disparities by gender and educational attainment later in my analysis.
The rest of this note focuses on adults aged 18–64, for whom long COVID is much more common than for seniors.
Symptoms of long COVID
The Pulse survey also asks a set of questions about physical and cognitive impairment. Figure 2 shows the share of respondents who express ""a lot"" of difficulty with a given activity (the darker portion of each bar) or at least ""some"" difficulty (the full height of each bar), separately by long COVID status. Consistent with medical and media reports, long haulers are much more likely to cite difficulties remembering or concentrating, walking or climbing stairs, and dressing or bathing than other adults do.
A degree of cognitive difficulty is especially common, cited by 62 percent of adults who currently report long-term COVID symptoms compared with 30 percent of those who have never had long-term symptoms.7 Such difficulty is also elevated among those whose long-term symptoms have ostensibly resolved, either because of subjectivity in self-reported long COVID status or because long haulers are in worse health partly for reasons unrelated to the coronavirus.
Long haulers also report high rates of psychological distress: for example, 38 percent felt down, depressed, or hopeless more than half of the days in the preceding two weeks, compared with 16 percent of adults who never had long COVID. Similar patterns hold for survey questions about anxiety, worry, and little interest or pleasure in doing things.
Possible effects on employment
Long-term COVID symptoms appear to significantly interfere with daily activities for many who suffer from them. Previous research on the labor market effects of medical and psychological impairments suggests that these symptoms are likely to constrain labor supply, as well.8
The Pulse survey asks questions about employment status and reasons for non-employment, and in unreported regressions I explore the relationship between employment and long COVID. Controlling for available demographics, I find that individuals who have had long COVID are about 3 percentage points less likely to be employed than those who had COVID but did not experience symptoms lasting more than three months. Individuals with long COVID are also more likely to report being out of work because they are sick with COVID or caring for someone sick with COVID. However, these cross-sectional relationships are likely to be biased by unobservable differences in underlying health status and labor market attachment. For that reason, regression estimates using the Pulse data are suggestive at best, and I do not pursue them further.
II. Evidence from the Current Population Survey
The Pulse survey has important shortcomings, including a low response rate, a modest sample size, and a lack of pre-pandemic history. To put the pandemic period into a broader context, and to ground my analysis in a larger and more representative dataset, I use Current Population Survey (CPS) data from IPUMS on adults aged 18–64, spanning January 2017 through June 2022 (Flood et al., 2021).
Impairments consistent with long COVID
The CPS lacks a question about long COVID, but it does contain a set of questions about physical and cognitive impairments similar to those asked in the Household Pulse Survey. Consistent with the evidence from Pulse, Figure 3 shows that the share of working-age adults who report ""serious"" difficulty remembering, concentrating, or making decisions has risen 0.6 percentage point since February 2020. Other forms of impairment—difficulty walking or climbing stairs, running errands, and dressing or bathing—are also elevated above their pre-pandemic trends.
The Pulse data indicate that women and those without a college degree are especially likely to have long COVID. The CPS corroborates this point. As shown in Figure 4, the shares of women and non–college graduates who report serious cognitive difficulties have risen especially sharply over the course of the pandemic.
Non-participation due to disability
The CPS asks respondents who are not in the labor force their primary reason for non-participation. As shown in Figure 5, the share of working-age adults out of the labor force due to disability, illness, or inability to work was in secular decline in the years preceding the pandemic, but—after a short-lived decline in 2020—has been holding relatively steady for the past two years.9 As of June 2022, this share is 0.6 percentage point above its pre-pandemic trend.
Though other factors may be at play, long COVID has likely contributed to the stalled decline in this series. As evidence, Figure 6 plots the share of individuals who are simultaneously (i) out of the labor force due to disability and (ii) experiencing serious cognitive difficulties. Among women and among non–college graduates—two groups, again, especially affected by long COVID—this share has been trending up over the course of the pandemic. Since not all individuals with long COVID have serious cognitive impairments, the increases in these series are likely a lower bound on the effect of long COVID on disability-driven non-participation.
III. Conclusion
Long COVID is associated with significant physical, cognitive, and psychological impairments that interfere with activities of daily life. Alongside their effects on health status and quality of life, long-term symptoms of COVID are likely to limit work capacity as well.
My evidence of labor market effects is not conclusive. Regressions in the Household Pulse Survey are consistent with negative effects of long COVID on individual employment rates, but these results are potentially biased by unobserved confounders. Long COVID has likely contributed to the stalling out of the trend decline in disability rates, but its quantitative importance is difficult to assess.
More research is needed. Long COVID appears to be a common condition, especially for some demographic groups, and has the potential to curtail employment, labor force participation, and hours worked. But much is still unknown about its medical causes, its labor market effects, and its future trajectory, which will depend on both the course of the pandemic and the duration of symptoms experienced by long haulers. Recent trends in disability rates also warrant further study, whatever long COVID's role in shaping them.
References
- Bach, Katie (2022), ""Is 'Long Covid' Worsening the Labor Shortage?"" Brookings Institution, January 11.
- Currie, Janet, and Brigitte C. Madrian (1999), ""Health, Health Insurance, and the Labor Market"", Handbook of Labor Economics, Vol. 3C: pp. 3309–3416.
- Flood, Sarah, Miriam King, Renae Rodgers, Steven Ruggles, J. Robert Warren, and Michael Westberry (2021), ""Integrated Public Use Microdata Series, Current Population Survey: Version 9.0"" [dataset]. Minneapolis, MN: IPUMS.
- Goda, Gopi Shah, and Evan J. Soltas (2022), “The Impacts of Covid-19 Illnesses on Workers,” Stanford University and MIT working paper.
- Ham, Dasom (2022), ""Long-Haulers and Labor Market Outcomes"", Federal Reserve Bank of Minneapolis Opportunity and Inclusive Growth Institute Working Paper No. 60.
- Household Pulse Survey, US Census Bureau.
- Lahart, Justin (2022), ""The Economy Could Have a Case of Long COVID"", The Wall Street Journal, July 8.
- UC Davis Health (2021), ""Studies Show Long-Haul COVID-19 Afflicts 1 in 4 COVID-19 Patients, Regardless of Severity"", March 30.
Acknowledgements
The views expressed here are strictly those of the author and do not necessarily represent the views of the Federal Reserve Board or its staff, nor those of the US Census Bureau or the Bureau of Labor Statistics. I am grateful to Andrew Figura, Charles Fleischman, and Ivan Vidangos for helpful comments.
1. See, for example, Bach (2022) and Lahart (2022). Using an event-study design, Goda and Soltas (2022) find that workers who experience week-long health-related absences during the pandemic are 7 percentage points less likely to be in the labor force one year later, compared with otherwise-similar workers who do not experience such absences. Their estimates encompass several possible mechanisms, one of which is long COVID, and imply that COVID-19 illnesses have reduced the US labor force by about 500,000 individuals. Return to text
2. Ham (2022) finds large effects of long COVID on employment as of mid-2021 using data from the Understanding America Study, a survey of about 6000 adults. Return to text
3. The listed symptoms include ""tiredness or fatigue, difficulty thinking, concentrating, forgetfulness, or memory problems (sometimes referred to as 'brain fog'), difficulty breathing or shortness of breath, joint or muscle pain, fast-beating or pounding heart (also known as heart palpitations), chest pain, dizziness on standing, menstrual changes, changes to taste/smell, or inability to exercise"". Return to text
4. I exclude from the sample individuals with missing values for COVID status, long COVID status, the timing of symptoms, current symptom status, or employment status. When respondents do not indicate whether they have difficulty with a given activity, I assume that they do not. I recode individuals who say they cannot do an activity at all as having ""a lot"" of difficulty doing so. Return to text
5. See UC Davis Health (2021). Estimates of the frequency of long COVID range widely, in part because the condition has no agreed-upon definition. Studies differ in the set of qualifying symptoms, the population studied, reliance on medical data versus self-reports, and the horizon at which symptoms are measured. Return to text
6. Similar qualitative patterns obtain in a multivariate regression that controls simultaneously for gender, age, race or ethnicity, and educational attainment, along with further controls for survey week, Census region, marital status, and parental status. Differences in long COVID across age groups primarily reflect differences in the likelihood of having had a diagnosed case of COVID, whereas disparities by gender and by educational attainment are mainly driven by differences in the prevalence of long COVID conditional on diagnosed COVID. Hispanics are significantly more likely to have been diagnosed with COVID and somewhat more likely to go on to contract long COVID. Return to text
7. The qualitative patterns shown in Figure 2 continue to hold in regressions that control for a rich set of demographic variables (three-way interactions of gender and educational attainment with survey wave, age bins, race or ethnicity, region, marital status, and parental status). In particular, I find that ""at least some"" cognitive difficulty is 32 percentage points (pp) more common among long haulers than among those who never had COVID, while ""a lot"" of difficulty is 13 pp more common. Return to text
8. See, for example, Currie and Madrian (1999). Return to text
9. The trend decline in non-participation due to disability began around 2015. Though its cause is unclear, possible contributors include changing demographics, changes in the structure of the disability insurance program (such as field office closures and changes in appellate rules), and a strengthening labor market providing more work opportunities for disabled individuals in the late 2010s. Data from the Social Security Administration show that applications for Social Security Disability Insurance benefits, which were similarly declining in the lead up to the pandemic, no longer appear to be doing so. Return to text
Price, Brendan M. (2022). ""Long COVID, Cognitive Impairment, and the Stalled Decline in Disability Rates,"" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, August 5, 2022, https://doi.org/10.17016/2380-7172.3189.
Disclaimer: FEDS Notes are articles in which Board staff offer their own views and present analysis on a range of topics in economics and finance. These articles are shorter and less technically oriented than FEDS Working Papers and IFDP papers.",4
107,"No matter how hard you work, it still takes a little bit of luck for something to hit. That can be discouraging, since luck feels like a force outside our control. But the good news is that we can increase our chances of encountering good luck. That may sound like magic, but it’s not supernatural. The trick is to increase the number of opportunities we have for good fortune to find us. The simple act of publishing your work is one of the best ways to invite a little more luck into your life.
Before we get into the “how,” it’s important to get on the same page about the “what.” What are we talking about when we say “luck?” There are a lot of definitions that could apply, but let’s stick with a simple one: Luck is when something unexpected and good happens to you. Unexpected and good. Who doesn’t want to increase the odds of something unexpected and good?
In our world, luck can include:
Having your OSS library take off
Being invited to speak at a conference
Landing a new job
Getting a new consulting client
Being invited onto a podcast
Making new friends in your community
None of these things are totally in your control, which can at times feel frustrating.
How can we increase the odds of finding luck? By being a person who works in public. By doing work and being public about it, you build a reputation for yourself. You build a track record. You build a public body of work that speaks on your behalf better than any resume ever could.
The goal is not to become famous, the goal is to increase the chances of luck finding us. For me, one of the most helpful ways to think about this has always been the concept of the “Luck Surface Area,” described in an old post by Jason Roberts. He wrote (and note, the emphasis is mine):
""The amount of serendipity that will occur in your life, your Luck Surface Area, is directly proportional to the degree to which you do something you’re passionate about combined with the total number of people to whom this is effectively communicated.""
Going further, he codifies it into a formula where:
Luck = [Doing Things] * [Telling People]
The more things you do multiplied by the more people you tell, the larger your Luck Surface Area becomes. The larger your Luck Surface Area, the more likely you are to catch luck as it flows by.
Source: Jason Roberts
Doing the work
Before you can publish your work, you have to actually do the work. The good news for you is that by even reading this Guide on The ReadME Project, you’ve probably already self-selected into a group of people for whom “doing things” comes somewhat naturally. You’re a developer, a designer, a creator, an author, or something else entirely. Whatever moniker you want to give yourself, you’re built to do things, and that’s the important part.
If that doesn’t ring true for you, you may fall into one of two groups:
You actually are doing things, you’ve just trained yourself to think that anything you do isn’t worth sharing.
You want to be doing things, but you can’t bring yourself to get started.
If you’re in the first group, you may need to step back and reframe the work you’re already doing. This is a common blind spot for people who are executing at a high level! They’ve forgotten just how much they know. They think that they’re not doing anything interesting because they assume that everyone knows as much as they do. This effect is only exacerbated when everyone in your immediate vicinity is at a similar—or higher—skill level. As you become more of an expert, your quality bar gets higher and higher and you forget that everything you know is not known by everyone.
If you’re in this group I want to give you a challenge: Watch the communities where you hang out and see what people are sharing and what gets noticed. Is it something you could have done? Is it something you’ve already done? At its worst this could lead you in the direction of becoming bitter, critical, and thinking that you’re smarter than everyone. To that I say “resist!” There is no life there. My encouragement to you is to view that as objective evidence that people want to know all of the things that you already know! There is a huge opportunity for you, should you decide to start sharing your work.
If you’re in the second group, you just need to start. Start anywhere, start on anything, start something. You’ll never come up with the perfect idea for an OSS library, a business, a podcast, or an article by just thinking about it. Start on something, today. It won’t be the perfect version of the thing you have in your head, but you’ll be in motion. Motion begets motion, progress begets progress. Pick the smallest thing you can do and get started.
Doing the work is the most important part. It’s the nucleus around which everything else revolves. What that “work” looks like, though, is entirely up to you! That’s the fun part. It can take any form and be in any domain. Wherever your curiosity or expertise draw you, dive into that.
Projects outside of work are a good place to dive into your curiosity.
If you want to make a thermal receipt printer that prints GitHub issues, you should.
If you want to turn a prefabricated shed into an office, go for it.
If you want to go all in on an SVG drawing tool, do it.
If you want to write tens of thousands of words about the infrastructure of modern money, that’s a newsletter.
Your curiosity will naturally pull you in certain directions, so don’t be afraid to go super deep into a topic that you’re interested in. When a person is truly interested in the thing they’re writing or talking about, their excitement is contagious. Whatever you’re excited about, be excited about it publicly. Whatever you’re curious about, be curious about it publicly. People will want to follow along and you’ll inspire people along the way.
Projects at work can be a good place to dive into your expertise.
It's likely you're constantly solving problems and learning interesting things at your job. This is a great opportunity to take what you’re already doing and repurpose it for the benefit of others. You can turn those learnings into blog posts, conference talks, meetups, podcasts, or open source projects.
Of course not everything you do at work is shareable. If the specifics aren’t shareable, the concepts, lessons, and takeaways likely are. While you’re working, keep a scratch pad open and jot down any problems you come across, interesting patterns you see, or things you found confusing. Do this for a month and you’ll have more things to share than you know what to do with!
You’ve done the work, now it's time to tell people.
Hitting the publish button
This part of the formula can be harder for most of us. Most of us really enjoy the building aspect but start to get a little shy when it comes to telling people about the stuff we’ve built. That could be for any number of reasons: fear, embarrassment, self-preservation, or an aversion to being perceived as hawking your wares.
It’s a valuable exercise to investigate whether or not you resonate with any of those reasons. Are you afraid people are going to make fun of what you built? Are you embarrassed that it isn’t up to your own (admittedly high) standards? Are you waiting for some elusive perfect moment? Do you have an aversion to “marketing” and don’t want to become the thing you hate? Whatever it is for you, I encourage you to really dig into it and see if that fear is worth keeping around.
Sharing things you’re learning or making is not prideful. People are drawn to other people in motion. People want to follow along, people want to learn things, people want to be a part of your journey. It’s not bragging to say, “I’ve made a thing and I think it’s cool!” Bringing people along is a good thing for everyone. By publishing your work you’re helping people learn. You’re inspiring others to create.
You can “publish” anywhere. For me that’s mostly Twitter because that’s where most of my peers hang out. It doesn’t have to be Twitter for you. It could be GitHub, a newsletter, a podcast, forums, your blog, YouTube, or something completely different that’s not even on my radar. Anywhere that’s not your hard drive counts!
Publishing is a skill, it’s something you can learn. You’ll need to build your publishing skill just like you built every other skill you have.
Don’t be afraid to publish along the way. You don’t have to wait until you’re done to drop a perfect, finished artifact from the sky (in fact, you may use that as an excuse to never publish). People like stories, so use that to your benefit. Share the wins, the losses, and the thought processes. Bring us along! If you haven’t been in the habit of sharing your work, it’s going to feel weird when you start. That’s normal! Keep going, you get used to it.
You’ve done the work. You’ve hit the publish button. You’ve done your part!
Capturing the luck
You’ve increased the odds that good, unexpected things will come your way. The exact form is hard to predict, but here are a few potential outcomes:
People start to know you as the person that talks about X, Y, and Z.
You start to get emails from people saying that they read your stuff and liked it.
You get a DM about a job you might be interested in.
People ask you if you’re taking on new clients.
Someone you’ve never met or interacted with will mention you as being an expert in your area.
A meetup asks you to come talk about the things you’ve been sharing.
You become friends with other people in your industry.
Your OSS library starts gaining mindshare.
This is not a random list of made-up examples, it’s a list of things that have literally happened to me once I got over my fears and started sharing my work. I had been doing the work all along, but was too afraid to publish. Once I overcame that fear, my Luck Surface Area expanded and good, unexpected things started happening.
The formula is simple.
Do the work. Don’t be afraid to dive deep into your curiosity and your expertise. We need more people that are intensely curious. We need more people with deep expertise.
Tell people. Press publish, bring us along, share the journey. Tell us what you’ve learned, what you’ve built, or what you’re excited about.
The formula may be simple, but I’ll admit it’s not always easy. It’s scary to put yourself out there. It’s hard to open yourself up to criticism. People online can be mean. But for every snarky comment, there are ten times as many people quietly following along and admiring not only your work, but your bravery to put it out publicly. And at some point, one of those people quietly following along will reach out with a life-changing opportunity and you’ll think, “Wow, that was lucky.”",4
108,"The Human Library at Amsterdam Pride
For the first time, the Human Library was a part of the Amsterdam Pride in August. We gathered 10 books from our book depots around Europe and published them during pride week. From Paris to Amsterdam to Borrow an Open Book With support from our friends at Heineken, the Human Library Book Cafe was…",2
109,"Digital applications permeate all aspects of our economies and societies, enabling us to sell and purchase goods, access government services, play games, listen to music, watch movies, travel more efficiently, and so much more.
But serious questions are still unanswered. For example, how can we protect critical digital infrastructure from threats? What is the best way to provide universal high-quality, affordable internet access to all citizens? How can we protect the rights of citizens and personal online data? What is the best way to provide regulatory responses to evolving technologies?
Finding the answers to these questions could be time-consuming and difficult. Wouldn’t it be better if we had access to a source of information that described how countries have succeeded in making these changes quickly, efficiently, and inclusively?
Enter the Digital Regulation Handbook
To fill this need, the World Bank’s Digital Development (DD) Global Practice and the International Telecommunication Union (ITU) have worked on updating the ICT Regulatory Handbook to transform it into the Digital Regulation Handbook.
The Handbook serves as a high-level reference document that supports digital regulation and provides insights on the challenges, opportunities, and solutions relating to digital regulation. Topics include regulatory governance and independence, competition and economics, access for all, consumer affairs, data protection and trust, spectrum management, emerging technologies, technical regulation, and emergency communications. Each chapter provides actionable guidance and concrete takeaways for decision-makers in deciding on the appropriate regulations and policies to guide digital transformation. Along with the English edition, the Handbook is also available in Arabic, Chinese, French, Russian, and Spanish.
Digital technologies have a profound impact on the way we live. The ongoing wave of innovation has the potential to remove many of the barriers that stand between people and opportunity, especially for populations in poorer communities. This is why the Handbook is also accompanied by an Online Platform, which provides up-to-date information and the latest good practice guidelines on digital regulation.
Critically, these resources also provide the tools for evaluating the effectiveness of those regulations. They can also help academics, and civil society actors navigate the emerging challenges associated with digital transformation. Other stakeholders, as well as the general public, who want to learn about topical regulatory issues and best practices related to the digital economy, can also use these resources.
Why it matters
Recent global events have highlighted the importance of global digital transformation. First, the COVID-19 pandemic demonstrated our reliance on digital technologies and the need to utilize and manage digital transformation more effectively. This, in turn, has raised concerns over the way we promote the digital economy and regulate digital platforms and services.
Second, cybersecurity has risen to the top of many national agendas as cyberattacks have increasingly threatened businesses, governments, and critical infrastructure. Even the United States is vulnerable, as demonstrated in May 2021 when the IT systems of Colonial Pipeline were breached, spurring panic-buying and shortages of gasoline in several states. The meat-processing giant JBS SA was similarly attacked that same month, halting production at many facilities. Governments and businesses cannot ignore the policy implications of the larger problem of cybersecurity and, in particular, the wave of cyberattacks targeted at critical national infrastructure.
We hope these resources can provide valuable information on regulatory practices to enable a safe, productive, and meaningful digital economy for all.
Join the Conversation",5
110,"Introduction
""For only death annihilates all sense, all becoming, to replace them with non-sense and absolute cessation.""
-- F. Gonzalez-Cruzzi, ""Days of the Dead"" in The New Yorker, November 1993
""Personally, I should not care for immortality in the least. Nothing better than oblivion exists, since in oblivion there is no wish unfulfilled. We had it before we were born, yet did not complain. Shall we then whine because we know it will return? It is Elysium enough for me.""
-- H. P. Lovecraft
The words quoted above distill a common secular conception of death. If we decline the traditional religious reassurances of an afterlife, or their fuzzy new age equivalents, and instead take the hard-boiled and thoroughly modern materialist view of death, then we likely end up with Gonzalez-Cruzzi, and perhaps with Lovecraft. Rejecting visions of reunions with loved ones or of crossing over into the light, we anticipate the opposite: darkness, silence, an engulfing emptiness, a peaceful oblivion. But we would be wrong.
The topic of our fate after death is a touchy subject, but nevertheless the error of anticipating nothingness needs rectifying. This misconception is so widespread and so psychologically debilitating for those facing death (all of us, sooner or later) it is worth a careful look at the faulty, rather subliminal logic which persuades us that dying leads us into ""the void.""
Here, again, is the view at issue: When we die, what's next is nothing; death is an abyss, a black hole, the end of experience; it is eternal nothingness, the permanent extinction of being. And here, in a nutshell, is the error contained in the view: It is to reify nothingness--make it a positive condition or quality (e.g., of ""blackness"")--and then to place the individual in it after death, so that we somehow fall into nothingness, to remain there eternally. It is to illicitly project the subject that died into a situation following death, a situation of no experiences, of what might be called ""positive nothingness."" Epicurus deftly refuted this mistake millennia ago, saying ""When I am, death is not, and when death is, I am not,"" but regrettably his pearl of wisdom has been largely overlooked or forgotten. In what follows I will try to refine this insight and, using a thought experiment, make its implications vivid.
Not that there haven't been more recent attempts to counter the myth of nothingness, notably by the philosopher Paul Edwards in his classic 1969 paper ""Existentialism and Death: A Survey of Some Confusions and Absurdities."" Below I will produce my own examples of those bewitched by the vision of the void, but before continuing I must bow to Edwards' ""who's who"" of thinkers that have fallen into this particular conceptual trap. He quotes Shakespeare, Heine, Seneca, Swinburn, Houseman, Mencken, Bertrand Russell, Clarence Darrow, James Baldwin, and others, all to the effect that, as Swinburne put it, death is ""eternal night."" Those who anticipate nothingness at death are at least in some pretty exalted company.
If, as I will argue, nothingness cannot be anything positively existent, that is, if it truly (as the term would indicate) doesn't exist, then the situation at death cannot involve falling into it. Those skeptical of the soul and an afterlife need not fear (or cannot look forward to, if such is their preference) blackness and emptiness. There is no eternal absence of experience, no black hole which swallows up the unfortunate victim of death. If we conscientiously eliminate the tendency to project ourselves into a situation following death, and if we drop the notion of positive nothingness, then this picture loses plausibility and a rather different one emerges.
Do people still really believe, as I claim they do, in a kind of positive nothingness? I will present enough examples to show that, beyond Edwards' celebrities, many do harbor such a misconception. In developing a plausible alternative, my operating assumptions and guiding philosophy will be resolutely naturalistic, materialist, and non-dualist. I assume only a single universe of interconnected phenomena, a universe devoid of souls, spirits, mental essences, and the like. In particular, persons, on this account, are not possessed of any essential core identity (an indivisible self or soul), but consist only of relatively stable constellations of dispositions and traits, both physical and psychological. Although some conclusions I reach may end up sounding counterintuitive to those inclined to naturalism, it won't be because the argument departs from naturalistic assumptions. And for readers who are skeptical about naturalism, these conclusions may not be so unpalatable as my starting point might lead them to suppose.
Anticipating Nothingness
The late Isaac Asimov, interviewed in Bill Moyers' series ""A World of Ideas,"" questioned the traditional religious picture of our fate after death: ""When I die I won't go to heaven or hell, there will just be nothingness."" Asimov's naturalistically based skepticism about heaven or hell is common among secularists (there is no evidence for such realms) but he commits an equally common fallacy in his blithe assumption about nothingness, namely that it could ""be."" By substituting nothingness for heaven and hell, Asimov implies that it awaits us after death. Indeed the word itself, with the suffix ""ness,"" conjures up the strange notion of ""that stuff which does not exist."" In using it we may start to think, in a rather casual, unreflective way, that there exists something that doesn't exist, but of course this is not a little contradictory. We must simply see that nothingness doesn't exist, period.
Harvard philosopher Robert Nozick, in his book The Examined Life, expresses much the same view as Asimov, and in much the same context. He debunks, in a very respectful tone, the wishful thinking that supposes there will be an afterlife involving the memories and personality of a currently existing person. ""It might be nice to believe such a theory, but isn't the truth starker? This life is the only existence there is; afterward there is nothing."" Although he probably doesn't mean to, with these words Nozick may suggest to the unwary that ""nothing"" is something like a state into which we go and never return. But, as Paul Edwards explained in ""Existentialism and Death,"" death is not a state, it is not a condition in which we end up after dying. Of course I'm not denying that we die and disappear, only that we go into something called non-existence, nothing, or nothingness.
My richest example is offered by the late novelist Anthony Burgess in his memoirs, You've Had Your Time: The Second Part of the Confessions. The following paragraph from his meditations about death contains several nice variations on the ""nothingness"" theme.
Am I happy? Probably not. Having passed the prescribed biblical age limit, I have to think of death, and I do not like the thought. There is a vestigial fear of hell, and even of purgatory, and no amount of rereading rationalist authors can expunge it. If there is only darkness after death, then that darkness is the ultimate reality and that love of life that I intermittently possess is no preparation for it. In face of the approaching blackness, which Winston Churchill facetiously termed black velvet, concerning oneself with a world that is soon to fade out like a television image in a power cut seems mere frivolity. But rage against the dying of the light is only human, especially when there are still things to be done, and my rage sometimes sounds to myself like madness. It is not only a question of works never to be written, it is a matter of things unlearned. I have started to learn Japanese, but it is too late; I have started to read Hebrew, but my eyes will not take in the jots and tittles. How can one fade out in peace, carrying vast ignorance into a state of total ignorance?
Listing the thematic variations, we have: ""darkness after death,"" ""approaching blackness,"" ""black velvet,"" ""a world that is soon to fade out,"" ""the dying of the light,"" ""a state of total ignorance."" All these express Burgess' expectation that death will mean entering a realm devoid of experience and qualities, a state something like losing all sensation (Gonzalez-Cruzzi's ""non-sense""), all perception, all thought. He is raging against the imminent arrival of Nothingness, the eternal experience of no experience in which the subject somehow witnesses, permanently, its own extinction. But death rules out any such experience or witnessing, unless of course we covertly believe, as Burgess seems to, that in death we persist as some sort of pseudo-subject, to whom eternity presents itself as ""black velvet."" Burgess, as well as Nozick and Asimov, all deny that they continue on in any form, so their picture of the subject trapped in nothingness after death is rather contradictory. Since death really is the end of the individual, it cannot mean the arrival of darkness as witnessed by some personal remnant.
Two more brief examples, which I believe are typical of those who face death without the traditional reassurances of an afterlife. Arthur W. Frank, author of At The Will Of The Body: Reflections on Illness, wrote about his heart attack that ""Afterward I felt always at risk of one false step, or heartbeat, plunging me over the side again. I will never lose that immanence of nothingness, the certainty of mortality."" And Larry Josephs, an AIDS patient, wrote in the Times that ""...I hope that when the time comes to face death, I will feel stronger, and less afraid of falling into an empty black abyss.""
Although the fear of death is undoubtedly biological and hence unavoidable to some extent, the fear of nothingness, of the black abyss, can be dealt with successfully. This involves seeing, and then actually feeling, if possible, that your death is not the end of experience. It is the end of this experiencer most definitely, but that end is not followed by the dying of the light. Experience, I will argue, is quite impervious to the hooded figure who leads his unwilling charges into the night.
Continuity and Being Present
In order to make this clear it will be helpful to consider some facts about ordinary experience. First is the initially somewhat surprising fact that, from our point of view as subjects of experience, there are no gaps during the course of our conscious lives. Despite the fact that we are frequently and regularly unconscious (asleep, perhaps drugged, knocked out, etc.) these unconscious periods do not represent subjective pauses between periods of consciousness. That is, for the subject there is an instantaneous transition from the experience preceding the unconscious interval to the experience immediately following it. On the operating table we hear ourselves mumble our last admonition to the anesthesiologist not to overdo the pentathol and the next instant we are aware of the fluorescent lights in the recovery room. Or we experience a last vague thought before falling asleep and the next experience (barring a dream, another sort of experience) is hearing the neighbor's dog at 6 a.m. As much as we know that time has passed, nevertheless for us there has been no gap or interval between the two experiences which bracket a period of unconsciousness. I will call this fact about experience ""personal subjective continuity"".
Next, note that this continuity proceeds from our first experience as a child until the instant of death. For the subject, life is a single block of experience, marked by the rhythm of days, weeks, months, and years, and highlighted by personal and social watersheds. Although it may seem obvious and even tautological, for the purposes of what follows I want to emphasize that during our lives we never find ourselves absent from the scene. We may occasionally have the impression of having experienced or ""undergone"" a period of unconsciousness, but of course this is impossible. For the subject, awareness is constant throughout life; the ""nothingness"" of unconsciousness cannot be an experienced actuality.
But what about the time periods before and after this subjectively continuous block of experience, that is, before birth and after death? Don't these represent some sort of emptiness or ""blank"" for the subject, since, after all, it doesn't exist in either? To think that they might, as I've pointed out, is to confuse non-existence with a state that we somehow primitively subsist in, as an impotent ego confronted with blackness. Certainly we don't ordinarily think of the time before we come into existence as an abyss from which we manage to escape; we simply find ourselves present in the world. We cannot contrast the fact of being conscious with some prior state of non-experience.
The same is true of the time after death. There will be no future personal state of non-experience to which we can compare our present state of being conscious. All we have, as subjects, is this block of experience. We know, of course, that it is a finite block, but since that's all we have, we cannot experience its finitude. As much as we can know with certainty that this particular collection of memories, desires, intentions, and habits will cease, this cessation will not be a concrete fact for us, but can only be hearsay, so to speak. Hence (and this may start to sound a little fishy) as far as we're concerned as subjects, we're always situated here in the midst of experience.
Even given all this, when we imagine our death being imminent (a minute or two away, let us suppose) it is still difficult not to ask the questions ""What will happen to me?"" or ""What's next?"", and then anticipate the onset of nothingness. It is extraordinarily tempting to project ourselves--this locus of awareness--into the future, entering the blackness or emptiness of non-experience. But since we've ruled out nothingness or non-experience as the fate of subjectivity what, then, are plausible answers to such questions? The first one we can dispense with fairly readily. The ""me"" characterized by personality and memory simply ends. No longer will experience occur in the context of such personality and memory. The second question (""What's next?"") is a little trickier, because, unless we suppose that my death is coincident with the end of the entire universe, we can't responsibly answer ""nothing."" Nothing is precisely what can't happen next. What happens next must be something, and part of that something consists in various sorts of consciousness. In the very ordinary sense that other centers of awareness exist and come into being, experience continues after my death. This is the something (along with many other things) which follows the end of my particular set of experiences.
Burgess suggests, when facing death, that ""concerning oneself with a world that is soon to fade out like a television image in a power cut seems mere frivolity."" But we know, as persons who have survived and witnessed, perhaps, the death of others, that the world does not fade out. It continues on in all sorts of ways, including the persistence of our particular subjective worlds. Death ends individual subjectivities while at the same time others are continuing or being created.
As I tried to make clear above, subjectivities--centers of awareness--don't have beginnings and endings for themselves, rather they simply find themselves in the world. From their perspective, it's as if they have always been present, always here; as if the various worlds evoked by consciousness were always ""in place."" Of course we know that they are not always in place from an objective standpoint, but their own non-being is never an experienced actuality for them. This fact, along with the fact that other subjectivities succeed us after we die, suggests an alternative to the intuition of impending nothingness in the face of death. (Be warned that this suggestion will likely seem obscure until it gets fleshed out using the thought experiment below.) Instead of anticipating nothingness at death, I propose that we should anticipate the subjective sense of always having been present, experienced within a different context, the context provided by those subjectivities which exist or come into being.
In proposing this I don't mean to suggest that there exist some supernatural, death-defying connections between consciousnesses which could somehow preserve elements of memory or personality. This is not at all what I have in mind, since material evidence suggests that everything a person consists of--a living body, awareness, personality, memories, preferences, expectations, etc.--is erased at death. Personal subjective continuity as I defined it above requires that experiences be those of a particular person; hence, this sort of continuity is bounded by death. So when I say that you should look forward, at death, to the ""subjective sense of always having been present,"" I am speaking rather loosely, for it is not you--not this set of personal characteristics--that will experience ""being present."" Rather, it will be another set of characteristics (in fact, countless sets) with the capacity, perhaps, for completely different sorts of experience. But, despite these (perhaps radical) differences, it will share the qualitatively very same sense of always having been here, and, like you, will never experience its cessation.
Transformation and Generic Subjectivity
To help make this shared, continuing sense of ""always having been present"" more concrete, I want to embark on a thought experiment of the Rip Van Winkle variety. So imagine, in the perhaps not so distant future, that we develop the technology to reliably stop and then restart biological processes. One could, if one wished, be put ""on hold"" for an indefinite period, and then be ""started up"" again. (Some trusting and perhaps naive souls have already had their brains or entire bodies frozen in the expectation of just such technology.) In essence, one is put to sleep and then awakened after however many years, memories and personality intact.
From the point of view of the subject, such a suspension of consciousness would seem no different from a normal night's sleep, or, for that matter, an afternoon nap. The length of the unconscious interval--minutes, years, or centuries--makes no difference. There is simply the last experience before being suspended, and then the first experience upon reactivation, with no experienced gap or interval of nothingness in between. In principle a subject could lie dormant for millions of years, to awaken with no sense of time having passed, except, of course, the clues given by the changed circumstances experienced upon regaining consciousness. Personal subjective continuity would have been preserved across the eons.
Next, suppose that during the unconscious period (the length of which is unimportant for the point I'm about to make) changes in memories or personality, or both, take place, either deliberately or through some inadvertent process of degradation. I go to sleep as TC and wake up as TC/mod. (Readers are encouraged to substitute their own initials in what follows.) If the changes aren't too radical, then I (and others) will be able to reidentify myself as TC, albeit a modified version, whose differences from the original I might or might not be able to pinpoint myself. (""Funny, I don't remember ever having liked calf's liver before. Was I always this grumpy? I wonder if this suspension technique really worked as well as they claimed. Maybe some unscrupulous technician fiddled with my hypothalamus while I was under. Still, all in all, I seem relatively intact."") Assuming this sort of reidentification is possible, personal subjective continuity is still preserved across the unconscious interval. There would be no subjective gap or pause between the last experience of TC and the first experience of TC/mod. For TC/mod, TC was never not here. There is simply one block of experience, the context of which suffered an abrupt but manageable alteration when TC woke up as TC/mod.
An interesting series of question now arises, questions which may generate some visceral understanding of what I mean by expecting the sense of always having been present. First, how much of a change between TC and TC/mod is necessary to destroy personal subjective continuity? At what point, that is, would we start to say ""Well, TC 'died' and a stranger now inhabits his body; experience ended for TC and now occurs for someone else""? It is not at all obvious where to draw the line. But let's assume we did draw it somewhere, for instance at the failure to recognize family and friends, or perhaps a vastly changed personality and the claim to be not TC but someone else altogether. Imagine changes so radical that everyone agrees it is not TC that confronts us upon awakening; he no longer exists. Given this rather unorthodox way of dying, what happens to the intuition that now, for TC there is ""nothing""?
We have seen that, given small or moderate changes in memory and personality, there is no subjective gap or ""positive nothingness"" between successive experiences on either side of the unconscious period. Instead, there is an instantaneous transition from one to another. (TC/mod says ""I'm still here, more or less like before. Seems like I went to sleep just a second ago."") Given this, it seems wrong to suppose that, at some point further along on the continuum of change (the point at which we decide someone else exists), TC's last experience before unconsciousness is not still instantly followed by more experiences. These occur within a substantially or perhaps radically altered context, that of the consciousness of the new person who awakens. These experiences may not be TC's experiences, but there has been no subjective cessation of experience, no black abyss of nothingness for TC. Destroying personal subjective continuity (i.e. ending a particular subject by means of the transformation envisioned here) doesn't result in the creation of some positive absence of experience ""between"" subjects into which the unfortunate TC falls or out of which the new person emerges. Rather, it just changes the context of experience radically enough so that we, and the person who wakes up, decide TC no longer exists. Death in this case is a matter of convention, not biology, and it hasn't interrupted awareness, only changed its context.
Although this transformation has disrupted the personal subjective continuity imparted by a stable context of memory and personality, there is another sort of continuity or sameness, that created by the shared sense of always having been present. Such generic subjective continuity is independent of the context of memory and personality (that is, of being a particular person), and it amounts simply to the fact that, whoever wakes up feels as if they've always been here, that there has been no subjective blank or emptiness ""in front"" of their current experience. We can, I think, imagine going to sleep, being radically transformed, and having someone else wake up, with no worry about falling into nothingness, even though we no longer exist. The first experience of TC/rad (a radically changed TC, no longer identifiable as the same person) would follow directly on the heels of the last experience of TC. If there are no subjective gaps of positive nothingness between successive experiences of a single individual, then there won't be such a gap between a person's last experience and the first experience of his or her radically transformed successor. That first experience occurs within a context of memory and personality which establishes the same sense of always having been present generated by the original person's consciousness.
But of course the difficulty here is that it seems arbitrary, or simply false, to say that TC/rad's experience instantly follows TC's last experience if there is no connection of memory or personality, but only some bodily continuity. (And if we wish, we can imagine that drastic changes in body as well are engineered during the unconscious period, so that TC/rad looks nothing like his predecessor.) The objective facts are that TC has a last experience, then sometime later TC/rad has a first experience. But despite the lack of personal subjective continuity, despite the fact that we may decide at some point on the continuum of change, (in memory, personality, and body) that TC no longer exists to have experiences, experience doesn't end for him, that is, there is no onset of nothingness. What we have instead is a transformation of the subject itself, a transformation of the context of awareness, while experience chugs along, oblivious of the unconscious interval during which the transformation took place. It's not that TC/rad's experience follows TC's in the sense of being connected to it by virtue of memory or personality, but that there is no subjective interval or gap between them experienced by either person. This is expressed in the fact that TC/rad, like TC, feels like he's always been present. However radical the change in context, and however long the unconscious interval, it seems that awareness--for itself, in its generic aspect of ""always having been present""--is immune to interruption.
Death and Birth
Let us call TC's fate in becoming TC/rad ""death by transformation"". My claim is that awareness is subjectively continuous, in this generic sense, across such a transformation. Considered from ""its"" point of view, experience never stops even though objectively speaking (from the ""outside"") one context for it ends and later on, as much later as you care to imagine, another context picks up. The next step in my argument is to apply this conclusion to ordinary death and birth. Instead of being transformed into some sort of successor, imagine that TC is allowed by a careless technician to lapse from unconsciousness into irreversible brain death. Somewhere, sometime later, a fresh consciousness comes into being, either naturally or by artifice. Except that the physical incarnations of TC and this other consciousness have no causal connection, this situation is the same as death by transformation. That is, one context of awareness has lapsed and another very different one begins. During the objective interval there has been no subjective hiatus in awareness; only the context of experience has changed.
This thesis implies that even if all centers of awareness were extinguished and the next conscious creature appeared millions of years hence (perhaps in a galaxy far, far away) there would still be no subjective interregnum. Subjectivity would jump that (objective) gap just as easily as it jumps the gap from our last experience before sleep to the first upon awakening. All the boring eons that pass without the existence of a subject will be irrelevant for the subject that comes into being. Nor will they count as ""nothingness"" for all the conscious entities which ceased to exist. Subjectivity, awareness, consciousness, experience – whatever we call it – never stops arising as far as it is concerned.
At this point it is likely that our intuitions about experience ""jumping the gap"" have been stretched beyond the breaking point. We have moved from the fairly uncontroversial fact of the continuity of one person's experience (no subjective gaps in consciousness during a lifetime) to this seemingly outlandish notion that consciousness, for itself, is impervious to death or indeed to any sort of objective interruption. But let me quickly reiterate my main points in order to reinstate some plausibility.
- It is a mundane, although contingent, fact of life that when I die other subjects exist, hence subjectivity certainly is immune to my death in these circumstances.
- If I am unconscious for any length of time I don't experience that interval; I am always ""present""; this is personal subjective continuity.
- If, after a period of unconsciousness, the transformed person who wakes up is not me there still won't be any perceived gap in awareness. The person who wakes up feels, as I did (hence ""still"" feels), that they've always been present. There has been no prior experience of not being present for them, nor when I stop existing do I have such an experience; this is generic subjective continuity.
- Death and birth are ""functionally equivalent"" to the sort of transformation in 3), so again there will be no perceived gap, no nothingness of non-experience into which the subject might fall. Generic subjective continuity holds across any objective discontinuities in the existence of conscious beings.
Points 3) and 4) are certainly the most difficult to accept, and accepting them really depends on whether we are willing to slide down the slippery slope of the transformation thought experiment. If you don't buy the idea of a soul or indivisible self it's an easy trip. From a naturalistic perspective the self is nothing more than a contingent collection of fairly stable personality traits, memories, and physical characteristics. Thus the difference between my transformation into someone still recognizably me and someone barely not me is not a difference which would prevent awareness from jumping the gap. If there is no nothingness between experiences in the first case, then there is no nothingness in the second.
The reason 3) may have some intuitive plausibility is that we can generalize from our own ordinary experience of subjective continuity to cases in which we may not be quite sure who it is that wakes up. We can then see that even significant changes in the context of experience won't create subjective gaps. It is the absence of such gaps, resulting in the continuing shared sense of always having been present, that constitutes generic continuity.
4) seems plausible only if we accept what I call generic continuity in the extreme case of 3) (a completely different person wakes up) and then buy the notion that there is no real difference between death by transformation and ordinary death. This equivalence is difficult to accept since in ordinary death there is no causal ""successor"" person which ""takes over"" the consciousness relinquished by the person who dies. But keep in mind that in our thought experiment the successor consciousness might be activated long after the original person was put to sleep, have very different physical and personal traits, and be somewhere else altogether. The only connecting link is presumably some bodily ""shell,"" any of the parts of which (including the brain) might be changed or replaced. The most extreme case of 3) looks a lot, then, like ordinary death, except that there is a very attenuated successor that comes into existence by virtue of a radical transformation. Ordinary death and birth amount, I think, to such radical transformations of subjectivity, except that there is no obvious candidate for a successor. My point is, however, that we don't need such a candidate to insure the generic continuity of experience. We need only see that the continuity is that of subjectivity itself, abstracted from any particular context, and it finds concrete expression in the fact that none of us has ever experienced (or will ever experience) not being here.
Despite my naturalistic and materialist caveats at the beginning of this essay, such a conclusion may still seem to have a mystical ring. It may seem as though I give too much weight to the subjective sense of always having been present, and, in claiming that subjectivity, for itself, always ""is,"" I ignore the vast times and spaces in which no consciousness exists at all. Nevertheless, I believe a materialist can see that consciousness, as a strictly physical phenomenon instantiated by the brain, creates a world subjectively immune to its own disappearance. It is the very finitude of a self-reflective cognitive system that bars it from witnessing its own beginning or ending, and hence prevents there being, for it, any condition other than existing. Its ending is only an event, and its non-existence a current fact, for other perspectives. After death we won't experience non-being, we won't ""fade to black."" We continue as the generic subjectivity that always finds itself here, in the various contexts of awareness that the physical universe manages to create. So when I recommend that you look forward to the (continuing) sense of always having been here, construe that ""you"" not as a particular person, but as that condition of awareness, which although manifesting itself in finite subjectivities, nevertheless always finds itself present.
To identify ourselves with generic subjectivity is perhaps as far as the naturalistic materialist can go towards accepting some sort of immortality. It isn't conventional immortality (not even as good as living in others' memory, some might think), since there is no ""one"" who survives, just the persistence of subjectivity for itself. It might be objected that in countering the myth of positive nothingness I go too far in claiming some sort of positive connection between subjectivities, albeit a connection that doesn't preserve the individual. I might be construed as saying, to borrow the language of a different tradition, that an eternal Subject exists, ever-present in all contexts of experience. I wouldn't endorse such a construal since it posits an entity above and beyond specific consciousnesses for which there is no evidence; nevertheless such language captures something of the feel for subjectivity and death I want to convey.
It is possible that this view may make it easier to cope with the prospect of personal extinction, since, if we accept it, we can no longer anticipate being hurled into oblivion, to face the eternal blackness that so unsettled Burgess (and, I suspect, secretly bedevils many atheists and agnostics). We may wear our personalities more lightly, seeing ourselves as simply variations on a theme of subjectivity which is in no danger of being extinguished by our passing. Of course we cannot completely put aside our biologically given aversion to the prospect of death, but we can ask, at its approach, why we are so attached to this context of consciousness. Why, if experience continues anyway, is it so terribly important that it continue within this set of personal characteristics, memories, and body? If we are no longer haunted by nothingness, then dying may seem more like the radical refreshment of subjectivity than its extinction.
© Thomas W. Clark",1
111,"Every two weeks from March to November, Chris Halsch walks a ten-mile loop near the Donner Pass, high up in California’s Sierra Nevada, for the sole purpose of counting butterflies.
It is one of five sites at various altitudes that Halsch, a PhD candidate at the University of Nevada, Reno, has been visiting with metronomic regularity for the past five years. At each one he retraces his steps, pausing every so often to jot down species and numbers in a notebook.
Along the way, he sometimes meets recreational birders or hikers who take photographs and use nature apps to identify species for fun. But unlike those random snapshots, Halsch’s notes are a coveted resource for scientists. Once he types them into a spreadsheet, each of his data points adds a new segment to a chain of observations that has been growing without interruption for half a century, in one the world’s longest-lived efforts to monitor butterfly populations. Like a relay runner, Halsch is extending a marathon of sustained attention that began 20 years before he was born.
Multi-decadal time-series of field observations are among the rarest and most valuable artifacts in ecosystem science because they help to overcome a peculiar weakness in our ability to perceive and interpret the natural world. Humans have developed powerful methods for reconstructing events in the distant past, from the birth of a galaxy to mass extinctions in the Devonian. We have built instruments that can parse the present down to the zeptosecond. But when it comes to the modest timescale of our own lifespans, we are like near-sighted moles.
Weren’t there more birds in this meadow when we were kids?
Doesn’t it seem like spring is a lot rainier than it used to be?
Are you sure it’s safe to eat fish from this river?
Our answers to these types of questions are notoriously unreliable. Think of the tendency to describe a single weather event as evidence for (or against) climate change, or the panic caused by invasive zebra mussels that, 20 years later, turns out to have been misplaced. Perceptions are distorted by selective memories, cognitive biases, political agendas and shifting baseline syndrome—the propensity of each generation to gradually forget past environmental conditions and accept present ones as normal. In an essay published in 01990, the zoologist John J. Magnuson wrote that this temporal myopia can trap us in the “invisible present,” a space where we fail to see slow changes and are unable to interpret effects that lag years behind their causes. “In the absence of the temporal context provided by long-term research, serious misjudgments can occur not only in our attempts to understand and predict change in the world around us, but also in our attempts to manage our environment,” he warned.
Magnuson was echoing a group of mid-century scientists who believed that some of the biggest questions in ecology could only be answered with field observations that were carefully structured and repeated at the same sites for at least two decades. The longer the time-series, the greater likelihood that the invisible present will “melt away,” exposing the complex and often unexpected dynamics of ecosystem change.
They had compelling examples to point to. Rachel Carson’s Silent Spring (01962) used a 20-year time-series of migrating raptor observations made by volunteers at Hawk Mountain Sanctuary in Pennsylvania to illustrate the devastating impact of DDT and other pesticides on bird populations. In 01972, precipitation samples analyzed by scientists at the Hubbard Brook Experimental Forest, a 7,800-acre living laboratory in New Hampshire that has been continuously studied since 01955, became the first irrefutable documentation of acid rain in North America, and led to landmark amendments to the Clean Air Act.
And yet, with the exception of weather records that have been widely maintained since the late 19th century, long time-series remained extremely hard to come by. The effort required to visit outdoor locations and keep meticulous records, year after year, discouraged most scientists. Three-year grant cycles—still the standard in academia—made it nearly impossible to finance long-term experiments. The result was thousands of “snapshot” studies that look, say, at the impact of a single hurricane on the health of a mangrove forest in Key West, but almost none that describe the deeper cycles of damage and recovery following multiple hurricanes spread over 30 years.
Now, thanks to several converging developments, that short-term bias is giving way to an era in which long time-series could become a ubiquitous tool for understanding the Anthropocene.
In 01980, at the urging of leading ecologists who were frustrated by the lack of funding, the National Science Foundation launched the Long Term Ecological Research (LTER) Program with the goal of financing multi-decade observations at a network of field stations throughout the United States. The network has since grown to 28 sites where some 2000 scientists—plus many more students and volunteers—gather data on a vast spectrum of ecosystem indicators. These observations have been quietly accumulating for four decades, providing the evidence for thousands of scientific papers, theses and books. But the raw data collected in the field—first in notebooks, later in spreadsheets and databases—were often saved in fragmented and incompatible formats that essentially hid them from all but the most dogged researchers. To ensure that more people would be able to harvest this data, in 02016 the NSF financed the creation of the Environmental Data Initiative, an open access data repository that has systematized terabytes of data from LTER sites and other sources.
Scientists quickly took note. In 02017, after a study in Germany based on a 27-year time-series showed a precipitous decline in flying insects, alarm over an “ecological armageddon” flared up around the world. At Hendrix College in Conway, Arkansas, biology professor Matthew Moran wondered if similar declines had been documented in the United States. He found some studies tracking individual species, but nothing that offered an aggregate picture of multiple species in ecosystems including deserts, mountains, prairies and forests. When Moran and his colleagues examined the LTER repository, they were amazed by the richness of the data—and the fact that no one had used it to look at the big picture. “We were the first ones to put it all together,” he recalls. Moran, who has since retired, assembled a 12-person team that ultimately reviewed more than 5000 insect time-series in the LTER repository. The resulting paper, published in 02020, revealed a much more varied picture than the authors anticipated. While some species have declined, others are increasing, and overall, there was no evidence of an insect apocalypse across these sites.
In the years since the founding of the LTER program, concern about climate change has also fueled a revolution in the study of climates from before the era of direct measurements. Even as scientists were tracking the rise in atmospheric CO2 (most notably at Mauna Loa Observatory in Hawaii, now in its 64th year of observations), new technologies were enabling the creation of proxy time-series by examining tree-rings, ice cores, lake and ocean sediment samples, pollen grains and other physical evidence, some going back two million years. Other researchers began to mine archives for human observations that were not intended for scientific purposes but can yield serendipitous climate data. Magnuson and several colleagues scoured archives for references to the freeze and thaw dates of lakes and waterways, including a river in Finland where locals have been keeping such records for 325 years. Yasuyuki Aono, a professor of environmental science at Japan’s Osaka Prefectural University, has pinpointed the spring flowering date of cherry trees for numerous years over the past 12 centuries by reading diaries and chronicles written by monks, aristocrats and public officials in Kyoto starting in 0812 AD.
These studies are exposing a vast reservoir of temporal evidence that has been hidden in pre-digital documents as varied as harvest reports, livestock records and ship passengers’ memoirs—but also in scientific papers whose titles don’t openly advertise that they include time-series data. Eliza Grames, a postdoctoral researcher at UNR’s Biology Department, spends several hours each week reading the freshly scanned pages of yellowed journals and unpublished dissertations related to moths. If she finds any time-series information, she uses data-capture tools to convert analog graphs into digital formats that will be accessible to researchers. “Sometimes the graphs are literally drawn by hand,” she says. No time frame is too short. “One multi-decadal time series is great, but if you find a thousand two-year studies and they are all showing the same trend, that’s also valuable,” she says.
Grames is co-coordinator of EntoGEM, a community of scientists that is compiling all available evidence about global insect population and biodiversity status and trends. She and her colleagues are sifting through more than 60,000 journal articles to both assess the current state of published evidence and surface data sources that have been overlooked, such as the research of Norman Criddle (01875-01933), a Canadian entomologist who devoted his career to combatting the grasshoppers that would periodically devour local crops. In the process, he left behind 30 years of observations on the relative abundance of several species. “We don’t have a lot of grasshopper population data from before 01920,” Grames says. “These records aren’t perfect, but they can complement other sources and help us better understand an issue.”
EntoGEM is one of several initiatives that aim to synthesize temporal evidence by conducting better meta-analyses of disparate data sources. BioTIME, a consortium based at the University of St. Andrews in Scotland, is curating a collection of time-series that track the assemblages of species that live in particular ecological communities. So far it has gathered records on more than 600,000 distinct geographic locations, some going back 130 years. More broadly, large international repositories such as DataONE and the Global Biodiversity Information Facility (GBIF) are facilitating access to time-series as part of the movement toward open science and FAIR data.
Collectively, these efforts are widening the aperture of our ecological attention, enabling scientists to find and stitch together scattered fragments of temporal data into panoramas that tell a more illuminating story about the interactions that drive change. Unfortunately, the emerging picture is still largely focused on wealthy countries—particularly ones with long histories of field-based science. A map of the International LTER network, an association of 750 field stations that, like their U.S. counterparts, are making long-term observations, shows that more than two thirds are concentrated in Western Europe. Numerous countries in Asia, Africa and Latin America have no stations at all. Moreover, even as scientists like Moran and Grames are exploiting the new wealth of temporal evidence, it is not clear how this research will influence the wider culture, where the blinkered perceptions of the “invisible present” are still pervasive.
The trend that may ultimately overcome both of these limitations is driven, paradoxically, by smartphones. Non-scientists have long been a critical source of field labor for long time-series, most famously for the Audubon Society’s 122-year-old Christmas Bird Count, but also in hundreds of smaller projects that monitor other kinds of flora and fauna. Now, smartphones with powerful cameras and apps such as eBird, iNaturalist, Seek and Picture Insect have enabled millions of casual observers to supplement this pool of dedicated volunteers. Despite the lively debate on whether smartphone usage in the outdoors enhances or interferes with people’s appreciation of nature, one fact is clear: because nature apps automatically time-stamp, geo-reference and store each observation in a robust database, they are generating potential time-series at an unprecedented scale.
In the 20 years since the Cornell Lab of Ornithology launched eBird, the app has amassed more than one billion observations by 700,000 birders from every country in the world. Carrie Seltzer, who heads stakeholder engagement at iNaturalist, says that more than 2.4 million people have made observations on the app, at a rate that has grown between 50 percent and 100 percent per year since 02012. “By October of 02022, iNaturalist had accumulated nearly 120 million observations, more than half of which have been classified as ‘research grade’ because the species has been verified by more than one user,” she says. Although observations in industrialized countries still predominate, iNaturalist users in the global South are rapidly catching up. In virtually every country on the planet, users have created dozens of self-administered “projects” that gather observations around specific themes. A group of spider enthusiasts in the Southern Cone of South America, for example, has so far uploaded 87,000 observations of 853 species.
This torrent of raw field data vastly exceeds what even well-funded researchers could ever dream of gathering with traditional methods. Not surprisingly, scientists have already published more than 2,800 studies citing iNaturalist data. One of them is Michael Moore, an assistant professor at the University of Colorado Denver. In 02019, he was pondering the potential impacts of rising temperatures on the evolution of wing coloration in dragonflies when his partner introduced him to iNaturalist. “I logged on and saw that at that time, there were around 14,000 observations of just one of the species of dragonfly that I wanted to study. I realized very quickly that I could essentially answer this question using the data that was already there.”
In 02021, Moore and his colleagues published a paper showing that over just 17 years, males of several species of dragonflies have evolved less breeding coloration on their wings in regions with hotter climates—a change that affects their breeding success and internal temperature regulation. The principal evidence was citizen science observations from GBIF and iNaturalist. “Thanks to this data, we’re able to literally watch evolution take place at a grand scale,” says Moore, who last year gave a keynote presentation entitled “How citizen science is super-charging the study of evolutionary adaptation” at the American Philosophical Society.
Moore acknowledges that citizen science data presents numerous statistical challenges. Sudden growth in users and observations can create the illusion of population growth in a species that simply was not being observed in the past. Observations are concentrated in accessible spots near cities and roadways, and they almost never occur at regular intervals over multiple years in the manner of Chris Halsch’s biweekly butterfly surveys. But Moore shares the optimism of many other researchers who believe that the sheer volume of these observations, combined with advances in data science and artificial intelligence, are enabling researchers to correct for these factors and extract powerful insights from citizen science. He also believes that by getting millions of people to discover the joy of habitual observation, these apps will ultimately deepen public understanding of incremental ecosystem change—and support for conservation.
Halsch, who has walked several thousand miles while gathering butterfly data for his PhD, straddles the age of laboriously hand-crafted time-series and the future envisioned by Moore. Although the fieldwork can be monotonous at times, Halsch says on most days he relishes the prospect of being outside with his notebook, his mind temporarily free of all other responsibilities. He has also come to love the analytical side of the research much more than he expected. “There’s a real sense of importance of the work, and the tremendous power of a long time-series,” he says. “There are things we can do because of the length of these data that no one else can do. It’s a quantitative gold mine.”
Matt Forister, a biology professor at UNR who is Halsch’s dissertation advisor, worries that some young scientists are not achieving this balance between observation and analysis. “There’s so much veneration of large data sets these days, and of the computational challenges of interpreting them, that I feel like too many students are just training to wrestle with big data,” he says. “They feel like all the data is already out there—we don’t need to go collect it.” Forister believes that paying close and repeated attention to “the chaos” of natural systems in the field is essential to sparking our awareness of anomalies and generating new questions. Although he is a tenured professor with his own lab and he could easily delegate, Forister chooses to spend hundreds of hours doing field work each year.
It is a mindset he picked up two decades ago from his own thesis advisor, Art Shapiro, a professor of evolution and ecology at the University of California, Davis. Shapiro began monitoring butterflies at 10 sites in a transect across central California in 01972. He single-handedly conducted observations at all the sites for more than four decades, amassing data that has become indispensable to understanding the decline of butterflies in the state, among other issues.
Around five years ago, when knee pain was making it harder for Shapiro to maintain his grueling fieldwork schedule, Forister offered to personally take over monitoring five of the sites. He subsequently recruited Halsch, with whom he tag-teams to ensure that no site ever misses its scheduled survey. Shapiro, at age 76, is still visiting five of the lower-elevation sites every two weeks. Forister, 48, intends to keep doing so “for at least another 20 years,” and he is confident that younger scientists will be happy to take the baton and maintain the time-series “in perpetuity.”
Halsch, 29, expects to help train a successor. “I often think about the fact that ideally, no one will see this to completion,” he says. “I’m going to do this for as long as I’m here, and then someone else will continue it.”
More from Long-term Thinking —
Explore over two decades of long-term thinking
Concepts
Projects
Disciplines
- Art
- Business
- Cities
- Civilization
- Climate Change
- Computing
- Culture
- Economics
- Energy
- Environment
- Evolution",2
112,"The Indian woman who married herself
Inspired by a Netflix show, 24-year-old Kshama Bindu tied the knot with herself last month – the first example of ‘sologamy’ in India.
New Delhi, India – Though she is dressed aptly as a newlywed, she is different from other brides. Because Kshama Bindu has not married a man, or a woman – she has married herself.
“People look weirdly at me. Like I have committed a crime,” she told Al Jazeera.
Bindu’s “sologamy” – a marriage with self – was conducted last month in an elaborate Indian wedding setup, making her an overnight internet sensation and the first Indian ever to engage in such a practice.
Bindu says she came up with the idea of sologamy only three months before her wedding after watching the Netflix show, Anne With An E, a coming-of-age story of a young orphaned girl who endured abuse as a child.
Taking the line from the show – “I want to be a bride but not a wife” – to another level, she finally tied the knot with herself on June 8.
Since then, from travelling for work to going out for shopping in the western Indian state of Gujarat, the 24-year-old has been earning disapproving looks from strangers.
But she could not be happier. The day of her wedding was the best day of her life, she said, adding, “I was in awe of myself when I looked into the mirror. I had no worries of a normal Indian bride. I felt like I was enough for myself.”
The best part about her marriage to self, she says, is that not much has changed since the wedding.
“I don’t need anybody else’s validation. I don’t have to think about moving to a different city because my partner has to move. I can think just about myself,” she told Al Jazeera, adding that no one but herself can give her greater love.
Bindu is an unusual woman in a traditional Indian society now undergoing rapid changes.
Is this radical self-love, a quest for fame, a deliberate glorification of being alone as a protest against loneliness, or a rejection of patriarchy and societal expectations of women?
Experts say such a declaration of self-love could have been a result of past trauma and failed relationships, and could even point to narcissistic tendencies.
Anusnigdha, a psychoanalytically-oriented researcher at Birmingham University in the United Kingdom, believes extreme trauma at a young age could explain self-love.
For someone who has gone through trauma, acceptance of this kind could be immensely healing, she said.
“In a society where everything is now celebrated on social media, it seems she wanted to make a public declaration that she has finally accepted herself after a journey of healing,” Anusnigdha told Al Jazeera.
I don’t need anybody else’s validation. I don’t have to think about moving to a different city because my partner has to move. I can think just about myself.
Bindu says she did have a tough childhood and was repeatedly sexually abused when she was eight.
“Every time it happened, I would look into the mirror crying and try to motivate and inspire myself. I would have to remind myself that I am strong. Because of this, I grew up much before my time,” she said.
According to India’s National Crime Records Bureau (NCRB) data from 2020, sex crimes against children in India went up, with at least 40 percent of the total crimes against children being sexual offences.
Bindu describes herself as a vocal person who always takes a stance against injustice.
“Some people dislike me and want me to take a chill pill, or to take it easy. I am a buzzkill because I call out casual sexism and misogynistic jokes,” she said.
“Rest in Peace, patriarchy and gender rules,” reads the graveyard tattoo on Bindu’s left wrist. “Patriarchy has hit me many times and in different stages of my life.”
Anusnigdha feels that the pressures of an ideal marriage for women in Indian society could also be a driving factor in Bindu’s marriage with herself.
“Most cases of sologamy across the world are women. From a young age, girls are prepared for marriage. It can feel like a lot of pressure. By marrying herself, she has shut people up,” she said.
What is sologamy?
There are multiple references to sologamy in Western popular culture. The idea has featured in several popular Hollywood films and television series, including Sex And The City, Glee and Doctor Who.
Organisations such as Marry Yourself Vancouver in Canada and IMarriedMe.com in the United States offer sologamy packages and assistance.
Bindu recalls not feeling shocked when she first learned about the concept. “I had heard a lot about polygamy and monogamy, but never sologamy,” she told Al Jazeera.
“After watching the show, I googled for the first time whether it was legal to marry oneself in India. When I read about it, it felt normal and even attractive to me. It wasn’t a shock.”
But to her friends and family, it was a bolt out of the blue. Eventually, they all came on board. Her friends even planned a bachelorette party for her, which could not take place in the end because of the barrage of media people outside her gate.
“I was on a sort of house arrest because of the media outside, I couldn’t go out. The neighbours too had objections,” she says.
After the news of her marriage broke, the media flocked outside her house for interviews. Her story got mixed responses, but most stories painted her as a pioneer of sorts.
Most cases of sologamy across the world are women. From a young age, girls are prepared for marriage. It can feel like a lot of pressure.
Anusnigdha feels that Bindu has successfully tapped into the social media potential and styled herself a trendsetter and feminist icon. She says that even the wedding, an act of self-acceptance, was done in a performative way.
But it was not an easy journey. Not only were people mocking her for the decision, there was political backlash too. Just a week before her wedding, the priest who was supposed to solemnise the marriage backed out.
“This is because politics got involved,” says Bindu, referring to the opposition she faced from Sunita Shukla, a politician from the governing Bharatiya Janata Party (BJP), who declared she would not allow the wedding to take place in a Hindu temple.
Because of threats, Bindu was under pressure to keep the marriage discreet. She held the ceremony in her house before the scheduled date. She said the wedding was authentic Gujarati, with garba – a Gujarati dance form – and sweets.
Shukla told the media such a marriage would be against Hinduism.
“I am against the choice of venue, she will not be allowed to marry herself in any temple. Such marriages are against Hinduism. This will reduce the population of Hindus. If anything goes against religion then no law will prevail,” she told India’s ANI news agency.
Bindu says she called at least 25 Hindu priests to perform the wedding rituals but to no avail. Ultimately, technology came to the rescue. The hymns and wedding chants were played on a Bluetooth speaker in Bindu’s house when the wedding finally took place.
Like a proper Indian bride, she got a full bridal mehndi (henna) on her hands and feet a day before the marriage ceremony. On her big day, she invited a makeup artist to get a bridal look.
“After my wedding, I received a lot of questions about how my sex life is going to be. While it is true that I have pledged not to date, remarry or have sexual relations with anyone but myself, I can fulfil my needs fully,” she said.
It can be called different things in different cultures but it has existed for a long time. In tribal cultures, there was always the unwed woman or man.
Anusnigdha says sologamy can be healthy only if treated as one phase of her life.
“She should not shut herself down. The healthy way to do it is to be open, in case she finds someone who can compliment her. There should be no guilt or anxiety in moving on, or her overall growth and development could get affected,” she says.
‘Concept needs better understanding’
Neha Bhat, a licensed sex and trauma therapist who writes on culture, abuse and relationships, says people have chosen to live with themselves – unmarried – since ancient times.
“It can be called different things in different cultures but it has existed for a long time. In tribal cultures, there was always the unwed woman or man,” she says.
According to her, sologamy is a radical move against patriarchy, a social justice expression, and an announcement of breaking away from the stereotypical expectations put on women.
In that sense, she says, it could be an empowering choice. “Many people can have many different ways of deciding what makes sense to them in terms of intimacy, and what kind of commitment is most nourishing for them,” she says.
Dr Saurabh Mehrotra, a psychiatrist at Medanta Hospital near New Delhi, says it is likely that sologamy will increase in future.
“The trend will only increase with time since a substantial part of the world’s population is either single, unmarried, separated or divorced. And the concept of self-love is also getting more acceptability,” he said.
Advising against dismissing sologamy as a bizarre act, he says, “The concept needs better understanding. As of now, we hardly have any data to understand if there are patterns in the cases.”
The flip side to sologamy, according to Mehrotra, is that it can cut people off from other relationships and even lead to isolation.
Bhat believes that linking Bindu’s childhood experiences with her decision to marry herself could be dangerous.
“To say that Bindu, as a survivor of sexual abuse, has married herself as a reaction to the abuse would be incorrect because that would mean we are pathologising the person,” she says.
“People don’t choose alternative modes of expressing their identities because something wrong has happened to them.”
At Bindu’s home in Gujarat, meanwhile, the media attention she had been getting for more than a month has finally stopped and the monsoon rains have started pouring.
She says this is the best time to go for her honeymoon – a vacation with herself to celebrate the marriage.",4
113,"2021 : l’Odyssée de l’espèce
Cette critique est réalisée dans le cadre d’un service de presse fourni par Albin Michel Imaginaire. Merci à l’éditeur, à Gilles Dumay et tout particulièrement à Romain Lucazeau pour sa sympathique dédicace.
Cinq ans après son premier roman, le très bon Latium (clic et clic), Romain Lucazeau revient avec un second (on l’espère plus prolifique à l’avenir, même si le fait qu’il vienne d’accéder à de prestigieuses fonctions ne rend pas l’hypothèse très probable, malheureusement), La nuit du faune, qui s’inscrit dans un univers différent. De Latium, j’avais dit : « Si Romain Lucazeau publie quoi que ce soit d’autre, j’achète sans la moindre hésitation. Parce que si pour un premier roman, on frôle le chef-d’œuvre, m’est avis qu’au deuxième, troisième au pire, on ne fera pas que le frôler ». Eh bien mon pressentiment était le bon, car La nuit du faune est bel et bien un authentique chef-d’œuvre, dépassant de très loin tout ce que la SF française a jamais pu produire, et projetant son auteur, tel un javelot tiré de la main d’un dieu, directement au panthéon de la Science-Fiction mondiale, grands-maîtres anglo-saxons y compris. Si, si. Car si l’auteur aixois s’est inspiré de ces derniers (j’y reviendrai), son roman est supérieur à la somme des parties qui le composent, et une Hard SF d’ampleur cosmique digne de Rajaniemi, Baxter, Zindell et Clarke, probablement ses principaux inspirateurs.
Et d’ailleurs, puisqu’on en parle, beaucoup de gens, qui déclarent avoir hâte de lire ce livre, semblent n’en avoir appréhendé (et la communication de l’éditeur n’y est certainement pas étrangère) que l’aspect conte philosophique. Il est certes incontestable, mais comme chez Hannu Rajaniemi, il est étroitement mêlé à une Hard SF de haut niveau, même si monsieur Lucazeau fait de bien plus gros efforts que le finlandais pour rendre l’aspect scientifique de la chose, de plus en plus (omni)présent au fur et à mesure qu’on avance dans le roman, accessible à toutes et à tous. Même si, d’expérience (pour avoir traduit une nouvelle de Rajaniemi opérant dans un registre assez similaire et pour observer de très près toutes les critiques de Hard SF dans la blogosphère et ailleurs), je sais que ce qui me paraîtra accessible théoriquement à toutes et à tous laissera en fait sur le bord de la route un certain nombre de lectrices et de lecteurs. Tout en étant conscient, donc, que La nuit du faune n’est peut-être pas ce qu’il pensait être de prime abord, j’espère toutefois que le lecteur potentiel ne sera pas effarouché et saura faire l’effort nécessaire pour suivre (il n’y a vraiment RIEN d’insurmontable, hein). Parce que dans le cas contraire, ledit lecteur passerait vraiment à côté d’un immense roman ! D’ailleurs, dans mon panthéon personnel de la SF, je le placerai désormais en quatrième position, ex aequo avec Diaspora de Greg Egan, et après l’indétrônable Hypérion, Vision aveugle et la médaille de bronze Inexistence (clic et clic).
Base de l’intrigue et personnages
Au sommet d’une montagne, il y a une maison entourée d’un vaste parc, et sertie dans une bulle qui la met à l’abri de toutes les forces régnant dans le monde extérieur, temps y compris. Une petite fille, Astrée, y vit. Un jour, un Faune, qu’elle nommera Polémas (la majorité des noms de personnages sont issus du « roman des romans », qui s’appelle bien entendu…L’Astrée !), y pénètre. Il considère cet endroit comme le séjour des dieux, et vient y chercher leur savoir pour conférer la puissance à son peuple, à peine sorti de sa préhistoire.
Bien entendu, Astrée n’est pas vraiment une petite fille, mais Kalinda des fleurs… pardon, une sorte d’avatar (au sens mythologique et Hindouiste du terme), rajeuni et à la mémoire expurgée, de la dernière (post)humaine, qui attend sans rien faire, sur cette montagne, depuis des centaines de millions d’années. Et la montagne n’en est pas vraiment une non plus, d’ailleurs. Pas plus que Polémas n’est un Faune (sa description évoque plus une sorte de… Totoro, si vous me permettez cette comparaison osée), mais un membre de la dernière en date des espèces intelligentes maîtresse de la Terre (je vais y revenir). Astrée le qualifie même de Premier représentant de celle-ci tant elle est d’apparition récente (les plus éveillés d’entre vous remarqueront que l’association du Premier et de la Dernière a déjà un certain parfum Stapledonien, qui ne va aller qu’en s’intensifiant). Elle lui explique que sa quête est vaine, car comme toutes les autres espèces intelligentes, la sienne s’apercevra que lorsque la science est achevée et qu’il n’y a plus rien à découvrir, il n’y a plus, non plus, de raison de vivre (une perspective très Eganienne, période Amalgame -on notera aussi avec intérêt que le centre de la galaxie est évité / inconnu des meta-civilisations-, voire… Lovecraftienne : le savoir causera notre perte). Et que donc, ses efforts héroïques pour parvenir jusqu’à elle sont stériles, puisque tout est voué à l’entropie, et que toutes les civilisations périront (une perspective cette fois proche d’Alastair Reynolds, période House of suns). En gros, trois sorts attendent toutes les races : stagner, mourir ou changer d’une façon si radicale que cela revient à mourir. Argh !
Mais lui s’entête, alors elle lui propose de lui démontrer la véracité de ses dires en lui montrant les différentes civilisations du Système solaire d’abord, de la galaxie ensuite, avant de finir leur odyssée à dix millions d’années-lumière de la Terre. Ce voyage, ils l’accompliront d’abord sous forme d’une copie sentiente composée de neutrinos (et ce transport sous forme « éthérée » évoque un des livres de SF les plus fondamentaux, Créateur d’étoiles d’Olaf Stapledon -et d’ailleurs pas que sur ce plan précis), tandis que leurs corps resteront au sommet de la montagne, puis grâce à un phénomène d’intrication quantique. En chemin, ils vont gagner un nouveau compagnon de route, Alexis, et rencontrer de nombreux personnages, comme Galatée (ces noms étant, une fois encore, tirés de L’Astrée).
Précisons que chacun des trois personnages principaux représente un désir des races de l’univers : l’immortalité (Astrée), le risque de mourir (Alexis ; à la Adam-Troy Castro) et la survie (Polémas le Faune). Signalons, aussi, au passage, la présence d’un petit aspect métafictif (p 175).
Structuration du récit
Il me faut tout d’abord expliquer que Romain Lucazeau fait de l’Hypothèse Silurienne une réalité : la Terre donne régulièrement naissance à une nouvelle espèce intelligente, qui développe la technologie, épuise les ressources en hydrocarbures, Terres rares et Actinides facilement accessibles, avant de provoquer un effondrement écologique et soit de mourir, soit de partir dans l’espace (sachant qu’à chaque fois, seule une « élite » part, grâce aux efforts de tous les autres). La tectonique des plaques permet alors à la fois d’effacer pratiquement toutes les traces de leur passage (une idée jadis employée par David Brin, d’ailleurs), de renouveler les gisements minéraux et de permettre la lente formation de nouveaux hydrocarbures et autres gisements de charbon. Au bout de 200 millions d’années, une nouvelle espèce intelligente apparaît, et le cycle, dit du Carbone, recommence. Les humains sont la cinquième espèce issue de la Terre, les Faunes la huitième (au passage, Lucazeau explique ainsi la régularité des extinctions de masse au cours de la longue histoire de notre planète). On voit donc que La nuit du Faune relève (comme La cité et les astres de Clarke, entre autres) de la SF de la fin des temps / Terre mourante, que ce soit du fait de l’échelle temporelle ou de la perte d’élan de la race humaine, oisive et indifférente.
Pourquoi est-ce que je vous dévoile ça ? Pour deux raisons. D’abord, parce que Astrée va commencer par montrer au Faune le devenir, invariablement tragique, dans un sens ou un autre, des différentes espèces issues du cycle Terrestre du carbone, avant de lui faire rencontrer des races extraterrestres. Ensuite parce que cette notion de cycles est un des éléments structurant le récit.
En effet, une lecture naïve ou peu attentive conclura que celui-ci est construit de façon centrifuge par rapport à la Terre, et centripète par rapport à la Voie Lactée (avant un grand bond vers les limites du Groupe Local un peu avant la fin). En clair, le voyage de nos héros va les mener d’abord vers Jupiter, puis Encelade, le nuage d’Oort, une planète errante dans l’espace interstellaire mais pas très loin de l’Héliopause, avant de se diriger petit à petit vers le Trou Noir central, Sagittarius A, et de faire un bond de géant final. Mais, si on y regarde de plus près, en fait le récit est structuré selon quatre autres axes, moins évidents. Le premier est de dévoiler une série de cycles enchâssés, celui du Carbone donnant naissance à celui du Silicium (dans une perspective très Asimovienne, période L’homme bicentenaire), qui lui-même donne celui de la matière exotique, puis de la matière non-baryonique. Le second, connexe, part de créatures familières comme le Faune et aboutit à des machins qui vivent dans des trous noirs ou sont codés dans la croute d’une étoile à neutrons (je vous l’avais dit, c’est de la Hard SF…). Dans le même genre, on part de la Terre et de la Physique banale et on aboutit aux frontières du Groupe Local et surtout de ladite science. Le troisième débute avec des créatures du même degré d’intelligence que le Faune, même si plus avancées, et donc au moins en partie compréhensibles, pour arriver à ce que Zindell ou le projet Orion’s arm appelleraient des « Dieux » de niveau toposophique élevé. Le quatrième part de « simples » civilisations, isolationnistes, voire égoïstes, passe par des meta-civilisations robotiques et finit en une pan-civilisation formée de ce que j’appellerais des (petits) Points Oméga du pauvre (à l’échelle d’un amas de galaxies), dans une perspective, une fois encore, Asimovienne (*ahem* Galaxia *hum*).
Sense of wonder / dread
Il n’y a pas de Sense of wonder présent dans le roman La nuit du Faune : cet objet n’est en réalité pas fait de papier, mais de senseofwonderium pur ! Romain Lucazeau imagine, recycle (je vais en reparler) et fait siennes certaines hypothèses et certains scénarios (comme la possibilité éventuelle de se servir d’un astéroïde interstellaire de passage dans le Système solaire comme d’une arche pour partir au hasard vers d’autres étoiles) lorsque Astrée montre au Faune ce que sont devenues les espèces successives issues de la Terre. Là aussi, on s’aperçoit d’une constante : une stratégie payante est de s’installer là où les autres ne veulent pas aller, parce que c’est trop dangereux ou pas assez rentable. D’où la plongée dans les nuages de Jupiter (vu l’état incorporel dans lequel se trouvent les personnages, difficile de ne pas penser à l’entité qui fut Dave Bowman chez Clarke et à son propre tour du Système solaire), d’où l’être qui est en fait une civilisation et qui s’est réduit à une expression tautologique effroyablement nihiliste et narcissique de lui-même, d’où l’affreuse « civilisation » esclavagiste des astéroïdes du Nuage d’Oort, puis celle d’Alexis (qui a eu une évolution « à la Clarke » -dans 2001-, où les explorateurs abandonnent leurs fragiles corps organiques pour des substituts de métal indestructibles). Et d’où cette espèce qui s’est embarquée sur l’astéroïde en vadrouille (à la Oumuamua)… sans aucun contrôle sur sa direction, mais par contre avec un abominable degré de contrôle sur la société qui peuple ses entrailles.
Et les merveilles ne font que commencer : étoiles à neutrons, trous noirs, IA, matière exotique, matière noire, autres galaxies, ce sont tout le ban et l’arrière-ban des prodiges de l’astrophysique, de la cosmologie et de la physique des particules qui sont conviés à la célébration. Et que dire de la fin, qui donne carrément une explication (à la Stephen Baxter) des plus grands mystères de la cosmologie, comme les trous noirs supermassifs primordiaux, la structure à grande échelle de l’univers, l’Hypothèse du Big Bounce, la formation des quasars et des galaxies, la cause réelle des extinctions de masse terrestres et l’origine de la vie et de l’intelligence (Clarke rencontre Leiber, en quelque sorte).
Mais bien entendu, il y a aussi de l’effroi dans ce récit, devant la puissance de certains êtres ou civilisations, les dimensions colossales ou les propriétés terrifiantes de certains objets astrophysiques, les gouffres spatiaux ou temporels impliqués, l’égoïsme de la plupart des civilisations (et leur impermanence due à leur propension à l’autodestruction), la guerre et l’esclavage omniprésents, la dictature absolue très fréquente, un cosmos qui n’offre que fausses solutions, errances et pièges, qu’un choix entre autonomie et mort ou au contraire survie et servitude (« bienveillante »), et j’en passe. Et peut-être par dessus-tout, le fait que quels que soient les efforts d’une race, ils resteront vains devant le poids écrasant de l’entropie (sauf que… la séquence de l’Observateur remet bien des choses en perspective !).
Le pauvre Faune, qui vient après tout d’une culture qui sort à peine de sa propre version de la Préhistoire, va ainsi avoir du mal à encaisser bien des choses ! (au passage, il sert de candide à qui il faut expliquer les choses simplement et de façon compréhensible, et donc d’avatar du lecteur non-féru de science ou de Hard SF -et j’ai l’inquiétante intuition que cela va constituer une très grosse part du lectorat du livre…).
Pourtant, même le féru de Hard SF va savourer La nuit du Faune, tout simplement parce que ce roman est un peu un best-of de ce qu’il a vu chez un grand nombre d’auteurs de tout premier plan. Ce qui me conduit à…
Hommages et ressemblances (peut-être involontaires)
Dans ma critique des deux volumes de Latium, j’avais souligné que le roman était un peu trop inspiré par Banks et Simmons à mon goût (au passage, la morale finale de La nuit du Faune à un très fort parfum de celle de L’éveil d’Endymion : le sens de la vie ne réside pas dans la durée, mais dans l’intensité), sans compter pléthore d’autres auteurs de SF. Défaut classique de tout premier roman, me direz-vous. Certes. Mais là, c’est le deuxième, donc le fait que les emprunts aux Grands Maîtres de la SF anglo-saxonne soient légion devrait me poser encore plus problème, théoriquement. Sauf que Romain Lucazeau a forgé une histoire de la vie dans l’univers qui transcende ses éléments constitutifs, qui est plus que la simple somme de ses parties : il recycle certes beaucoup Clarke (de la montagne qui est presque une Diaspar -la mémoire d’Astrée est « éditée », après tout- aux posthumains qui reviennent sur Terre après avoir visité la galaxie, du Monolithe en passant par le fantôme de Bowman), toute la fin hurle « STEPHEN BAXTER ! », une partie pourrait sortir tout droit de chez David Zindell, le Tubule est la Voie chez Greg Bear, il y a une mention difficile à rater au Fleuve de l’éternité de Farmer, la page 243 cite mot pour mot le début de Star Trek : TOS, et j’en passe (sans compter que le concept de base a l’air de sortir d’un mélange de la nouvelle Le serveur et la dragonne d’Hannu Rajaniemi, avec son entité post-humaine qui s’ennuie, cherchant désespérément la nouveauté alors que tout a été expliqué par la science, et bien entendu des romans d’Olaf Stapledon, et que Lucazeau recycle une partie de ses propres concepts -philosophie, mythologie grecque et SF-), MAIS l’ensemble forme un tableau plus complet que celui de ses prédécesseurs (à l’exception peut-être de Stephen Baxter et Stapledon -et encore, ça dépend sur quel plan on se place), réduisant leurs œuvres, pourtant formidables, à l’état de simple grain sur un chapelet.
Signalons tout de même qu’il y a des « anti-influences » : p 97, le fait de guider de « jeunes races » est par exemple présenté comme un tabou, alors que c’est la base de l’univers phare de David Brin ! Et ceci alors que comme chez ce dernier, l’Humain est un Franc-Tireur, qui refuse de se laisser embrigader dans une des meta-civilisations galactiques. Influences et anti-influences peuvent, pour un même auteur, cohabiter, ce qui rend ainsi l’aspect « ce n’est qu’un assemblage d’éléments vus ailleurs » à nuancer, et ce d’autant plus que Romain Lucazeau apporte aussi, évidemment, ses propres idées dans ledit assemblage.
Si je ne devais toutefois retenir qu’une poignée d’influences, les principales, outre Baxter sur la fin du roman (où il éclipse toutes les autres), je choisirais Rajaniemi et Clarke, pour le mélange conte (pour le premier), et Hard SF + côté poétique (pour les deux).
En chipotant beaucoup…
Outre des influences omniprésentes et très (trop ?) visibles, toujours au chapitre défauts potentiels, mais peut-être pas pour tout le monde ou selon tous les angles d’analyse, j’ai été TRÈS frustré par la « Guerre temporelle » à la Leiber expédiée en un recto et demi à la fin, presque autant que par le très court passage uchronique (celui dans l’équivalent du RTH-ECMO de Simmons) dans Latium. Monsieur Lucazeau me « doit » donc désormais deux romans : le prélude uchronique de ce dernier, ET « Astrée dans le Temps » (il y a d’ailleurs un vague côté « fin de BSG » à la chose, je pense). De même, on pourrait dire que un peu comme dans Latium (même si ici, ça ne m’a pas frappé, et encore moins gêné), l’auteur ne s’attarde pas assez sur certaines scènes / personnages / décors, passant à cent à l’heure des uns aux autres. Mais tout compte fait, vraiment pas de quoi remettre en cause l’excellence globale du roman !
Un incontestable monument de la SF… mais peut-être pas à conseiller à tout le monde
Comme je l’ai déjà précisé, je n’ai pas l’impression que beaucoup de ses lecteurs potentiels aient pris la mesure de la Hard SF d’élite que constitue en fait La nuit du faune, s’étant arrêtés à l’aspect « Conte » avec une petite fille et un Faune. J’imagine sans peine que le réveil va être brutal et douloureux pour la plupart, surtout que l’écrasante majorité ne lisent pas ce type de Hard SF (vous me direz, c’est peut-être l’occasion d’y prendre goût…). Pourtant, ce n’est pas la seule difficulté qui attend un lecteur potentiel : il y a bien sûr le contenu philosophique, loin d’être négligeable ; il y a aussi le style de Romain Lucazeau, qui tout en étant d’une incontestable richesse, est sans doute moins accessible à celui ou celle qui lit peu de grosse SF adulte que d’autres, même si les parties Hard SF sont (paradoxalement ?) plus accessibles sur le plan stylistique (pas forcément sur celui du contenu, mais plutôt du vecteur) que les autres (et plus on avance dans le roman, plus l’aspect Hard SF est omniprésent) ; il y a, enfin, la densité absolument hors-normes de la chose : le roman ne fait « que » 250 pages, ce qui peut donc faussement indiquer quelque chose de facile et de rapide à lire (je l’ai achevé en moins de 24 heures, écriture de cette critique comprise, après tout), alors qu’en réalité, il n’en est rien : chaque page, chaque ligne, est remplie de concepts philosophiques, Historiques, scientifiques, SF, à méditer, digérer, analyser, ce qui représente un effort mental digne d’un roman au bas mot deux fois plus gros. Sans compter que ce n’est certainement pas le genre de lecture « détente » ou « reposante » (là aussi, j’ai l’impression que pas mal de gens se font une idée particulièrement fausse de la chose), mais une Histoire passée et future de l’univers d’une ampleur exceptionnelle et d’une vertigineuse complexité.
Bref, comme je l’ai dit en introduction, si je tiens La nuit du faune pour un roman exceptionnel, je ne le recommanderais pourtant pas à tous les profils de lectrices et de lecteurs, et certainement pas à des débutants ou des gens qui ne lisent que du Young Adult. Mais bon, comme le dit l’auteur, « Rien n’est plus important que la capacité du monde à contredire nos attentes », donc…
Aux autres, je dirais ceci : ceux d’entre vous qui me connaissent savent que je ne place pas facilement un auteur français sur le même plan, voire sur un plan supérieur, à celui des plus Grands Maîtres de la SF anglo-saxonne ; et pourtant, je le dis haut et fort : avec ce deuxième roman, Romain Lucazeau a conté une saga de l’Histoire des civilisations (et de leur impermanence) et surtout de la vie dans l’univers (et de son combat pour survivre et prospérer) d’une ampleur, d’une puissance épique et d’une démesure exceptionnelles, et même s’il reste encore un auteur relativement débutant (dans la forme longue, du moins), La nuit du faune le place sans conteste possible au panthéon de la Science-Fiction, au minimum francophone. Je ne serais d’ailleurs pas du tout étonné que ce roman, comme Latium, soit traduit dans d’autres langues, ce qui, pour un auteur français de SFFF, reste rarissime.
Pour finir, un passage plus personnel, disons : pour sa coopération avec l’Armée via sa participation à la Red Team, Romain Lucazeau a, avec d’autres, subi l’ire de la frange la plus militante des écrivain(e)s de SFFF. La qualité phénoménale de ce roman, et le succès, considérable et amplement mérité, que je ne doute pas qu’il va rencontrer, constitue la plus belle réponse qu’il pouvait leur apporter ! Et d’ailleurs, à l’heure où, dans les mêmes cercles, il est de bon ton de dénigrer la SF des Grands Maîtres, Lucazeau, tout au contraire, leur apporte, ainsi qu’aux classiques issus de leurs plumes, un des plus vibrants hommages que j’ai eu le plaisir de lire. On imagine d’ailleurs sans peine que des passages comme ceux de la page 153 (« Vous ne partagez pas la bonne vision. Cette discussion est inutile ») pourraient résumer le sectarisme de certains !
Pour aller plus loin
Si vous souhaitez avoir un deuxième avis sur ce roman, je vous recommande la lecture des critiques suivantes : celle de Feydrautha, celle de Gromovar, de Just a word, de Yogo, de Fourbis et têtologie, de Yuyine, de Célinedanaë, de Tachan, du blog Constellations, du Nocher des livres, du Chroniqueur, de C’est pour ma culture, de la Navigatrice de l’imaginaire, de FeyGirl, du Dragon Galactique,
Envie de soutenir le blog ?
Ce roman vous intéresse, vous êtes client d’Amazon et souhaitez soutenir le blog ? Passez par un des liens affiliés suivants pour votre achat, cela ne vous coûte strictement rien de plus !
Acheter en version papier / Kindle
Si vous lisez sur Kindle, vous pouvez également soutenir le blog en vous inscrivant pour un essai gratuit de l’abonnement Kindle, via ce lien, et si vous audiolisez, vous pouvez aider le Culte en essayant gratuitement Audible via ce lien.
***
Retour à la page d’accueil
75 réflexions sur “La nuit du Faune – Romain Lucazeau”
J’ai survolé ta chronique, j y reviendrai après ma lecture. J’ai un peu peur tout de même…
J’aimeAimé par 1 personne
Si ça peut te rassurer, Romain Lucazeau aurait fait un excellent vulgarisateur scientifique. Avec un peu de bonne volonté (ce dont tu ne manques pas), ça passera sans souci. Au pire, si il y a un point que tu ne saisis pas, un petit mp sur Twitter et c’est réglé 😉
J’aimeAimé par 1 personne
OK. Je note. Merci 😀
J’aimeAimé par 1 personne
Wow quelle chronique ! J’avoue que je vais me laisser tenter.
J’aimeAimé par 1 personne
Tu vas adorer 😉
J’aimeAimé par 1 personne
Je viens juste de finir. C’est monumental de SoW. Comme dirais les jeunes « C’est une dinguerie ». Il me reste plus qu’à pondre ma chronique.
J’aimeAimé par 1 personne
C’est tout à fait ça 😉
J’aimeAimé par 1 personne
J’ai dévoré la première moitié… et je suis conquis !
C’est « très » accessible, le langage est riche, la Science est à l’honneur mais (pour l’instant) très bien explicitée.
Un plaisir de lecture, j’y retourne et relirai ta chronique que je n’ai que survolé après ma lecture.
J’aimeAimé par 1 personne
Je trouve que Romain Lucazeau a un vrai talent de vulgarisateur scientifique, en effet.
J’aimeJ’aime
Un bon vulgarisateur en effet mais il y a quand même quelques passages assez ardus.
Et quel voyage, se laisser porter par la prose de Lucazeau est un bonheur.
J’aimeAimé par 1 personne
Vivement le prochain ! 😉
J’aimeJ’aime
Bonjour Apophis,
Fervent lecteur de ton blog (et notamment des formidables Guides de lecture et autres Oeil d’Apophis & Co : Bravo et grand merci pour cette initiative qui me permet de découvrir de supers bouquins adaptés à mon niveau littéraire SFFF!), cette critique me laisse un petit goût amer : ayant déjà eu bien du mal à comprendre / apprécier la nouvelle de Rajaniemi cet après-midi, c’est sacrément frustrant mais j’ai bien peur que ce chef-d’œuvre (comme qlqs autres) ne sera pas pour moi…
Allez je retourne aux Émissaires des Morts…
Petit scarabée qui apprend l’humilité littéraire 🤪
J’aimeJ’aime
Bonjour et merci ! La nouvelle de rajaniemi ressemble à La nuit du faune dans le sens où ce sont deux contes philosophiques mélangés avec de la Hard SF et une écriture avec un côté poétique. En revanche, là où le finlandais ne fait aucun effort pour être compréhensible par les lecteurs non-férus de science ou de SF, le français en fait, lui, beaucoup pour être compréhensible par le plus grand nombre. Je pense donc que tu as bien plus de chances d’apprécier / saisir le texte de Lucazeau que celui de Rajaniemi.
J’aimeAimé par 1 personne
Je suis entrain de le lire donc je lirai ta chronique quand j’aurai fini ^^. C’est pour le moment passionnant. J’ai le coté poésie et philosophie que j’attendais, mais c’est vrai, peut-être pas autant que je l’attendais :D.
J’aimeAimé par 1 personne
J’ai trouvé que plus on avançait, plus il s’effaçait devant le côté scientifique, Hard SF et sense of wonder. Moi ça me convient très bien, mais je conçois aisément que d’autres profils de lectrices et de lecteurs recherchent plus le côté conte / philo / poésie. C’est d’ailleurs pour ça que j’ai essayé de bien faire saisir aux lecteurs potentiels ce qu’était exactement La nuit du faune, toutes ses dimensions.
J’aimeJ’aime
Devant cette chronique alléchante , je vais le précommander sans tarder, il devrait arriver assez vite chez nous quand même. Comme je suis en train de lire Latium , je resterai dans les univers étonnants de Lucazeau.
J’aimeAimé par 1 personne
Bonne lecture 😉
J’aimeJ’aime
Merci pour les précisions concernant le côté Hard SF, comme d’autres avant moi, ça me donne encore plus envie de le lire (d’autant plus d’un auteur français !).
Très étonné concernant le nombre de pages, en lisant ta chronique, je visualisais un roman de 500/600 pages voire plus !
J’aimeAimé par 1 personne
Oui, c’est court mais d’une densité complètement folle.
J’aimeJ’aime
Même si t’as failli m’avoir avec le faune-totoro, je sais bien que ce bouquin est pas du tout pour moi 😀
J’ai vu sur Twitter que les auteurs de la red team se font cracher dessus par une partie des lecteurs. Je trouve ça vraiment dommage. Pour un lectorat qui encense souvent l’art de la nuance, c’est un jugement binaire assez bas du front.
J’aimeAimé par 1 personne
Je ne pense pas que ce soit pour toi, en effet.
Je suis bien d’accord. Et je suis de plus fermement convaincu que chacun devrait pouvoir travailler avec / pour qui bon lui semble sans se faire trainer dans la boue.
J’aimeJ’aime
Bon, Latium m’ayant plu, le début de la critique semble dithyrambique dès les premiers paragraphes, j’arrête là et il prend sa place dans la valise avec les autres. ‘faut juste que je l’achète…
J’aimeJ’aime
rahh non, à mois de me le faire livrer en Grèce…
J’aimeAimé par 1 personne
Les problèmes de place, de poids et de livraison se règlent très facilement avec une liseuse et les versions électroniques 😉
J’aimeJ’aime
Je viens seulement de recevoir « Latium » donc malgré ta critique dithyrambique il attendra sans doute l’année prochaine ! Mais sûr qu’en citant Olaf Stapeldon en référence je m’évade déjà entre poésie cosmique et nostalgie juvénile! Merci à toi de mettre à notre portée le meilleur de la SF 😉 (parce que je n’en lis plus autant qu’avant et donc que le choix est d’autant plus crucial )
Longue vie au Culte!
J’aimeAimé par 1 personne
Merci ! J’aime beaucoup ta « poésie cosmique », le terme décrit admirablement les textes de Stapledon, Lucazeau ou Rajaniemi 😉
J’aimeJ’aime
Je ne sais pas trop si ce roman est fait pour moi ou non. Je suis un peu perplexe après la lecture de ton excellente et très complète chronique. Je vais attendre les retours de lecteurices à mon niveau en hard sf pour juger. J’avoue qu’en plus je ne m’attendais pas du tout à ce que ça soit de la hard sf en voyant la couverture, le titre, bref surprise surprise. J’admets qu’en prime, j’étais davantage concentrée sur le roman d’Estelle Faye à venir bientôt chez AMI aussi 😅
J’aimeAimé par 1 personne
Je dirais oui pour le niveau et oui pour la capacité de ce roman à te séduire (et sinon, au pire, nous ne sommes pas si loin de Noël que ça 😀 ).
C’est pour ça que j’ai lourdement insisté sur l’aspect Hard SF : ces dernières semaines, j’ai clairement eu l’impression que des tas de gens n’avaient pas conscience du sous-genre majoritaire du livre, le « réduisant » à un conte philosophique (ce qu’il est, mais pas seulement, et sans doute pas principalement ; comme le dirait probablement l’auteur, c’est une « poésie scientifique »). Parce que je ne voudrais pas voir des dizaines de « ce livre n’était pas pour moi » juste parce que les gens sont partis avec des idées préconçues (il est vrai bien « aidés », si j’ose dire, par une présentation de l’éditeur qui me paraît inadaptée).
J’aimeJ’aime
Je trouve ça un peu surprenant quand même. L’éditeur en vendra sûrement davantage en le présentant comme il le fait mais l’accueil critique risque d’être très mauvais et de nuire à l’auteur du coup, c’est plutôt dommage de présenter les choses sous cet angle au lieu d’assumer le roman dans sa globalité.
Je te ferai sûrement une fois de plus confiance, nous verrons ce que ça donnera 😉
J’aimeAimé par 1 personne
Je vois les choses de la même façon que toi : visiblement, chez AMI, ils pensaient qu’en présentant le roman comme de la Hard SF, ils allaient effaroucher une partie du lectorat (alors que je vois presque plus de : « Ah, c’est aussi de la Hard SF ? Chouette ! » qu’autre chose), mais comme me le disait il y a quelques années un des directeurs de collection de l’Atalante, il vaut mieux des gens qui ne lisent pas (et donc n’écrivent pas de critiques, particulièrement sur les sites marchands) un livre qui n’a aucune chance de leur plaire que d’autres qui l’ont lu par erreur et qui vont répandre leur déception (et, pour certains, leur fiel…) dans des dizaines de chroniques catastrophiques qui vont couler le livre. C’est d’ailleurs pour ça que pour lui, des chroniques négatives / mitigées / nuancées très détaillées, argumentées et surtout précoces sont un bien, contrairement à ce que l’on pourrait penser intuitivement : elles détournent du bouquin ceux pour qui il n’est pas fait et donc provoquent un ratio critiques positives / négatives nettement plus favorable.
J’aimeAimé par 1 personne
Et ben, pu…, Tu sais allécher le chaland…
Ca doit être quelque chose ce roman, hâte de découvrir mieux que le splendide Latium
Gloire au ferpent !
J’aimeAimé par 1 personne
Merci ! Avec Feydrautha et d’autres, on pense que c’est le roman de SF française de l’année… minimum. Pour ma part, je pense qu’on peut largement le placer au panthéon de la SF francophone toutes époques confondues et que même si on élargit au monde anglo-saxon, ça reste du lourd.
J’aimeJ’aime
D’habitude j’interviens sur le forum du Belial mais je n’ai pas trouvé de topic sur le livre.
Ta critique m’a convaincu. La prese’tation de Gilles m’avait titillé mais là vendu.
J’aimeJ’aime
Salut et bienvenue, M ! Il n’y a pas encore de fil sur ce livre sur le forum (au moment où je rédige ces lignes) à ma connaissance. Connaissant un peu tes goûts, je pense que ce roman a tout pour te plaire 😉
J’aimeJ’aime
Ping : La Nuit du Faune – Romain Lucazeau – L'épaule d'Orion
Merci pour cette critique, je pense que je serais passé à côté sinon, livre perdu au milieu de l’avalanche de sorties 😉
J’aimeAimé par 1 personne
De rien ! C’est vrai qu’aussi bien en VO qu’en VF, c’est un tsunami, et c’est très loin d’être fini. Mon programme de lecture compte une écrasante majorité de nouveautés jusqu’en… novembre !
J’aimeJ’aime
Ping : Throwback Thursday #2021-29 – Les Blablas de Tachan
Ping : Chroniques des livres éligibles au Prix Planète-SF 2022 : L à Z (par titre) - Planète-SF
J’ai commencé à lire cette critique mais je n’ai pas pu arriver au bout… entre temps j’ai scrollé tout en bas pour prendre le livre sur Amazon. 🙂
On m’a rarement vendu aussi bien et aussi rapidement un livre je dois dire !
J’aimeAimé par 1 personne
A ma connaissance, il y a pour l’instant quatre critiques sur ce roman : la mienne (dithyrambique), celle de Feydrautha (le livre de SF française de l’année… au minimum), celle de Just a word (10/10, note rarissime chez lui) et celle de Gromovar (Bluffant) : ça pose tout de suite le niveau 😀
J’aimeJ’aime
Le côté conte philosophique de la 4e de couverture ne me tentait pas du tout. Heureusement ta critique et celles des autres blogueurs (toutes dithyrambiques) me rassurent avec la hard SF. Vendu donc !
J’aimeJ’aime
Vu que le côté Hard SF est très largement plus présent que le côté conte et le côté philosophique, tu devrais logiquement aimer ce livre toi aussi. N’hésite pas à repasser par ici pour nous résumer ton avis 😉
J’aimeJ’aime
Ping : La nuit du faune – Fourbis & Têtologie
Merci pour ta chronique qui m’a permis de découvrir ce petit bijou, un véritable plaisir !
J’ai une question, il y a un concept que je n’arrive pas à appréhender (spoilers ahead) :
Les civilisations vivant au centre des galaxies dans des trous noirs supermassifs primordiaux, s’y sont recluses afin de se protéger de l’Ennemi. Or si l’entropie l’emporte, sur une échelle de temps suffisamment longue, elle fera s’évaporer les trous noirs primordiaux et ces sociétés s’éteindront, non ?
Je ne vois pas comment ils sont protégés de l’entropie, peux-tu éclairer ma lanterne de jeune faune perdu ?
J’aimeJ’aime
La clé est justement dans la durée de vie incroyablement longue des trous noirs et dans la stabilité de ce milieu, du moins jusqu’à l’évaporation finale : pour un trou noir d’une masse solaire, elle est de l’ordre de quelque chose comme 10 puissance 67 ans, il me semble. Et plus le trou noir est gros, plus la durée de vie augmente de façon « exponentielle ». Autant dire qu’il n’existera plus d’étoiles normales aptes à réchauffer des planètes très, très, très longtemps avant que les trous noirs ne disparaissent à leur tour. Ces civilisations seront donc en fait protégés de l’entropie bien plus longtemps que celles s’épanouissant hors des trous noirs.
J’aimeJ’aime
Ping : La nuit du faune de Romain Lucazeau – Au pays des cave trolls
Je viens de finir ma lecture, c’était du bonheur.
Spoilers : Comme le dit le commentaire juste au-dessus, l’auteur ne devrait pas dire que les Confinés seront à l’abri, les radiations Hawking en viendront à bout. Alors oui ce sera très long, mais ils disparaîtront aussi. J’ai trouvé que l’auteur se contredisait sur ce point.
Sinon rien à dire, si ce n’est que je serai ravi de trouver une analyse du texte et de ses références, je suis sûr que j’en ai manqué des tas. Merci encore une fois du conseil de lecture !
J’aimeJ’aime
Ping : Récursion – Blake Crouch | Le culte d'Apophis
Ping : La Nuit du Faune de Romain Lucazeau – Les Blablas de Tachan
Ping : La nuit du Faune — Romain Lucazeau – Constellations
Ping : La Nuit du faune, Romain Lucazeau – Le nocher des livres
Ping : La Nuit du Faune, de Romain Lucazeau – Les Chroniques du Chroniqueur
Quelle critique! J’ai écouté hier l’auteur invité dans le podcast de Lloyd Cherry, il est hautement intéressant, s’exprime très bien et semble très érudit. Comme dirait un ancien collègue : « chez celui là, il y a de la lumière à tous les etages » 🙂
Je vais commencer Latium, si son style me plait je continuerais avec La nuit du Faune.
Merci pour cette découverte
J’aimeJ’aime
Merci ! Les deux livres sont relativement différents, de mon point de vue (ne serait-ce qu’en terme de longueur), donc aimer / détester l’un n’est probablement pas une garantie absolue d’avoir le même sentiment pour l’autre.
J’aimeJ’aime
Ping : Apophis Box – Octobre 2021 | Le culte d'Apophis
Je viens de finir la nuit du Faune mais je suis dans un avis contraire: lecture pénible tout du long, je pense que le style de l’auteur n’est pas pour moi ( je n’avais pas réussi à aller au bout du 1er tome de Latium). Je n’y ai vu que des défauts: déséquilibre dans la narration entre les 3 personnages et le narrateur/auteur omniscient. Pas de différence de style suivant les personnages, même structure grammaticale et niveau de vocabulaire alors que le Faune est sensé être le « primitif ». Utilisation de vocabulaire « courant » terrien pour des métacivilisations. On commence avec le magicien d’Oz, on saute à une fantasy avec sémantique SF, on termine par une cosmogonie « humaine » ( conflit entre deux entités opposées ayant des agents se combattants depuis la naissance de l’univers). Tic d’écriture : répétition à « foison » des terme éternité, perfection et artificielle… J’arrête là, je dois avoir un biais mais j’avais l’impression d’un auteur qui n’avait pas réussi à choisir son style de roman, et naviguait entre plusieurs… Un roman hybride raté mais bourré d’idée intéressantes prisent séparément… Voila , un avis plus que mitigé mais je voulais vraiment terminer la lecture au vu des avis positifs dans bon nombre de blog, sachant que je suis régulièrement en phase avec Apophis sur les conseils de lecture SF/Fantasy. Par comparaison, un auteur comme Rich Larson à une facilité à jouer sur plusieurs styles d’écriture en lien avec le sujet et les personnages de ses nouvelles: lisez la Fabrique des lendemains (plusieurs pépites à l’intérieur). Désolé pour la longueur du comm. Cordialement
J’aimeJ’aime
Et bien je n’ai pas réussi à le finir 😦 J’ai aimé la mise en place, mais dans l’espace, mon coeur s’est arrêté. J’aime la Hard SF, la SF tout court, je comprends les concepts (je suis physicien de métier) … mais je n’ai pas pu décollé avec le duo. J’ai souvent trouvé artificiel l’usage de la science « dure » et l’effort de vulgarisation ne m’a pas aidé à l’accepter. Je me faisais une joie de ce roman… je crois que je vais laisser décanter quelques mois et y revenir.
J’aimeJ’aime
Merci pour cette analyse magnifique de ce récit tout à fait particulier. Ma culture en matière de littérature SF étant proche du néant en comparaison avec la votre, je n’ai pas pu déceler les similitudes avec les auteurs cités puisque je n’en ai encore lu aucun. Je me suis délectée de cette lecture et ressors avec les mêmes impressions : j’ai le cerveau en feu tellement il a été nourri !
J’aimeAimé par 1 personne
Avec plaisir !
J’aimeJ’aime
Ping : Prix Apophis 2021 | Le culte d'Apophis
Ping : « La nuit du faune » : Star Wars to the heaven – C'est pour ma culture
Je viens de terminer La nuit du faune, et j’en suis tout émoustillé. Son style, son contenu, l’émerveillement qu’on en ressent sont un véritable cadeau de l’univers et savoir qu’un tel livre peut être écrit me remplit de joie. Il est très inspirant et prend immédiatement le podium dans mon petit panthéon, directement à la place d’un autre roman moins touchant, moins immense, moins beau mais somme toute assez similaire : Les vaisseaux du temps de Stephen Baxter.
Merci pour cette découverte merveilleuse.
J’aimeJ’aime
Ping : Apophis Box – Avril 2022 | Le culte d'Apophis
Ping : Le courage de l’arbre – Leafar Izen | Le culte d'Apophis
Salut !
Lectrice de science fiction depuis un bon moment, je me suis mise à la hard SF l’année dernière grâce à tes chroniques qui sont un phare très précieux pour mes pérégrinations littéraires ! Merci donc à toi.
La lecture de La Nuit du Faune m’a beaucoup absorbée. Le foisonnement d’intelligences très diverses, offert par l’évolution et les avancées technologiques à travers l’univers, m’a laissé très rêveuse, d’autant que le récit malgré le déploiement de beaucoup de notions abstraites, est écrit dans un style très imagé, concret, sensible au sens de matériel. C’est sans doute la force du vulgarisateur et de l’écrivain.
N’étant cependant pas spécialiste (du tout) de sciences physiques (malgré mes efforts), je ne pense pas avoir aussi bien compris certains concepts que je ne l’aurais aimé (je pense notamment à la matière exotique ou à la matière non-baryonique). Surtout quelque chose me chiffonne et peut-être auras-tu le temps ou le souhait de m’aider à le comprendre : c’est le voyage permis par l’intrication quantique. Dans le récit, il semble que les personnages puissent passer d’un endroit à l’autre de l’univers car ils ne sont que des copies quantiques d’eux mêmes, et que (d’après ce que je comprends), leur identité est reproduite d’un ensemble de particules à un autre ensemble (puisque ces deux ensembles sont intriqués). Cela leur permettrait de voyager de façon instantanée. Toutefois, je lis partout que l’intrication quantique ne permet pas un transfert d’information instantané et même qu’aucune information n’est transférée ou échangée entre deux particules intriquées. Evidemment, il se peut que quelque chose cloche complètement dans ma compréhension de ce que présente Romain Lucazeau ou dans ma compréhension de la théorie de l’intrication quantique.
Pourrais-je bénéficier de quelques lumières ?
Merci beaucoup pour tout ton travail !
J’aimeJ’aime
Bonjour,
l’intrication signifie que les deux particules / objets corrélés doivent être décrits par un seul état quantique, et ce quelle que soit la distance qui les sépare. En clair, il n’y a pas, en vérité, deux objets ou particules, mais un tout inséparable (malgré la distance, parfois considérable, à laquelle se trouvent les composantes de ce tout), et tout changement ou mesure affectant l’un est instantanément répercuté sur l’autre, et ce bien avant que le résultat dudit changement ou de ladite mesure ait pu se transmettre à la vitesse de la lumière, limite indépassable par toute particule se trouvant dans l’espace (sachant que la théorie cosmologique de l’Inflation ainsi que l’expansion de l’univers nous enseignent que l’espace lui-même peut allègrement dépasser la vitesse limite : c’est la base du moteur supraluminique -théorique- d’Alcubierre ou de la propulsion dans Star Trek – par exemple-). Bien sûr, cela crée tout un tas de paradoxes et de problèmes avec les théories admises, mais constitue un phénomène incontestable, puisque prouvé par différentes expériences, y compris pour des « touts » comprenant un grand nombre de particules (jusqu’à des fullerènes et des petits diamants).
Différentes théories tentent d’expliquer comment la chose peut fonctionner dans le cadre des modèles faisant consensus de la Physique (Relativité, Mécanique quantique), mais on entre là dans des domaines qui dépassent de loin mes connaissances en physique quantique. Peut-être que mon camarade blogueur FeydRautha, du blog L’épaule d’Orion, que tu connais sûrement et qui est Physicien de profession, pourra te renseigner plus / mieux que je ne saurais le faire si tu as encore des questions. Sans parler de Monsieur Lucazeau lui-même.
J’aimeJ’aime
Merci, c’est très clair. J’irai très certainement embêter FeydRautha à l’occasion, alors !
Mais donc, si je comprends bien (désolée si j’enfonce des portes ouvertes), le dispositif que les personnages « empruntent » pour « voyager » produit une intrication entre les particules qui les composent et d’autres particules dans l’univers ? En fait, je partais du principe que ces particules étaient déjà intriquées et je ne comprenais pas vraiment le principe du « transfert » de leurs personnalités, alors qu’il est dit explicitement qu’ils sont simplement de nouveau « recopiés »… Est-ce que je me trompe ?
Merci encore en tout cas ! 😀
J’aimeJ’aime
Après une recherche rapide, l’auteur donne une explication du processus à la page 130 du roman. Le voyage dans le Système solaire et un peu au-delà se fait dans des « corps » faits de neutrinos, comportant une copie de la personnalité des personnages (les corps physiques restant sur Terre). Mais, pour aller plus loin, et étant donné que la vitesse de la lumière ne peut être dépassée, Astrée se sert de la machine cachée dans l’espace interstellaire pour déplacer, par intrication, sa conscience et celle de ses deux compagnons ailleurs dans la galaxie, en procédant à l’intrication entre les neutrinos d’une part et des particules se trouvant dans les lieux à visiter d’autre part. Enfin, c’est comme cela que je l’ai compris. En cas de doute, je vous suggère de poser directement la question à monsieur Lucazeau, sur Twitter, par exemple.
J’aimeJ’aime
Ping : Apophis Box – Mai 2022 | Le culte d'Apophis
Mais quelle belle histoire !
Après m’avoir fait découvrir Egan, Baxter et redécouvrir Clark, tu me fais rencontrer un nouvel auteur SF français qui plus est !
Merci Apophis.
Je confirme qu’il faut être attentif pour lire ce roman. Préféré être au calme pour apprécier !
J’aimeAimé par 1 personne
Avec plaisir !
J’aimeJ’aime
Ping : La nuit du Faune – Romain Lucazeau – Navigatrice de l'imaginaire
Ping : La Nuit du Faune, de Romain Lucazeau – Les Chroniques de FeyGirl
Ping : La nuit du faune | Miroir aux alouettes non baryonique – Le dragon galactique",0
114,"DALL·E 2
DALL·E 2 is a new AI system that can create realistic images and art from a description in natural language.
DALL·E 2 can create original, realistic images and art from a text description. It can combine concepts, attributes, and styles.
DALL·E 2 can can expand images beyond what's in the original canvas, creating expansive new compositions.
DALL·E 2 can make realistic edits to existing images from a natural language caption. It can add and remove elements while taking shadows, reflections, and textures into account.
DALL·E 2 can take an image and create different variations of it inspired by the original.
DALL·E 2 has learned the relationship between images and the text used to describe them. It uses a process called “diffusion,” which starts with a pattern of random dots and gradually alters that pattern towards an image when it recognizes specific aspects of that image.
In January 2021, OpenAI introduced DALL·E. One year later, our newest system, DALL·E 2, generates more realistic and accurate images with 4x greater resolution.
DALL·E 2 is preferred over DALL·E 1 for its caption matching and photorealism when evaluators were asked to compare 1,000 image generations from each model.
preferred for
caption matching
preferred for
photorealism
DALL·E 2 began as a research project and is now available in beta. Safety mitigations we have developed and continue to improve upon include:
We’ve limited the ability for DALL·E 2 to generate violent, hate, or adult images. By removing the most explicit content from the training data, we minimized DALL·E 2’s exposure to these concepts. We also used advanced techniques to prevent photorealistic generations of real individuals’ faces, including those of public figures.
Our content policy does not allow users to generate violent, adult, or political content, among other categories. We won’t generate images if our filters identify text prompts and image uploads that may violate our policies. We also have automated and human monitoring systems to guard against misuse.
Learning from real-world use is an important part of developing and deploying AI responsibly. We began by previewing DALL·E 2 to a limited number of trusted users. As we learned more about the technology’s capabilities and limitations, and gained confidence in our safety systems, we slowly added more users and made DALL·E available in beta in July 2022.
Our hope is that DALL·E 2 will empower people to express themselves creatively. DALL·E 2 also helps us understand how advanced AI systems see and understand our world, which is critical to our mission of creating AI that benefits humanity.",3
115,"Numéro coordonné par Evelyne Pieiller
Édition : Olivier Pironet
Conception graphique : Nina Hlacer
Photogravure : Patrick Puech-Wilhem
Cartographie : Cécile Marin
Correction : Dominique Martel
Remerciements à Philippine Masson et Kiliz Roques-Maitia
Travail de sape dans la galaxie ///// Evelyne Pieiller
I. La dystopie au pouvoir
Le pire n’est pas toujours sûr et l’avenir n’est jamais écrit, évidemment. Mais certains auteurs de SF ont su déceler les menaces dont sont porteuses les contradictions des démocraties libérales, y compris dans l’usage des nouvelles technologies, sous couvert de progrès. Quand la réalité commence à ressembler à la littérature, il est temps de se rappeler que la politique n’est pas une fiction.
Les meilleurs d’entre nous ///// Pierre Rimbert
L’État ou la beauté du manager ///// Pierre Musso
Numériser la société, éviter les conflits ///// Pablo Jensen
Protégés de A à Z
Vos souvenirs sont notre avenir ///// Alain Damasio
Ils arrivent, ils sont là ! Alors, on fait quoi ? ///// Marie-Françoise Allain
La SF à l’assaut du Pentagone : l’autre « Star Wars » ///// Norman Spinrad
Des tourne-disques en Amazonie ///// Greg Grandin
II. Les plus qu’humains
Les vieux mythes semblent sur le point de se réaliser : l’humain aura bientôt aboli ses frontières naturelles. Il ne connaîtra plus la mort, et il sera omniscient. En d’autres termes, il sera devenu un dieu, si du moins il a les moyens de payer la technologie nécessaire, et les pièces de rechange. Et si les intelligences artificielles ne prennent pas le pouvoir. Mais comment définira-t-on alors l’humanité ?
Comment engager la conversation avec les Martiens ///// Finn Brunton
Immortalité et pièces de rechange ///// Marcus D. Besnard
Voyager vers d’autres mondes, un désir vieux comme l’humain ///// Gérard Klein
Le temps d’un souffle… ///// Roger Zelazny
Vivre est dangereux : quantifier le risque ///// Dan Bouk
Oracles, mode d’emploi ///// E. P.
Une version singulière du transhumanisme, le cosmisme ///// Juliette Faure
La SF a-t-elle de l’avenir ? ///// Catherine Dufour
Devenez la marionnette virtuelle de vos désirs ///// Guillaume Barou
III. Perturbations dans le consensus
Une contre-information : la SF a beau batifoler dans les galaxies, elle rejoint parfois les objectifs de la philosophie selon Platon, en jetant la suspicion sur ce qui nous est présenté comme la vérité, le bon sens, l’unique voie à suivre. Parce qu’elle est, par nature, peu encline à se contenter de ce qui est, elle fait un travail de sape des illusions, qui est mine de rien foncièrement politique.
Les étoiles de l’utopie ///// Lionel Richard
Celle qui brouilla les frontières ///// C. D.
Le genre qui cartographie nos possibles avenirs ///// Valerio Evangelisti
Futur sous connexion dans un « Black Mirror » ///// Thibault Henneton
De la nature du pouvoir selon la SF ///// Yves Di Manno
L’informatique, auxiliaire de la révolution ///// Philippe Rivière
Recto-verso : les deux façons d’être mis en esclavage ///// François Brune
Baze magané ///// Sabrina Calvo
Voix de faits
Chronologie, cartographie, chiffres-clés, citations…
Encadrés
La guerre des mondes
L’équation du bonheur
Détraquer les programmes
Algorithmes-missiles
Enfin, l’afrofuturisme
Après l’Apocalypse, les mêmes combats
Les nazis ont gagné, tout va bien
Iconographie
Ce numéro est accompagné des œuvres de :
Bande dessinée
Coordonné par Guillaume Barou
Dernier contact ///// Sajan Rai
Documentation
Olivier Pironet
Bibliographie
Sur la Toile
Dates de parution des articles
Les articles publiés dans ce numéro — à l’exception de 3 inédits — sont déjà parus dans Le Monde diplomatique. La plupart ont fait l’objet d’une actualisation, et leur titre a souvent été modifié. La date de première publication ainsi que les titres originaux figurent ci-dessous.
• Pierre Rimbert, « La bourgeoisie intellectuelle, une élite héréditaire », août 2020.
• Pierre Musso, « L’ère de l’État-entreprise », mai 2019.
• Pablo Jensen, « Simulation numérique des conflits sociaux », avril 2013.
• « Abécédaire de la surveillance », Manière de voir n° 133, « Souriez, vous êtes surveillés », février-mars 2014.
• Alain Damasio, « Vos souvenirs sont notre avenir », juin 2015.
• Marie-Françoise Allain, « La bête n’est pas morte », mars 1976.
• Norman Spinrad, « Quand “La Guerre des étoiles” devient réalité », juillet 1999.
• Greg Grandin, « Le rêve amazonien de Henry Ford », août 2011.
• Finn Brunton, « Petit guide de conversation avec les extraterrestres », août 2016.
• Marcus D. Besnard, « Fin programmée pour “Homo sapiens” », janvier 2018.
• Gérard Klein, « Deux millénaires de fictions pour stimuler les ingénieurs », Savoirs/Le Monde diplomatique, « Les conquêtes de l’espace », 1994.
• Roger Zelazny, « Le temps d’un souffle… » (inédit).
• Dan Bouk, « Ainsi nos jours sont comptés », novembre 2015.
• Evelyne Pieiller, « Oracles, mode d’emploi », novembre 2014.
• Juliette Faure, « Le cosmisme, une vieille idée russe pour le XXIe siècle », décembre 2018.
• Catherine Dufour, « Dépassée, la science-fiction ? », juillet 2017.
• Guillaume Barou, « Devenez la marionnette virtuelle de vos désirs » (inédit).
• Lionel Richard, « Pleins feux sur l’utopie », avril 2000.
• Catherine Dufour, « Une pionnière sous les étoiles », mai 2018.
• Valerio Evangelisti, « La science-fiction en prise avec le monde réel », août 2000.
• Thibault Henneton, « Science et prescience de “Black Mirror” », Manière de voir n° 154, « Écrans et imaginaires », août-septembre 2017.
• Yves Di Manno, « Science-fiction et rêves de l’État », novembre 1977.
• Philippe Rivière, « Allende, l’informatique et la révolution », juillet 2010.
• François Brune, « Petit parallèle entre deux utopies complémentaires », octobre 2000.
• Sabrina Calvo, « Baze Magané » (inédit).",0
116,"2 months ago
full shot of a sexy beautiful, (female nubian goddess),30 yea...
Search millions of art images by AI models like DALL-E, Stable Diffusion, Midjourney...
Create an account and bookmark your favorite prompts, upload your own creations – and much more!Create account",3
117,"The first thing to know about the Madagascar hissing cockroach, a black-and-brown invertebrate about as long as your forefinger, is that it lives up to its name. When it feels threatened, it squeaks out a hiss by quickly passing air through holes in its back. The result is something resembling the rattle of a snake's tail. Weird but cool.
The second thing to know about the Madagascar hissing cockroach is that scientists have used it to create insect cyborgs that could one day be used to monitor the environment or help with urban search and rescue missions after a natural disaster. Also weird. Also cool.
In a new study, published Monday in the journal npj Flexible Electronics, an international team of researchers revealed it has engineered a system to remotely control the legs of cockroaches from afar.
The system, which is basically a cockroach backpack wired into the creature's nervous system, has a power output about 50 times higher than previous devices and is built with an ultrathin and flexible solar cell that doesn't hinder the roach's movement. Pressing a button sends a shock to the backpack that tricks the roach into moving a certain direction.
If you're freaked out, let me explain.
Rise of the robo-roach
Cockroach cyborgs are not a new idea. Back in 2012, researchers at North Carolina State University were experimenting with Madagascar hissing cockroaches and wireless backpacks, showing the critters could be remotely controlled to walk along a track.
The way scientists do this is by attaching the backpack and connecting wires to a cockroach's ""cerci,"" two appendages at the end of the abdomen that are basically sensory nerves. One on the left, one on the right. Previous studies have shown electrical impulses to either side can stimulate the roach into moving in that direction, giving researchers some control over locomotion.
But to send and receive signals, you need to power the backpack. You might be able to use a battery but, eventually, a battery will run out of power and the cyborg cockroach will be free to disappear into the leaf litter.
The team at Riken crafted the system to be solar-powered and rechargeable. They attached a battery and stimulation module to the cockroach's thorax (the upper segment of its body). That was the first step. The second step was to make sure the solar cell module would adhere to the cockroach's abdomen, the segmented lower section of its body.
While humans have worked out optimal ways to wear a backpack, it's not quite the same for insects. The segmented nature of a cockroach's abdomen, for instance, provides it with the ability to contort itself or flip itself over should it get into a hairy situation. If you slap a sticky backpack or charging cell on it, you limit its movement and take away its ability to maneuver.
To overcome this, the Riken team tested a number of thin electronic films, subjecting their roaches to a bunch of experiments and watching how the roaches moved depending on the thickness of the film. This helped them decide on a module about 17 times thinner than a human hair. It adhered to the abdomen without greatly limiting the degree of freedom the roaches had and also stuck around for about a month, greatly outlasting previous systems.
Then, the fun part (I assume): Remote control of the insects.
In a series of experiments, the team demonstrated how the system could steer the roach right, as desired, via a wireless system. You can see that above.
And, for now, that's as far as they've got.
""The current system only has a wireless locomotion control system, so it's not enough to prepare an application such as urban rescue,"" said Kenjiro Fukuda, an expert in flexible electronics at Japan's Riken. ""By integrating other required devices such as sensors and cameras, we can use our cyborg insects for such purposes.""
Fukuda notes cameras would likely require a lot more power, but there are sensors that use little power that could be integrated into the system today. If cameras were able to be used, they would likely be very low resolution.
Notably, because of the design of the ultrathin solar cell, Fukuda notes it could be applied to other insects -- potentially even creating a flying army of robot insects controlled by human hands. Beetles and cicadas are potential candidates.
Insect robots are having a bit of a moment. In July, researchers at Rice University unveiled their spider ""necrobots"" -- insect-machine hybrids they used to create the world's creepiest claw machine.
But those spiders were dead. The roaches aren't.
I must admit that when I saw the images of the roboroaches crawling in a certain direction, I felt a weird pang of... guilt. Or something like it, perhaps. I wondered if there was any sort of understanding by the creepy crawlers that their legs are being steered against their own will and whether this process was painful. Fortunately, ""according to research related to insects, cockroaches do not experience pain,"" said Fukuda. Phew.
However, there has been some research in recent years looking at how insects might experience emotive states and discussion about the ethical implications of such research. A recent piece in Undark magazine wrestled with the question of insect pain, too, noting there's still a lack of understanding about insect consciousness.",2
118,Ucoolity - Wearable Air Conditioner Cooling Vest | Indiegogo,8
119,"If I had a nickel every time I heard someone scoff at brands’ publishing initiatives because they believe they’re bad for the “future of media” – well, I’d be somewhat well off.
The needlessly adversarial narrative around brand publishers vs. traditional publishers is moving on to what I think is a much more interesting discussion on how the consumption and creation of content has become more complex and “media” is changing dramatically.
Like it or loathe it, one result of the brand publishing movement has been an increase in the availability of information. One sector that’s been particularly active building “media companies” within their walls recently is investment banking. Consider:
- Goldman Sachs hired a new editor-in-chief: Quartz EIC Katherine Bell joined the investment bank, where, per a job posting, Bell will “play a key role in creating modern, best-in-class content.” At Goldman, the content team sits inside the global marketing division. Bell joined a handful of Quartz alums, including its membership editor Sam Grobart, who is the vp of content at Goldman. The bank creates videos and audio updates on what’s happening in finance, and produces content that repackages intelligence within the company into stories.
- Goldman’s consumer bank, Marcus, is also hiring an editor in chief who will drive commercial growth via thought leadership.
- On the internal side, Citi recently posted a role for an editorial executive who will strategize on content and storytelling for the bank’s 250,000 employees – driving attention and engagement for internal audiences. (That’s a lot of eyeballs.)
- JPMorgan Chase has been an active player in the publishing space, snapping up restaurant review site the Infatuation last year.
- As my former colleague Lucia Moses reported for Insider recently, JPM also hired David Moss, who oversaw Robinhood’s content efforts, to lead its publishing efforts for U.S. Wealth Management.
There are obvious reasons for banks getting deeper into content: An effort to increase favoribility scores among various audiences, including consumers and prospective employees, particularly during a time trust in these instiutitions remains low. (It’s not surprising that many of these content initiatives first actually began during the 2008 financial crisis and its aftermath. Remember “vampire squid”?)
Plus, most banks also already have a deep bench of expertise within their walls. At investment banks, content is already a core offering – analysts write detailed notes going deep inside companies and analyzing market trends – so translating this into an editorial-first opportunity feels a little bit like a no-brainer.
For banks, publishing isn’t as much a new muscle as much as a slightly new workout. There’s some historical precedent here that backs this up. So much of what financial-types do is create content, then figure out a way to make money out of it. The Diff, Byrne Hobart’s (excellent) newsletter about financial markets, made this point astutely in a post about newsletter economics, pointing out all the finance companies that started as content/newsletter offerings before turning into something different, including Bridgewater, Charles Schwab and Tudor, Pickering, Holt.
As Hobart writes: “asset management is really just making connections between people who have money and need investment opportunities and people who have opportunities and need money to take advantage of them.”
Financial services also generally have the problem of high CAC that publishing can help with. JP Morgan’s acquisition of The Infatuation (and Frank, an online portal that helps students research and apply for financial aid) is an effort to build an ongoing relationship with an audience in an effort to create more value for customers and retain them longer.
In financial services, customers generally have extremely high lifetime value – when was the last time you switched a bank? – but operate in highly competitive markets, making the customer acquisition costs also high. A site like The Infatuation can help a bank like JP Morgan Chase keep its customers by giving them more in exchange for being customers – content and experiences.
Content can also double up as a service internally. Publishing teams inside brands often do double duty: They act as reporters and editors, but also in-house consultants on editorial strategies and processes. For banks, brand publishing teams are often used as internal advisors for any client initiatives that have to do with content.
What’s next: As brand publishers get more serious about their content and publishing operations, they’re becoming more discerning about the editorial talent that they hire to power and grow their efforts. One group in their crosshairs: editors and reporters at business focused media companies.",1
120,"With the iPhone approaching its 15th anniversary, it’s clear that the next major shift in consumer behaviour will expand beyond smartphone-based technologies. Modem has collaborated with Studio Bjørn Ibsen to explore the blueprint for our future lifestyles according to Silicon Valley. Patented Futures reimagines nondescript patent filings from tech corporations as forward-looking designs — mapping the vast promises and implications of tomorrow’s wearable technologies.
We’ve all been raised on visions of cyborgs. Whether utopian or dystopian, the imagined futures we watch on our TV screens have always been the domain of hybrid creatures: part-human and part-machine. As a society, we are mesmerised by the familiar softness of the human body blended with high-performance tech — whether that’s the augmented eyes of anti-cybercrime agent Major Kusanagi in 1995 anime Ghost in the Shell, or the moment Neo discovers a metal headjack on the back of his neck in The Matrix. These stories from the dawn of the internet age help us process our complex and increasingly intimate relationship with technology. We’re on the brink of a new era enabled by artificial intelligence, augmented reality and cloud computing — and in the next decade, wearable tech will likely become the most prevalent way to access all of these innovations. But how will this change our social interactions? What kind of horizons will it open for our minds and bodies? And what could we have to sacrifice along the way? The answers are yet to be determined.
We cling to futuristic narratives of wearable tech because they promise instant augmentation: glasses which allow people to see in the dark, shell-suits which make us invincible. But really, wearable tech is just a reflection on our rapidly evolving social lifestyles. The future is already here – embedded in our habits, routines and identities.
CYBORG LIFESTYLES — REAL AND IMAGINED
Feminist scholar Donna Haraway published A Cyborg Manifesto in 1985. In it, she wrote about a “relationship between people and technology so intimate that it’s no longer possible to tell where we end and machines begin”. She laid out a vision of people not as individuals, but as nodes within a wider network. Her vision was formulated before the internet and before the smartphone — yet over three decades later, we are witnessing its truly prophetic nature. Today, we undeniably inhabit cyborg bodies. We check up on our Snapchat or Axie Infinity avatars as we queue for a caffeinated drink; we keep track of how many steps we take each day; we use apps to track our nutritional supplements and period cycles. Particularly for millennials and Gen Z, the separation of our online and physical identities is becoming less and less relevant. We are on the verge of a world which will allow us to exist in both dimensions simultaneously — and wearables could allow us to physically inhabit both of those spaces more fully.
In the next decade, we will inevitably see the growing presence of wearable tech in our day-to-day lives. With the iPhone approaching its 15th anniversary, it’s clear that the next major shift in consumer behaviour will take place beyond the boundaries of smartphone-based technologies. We can glimpse this future through the current patent filings from corporations and start-ups – the blueprint of our future lifestyle according to Silicon Valley’s secretive R+D labs. We are decades away from these technologies being built and deployed, yet they’re being shaped here and now, rooted in the current social and cultural contexts.
THE SEAMLESS TRANSITION TO WEARABLES
Success in wearable tech isn’t always packed with surprise or even futuristic sensibility – sometimes, new devices fit so seamlessly into consumers’ lives that it’s barely even noticeable. Just look at Apple AirPods, which made the company an estimated $7.3 billion in 2019 alone (with an estimated 35 million pairs sold). Wireless charging, noise-cancelling capabilities, and an ergonomic design which fits most ears have all been crucial factors in AirPods’ success — alongside their aesthetic and cultural context. AirPods created a buzz in the fashion world: they were spotted inside fashion week street style reports, combined with fine jewellery, and even inspired brands to create various add-on accessories like chains and pendants. To sum it up, AirPods look good enough and are practical enough to keep them on all the time – which might be the ultimate goal for wearables.
With the widespread use of wireless earphones now all but assured, the appearance of similar products with more sophisticated technological features is just a matter of time. Apple owns a patent for wireless earbuds with built-in health sensors, capable of monitoring heart rate and measuring body temperature. Disney Enterprises is planning to develop an AR audio system to create spatial audio-enhanced environments — earphones which react to users’ location and movement. Facebook owns a patent for a “cartilage conduction audio system for eyewear devices”: essentially a portable sound system located both behind and inside the ear, ready to be paired with AR glasses for the ultimate immersive experience.
GOOGLE GLASS AND ITS COMPLEX LEGACY
If earphones are connected with the story of success, glasses are ultimately linked to wearable tech’s biggest failure: Google Glass. The rise and fall of Google Glass was stark and rapid: in 2012, it was named one of the “Best Inventions of the Year” by Time Magazine; Oprah, Beyoncé, and Prince Charles all wore a pair; and the device even appeared on the Diane von Furstenberg Spring-Summer 2013 catwalk. But now Google Glass looks distinctly odd, filled with all the cringe factor of something very recently out of date — perhaps akin to a CD or a car stereo. When Google Glass was released, the project was still very much work in progress, and hence not sold in stores. Instead, it was offered to “a select group of geeks and journalists, who paid $1,500 for the privilege of being an early adopter”. The hype was soon crushed by numerous bugs, abysmal battery life and, most importantly, the overwhelming fear of discrete rolling recording. This particular vision of the future – where users are not only watching, but are constantly being watched – is embedded in the way that tech-enhanced eyewear is likely to develop.
Back in the day, Glass evoked persistent anxiety and annoyance in social situations. (So much so that it gave birth to its own term — “Glasshole” — that referred to people who refused to remove their Glass when directly interacting with other people.) Today, Glass exists as a tool for the enterprise. It is used by shipping companies like DHL and DB Schenker to help employees while scanning and sorting orders. As veteran tech writer and Wired co-founder Kevin Kelly pointed out: “You are likely to put on AR glasses at work long before you put them on at home.”
Judging by the sheer number of patent filings, AR-enhanced glasses are inevitable. They will, however, be complex to implement — not only technologically, but also aesthetically and culturally. Eyewear holds a precarious position at the intersection of fashion and practicality. They are a luxury accessory, but are usually also discreet. Most smart glasses are currently a complete antithesis to the futuristic design trend in eyewear, which has largely borrowed from sci-fi and sports models. It is a hint that wearable tech, with all its futuristic potential, most likely won’t look that futuristic.
Our future wearables will be subtle and tactile, generating a new type of gentle and comforting stimulation. They might borrow the soft textures of a pebble polished by the ocean, or the muted pastel colours of hand-made paper. They may even have carefully constructed imperfections. This is not only about aesthetics, but reframing the position of tech in our lives and minds, positioning it as invisible, unassuming, intuitive. Wearable tech is no longer about giving up a part of ourselves to a machine, but about products and services created to fit both our smallest needs and our cosy home interiors. We still are in the process of admitting to ourselves that the ubiquitous presence of technology in our lives is inevitable. While that process is ongoing, however, we are keen to find ways to give technology a less invasive look and feel.
AR: ENTERING THE METAVERSE
By using unassuming, grounded aesthetics and tactile familiarity, the wearable tech of the future may be able to counter the anxiety we feel as we face the unknown worlds and technologies. AR is certainly one such innovation. In addition to glasses and earphones, a number of wearables in the works are designed to introduce the metaverse into our daily lives. Magic Leap has a bracelet which will allow users to access their AR apps by touching certain corresponding charms. Google has filed a patent for motorized footwear that will allow users to walk, seemingly endlessly, through virtual environments, all while remaining within a defined physical space. Major companies such as Apple, Facebook, and Samsung are developing smart gloves which will enable wearers to feel and manipulate virtual objects. Alongside numerous practical applications, like virtual sculpting tools, such devices will finally allow us to see and feel our hands in VR and AR – moving one step closer to feeling like we’re “really there”. The concepts of “there” and “here”, however, might not be as relevant in the future post-wearables – just as the online and offline worlds have joined in modern society, the VR and “real-life” world will merge into the new hybrid reality.
And this is where we circle back to the field of imagination and sci-fi – because as much as we can try to predict the development of wearable technology, it’s much harder to imagine how we, as humans, will fit into this new world. The wider application of AR would mean a society where everything around us becomes meticulously mapped and documented. Whatever we see, machines will also see: smart glasses will capture the world through human eyes, while AI gradually learns to make sense of everything that the wearer encounters, whether living things or inanimate objects. This could introduce a new era of surveillance that is cosy, ubiquitous and, most likely, completely consensual. But even if comfortable with being constantly seen by mechanical eyes, are we ready for a new vision of society to unfold in various dimensions?
At the end of the day, wearables will forge a completely new relationship between ourselves and our own bodies. On the one hand, we will be given the chance to expand the boundaries of our physical selves. On the other, we will forever be bound to our bodies’ practical applications as a form of ID, a high-performance machine, and as node on the network — just as Donna Harraway predicted.
NEWSLETTER
Subscribe to the Modem newsletter to receive early access to our latest research papers exploring new and emerging futures.",1
122,"NO MERCY / NO MALICE
Text-ure
We thought billionaires were playing 3D chess while we played checkers. It turns out they’re playing the same game, but on a more expensive board.
Every medium has its own behavioral norms and nuances. Few are more casual, and authentic, than texting. There’s a feeling of intimacy and immediacy, as a smaller circle has access. Most people read all their texts, while few read all their email, and almost nobody opens all their physical mail. Many of us no longer even bother to listen to our voicemail messages, and you out yourself as old when you (gasp!) call your kids.
One of the reasons we relish the live interview and testimony under oath is that they inspire real moments, scarce in a world where communications departments preview, starch, and sanitize anything people of power say. So when (some of) Elon’s text messages became public during the discovery process in Twitter v. Musk, it offered us a glimpse into the bowels of tech power. Bowels is the correct metaphor.
Some observations re these texts, and what they illuminate about the texture of the tech community’s upper caste:
Checkers, Not Chess
The texts are between Elon and some of the wealthiest and most influential people in the world, including Larry Ellison, Joe Rogan, Sam Bankman-Fried, Satya Nadella, and Jack Dorsey. The logic, prose, and general discourse they reveal are astoundingly … unastounding. The wealthiest man in the world and his acolytes are, like the rest of us, unsophisticated, obtuse, and petty. Maybe more so. We thought billionaires were playing 3D chess while we played checkers. It turns out they’re playing the same game, but on a more expensive board.
They fumble with their computers.
They lean on others to get jobs for their kids (no surprise).
No matter how rich, they always could use more (money).
Where they differ: There’s clearly a pecking order, a social hierarchy. And, as far as I can tell, among this circle the currency of deference is … currency. Specifically, the more money you have the greater the degree of sycophantry. The Oculus and texts to Elon from his “friends” invite the same sensation: nausea.
And everyone struggles with autocorrect.
What I find most remarkable about these texts isn’t Elon — he comes off mostly OK in my view. It’s the people around him. It appears our idolatry of innovators has seeped into the minds of the uber-wealthy, sickening them with an uncontrollable tendency to fellate the cool kid for a chance to sit at his table in the cafeteria. “I would jump on a grenade for you.” If anyone ever tells you this, and they’re not literally in battle with you, it means they are a fan … not a friend.
The undoing of many powerful people is that they enter a hermetically sealed bubble of fake friends. Enablers, not people concerned with their well-being. When the Elon-Twitter debacle started this spring, I wrote a post about power. My thesis: Power, unchecked, is a psychological intoxicant. OK, this isn’t so much a thesis, as it’s scientifically proven. Research shows power causes us to downplay potential risk, magnify potential rewards, and act more precipitously on our instincts. In other words, you lose your ability to self-regulate; you need others to do it for you.
You’d hope the richest person in the world would assemble a circle of advisers who push back when appropriate (i.e., not yes men). But Elon’s history of reckless, childish behavior and these texts prove there is no group or individual who is a truth-teller. In the whole 151-page document, I found, no joke, just one instance of pushback. It came from Twitter CEO Parag Agrawal, who, in response to Elon’s unhelpful “Is Twitter dying?” tweet, let Elon know what he thought: It was unhelpful. Elon’s response? A childish, terse insult.
Scale
The texts are mostly unremarkable. There are some, however, that do remind us the (super-)rich are different. Specifically, the discussions of possible equity investments from crypto-billionaire Sam Bankman-Fried (“Does he have huge amounts of money?”) and this exchange with Larry Ellison:
It’s common knowledge that Ellison, who co-founded Oracle, a company worth more than $175 billion, is rich. Less clear is that he has enough money to offer a billion dollars over a text. I mean, who hasn’t had a friend offer them $1 billion in a text? Ellison offered 8,000 times the median net worth of an average American, enough to buy more than 3,000 Ferraris or the Chicago Blackhawks, as if he was picking up a latte. I believe it’s important to have incredibly successful people who are exponentially wealthier than the rest of us — it’s a bedrock principle of capitalism, creating an incentive structure that inspires productivity and prosperity. However, when people are offering billions over text to help out with another billionaire’s vanity project, in the same nation where 1 in 5 children live in food-insecure homes, then … isn’t America a bit fucked up?
Later on, Elon’s Morgan Stanley banker, Michael Grimes, tells him that Bankman-Fried, a major investor in Web3 ventures, can invest $5 billion in the deal: “could do $5bn if everything vision lock … Believes in your mission.” In response, Elon … dislikes the message. Five billion dollars is on the line, and in Elon’s world it doesn’t merit a worded response. For context, $5 billion is more than the GDP of many small nations, twice the budget of the SEC, and more than five times the budget of the nuclear regulatory commission.
If, after reading this, you’re increasingly concerned about income inequality, well … trust your instincts.
The Rich Are Different, Billionaires Are Not
As an entrepreneur, academic, and investor, I’ve had the opportunity to develop professional and personal relationships with people who make a modest living, rich people, and several billionaires. My observation is that the rich are different. On average, they’re more intelligent and harder working than your average citizen. There is a cartoon of rich people — e.g., Monty Burns from The Simpsons — and it’s just that … a cartoon. Wealthy people usually demonstrate character and know how to foster allies. Having people who want you to win is key to success.
But I have never registered a difference in talent or intellect between the wealthy, and the uber-wealthy. Yet this is the virus that infects the tech elite: conflating talent with luck. Going from millions to hundreds of millions or billions is less a function of incremental intelligence and more a function of timing. Proof? Elon’s text record. Any man who can inspire the electrification of the auto industry and land two rockets on barges concurrently deserves the label “genius.” But his mega-billions flow from a well regulated capital market, a web of enforceable contracts, the diligent labor of thousands of workers, and, not least, billions of dollars in government subsidies, including a timely $465 million DOE loan that enabled Tesla to produce the Model S. So, is Mr. Musk a genius or an impressive man whose skills were set against a unique moment and place in time? The answer is likely yes.
The Point
Something else we learned from Elon’s texts? He has no clue how to “fix” Twitter. For two weeks in April, he was all in on blockchain Twitter, brainstorming about Dogecoin payments for tweets with his brother — i.e. the opposite of free speech … paid speech — literally as he was telling Twitter’s board he was going to make a hostile tender offer. (Spoiler alert: Kimbal loved it.) By May, he was over crypto and not interested in a “laborious blockchain debate.” (Mood.)
At one point, Elon asked the Twitter CEO for “an update from the Twitter engineering team so that my suggestions are less dumb.” The record does not reflect whether he got that meeting. Neither does it reflect any actual plan for “fixing” Twitter. And this is the problem with the entire Elon misadventure. He’s a child grown old, given all the toys but no boundaries, nobody to tell him no. His army of yes men encourages his most facile thoughts, and the genius he and we have been blessed with is diminished by shitposts and errant behavior.
Post-Apocalyptic
I will give the titans of the universe credit for one thing: a sense of humor.
Psychosis
Psychosis sets in when people lose touch with reality. Elon’s atmosphere is so thick with people reinforcing that his every move is laudable or genius, he’s become a pathological liar who believes we believe him. The latest batch of lies? He canceled his deposition earlier this week, on 24 hours notice. His reason? Risk of Covid exposure. A guy who refused to close his Alameda plant as the pandemic was raging, under a closure order from the health department, couldn’t sit for a deposition because of his fear of the virus. His psychosis is fed by the media, which this week ran millions of versions of “Musk to close Twitter deal.” No, he said he intends to close the Twitter deal, which means nothing. In the same letter he asks for, in exchange, a suspension of the trial and that Twitter agrees to a financing contingency. In sum, he’s lying, engaging in further delay and obfuscation, and attempting to set a pretext to (again) walk away from the deal. One group that appears to “get” Elon? Wachtell Lipton, Twitter’s counsel. They’ve said no.
Every day, every one of us needs to ask ourselves an important question: Who keeps it real for me? Who will push back, who will tell me I’m wrong … who will save me from myself and the psychosis that’s led to so many successful people’s fall from grace. Elon Musk doesn’t need anybody to jump on a grenade for him, but to tell him to stop throwing grenades as it’s only a matter of time before one detonates in his hand.
Life is so rich,
P.S. Our highest-rated workshop, How to Build a Product Strategy with Netflix’s Gibson Biddle, is next Wednesday. Sign up now to grab your seat.",1
123,"The Next Big Battle Between Google and Apple Is for the Soul of Your Car
In the future, your choice of smartphone ecosystem—Android or iPhone—could determine which make and model of car you choose
A few years from now, in addition to deciding your next vehicle’s make and model, you may have another tough choice: the Google model or the Apple one? Other options may include “car maker generic” and even, I’m spitballing the name here: Amazon Prime Edition.
Now that cars, especially electric ones, are becoming something like smartphones on wheels, some of the dynamics that played out in the early days of the mobile industry are playing out in the auto industry. Competition between the two kingpins of the smartphone industry has in the past couple of years gained new momentum, with Google racking up auto-maker partnerships for the automobile-based version of its Android operating system, and Apple teasing plans to expand its software capabilities in the car.
Continue reading your article with
View Membership Options
a WSJ membership
Already a member? Sign In
-
The Motley Fool:
New members save 55% on Stock Advisor
-
Wayfair:
Up to 15% off + free shipping at Wayfair
-
American Eagle Outfitters:
Sign up for emails and get 10% off American Eagle promo code
-
Kohl's:
Kohl's coupon - 30% off sitewide for Rewards members
-
Walmart:
Walmart coupon: $20 off your $50+ order
-
Chase:
Get up to $625 unlimited commission-free online trades
Most Popular News
-
Apple Makes Plans to Move Production Out of China
-
Sam Bankman-Fried Says He Can’t Account for Billions Sent to Alameda
-
Kate Middleton’s Style Stays on Message Amid Ongoing Royal Turmoil
-
A Military Wife’s Descent Into Meth Addiction—And Her Agonizing Journey Back
-
U.S. Unwraps B-21 Bomber, Designed to Deter China",1
124,"TikTok has become a global phenomenon. In an op-ed for The New York Times, tech reporter Shira Ovide wrote, “TikTok might be rewiring entertainment, giving the next generation of activists new ways to tell stories and challenging the global internet order.”
It looks like Ovide’s claim is quickly becoming reality. Insights from Cloudflare Radar show the explosive growth and global popularity of the social platform.
TikTok is not just surpassing other social platforms, in terms of global internet traffic, but is becoming more accessed than Google and its suite of services, including Google Maps and Gmail.
Cloudflare’s Radar project publishes information on website traffic metrics and other up-to-date internet trends. By the end of 2021, the company’s data showed TikTok.com was the #1 most popular domain. Google.com came in second, followed by Facebook.com, Microsoft.com and Apple.com.
It is worth noting that ByteDance, the parent company of TikTok, is one of the few major tech companies that also runs a popular consumer app in China. ByteDance runs Douyin in China, which is comparable to TikTok features. However, Douyin traffic is not directed to the TikTok.com domain.
In addition, Google’s domain does not include YouTube’s web traffic. Facebook’s domain does not include Instagram.com or WhatsApp.com.
Late 2020, Google was the most accessed domain, according to Cloudflare. This was followed by Facebook, Microsoft, Apple and Netflix. TikTok’s traffic came in #7.
Movement for TikTok started in February 2021, according to the internet security agency. On February 17, TikTok got the top spot for one day. This was followed by a few stretches where TikTok was on the top for a few days in March and May. But in August, TikTok started taking the top spot on most days, while there were some days where Google held onto the #1 position.
TikTok’s continued dominance and popularity is a remarkable turn of events for the social platform that was almost shut down in the U.S.. In August 2020, President Trump signed an executive order that would have imposed sanctions against the platform, citing security issues due to its ties to China. Eventually, the Commerce Department said it would not enforce the order, amid legal battles. However, President Biden has backed off the efforts.",5
125,"Folks, we're nearly halfway through 2022. I know — some days, it feels like we're stuck in 2020 purgatory. But no, that's merely our ""new normal,"" if anything about the current state of the world could be called normal.
For two years, change has upended every aspect of life, including dating. Both 2020 and 2021 made way for an unprecedented slow-down, causing us to connect with others in new ways (like virtual dates) while also taking time to self-reflect. The result…isn't half bad, actually. Here are this year's dating trends so far, according to experts.
Choose your priority
The pandemic forced us all to reevaluate our priorities. This isn't a new revelation: From coming out to breaking up, COVID's figurative or literal jolt to our systems made us rethink what we really want in life.
""What was important to us two, three years ago simply isn't anymore,"" said OkCupid's associate director of global communications, Michael Kaye.
Considering all we've been through in the past two years even beyond the pandemic — like the threat to reproductive rights — we're less concerned about superficial qualities like looks, and more concerned about values like where a date stands on climate change, Kaye explained.
""What was important to us two, three years ago simply isn't anymore.""
During the brunt of quarantine especially, many of us had the space to reflect on who we are and what we want, perhaps for the first time in our lives. This caused daters to be both more honest and intentional when meeting new people.
Before COVID, dating coach and eharmony relationship expert Laurel House's clients had a laundry list of traits they wanted in a partner. Now, people are homing in on what really matters to them.
House calls this shift ""prioridating."" She encourages her clients to go after a single priority with potential partners. This can be anything, but one House sees a lot is safety, whether physically, emotionally, or financially.
This trend aligns with the data, as well. Eighty-six percent of singles want a partner of equal or higher income, according to Match's latest Singles in America, a survey of 5,000 Americans aged 18 to 75. This is a jump from 70 percent who wanted the same back in 2019.
Shallow desires, meanwhile, are on the decline: More singles (83 percent) want an emotionally mature partner rather than someone physically attractive (78 percent) according to the same survey.
""Many [daters] are looking for someone who inspires them to be their best selves,"" Kaye said. ""Someone they are proud to date. It's less about superficial characteristics and more about those deeper, more meaningful traits.""
Increased vulnerability and mindfulness
Prioridating engenders the next trend: an increase in openness. This increased communication (or want for such) has occurred since 2020, when we had to be honest about our COVID preferences. Daters found themselves having deeper conversations quicker amid the pandemic. We didn't have time for small talk or situationships; we got down to the nitty gritty. This is still true in 2022.
""People are having these real scary — historically scary — conversations,"" House said. ""Now it's not scary because now it's like, 'Well, I know me. I know my needs. I'm confidently, vulnerably, unapologetically aware of my needs.'""
In an interview at the end of 2021, Hinge's director of relationship science, Logan Ury, called this trend ""hardballing"": being upfront about what you want out of dating. This can look like, say, telling your first date that you want kids someday and asking them what they want.
In addition to vulnerability, prioridating is supported by mindfulness while dating. House suggests checking in with yourself while on dates. If your priority is safety, for example, and someone makes fun of a vulnerability, check in at that moment. House modeled how the thought process can look: ""Does that make me feel safe? It doesn't. OK, well, what am I going to do with that information? Either I'm going to say 'thank you, goodbye,'"" she said, ""or I'm going to voice my priority and make it clear what my priority is.""
While you may want to know if your date wants kids someday, it's not necessary to project into the future and dream up your whole life together now. Knowing you have the same beliefs and goals is valuable information, but you can focus on this one date, this one moment.
Virtual dates haven't gone anywhere
Another trend House noticed traces back to earlier in the pandemic: phone and video dates. These virtual dates have entered some people's repertoire, especially if they still don't feel safe dating in person. Another reason people may do this, House said, is saving time and money (getting ready, commuting, sitting there on the date).
""Now people are much more protective…of their time,"" she said.
If people are comfortable meeting in-person but still want to be close to home, House has noticed people having more dates at a nearby park or even in their backyard or patio if they have one.
Sober (curious) dating on the rise
Given the rise in alcohol consumption during the pandemic, more people are now sober curious, a concept of limiting drinking but not going completely sober. This is in tandem with a rise of zero-proof mocktails. This has led to a rise in sober (curious) dating as well.
In 2022, daters are more mindful about their drinking: 74 percent of single daters restricted their alcohol use in the last year, according to eharmony's 2022 Happiness Index, a survey of 3,000 adults over 21. A whopping 94 percent said ""they'd be interested in someone who doesn't drink at all.""
Like other facets of life, some people may have realized alcohol isn't a priority anymore, so they've chosen to be sober (or curious, anyway).
Given these trends, House is optimistic about relationships. She believes this slower, more intentional dating will lead to longer relationships and marriages. The pandemic disrupted everything — but in terms of dating, it actually may have been for the better.",4
126,"In the warm air of an early-June morning, Jose Antonio Peña walks along a channel of gushing water in the Sierra Nevada of southern Spain. Traversing the rocky terrain and ducking beneath boughs of pine, he eventually reaches a grassy meadow on his left. The ancient artificial channel, known as an acequia, empties into the meadow, where its water branches into meandering streams that soak into the mountainside.
Throughout the spring thaw, Peña makes several trips a week from nearby Mecina-Bombarón – a whitewashed village on the southern slope of the mountain range – up a winding, potholed dirt road to monitor the acequia's level and flow, making adjustments as needed. The entire village depends on his actions – where the water flows now, in spring, determines where it will eventually end up when the summer comes.
For over a millennium, this acequia – from the Arabic as-saqiya, meaning ""water conduit"" or ""water bearer"" – has provided irrigation and drinking water to Mecina-Bombarón, enabling survival and agricultural prosperity in the semi-arid environment. The methods used by acequieros – people with expert skills in water catchment and allocation – to tend the channels today differ little from those used in the Middle Ages.
The channel is part of a 3,000km (1,800 mile) irrigation network built by the Moors across the Sierra Nevada between the 8th and 10th centuries. The Islamic water management techniques introduced from the east transformed the landscape and agriculture in what was then Al-Andalus. Acequias made life possible for agrarian communities, conserving and distributing scant and seasonal water resources throughout the rugged mountains. In the newly fertile conditions, the abundance of crops introduced by the Moors thrived, among them almonds, artichokes, chickpeas, aubergine (eggplant), lemons, pomegranates, spinach, quince, walnuts and watermelon.
While this ancient system is needed now more than ever, it's threatened like never before
Though ancient, this traditional water management system is sustainable, efficient and resilient. As climate change worsens, the network will become even more important for helping communities in the Sierra Nevada cope and equitably share an increasingly scarce and unpredictable resource.
While this ancient system is needed now more than ever, it's threatened like never before. As traditional irrigation systems struggle with a lack of profitability compared with intensive agriculture and the rural exodus continues, increasingly few people still hold the skills and knowledge required to maintain acequias.
Jose Antonio Peña observes water as it's diverted from an acequia into a sima, part of a traditional system that provides water in the dry season (Credit: Kira Walker)
Each year, when the warmth of spring returns to the Sierra Nevada and the thaw begins, snowmelt is diverted from the headwaters of rivers into earthen, porous channels dug into the mountainside. As water flows through the gently descending acequias, ranging in length from tens of metres to kilometres, it's diverted to areas along the upper valley known as simas, where the channel empties and seeps into the ground, a process known as ""sowing water"". As water percolates through the subsoil, it replenishes aquifers and feeds springs and streams that emerge further down the mountain. The acequias of the Sierra Nevada are the oldest underground aquifer recharge system on the European continent, dating back more than 1,200 years.
Based on knowledge transmitted from generation to generation, acequieros like Peña understand the subterranean routes water takes. Where water is sown high in the valley determines where it eventually surfaces downslope, where it can be ""harvested"" to irrigate orchards, crops and gardens throughout the thirsty summer months. Without this system, most snowmelt and rain would flow quickly off the steep slopes as runoff in rivers. Sowing water slows the flow of water from the mountains, extending its availability for when it's most needed during the dry season.
Through research on sowing water, ""we've found the river…has fewer peak flows and contains a more constant flow throughout the year,"" says Sergio Martos-Rosillo, a hydrogeologist at the Spanish Geological Survey. Research has also demonstrated how sowing water doubles the recharge of water in aquifers. The system follows the principles of ecohydrology, which uses ""the regulating effect of vegetation, soil and aquifers, imitating nature to regulate water, instead of building concrete structures that alter the flow of water upstream and downstream"", he says.
Water sowing and harvesting systems could be replicated in mountainous areas elsewhere in the world, where the geological and hydrological conditions are similar to those of the Sierra Nevada, Martos-Rosillo adds, noting there is interest in several Andean countries. In some areas, such systems already exist – one indigenous water management system developed independently in Peru around 1,400 years ago uses similar principles, which the government has been investing in to revive.
Snowmelt and rainfall runoff from the peaks of the Sierra Nevada is diverted into acequias, which channel water towards infiltration zones called simas (Credit: Kira Walker)
While the global potential of these water sowing techniques is perhaps underutilised, each area poses its own specific opportunities and challenges.
Standing in a sima, surrounded by rivulets of water, Peña, who became an acequiero three years ago and works in construction when not tending acequias, says he learned how the system works by accompanying his grandfather and uncle to the waterways as a young boy. Dressed in rubber boots and with a wooden hoe-like tool known locally as a leguna in hand, he nudges rocks and clears away grass, ensuring water flows unobstructed as it enters the sima. The work is repetitive and can be physically demanding. At nearly 10km (6 miles), with 15 simas spanning its length, the acequia providing Mecina-Bombarón with water is the largest in the Sierra Nevada.
Without these ancestral water channels, life as it now exists here would not be possible. No one knows this better than those who depend on the water, which is why the acequia in Mecina-Bombarón has been kept in continuous use for over a thousand years, having weathered many social, cultural, political and environmental changes. ""The acequia is the life of the village. Without the acequias, all these villages would be a dryland, all these farms would be dry. It was very well planned,"" says Matilde Ruiz, who has lived her entire life in the village, standing in front of her garden planted with aubergine, lettuce, garlic and onions.
Water is normally sown until the end of June. But this year was far from normal. First, the snow came late, so it didn't freeze as solidly. Then, a heatwave arrived mid-May, accelerating the thaw. By early June, most snow had melted and water levels were low. And then another sweltering heatwave began mid-June. Peña says once-predictable weather patterns are gone: ""Before, it snowed when it was supposed to snow, and the storms arrived when they were supposed to arrive."" Now, neither snow nor rain behave as they used to, he says.
These shifts are a signal of what's to come in southern Spain, among Europe's driest and most climate-vulnerable regions. As summers become hotter and longer and winters milder and drier, learning how to cope with worsening water scarcity and prolonged droughts is taking on new urgency. Because acequias are resilient, efficient and a cost-effective way to provide water for communities and small-scale agriculture during the dry season, they're considered a vital tool to adapt to the region's changing climate.
Since the channels were built over 1,000 years ago, acequias have sustained settlements like village of Mecina-Bombarón (Credit: Kira Walker)
When water sowing systems flow they provide numerous ecological benefits, too. Where such systems are used in Ecuador, biodiversity is higher than in areas where they haven't been implemented. In New Mexico, the channels function as ecological corridors, enhancing plant cover and diversity, which reduces soil erosion, and supporting wildlife habitat. In the Sierra Nevada, which also experiences the above benefits, irrigation made possible by acequias maintains pastures for grazing and supports crop diversity, bolstering local food security.
With the acequia, the life we have here is very different. They're magnificent – María José Estévez Villalba
In Spain as in Latin America, sowing water is a system of communal governance dependent on principles of equity, cooperation and trust. Water users share responsibility for maintaining and cleaning acequias, which favours social cohesion. Ensuring water is distributed fairly is just one of many challenges Peña must navigate in his role, which is as much about managing people as it is about managing water. ""An acequiero has to be impartial, like a referee,"" he says.
In some villages, like Mecina-Bombarón, acequias have flowed continuously since the Middle Ages. Others were less fortunate. From the 1960s onwards, people began leaving the countryside in droves for cities across Spain and Europe in search of better lives. Widespread rural depopulation caused villages to fall into a state of decline, and many acequias – an estimated 15-20% of the Sierra Nevada's total – were abandoned and fell into disuse. When people left, with them went knowledge accrued over centuries.
To reverse this trend, a project established in 2014 by the Laboratory of Biocultural Archaeology at the University of Granada has been working to restore abandoned acequias and recover the flow of water, and traditional ecological knowledge, to villages across the Sierra Nevada. To date, the Memolab project has restored 14 acequias and cleaned 30 others. While the project's primary objective is to revive acequias, it's also a social intervention, says project coordinator José María Martín Civantos, an archaeology professor at the university. ""We try to improve the governance of the community, to empower the community, to promote the dynamisation of the community and the recovery of knowledge and practices,"" he says.
The practice of sowing water ensures its availability for irrigating crops, orchards and gardens throughout the dry season (Credit: Kira Walker)
The restoration projects are a way to provoke debate about agrarian and environmental policies, cultural heritage and values and address local tensions, says Civantos. ""When there's an acequia that was abandoned 20, 30 or 40 years ago, you need to restore social distribution of water. That means you have to recover part of the knowledge and practices, and that also means conflict,"" he says. ""But those conflicts are positive because that means the community is alive.""
On the other side of the Sierra Nevada, in the village of Jérez del Marquesado, the benefits of restoration are tangible, says María José Estévez Villalba, secretary of the local irrigation community. ""We compare villages next door [without acequias] that have drought, which we don't have. With the acequia, the life we have here is very different,"" she says. ""They're magnificent. Whoever sees them, they understand.""
With over 24,000km (15,000 miles) of acequias and 550 irrigation communities across the Andalusian provinces of Granada and Almeria, wider restoration could bring climate, environmental and social benefits to many. Yet despite their potential, acequias remain undervalued and getting support for further restoration is not easy, says Civantos.
The lack of support is related to the growth of high-tech, industrialised agriculture, Civantos says, as well as a lack of understanding of the acequias or their benefits. When efficiency is considered in terms of productivity, traditional agrarian systems, with their lower output, cannot compete with industrial agriculture. ""But if we consider efficiency from a multifunctional perspective, traditional systems should be considered extremely efficient because they provide us with so many ecosystem services.""
The practice of sowing and harvesting water can help communities adapt to climate change (Credit: Kira Walker)
According to Civantos, at the heart of the issue is how the rural world, and those who inhabit it, are often perceived. Lack of acknowledgement for agrarian activities and those who work the land, rooted in long-standing marginalisation and prejudice, pushes people towards other types of work that are better-regarded, he explains. Add in the low profitability of small-scale agriculture, making it near impossible to compete with the industrial model, and people, especially younger generations, have had enough. So they continue to leave.
Peña, who at 61 thinks he has only a few years left in him as an acequiero, is concerned the village's acequias will be abandoned. ""That's why I'm here, because there aren't any young people. All these customs are being lost and young people don't want to know about it,"" he says. ""They just put the glass under the tap, they don't know where the water comes from.""
Carmen Aguilo, a fourth-year archaeology student at the University of Granada who has assisted several restoration and cleaning projects, thinks more awareness about acequias is needed if they are to survive. Starting in schools, she sees a need ""to teach the values and the importance of water in general, as well as working with local people so that they understand this is also a heritage that has been bequeathed to them"".
Carbon Count
The emissions from travel it took to report this story were 16kg CO2. The digital emissions from this story are an estimated 1.2g to 3.6g CO2 per page view. Find out more about how we calculated this figure here.
Ultimately, much of the acequias' fate rests with communities themselves. ""At the end of the day we can go, we can help, we can start them up, we can clean them, but they're the ones who are going to have to take care of their maintenance and social organisation,"" says Aguilo. ""In some places, they'll probably be very successful if the community gets involved. And in other places, if there's no involvement, they'll probably end up being lost. It's a shame.""
Peña is pinning his hopes on children; reckoning that like him, exposure early on will help foster an appreciation for acequias that will translate into their preservation. In late May, he made a proposal to the municipal council to take children on excursions to see acequias and learn where their water comes from – a rich legacy they all share a stake in, but which they otherwise might not learn about. The mayor responded favourably, but the proposal has not yet moved forward.
Without sufficient people committed to preserving the acequias, this ancient system that has withstood so much may finally cease flowing. For Peña, it's a heartbreaking prospect. ""The acequias are the most important thing we have in the village,"" he says. ""If there's no water here, people can't live.""
--
Join one million Future fans by liking us on Facebook, or follow us on Twitter or Instagram.
If you liked this story, sign up for the weekly bbc.com features newsletter, called ""The Essential List"" – a handpicked selection of stories from BBC Future, Culture, Worklife, Travel and Reel delivered to your inbox every Friday.",2
127,"If you read only one book about globalization, make it The Box: How the Shipping Container Made the World Smaller and the World Economy Bigger, by Marc Levinson (2006). If your expectations in this space have been set to “low” by the mostly obvious, lightweight and mildly entertaining stuff from the likes of Tom Friedman, be prepared to be blown away. Levinson is a heavyweight (former finance and economics editor at the Economist), and the book has won a bagful of prizes. And with good reason: the story of an unsung star of globalization, the shipping container, is an extraordinarily gripping one, and it is practically a crime that it wasn’t properly told till 2006.
There are no strained metaphors (like Friedman’s “Flat”) or attempts to dazzle with overworked, right-brained high concepts (Gladwell’s books come to mind). This is an important story of the modern world, painstakingly researched, and masterfully narrated with the sort of balanced and detached passion one would expect from an Economist writer. It isn’t a narrow tale though. Even though the Internet revolution, spaceflight, GPS and biotechnology don’t feature in this book, the story teases out the DNA of globalization in a way grand sweeping syntheses never could. Think of the container story as the radioactive tracer in the body politic of globalization.
The Big Story
(Note: I’ve tried to make this more than a book review/summary, so a BIG thank-you is due to @otoburb, aka Davison Avery, a dazzlingly well-informed regular reader who provided me with a lot of the additional material for this piece.)
What is amazing about The Box is that despite being told from a finance/economics perspective, the story has an edge-of-the-seat quality of excitement to it. This book could (in fact, should) become a movie; a cinematic uber-human counterpoint to Brando’s On the Waterfront. The tale would definitely be one of epic proportions, larger than any one character; comparable to How the West Was Won, or Lord of the Rings. The Box Movie could serve as the origin-myth for the world that Syriana captured with impressionistic strokes.
The movie would probably begin with a montage of views of containerships sounding their whistles in h0mage around the world on the morning of May 30, 2001. That was the morning of the funeral of the colorful character at the center of this story, Malcolm McLean. McLean was a hard-driving self-made American trucking magnate who charged into the world of shipping in the 1950s, knowing nothing about the industry, and proceeded, over the course of four decades, to turn that world upside down. He did that by relentlessly envisioning and driving through an agenda that made ships, railroads and trucks subservient to the intermodal container, and in the process, made globalization possible. In doing so, he destroyed not only an old economic order while creating a new one, he also destroyed a backward-looking schoolboy romanticism anchored in ships, trucks and steam engines. In its place, he created a new, adult romanticism, based on an aesthetic of networks, boxes, speed and scale. Reading this story was a revelation: McLean clearly belongs in the top five list of the true titans of the second half of the twentieth century. Easily ahead of the likes of Bill Gates or even Jack Welch.
Levinson is too sophisticated a writer to construct simple-minded origin myths. He is careful not to paint McLean as an original visionary or Biblical patriarch. From an engineering and business point of view, the container was a somewhat obvious idea, and many attempts had been made before McLean to realize some version of the concept. While he did contribute some technological ideas to the mix (marked more by simplicity and daring than technical ingenuity), McLean’s is the central plot line because of his personality. He brought to a tradition-bound, self-romanticizing industry a mix of high-risk, opportunistic drive and a relentless focus on abstractions like cost and utilization. He seems to have simultaneously had a thoroughly bean-counterish side to his personality, and a supremely right-brained sense of design and architecture. Starting with the idea of a single coastal route, McLean navigated and took full advantage of the world of regulated transport, leveraged his company to the hilt, swung multi-million dollar deals risking only tens of thousands of his own money, manipulated New-York-New-Jersey politics like a Judo master and made intermodal shipping a reality. He dealt with the nitty-gritty of crane design, turned the Vietnam war logistical nightmare into a catalyst for organizing the Japan-Pacific coast trade, and finally, sold the company he built, Sea-Land, just in time to escape the first of many slow cyclic shocks to hit container shipping. His encore though, wasn’t as successful (an attempt to make an easterly round-the-world route feasible, to get around the problem of empty westbound container capacity created by trade imbalances). The entire story is one of ready-fire-aim audacity; Kipling would have loved McLean for his ability to repeatedly make a heap of all his winnings and risk it on one turn of pitch-and-toss. He walked away from his first trucking empire to build a shipping empire. And then repeated the move several times.
McLean’s story, spanning a half-century, doesn’t overwhelm the plot though; it merely functions as a spinal cord. A story this complex necessarily has many important subplots, which I’ll cover briefly in a minute, but the overall story (which McLean’s personal story manifests, in a Forrest Gumpish way) also has an overarching shape. On one end, you have four fragmented and heavily regulated industries in post World-War II mode (railroads, trucking, shipping and port operations). It is a world of breakbulk shipping (mixed discrete cargo), when swaggering, Brando-like longshoremen unloaded trucks packed with an assortment of items, ranging from baskets of fruit and bales of cotton to machine parts and sacks of coffee. These they then transferred to dockside warehouses and again into the holds of ships whose basic geometric design had survived the transitions from sail to steam and steam to diesel. It was a system that was costly, inefficient, almost designed for theft, and mind-numbingly slow, keeping transportation systems stationary and losing money for far too much of their useful lives.
On the other end of the big story (with a climactic moment in the Vietnam war), is the world we now live in: where romantic old-world waterfronts have disappeared and goods move, practically untouched by humans, from anywhere in the world to anywhere else, with an orchestrated elegance that rivals that of the Internet’s packet switching systems. Along the way the container did to distribution what the assembly line had done earlier to manufacturing: it made mass distribution possible. The fortunes of port cities old and new swung wildly, railroads clawed back into prominence, regulation fell apart, and supply chains got globally integrated as manufacturing got distributed. And yes, last but not the least, the vast rivers of material pouring through the world’s container-based plumbing created the quintessential security threat of our age: terror sneaking through security nets struggling to monitor more than a percent or two of the world’s container traffic.
Now if you tell me that isn’t an exciting story, I have to conclude you have no imagination. Let’s sample some of the subplots.
The Top Five Subplots
There are at least a dozen intricate subplots here, and I picked out the top five.
One: The Financial/Business Subplot
At heart, containerization is a financial story, and nothing illustrates this better than some stark numbers. At the beginning of the story, total port costs ate up a whopping 48% (or $1163 of $2386) of an illustrative shipment of one truckload of medicine from Chicago to Nancy, France, in 1960. In more comprehensible terms, an expert quoted in the book explains: “a four thousand mile shipment might consume 50 percent of its costs in covering just the two ten-mile movements through two ports.” For many goods then, shipping accounted for nearly 25% of total cost for a product sold beyond its local market. Fast forward to today: the book quotes economists Edward Glaeser and Janet Kohlhase: “It is better to assume that moving goods is essentially costless than to assume that moving goods is an important component of the production process.” At this moment in time, this is almost literally true: due to the recession. These sort of odd dynamics are due to the fact that world shipping infrastructure changes very slowly but inexorably (and cyclically) towards higher, more aggregated capacity, and lower costs. This is due to the highly capital-intensive nature of the business, and the extreme economies of scale (leading to successively larger ships in every generation). Ships, though they are moving vehicles, are better thought of as somewhere between pieces of civic infrastructure (due to the large legacy impact of government regulation and subsidies) and fabs in the semiconductor industry (which, like shipping, undergoes a serious extinction event and consolidation with every trough in the business cycle). Currently the top 10 companies pretty much account for 100% of the capacity, as this visualization from from gcaptain.com shows, which tells us that today there are over 6048 container ships afloat, with a total capacity of around 13 million TEU (twenty-foot equivalent).
The mortgaging and financial arrangements dictate that ships absolutely must be kept moving at all costs, so long as the revenue can at least make up port costs and service debt. As the most financially constrained part of the system, ships dominate the equation over trains and trucks. One tidbit about the gradual consolidation: as of the book’s writing, McLean’s original company, Sea-Land, is now part of Maersk.
How this came to be is the most important (though not the most fun) subplot. Things didn’t proceed smoothly, as you might expect. All sorts of forces, from regulation, to misguided attempts to mix breakbulk and containers, to irrationallities and tariffs deliberately engineered in to keep longshoremen employed, held back the emergence of the true efficiencies of containerization. But finally, by the mid-seventies, today’s business dynamics had been created.
Two: The Technology Subplot
If the dollar figures and percentages tell the financial story, the heart of the technology action is in the operations research. While McLean and Sea-Land were improvising on the East Coast, a West Coast pioneer, Matson, involved primarily in the 60s Hawaii-California trade, drove this storyline forward. The cautious company hired university researchers to throw operations research at the problem, to figure out optimal container sizes and other system parameters, based on a careful analysis of goods mixes on their routes. Today, container shipping, technically speaking, is primarily this sort of operations research domain, where systems are so optimized that an added second of delay in handling a container can translate to tens of thousands of dollars lost per ship per year.
If you are wondering how port operations involving longshore labor could have been that expensive before containerization, the book provides an illuminating sample manifest from a 1954 voyage of a C-2 type cargo ship, the S. S. Warrior. The contents: 74,903 cases, 71,726 cartons, 24,0336 bags, 10,671 boxes, 2,880 bundles, 2,877 packages, 2,634 pieces, 1,538 drums, 888 cans, 815 barrels, 53 wheeled vehicles, 21 crates, 10 transporters, 5 reels and 1,525 “undetermined.” That’s a total of 194,582 pieces, each of which had to be manually handled! The total was just 5,015 long tons of cargo (about 5,095 metric tons). By contrast, the gigantic MSC Daniela, which made its maiden voyage in 2009, carries 13,800 containers, with a deadweight tonnage of 165,000 tons. That’s a 30x improvement in tonnage and a 15x reduction in number of pieces for a single port call. Or in other words, a change from 0.02 tons (20 kg) per “handling” to about 12 tons per “handling”, or a 465X improvement in handling efficiency (somebody check my arithmetic… but I think I did this right). And of course, every movement in the MSC Daniela’s world is precisely choreographed and monitered by computer. Back in 1954, Brando time, experienced longshoremen decided how to pack a hold, and if they got it wrong, loading and unloading would take vastly longer. And of course there was no end-to-end coordination, let alone global coordination.
That’s not to say the mechanical engineering part of the story is uninteresting. The plain big box itself is simple: thin corrugated sheet aluminum with load-bearing corner posts capable of supporting a stack about 6-containers high (not sure of this figure), with locking mechanisms to link the boxes. But this arrangement teems with subtleties, from questions of swing control of ship-straddling cranes, to path-planning for automated port transporters, to the problem of ensuring the stability of a 6-high stack of containers in high seas, with the ship pitching and rolling violently up to 30 degrees away from the vertical. Here is a picture of the “twist-lock” mechanism that holds containers together and to the ship/train/truck-bed and endures enormous stresses, to makes this magic possible:
I am probably a little biased in my interest here, since I am fascinated by the blend of OR, planning and mechanical engineering (particularly stability and control) problems represented by container handling operations. I actually wrote a little simulator for my students to use as the basis for their term project when I taught a graduate course on complex engineering systems at Cornell in 2006 (it is basically a Matlab visualization and domain model with swinging cranes and stacking logic; if you are interested, email me and I’ll send you the code). But if you are interested in this aspect, try to get hold of the Rotterdam and Singapore port episodes of the National Geographic Channel Megastructures show.
There is a third thread to this subplot, that is probably the dullest part of the book: the story of how American and International standards bodies under heavy pressure from various business and political interests struggled and eventually reached a set of compromises that allowed the container to reach its full potential as an interoperability mechanism. The story was probably a lot more interesting than Levinson was able to make it sound, but that’s probably because it would take an engineering eye, rather than an economist’s eye, to bring out the richness underneath the apparently dull deliberations of standards bodies. There are also less important, but entertaining threads that have to do with the technical challenges of getting containers on and off trains and trucks, the sideshow battle between trucking and railroads, the design of “cells” in the ships themselves, the relationship between a ship’s speed/capacity tradeoffs and oil prices, and so forth.
Three: The Labor and Politics Subplot
This is the subplot that most of us would instinctively associate with the story of shipping, thanks to Marlon Brando. The big picture has a story with two big swings. First, in the early part of the century, dock labor was a truly Darwinian world of competition, since there were spikes of demand for longshore labor followed by long periods of no work. Since it was a low-skill job, requiring little formal education and a lot of muscle, there was a huge oversupply of willing labor. Stevedoring companies — general contractors for port operations — picked crews for loading and unloading operations through a highly corrupt system of mustering, favors, bribes, kickbacks and loansharking. The longshoremen, for their part, formed close brotherhoods, usually along ethnic lines (Irish, Italian, Black in the US) that systematically kept out outsiders, and maintained a tightly territorial system of controls over individual piers. This capitalist exploitation system then gave way to organized labor, but a very different sort of labor movement than in other industries. Where other workers fought for steady work and regular hours and pay, longshoremen fought to keep their free-agent/social-network driven labor model alive, and resist systematization. This local, highly clannish and tribal labor movement had a very different kind of DNA from that of the inland labor movements, and as containerization proceeded, the two sides fought each other as much as they fought management, politicians and automation. Though longshore labor is at the center of this subplot, it is important not to forget the labor movements in the railroad and trucking worlds. Those stories played out equally messily.
East and West coast labor reacted and responded differently, as did other parts of the world, but ultimately, the forces were much too large for labor to handle. Still, the labor movement won possibly its most significant victory in this industry, and came to be viewed as a model by labor movements in other industries.
The labor story is essentially a human one, and it has to be read in detail to be appreciated, for all its drama. The story has its bizarre moments (at one point, West Coast labor had to actual fight management to advocate faster mechanization and containerization, for reasons too complex to go into in this post), and is overall the part that will interest the most people. It is important though, not to lose sight of the grand epic story, within which labor was just one thread.
The other big part of this subplot, inextricably intertwined with the labor thread, is the politics thread. And here I mean primarily the politics of regulation and deregulation, not local/urban. To those of us who have no rich memory of regulated economies, the labyrinthine complexities of regulation-era industrial organization are simply incomprehensible. The star of this thread was the all-powerful Interstate Commerce Commission of the US (ICC), and its sidekicks, the government-legitimized price-fixing cartels of shipping lines on major routes. The ICC controlled the world of transport at a bizarre level of detail, ranging from commodity-level pricing, to dictating route-level access, to carefully managing competition between rail, road and sea, to keep each sector viable and stable. And of course, there was a massive money-chest of subsidies, loans and direct government infrastructure investment in ports to be fought over. The half-century long story can in fact be read as the McLean bull in the china shop of brittle and insane ICC regulations, simultaneously smashing the system to pieces, and taking advantage of it.
Four: The Urban Geography and History Subplot
This is the subplot that interested me the most. Containerization represented a technological force that old-style manual-labor-intensive ports and their cities simply were not capable of handling. The case of New York vs. Newark/Elizabeth is instructive. New York, the greatest port of the previous era of shipping, was an economy that practically lived off shipping, with hundreds of thousands employed directly or indirectly by the sector. Other industries ranging from garments to meatpacking inhabited New York primarily because the inefficiencies of shipping made it crucial to gain any possible efficiency through close location.
Containerization changed all that. While New York local politics around ports was struggling with irrelevant issues, it was about to be blindsided by containers. The bistate Port Authority, finding itself cut out of New York power games, saw an opportunity when McLean shipping was looking to build the first northeastern container handling wharf. This required clean sheet design (parallel parking wharfs instead of piers perpendicular to shore), and plenty of room for stacking and cranes. While nominally supposed to work towards the interests of both states, the Port Authority essentially bet on Newark, and later, the first modern container port at Elizabeth. The result was drastic: New York cargo traffic collapsed over just a decade, while Newark went from nothing to gigantic. Today, you can see signs of this: if you ever fly into Newark, look out the window at the enormous maze of rail, truck and sea traffic. The story repeated itself around the US and the world. Famous old ports like London, Liverpool and San Francisco declined. In their place arose fewer and far larger ports in oddball places: Felixstowe in the UK, Rotterdam, Seattle, Charleston, Singapore, and so forth.
This geographic churn had a pattern. Not only did old displace new, but there were far fewer new ports, and they were far larger and with a different texture. Since container ports are efficient, industry didn’t need to locate near them, and they became vast box parking lots in otherwise empty areas. The “left-behind” cities not only faced a loss of their port-based economies, but also saw their industrial base flee to the hinterland. Cities like New York and San Francisco had to rethink their entire raison d’etre, figure out what to do with abandoned shorelines, and reinvent themselves as centers of culture and information work.
There is a historical texture here: the rise of Japan, Vietnam, the Suez Crisis, oil shocks, and the Panama Canal all played a role. Just one example: McLean, through his Vietnam contract, found himself with fully-paid up, return-trip empty containers making their way back across the Pacific. Anything he could fill his boxes with was pure profit, and Japan provided the contents. With that, the stage was set for the Western US to rapidly outpace the East Coast in shipping. Entire country-sized economies had their histories shaped by big bets on container shipping (Singapore being the most obvious example). At the time the book was written, 3 of the top 5 ports (Hong Kong, Singapore, Shanghai, Shenzen and Busan, Korea) were in China. Los Angeles had displaced Newark/New York as the top port in the US. London and Liverpool, the heart of the great maritime empire of the Colonial British, did not make the top 20 list.
Five: The Broad Impact Subplot
Let’s wrap up by looking at how the narrow world of container shipping ended up disrupting the rest of the world. The big insight here is not just that shipping costs dropped precipitously, but that shipping became vastly more reliable and simple as a consequence. The 25% transportation fraction of global goods in 1960 is almost certainly an understatement because most producers simply could not ship long distances at all: stuff got broken, stolen and lost, and it took nightmarish levels of effort to even make that happen. Instead of end-to-end shipping with central consolidation, you had shipping departments orchestrating ad hoc journeys, dealing with dozens of carriers, forwarding agents, transport lines and border controls.
Today, shipping has gotten to a level of point-to-point packet-switched efficiency, where the shipper needs to do a hundredth of the work and can expect vastly higher reliability, on-time performance, far lower insurance costs, and lower inventories. That means a qualitatively new level of thinking, one driven by the axiom that realistically, the entire world is your market, no matter what you make. The dependability of the container-plumbing makes you rethink every business.
In short, container shipping, through its efficiency, was a big cause of the disaggregation of vertically integrated industry structures and the globalization of supply chains along Toyota-like just-in-time models. Just as the Web (1.0 and 2.0) sparked a whole new world of business models, container shipping did as well.
The deepest insight about this is captured in one startling point made in the book. Before container shipping, most cargo transport involved either raw materials or completely finished products. After container shipping, the center of gravity shifted to intermediate (supply chain) goods: parts and subassemblies. Multinationals learned the art of sourcing production in real time to take advantage of supply chain and currency conditions, and moving components for assembly and delivery at the right levels of disaggregation. Thanks to container shipping, manufacturers of things as messy and complicated as refrigerators, computers and airplanes are able to manage their material flows with almost the same level of ease that the power sector manages power flows on the electric grid through near real-time commodity trading and load-balancing.
My clever-phrase-coinage of the day. The container did not only make just-in-time possible. It made just-in-place possible.
Conclusion: Towards Box: The Movie
I wasn’t kidding: I think this story deserves a big, epic-scale movie. Not some schmaltzy piece-of-crap story about a single longshoreman facing down adversity and succeeding or failing in the container world, but one that tells the tale in all its austere, beyond-human grandeur; one that acknowledges and celebrates the drama of forces far larger than any individual human.
An end-note: this is my first post in a deliberate attempt to steer my business/management posts and book reviews 90 degrees: from a focus on general management topics like leadership, and functional topics like HR and marketing, towards “vertical” topics. I have felt for some time that business writing is facing diminishing returns from horizontal and functional foci, and while I’ll return to those views when I find good material, my pipeline is mainly full of this kind of stuff now. Hope you guys like the change in direction: steering a major theme of a very wordy, high-inertia blog like this one is as hard as steering a fully-laden container ship. It is going to take some time to overcome the directional inertia. Some verticals on my radar, besides shipping, include the garbage/trash industry, healthcare, and infrastructure. If you are interested in particular verticals, holler ’em out, along with suggested books.
Comments
Thank you for this great review/summary. Now I dont need to read the book!
Excellent post! I didn’t expect to read the whole thing, but I’m glad I did. That is a fascinating story.
Venkat – riveting story!! Post reverberates with energy & makes for a compelling read. I will pick this book up, for high-intensity drama, if not anything else :)
Manju
Grrr..
That was the exhaustive summary of the book. It seems like one of the few business books I have come across that are worth reading. Will pick it up sometime, thanks.
Hope you are doing well.
Sharad
I just thoroughly enjoy your blogs, and twits. A guy called Martin Geddes, not Head of Strategy at BT Design, used this metaphor at Telco2 Conference, london , to explain the role that the Telco’s need to play in the future. Keep up the good work.
Thanks for your comments folks! Glad you liked it.
Deepak: don’t let the review stop you from reading the book. I have not captured more than 1% of the story, so the full read is worth it.
Paul: Yes, the analogy between telecom infrastructure and shipping is very close. Maybe at some level, even the math models are the same. But I suspect there are important differences too, that makes the industries different, and I hope to figure them out some day.
Venkat
Excellent article. You mention “just in time” and “just in place.” Please keep in mind that all it takes is one piece of code out of place, a single digit and possibly a single byte of data and the system will malfunction. And it’s no longer “just in time” it’s “oh my gosh we’re out of materials.” It’s the digital Murphy’s Law as applied to container logistics.
Thanks.
Absolutely rivetting post. Stumbled across to this page from your ‘Office’ post linked on HN (which I haven’t read in full because of the awesomeness I encountered in the first few paragraphs, and having never watched the series – I’ve decided to push it for later to enjoy it fully). I just want to say thanks for writing this. I’ve had a great fascination in all things shipping, railroads, NatGeo supertructures etc..(doesn’t mean I have a whole lot of knowledge on it) and I really enjoyed this so much. I’ll come back to you later probably with a detailed email once I’ve read the book and ‘Office’ post.
I would like to have information about the container model # IRO-25/0T. How can I unload that container from the train and how I can empty it . Do you have video or catalog about it ?
Thanks,
Robert Ratelle
fermedelapresquile@qc.aira.com
Season 2 of The Wire could be part of your Box movie.
there was a box docu called “The Box That Changed Britain” http://vimeo.com/21395880 – you can probably finde the full show on download still.
mostly about britain but still interesting to see how a box could change so much.
Thanks for the blog. On the back of this I’ve just ordered the book!",8
128,"Work on what matters.
We all have a finite amount of time to live, and within that mortal countdown we devote some fraction towards our work. Even for the most career-focused, your life will be filled by many things beyond work: supporting your family, children, exercise, being a mentor and a mentee, hobbies, and so the list goes on. This is the sign of a rich life, but one side-effect is that time to do your work will become increasingly scarce as you get deeper into your career.
If you’re continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. For a while you can try sleeping less or depriving yourself of the non-work activities you need to feel whole, but you’ll inevitably find that your work maintains a aloof indifference to your sacrifice rather than rewarding it. Only through pacing your career to your life can you sustain yourself for the long-term.
Indeed, pacing yourself becomes the central challenge of a sustained, successful career: increasingly senior roles require that you accomplish more and more, and do it in less and less time. The ledge between these two constraints gets narrower the further you go, but it remains walkable if you take a deliberate approach.
First a discussion on a few common ways to get tripped up: snacking, preening, and chasing ghosts. Then we’ll get into the good stuff: how do you work on what really matters?
Avoid snacking
Hunter Walk recommends that folks avoid “snacking” when they prioritize work. If you’re in a well-run organization, at some point you’re going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The later choice–easy and low-impact–is what Walk refers to as snacking.
When you’re busy, these snacks give a sense of accomplishment that makes them psychologically rewarding but you’re unlikely to learn much from doing them, others are likely equally capable of completing them (and for some of them it might be a good development opportunity), and there’s a tremendous opportunity cost versus doing something higher impact.
It’s ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you’re spending on high-impact work versus low-impact work. In senior roles, you’re more likely to self-determine your work and if you’re not deliberately tracking your work, it’s easy to catch yourself doing little to no high-impact work.
Stop preening
Where “snacking” is the broad category of doing easy and low-impact work, there’s a particularly seductive subset of snacking that I call “preening.” Preening is doing low-impact, high-visibility work. Many companies conflate high-visibility and high-impact so strongly that they can’t distinguish between preening and impact, which is why it’s not uncommon to see some companies’ senior-most engineers spend the majority of their time doing work of dubious value but that is frequently recognized in company meetings.
If you’re taking a short-term look at career growth, then optimizing for your current organization’s pathologies in evaluating impact is the optimal path: go forth and preen gloriously. However, if you’re thinking about developing yourself to succeed as your current role grows in complexity or across multiple organizations, then it’s far more important to strike a balance between valued work and self-growth.
This is also an important factor to consider when choosing a company to work at! Dig into what a company values and ensure it aligns with your intended personal growth. If a company’s leadership is entirely folks who focus their energy on performant urgency or acts of fealty, don’t be surprised when your success in the company depends on those activities.
Worse, to be a successful preener requires a near invulnerability to criticism of your actual impact, and your true work will suffer if your energy is diverted to preening. Typically this means you need to be a vanity hire of a senior leader or to present yourself in the way a company believes leaders look and act. If that isn’t you, then your attempt to exchange your good judgement for company success will end up failing anyway: you’ll get held accountability for the lack of true impact where others who match the company’s expectation of how a leader appears will somehow slip upward.
Stop chasing ghosts
Many folks would assume that companies, rational optimizers that they are, avoid spending much time on low-impact high-effort projects. Unfortunately that isn’t consistently the case. It’s surprisingly common for a new senior leader to join a company and immediately drive a strategy shift that fundamentally misunderstands the challenges at hand. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential.
As a senior leader, you have to maintain a hold on your ego to avoid investing into meaningless work at a grand scale. This can be surprisingly challenging when during your hiring process you’ve been repeatedly told that you’ve been hired to fix something deeply broken – you’re the newly-hired savior, of course your instincts are right! Taking the time to understand the status quo before shifting it will always repay diligence with results.
I had a recent discussion with someone who argued that new senior leaders deliberately push for major changes even though they suspect the efforts will fail. Such changes make the organization increasingly dependent on the new leader, and also ensures anything that does go well gets attributed to the new leader directly rather than their team. If this is your approach to leadership, please know that you’re awful and take the time to work on yourself until the well-being and success of an entire company matters to you more than being perceived as essential.
Existential issues
Now that you’re done snacking, preening and chasing ghosts, the first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal iterative elimination tournament, balancing future success against surviving until that future becomes the present. If you’re about to lose one of those rounds, then always focus there.
Running out of money, like my experience at Digg, can be the most obvious issue, but not every existential issue is financial, like Twitter’s fail whale stability challenges or adapting to the shifts caused by the Covid-19 pandemic.
If something dire is happening at your company, then that’s the place to be engaged. Nothing else will matter if it doesn’t get addressed.
Work where there’s room and attention
Existential issues are usually not the most efficient place to add your efforts, but efficiency isn’t a priority when the walls are crashing down around you. You should swarm to existential problems, but if a problem isn’t existential then you should be skeptical of adding your efforts where everyone’s already focused. Folks often chase leadership’s top priority, but with so many folks looking to make their impact there, it’s often challenging to have a meaningful impact.
Instead, the most effective places to work are those that matter to your company but still have enough room to actually do work. What are priorities that will become critical in the future, where you can do great work ahead of time? Where are areas that are doing ok but could be doing great with your support?
Sometimes you’ll find work that’s worthy of attention, but which an organization is incapable of paying attention to, usually because its leadership doesn’t value that work. In some companies this is developer tooling work, in others it’s inclusion work, and in most companies it’s glue work.
There is almost always a great deal of room to do this sort of work that no one is paying attention to, so you’ll be able to make rapid initial progress on it, which feels like a good opportunity to invest. At some point, though, you’ll find that the work needs support, and it’s quite challenging to get support for work that a company is built to ignore or devalue. Your early wins will slowly get eroded by indifference and misalignment, and your initial impact will be reclaimed by the sands of time.
Does this mean you shouldn’t do inclusion work? No, that’s not the conclusion I want you to take away from this. Sometimes an area that an organization doesn’t pay attention to is so important that you’re going to want to advocate for it to start paying attention. Teaching a company to value something it doesn’t care about is considerably the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. As a senior leader, you have an ethical obligation that goes beyond maximizing your company-perceived impact, but it’s important to recognize what you’re up against and time our efforts accordingly.
Foster growth
One area that’s often underinvested in (e.g. lots of room to work in) while also being highly leveraged is growing the team around you. Hiring has a lot of folks involved in it, usually in terms of optimizing the hiring funnel, but onboarding, mentoring and coaching are wholly neglected at many companies despite being at least as impactful as hiring to your company’s engineering velocity.
If you start dedicating even a couple hours a week to developing the team around you, it’s quite likely that will become your legacy long after your tech specs and pull requests are forgotten.
Edit
A surprising number of projects are one small change away from succeeding, one quick modification that unlocks a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications and short conversations as editing your team’s approach.
With your organizational privilege, relationships you’ve built across the company, and ability to see around corners derived from your experience, you can often shift a project outcomes by investing the smallest ounce of effort, and this is some of the most valuable work you can do.
It’s particularly valuable because it’s quick, it’s easy, it’s highly motivating for both you and the person you help, and it’s hugely impactful when done well. (Also, it’s highly demotivating when done poorly, so your approach matters!)
Finish things
One special sort of editing is helping finish a project that just can’t quite close itself out. Often you’ll have a talented engineer earlier in their career who is already doing the work but can’t quite create buy-in or figure out how to rescope their project into finishable work. It’s surprisingly common that coaching a teammate on how to tweak a project into something finishable, and then lending them your privilege to budge the right friction points will transform a six month slog into a two week sprint with almost an identical impact.
We only get value from finishing projects, and getting a project over the finish line is the magical moment it goes from risk to leverage. Time spent getting work finished is always time well spent.
What only you can
The final category of work that matters is the sort that you’re uniquely capable of accomplishing. Sure there’s work that you’re faster at or better at than some other folks, but much more important is the sort of work that simply won’t happen if you don’t do it.
This work is an intersection of what you’re exceptionally good at and what you genuinely care about. It might be writing your company’s technology strategy that folks will actually follow, it might be convincing a great candidate to join, it might be changing your CEO’s mind on how you pay down tech debt, it might be crafting a discerning API.
Whatever it is, things that simply won’t happen if you don’t do them are your biggest opportunity to work on something that matters, and it’s a category that will get both narrower and deeper the further you get into your career.
Why it matters
If you’re interviewing for a new role twenty years into your career, the folks interviewing you won’t know what your real impact was on any given project you worked on, nor will they know your true contribution to any of the companies you worked at. Instead you’ll find yourself judged by a series of surprisingly subjective measures: your prestige, the prestige of the titles you’ve had and companies you’ve worked at, your backchannel reputation, and how you present in your interview process.
If you spend your career snacking, preening or chasing ghosts, it’s possible but relatively unlikely that what you’ve done before will be valued at companies you interview with. Instead, the only viable long-term bet on your career is to do work that matters, work that develops your and to steer towards companies that value genuine expertise.",4
129,"Ethereum Blockchain Eliminates 99.99% of its Carbon Footprint Overnight After a Successful Merge According to New Report
New York, NY, September 15th, 2022 — Today, ConsenSys confirms that the goal of making Ethereum more sustainable through a historic transition from the Proof of Work to a Proof of Stake consensus mechanism has been achieved. This upgrade transforms Ethereum, the world’s first and largest smart contract platform, into an almost net-zero technology positioned for sustainable future growth, reducing overnight its carbon footprint by over 99.99%, according to a new report from CCRI (Crypto Carbon Ratings Institute), commissioned by ConsenSys. This surpasses the 99.95% estimate from the Ethereum Foundation.
According to CCRI, Ethereum’s electricity consumption has reduced by over 99.988%, from nearly 23 million megawatt-hours per year to just over 2,600. As a result, CO2 emissions are down 99.992%, from over 11 million tons annually to under 870, which is the equivalent of less than the annual energy use for a hundred homes in the United States.
The biggest decarbonization in the history of tech paves the way for industries
The Merge represents an extraordinary engineering feat on the part of Ethereum’s core developers – a unique and complex upgrade made possible by years of research and testing. It is the first time in history that an operational blockchain network has changed its consensus model while in continuous operation, dramatically slashing its carbon footprint overnight. Moreover, the Merge was carried out in a way that was entirely seamless for users, without any downtime.
The collaboration of hundreds of developers from all over the world, often working on a voluntary basis, is an interesting example of collective action to improve a public good and could provide a model for other industry overhauls in the future. It demonstrates how innovation and technology improvement can radically reduce emissions. Similar radical innovation and efforts are inevitable also in other sectors to achieve deep decarbonization. The slow progress of nations to decarbonize in line with the Paris Agreement underpins the necessity to act now and follow the example of Ethereum.
The Merge is the second implementation in a three-phase plan designed to make Ethereum more sustainable and secure. The transition to Proof of Stake sets the foundation for these next pivotal stages in the Ethereum development roadmap.
Speaking of the report and the success of the transition, Joseph Lubin, founder of ConsenSys and co-founder of Ethereum, said, “We’re delighted to have commissioned this report from CCRI, which substantiates the Ethereum Merge’s impact as likely the biggest decarbonization effort of any industry in history. Having removed the high carbon footprint as one of the biggest barriers to future growth, Ethereum is now primed for further waves of interest, development, adoption, and investment, as The Merge enables Ethereum to become internet scale IT infrastructure for low carbon projects around the globe.”
Uli Gallersdörfer, Co-founder and CEO of CCRI, stated, “We’re pleased to have been able to leverage our expertise to evaluate the success of Ethereum’s transition to Proof of Stake in sustainability terms and to have such positive findings. As a result, Ethereum’s green credentials are now comparable to any of the newer platforms launched based on Proof of Stake from the outset.”
The Merge opens a vast horizon of new opportunities for brands
The carbon footprint of the blockchain and cryptocurrency sector, particularly Proof of Work networks, has come under increasing scrutiny. At the same time, blockchain innovations like NFTs and decentralized finance have gained prominence and sizable user bases.
Ethereum’s transition to Proof of Stake could not be more timely. The move paves the way for adopting Ethereum-based applications and tokens by groups who would otherwise have been deterred by the high carbon footprint, allowing them to participate in the vast global network of Ethereum-based apps and services. For example, more complex smart contracts, such as those used to power NFTs or enterprise applications, invariably rely on more code to transact. Under Proof of Work, the environmental price of using these applications was simply too great given the current state of the power sector decarbonization and typical mining locations. Under Proof of Stake, users can transact with NFTs or use complex smart contracts with just a fraction of the impact.
In carrying out this research, CCRI used established literature and methodologies for the Proof of Work component, while the Proof of Stake assessment was conducted using a research framework developed by CCRI and adapted for Ethereum’s specific landscape.
The full CCRI report is available for download at https://carbon-ratings.com/eth-report-2022.
Media contact: [email protected]
ABOUT CONSENSYS
ConsenSys is a leading Ethereum and decentralized protocols software company. We enable developers, enterprises, and people worldwide to build next-generation applications, launch modern financial infrastructure, and access the decentralized web. Our product suite, composed of Infura, Quorum, Codefi, MetaMask, MetaMask Institutional, Truffle, Diligence and our NFT platform, serves millions of users, supports billions of blockchain-based queries for our clients, and has handled billions of dollars in digital assets. Ethereum is the largest programmable blockchain in the world, leading in business adoption, developer community, and DeFi activity. On this trusted, open-source foundation, we are building the digital economy of tomorrow. To explore our products and solutions, visit https://consensys.net/.
ABOUT CCRI
CCRI – Crypto Carbon Ratings Institute – is a research-driven company providing data on sustainability aspects of cryptocurrencies, blockchain and other technologies. The interdisciplinary team has built a multi-year track record with a specific focus on cryptocurrencies and their sustainability impacts. CCRI uses the most up-to-date data sources as well as methods based on formerly peer-reviewed studies published in renowned scientific journals. CCRI provides insights that help their clients to understand and manage crypto-related ESG exposure. CCRI’s client base covers a broad range of clients including institutional investors, exchanges and blockchain networks. To explore CCRI’s products and services, visit https://carbon-ratings.com/.",2
131,"HydraUSB3 V1 is an open source developer kit for the WCH CH569 MCU to experiment with streaming / high-speed protocols like HSPI and SerDes through USB3.
It allows to test and discover the MCU main features, like:
- USB3 SS built-in PHY (5Gbps) and USB2 built-in PHY FS/LS/HS (480Mbps)
- Can be used as Device or Host.
- HydraUSB3 dedicated test firmware support USB2 HS and USB3 SS (in a transparent way) basic/bare metal stack in Device Bulk mode with Burst for USB3 Super Speed best performances.
- HydraUSB3 example firmware support streaming/transfer (with libusb) at more than 330MBytes/s (from HydraUSB3 <=> PC Host).
- HydraUSB3 test firmware for USB2 & USB3 does not requires any driver for Windows (using native WinUSB WCID descriptors in firmware) or GNU/Linux and is supported with libusb open source example codes.
- See https://github.com/hydrausb3/hydrausb3_fw/tree/main/HydraUSB3_USB
- High Speed Parallel Interface (HSPI) up to 3.8Gbps with unique fast bidirectional parallel bus 8, 16 & 32bits up to 120MHz
- Can be interfaced with an FPGA to be used as USB3 Super Speed / HSPI bridge.
- Can be used to interface two HydraUSB3 boards for ultra fast communication/transfer of data.
- See https://github.com/hydrausb3/hydrausb3_fw/tree/main/HydraUSB3_DualBoard_HSPI
- SerDes (up to 1.20Gbps officially, up to 1.38Gbps non officially)
- Can be interfaced with an FPGA to be used as USB3 Super Speed / SerDes bridge.
- Can be used to interface two HydraUSB3 boards for ultra fast communication or output some traces in real-time with latency < 1us.
- See https://github.com/hydrausb3/hydrausb3_fw/tree/main/HydraUSB3_DualBoard_SerDes
- eMMC / SDCard / SDIO (up to 96MHz 8bits mode with option/extension)
- Can be used over USB3 SS for ultra fast communication/transfer of data.
HydraUSB3 V1 Evaluation Board / Dev Kit and test firmware are not linked to HydraBus v1 hardware/firmware projects and will not replace it.
HydraUSB3 support natively dual board connection (without requiring any wire/cable except for SerDes connection which requires 2 wires for GXP/GXM)
- The aim is to connect two HydraUSB3 V1 boards together (one on top of another) for multi CPU communication / special streaming features and to use the different supported protocols between 2 boards (one board can act as device and the other as host with the help of PB24 jumper to identify host or device…).
HydraUSB3 V1 Board
HydraUSB3 V1 in stock at digikey.com HYDRAUSB3_V1 / 3792-HYDRAUSB3_V1-ND, Pack of 2x HydraUSB3 v1 boards are available also on HydraBus Store
HydraUSB3 V1 is produced using components with Operating Temperature -40°C / +85°C (or more), the MCU WCH CH569W Operating Temperature is -20°C / + 85°C.
Caution HydraUSB3 V1 is an Electrostatic Sensitive Devices Do Not Handle Except at a Static Free Workstation.
HydraUSB3 open source test firmware / API:
See github: https://github.com/hydrausb3/hydrausb3_fw
For more info on open test firmware or hardware for HydraUSB3 see
https://github.com/hydrausb3/hydrausb3_fw/wiki/Getting-Started-with-HydraUSB3
HydraUSB3 V1 package content:
- Pack of 2x HydraUSB3 v1 boards are available now on HydraBus Store
- 1x HydraUSB3 V1 board (fully tested)
- Available on Digi-Key (PN 3792-HYDRAUSB3_V1-ND)
- The board have 3 Jumpers populated on P4(SHUNT), PB22/ULED, PB23/UBTN
- Additional jumpers are required for other mode like Flash Mode P3, ENABLE 3V3_EXT, PB24
- Note: For Flash Mode P3 you can also just short the 2 pins during boot/power ON to Enter WCH ISP Flash Bootloader
- HydraUSB3 V1 board has been designed, produced & validated to meet the best possible performances
- Each board has been validated with impedance tests on SerDes (Zdiff 100 Ohms+/-10%), USB2 & USB3 signals (Zdiff 90 Ohms+/-10%)
- Each board use high quality Industrial Grade components
- Including +/-10ppm 30MHz Crystal (Operating Temperature -40℃~+85℃)
- The MCU WCH CH569W Operating Temperature is -20°C / + 85°C
- USB A Male to USB A male cable is NOT included (required to flash the WCH CH569 MCU or to communicate over USB2 or USB3 with the MCU).
- Warning It is MANDATORY to buy a “USB 3 Type A male to USB 3 Type A male cable” (the cable shall have Power+Data with USB2 and USB3 SS signals)
- Recommended “USB A Male to USB A male cable” (not included with HydraUSB3 v1 board)
- Manufacturer deleyCON
- Model No: MK744 (2m blue/black)
- Model No: MK743 (1.5m blue/black)
- Model No: MK742 (1m blue/black)
- Model No: MK741 (0.5m blue/black)
- Manufacturer Stewart Connector (Available at Digi-Key…)
- USB 3.2 Gen 1 (USB 3.1 Gen 1, Superspeed (USB 3.0)) Cable A Male to A Male 3.00′ (914.4mm) Shielded
- Manufacturer Product Number SC-3AAK003F
- Digi-Key Part Number 380-1415-ND
- Manufacturer deleyCON
- It is highly recommended to buy 2x HydraUSB3 V1 boards to evaluate the full potential of HydraUSB3 V1 (WCH CH569 MCU) especially with high speed peripherals like USB3 SS(5Gbps), HSPI(up to 3.8Gbps), SerDes(>1Gbps) or even slower peripherals.
- It is recommended to use high quality “Jumper Wire Female to Female standard-pitch 0.1″ (2.54mm)” for prototyping (or to connect SerDes between 2 boards…) like Premium Female/Female Jumper Wires – 20x 3″ (75mm) 28 AWG from Adafruit Industries Digi-Key Part Number LLC 1528-1962-ND
- It is also recommended to buy some additional CONN JUMPER SHORTING (for Flash Mode P3, PB24, ENABLE 3V3 EXT …) “2 (1 x 2) Position Shunt Connector Black Closed Top 0.100″ (2.54mm)” like https://www.digikey.com/en/products/detail/sullins-connector-solutions/STC02SYAN/76372
Overview:
- Very small board size 60mm x 60mm.
- Including 4 holes (3.2mm for M3 bolt) to mount screws or even a case (not included).
- Features of the HydraUSB3 V1 board:
- WCH CH569W MCU RISC-V 32-bit (RISC-V3A based on RV32IMAC) up to 120MHz & 448KB Embedded Flash.
- For more details about RISC-V3A see CH32V103 datasheet (which is based also on RISC-V3A with more details)
- See RISC-V ISA Doc: https://github.com/msyksphinz-self/riscv-isadoc
- RISC-V features:
- RV32I = Base Integer Instruction Set, 32-bit
- M = Standard Extension for Integer Multiplication and Division
- A = Standard Extension for Atomic Instructions
- C = Standard Extension for Compressed Instruction
- Fast Interrupt (do automatic save/restore of registers in interrupt when IRQ function use attribute((interrupt(“WCH-Interrupt-fast”))))
- 64 bits SysTick (which can be used to count CPU cycles too)
- Free multi-platform Eclipse RISC-V IDE (Community) (to build project/source code) supporting WCH CH569 on Linux & Windows
- See MounRiver_Studio_Community http://www.mounriver.com/download
- Ultra fast programming through USB2 HS bootloader/flasher (requires a jumper on P3/Flash Mode)
- Supported officially with wch-isp open source native multi-platform C tool
- 1x USB Type A female connector (with USB2 and USB3 SS signals) with ESD protections.
- USB VBUS (5V) protections with ESD protection and 1A resettable fuse
- 1x Reset (3V3_DISABLE) & 1x User Button (PB23/UBTN) with 1x User LED (PB22/ULED)
- Such feature can be disabled to reuse I/O for other purpose.
- There is also a 2pins 2.54mm (P5) connector to disable the LDO / 3V3 Output(MCU power) with a Jumper.
- 1x Shunt (P4/SHUNT) (2 pins 2.54mm) connector with Jumper can be used to measure accurately WCH CH569 power consumption with an external multimeter.
- 1x GND 3V3 (P2 with 2 pins 2.54mm) connector can be used to power externally the WCH CH569 MCU (it is recommended to remove the P4/SHUNT in that case it is not mandatory as the the 3V3 LDO IC1 is protected against reverse current)
- 3V3 LDO IC1 features:
- Input voltage range up to 16V
- 500mA Low-Noise LDO Voltage Regulator
- Low Noise: 40µV Possible
- High Accuracy: 1%
- Reverse Battery Protection
- Low Dropout: 340mV at Full Load
- Low Quiescent Current: 90µA
- 3V3 LDO IC1 features:
- 1x ENABLE 3V3 EXT (2 pins 2.54mm) connector (P7) to connect the 3V3 power from LDO (IC1) to J5 connector pin 3V3 EXT
- Breakout of all 49 I/O.
- Debug/Programming through low cost RISC-V Debugger (not included)
- DEBUG WCH-Link (2-wire SWDIO/SWCLK)
- WARNING Debug/Flashing with 2-wire is not recommended as it can permanently brick the WCH CH569 MCU.
- It is advised to use log/traces and/or GPIOs (with Oscilloscope/Logic Analyzer) for debug purposes
- See CH56x_debug_log.h for log traces API
- log traces are possible over UART / SerDes / HSPI for real-time debug/traces of fast protocols like USB2, USB3, SerDes, HSPI, eMMC …
- See CH56x_hydrausb3.h & CH56x_gpio.h for GPIOs API
- See CH56x_debug_log.h for log traces API
- The hardware support different protocols
- USB3 SS built-in PHY (5Gbps) and USB2 built-in PHY FS/LS/HS (480Mbps)
- High Speed Parallel Interface (HSPI) up to 3.8Gbps with unique fast bidirectional parallel bus 8, 16 & 32bits up to 120MHz
- SerDes (up to 1.20Gbps and even up to 1.38Gbps non officially)
- Gigabit Ethernet controller (with option/extension).
- The hardware provide RGMII and RMII PHY interface for 10/100/1000Mbps transfer rate.
- eMMC / SDCard / SDIO (up to 96MHz 8bits mode with option/extension).
- The hardware provide a Built-in EMMC controller. Support single-wire/4-wire/8-wire data communication mode. Comply to EMMC Specification Rev. 4.4 and Rev. 4.5.1, compatible with Specification Rev. 5.0.
- Support AES/SM4 algorithm. 8 types of combinations for encryption/decryption modes. Support encryption/decryption of SRAM/EMMC/HSPI data.
- SPI (exceed 50MHz).
- UART (up to 6Mbauds and 12Mbauds non officially).
- GPIO (In/Out/Open-Drain with internal pull-up/pull down).
- Active parallel port: 8-bit data, 15-bit address bus.
- Hardware documentation is available on github: https://github.com/hydrausb3/hydrausb3_hw
- For more details on HydraUSB3 v1 (first version is V1 R1) the schematic is available in PDF see https://github.com/hydrausb3/hydrausb3_hw/blob/main/HydraUSB3_V1R1_schematic.pdf
- WCH CH569W MCU RISC-V 32-bit (RISC-V3A based on RV32IMAC) up to 120MHz & 448KB Embedded Flash.
- Features of the HydraUSB3 test firmware / examples (hydrausb3_fw):
- Fully open source test firmware with examples Licensed under the Apache License, Version 2.0
- It is based on official WCH CH569 Examples https://github.com/openwch/ch569/tree/main/EVT/EXAM
- The test firmware / examples with host tools (using libusb) allow to do real-time streaming / data exchange over USB2 HS or USB3 SS mainly for HSPI and SerDes protocols (between 2x HydraUSB3 V1 boards connected together).
- Fully open source test firmware with examples Licensed under the Apache License, Version 2.0",2
132,"Neophilia and Its Discontents
TAoN No. 119: Why nuance beats novelty. Plus: LOST OBJECTS in New York City; don't miss the orc; and more.
By Ivan Babydov via Pexels
THANK YOU FOR YOUR PATIENCE
Hello all. I am back! Thank you for understanding that a break was in order. Note to those of you who have a paid sub: As you know, I paused billing on paid subs, so I am now reactivating that. And note to those who have been waiting to get a paid sub (you’ll have access to more posts and discussions, and most important you support this entire enterprise), you can now go for it!
Also, welcome to all you newcomers. I found it surprising that hundreds of people signed up (for the free edition) during the weeks I was publishing nothing at all. I hope you aren’t too disappointed now that I’m actually in your inbox :/
Anyway, I’m truly excited to be back, so here goes.
NUANCE > NOVELTY
Longtime readers know I’m a fan of the podcast No Stupid Questions, in which academic and author Angela Duckworth and journalist and Freakonomics co-creator Stephen Dubner talk over various behavioral psychology topics. One recent episode, mostly about the idea of the mid-life crisis, included a passage that struck me as really insightful — and useful.
Dubner reminds Duckworth about a prior conversation in which she’d underscored the importance of prizing nuance over novelty. He continues:
That resonated so much with me because I feel like so many of us are in search of novelty all the time, and when we are not getting it, we can feel like we’re in a rut.
Dubner ties this to the episode’s main theme: someone in a stereotypical midlife crisis might deal with that “rut” by pursuing some big, nutty change or adventure (a tattoo! etc.). So Dubner asks if Duckworth can say more about nuance vs. novelty. She replies in part:
It is part and parcel of human D.N.A., the human condition, to be interested in things that are new — things that we haven’t seen before, things that we haven’t experienced before. This drive for novelty, neophilia, is with us at all stages of life.
Somehow I did not know the term “neophilia,” but you can intuit how so much of the modern world is designed to exploit our innate “drive for novelty.” Back to Duckworth:
I think the way to steer that in a way that’s beneficial — it doesn’t require piercing, tattoos, or [similar extreme maneuvers] — is to discover the pleasure of nuance.
She zeroes in on her own work as a psychologist: This is what she’s done for decades, but she doesn’t feel a rut, because she savors nuance.
Once you are an expert, you can discern these subtle differences. And I think that makes life full of novelty. … It’s not that you run out of these subtleties. In fact, the more you know, the more you notice. And so, you can, essentially, enjoy a life of never being bored.
In other words, being super-familiar with a job, a place, a topic, can be a good thing. Dubner replies:
I love the use of “discernment,” which is also a religious or spiritual phrase — a way of taking stock of your soul. But basically, what you’re saying — I mean, it goes back to Socrates, right? “The unexamined life is not worth living.” You’re saying, “Examine the life. You will find nuance in gradation there.”
Arguing for nuance over novelty is that it’s an example of itself: a subtle idea that you have to make an effort to appreciate. This is a reminder I needed — and need often. You could, after all, argue that the entire TAoN project is about an obsession with novelty! But I’m hoping it’s also about an obsession with nuance.
Spend a week or two making an effort to attend to nuance — things you perceive or notice that most people miss. Make a nuance list. Appreciate it.
Here again is the link to the NSQ episode.
COMING UP
In forthcoming Thursday paid-subscriber-only editions: I’m kicking off a new series about “other people.” That is: I’ve been thinking and reading a lot about how we relate to friends and colleagues etc., and how the pandemic years affected those relationships. I’m planning to write about a new book from a psychologist who has studied making (and keeping) friendships, and I’ll be seeking your feedback and experiences — and, to be honest, your advice!
In recent subscriber-only issues I wrote about, mindwondering, attention as activism, and Hero of Noticing street artist Tom Bob.
For access to past and future subscriber-only posts, discussion threads, and more, support TAoN with a paid subscription.
THE NEXT FREE MONDAY EDITION IN TWO WEEKS! (WILL INCLUDE A NEW ICEBREAKER, I PROMISE!)
IN OTHER NEWS
^^ If you’re in New York City, stop by a fun and free event promoting the book I co-edited with Joshua Glenn, Lost Objects: 50 Stories About the Things We Miss and Why They Matter. I’m planning to be there, and so is Josh, and we have scheduled readings from an all-star selection of our contributors. Come say hi! More info on the event and the book here.
—> If you buy the book directly from the publisher, you can get a 20% discount off the retail price, through 12/25, by using the code LOSTOBJECTS. Here.
An excellent episode of Latino USA focuses on how “the little black dress” has functioned as a sort of uniform for certain workers in luxury retail.
Shazam for rocks. “Rock Identifier (Google Play, iOS) works fast in scanning and identifying rocks, minerals, and crystals.” Via.
Getting more awe in your life. (Thx, Kevin!)
The case for paying attention to your server’s name.
“I have a friend who’s [always] on his phone. We were sitting out in a parking lot, and there was a guy who came out who was in this full orc costume with a shield. I thought, I’m not going to say anything. … The guy passed right by [us] and — it was outside a hotel — tried to get through a revolving door. There’s all this bump ba bump ba bump, … But [my friend] never looked up! Then later I told him, and he’s like, “That didn’t happen!” … I mean, I could be on TikTok all night long… . But something that takes you out of your environment, you pay a high price. You miss the orc.” — Lynda Barry.
OKAY THAT’S IT!
As always, I value your feedback (suggestions, critiques, positive reinforcement, constructive insults, etc.), as well as your tips or stories or personal noticing rituals, things we need a word for, and of course your icebreakers: consumed@robwalker.net. Or use the comments. —> Or just click the heart symbol. That always makes my day.
And thanks for reading …
rw
Twitter | RobWalker.net | NB: I use (some) Amazon Affiliate links
All this by Rob Walker PO Box 171, 748 Mehle St., Arabi LA 70032
To unsubscribe see the grey box at the bottom of the email, or go here.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
I too have looked for novelty most of my life. I have moved on average every three years, I think because I get itchy feet. My father was in the army and it was not by choice that we moved so often but I grew into the habit. Now that I am 69 I find moving to be most unpleasant. I would rather slow down and look at things carefully. I take pleasure in small things – my dog's wet nose in the morning, the flowers blooming outside, the birds hopping in the bushes next door, and the generosity of my husband.
You see, I have developed heart failure. I have to slow down. I have to appreciate what is around me more. Knowing something really well allows you to notice details that may have escaped you before. It’s like reading a book for the fourth time. You notice themes and character development and modes of expression that the writer use as well. You have new insights. Listening to a piece of music you have heard many times before and discovering a new depth of meaning in it or a particular phrase that moves you – these are examples of nuance.
I find that coming to know someone really well requires understanding the nuances of their facial expressions, their mannerisms, and their unique quirks. You have to learn their face so well that you can see shades of meaning on it.￼
￼
My way of seeking novelty was to always move to a new place. What was interesting in this pattern was that once I relocated, I’d obsess over the nuances of the place I left. I spent 50 years of life doing this yet not understanding. Craving but never satisfied. Now I’m too tired to move around and I am learning to observe the nuances of life in this place that is my home town. It’s painful at times. But worth it.",2
133,"créativité de masse, production en série
Cette semaine, je me questionne sur le geste humain dans les rouages de l’industriel.
Travail manuel, travail industriel
Je vois souvent au centre l’évocation de l’artisanat et la relocalisation des processus de production dans les discours écologistes. Pour moi, l’artisanat, c’est les 24 portraits d’Alain Cavalier qui la mettent au premier plan, et l’industrie, ce sont des processus automatisés, des auteurs remplaçables, des robots.
Ma copine aelle m’explique que, pourtant, la différence entre l’artisanat et l’industrie ne se joue pas sur la supervision par l’humain d’une machine. L’outil est encore bien ancré dans la main des centaines d’humains qui réalisent de la technologie de pointe. L'industrie s’appuie non seulement sur une échelle plus importante mais sur des processus normés et des attendus basés sur les spécifications d’un cahier des charges. Mais la main n’est pas détachée de ces processus, et l’imagination non plus. Parfois, seules les performances du produit fini sont définies: le processus de fabrication n’est pas toujours normalisé, ni la source de matériaux standardisée. Dans les aciéries, la composition de l’acier, issu du recyclage, n’est pas nécessairement pré-déterminée : elle s’adapte aux matériaux fournis par la ferraillerie. La spécification précise les performances voulues selon l’utilisation prévue: la résistance à la traction, les contraintes internes, le point de fusion, mais pas forcément la composition de l’acier résultant.
Le geste ouvrier est essentiel à la réalisation, et ce bien plus que les machines, dans certains processus. Les joints des aérofreins des avions de ligne sont ainsi faits main pièce par pièce, notamment par des ouvrières issues de la bonneterie et de la corsetterie. Pour les formes de la jointerie des parties mobiles de l’aile, il faut savoir former un tricot avec la courbure en trois dimensions, donc c’est du travail du textile façonné main dans un moule, et ça dépend énormément du coup de main de l’ouvrier qui doit bien maîtriser son tissu. En Corée, on peut voir des ateliers spécialisés dans la maintenance des valves de l’aéronautique utiliser des tours non programmables, voire à pédale, pour réaliser le profilage des pièces. Certains ouvriers profilent les pièces à l’œil et à la main levée : tant que le résultat est conforme à la spécification, il est le résultat attendu.
Dans une usine, le tout-machine est rentable pour des produits très précisément standardisés et conçus en masse. Pour un avion, la configuration est presque unique et tu en produis tellement peu que ça ne vaut pas le coup de concevoir une machinerie automatique.
Dans ses collaborations avec des designers de meubles, Ikea joue pour incorporer le plus possible à son processus de production de masse le geste artisanal et son dessin, qui joue avec/s’accommode de légers ratés ou de décalages (une ligne non droite, par exemple). Certains objets sont produits en masse, mais à la main (ainsi, la collection de lampes de Piet Ein Eek, tissée main au Viêtnam, et une chaise en pin réalisée en Pologne, où le designer a demandé aux ouvriers de ne pas retirer les défauts et irrégularités des planches utilisées, contrairement à leur habitude.)
Ce qui m’a le plus frappée, c’est ma naïveté quant aux nourritures industrielles, souvent réalisées à la main à partir d’éléments à assembler. Il y a un coup de main à acquérir, mais il permet de produire des pâtisseries strictement identiques. Même si on ne voit pas l’humain dans la réalisation lisse et standardisée, c’est un geste individuel qui reste le créateur indispensable de la réalisation en série.
“Nobody complains about their job more than Starbucks baristas”
En septembre, avant même la saison du Pumpkin Spice Latte, les baristas chez Starbucks affichaient une grande lassitude. Depuis la pandémie, le nombre de commandes en ligne a explosé, déréglé le rythme de la ligne de production en créant deux canaux de commande et ouvert la possibilité de customisations quasi infinies sur une quinzaine de produits. Tiktok utilise l’aspect spectaculaire de cette inventivité toute personnelle en proposant des mélanges toujours plus extraordinaires, repoussant les limites de la créativité et de l’humainement absorbable. Or, cette demande intense et exigeante se heurte parfois au principe de réalité. La boisson commandée n’a pas de réalité concrète dans le magasin où elle doit être conçue. L’application permet de commander des produits en rupture de stock ou indisponibles dans le lieu choisi pour récupérer la commande. Elle ne tient pas compte de la disponibilité des baristas sur site.
Enfin, elle déroge au principe de la boisson testée, approuvée et standardisée par le corporate. Sur le principe, solliciter la créativité du barista pour jouer sur les goûts tient compte de la compétence développée en matière d’interactions dans les goûts. Dans la pratique, en créant des cadences infernales, des entorses au système et en ramenant à un rôle de pure exécution le barista, ce système créatif pousse de plus en plus de baristas à se réunir en syndicats pour défendre leurs conditions de travail et leur métier.
Starbucks a basé son modèle sur la possibilité d’adapter à soi sa boisson, à travers un système savamment dosé de variations : ajout de crème, de sucre, de cannelle en magasin, choix du type de lait, taille du gobelet… Norah Ephron en vante fameusement les mérites dans un formidable placement de produit au cours du film You’ve got Mail :
Le mérite d'endroits comme Starbucks est de permettre aux gens indécis de prendre six décisions d’un seul coup simplement pour acheter un café. Court, grand, décaf, léger, noir, avec crème, sans crème, etc. Les personnes qui ne savent comment se définir peuvent, pour seulement 2,95 dollars, s’offrir non seulement une tasse de café, mais, une définition absolue d’eux-mêmes : grande ! décaf ! capuccino!
La nouvelle demande de customisation va un cran plus loin. Il est désormais possible de prendre le temps de définir la quantité d’une dizaine d’ingrédients pour paramétrer une boisson parfaitement sur mesure (plus de 170 000 possibilités d’après le site Starbucks).
Les baristas sont pris en étau entre les demandes “corporate” qui fournissent les sirops, les crèmes et des formules précises de boissons, étudiées pour la rentabilité et la compatibilité des différents ingrédients. Or le travail de barista est un travail d’assemblage. Certaines boissons sont “layered” (chaque élément constitue une couche distincte) et d’autres “shaken” (le coup de main du barista compte pour mélanger correctement les différents éléments de la boisson).
170 000 combinations ?
I’m surprised it’s that low. Type of flavor syrup, combined with amount of pumps, combined with type of milk, combined with amount of milk item, combined with other additions, also, virtually endless amounts of things that you can stack on top each other, like different flavors of syrup types of shots, etc. Then on top of all of that, what kind of coffee you want? I’d say it’s easily in the millions of combinations, but I don’t have all the information to do the math otherwise I’d figure it out.
Chaque marge de négociation que réclame le client, chaque personnalisation qui risque d’entraîner un mélange répugnant entre deux crèmes ou sirops (compatibilité de substance, de goût ou de phase, le liquide pouvant redescendre vers le fond dans le temps où la commande attend sur le comptoir que son destinataire arrive au magasin) crée un décalage entre l’attendu et le fourni.
Le travail d’assemblage est remis en question à la fois par les options offertes par le corporate et l’usage qui en est fait par les clients. Le modèle évolue plus vite que les modalités enseignées (et dépasse même parfois les lois de la physique). Le plus amusant est que ces assemblages “secrets” visent souvent à reproduire le goût d’autres créations industrielles (ainsi le Gummy Bear ou le Sour Patch Kid).
Just politely ask: ‘Hey, could I please have a Grande Mango Dragonfruit Lemonade with no dragon fruit inclusions, and a splash of peach juice, with Iced Passion Tango Tea layered on top?’
- Suggestion pour TikTok Sunset
Le r/Starbucks, qui réunit clients et baristas dans des discussions parfois très pointues autour des boissons servies, permet de mesurer la complexité du travail demandé. Pourtant, les how to order de TikTok développent une notion nouvelle : commander chez Starbucks n’est plus seulement une définition personnelle de son moi authentique, c’est avant tout un spectacle, une occasion de repousser les limites du système (en omettant au passage le travailleur qui va réaliser ladite création.) Les mêmes tendances surréalistes de la commande par Internet avaient déjà été explorées par Steven Mollaro en 2007 avec sa pizza-troll, qui jouait avec le configurateur de Domino’s pour retirer tous les ingrédients et commander une pâte ornée seulement de boulettes de viande (sur la partie gauche). Les corporations de fast food sont là pour vous apporter ce que vous demandez, peut importe si c’est dégoûtant. Ainsi, la dernière mode chez Starbucks est au Puppuccino, un petit gobelet de crème fouettée offert par les baristas aux chiens dont les maîtres le demandent.
Merci beaucoup de m’avoir lue cette fois encore ! Écrire cette lettre me prend en moyenne 3 heures de rédaction, et autant d'heures de recherche, d’infusion et d’explorations. Si vous souhaitez soutenir ce travail, vous pouvez me payer un café via Kofi ! Promis, je n’irai pas persécuter de baristas avec.
N’hésitez pas à partager cette lettre si elle vous a plu et à y répondre si vous souhaitez m’en faire part !
Je suis en train de travailler sur plusieurs thèmes pour les prochaines lettres ; parmi ces derniers, le courrier du cœur, les animaux dans la maison, les chambres d’enfant qui deviennent des salles de sport, la tentative des années 70 de créer des ""salons de bain”, et bien d’autres choses encore.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.",0
134,"Are you familiar with a high-risk merchant or do you process payments? Yes, I am. ×
We are always looking for an opportunity to connect new payment methods for our users from different parts of the world.
If you are professionally involved in payment processing or have the information about high-risk merchant, contact us via zlibsupp@gmail.com with the subject line ""High-risk merchant"". We look forward to cooperate with you!
Please refrain from emailing if you are not familiar with this topic.
Thank you!",1
135,"The Moon Moth
This article needs additional citations for verification. (October 2022)
|The Moon Moth|
|by Jack Vance|
|Country||United States|
|Language||English|
|Genre(s)||Science fiction|
|Publisher||Galaxy|
|Media type||Print (Hardcover & Paperback)|
|Publication date||August 1961|
""The Moon Moth"" is a science fiction short story by American author Jack Vance, first published in Galaxy Science Fiction (August 1961).
Plot summary[edit]
Edwer Thissell, the new consul from Earth to the planet Sirene, has trouble adjusting to the local culture. The Sirenese cover their faces and heads with exquisitely crafted masks that indicate their social status (strakh) and mood. They also communicate by singing, accompanying themselves with one of a score of musical instruments, selected based on the social situation and feelings. Furthermore, errors of etiquette may prove fatal. Thissell is a clumsy musician and lacks confidence in the alien society, so he is forced to wear a lowly Moon Moth mask.
One day, he receives an alert to arrest a notorious assassin named Haxo Angmark, who is due on the next starship. Thissell, however, gets the message too late. He races to the spaceport, but Angmark, thoroughly comfortable with Sirenese customs, has already landed and disappeared. Thissell commits a number of serious social blunders in his haste to reach the spaceport and in enquiring after Angmark.
The next morning, Thissell is shown the body of an offworlder. He concludes that, since the fugitive would be unable to pass himself off as a native, Angmark must have killed and taken the place of one of the other three expatriates on the planet. But since even they wear masks, how is Thissell to know which one?
Eventually, Thissell solves the mystery by borrowing a slave from each of the suspects and determining their masters' mask preferences before and after Angmark's arrival. He succeeds in identifying his quarry, but is captured and forced to walk unmasked in public (the ultimate humiliation to the natives), while Angmark masquerades as Thissell by wearing his Moon Moth mask. However, the Sirenese turn on Angmark and kill him for the perversion of unmasking another man and, ironically, for Thissell's previous gaffes.
Thinking quickly, Thissell cleverly represents his humiliation as an act of unsurpassed bravery, asking if any present would be willing to be so shamed in order to destroy his enemy. With his new-found confidence, Thissell receives offers of gifts (the acceptance of which would enhance the prestige of both the giver and the recipient). He first goes with a mask maker to procure a covering more befitting his lofty new strakh.
Adaptations[edit]
First Second Books published a graphic novel edition by Jack Vance and illustrated by Humayoun Ibrahim in May 2012.
Translations[edit]
- La Luna Sfingo, translation into Esperanto under Creative Commons licence: EPub, Mobi, PDF and MP3
References[edit]
- Vance, Jack (1965). The World Between & Other Stories (1st ed.).
External links[edit]
- The Moon Moth title listing at the Internet Speculative Fiction Database
- The Moon Moth at the Internet Archive
- StarShipSofa serialized a narration by fiction writer and voice artist Josh Roseman in two parts on January 16 and 23, 2013",8
136,"Flowers have a longstanding tradition as a means of emotional expression. When we wish to convey our affection, joy or condolences, and words won't suffice, we rely on their beauty. Through the art of floriography, a coded means of communication more commonly referred to as the language of flowers, emotional intimacy has been allowed to flourish where it may otherwise be repressed. According to the Royal Horticultural Society, it's a practice that dominated Victorian culture in England and the US, and, despite being largely forgotten for decades, is steadily gaining popularity once more.
More like this:
- The vintage French style resonating now
- The hidden meanings in wearing black
- Eight nature books to change your life
One of the most prominent examples of recent floriography is King Charles's choice of funeral wreath for his mother, the late Queen. Bound by a tradition that is steeped in keeping emotions concealed, he expressed his sense of loss through his choice of blooms; myrtle for love and prosperity, paired with English oak to represent strength. To the uninformed, the wreath stood alone as a symbol of familial grief, its meaning derived from its presence not its substance. It was only by analysing the stems that the breadth of his emotions could be better understood.
Such poignant personalisation is part of a cultural foundation we all share. The tradition of floriography has always been there, but these days is a shadow of its former self – many know that a bouquet of roses symbolises romance, for example, but few know why. We might not perceive certain stems as positive or negative as the Victorians did, but we do still know that certain blooms better suit certain occasions. An understanding of flowers' meanings, however, can help us progress from the simplicity of sending a bouquet based on only its beauty to tapping into a deeper and more nuanced emotional intimacy.
""Flowers, as gifts or for special occasions, can be all the more thoughtful when using the language of flowers. This could be based on the colour, or the type of the flower, or both,"" explains Harriet Parry, a florist for Bloom & Wild. ""Floriography has been around for thousands of years, but we still have customers today asking for flowers that mean something special to them, either personally or through their symbolic meaning.""
How floriography influences our decisions has enabled florists, like Bloom & Wild, to make some fascinating observations. For one, they have recorded that 29% of people select their blooms based on bouquet colour, with red being the most popular choice. The colour of passion, red is universally recognised as an expression of love. Pink, however, has a myriad of meanings depending on where you live; in Thailand it's symbolic of trust, while in Japan it's believed to be a symbol of good health. In a single hue there's a variety of symbolism, yet this only begins to scratch the surface of floriography.
Take the sweet pea, a summertime flower that comes in an array of colours, but whose meaning remains the same: as a token of thanks. In the Victorian era, sweet peas were the go-to gift when thanking a host for a wonderful time, a gratitude that could be expressed even further by pairing it with other stems. If paired with zinnias, a flower that signifies everlasting friendship, your bouquet would help differentiate between casual acquaintance and dear friend.
But like everything in this world, for a good there is a bad, with some flowers used to represent negative feelings towards the recipient. You might think yellow carnations are beautiful, but they have a long history of being a symbol for disdain. Another flower also best to avoid is the buttercup, its yellow petals synonymous with childishness. And it was long considered inauspicious to place red and white plants together, with the belief that this combination foretold death still held by some.
The significance of all these codes and connections is explored in An Illustrated Guide to the Victorian Language of Flowers by floriography expert Jessica Roux. Symbols of all kinds have long been part of culture, she tells BBC Culture. ""Historically, we've been using symbolism since the beginning of our human history, working in meanings of stylised icons and hieroglyphics based on characteristics and ideas we see and experience every day.""
Floriography emerged as a clandestine method of communication at a time when etiquette discouraged open and flagrant displays of emotion
In her book, which has recently been adapted into a calendar, Roux explores the long, multifaceted development of floral language. ""Flower meanings were taken from literature, mythology, religion, mediaeval legend, and even the shapes of the blooms themselves. Often, florists would invent symbolism to accompany new additions to their inventory, and occasionally, flowers had different meanings depending on the location and time.""
Although our modern-day use of floriography comes from a different place, we're not too unlike our Victorian ancestors in our desire to only share certain aspects of ourselves. Most of us might not be trapped by repressive etiquette, but we are still bound by the perception of others. ""I wouldn't say we're living in a similar repressed world of etiquette today,"" says Roux. ""But I do think we present only certain sides of ourselves online."" During the Victorian era when ""stiff upper lip"" was the expected societal decorum, the language of flowers was a means of bypassing repressive etiquette. Roux explains: ""The Victorian language of flowers – also called floriography – emerged as a clandestine method of communication at a time when etiquette discouraged open and flagrant displays of emotion.""
Say it with flowers
Charlotte de la Tour's Le Langage des Fleurs, published in 1819, was the first book of its kind that detailed the immense symbolism of flowers. This book had such a profound impact on 19th-Century Western society that scholars cite it as a valuable artefact in understanding the traditions of the time.
Although the practice filtered through the social classes, it was primarily popular with women of the privileged classes – a demographic that, while in a position of financial privilege, was still regarded as inferior to its male counterpart. In a time when women were not encouraged to be outspoken, these floral accessories allowed them to communicate with their peers, offering a means for them to speak out without impeding their societal status.
""Young women of high society in this era embraced the practice, sending bouquets as tokens of love or warning, wearing flowers in their hair or tucked into their gowns, and celebrating all things floral."" Roux explains. ""Many of them created small arrangements of flowers, called tussie-mussies or nosegays, by combining a few blooms in a small bouquet. Worn or carried as accessories, these coded messages of affection, desire, or sorrow allowed Victorians to show their true feelings in an enigmatic and alluring display."" Tussie-mussies were also thought to help ward off disease.
At the beginning of the 20th Century, particularly once World War One started, the art of floriography was largely lost. In a society fractured by war, austerity became the language everyone spoke, leaving in its wake the obsession with aesthetically elegant flowers.
I've heard Victorians' usage of floriography compared to how we use emojis today to communicate in messages – Jessica Roux
Nonetheless, the memories of those floral customs, so deeply woven into Victorian culture, still resonated; floriography still permeated literature, ensuring the tradition was always in the periphery. Most notably, floriography plays a key role in Edith Wharton's 1920 novel The Age of Innocence, set in the Gilded Age of New York.
Centred around an upper class couple's imminent marriage, Wharton's story explores the intricacies of societal mores in 1870s New York, a salacious landscape of gossip. Wharton was able to tap into the complexities of high society through an understanding of the era's traditions. Consequently, the use of flowers plays an important role in the narrative, with the character of May always sporting white blooms.
While lily-of-the-valley blooms are used to reference May's innocence in worldly matters, in stark contrast, there's the character of Ellen, May's cousin, who is associated with yellow throughout the novel. Archer, May's betrothed, sends Ellen yellow blooms because he believes them fitting of her confidence and worldly experience. In Archer's eyes, Ellen is an exotic, knowing woman, with the brightness of yellow capturing that belief. The continued juxtaposition between white and yellow cements the notable differences between the two women, an important thread that would be lost without the language of flowers.
Later, in the 1980s, Margaret Atwood drew on the symbolism of flowers in her 1985 dystopian classic The Handmaid's Tale – red tulips were symbolic of the handmaids' fertility as well as their confinement, for example. And even today, fiction still uses floriography as an important narrative tool. Barbara Copperthwaite's Flowers For The Dead may be a thriller, but at its heart is the language of flowers, with the killer courting his victims through their varied meanings. Although clearly more chilling than Wharton's The Age of Innocence, Copperthwaite's story shows how these coded messages still resonate – they have a timelessly irresistible allure.
By welcoming the tradition of floriography back into wider culture, we can explore the depth of our emotions in unique ways. It becomes a postmodern means of communication, able to grow as we do, its symbolism steeped in tradition but open to change. ""I've heard Victorians' usage of floriography compared to how we use emojis today to communicate in messages,"" says Roux. ""They can vary in meaning depending on who's using them, the context of how they're being used, and with what other emojis (or, for the Victorians, flowers) we combine them with.""
We can talk without typing a single word. Send a heart here, a fire icon there – emojis speak through their aesthetics, a secret language all their own. Flowers are no different. They're merely the emojis of the 19th Century, still filtering through after all this time.
If you would like to comment on this story or anything else you have seen on BBC Culture, head over to our Facebook page or message us on Twitter.
And if you liked this story, sign up for the weekly bbc.com features newsletter, called The Essential List. A handpicked selection of stories from BBC Future, Culture, Worklife and Travel, delivered to your inbox every Friday.",1
137,"Search 10M+ of AI art and promptsgenerated by DALL·E 2, Midjourney, Stable Diffusion
Discovery
Challenges
Community
DALL·E 2
Stable Diffusion
Midjourney",3
138,"When you think of a factory, you might imagine a giant facility with huge chimneys belching steam. But consumer goods giant Unilever has developed a fully functioning production line inside a shipping container.
The company has over 300 factories in 69 countries, but this is its first experiment with what it calls a “nano” or “travel” factory.
Mass production lines allow manufacturers to make large quantities of products but using the same facilities to produce smaller batches of goods – to test new ideas or to meet seasonal demand – can be wasteful and inefficient.
Because of its size, the 40-foot container can be transported by cargo ship or truck to any location, says Unilever. It just needs a source of water and access to electricity to begin production.
The nano factory is currently in the Netherlands, in the middle of its first trial producing liquid bouillon, a cooked stock packed in a bottle. Unilever says the factory is making around 300 tons of bouillon per eight-hour shift.
According to Marc Engel, Unilever’s chief supply chain officer, the whole manufacturing process happens inside the container, starting with processing the raw ingredients, and including packaging the finished product. As the equipment has been specifically developed for small spaces, he says there are some differences to a standard factory, such as using electricity for heat instead of steam.
Greater flexibility
Engel says the nano factory is fully digitized and has sensors that send live production data to a central control room. While some processes are fully automated, he says three on-site operators are required per shift – two to activate the production and manage the line and one to manage packaging and take away the final product.
For Engel, one of the most important features of the nano factory is that it’s mobile. This allows for greater flexibility to tailor to demand in local markets and to source local ingredients, meaning resources and emissions aren’t wasted shipping ingredients and products from faraway, he says.
“Having the nano factory in a shipping container lets us get our production to where it needs to be,” Engel says. “Products can be rolled out faster and scale can be ramped up or down quickly to match consumer trends.”
Scaling up
The trial of the nano factory started in June, after delays due to Covid-19 restrictions, and will run for the next few weeks, according to Engel.
If the trial is successful, he says Unilever hopes to use the factory to make other products, as well as looking to create new nano factories.
“This small-scale production approach can definitely go beyond liquid bouillon and be used to produce mayonnaise, ice cream and even beauty or home care products,” he says. “We are also exploring plans to lease, rent or sell these units to young entrepreneurs.”
Richard Wilding, professor of supply chain strategy at Cranfield University, in England, says that if rolled out in greater numbers, these kinds of nano factories could help make manufacturing networks stronger and more specialized, but could also create problems further down the line.
“You are distributing your manufacturing base and that is going to be more resilient, particularly in a Covid world,” he says. “But one of the things you have to think about is once the items are actually produced, how do you manage the supply chain to the actual customers?”
Wilding adds that nano factories will require workers to have new skills, which may be challenging to find in some locations. However, he can see a future for these kinds of facilities responding to local needs.
“What we could start envisaging, if you’ve got a large retail outlet or retail complex, why not have a nano factory located at the complex? So it is producing precisely what the customer wants – more or less on demand,” he says.
Engel says a network of nano factories with local supply lines and a centralized controller could be part of Unilever’s future.
“The purpose of the nano factory is not to match the output of a big factory with large-scale facilities, but a network of these nano factories would give Unilever greater innovation flexibility,” he says. “The future could potentially see a new, dynamic model with local, distributed production lines all over the world, run from a central mothership.”",2
139,"BornHack is a 7 day outdoor tent camp where hackers, makers and people with an interest in technology or security come together to celebrate technology, socialise, learn and have fun.
BornHack 2022 will be the seventh BornHack. It will take place from Wednesday the 3rd of August to Wednesday the 10th of August 2022 at our venue on the Danish island of Funen.
The BornHack team looks forward to organising another great event for the hacker community. We still need volunteers, so please let us know if you want to help!
We want to encourage hackers, makers, politicians, activists, developers, artists, sysadmins, engineers with something to say to read our call for participation.
BornHack aims to keep ticket prices affordable for everyone and to that end we need sponsors. Please see our call for sponsors if you want to sponsor us, or if you work for a company you think might be able to help.
You are very welcome to ask questions and show your interest on our different channels:
- IRC: #bornhack @ 6nbtgccn5nbcodn3.onion or irc.baconsvin.org (TLS port 6697)
- Email: info@bornhack.dk
- Twitter: @BornHax
- Facebook: @BornHax
- Instagram: @BornHax
- Flickr: @BornHax",4
140,"La musique du corps
Et si on pouvait s'exprimer autrement ?
En 2022, on inventa des bracelets connectés qui permettaient de créer facilement de la musique en faisant des mouvements. Cette nouvelle interface connut un grand succès commercial et les plates-formes musicales croulèrent sous les nouvelles compositions venues du monde entier.
Les simples quidams ne furent cependant pas les seuls utilisateurs : les artistes se saisirent aussi de l’innovation. De ce fait, la scène hip-hop subit une transformation radicale, avec le développement d’une nouvelle branche hybridant les mouvements très athlétiques du hip-hop au sol et ceux, debout et tout en maitrise, du tai-shi. La musique qui en résulta posait des nappes instrumentales et des mélodies lentes sur des rythmiques énergiques et récurrentes, dans un style assimilable à une compression du Sacre du printemps.
Les artistes contemporains ne furent pas en reste et livrèrent leur lot de créations décalées. Une ondiste fribourgeoise eut ainsi l’idée de faire travailler la nature : elle se rendit à la source du Danube et y lança une petite bouée contenant les capteurs du bracelet, de façon à ce que les mouvements de l’eau génèrent la musique du fleuve. Le voyage dura plusieurs mois, durant lesquels l’artiste suivit la bouée en monopalme jusqu’à la Mer noire, tandis que le flux musical était diffusé en continu sur les réseaux. Un mythe tomba, certains mêmes crièrent à l’imposture, quand on s’aperçut que le résultat n’avait rien à voir avec Le beau Danube bleu.
Exploitant le filon, l’entreprise à l’origine du dispositif l’adapta aux autres sens et on assista à une efflorescence de danseurs-peintres, danseurs-créateurs de parfums et même de danseurs-architectes, avec un succès variable. Mais c’est une utilisatrice du dispositif initial qui finalement fit le plus de bruit : lors d’un festival de danse contemporaine à Marseille, sur une scène posée sur l’eau du Vieux Port, une longue improvisation dansée donna lieu à une quasi-émeute de dauphins.
Un technicien-son de l’équipe put établir que la musique créée par les mouvements de la danseuse se transmettait jusqu’à l’eau par l’infrastructure de la scène, avant d’arriver transformée jusqu’aux dauphins. Cet incident constitua une percée spectaculaire dans le domaine de la communication inter-espèces. En effet, le principe étant affiné et adapté, on put envisager d’aborder toutes sortes d’animaux, allant des araignées jusqu’aux poulpes, au moyen d’interfaces adaptées.
En parallèle, le dispositif sortait du domaine strictement artistique. Un menuisier curieux fit une première expérimentation, dont le résultat musical assez convaincant fit des émules un peu partout. Toutes sortes de professions manuelles, pâtissiers, élagueurs, chirurgiens, se saisirent du dispositif, revivifiant la notion d’intelligence de la main, quelque peu tombée en désuétude. Une brodeuse d’une grande maison de couture fut à l’origine du titre Point de croix au coin du feu, un genre de ritournelle rétro-électro, qui devint en quelques semaines la référence des temps calmes dans les écoles maternelles.
Puis l’onde prit de l’ampleur. Certains jeunes sourds se saisirent du dispositif pour faciliter la communication avec leurs parents entendants, avec de bons résultats. Le système fut ensuite adapté et élargi à tous ceux à qui le langage posait des difficultés, atteints de troubles dys-, autistiques ou de bégaiement, ou simplement ceux qui se sentaient plus à l’aise dans le mouvement, et leur fournit un canal supplémentaire d’expression. Les jeunes parents furent avertis des mouvements que leurs nourrissons faisaient avant de se mettre à hurler, échappant ainsi à nombre de réveils traumatiques.
Arrivé à ce stade, le dispositif fonctionnait avec les lunettes de réalité augmentée, qui affichaient la transcription des mouvements en couleurs. On recevait ainsi un message constitué à la fois de mots, de mouvements, de couleurs et de musique. Chacun se mit à ajuster son système comme il l’entendait, en réglant la balance de ces modes d’expression. Avec le temps, cette hybridation s’installa dans toute la population et la notion de communication non-verbale prit tout son sens.
Ancrage dans le monde actuel :
A l’origine de ce texte, cet article : « Nouveaux accessoires musicaux : plus besoin de cours (ni d’instrument) » (en anglais)
Qu’est-ce que c’est qu’une ondiste ? Echantillon
Le light painting consiste à photographier avec des temps de pose longs les mouvements d’un objet lumineux, de façon à créer un motif.
Sur le dialogue inter-espèces, je remets ici la référence de Vinciane Despretz « Autobiographie d’un poulpe ».
L’article Wikipédia sur la communication non-verbale
Photo de Ahmad Odeh sur Unsplash
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.",0
141,"The rise of community-curated knowledge networks
The Internet put thousands of years of human thought at our fingertips, and enabled billions of people to create content. At least 2.5 quintillion bytes of information are produced every day, which is approximately what was produced during all of 2002. While this presents enormous opportunities, our brains are not equipped to deal with this abundance.
In Curators are the new Creators, Gaby argues that this will create opportunities for curators — increasingly, we will pay people with good taste to help us sort through the ever-growing mass of…",1
142,"On October 7, 2022 Toyota, the Japanese-based automotive manufacturer, revealed they had accidentally exposed a credential allowing access to customer data in a public GitHub repo for nearly 5 years. The code was made public from December 2017 through September 2022. While Toyota says they have invalidated the key, any exposure this long could mean multiple malicious actors had already acquired access.
This incident adds Toyota to the list of companies that have had similar exposures; a list that includes Samsung, Nvidia, and Twitch, just to name a few. While this breach at Toyota is currently understood as fairly limited, compared to the 6,695 secrets exposed in the Samsung case, the growing number of companies experiencing such issues is still a very disturbing trend.
Data exposures on public Git repositories are a particularly troubling topic. Code intended for tightly controlled private repos are very often pushed to public repos owned by employees or contractors, outside the security control of their GitHub organizations.
What Happened
T-Connect
In 2014, Toyota introduced a new telematics service called T-Connect to customers, offering interactive voice response and allowing drivers to connect to third-party apps. Toyota advertises it as their “connected services that provide safe, secure, comfortable, and convenient services through vehicle communication.”
T-Connect enables features like remote starting, in-car Wi-Fi, digital key access, full control over dashboard-provided metrics, as well as a direct line to the My Toyota service app. The servers that control these options contain unique customer identification numbers and customer emails.
A Subcontractor And A Public Repo
In December 2017, while working with an unnamed (so far) subcontractor, a portion of the source code for T-Connect was uploaded to a public GitHub repository. Inside the repo there was a hardcoded access key for the data server that manages customer info. Anyone who found that credential could access the server, gaining access for 296,019 customers.
It was not until September 15, 2022, that anyone noticed this repo was public and that customer data was potentially exposed. Toyota has since made the repo private and has invalidated and replaced any affected connection credentials.
How Bad Is this Security Breach?
While customer identification numbers and emails have potentially been exposed, customer names, credit card data, and phone numbers were not stored in the exposed database, and are therefore not at risk. Toyota has begun outreach to affected customers. As part of this outreach, the company has set up a special form on its site to let customers check to see if their data was part of the exposure.
As of now, there is no sign that this breach would allow bad actors to do more than just harvest emails and the associated customer management numbers. Toyota has not been able to confirm any abuse or attacks have occurred using harvested data.
How can people protect themselves
Toyota does warn customers that although there has not been any unauthorized use of their personal information detected, all affected users should be on the lookout for spam emails and phishing attacks.
The notice from Toyota states: “If you receive a suspicious e-mail with an unknown sender or subject, there is a risk of virus infection or unauthorized access, so please do not open the file attached to the e-mail and delete the e-mail itself immediately.”
This incident serves as a good reminder that with all emails it is important to only follow links in emails from trusted sources. When in doubt about the validity of an email, you should inspect the header to make sure the email domain is legitimate and use the hover preview for any link to ensure the URL is not redirecting you to a potentially dangerous site.
Attackers can use context along with stolen emails to create more convincing phishing campaigns. For example, knowing they are a Toyota customer can make them appear more trustworthy.
How can devs prevent this from happening again?
There are two security missteps at the heart of this latest incident at Toyota:
- Code intended to be private was pushed to a public repository.
- A credential for a DB server holding customer data was hardcoded into the repo.
Git is an awesome version control system, used by over 93% of developers, and is at the heart of modern CI/CD pipelines. One of the benefits of Git is that everyone has a complete copy of the project they are working on. That full copy access also means each developer can, in turn, push their copy to unauthorized places, such as public repositories. While it might not be possible to prevent a contractor from pushing code wherever they want, it is possible to detect when code or IP has been pushed somewhere it should not be. This is a serious issue affecting the software industry that we have previously reported on.
GitGuardian has made available a free tool, HasMyCodeLeaked, to help companies identify potential source code leaks. Our free tool can perform an exact lookup of code ""fingerprints"" in GitHub's public history, helping you quickly identify repositories that contain private code or data.
Hardcoding secrets is a serious issue affecting the software industry today. In 2021, we discovered over 6 Million secrets in public GitHub repos alone. As security in DevOps ‘shifts left’ on the shoulders of developers pressed for time, it is critical that they leverage tools and services that prevent secrets from ending up as parts of their repos. A company’s secrets that get hardcoded can be exposed in a number of ways, including pushed to public repos, but also if the code is leaked by a disgruntled employee or stolen by a malicious actor. This is a real blind spot for companies that do not have secrets detection in place.
Before you go
Want to learn more about the problem of hardcoded credentials? Read our State of Secrets Sprawl 2022 report or contact us for a free assessment of your secrets exposure.
If you are interested in other 2022 data breaches and attacks, you can find a detailed analysis of the Uber breach and of the Dropbox data breach.",5
143,"We’re experiencing a content overload. There are an average of 550 new social media users each minute, and over 40,000 search queries on Google every second. The Facebook like button has been pressed 13 trillion times, and each new day welcomes another 682 million tweets. It seems that every time we blink there’s a new podcast published, or blog post to read, or book recommendation to order on Amazon. To make a long story short, it’s becoming increasingly difficult to disaggregate signal from noise.
Andrew Chen, General Partner at Andreessen Horowitz, wrote last year:
“We’re living in a pivotal time in the history of mass communication — what we believe is the golden age of new media.”
With more creators, more content, and more choice than ever before, consumers are now being consumed by a state of analysis paralysis. The real scarcity isn’t content anymore. It’s attention. When it’s impossible to absorb everything from the flood of information, the best we can do is pick and choose what matters to us most — or, better yet, find the people who can do the curating for us. Mario Gabriele from The Generalist said it best:
“We’re all consuming more media, and there’s an increasing willingness to pay for high-quality content. The last year has also seen an explosion of great writers and analysts in the space — I believe we’re at the start of a creator breakout.”
As the amount of content grows, so does the market for credible curators.
A great case study is Nathan Baschez and Dan Shipper’s Everything Bundle. In April, they decided to offer a bundled version of their newsletters, expecting a few extra subscribers from the experiment. Instead, they grew together from 600 to 1,000 paying subscribers within the first month. With all this talk of unbundling (some examples are the unbundlings of college, G Suite, Reddit, and venture capital), Nathan and Dan’s intentional bundling proved to be a striking success.
The Everything Bundle case study is one of my favorites, but it’s not the only one, by any means. Channels Stack is a curated site for educational content on YouTube, organizing hundreds of channels into defined categories. The Browser is a daily newsletter from someone who reads 1,000 articles a day, choosing his five favorites and sending them out with a short summary. Oftentimes, these linked articles don’t have a paywall of their own at all — but subscribers of The Browser pay to have them sent in a curated list.
The demand is certainly there: Channels Stack launched on Product Hunt with a 5.0/5 average rating and nearly 400 upvotes, and The Browser has successfully figured out how to monetize free existing content (with over 40,000 followers on Twitter to boot).
We can go even further back — classic examples of successful curation businesses are record shops and bookstores, and examples in tech include Spotify (for music), Netflix (for TV and movies), and Uber (which bundled its UberEats offering into one app, thus increasing Uber’s TAM, or total addressable market).
In my view, however, the business of influencer bundling has only just begun. Curators are the new creators, and as consumers, we’re going to be willing to pay someone with good taste to help us sort through the ever-growing mass of information at our fingertips.
The Psychology Behind the Need for Curation
As it turns out, there’s some psychological ground to all of this. Think of it as a carefully mixed cocktail of the following:
- Zuckerberg’s Law, or the tendency to share more and more on social media over time
- Dunbar’s number, or the average number of stable social relationships one can maintain at a given time (it’s around 150)
- Zipf’s Law, which describes how in any system of resources there are a small number of items of high value, and a “long tail” of many more of low value (slightly tangential but related reading: Metcalfe’s Law, which has now largely been refuted as a method of evaluating social networks, but in 2012 helped to rationalize Facebook’s insane over-valuation in its IPO)
To me, online content consumption seems to exist on a pendulum of sorts: we love content to the extreme — Unbundle!! Give us more! — until we are overwhelmed with choice and analysis — It’s too much!! Bundle it back up again! — and swing to the opposite side. In the end, we always end up somewhere in the middle… but it’s a lot of swinging back and forth on this creation/curation pendulum until we get there.
“There are only two ways to make money in business: One is to bundle; the other is to unbundle.” — Jim Barksdale
Having said this, and looking at the current information overload we all face on a day-to-day basis, I think there’s room for a new market of creators as curators. So, with that said, what does this look like for an influencer or brand?
How Do You Curate — and Why?
There isn’t one sole motivation behind why creators, influencers, and brands may want to curate. In fact, curation can:
- Build a personal brand or audience.
- Fulfill a need in a particular market. For example, Femstreet is a weekly digest of timely posts from female investors and operators. It’s racked up thousands of subscribers and has been featured in Fortune, Forbes, and Crunchbase.
- Create an extra category within an existing business.
- Become an additional revenue source. As we saw with The Browser example, it’s possible to monetize free content if it’s curated well — consumers are willing to pay someone who has good taste, and it’s an easy way to add a revenue stream to your business.
To learn more, I asked my own audience about their favorite curated content:
Below is a categorized list of some of the responses I received. My favorites are in bold:
Newsletters: Morning Brew, Everything Bundle, LetterDrop, Femstreet, Brain Pickings, The Generalist, The Browser, Snaxshot, The Profile, The Takeoff, Social Studies, Techmeme
Podcasts: Podcast Notes, TLDL, Shuffle, Podshots, Podcast Review
Crowdsourced Curation: Pocket, Bookshlf, Listory, MyHighlights
[Note: there are even more responses in the Twitter thread above, in case you’re curious and want to check out more!]
Making Curation Profitable
The best brands (and individual influencers, at that) are the best at an always-evolving curation as a service. Nathan and Dan’s Everything Bundle seems to be a playbook in itself, as outlined by Ari Lewis in this thread:
- Find initial traction
- Shift the emphasis from the individual to the greater media brand
- Scale and continue to add value
One way to monetize curation is through a paid newsletter, with the Everything Bundle as a great example. Other opportunities include blogs, ebooks, e-commerce stores, and consultations/speaking gigs. I even came across ReadBase during my research, which allows curators to monetize their bookmarks and reading lists. In any case, curators can find success by building up a targeted online presence and then providing curated content to that audience.
It’s clear that curating content within a particular niche can be an incredible way to build an audience and add value. Content curation hooks people in with the promise of learning new skills while saving time, and it keeps them coming back by building a sense of community around a particular subject or vertical. As outlined in this Harvard Business Review interview with Marc Andreessen and Jim Barksdale, bundling and curation can be a strategic decision for your business, as long as it’s done correctly.
Curation, in a sense, is its own form of intertextuality, or the shaping of a text’s meaning by another text. Content doesn’t exist on the Internet in a vacuum: it takes up space, and it forms a web of influence and connections. We have the content. Now, the question becomes: what will we do with it?",1
144,nytimes.comPlease enable JS and disable any ad blocker,9
146,"Access denied Error code 1020
You cannot access www.barilla.com. Refresh the page or contact the site owner to request access.
You cannot access www.barilla.com. Refresh the page or contact the site owner to request access.
Copy and paste the Ray ID when you contact the site owner.
Ray ID: 75b09b51e884d686
For help visit Troubleshooting guide",5
148,"Their drinking habits have seen them derided as ‘generation sensible’, but this overlooks the complex and nuanced reasons people are turning their back on alcohol.
Their drinking habits have seen them derided as ‘generation sensible’, but this overlooks the complex and nuanced reasons people are turning their back on alcohol, writes Eve Upton-Clark.
In 2022, the idea that young people are going sober is nothing new. While this trend has been bubbling away for a while now, over the past year, it seems to have accelerated: in fact, almost 150,000 university students have stopped drinking since last September alone, according to new research by Student Beans. This means a third of university students in the UK identify as sober, joining the ranks of 800,000 teetotal young Brits. Undoubtedly, sobriety is having a moment, rising by 22 per cent from Freshers 2021.
It’s a trend which has often been viewed with wariness and judgment. Some have put it down to productivity culture, while a recent opinion piece in the Guardian chastised “generation sensible” for trying to “self-maximise all the time”. The article goes on, “all the joy in life, all the beauty, is going to come from sex, fellowship, revolution and the life of the mind. You know where all those things start? They start in a pub.” Questionable, if not slightly patronising, advice.
Numerous reports have put this shift in drinking habits down to self-consciousness. Thanks to social media surveillance, the chances of your sloppy antics being captured on camera and potentially going viral is now at an all-time high. While there might be some truth to this, this explanation paints a picture of a generation overly concerned with their self-image. And, it tends to flatten the complex and often nuanced reasons young people are putting down their drinks.
For Leilani, a 20-year-old psychology student who is also president of Queen Mary’s Sober Society, gender played a part in her decision to cut back almost entirely on booze. She points to how the media has often demonised drunk women over the years. “It’s terrifying to be a woman and you get a harsher punishment for poor decisions,” Leilani explains. “Think on a small scale: if you cheat then it’s usually presented as the woman’s fault. Then on a more dangerous scale, there’s the case of predatory men.” It’s a sad truth that staying sober is a safety precaution many women have to factor in.
While Leilani exercises booze with caution, limiting herself to a glass or two of wine at dinner, others avoid it entirely. Irina, a 22-year-old music student from London, drank throughout the first few years of university. She was going through a dark time in her life, and looking back, she feels she drank as a way to cope. “I wasn’t really dealing with the problem,” she says, “I was just kind of postponing it.”
Irina has been sober since January. “One thing that has kept me sober is finding faith,” she explains. “I wouldn’t say I’m religious, I’m more spiritual. As I started developing my spiritual side, when I would drink, I would feel really negative and clouded. I saw that as a sign to just stop drinking altogether. I feel a lot more connected with spirituality when I’m sober.”
Unsurprisingly, alcohol and mental health are an unhealthy mix. Recently, there have been widespread warnings of a mental health crisis among students, with nearly half of students saying mental health difficulties had a negative impact on their university experience. “Literally the only reasons I was drinking was because I was feeling sad, and because other people were doing it – which aren’t really good reasons,” Irina explains. “When I’m sad I now turn to journaling or writing music or anything that’s not drinking basically.”
Andrew Misell, from the charity Alcohol Change UK, says that in general, people are more aware of the consequences of drinking. “It’s also possible that there is a kind of rebellion here, and that young people are looking at their parents’ habits and thinking, ‘I don’t want to actually live like that’,” Misell says. Another factor Misell points to is the changing population in the UK. “The population of the UK is more diverse than it was, say 50 years ago. More of us are part of or familiar with cultures in which alcohol doesn’t play a part.”
AJ, a second-year International Relations student and the current President of the Lancaster University Sober Society, echoes Misell’s point, noting religion as a factor for not drinking for a handful of people in the society she runs. However, AJ made the decision to go sober for similar reasons to Irina. “I think mental health is a big thing in our current generation. There’s a lot of pressure on us with how the world is. I guess it can go either way, as people can turn to alcohol as stress relief. Then, on the other hand, there are people turning away from it, as it doesn’t really contribute to self-improvement.” Having struggled with her mental health growing up, AJ had promised herself she would only drink when she wasn’t already feeling anxious or negative before making the decision to go tee-total earlier this year.
Less repressed than previous generations, young people like AJ are turning to more mindful methods to cope. “People tend to turn to drink as a way to forget,” she says. “But then when you sober up it just comes back. It starts a cycle. For me personally, I want to deal with my issues head-on. I try to self-reflect, think why am I feeling like this, and find resources to help.”
Despite the sober movement sweeping the UK, alcohol remains part of the fabric of many people’s social lives, from mimosas at brunch to post-work beers to boozy dinner parties. However, more and more, in-person groups and online communities are offering alcohol-free alternatives to going out on the piss. “You can go on a walk, or bowling, or mini golf,” suggests AJ. “There’s plenty of things to do sober if you just look.” In fact, seven out of 10 say they felt they did not need to drink as much because they have a better choice of hobbies than their parents’ generation.
And to state the obvious, students are skint. A student cost of living survey conducted by the National Union of Students (NUS) in June found a third had less than £50 a month left after paying rent and bills and one in 10 reported using food banks. University is the traditional training ground for drinking to excess but with a cost-of-living crisis, buying a round may have you living off beans on toast for the rest of the week.
When Leuan, a 22-year-old Masters student at Queen Mary’s University, moved to London from Gibraltar, the alcohol prices in the city came as a shock. “In Gibraltar, I could get two litres of vodka for £4,” he says. “London alone is very expensive, and then drinking on top was getting very pricey. I could spend up to £90 on one-night of drinking. It was something I could easily cut off and save a lot of money.”
Tom, 30, also noticed his drinking habits impacting him financially. “I often would sacrifice things that I perhaps need or things that would be more beneficial to me,” he explains. “I would rather buy the cheapest washing detergent or skip dinner out to go drinking instead.” While he isn’t teetotal, Tom has consciously cut down on drinking, opting for cheaper options along the way. “I also try and do stuff that doesn’t involve alcohol, “ he explains. “If I’m having dinner out I’ll try to stick to one drink only or just go for tap water.”
The reasons why young people are turning away from alcohol are multifaceted. Sober societies at universities and alcohol-free events offer spaces free from the pressure to drink, or simply a break, rather than a replacement, from other alcohol-fuelled events. “I would always say don’t let other people tell you how to drink,” says Misell. “I think it’s great to take information and advice from people, but if you decide within yourself that you would like to significantly reduce or stop drinking because alcohol isn’t really working for you in a good way, it’s a positive choice and can be quite empowering.”
Rather than virtue-signaling, the decline in drinking among young adults is driven by the unique conditions of their lives – particularly economic and health factors. Becoming more intentional about one’s relationship with alcohol can only ever be a good thing. “It’s a myth really that you are boring if you’re not drinking,” Misell says. “As anyone who’s ever been sober with a drunk friend will know that when people are drunk, that can be extremely boring too.”
Follow Eve Upton-Clark on Twitter.
Enjoyed this article? Like Huck on Facebook or follow us on Twitter.",4
149,"The Open Source Imaging Initiative (OSI²) represents a new approach to the development of medical imaging devices, aiming to make the health-care benefits of modern instruments accessible to many more people around the globe. The project will pool the knowledge and experience of many experts in open-source designs for Magnetic Resonance Imaging devices (MRI) which can be built and maintained for a fraction of the price of current instruments.
photo: Katharina Bohm / MDC
Medical imaging is crucial to both the diagnosis and treatment of most diseases and progress in understanding their causes. MRI is currently the most powerful diagnostic imaging tool in medicine because it provides a detailed view of internal tissues without invasive procedures or damage to the body.
photo: Katharina Bohm / MDC
Globally, MRI is a scarce commodity – its cost and complexity restrict its availability mostly to industrialized countries and larger hospitals. We aim to develop an MR scanner that is affordable to build, operate, maintain and repair by providing full, freely available technical documentation that follows the standards of open-source hardware. In combination, innovation and the open-source philosophy have the potential to dramatically lower costs and take health care “From the community, to the community.”
Benefits
Affordability
State-of-the-art clinical MRI devices are costly, to which expensive operation and technical support must be added. We believe it is possible to reduce these costs drastically making high end medical devices accessible to many more people around the globe.
Innovation
An open collaborative approach will spark innovation allowing for customized MR developments meeting local needs. The devices will be simpler whenever possible, providing streamlined procedures for imaging that are ready to use and adopted to a clinical need.
Community value
By uniting the efforts of collaborators from around the world in an open-source approach, we will create a unique pool of knowledge that will help advance the field. Our efforts may provide a model for other communities interested in giving greater global access to medical technologies by decreasing costs of development and maintenance.
Quality
All medical devices must meet the same high quality standards, regardless of their price. We encourage design considerations during all phases of development that allow an easy transition of an open source prototype to meet local regulatory requirements as a medical device.
Knowledge Transfer
Open source development shares and grants access to knowledge which is mandatory to understand, study and repair complex MR devices. This freedom of information improves documentation and education to train makers and users in regions of resource scarcity.
Business
Outsourcing development to the community reduces development costs and allows for fast time to market operation. We want to promote businesses around and the distribution of open source based medical devices.
Projects
Overview
Here you can find an overview of open source hard- and software projects, current progress, contact persons and links to the development and documentation websites. We just started, more projects will be uploaded very soon.
Do you work on an open source project with potential application for MRI or other related medical research and technology? We will also highlight early stage projects (prior to a stable release and documentation) in order to improve collaboration at that early stage.",2
150,"Focus
Petite ceinture : 4 km de tronçons bientôt ouverts au public
Mise à jour le 16/05/2022
Sommaire
Revenir en haut
La petite ceinture poursuit ses réaménagements, avec 4 kilomètres de sentiers bientôt ouverts à la promenade. Tous sont pensés pour préserver une faune et une flore qui y ont repris leurs droits.
D'ici fin 2026, 4 kilomètres supplémentaires seront ouverts sur la petite ceinture. Cela représente 7,6 hectares en plus, favorables à la nature et la biodiversité.
Un parc de 3,5 hectares et une forêt urbaine au cœur du 20e dès 2024
Sur le tronçon de petite ceinture, situé entre le 56 rue du Volga et le 103 Cours de Vincennes, le projet de ""forêt urbaine de Charonne"" et de sentier ferroviaire avance. L'opération représente un potentiel de 3,5 hectares d’espace vert et la plantation de plus de 1000 arbres. Ce projet est lauréat de l’Appel à Projet Nature 2050 porté conjointement avec la CDC Biodiversité et la Métropole du Grand Paris.
La foret urbaine de Charonne permettra la connexion des zones arborées existantes de la gare d’Avron, du jardin de la Gare de Charonne et des résidences alentours.
Ce projet est possible grâce au rachat par la Ville de Paris de la surlargueur, propriété de la SNCF, qui suit les rails et offre une opportunité rare de créer un parc arboré grâce à la désimperméabilisation et la renaturation de l’ancien dépôt de bus RATP
• Sept 2023 : Préparation de chantier
• Oct 2023 / mars 2024 : travaux génie civil
• Mars/ avril 2024 : plantations
• Livraison : printemps 2024
Seront aussi bientôt ouverts
-
Promenade Bercy-Charenton (12e) 10 000 m². En travaux de fin 2023 à début 2025
-
Escalier Daumesnil (12e) 100 m². À venir au printemps 2024
-
Promenade Brassens (15e) : une première phase inclura un tronçon jusqu’à la rue Brançion (11 400 m²) et le tunnel (2750 m²). En travaux en 2025 et 2026.
-
Promenade Pereire (17e) : un parcours sportif supplémentaire sera créé sur la promenade ouverte depuis 2019. À venir en janvier 2023.
-
Promenade Ney (18e) : 24 710 m². deux premiers tronçons ouvriront en avril 2023 et un tronçon où s'installera un lauréat des Parisculteurs à l'été 2023.
-
Promenade Thionville (19e) : 7280 m². En travaux en 2025 et 2026.
-
Promenade Charonne (20e) : 20,470 m² de parc arboré sont prévus. En travaux en 2023 et 2024.
En attendant il est déjà possible de profiter des tronçons déjà ouverts.
Suivez-nous, On vous fait découvrir une promenade qui démarre à l’est de Paris dans le 12e, et fait le tour par le sud.
Un site à respecter
Depuis 2006 où la Ville de Paris et la SNCF se sont engagées à réhabiliter progressivement la petite ceinture et à ouvrir ses espaces à la promenade, son tracé est devenu un corridor écologique, sur lequel une végétation sauvage et des espèces animales ont pu se développer.
C'est aujourd'hui un véritable écrin pour la biodiversité. Sentiers nature, promenades plantées, infrastructures sportives, lieux culturels et même jardins partagés y ont vu le jour. Le tout animé par des associations, des habitants, voire des écoles des quartiers.
Les promeneurs sont invités à fouler ce territoire fragile, avec le plus grand respect et la plus grande attention.
À noter : les chiens y sont interdits, même tenus en laisse (contrevenants verbalisés).
C'est aujourd'hui un véritable écrin pour la biodiversité. Sentiers nature, promenades plantées, infrastructures sportives, lieux culturels et même jardins partagés y ont vu le jour. Le tout animé par des associations, des habitants, voire des écoles des quartiers.
Les promeneurs sont invités à fouler ce territoire fragile, avec le plus grand respect et la plus grande attention.
À noter : les chiens y sont interdits, même tenus en laisse (contrevenants verbalisés).
12e : de la rue de Charenton à l'avenue de Saint-Mandé (1,67 km)
C'est le plus long tronçon ouvert à la promenade. Il s’inscrit dans un ensemble de promenades vertes, le square Charles Peguy, la Promenade plantée, et crée un nouveau lien avec le bois de Vincennes.
Ce secteur a été aménagé de manière à accueillir un jardin partagé et un sentier nature long de 200 mètres. Il aborde la diversité biologique à travers trois stations : prairie, taillis (ou boisement en formation) et boisement. Grâce à sa signalétique, le parcours propose de découvrir les plantes et les animaux caractéristiques de ces types de milieux. Le jardin partagé est, lui, constitué de deux parcelles mises à la disposition de l’association Graine de partage qui y développe notamment des actions pédagogiques avec les écoles. Des mobiliers (plateforme, banquette, table…) ont été réalisés lors d’ateliers de co-construction.
Le plus biodiversité : environ 170 espèces floristiques (dont 117 régionales) et 70 espèces animales ont été observées sur ce tronçon.
13e : entre la place de Rungis et la rue du Moulin-de-la-Pointe (0,5 km)
Cet aménagement facilite l’accès au tramway T3. Un espace de détente, avec une pelouse, a été réalisé. La faune et la flore typiques des friches industrielles ont été préservées, ce qui renforce le couloir écologique. Une prairie sèche et des massifs arbustifs ont été créés. Des inventaires floristiques et faunistiques ont par ailleurs été réalisés en amont et ont largement influencé le projet. Le mélange de graines pour l’habitat de prairie sèche a ainsi été créé selon la composition floristique du milieu présent avant les travaux. Les espèces exotiques envahissantes du talus ont aussi été remplacées par des espèces régionales.
À noter : un itinéraire de randonnée du 13e au 15e empruntant les tronçons de la petite ceinture et l’espace public a été créé. La création d’un « fil d’Ariane » guide les personnes malvoyantes et leur permet de se déplacer plus facilement. Le sol de la place est repris en pentes douces pour le confort des personnes à mobilité réduite.
Le plus biodiversité : une Zone naturelle d’intérêt écologique, faunistique et floristique a été créée. Elle accueille notamment le criquet à ailes bleues, espèce cible protégée.
14e : de la rue Didot à l’avenue du Général-Leclerc (0,75 km)
La configuration de cette promenade en tranchée procure le sentiment d’être hors de la ville, au milieu d’une nature omniprésente qui s’est développée spontanément sur l’ensemble des talus. Sur ce tronçon qui ne dispose que d’une seule voie ferrée, pour permettre le passage d’un vélo rail (utilisé régulièrement par l’association d’insertion qui assure l’entretien du site), le mulch, matériau plus souple issu du broyat, a été retenu pour permettre un cheminement au milieu des rails existants et donc la déambulation.
Cette séquence s’inscrit dans la continuité de la promenade Jane et Paulette Nordal (Broussais).
Le plus biodiversité : 131 espèces floristiques régionales ont été recensées sur ce tronçon dont 101 sont régionales. Environ 110 espèces animales sont aussi présentes.
À découvrir : avenue du Général-Leclerc : la gare de Montrouge-ceinture - Poinçon Métamorphosé en un espace contemporain regroupant une programmation culturelle et sociale, un café, un restaurant, des expositions, des événements et une terrasse donnant sur la petite ceinture (sur une surface de 400 m² et de 250 m² de terrasse).
15e : du 101 rue Olivier-de-Serres à la place Balard (1,5 km)
Un aménagement paysager réalisé dès 2013 préserve le patrimoine ferroviaire et met en valeur la biodiversité singulière. Il réunit des habitats naturels variés tels que le boisement, la prairie, la friche, la lisière forestière, la végétation pionnière des ballasts et des murs. Chacun de ces milieux accueille des espèces animales différentes : 220 espèces de plantes et d’animaux y vivent ou s’y promènent, entre le parc André-Citroën et le parc Georges-Brassens. Dans les endroits plus ouverts comme les lisières, les prairies ou le ballast, des hyménoptères, des papillons de jour et des coléoptères viennent butiner.
Le plus biodiversité : Dans les talus boisés, 21 espèces d’oiseaux, parmi lesquels le gobe-mouche gris (Muscicapa striata) menacé, viennent faire leur nid.
16e : du boulevard de Beauséjour à la porte d'Auteuil (1,43 km)
Son aménagement en promenade a fait l’objet de chantiers d’insertion, spécialisés dans la préservation de la biodiversité. En marge du projet d’aménagement du site de la gare d’Auteuil qui regroupe logements et équipements culturels, la promenade de la petite ceinture a été prolongée jusqu’à la porte d’Auteuil et jusqu’au boulevard Suchet (0,23 km, soit 3798 m²). Le pignon du restaurant de la gare d’Auteuil a été végétalisé. Prairie et fourrés, bosquets ponctués de clairières et de zones aquifères, murs et talus calcaires sont autant d’habitats pour une multitude d’êtres vivants insoupçonnés.
Pour guider le promeneur néophyte, un parcours ponctué de six étapes nature présente le lieu à travers ses stations écologiques les plus représentatives. Les plantations d’arbres et d’arbustes ont été réalisées dans la continuité des strates arborées et arbustives naturelles du site. Les plantes herbacées - plantes à fleurs sauvages, graminées rustiques… - ont été choisies dans la continuité de la biodiversité du sentier nature en tenant compte de leur exposition et du piétinement. Deux associations d’habitants ont manifesté en 2019 leur souhait d’y créer un jardin partagé, l’un au niveau de la Muette (association Les Jardins de Camille) et l’autre de l’ancienne gare d’Auteuil (association Horizon Verdure).
Le plus biodiversité : dès 2003, ce ne sont pas moins de 217 espèces végétales qui étaient recensées sur ce sentier. De nombreuses espèces animales sont également présentes.
17e : de la rue de Saussure à la rue Alphonse-de-Neuville (0,7 km)
Tout comme le tronçon dans le 14e, la configuration de cette promenade en tranchée procure le sentiment d’être au milieu d’une nature omniprésente qui s’est implantée spontanément sur l’ensemble des talus. Un cheminement au milieu des rails existants permet de déambuler. L’accès se fait au travers de deux escaliers. Ces ouvrages déclinant une esthétique industrielle et fonctionnelle dans sa structure sont aussi des signaux permettant d’identifier les accès à la petite ceinture.
Le plus biodiversité : ce tronçon accueille 181 espèces faunistiques et floristiques.
18e : les jardins du Ruisseau, la REcyclerie et le Hasard Ludique
Les aménagements de la petite ceinture dans le 18e arrondissement se caractérisent par trois lieux dédiés à des projets associatifs :
-
Les Jardins du Ruisseau, premier jardin partagé à s’être installé sur la petite ceinture dès juin 2004.
-
Plus récente, la REcyclerie – gare Ornano – porte de Clignancourt, implantée au sein d’une ancienne gare de la petite ceinture réhabilitée en lieu de vie. Elle a pour ambition de sensibiliser le public aux valeurs écoresponsables, de manière ludique et positive. Outre son activité de café et de restauration, la REcyclerie propose de nombreux ateliers, conférences, expositions temporaires et un festival de cinéma en plein air sur les voies ferrées. On y trouve également une ferme urbaine.
-
Le Hasard Ludique – gare de l’avenue de Saint-Ouen enfin, avec sa terrasse le long des voies. Il fait désormais partie des lieux emblématiques du quartier de la porte de Saint-Ouen grâce à une programmation musicale pointue et ouverte sur le monde.
19e : entre la rue de Thionville et le 2 bis, rue de l’Ourcq (0,230 km)
L'ensemble du parcours a été conçu comme un sentier respectant les espaces préexistants et le patrimoine architectural et végétal. Ce tronçon est un corridor écologique reconnu et identifié au Schéma régional de cohérence écologique (SRCE) d’Île-de-France mais aussi dans les Chemins de la Nature. Il joue en effet un rôle important dans le cheminement de la diversité entre le parc des Buttes Chaumont en passant à proximité du parc de la Villette et les canaux. L’aménagement préserve donc au maximum la faune et la flore présentes sur le site. Des débroussaillages légers sont effectués par une association d’insertion dans l’objectif de favoriser le développement de la diversité d'habitats par une gestion différenciée.
Le plus biodiversité : par la forte présence d'habitats comme prairies, massifs arbustifs indigènes, arbres à cavités, plantes grimpantes… et par la sous-trame minérale représentée par le ballast et sa végétation de friche herbacée, ce site est un sanctuaire pour la reproduction de certaines espèces d'oiseaux, de reptiles et de micro mammifères. L’Hypolaïs polyglotte (Hippolais polyglotta), une fauvette forestière rare et le lézard des murailles y ont été observés.
À découvrir la Ferme du Rail 2 bis rue de l'Ourq avec son restaurant Le Passage à Niveau avec une cuisine pour tous, à base des produits de la Ferme et de producteurs de qualité, en terrasse au calme de la Petite Ceinture.
19e : entre la gare Rosa Parks et l'avenue de Flandres (0,590 km)
L’aménagement préserve au maximum la faune et la flore présentes sur la petite ceinture, aussi des débroussaillages légers sont effectués par une association d’insertion dans l’objectif de favoriser le développement de la diversité d'habitats par une gestion différenciée. Le tronçon Rosa Parks/Flandre forme un ensemble écologique fort entre le jardin Cesária-Évora, la forêt linéaire et plus au sud le parc des Buttes-Chaumont en passant à proximité du parc de la Villette et des canaux.
L'ensemble du parcours a été conçu comme un « sentier ferroviaire » circulant sur la plateforme ferroviaire, dans le respect des espaces préexistants et du patrimoine architectural et végétal.
Le plus biodiversité : Par la forte présence d'habitats d'intérêt parisien (prairies, massifs arbustifs indigènes, arbres à cavités, plantes grimpantes…) et par la sous trame minérale représentée par le ballast et sa végétation de friche herbacée, ce site est indéniable pour la reproduction de certaines espèces d'oiseaux, de reptiles et de micromammifères. L’Hypolaïs polyglotte (Hippolais polyglotta), une fauvette forestière rare, protégée sur l’ensemble du territoire et le Lézard des Murailles ont été observés sur le site.
À découvrir : La Gare-Jazz – gare du pont de Flandres. La gare abandonnée du pont de Flandres est devenue un bar-club musical « de concerts de jazz ». Le lieu est ouvert avec une programmation adaptée. Voir leur page Facebook.
20e : entre la rue des Couronnes et la rue de Ménilmontant (0,2 km)
Implantée au creux d’un vallon encaissé et délimitée par deux tunnels, cette promenade a été aménagée pour accueillir le public dans le respect du patrimoine existant. Une plateforme en bois de 56 mètres de long construite le long des rails, lors d’ateliers tenus avec les habitants, apporte au site un lieu d’accueil adapté pour les pique-niques ou simplement pour faire une pause. On y a conservé la végétation qui s'y est installée spontanément. Elle s'avère particulièrement riche écologiquement. Cette végétation a colonisé les talus, le ballast, les ponts et les murets, formant différentes strates végétales où se nichent de nombreuses espèces animales. Pour ne pas troubler le rythme biologique des animaux (nidification des oiseaux…), le site est fermé la nuit et l’entretien est adapté.
En complément, un jardin d’ombre a été conçu et réalisé avec les habitants et sera également entretenu par ces derniers grâce à une association.
Le plus biodiversité : d’après les inventaires réalisés au cours des dernières années, ce tronçon accueille une centaine d’espèces animales. Pour la flore, ce sont environ 140 espèces qui ont été recensées. Cette flore constitue des habitats favorables à la faune, comme des friches, des plantes grimpantes et des ronciers très recherchés par les espèces animales qui apprécient à la fois la nourriture qu’ils produisent mais aussi le refuge qu’ils offrent.
Un peu d'histoire
La petite ceinture, patrimoine industriel qui transporta sur ses rails marchandises puis voyageurs, a été fermé au trafic de voyageurs en 1934, persistant néanmoins pour des trains de liaisons grandes lignes jusqu'en 1989. Et si vous êtes habitués de la ligne C entre les stations Avenue Henri Martin et Porte de Clichy, vous empruntez une ancienne section de la petite ceinture.
Les trains de fret ont été arrêtés en 1993. Cependant des échanges de matériels roulants avaient encore lieu dans la partie nord jusqu'en 2000 et des trains de découverte circulaient des années 60 à la fin 2003. On notera aussi des circulations de service de matériels lourds en janvier 2012 et avril 2019.
En 2006, la Ville de Paris et la SNCF se sont engagées à réhabiliter progressivement la petite ceinture et à ouvrir ses espaces à la promenade, tout en veillant à permettre la circulation ferroviaire et la réversibilité des lieux.
Toute l'histoire de la petite ceinture
Les trains de fret ont été arrêtés en 1993. Cependant des échanges de matériels roulants avaient encore lieu dans la partie nord jusqu'en 2000 et des trains de découverte circulaient des années 60 à la fin 2003. On notera aussi des circulations de service de matériels lourds en janvier 2012 et avril 2019.
En 2006, la Ville de Paris et la SNCF se sont engagées à réhabiliter progressivement la petite ceinture et à ouvrir ses espaces à la promenade, tout en veillant à permettre la circulation ferroviaire et la réversibilité des lieux.
Toute l'histoire de la petite ceinture
Votre avis nous intéresse !
Ces informations vous ont-elles été utiles ?
Attention : nous ne pouvons pas vous répondre par ce biais (n’incluez pas d’information personnelle).",0
151,"MCU (Microcontroller unit)
Model: STM32WB55RG
ARM Cortex-M4 32-bit 64 MHz (application processor)
ARM Cortex-M0+ 32 MHz (network processor)
Flash: 1024 KB
SRAM: 256 KB
LCD Monochrome
Resolution: 128x64 px
Controller: ST7565R
Interface: SPI
Diagonal Size: 1.4“
Chip: TI CC1101
TX Power: 0 dBm max
Frequency bands (depends on your region):
● 315 MHz
● 433 MHz
● 868 MHz
● 915 MHz
Frequency: 100-2500 Hz
Sound Output: 87 dB
Type: Coin
LiPo 2000 mA⋅h
7 days approximately
Size: 100 x 40 x 25 mm
Weight: 102 grams
Body materials: PC, ABS, PMMA
Operating temperature: 0 ~ 40 °C
3.3 CMOS Level
Input 5V tolerant
Up to 20 mA per digital pin
TX Power: 0 dBm max
RX Sensitivity: -96 dBm
Data rate: 2 Mbps
TX/RX range: 800-950 nm
TX power: 300 mW
Frequency: 13.56 MHz
Supported cards:
● ISO-14443A/B
● NXP Mifare® Classic/Ultralight/DESFire/etc
● FeliCa™
● NFC Forum protocols
Frequency: 125 kHz
Modulation: AM, PSK, FSK
Supported cards:
● EM400x, EM410x, EM420x
● HIDProx, Indala
Force value: 30 N
Speed: 13500 rpm
Up to 64GB MicroSDHC
Read/Write speed: up to 5 Mbit/s
5-button joystick
Back button
Reboot — Back+Left buttons for 2 seconds
1x USB 2.0 port, type C
USB device
Charging
Operate modes: Reader/Writer/Emulator
Supported protocols:
● Dallas DS1990A
● CYFRAL",8
152,"Satellites give clues about the coming global harvest
- Published
As harvest time looms for the world's main wheat producers, countries that import wheat are hoping for a bumper global crop so that record high prices might fall. But analysis on the health of crops around the world, shared with the BBC, suggests that's unlikely, and that Russia could be the only big winner.
From his farm three hours south-east of Paris, Sébastien Neveux is worried. Here in France's main wheat-producing region, the weather has been strange recently.
It was extremely dry in March, April and May, a crucial time for wheat crops in France which need moisture to pull minerals up from the ground. Then, in June, there was heavy rain and hail. It was too much, too late.
""I'll have lost 40% of this field because of drought and intense heat,"" says Mr Neveux. He estimates he'll lose 25% of his wheat crop overall.
Working with two companies that analyse data on crop health, the BBC has found that some of the world's main wheat producers could see weaker harvests than anticipated this year because of bad weather.
In the EU that could mean 4.7 million tonnes less wheat than last year, which is bad news for countries hoping to find alternatives to Ukrainian wheat.
The analysis looked at information from satellite images, which can determine how healthy a plant is by how much infrared light the plant reflects back at the satellites' cameras. That information is then cross-referenced with data about weather and soil moisture to indicate the potential harvest.
Standing in his wheat field, Mr Neveux pulls two stalks from the ground. One is long and golden, the other short and blackened. Rolling each ear between his palms, he blows away the husks to reveal the grains inside. The healthy plant has many plump grains, the other one has just a couple of shrivelled ones. It's disappointing.
""The grain won't have the right quality for milling flour. It'll have to go to cow or chicken feed. So I'll sell it for less,"" he says.
More than a third of the planet relies on wheat as a staple food. It provides more calories in the world's diet than any other single crop. And as the global population is growing, every year we have to produce more.
At the beginning of 2021 wheat prices were at a record high, thanks to a spike in demand after the coronavirus pandemic and bad harvests in some major exporting countries. Then Russia invaded Ukraine - the world's fifth biggest wheat exporter - and prices soared even higher, sparking concerns of a global hunger crisis.
According to analysis shared with the BBC by Kayrros and EarthDaily Analytics, three of the world's five major wheat exporters (the US, France and Ukraine) could see lower than expected yields this year.
The US is the world's third-biggest wheat exporter but severe drought in spring in two main wheat-producing states, Kansas and Oklahoma, could mean yields are 7-8% lower this year than the five-year average.
India also produces vast volumes of wheat, most of which is consumed within the country. This year India increased the amount of wheat planted, leading many to hope it could become a significant exporter and ease the strain on global supplies. But extreme heatwaves hit India just as the crop was at a crucial stage for developing grain.
In response, the Indian government put an export ban on wheat in early May. EarthDaily's analysis suggests that India's production this year has been 10 million tonnes lower than expected.
Not everywhere has seen disastrous weather though. Canada experienced very severe drought last year which led to historically low yields for wheat. This year the crop is looking much healthier, and EarthDaily estimates that the harvest will be above the five-year average.
In Russia, the world's largest wheat exporter, the crop is looking particularly promising. Thanks to very favourable weather its yields could be 6% higher than average this year, leading to fears that Russia could use grain for political leverage.
Margarita Simonyan, editor-in-chief of the Russian state-controlled news network Russia Today, joked at the St Petersburg Economic Forum in June about how Moscow could exploit the crop, commenting that she had heard people saying, ""All hopes are pinned on the famine.""
""It means that a famine is about to start and now they will come to their senses and lift sanctions, and generally make friends with us,"" she continued, ""because they will realise that it's impossible not to be friends with us.""
In response, Russian President Vladimir Putin said the country had no plans to restrict access to its grain.
But Russia's crop may not be enough to offset deficits elsewhere in the world, says Elena Neroba, a Ukrainian grains analyst with the trading firm, Maxigrain. And Russia could find it difficult to sell. Food is not subject to sanctions, but the restrictions make doing business with Russia complicated.
""Really big companies will avoid trading with Russia because it's a huge risk. If you are a state reserve or a multinational company, it's not just the risk of a volatile price, it's a risk to your reputation,"" Ms Neroba says.
It's also unclear how much of Ukraine's wheat will make it out of the country, as Russia has been attacking grain stores, dropping incendiary bombs on fields of dry crops, and blockading the main export route via ports in the Black Sea.
As wheat harvests get under way, prices are dropping slightly but they are still 48.5% higher than this time last year, according to the UN's Food and Agriculture Organization (FAO).
Price is determined by supply and demand and it is heavily influenced by expectation. Earlier this year expectations were high for the wheat crop in most regions, but war and bad weather dashed those hopes.
The FAO is more optimistic about the crop in the US than the satellite-based analysis from Kayrros and EarthDaily. But it predicts that global wheat production will decline by 0.8% or three million tonnes. That doesn't mean a major shortage of wheat but it does ensure prices will remain high, hitting low-income countries that rely on wheat imports the hardest.
The FAO's chief economist, Maximo Torero, is especially worried about next year, if the war continues and farmers can't access fertiliser, much of which comes from Russia.
""If we continue to have increasing prices of fertilisers, there is potential risk that yields will reduce,"" he says. ""And that's when we could be talking about a huge food crisis.""
The pandemic and the invasion of Ukraine have exposed just how vulnerable our global food system is to shocks. Climate change, which makes extreme and unpredictable weather more common, means more shocks are sure to come.
""Four or five countries control the major share of the wheat exports in the world,"" says Mr Torero. ""If something happens to any of these countries because of extreme weather conditions, it will immediately have an impact on world exports.""
Farmers like Sébastien Neveux have no choice but to try to adapt. He's in his early 40s and inherited the farm from his father, but the way he must farm is different now.
""We need to find plants that are more resistant. And they have to become resistant more quickly to survive climate change. The natural cycle of selection is not going to adapt quickly enough.""
Marching through his wheat field he stops to pull another small, stunted stalk from the ground. Though this damaged plant won't make him any profit, he turns it over in his hands admiringly. It's sad, he says - but it also gives him hope.
""It does everything it can to fight, to produce, to make grain,"" he says. ""It has this extraordinary instinct to survive.""",8
153,"Meta CEO Mark Zuckerberg announced today that the company is launching a new “payments in chat” feature on Instagram. With this new feature, users can purchase products from small businesses and track orders via direct messages on Instagram in the United States.
To use the new feature, users can start by sending a direct message to a qualified small business they’re interested in buying from. In that same chat thread, they’ll then be able to pay, track their order and ask the business any follow-up questions. The company says users often chat about their orders with businesses via DMs on Instagram before purchasing but will now be able to pay sellers directly within their Instagram chat thread. Purchasing via DMs also gives users access to in-app chat support, Meta says.
“You can now buy products from small businesses and track your order in chat on Instagram in the U.S.,” Zuckerberg said in the announcement post. “Pay with Meta Pay and checkout in a few taps.”
A screenshot shared by Meta shows that once a buyer has decided to make a purchase, the seller can create a request for payment. Once a user selects the “Pay” button, they will be asked to add and review their payment information and shipping address. The screenshot notes that “your payment will be processed by PayPal.”
Meta notes that small businesses in the United States who currently don’t use Shops will now be able to discuss products, create orders with customer details and accept payments — without having to switch to another app. When a business is ready to set up a digital storefront, they can use Shops on Instagram and Facebook.
The company says one billion people message a business across its family of apps each week, whether it’s chatting with brands, browsing products or asking for support.
The launch of the new feature comes as Meta officially renamed Facebook Pay to Meta Pay last month. The current product features and overall user experience that people are used to with Facebook Pay remain the same across across Facebook, Instagram, WhatsApp and Messenger. At the time of the rebrand, Zuckerberg said although the service will remain the same, the rename represents Meta’s first step toward creating a digital wallet for the metaverse. He says his vision for a digital wallet in the metaverse will let users securely manage their identities, what they own and how they pay.",1
154,"The technology to use biodegradable film in place of some plastic or paper packaging is there, say researchers. But first, the industry needs to get on board.
Imagine making a bowl of oatmeal or a cup of instant ramen noodles. You likely rip open a plastic package and fish out the little sachet of desiccant destined to be thrown away before pouring the rest of the contents into a bowl.
But what if you could toss the whole package directly into the bowl with your boiling water, saving yourself a bit of fuss and another piece of waste? Yanyun Zhao hopes we’ll see that option become more widely available soon.
Zhao, a professor of food science at Oregon State University, has researched material compositions and applications since 2008. That’s when cranberries first caught her eye. While visiting a juice company’s production facilities, she spotted the remains of pressed cranberries being carted off to use in animal feed or compost.
But to Zhao’s eye, the squashed berries still had a lot of value as a fibrous substance. “I brought some back to the lab, and in our weekly meeting, displayed it to the students,” says Zhao. She put a challenge out to her grad students and colleagues: What can we make with this? “You can imagine all sorts of ideas we came up with.”
Of all the ideas presented, creating a fibrous film that is edible, no-waste, anti-microbial and water soluble was the one that took off, and Zhao published her first paper on the subject 15 years ago. Since then, she’s continued to tweak and refine the formulation.
The film itself looks like a pale strip of fruit leather. It’s mostly tasteless, although there could be a version with a stronger flavor, as it’s completely edible. It’s made by taking the cranberry pomace—or the residue that’s left over once the juice has been pressed out—and mixing that with other food polymers. “When you’re making this film, you need stretch, you need elasticity, you need a lot of functionalities. So, we incorporate other functional food, like other carbohydrates, a little bit of glycerin,” Zhao explains. The end result is a moveable, stretchable, completely biodegradable film.
The film could someday replace traditional packaging materials, but that’s not the only factor that makes it so appealing. It’s also anti-microbial. The cranberry film can work as a replacement for film plastic, protecting fruits and vegetables with delicate skins, such as English cucumbers. Zhao says there could even be a version of the film strong enough to hold liquids, although that requires more study and experimentation.
Currently, Zhao is working on a version of the natural film that could replace paper cupcake and muffin liners, which actually perform a complex task. The liners have to hold a damp batter without dissolving, and then go into a hot oven without melting or losing shape. “We’ve produced these edible cup liners. You can consume them as part of your muffin or you can peel them off and compost them,” says Zhao. The only real hiccup to mass producing these cranberry-based films comes down to cost. “Since those liners are so cheap, people might not care. I can get 100 cupcake liners for a couple of dollars. But if you’re really sensitive to promoting sustainability, we do have the technology there. We are able to achieve this goal.”
The real test will be if companies and manufacturers are willing to switch up production and packaging standards to incorporate new, environmentally friendly materials. Over the pandemic, as more people ordered takeout, there was a rise in plastic and non-compostable containers, which created more waste for our cities. Before COVID-19, many cities moved towards banning single-use plastics, such as plastic bags, but the pandemic slowed that progress. But as folks are still interested in takeout, some experts think there’s a timely opportunity to update food storage options. Zhao says that’s why industry and researchers should work closely together.
“There’s not a perfect product yet. How can we reduce the cost? How can the formulations and technology more easily scale up through companies?” says Zhao. “But the future is very bright for me, because there’s more consumer education, which is important.” One day soon, you might just bite into your muffin liner or dissolve your instant coffee right in its package. Until then, this might make you look at that Thanksgiving cranberry sauce a bit differently.
I would pay more for take out to cover the cost of these containers!
This is amazing! I can’t wait to see where this goes. What an incredible invention.
This is intriguing!
Can see using the product, but not sure if I would eat it.
What plant is this article talking about? You have a picture of one plant Initially introducing the article Which I think is about another plant but itwhich never explains which plant you’re talking about.",2
155,"Systems thinking case study bank
Published 24 May 2022
© Crown copyright 2022
This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit nationalarchives.gov.uk/doc/open-government-licence/version/3 or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: psi@nationalarchives.gov.uk.
Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
This publication is available at https://www.gov.uk/government/publications/systems-thinking-for-civil-servants/case-studies
This document is a case study bank of systems thinking for civil servants. It is one component of a suite of documents that aims to act as a springboard into systems thinking for civil servants unfamiliar with this approach. These documents introduce a small sample of systems thinking concepts and tools, chosen due to their accessibility and alignment to civil service policy development, but which is by no means comprehensive. They are intended to act as a first step towards using systems thinking approaches to solve complex problems and the reader is encourage to explore the wider systems thinking field further.
Introduction
This systems thinking case study bank has been produced by the Government Office for Science as part of a wider systems thinking programme to promote and embed systems thinking across the Civil Service. The programme includes the Systems Thinking Journey, which weaves systems thinking through policy making, and the Systems Thinking Toolkit, which takes a step-by-step approach to 11 systems thinking tools.
The case study bank contains a collection of 14 personal testimonials from a diverse range of civil and public servants. Each case study tells a story of how and why systems thinking was applied to a specific project, what worked well, and any barriers or challenges that were encountered. Examples range from working on net zero to understanding how universities make financial prioritisations. We also signpost at the end of this document to a small sample of further examples of systems approaches that have been used in policy development or public management.
The aim of this case study bank is to highlight the wide range of projects that have benefited from a systems approach, as well as the tools and techniques that other civil and public servants have used and found valuable. Likewise, descriptions of the barriers that different individuals have encountered may also help readers to anticipate and mitigate potential challenges ahead of using systems thinking in their own work.
To create the case study bank, a group of volunteer systems thinking practitioners from across government gave a 30-minute interview to the Government Office for Science on their experiences of using systems thinking for a specific project. Case studies were written up after each interview, and then circulated for review and permission to publish by authors and relevant stakeholders. It should be noted that all views and opinions are those of the individual interviewee and do not represent government policy.
Key themes and perspectives
The case studies in this bank highlight useful themes and perspectives on the benefits and barriers to using systems thinking. The benefits include the power of systems thinking approaches in bringing together diverse stakeholders with unique perspectives and together agreeing a shared goal. Systems thinking was frequently used to highlight the interrelationships within a system and promoted a better understanding of different problems. Some of the common barriers were the time and resource required for workshops, and how to effectively convey the complexity of key findings (for example, systems maps) to different audiences. However, this barrier was often overcome by bringing in design experts and consultants with expertise in data visualisation, and by creating a good narrative to accompany systems maps.
Methodology
The testimonials were collected from individuals working across a range of professions in 6 government departments, 1 public body and 1 executive agency. These individuals cover a range of grades from Senior Civil Servants to Higher Executive Officer, with approximately equal numbers of men (56%) and women (44%). We hope to continue to add further case studies to this bank; if you are interested in featuring, then please get in touch with systems@go-science.gov.uk.
Case studies
|Title||Author||Affiliation||Systems thinking tools or approach used|
|1. Creating a tool to improve net zero policy design||Adam Mackenzie-Jones||BEIS||Causal loop maps|
|2. Reforming agricultural policy design||Caitlin Jones||Defra||Causal loop maps|
|3. Improving the performance of a government directorate||Gary Preece||Defra||Rich pictures|
|4. Creating a new tax system||Hazel Challenger||MOJ||Causal loop maps|
|5. Understanding how universities make financial and prioritisation decisions||Isabel Ruckelshauss||UKRI||Causal loop maps|
|6. Creating a healthy business finance system in the UK||Mark Renshaw, Jennifer Panting, Nafeesah Ameerudden||BEIS||Goal setting, framing questions, causal loop maps|
|7. Improving Net Zero policy design||Jonathan Hoare||BEIS||Systems mapping, Sankey diagrams, general systems approach|
|8. Developing a new capability for the Home Office||Niki Jobson||Dstl||PQR statement, soft systems methodology|
|9. Explaining the DWP policy simulation model||Rachel Bennett||DWP||Rich pictures, cognitive maps|
|10. Tackling multiple disadvantage||Richard Lewis, Shane Britton||DLUHC||General systems approach|
|11. Developing the business in human rights action plan||Richard Fitzgerald||BEIS||Soft Systems Methodology, causal loop maps|
|12. Joining-up air quality and climate change policies||Rose Willoughby||Defra||Soft Systems Methodology|
|13. Ageing Foresight Project||Tom Wells, Stephen Bennett||GO-Science, Policy Lab||Causal loop maps|
|14. Establishing a systems team to inform land use policy||Dan McGonigle||Defra||Causal loop maps and general systems approach|
Case study 1: Creating a tool to improve net zero policy design
Adam Mackenzie-Jones is an experienced analyst who leads the Net Zero Systems Team in the Department for Business, Energy, and Industrial Strategy (BEIS). This testimony describes Adam’s personal experience of using systems thinking to design a tool that aims to improve Net Zero policy design.
What were you trying to do?
My role in BEIS is about embedding systems thinking across the Net Zero programme to facilitate more systemic and effective collaboration. My team wants to help make policy design in the net zero space more robust by avoiding unintended consequences and leveraging synergies in the system. For this specific project, we secured funding from the shared outcomes fund[footnote 1] to do an initial exploration of how systems approaches might be applied to land use and heat and buildings systems. The aim of this project was to create an interactive tool that helps officials to explore both these systems. The tool highlights interdependencies, trade-offs, unintended consequences, and feedback loops to give policy officials a richer understanding of the system they are designing policy for. Outputs of the tool will be indicative of what might happen in the system if a certain course of action is taken, which could lead on to further research being commissioned. This also means that any further analysis will be underpinned by a systemic appreciation.
Why did you think that a systems approach was right?
Net zero is a complex problem, in part because it requires a complete transformation of many of our existing systems (by complex, I mean something that is comprised of many parts that are interconnected). Human behaviour is an important part of this system, and our goal is for systems approaches to be used widely across the net zero world to tackle this complexity. Land use and heat or buildings are at opposite ends of complexity; land use is broad and less quantifiable while heat and buildings are narrower and more quantifiable. Using a spectrum of system types like this will help provide proof of concept for the tool.
What did you do?
Causal loop diagrams underpin the tool that we are creating. These diagrams were developed across several workshops with government officials, academics, and third-sector parties. It was important from my perspective to get a broad view of the system that isn’t purely government focused. These initial workshops were focused on the key factors in land use and heat and buildings systems. This helped to scope out boundaries and delve more into the detail of individual sub-systems. The next workshops aimed to iterate these boundaries and gain a broad consensus on the way forward. We cross-referenced our maps against existing government models as a form of validation to gain quality assurance. The key thing was to go beyond having a map and move towards creating a tool that people can interrogate and use. Causal loop maps usually sit in posters or on a static computer screen and are hard for people to engage with. The aim of this project is to create a causal loop map-based tool that people can explore themselves.
After the workshops we created a proof of concept for what the tool would look like; consultants were brought in at this stage to help make it attractive and useable. There will be many possible applications for the tool, and we are looking to embed this in as many processes as we can. For example, we are looking to use this tool to feed into the identification and capture of key interdependencies in the system for delivery reporting purposes. We are also looking at embedding this in appraisal and monitoring or evaluation processes to define theories of change in different policy areas.
What worked well?
The workshops worked well. We gathered diverse perspectives on what the most important factors (variables) are in the land use system and heat and building system. It is important to ensure that everyone is on board with the exact phrasing of a variable, and I think that aspect this went particularly well since we worked through the problem iteratively in multiple workshops. I hope that the tool will work well in embedding systems approaches through net zero and policy design. We plan to conduct an evaluation with the Evaluation Task Force which will give a good idea of how effective the tool is being.
What didn’t work so well (what challenges or barriers did you encounter)?
One of the challenges we encountered when making the tool was ensuring that causal loop diagrams are easy to read and interpret. It is important to remember that just because a certain notation makes sense to you it doesn’t mean that it will make sense to everybody. The challenge is to make sure that the tool tells a story to people and doesn’t depend on being too analytical. To help overcome this we bought in consultants with expertise in visualisation to bring out different perspectives with different tabs to help people to interpret the map.
What were the outcomes of using systems thinking in your work?
We are helping to facilitate systemic discussion across different net zero policy areas. At the end of this project, we should have a tool that people can easily navigate to explore land use and heat and buildings systems, with the opportunity to easily expand this proof of concept to wider sectors. More generally, we expect to see longer term policy outcomes through the course of net zero.
Case study 2: Reforming agricultural policy design
Caitlin Jones is a Senior Operational Research Officer in the Department for Environment, Food and Rural affairs (Defra, Future Farming and Countryside programme). This testimony describes Caitlin’s personal experience of using systems thinking to deliver large-scale, rapid change in agricultural policy design and evaluation.
What were you trying to do? What was the project and what were its overarching aims?
Leaving the EU has meant that there needs to be a large-scale, rapid change in agriculture policy design and evaluation. This system deals naturally with complexity, and we had always wanted to understand where there might be risks, opportunities, loops, and non-linear interactions. The aim of this project was to undertake an ambitious participatory systems mapping exercise to understand the real-world agricultural system and generate a conceptual model that could be used to draw insights for policy and evaluation design.
Why did you think that a systems approach was right?
Agricultural policy space is complex and interconnected, and we wanted to clarify relationships to build up a big picture of the whole system. There are around 500 people working on this programme, with many teams working on individual products, schemes, and interventions. Things can easily fall into siloes, which wouldn’t have worked well for this project. We wanted to use systems thinking to build a shared understanding of what the system looked like with key stakeholders, challenge assumptions, and break down boundaries between different teams and policy areas. This policy area also relies on a mixture of quantitative and qualitative data, which systems approaches can handle quite well. We knew that analysis could be run on a systems map to gain useable insights such as risks and opportunities.
What did you do?
The basis of our approach was a participatory systems mapping exercise that was completed internally. First, we ran a preliminary workshop with policy and analysis leads to identify stakeholder interests, with the purpose being to try and get into the headspace of key stakeholders. We then worked with the Centre for the Evaluation of Complexity Across the Nexus (CECAN) to deliver a 1-day participatory systems mapping workshop, which was delivered in person before the COVID-19 pandemic. As we had 4 main agricultural policy areas, we broke these up into 4 separate maps, with a different team working on each map. We then got people to rotate around tables to start linking maps together. People drew stars on each other’s maps to highlight the factors that linked to the map that they had originally drawn.
After this workshop, the team at CECAN took all 4 maps and put them into Draw.io software. This would not have worked for the whole map as it was too big and unwieldy to deal with. We then ran a set of verification workshops where people came back in pairs or trios to address the map that they had originally worked on. Another round of updating followed on from this workshop, and we then used Gephi software to visualise networks and generate a final systems map.
What worked well?
We ran this project in early 2018 when systems thinking was still a novel concept for the department. There was a recognition that agricultural policy space is a highly complex and that something needed to be done to understand this. Everyone was very keen to engage with systems thinking which was a pleasant surprise. The workshops were very effective in challenging perspectives, and we found it useful to show people their thoughts written down on the map. The participatory nature of the systems mapping workshops really helped create a shared understanding of the system.
We did find that the mapping workshop was a little slow at first, with people being reticent to jump in, but things got going quickly with some strong facilitation involved. By including stakeholder interests as well as policy outcomes in these discussions, we really helped steer the conversation towards the bigger picture of the system.
What didn’t work so well (what challenges or barriers did you encounter)?
One difficult aspect in steering people away from linear, siloed thinking is the different levels involved in causal loop maps. The high-level outcome is different to the policy outcome, and we found that people were uncomfortable with the idea of mixing these levels. People also struggled with the idea of positive and negative relationships in causal loop diagrams. They often confused positive and negative notations with factors being desirable or undesirable, rather than a correlative effect.
The scale and novelty of techniques used in the workshop meant that we needed expert facilitators and lots of help from CECAN to steer the systems thinking aspect and hammer home key concepts. A technical issue that we encountered was how we should combine data from the big systems mapping exercise.
What were the outcomes of using systems thinking in your work?
The outcome of using systems thinking in this project was an increased awareness and appreciation of this technique as a way of dealing with complex policy problems. Nobody in our workshops had ever used techniques like this before, whereas now people actively ask for systems thinking-based input into policy. The causal loop maps we created were powerful as they conceptualised theories of change and reframed how people approach doing evaluation. A longer-term outcome is that there is now a willingness to engage with different systems thinking methods in Defra. We also have a community of systems thinking practitioners within Defra that didn’t exist before.
Final systems map generated by Gephi software to visualise networks, contributed by Caitlin Jones
Case study 3: Improving the performance of a government directorate
Dr Gary Preece is Head of the Systems Research Programme in the Department for Environment, Food, and Rural Affairs (Defra). Gary is also an analyst in the Government Operational Research Service. This testimonial describes Gary’s personal experience of using systems thinking to improve the performance of a directorate as an analyst for the Government Operational Research Service.
What were you trying to do? What was the project and what were its overarching aims?
I led this project during my time working as an analyst for the Government Operational Research Service. A directorate wanted an evaluation of how well it was working and how it might be able to perform better in the future. The aim of this project was to work out what was working well, what was driving issues and help people decide how to solve these issues.
Why did you think that a systems approach was right?
The directorate consisted of around 80 people, so I was never going to be able to interview all of them individually. A systems approach is great for bringing people together to share and challenge perspectives. A range of issues were being flagged within the directorate and it sounded like these were all interlinked. For example, teams were not as joined-up as they could have been, and interlinkages were broken. Systems thinking is great for tackling complex and interlinked problems.
What did you do?
I held a workshop with staff in the directorate and used soft systems methodology[footnote 2] to get people thinking about how the directorate was currently working. First, I put people into small groups and got them to draw a rich picture[footnote 3] of how they thought the directorate was working. Each group had a facilitator to support them in creating this, and we then got everyone to present their rich pictures to the rest of their peers. These brought up some interesting issues on how people were working, such as a lack of information sharing across teams. I then used viable systems modelling[footnote 4] to dig further into these issues to see how the rich pictures mapped onto this model. This tool models an ideal system with effective and efficient functions and provides a way of comparing the current system to this ideal system. This process helped to identify what was driving issues in the directorate and what steps might be taken to solve them.
What worked well?
A systems approach was great for highlighting interrelationships between issues and understanding how certain issues can cascade into others. This information is helpful, as it highlights how issues could become more serious over time if left unchecked. We found that people really enjoyed drawing rich pictures after a few minutes of settling into the activity. There was a huge amount of energy in the room with people bouncing ideas off one another, which created a great atmosphere. Rich pictures were also great for providing a visual representation of the problem. When creating a workshop, it can be difficult to know where to get started. Systems thinking tools offered structure and flexibility to support the design and delivery of the workshop.
What didn’t work so well (what challenges or barriers did you encounter)?
At the start of the workshop some attendees were clearly not comfortable with drawing a rich picture. People did get into it, but every individual has a different preference for how they express themselves, and drawing does not work for everybody. Time is a common challenge with using systems thinking. There is always the classic problem of trying to get everybody in the same room at the same time for workshops. Another challenge is that people often view systems thinking as something that provides all the answers to a problem. Systems thinking is great for clarifying a problem and setting people off on a journey to start analysing and solving it. This approach gets people into a holistic mindset to start thinking about complex problems and how to tackle them. However, systems thinking can often be too abstract and high-level to give the complete and final answer to a problem.
What were the outcomes of using systems thinking in your work?
The outcomes of using systems thinking in this project were a better understanding of where there were issues in the directorate and how these could be tackled. The collaborative nature of the workshops generated buy-in from attendees and a willingness to make changes in the directorate.
Case study 4: Creating a new tax system
Hazel Challenger is an Operational Researcher in the Ministry of Justice. Before this, Hazel worked as a Higher Scientific Officer for Inland Revenue: a predecessor of Her Majesty’s Revenue and Customs. This testimony describes Hazel’s personal experience of using systems thinking to create a new tax system during her time at Inland Revenue.
What were you trying to do? What was the project and what were its overarching aims?
This project was initiated soon after the poll tax riots when the old rate system was thrown out by the public. The overarching aim was to introduce a new tax system that would cover approximately 9 million taxpayers. This applied mainly to self-employed people and higher rate taxpayers. If this hadn’t worked, there would have been a break in funding arriving at the Treasury. My aim was to identify key factors in this system to ensure that the new tax system went live smoothly.
Why did you think that a systems approach was right?
Everyone was using a siloed approach to view this problem, which was driven by how budget was allocated to each part of the process. Due to the scale of the project, there was no overarching view end-to-end. Creating a new tax system requires an overarching view of the whole system, which is why I thought that a systems approach was right for this project. Systems thinking was a mostly unknown concept in the civil service at this time and had not been widely used across government, although this approach is much more normalised today.
What did you do?
I ran workshops with the people who were working within each silo to create causal loop diagrams. This was the first time that these individuals had been brought together to talk about how to create the new tax system. I also trained a consultant in causal loop mapping beforehand so that he could support people during the workshop. As a result of the causal loop mapping exercise, people recognised that the success of each silo was dependent on each of the other silos; people began to work collaboratively and were no longer defensive of siloed approaches
Next, our consultant created a numerical model of these maps in excel to do a cost-benefit analysis. This helped to justify why there should be an increase in funding on the marketing element of the project. The result was a massive increase in the marketing budget, meaning that Inland Revenue were able to advertise on TV for the first time. This resulted in the creation of the marketing figurehead - Hector the Taxman.
What worked well?
Mainly getting everyone to talk to each other, collaborate, and realise the interdependencies of their individual work areas. The conversations that people had in the workshop were really helpful and meant that things continued to go smoothly afterwards. Getting everyone together in the same room is a huge benefit of causal loop maps - as well as the conversations that are held while creating them. This is a standard approach that allows people to express opinions, explores the what and why of a problem, and captures conflicting opinions. The result of putting in a budget for marketing was a great outcome that came from using systems approaches in this project – at that time it was rare for the Inland Revenue to spend money on something like this!
What didn’t work so well (what challenges or barriers did you encounter)?
This was the first time that systems thinking had been used in an Inland Revenue project, and the first time that I had used the approach in a real situation. A big challenge that I encountered was the lack of guidance on how to effectively run a workshop. Without good technique or facilitation skills people interpret causal loop maps differently, and the power that comes from creating them dissipates. At the time, we didn’t have a scribe there to point out when something has been missed and annotate the ‘why’s’ of the problem. Since that time, I have developed a standard way for recording this information.
What were the outcomes of using systems thinking in your work?
The outcomes of using systems thinking in this work were that the self-assessment tax system went live successfully. Without this, we could potentially have had lots more objection to the new tax system, and in the worst case, more tax riots.
Case study 5: Understanding how universities make financial and prioritisation decisions
Isabel Ruckelshauss is the Principal Analyst for systems thinking at UK Research and Innovation (UKRI). This testimony describes Isabel’s personal experiences of using systems thinking to understand if research in UK universities is funded in a sustainable way.
What were you trying to do? What was the project and what were its overarching aims?
Universities in the UK deliver teaching and research activities to benefit society and the economy. These activities are funded through a variety of income sources (including tuition fees and project-specific research grants).
Our project centred around the financial sustainability of research activity and understanding the factors that affect financial and prioritisation decisions in universities.
We wanted to work with universities all over the country to understand nuances in the system and emphasise any differences in their views.
Why did you think that a systems approach was right?
We decided that a systems approach was appropriate because this is a question to which there is no single answer, and we wanted to use systems thinking to understand which incentives we might set through our policymaking.
This was more about:
- gaining a better understanding of the system
- the different views that stakeholders hold of it
- the complexity associated with it
What did you do?
Together with policy colleagues, I spent time defining the problem as there were lots of questions relating to research sustainability overall. We then ran a series of causal loop mapping workshops with internal and external stakeholders with the eventual aim of identifying key loops and any systems archetypes[footnote 5] along with themes to broaden our understanding of how universities behave.
We also looked at what dynamics play the greatest role in this system. Building separate maps with internal and external stakeholders will help us to identify where the key differences between them lie. Causal loop maps are very handy for this kind of analysis as they highlight which factors and interrelationships play the biggest role in the behaviour of the system. The outputs of these mapping exercises will be used for scenario analysis.
What worked well?
For a project to work well you need to have strong stakeholder engagement. It’s vital that these stakeholders have an interest in working with systems thinking and are willing to dedicate time and resource to the project. I was very lucky in that regard.
Causal loop diagrams promoted interaction and a shared learning that we found to be very useful. The fact that stakeholders must come to an agreement on what they put on their causal loop map worked well, and many people exchanged contact details to continue this shared learning after the workshop. I thought that this was a very positive outcome given that many first met in the workshop!
We also found causal loop maps to be extremely effective in communicating complex situations to senior decision-makers.
What didn’t work so well (what challenges or barriers did you encounter)?
We found time-constraints to be the biggest problem. Causal loop mapping takes a long time and requires many resources to be done well, especially for bigger projects. During the 8 months that I have been working on this project I have had to adapt to changes in the organisation. It can be challenging to adapt to the constant fluctuation around you and ensure that everything still works around set timelines. We also had to convene all our workshops via Zoom, which had advantages, but also meant it could be difficult to encourage reluctant speakers to contribute to the discussion.
What were the outcomes of using systems thinking in your work?
After our causal loop mapping workshops people always say “I had never thought about a problem this way before”.
I have had positive follow-up from people who participated in the workshops and lots of colleagues are interested to find out what we have discovered through the system mapping approach. Specifically, I expect that systems thinking will promote a much greater understanding between internal and external stakeholders. We are starting to convince senior stakeholders of the patterns that we are seeing and issues that will need to be addressed. The work is being used to inform the analysis of drivers of change and policy work on addressing sustainability pressures in the research and innovation sector.
Causal loop map generated by Kumu.io software, contributed by Isabel Ruckelshauss
Case study 6: Creating a healthy business finance system in the UK
Mark Renshaw, Jennifer Panting and Nafeesah Ameerudden (photo not included) work within the Technology, Strategy, and Security Team in the Department for Business, Energy, and Industrial Strategy (BEIS), along with 2 others who were not interviewed. This joint testimonial describes Mark, Jennifer, and Nafeessah’s personal experiences of using systems thinking to understand how businesses in the technology sector (deep and emerging) can be scaled-up.
What were you trying to do?
The UK is very good at creating start-up and spin-out companies but less efficient at scaling small firms into large firms. Furthermore, everyone has different ideas on what the enablers and blockers are to scaling-up a business. As a team, we decided that the crux to solving this problem is reducing complexity so that policy officials can make interventions that are evidenced and supported. We wanted to create something that we could show to stakeholders to create a shared understanding of the problem.
Why did you think that a systems approach was right?
We thought that a systems approach was right due to the complexity of the problem and the diverse range of stakeholders involved. Systems thinking is a great way for engaging stakeholders and aligning people’s understanding on a complex problem.
What did you do?
We followed a course on systems practice provided by Acumen Academy, which was very practical as opposed to theoretical. First, we identified a set of candidate problems that were amendable to a systems approach and developed a long-term goal for the system known as a ‘guiding star’. This describes an aspirational state for the system and acted as an anchor for the questions that we asked stakeholders. Our long-term vision (guiding star) of a healthy UK business finance system for deep and emerging technology is one that effectively invests money into firms with the highest potential for creating positive economic and societal impacts. In the nearer term (near star), we want investors to be increasingly comfortable backing UK deep and emerging technology firms, understanding the risks and the rewards this could bring given immature markets. We want firms to demonstrate the potential impacts and markets of their technologies to investors, and government to cultivate a healthy ecosystem of investors and firms. To understand how the system currently works, we will use the framing question[footnote 6] “what constrains and enables effective investment into UK deep and emerging technology firms?”
Next, we brainstormed all relevant factors (those that constrain and enable effective investment in UK emerging and deep technology firms) into one big Visio[footnote 7] file, which included virtual post-it notes. We identified 8 broad themes that were relevant to explore and used these as a basis for a series of consultations with people in the Civil Service. These consultations fed into big workshops that were held with stakeholders to flesh out themes and identify key insights or narratives.
We are now taking our learning from these workshops to generate a series of loops. In consultations there were 32 individual stories that seemed relevant, and we built these out into a series of causal loop diagrams. This was a complex, iterative process. We are now in the process of distilling these loops into 15 or 16 key loops and will then condense these further into a core story on why the system functions as it does. This core will be used to build up a final systems map that our team and stakeholders can use to identify points of leverage in the system.
What worked well?
Taking a systems approach was effective in helping us to work with different teams and stakeholders to gather diverse perspectives. Working together to create causal loop maps was very useful from an analytical point of view and helped us to summarise evidence on key enablers and inhibitors in the UK business finance system for deep and emerging technology.
What didn’t work so well (what challenges or barriers did you encounter)?
The biggest challenge that we face is time (we are the 3 core members of this project team) and the fact that we have been working at home due to the COVID-19 pandemic. This has not presented a major barrier so far, but it might make the process trickier now that we are ready to build our systems map. It would be most efficient and effective to do this in person so that we can highlight key information and cut out unneeded bits. Having said that, working from home has made it much easier to talk to a wide diversity of people and gather a broad range of perspectives. We are also limited by technology; now that we are building a systems map we may need to explore mapping options requiring additional resource.
What were the outcomes of using systems thinking in your work?
We have not finished this project and so do not know what the long-term outcomes of using systems thinking will be. However, so far systems thinking has helped to create a shared understanding between stakeholders on how to create a healthy finance system for businesses in the UK. By taking a systems approach, we have bought together a range of stakeholders from across the Civil Service to create a core working group. The short-term goal of this working group is to decide how we should talk to senior government leaders to address the problem.
The longer-term goal of this project is to provide an essential framework that will enable the Civil Service to start thinking about this issue from different perspectives. The evidence generated from working group consultations formed the basis of a paper that was sent to senior government leaders.
Examples of brainstorms generated during workshops, contributed by Mark Renshaw, Jennifer Panting, and Nafeessah Ameerudden
Case study 7: Improving Net Zero policy design
Jonathan Hoare is a Deputy Director in the Net Zero Strategy Directorate at BEIS. This testimonial describes Jonathan’s personal experiences of embedding systems thinking into the Net Zero strategy. This work was initiated in response to a pull from the Prime Minister’s Council for Science and Technology in 2020.
What were you trying to do?
The UK government has set a bold and ambitious target to reach net zero carbon emissions by 2050. In our team, we use a systems approach to visualise how different parts of this the net zero system are interconnected. This helps identify where to make changes in the system to achieve government priorities. We can then use this insight to support delivery modelling, policy development, and the reporting or understanding of net zero.
Why did you think that a systems approach was right?
Achieving net zero carbon emissions requires a massive change in the way that society operates, and this will include a whole economy transformation. The sheer complexity of this problem means that a systems approach is required to tackle it. It is important to recognise the timeline of net zero, and the fact that during the next 30 years there will be changes in science, technology, and economies that impact the whole system. A combination of hard and soft systems tools is required to tackle this issue.
What did you do?
We have 3 main missions; to ensure that governance of government programmes is organised in a holistic way, to use a strategic systems approach as an organisational learning machine, and to embed a culture of learning and reflection across the net zero landscape.
We have used lots of systems maps to build our understanding, and Sankey diagrams were used in the Net Zero Strategy to show anticipated changes to the energy system over time. We are also building and developing a systems interrogation tool for land use and heat and building systems to help inform decisions by policy makers (see case study by Adam Mackenzie-Jones for further details). At a strategic level we work with the Council for Science and Technology (CST), subgroups of CST and others such as The Royal Academy of Engineering for advice on how best to approach different issues.
What worked well?
Systems reasoning also informs our decisions on what factors need to be kept on close watch. We’re continuing to embed the approach, and systems approaches have enabled us to think about interdependencies in the system. It’s not a totally new approach. BEIS has used cutting-edge whole energy systems models like UK TIMES for a number of years, which have helped the whole of government design policies and programmes to meet our Carbon Budgets.
What didn’t work so well (what challenges or barriers did you encounter)?
We haven’t encountered any barriers, but there are things that we might have done differently. When building things like tools there is a risk of doing so in a non-systemic way, it’s important to bring in stakeholders right at the beginning of this project to ensure that we are working within the policy making system (as opposed to outside the policy environment). There is also a risk that people can think that they are already doing systems if they have used systems thinking in the past. It is important for people to understand that this isn’t something that they do once and then go back to the ‘normal’ way of doing things, and a shift in perspective is needed here. But people are also right that excellent policymaking and advice means thinking beyond the immediate issue and time horizon.
What were the outcomes of using systems thinking in your work?
We are now approaching the challenge of achieving Net Zero in much more sure-footed way. We know that there is uncertainty in the system, but by using systems thinking we are equipping ourselves to deal with this in best way.
Case study 8: Developing a new capability for the Home Office
Dr Niki Jobson is a Chief in Systems and Consulting at the Defence Science and Technology Laboratory (Dstl). This testimony describes Niki’s personal experiences of using systems thinking to help establish a new capability for the Home Office.
About Dstl
Dstl has a cadre of staff, with highly developed systems thinking and systems leadership skills, that work closely with senior Defence and Security decision makers to:
- accelerate their understanding of complex, turbulent challenges with high degrees of uncertainty
- structure the problem they are facing and develop sound, evidence-based approaches to addressing them
- explore, develop, and test potential systemic intervention strategies
- design collaborative approaches for working effectively across multiple organisation boundaries and technical disciplines
What were you trying to do? What was the project and what were its overarching aims?
Dstl was tasked by the Home Office to help them identify options for establishing a new systems-of-systems capability. As several government departments had a stake in the situation it was vital to agree the purpose of the endeavour, explore the policy, operational and technical challenges, and constraints holistically and generate a coherent set of requirements.
Why did you think that a systems approach was right?
We took a systems approach because we needed to work across organisational boundaries with a diverse set of stakeholders, each with different foci, roles, responsibilities, and technical knowledge. No single organisation had a holistic view of the challenge nor owned the system-of-systems that needed to be delivered. Successful outcomes would only be achieved by bringing the stakeholder organisations’ together to develop a shared understanding of the challenges faced, agree the purpose of the capability, and collaboratively develop a way forward.
What did you do?
As with any challenge, we started by exploring the multiple perspectives on the purpose of the capability and the context it would operate in. This provides a sound foundation for moving forward. This activity was based around the PQR formula of soft systems methodology. We developed scenario narratives to help stakeholders collaboratively explore and debate the broad range of policy, operational and technical issues they would need to address to achieve the desired outcomes. The approach was based on an iterative cycle of interviews and workshops that enabled us to build knowledge and understanding progressively, across the stakeholder community, adapting the approach as we learned what we needed to know next.
What worked well?
This was the first time the stakeholders had come together to explore and understand the capability as a cohesive whole. The collaborative and consultative approach allowed the team to harness the intelligence of the collective, but more importantly see the issues, challenges and needs of others from alternative perspectives. This created greater empathy in the stakeholder a group, making it easier to find accommodations and establish a more unified approach for moving forward.
What didn’t work so well (what challenges or barriers did you encounter)?
Collaborative working requires stakeholders to dedicate time to coming together; diary availability was a recurring issue. People can find it challenging to leave behind today’s urgent operational challenges to address scary, future problems. Understanding the complexity and variety of requirements and challenges across the whole system is cognitively taxing. Hearing alternative perspectives and views that challenge your own understanding can be uncomfortable. Dstl was fortunate to have customer who championed the systems approach and corralled stakeholder attendance for the initial workshops. After the first couple stakeholders began to see the value in attending and prioritised their time to do so – they had a vehicle to get their voice heard and they got a much better understanding of the context of their work.
What were the outcomes of using systems thinking in your work?
Option development is currently paused as our exploration of the space identified some intermediary issues that need to be addressed first. These range from putting in place policy enablers and addressing gaps in technical knowledge that would enable the cost-benefits of the options to be properly explored. However, with all the information gathered we were able to rapidly identify and agree a set of actions that the Home Office and its stakeholders could take immediately to effect change and yield improvements.
Case study 9: Explaining the Department for Work and Pensions policy simulation model
Rachel Bennett is an operational researcher in the Department for Work and Pensions (DWP). She recently completed a master’s degree in systems thinking with the Open University. This testimony describes Rachel’s personal experience of using systems thinking in her master’s dissertation project to help explain the DWP policy simulation model.
What were you trying to do? What was the project and what were its overarching aims?
I was working in a modelling team, and my specific team were looking after a model called the policy simulation model. This looks at all the benefits that DWP is responsible for such as universal credit and legacy benefits. The model can be used for ‘what if?’ analysis; for example, if an extra £10 was added to universal credit, how many people would it affect and what would it cost the government? This is a very powerful tool that can look 5 years ahead and is used for forecasting in the department. The model itself consists of lots of modules of code. A user interface is essential so that analysts can reach in and get outputs without going into the depths of the code.
When I joined the department there was no schematic to visualise the policy simulation model and what it does. People would have to jump into the code, read it, and look at the data outputs. Therefore, the aim of this project was to use systems thinking to explain the model to new modellers and analysts.
Why did you think that a systems approach was right?
This was a collision of 2 things; I was learning about systems thinking and had an interest in it. I felt that this situation needed pictorial representation and knew that systems thinking could do that. I also wanted to bring people into the process to promote shared learning and knew that systems approaches are helpful for doing that. It was important to shed light on the complexity of the situation and I knew that systems approaches are good for bringing people with different perspectives on board. This wasn’t a policy process with different individuals disagreeing, so I wasn’t sure if it was the right approach. It was pitched more as an experiment.
What did you do?
Everything that I did was internal to DWP. I experimented with several different systems thinking techniques to see if they were helpful. Firstly, I drew a rich picture[footnote 3] of how the policy simulation model sits in the organisation. This included what the model is used for and who the different actors are. Once I had drawn the rich picture, I shared it with analysts to test my understanding and made further changes based on their feedback. I then made a cognitive map of me, my Grade 6, and Grade 7’s views about the policy simulation model’s relative strengths and weaknesses. This helped us to articulate what we thought the key issues were with the model as well as what was going well and helped us focus our efforts on where systems approaches could most help. We concluded that the model had great quality assurance and was robust. The key issue was trying to improve accessibility. The crux of this was to get modellers and analysts together in a workshop to talk about the model and do some mapping of how key elements within the model worked together. In the end we made a hierarchy of maps, including a high-level map and some detailed maps for more specific benefit types.
What worked well?
Drawing the rich picture went better than I expected – this was quite a risky thing to do as rich pictures can look quite naive. I did this more for myself, but other people found it helpful when I showed it to them. This is now used in the team induction pack to describe the model, what it does and how it is used. The cognitive map was useful in the process of articulating what I wanted to do for the workshops, but the outputs were not surprising as the people who helped to create them already knew the outcomes. The workshops worked well as people talked to each other and shared their knowledge about the model. This verbal sharing of knowledge to capture everyone’s collective learning had not happened before.
What didn’t work so well (what challenges or barriers did you encounter)?
Systems thinking was a new concept for everybody in the team, so I felt that I had to pitch its usage as an experiment to limit expectations. The challenge was to get people’s time whilst promoting this as something new to try. If systems thinking based workshops do not stack up with people’s day to day priorities it can be hard to get them to contribute. It is also important to come up with a collaborative learning outcome to show workshop benefits and convince people to spend time on them.
What were the outcomes of using systems thinking in your work?
The rich picture that I drew is in our team induction pack along with the other maps. The primary objective of the project was to enhance the accessibility of the policy simulation model for people coming into the team and the department. This objective was definitely met and has given me confidence that these systems thinking approaches can work for these types of problems.
I learnt that we need to be careful with what language is used when presenting systems thinking to people. I realised that it can be more off-putting than helpful to name the specific type of approach used. For example, rather than saying ‘systems maps’ it can be good to simplify this by using a phrase like ‘collecting ideas’. In addition, I was able to put the outputs from this project into the dissertation for my master’s degree.
A rich picture to understand how the policy simulation model fits into DWP, contributed by Rachel Bennett
A cognitive map to bring together people’s different perspectives about the relative strengths and weaknesses of their model, contributed by Rachel Bennett
Case study 10: Tackling multiple disadvantage
Shane Britton is the Lead Policy and Programme Advisor for the Changing Futures Programme at the Department for Levelling up, Housing and Communities (DLUHC). Richard Lewis is the Engagement Advisor for this programme. This testimonial describes Shane and Richard’s personal experiences of using systems thinking to help tackle multiple disadvantage.
What were you trying to do? What was the project and what were its overarching aims?
Changing Futures is a cross-government programme funded by HM Treasury’s Shared Outcomes Fund with additional aligned funding from the National Lottery Community Fund. It aims to improve outcomes for adults experiencing multiple disadvantage – including combinations of homelessness, substance misuse, mental ill health, domestic abuse, and contact with the criminal justice system.
Working with 15 local areas, our work focuses on 3 interlinked levels of activity. At an individual level, areas are coordinating better ‘whole person’ support for local cohorts of people experiencing multiple disadvantage. At a service level, we are exploring how services can join up and work together more effectively to coordinate that support. At a systems level, we want to determine how to drive long-term impactful change in local systems in a way that is sustainable. We will also consider how to achieve more join-up across government to understand and address the systemic challenges that exacerbate the problem.
Why did you think that a systems approach was right?
This is a complex challenge. Individual services and siloed approaches are limited in how far they can address this challenge and deliver outcomes for people with multiple disadvantage. Taking a system-wide view is therefore key, and brings together the right partners to coordinate a more effective response.
This also means working differently. Traditional methods of public management focus on a linear method of inputs and outputs which is hard to follow with this cohort, who face complex needs and require support from a range of partners in a local system. A wide range of services and other factors influence the outcomes in peoples’ lives. Local partnerships of statutory and voluntary sector agencies therefore need to build shared ownership of the problem and continually learn and adapt in developing solutions, listening to people with lived experience and to emerging learning about systemic barriers and challenges from their frontline delivery.
What did you do?
We have embedded systems thinking into all our plans from the start, with all areas required to develop system-level theories of change and to identify a named system change lead locally. By acknowledging that local systems vary, and that local partners know their own system best, we have built in a high level of local flexibility. However, our Changing Futures prospectus established a set of core principles for areas to follow, including a focus on driving lasting system change. All of this means that alongside frontline delivery, areas are investing in their strategic partnership and system change capacity; looking at how improved data sharing and systems can improve their understanding of the problem; and are undertaking system mapping and lived experience engagement to identify key barriers and points of the local support system that need a specific priority focus.
The evaluation running alongside this also takes account of systems thinking, with evaluators supporting local system mapping sessions and social network analysis. Understanding to what extent and how areas have been able to drive local system change, and how this affects people’s experiences of services, will be a key part of the evaluation.
One benefit of systems thinking is the many voices and perspectives that this approach brings in. We have involved people with lived experience of multiple disadvantage in developing our core principles and set a requirement for each area to co-develop their delivery plans with input from people with lived experience.
What worked well?
It is still early in the programme, so we will see more as the approach develops and is embedded in areas. So far, we have found that our locally driven and system focused approach has helped generate strong local ownership, buy-in from a wide range of local partners and powerful momentum for change.
What didn’t work so well (what challenges or barriers did you encounter)?
Systems thinking can appear very abstract which is sometimes a challenge in supporting areas with their approaches. We have tried to overcome this with a support provider helping areas develop and think through their approaches, but it is something we are continually learning how best to develop and support. A further challenge is linking up with the range of other transformation and change activities across different parts of the system that also impact on local areas, from health transformation to probation changes. All of these present opportunities to improve local systems, but also mean lots of change and competing demands on local leaders from different parts of the system.
What were the outcomes of using systems thinking in your work?
The programme is still in the early stages, but a focus on systems change and systems thinking from the start has encouraged areas to think early about their wider partnerships and the long-term impact of their work. By looking outside the usual structures of service funding, Changing Futures has given local areas space to think about new approaches to tackle multiple disadvantage. In the longer-term, we hope that this programme will generate important learning that can lead to long-lasting and transformational change for a very vulnerable group.
Case study 11: Developing the business in human rights action plan
Richard Fitzgerald is an Operational Research Analyst at Department for Business, Energy, and Industrial Strategy (BEIS). This testimonial describes Richard’s personal experiences of using systems thinking to help develop a policy called the Business and Human Rights Action Plan.
What were you trying to do? What was the project and what were its overarching aims?
I was working as part of an internal consultancy in BEIS called the Operational Research Unit. This specific project was on a policy called the Business and Human Rights Action Plan. BEIS held the lead in terms of policy development but were dealing with lots of internal and external stakeholders. The aim of this policy was to ensure that businesses review their Human Rights impacts across national and international supply chains and take action to mitigate any harms. Businesses operating in the UK should have an awareness and responsibility for how suppliers overseas treat their own workforce and their sub-suppliers. This was the overarching aim of the Business and Human Rights Action Plan. This project involved multiple stakeholders with different approaches or points of view. There was no immediate consensus on what needed to be done or who was responsible for what, so the policy team invited me and my colleague to set up and facilitate a workshop with stakeholder representatives. The aim was to bring people together to reach a consensus and validate areas of concern.
Why did you think that a systems approach was right?
We were invited in because systems thinking had been used for a previous piece of work on a different policy relating to gender representation. This had involved a workshop with a broadly similar systems mapping approach. The policy sponsor was pleased with the outputs and invited us to use a similar approach for the Business and Human Rights Action Plan. Our team had also been encouraging the use of soft systems[footnote 2] for complex problems which had multiple viewpoints and no shared understanding of the whole system. Soft systems techniques help to solidify this shared understanding and give a clearer picture of key issues and interrelationships. Our previous work raised the profile of this technique, and our policy sponsor realised that this approach was a way to help crack other problems which had so far been intractable.
What did you do?
First, we organised a workshop with representatives for the main stakeholders involved in the Business and Human Rights Action Plan (for example, Department for International Trade, Foreign, Commonwealth and Development Office, Confederation of British Industry). These sessions were 2 to 3 hours long and it was important that these were as productive as possible.
At the start of the session, I emphasised the importance of the Chatham House rule to encourage people to talk freely. It was also important to emphasise that I was independent to the policy sponsor team to show that I had no pre-conceived views on the policy myself. This helped reassure participants that I would respect all viewpoints and give people a fair hearing. I took a systems approach to leading conversations and drawing out the potential conflicts that might impact policy goals. I then presented my assessment on what further work needed to be done before the policy could work in practice. We validated this as a group at the end of the session and everyone committed to delivering on specific outputs.
We also took photos of the workshop outputs and I used this to create a ‘first pass’ draft systems map in Vensim software. This highlighted the interrelationships and risks associated with the policy that the stakeholders had articulated in the session. We then validated this map with stakeholders and policy sponsors over the course of a few iterations. The map was then adopted by our sponsors as a reference guide to help explain the policy to other people and clarify responsibilities. Finally, this was converted into a massive printout for the office wall, as a visible reminder of what had been agreed.
What worked well?
Although systems thinking was not applied to the workshops per se, the sessions were structured with a systems approach in mind. I used the building blocks of a systems map in conversations with stakeholders without drawing it out in real-time. Systems thinking was also useful in setting up a framework for how to approach the session and helped us to home in on key emerging areas that were most important. The final map was converted into a printout that was circulated to people for comment and subsequently used as a reference point for policy professionals.
What didn’t work so well (what challenges or barriers did you encounter)?
The main barrier that I encountered was getting buy-in from stakeholders to go along with the technique itself. One problem that I have found in workshops is that people can get more hung up on the technique rather than the purpose of the workshop itself, which can detract from what you are meant to be talking about.
What were the outcomes of using systems thinking in your work?
The workshop generated a real consensus on who was responsible for different actions. There was also an agreement on which areas stakeholders needed to focus on going forward in terms of policy development. The systems map was effective in highlighting areas that we didn’t have a lot of knowledge on. For example, how would consumers react to publicity around infringement of human rights by a High Street brand? Would this influence their buying decisions and, if so, would this be a lasting effect? We initiated research to anticipate and uncover this type of reaction, which formed the basis for further work by the policy team.
Case study 12: Joining-up air quality and climate change policies
Rose Willoughby is a systems research scientist in the Department for Environment, Food, and Rural Affairs (Defra). This testimonial describes Rose’s personal experiences of using systems thinking to help join up air quality and climate policies.
What were you trying to do? What was the project and what were its overarching aims?
The aim of this project was to integrate thinking around climate change and air quality. When the government announced plans to achieve net zero carbon emissions by 2050, we saw an opportunity to integrate climate and air quality policy decisions.
Why did you think that a systems approach was right?
Climate change and air quality were historically seen as 2 separate issues, although greenhouse gases and air pollutants are co-emitted. A systems approach seemed like a really good way to join-up these 2 areas and build a shared understanding of how to simultaneously tackle both issues. There are many past examples of where actions have been taken to combat one of these issues but had a knock-on effect on the other. For example, diesel cars were incentivised to tackle greenhouse gas emission, but also had unintended consequences on air quality.
What did you do?
We used a soft systems methodology[footnote 2] to convene experts and facilitate knowledge exchange between stakeholders holding responsibility for different parts of the system. We identified stakeholders by deciding as a team what expertise we needed present. These included representatives from a number of government departments such as the Department for Transport, as well as the Climate Change Committee and Air Quality Expert Group. We designed workshops to ensure that a broad range of experts and policy design makers were brought together to share information.
To ensure that workshops were productive, we set expectations on what information we wanted to gather and what we wanted participants to gain from attending the workshop. We also completed a lot of pre-work and considered what information we should share in advance or during the workshop. For example, we pre-shared an information pack with participants to ensure that they came armed with knowledge on what the team wanted to get out of the workshops.
On the day, there was an excellent presentation from the Climate Change Committee; representatives were great at fielding questions and discussing what measures they had put forward to achieve net zero. This gave participants a good understanding of what each of these measures actually meant. People were then put into breakout groups which enabled valuable conversations on how different interventions might affect levels of specific air pollutants. We ensured that we had air quality and climate change experts in each room to facilitate conversations on what different interventions for climate change could mean for air quality.
What worked well?
Holding workshops at an early stage of the project helped to spark and enable conversations that contributed to our success. It ensured that our message on air quality was weaved into key thinking and strategy making by policy officials. It was great having a mix of policy leads in the room, and the workshops helped develop a shared understanding between these stakeholders in a way that felt open and engaging. Their perspectives helped us to develop a much wider breadth of knowledge on the subject matter, which enabled us to have lot more impact in the long-term. Bringing new perspectives and in-depth knowledge into the workshop meant that policy officials were able to further their understanding of how different policies might impact greenhouse gases and air pollutants.
The workshops also enabled us to start building informal networks. The timing of the workshop worked well because we were quick to act after the UK government announced their commitment to achieving net zero greenhouse gas emissions by 2050. We were well poised to get people thinking about different climate policies and ensure that they were taken into consideration. Important conversations were sparked early and allowed air quality to be considered upfront in climate policy decisions. The Climate Change Committee also submitted a progress report to parliament stating that air quality and health impact must be considered alongside climate change policies. Ultimately, taking a systems approach allowed us to get our message into key strategies and decisions.
What didn’t work so well (what challenges or barriers did you encounter)?
It was a challenge to organise the workshops at the time because there was no sense of urgency; the joining-up of air quality and climate change policies was not seen as a pressing issue at that time. It was also a challenge to gain buy-in from some stakeholders who could not immediately see why the problem was relevant to them.
What were the outcomes of using systems thinking in your work?
The obvious output was the report that the Air Quality Expert Group wrote up to summarise the findings of our workshop. This publicly available report shares key findings and highlights potential risks associated with different policies. For example, the report summarises the risks and hazards of potential climate policies (for example, the risk of bioenergy to air quality) which helps stakeholders consider how these could be mitigated. The Climate Change Committee also submitted a progress report to parliament stating that air quality and health impact must be considered alongside climate change policies.
Taking a systems approach has also enabled the Air Quality Team to proactively engage with different policy areas and have evidence-based conversations. Furthermore, we have raised awareness of the interlinkages between climate change and air quality. Ultimately, we have raised the profile of this issue so that policy officials are now aware that air pollution needs to be considered alongside greenhouse gas mitigation policies.
Case study 13: Ageing Foresight Project
Tom Wells is a deputy director at the Government Office for Science (Emerging Technology, Futures and Projects division). Stephen Bennett is co-head of Policy Lab at Policy Lab UK. This testimony describes Tom’s and Stephen’s personal experience of working together and using systems thinking to help deliver objectives in the Ageing Foresight project.
What were you trying to do? What was the project and what were its overarching aims?
The Government Office for Science led a Foresight project on the future of population ageing and collaborated with Policy Lab specifically to help policymakers think strategically about what population ageing would mean for the UK. Foresight projects use science and evidence to help ministers create policies that are more resilient to the future.
Why did you think that a systems approach was right?
Population ageing is one of those long-term, thorny issues that you can come at from multiple angles. Is it an NHS issue or pensions? Was technology coming to the rescue, or does it all boil down to education opportunities earlier in life? Or housing? As we got into the evidence, it became increasingly clear just how interconnected and mutually reinforcing the issues were. Good health makes it easier to keep active, both socially and in work. That is likely to mean someone is wealthier in later life and better able to afford good housing… and in turn they are likely to be associated with better health outcomes. There’s a vicious circle version of that. Whether you took an individual focus – how do we help people age well? – or a national perspective – how do we make sure the UK makes the most of population ageing? – our challenge was to bring these things together in a way where people could quickly visualise the linkages.
What did you do?
The Government Office for Science commissioned the Operational Research team in BEIS to develop a systems map through a series of workshops. They created a detailed map in PowerPoint, with lots of nodes and connections. Policy Lab then asked designers to create and deploy a clear visual language which brought out the important systemic fundamentals, including reinforcing loops, critical nodes, and unintended consequences. That map then was an input to workshops we collectively ran for policy officials to think through interventions in the “ageing system” that would lead to better outcomes for people and the UK by 2040.
What worked well?
The systems approach really helped the project team to develop a coherent narrative around ageing and how all the different levers fitted together to affect outcomes across departments. It also led us to one of the solutions to the challenge – better cross-government working. If we respond to ageing by working in silos, we will never solve some of the structural and systemic issues or take advantage of important cross-sector benefits. Finally, the designed map was a useful prompt to challenge policymakers. We could help them see that their policy challenge may lie in one part of the system, but the solution may lie in another part - and that part may not necessarily be one that they had jurisdiction for.
What didn’t work so well (what challenges or barriers did you encounter)?
We learnt that systems maps can paralyse people. The final map is often huge, messy, and complex. It is intimidating to anyone presented with it, whether they be stakeholders, policymakers, or ministers. Working with designers we have learnt some useful tactics to overcome this. First, clear and intentional visual language can bring out key systems concepts, like reinforcing circles or critical nodes. Second, it is helpful to build up the map gradually using different layers, so that readers can orient themselves before the map becomes too complicated. Third, narratives are extremely important. The map is really just a device to identify systemic policy stories relevant to the challenge - for example the interplay of education, housing, and health in ageing. These stories are as important as the map itself.
The facilitator plays an important role here helping people navigate, contribute to, and make sense of the map, although ultimately the design and narrative needs to be strong enough that people can use it without that person. Finally, our map was entirely qualitative: for example, X helps or hinders Y. We didn’t say how strong the connection was or how much impact each factor had on the next. That would be an interesting additional layer of analysis to help a policymaker identify what would make the biggest difference - or where the government should prioritise its efforts.
What were the outcomes of using systems thinking in your work?
In the end the systems approach was integral into the Industrial Strategy Ageing Society Grand Challenge that we helped BEIS design. That Challenge focused on the intersection of education, public health, innovation, and technology. We could not have helped them think through all the aspects of ageing, how they fitted together and how that could be addressed through industrial policy, without having taken a systems approach. The fact that you had an industrial strategy talking about much broader issues, and even measuring success in terms of public health, is a sign that the systems analysis landed well with our colleagues.
A systems map of the different factors involved in wellbeing, contributed by Tom Wells and Stephen Bennett
View the full size systems map.
Case study 14: Establishing a systems team to inform land use policy
Dan McGonigle is the head of Systems, Innovation and Futures in the Department for Environment, Food and Rural Affairs (Defra). This testimonial describes Dan’s personal experience of setting up a systems team in Defra and leading on systems programmes across the department.
What were you trying to do? What was the project and what were its overarching aims?
I joined the Chief Scientific Adviser’s Office in Defra in May 2019 to set up a new research capability in systems thinking. At the time, environmental and agricultural policies were highly fluid as a result of Brexit; the department was developing new bills on the environment, agriculture, and fisheries. The 25 Year Environment Plan had recently been published setting ambitious and broad policy goals. With so much changing, the systems team was set up to help the department navigate interdependencies and trade-offs between policy goals.
My team consisted of fifteen people, including 6 externally seconded academics who came into Defra 2 or 3 days a week to help develop the systems programme. Our programme was split thematically into 5 cross-cutting areas relating to different parts of Defra’s agenda. My role was to establish a systems team in Defra and to establish systems approaches that can be integrated into the way that policy is developed.
Land use is at the core of much of what the department does. It affects food production, bioenergy, recreation, water quality, air quality, biodiversity, resilience to flooding and many other outcomes. Our transition to net zero will have fundamental implications for land use, so I set up a programme to help recognise the trade-offs between outcomes.
Why did you think that a systems approach was right?
We were dealing with highly complex systems involving many interacting environmental, social, economic and political processes. The interactions that feed into policy outcomes are complex, evidence is fragmented, and we have indirect control over the nature of these policy areas and the way that land is used. In many cases issues are contested – different groups have different goals, perspectives, and knowledge of the system. We needed to find ways to cut through this complexity and to help different policy teams to come to a common understanding.
What did you do?
We broke the problem down into 3 sets of questions:
-
The social, environmental, and economic drivers of land use change: What are the main drivers and when do particular drivers become dominant? We held workshops with academics, farmers and other stakeholders and developed causal loop maps to explore interactions between drivers and shed light on areas for policy interventions.
-
Configuration of land use: What is the trajectory of land use in different parts of the country? How does this align with our policy goals? We held regional workshops to identify trajectories of change and policy workshops to identify land allocation ‘rules’ which colleagues built into a spatial model.
-
Trade-offs between multiple environmental outcomes: How might actions to meet net zero affect water quality, air quality, flooding, wildlife, water resources, biodiversity, access to land for recreation etc? We reviewed evidence and held expert elicitation workshops with academics to develop cross-impact matrices to show potential areas of conflict. We also worked with BEIS to develop an overall land use systems tool, allowing users to explore the overall system.
What worked well?
We used lots of workshop-based mapping approaches to develop a shared understanding of the interactions between different factors in the system. To do this, we brought together expert witnesses and academics from different parts of the country to help identify the major drivers of land use change. This provided a space for dialogue between different disciplines and interest groups. We also used ideas from Critical Systems Heuristics to explore differences in perception, goals, and knowledge.
The process of engaging people with different purposes, knowledge, and value sets on how the system operates was invaluable. Having a collaborative and open conversation worked well and meant that we got a shared output and shared goals from workshops. We worked with stakeholders to develop causal loop maps and used these to understand the major factors involved. Causal loop maps are often only intelligible to those involved in drawing them, so we found it worked well to engage stakeholders in this process.
We used the opinions and perspectives of experts in this area to deepen our own understanding of the system and develop a policy dialogue. Since these workshops, we have taken our perspectives forward to begin developing some systems dynamics modelling of the land use system.
What didn’t work so well (what challenges or barriers did you encounter)?
We treated this whole programme as an action learning process. There are plenty of things that have not worked so well and that we have learnt from. For example, people viewed the land use system from different angles and had different goals. Bridging these can be difficult and this needs to be built into the design of how you structure your work. Another challenge was the difference in language that people use to talk about the same system. Fundamentally, different stakeholder values can also be challenging.
What were the outcomes of using systems thinking in your work?
Systems thinking helped bring together policy teams across the department and helped us to frame the land use problem in a more systemic way. Our work is helping to frame a more holistic approach to land use policy, and our systems approach to framing the problem has changed the way the department thinks about these types of issues and provided a common language to overcoming these.
We have built on our experiences from our work to develop a Systems Primer for Defra staff, which sets out some broad considerations for applying systems thinking:
- to frame policy
- for two-way learning at the science-policy interface
- in working with stakeholders
We also developed a stepwise approach which provides a how-to guide to applying systems thinking in policy development.
Further examples
The case studies listed in this section highlight how systems thinking has been used in a policy development or public management setting. It is not designed to be a comprehensive selection of all applicable examples but is a selection of examples that seemed particularly accessible and relevant to civil servants.
Government publications
Net Zero strategy
A study published by the Department for Business, Energy and Industrial Strategy (2021). Describes how a systems approach will help deliver a better transition towards the net zero emissions target. Includes a causal loop map that was used to visualise interactions between factors that need to be considered in the roll-out of electric vehicles.
‘Net Zero Strategy: Build Back Greener’
Understanding child and adolescent wellbeing
A study published by the Department for Education (2019). Uses causal loop maps to capture the interdependencies and interrelationships between the various factors influencing child and adolescent wellbeing.
‘Understanding child and adolescent wellbeing: a system map’
Independent review of building regulations and fire safety
A study published by the Department for Levelling Up, Housing and Communities and led by Dame Judith Hackitt (2018). Details how causal loop maps were used to review high-rise building safety and reveal unexpected areas for intervention.
‘Independent Review of Building Regulations and Fire Safety: Hackitt review’
Child protection review
A study published by the Department for Education and led by Professor Eileen Munro (2011). Details how causal loop maps were used to help understand past failures in the child protection system and help inform new policy recommendations.
‘Munro review of child protection: a child-centred system’
External publications
Beyond Net Zero, Design Council
A publication from the Design Council (2021). Describes how a systemic design approach can be used to design new interventions that will help achieve net zero targets.
‘Beyond Net Zero: A systemic design approach ’
Critical Capabilities, Royal Academy of Engineering
A report produced by the Royal Academy of Engineering (2021). Details how systems approaches can be used to help build whole society resilience and leverage the UK’s strengths to address emergencies of the future.
‘Critical Capabilities: Strengthening UK Resilience ’
Decarbonising construction, Royal Academy of Engineering and National Engineering Policy Centre
A report by the Royal Academy of Engineering and National Engineering Policy Centre (2021). Uses the concept of systems levers where action taken now will result in rapid decarbonisation of the construction sector.
‘Decarbonising construction: building a new net zero industry’
Human learning systems case studies
A selection of human learning system case studies (2021). Details how human learning systems can be used to improve public service and management.
Human learning systems: Public service for the real world.
Rapid ‘low regrets’ decision making, Royal Academy of Engineering and National Engineering Policy Centre
A report by the Royal Academy of Engineering and National Engineering Policy Centre (2021). Uses elements of a systems approach to identify low regret decisions that can be taken now to decarbonise the UK economy.
‘Rapid ‘low regrets’ decision making for net zero policy’
Transport strategies for Net-Zero systems by design, OECD
A book from OECD (2021). Details how systems thinking can be used to inform transport strategies that will help achieve net zero targets.
‘Transport strategies for Net-Zero systems by design’
Getting to net zero: video explainers, National Engineering Policy Centre
A series of 5 short films from the National Engineering Policy Centre (2021). Explain why reaching net zero in time requires a new approach to transforming infrastructure, and how a systems approach can help tackle such a complex and broad challenge.
‘Getting to net zero: a systems approach’.
Safer Complex Systems and Safer Complex Systems Strategy
Reports produced through the Engineering X Safer Complex Systems Programme with the Royal Academy of Engineering (2020). Draws on complex systems theory and real-world experience of complex systems engineering and operation to provide an initial framework for complex infrastructure systems safety management.
Sustainable living places
A report by the Royal Academy of Engineering and National Engineering Policy Centre (2020). Provides a systems perspective on planning, housing and infrastructure.
‘Sustainable living places – a systems perspective on planning, housing and infrastructure’
Engineering Better Care
A report produced by the Royal Academy of Engineering, the Academy of Medical Sciences, Royal College of Physicians and Future Hospital (2017). Details how a systems approach can be used to help make improvements to the UK’s Health and Social Care System.
‘Engineering better care: a systems approach to health and care design and continuous improvement’
Systems Approaches to Public Sector Challenges
A publication by OECD (2017). Details how systems approaches can be used in the public sector to help solve complex or ‘wicked’ problems and includes a selection of case studies.
‘Systems approaches to public sector challenges: working with change’
Systems Thinking: An introduction for Oxfam programme staff
A publication by Oxfam (2015). Introduces the concept of systems thinking for Oxfam staff and the broader development community. Contains case studies and questions for staff to consider, as well as useful tools and links to resources on systems thinking.
‘Systems Thinking: An introduction for Oxfam programme staff’.
Acknowledgements
Case study authors
The case study authors (in alphabetical order):
-
Nafeesah Ameerudden, Department for Business, Energy and Industrial Strategy
-
Rachel Bennett, Department for Work and Pensions
-
Stephen Bennett, Policy Lab
-
Shane Britton, Department for Levelling Up, Housing and Communities
-
Hazel Challenger, Ministry of Justice
-
Richard Fitzgerald, Department for Business, Energy and Industrial Strategy
-
Jonathan Hoare, Department for Business, Energy and Industrial Strategy
-
Niki Jobson, Defence Science and Technology Laboratory
-
Adam Mackenzie-Jones, Department for Business, Energy and Industrial Strategy
-
Caitlin Jones, Department for Environment, Food and Rural Affairs
-
Richard Lewis, Department for Levelling Up, Housing and Communities
-
Dan McGonigle, Department for Environment, Food and Rural Affairs
-
Jennifer Panting, Department for Business, Energy and Industrial Strategy
-
Gary Preece, Department for Environment, Food and Rural Affairs
-
Mark Renshaw, Department for Business, Energy and Industrial Strategy
-
Isabel Ruckelshauss, UK Research and Innovation
-
Tom Wells, GO-Science
-
Rose Willoughby, Department for Environment, Food and Rural Affairs
We are grateful to the authors who contributed their time and knowledge to contribute to the case study bank.
Government Office for Science Systems Thinking Team
The Government Office for Science Systems Thinking Team (in alphabetical order):
-
Jo Foreman
-
Rachel Hardy
-
Chris Pook
-
Claire Sarell
-
Sarah Steiner
-
Stuart Wainwright
Suggested citation
‘Systems thinking: case study bank’, Government Office for Science (2022).
Contact us
Please contact systems@go-science.gov.uk for further information.
References
-
Shared Outcomes Fund: round 2 ↩
-
Soft systems methodology developed by Peter Checkland (Checkland P. 1981. Systems Thinking, Systems Practice. John Wiley: Chichester). ↩ ↩2 ↩3
-
Rich pictures are explored in the Civil Servant’s Systems Thinking Toolkit ↩ ↩2
-
The viable systems model developed by Stafford Beer (Beer S. 1979. The Heart of Enterprise, Wiley Chichester; Beer S. 1985. Diagnosing the System for Organisations, Wiley Chichester) ↩
-
System archetypes are patterns of behaviour of a system. ↩
-
A framing question is a compelling question that guides your work, and is especially relevant to acting as an anchor when creating maps of your system. ↩
-
Microsoft Visio is a data visualisation app ↩",2
156,"The Lifecycle of Software Objects
|Author||Ted Chiang|
|Original title||The Lifecycle of Software Objects|
|Cover artist||Christian Pearce|
|Country||United States|
|Language||English|
|Genre||Science fiction novella|
|Publisher||Subterranean Press|
Publication date
|2010|
|Media type||Print (Hardcover)|
|Pages||150 pp (first edition, hardback)|
|ISBN||978-1-59606-317-4 (first edition, hardback)|
|OCLC||567188308|
""The Lifecycle of Software Objects"" is a novella by American writer Ted Chiang, originally published in 2010 by Subterranean Press.[1] It focuses on the creation of digital entities and their growth as they are raised by human trainers over the course of many years. The novella received critical praise, winning the 2011 Locus Award for Best Novella and the 2011 Hugo Award for Best Novella.
Plot[edit]
Ana, a former zookeeper, begins working for software firm Blue Gamma. The firm is creating “digients”, or digital entities. The digients are designed by another Blue Gamma employee, Derek. They are relatively intelligent and have rudimentary speech; Blue Gamma begins to sell them as virtual pets.
Over the course of many years, Ana grows close to a digient named Jax. The digients become more intelligent and develop their own personalities and quirks. Eventually, Blue Gamma goes bankrupt. The digients are cut off from the wider internet. Derek and Ana disagree on the best way to raise funds to transfer the digients to a new system. Options include modifying their brain structures to serve as sexual companions for humans, using the digients as employees, or raising funds from sympathetic donors. Derek and Ana debate the nature of consent, experience, adulthood, and personhood with respect to the digients. With the consent of his digient, Derek sells the rights to a sex toy company. Ana plans to continue raising Jax, promising to discover what ""adulthood"" means for a digital being alongside him.
Major Themes[edit]
Writing for the Los Angeles Review of Books, Joan Gordon writes that the novella explores interesting ethical questions including the meaning of consciousness. She also writes that the story explores the way in which ""subjects – human or non-human – become enmeshed in and trapped by the capitalist system"". The story explores this theme with digients who are treated both as company property and as individuals.[2]
Elizabeth Bear compared the raising of the digients to parenthood and pet ownership. The human caretakers must balance the digients' right to self-determination and choose how many mistakes that the digients should be allowed to make.[3]
Style[edit]
Joan Gordon wrote that the tone of the novel is cool and that emotions are tamped down. This emotional distance allows the reader to take the novella's ethical questions more seriously.[2] Elizabeth Bear felt that the story's lack of physical grounding contributed to the feeling that it takes place in a virtual setting.[3]
Background[edit]
This is Chiang's first novella to be published originally in hardcover.[citation needed] It is the second written work by Chiang that is long enough to stand alone, after The Merchant and the Alchemist's Gate.[4] The tale was later included in Chiang's second collection, Exhalation: Stories, released in 2019.
The Subterreanean Press edition of the novella features ten internal paintings and cover art by Weta Workshop artist Christian Pearce.[5] Each of the novella's ten chapters is preceded by a map designed by Jacob McMurray.
Reception and Awards[edit]
Author Elizabeth Bear praised the work for its discussion of complex topics relating to artificial intelligence, calling it ""very peculiar ... in the absolute best way possible"".[3] Writing for Publishers Weekly, author Charles Stross praised the work, calling it a ""very rare thing: a science fictional novel of ideas that delivers a real human impact"".[4]
“The Lifecycle of Software Objects” won the 2011 Locus Award for Best Novella[6] and the 2011 Hugo Award for Best Novella.[7]
References[edit]
- ^ [1] Archived December 11, 2010, at the Wayback Machine
- ^ a b Joan Gordon (27 Apr 2012). ""Winsome Ghosts in the Machine: Joan Gordon's ""The Lifecycle of Software Objects"""". Los Angeles Review of Books. Retrieved 13 May 2022.
- ^ a b c Elizabeth Bear (1 Sep 2010). ""Your Tamagotchi misses you. (Being a review of Ted Chiang's The Lifecycle of Software Objects)"". Tor.com. Retrieved 13 May 2022.
- ^ a b Charles Stross (21 June 2010). ""Fiction Book Review: The Lifecycle of Software Objects by Ted Chiang"". Publishers Weekly. Retrieved 13 May 2022.
- ^ ""Christian Pearce"". Christian Pearce. Retrieved 2014-02-16.
- ^ ""Announcing the 2011 Locus Award Winners"". Tor.com. 25 June 2011. Retrieved 16 Feb 2014.
- ^ ""Announcing the 2011 Hugo Award Winners!"". Tor.com. 21 Aug 2011. Retrieved 13 May 2022.",8
157,"Teixcalaan #1
A Memory Called Empire
Ambassador Mahit Dzmare arrives in the center of the multi-system Teixcalaanli Empire only to discover that her predecessor, the previous ambassador from their small but fiercely independent mining Station, has died. But no one will admit that his death wasn't an accident—or that Mahit might be next to die, during a time of political instability in the highest echelons of the imperial court.
Now, Mahit must discover who is behind the murder, rescue herself, and save her Station from Teixcalaan's unceasing expansion—all while navigating an alien culture that is all too seductive, engaging in intrigues of her own, and hiding a deadly technological secret—one that might spell the end of her Station and her way of life—or rescue it from annihilation.
Now, Mahit must discover who is behind the murder, rescue herself, and save her Station from Teixcalaan's unceasing expansion—all while navigating an alien culture that is all too seductive, engaging in intrigues of her own, and hiding a deadly technological secret—one that might spell the end of her Station and her way of life—or rescue it from annihilation.
462 pages, Paperback
First published March 26, 2019
About the author
Ratings & Reviews
Friends & Following
Create a free account to discover what your friends think of this book!
Community Reviews
5 stars
16,310 (40%)
4 stars
15,694 (39%)
3 stars
6,053 (15%)
2 stars
1,567 (3%)
1 star
560 (1%)
Can't find what you're looking for?
Get help and learn more about the design.",8
159,"- Bitcoin fell to about $17,749, and ether fell to about $897 on Saturday afternoon, as the sell-off in the crypto market accelerates.
- Bitcoin bounced back to around $18,955 and ether was trading at about $955 just after 8 p.m. ET.
- Bitcoin peaked at $68,789.63 in November.
Bitcoin plunged to about $17,749 and ether fell to about $897 at around 4:15 E.T. on Saturday afternoon, as the sell-off in the crypto market accelerates. The world's two most popular cryptocurrencies are down more than 35% in the past week, as both breach symbolic price barriers.
Bitcoin bounced back to around $18,955 and ether was trading at about $995 just after 8 p.m. ET.
The carnage in the crypto market is partly caused by pressure from macroeconomic forces, including spiraling inflation and a succession of Fed rate hikes. We have also seen these blue chip cryptos track equities lower. It doesn't help that crypto firms are laying off large swaths of employees, and some of the most popular names in the industry are facing solvency meltdowns.
Bitcoin peaked at $68,789.63 in November. Ether peaked at $4,891.70 that same month. Bitcoin last traded this low around December 2020.
Here's how we got here.
Monday
The week started with crypto prices plummeting, and bitcoin falling as much as 17% at one point in the day. It seemed like the crypto winter was here.
In the chaos, Celsius, a major crypto staking and lending firm, shocked the market when it announced that all withdrawals, swaps and transfers between accounts have been paused due to ""extreme market conditions."" In a memo addressed to the Celsius Community, the platform also said the move was designed to ""stabilize liquidity and operations.""
Celsius effectively locked up its $12 billion in crypto assets under management, raising concerns about the platform's solvency. The news rippled across the crypto industry, reminding some of what happened in May, when a failed U.S. dollar-pegged stablecoin project lost $60 billion in value and dragged the wider crypto industry down with it.
Celsius was known for offering users a yield of up to 18.63% on their deposits. It's like a product a bank would offer, except with none of the regulatory safeguards.
Those crazy high yields were what eventually came under scrutiny.
""This risk certainly seems like it's just the beginning,"" said John Todaro, Needham's vice president of crypto assets and blockchain research.
""What I would say is on the decentralized side — a lot of these DeFi protocols, a lot of those positions are over collateralized, so you shouldn't quite see the underfunding situation that could happen with centralized borrowers and lenders. But that being said, you could still see a lot of liquidations with that collateral being sold off on DeFi protocols,"" continued Todaro.
Tuesday
Crypto markets appeared to stabilize on Tuesday, with bitcoin hovering at around $22,000 and ether at around $1,100.
Investors were assessing the fallout of Celsius, and meanwhile, another crypto firm joined a growing list of companies cutting staff to try to shore up profits.
Coinbase announced it was laying off nearly a fifth of its workforce due to crypto volatility. The company had previously cut spending and even rescinded job offers in the hopes of stabilizing its business.
""We had the recent inflation report that came out that I think surprised many folks,"" explained President and Chief Operating Officer Emilie Choi.
""We've had Jamie Dimon and others talk about an upcoming economic hurricane and so given what's happening in the economy, it feels like the most prudent thing to do right now,"" continued Choi.
Crypto companies across the board are looking for ways to cut costs, as investors rotate out of the riskiest assets, pulling down trading volumes.
Crypto.com recently announced a staff reduction of 260 people, as did Gemini, which said it would lay off 10% of its workforce — a first for the U.S.-based cryptocurrency exchange and custodian.
Wednesday
MicroStrategy CEO Michael Saylor appeared on CNBC Wednesday morning to discuss concerns around his firm, which has made a $4 billion bet on bitcoin. Saylor has said the company doubles as the first and only bitcoin spot exchange-traded fund in the U.S., so investing in MicroStrategy is the closest you'll get to a bitcoin spot ETF.
MicroStrategy has used company debt to purchase bitcoin, and in March, Saylor decided to take another step toward normalizing bitcoin-backed finance when he borrowed $205 million using his bitcoin as collateral — to then buy more of the cryptocurrency.
""We have $5 billion in collateral. We borrowed $200 million. So I'm not telling people to go out and take a highly leveraged loan. What I am doing, I think, is doing my best to lead the way and to normalize the bitcoin-backed financing industry,"" said Saylor, who added that publicly traded crypto miner Marathon Digital also took out a credit line with Silvergate Bank.
As bitcoin prices tanked this week, investors worried the company would be asked to put up more collateral for its loan, but Saylor said the fears were overblown.
""The margin call is much ado about nothing,"" Saylor told CNBC earlier this week. ""It's just made me Twitter famous, so I appreciate that...We feel like we have a fortress balance sheet, we're comfortable, and the margin loan is well managed.""
Then on Wednesday afternoon, the Federal Reserve raised its benchmark interest rates three-quarters of a percentage point in its most aggressive hike since 1994. The Fed said the move was made in an effort to curb sky-high inflation.
Crypto prices initially rallied on the news as investors hoped we could avoid a recession, but that rally was short-lived.
Thursday
We were back in the red on Thursday. Bitcoin fell to around $20,000, to prices it hadn't seen since the end of 2020.
The losses were closely tied to a sell-off on Wall Street, in which the Dow fell 700 points to its lowest level in more than a year.
It appears that investors can't shake the fears of recession, and some say it could take time for cryptocurrencies to recover from the sell-off in riskier assets.
""I think that we're in a long drawdown period here,"" Jill Gunter, Espresso Systems co-founder & chief strategy officer, told CNBC's Squawk on the Street.
""I think that we've taken the elevator down, and I think that we, as an industry, are going to have to take the stairs back up and climb out by building real utility,"" she said.
Gunter said that, in many ways, what we're seeing is a ""healthy washout.""
""One doesn't want to, as a builder, as an investor for the long-term... be in a market where it's being driven by just short-term price action, by speculation, as, let's be honest, the crypto market has been largely over the last couple of years,"" continued Gunter.
Friday into Saturday
Carnage in the crypto markets shows no signs of slowing down, as bitcoin and ether continue their sell-off at a rapid clip on Saturday afternoon.
This comes as crypto hedge funds and businesses face growing questions about insolvency.
""We had financial instability because of this opaque leverage, you just couldn't tell where all these risks were building up,"" Paxos CEO & Co-Founder Charles Cascarilla told CNBC.
""In some ways, this is just an age old story. You're borrowing short and lending long. And I think it's really unfortunate that people lost money, and I think it will, in some ways, set back the space, because you will lose some early adopters or some of the people who just came in new to the space,"" continued Cascarilla.
But Cascarilla also says that investors are still looking for quality crypto investments.
""The fundamental technology here and the adoption curve that we see, the institutions that are coming in, how you can get your financial system to operate at the speed of the internet, those are things that need to happen,"" he said.",8
160,"Girls in Yoga Pants Explain The Higher Education Apocalypse
We'll miss it when it's gone.
Students used to show up drunk to my class, especially during football season. They filled Gatorade bottles with vodka.
At least they smiled through my lectures, even if they didn’t read a single page of Marilynne Robinson’s Housekeeping, which they considered the most boring book ever written.
Students started drinking during their Thursday afternoon classes. They kept going through the entire weekend, which included all of Friday. Honestly, I was ready for a drink by Thursday afternoon myself. Back then I was teaching for a big state university with a student population somewhere in the neighborhood of 30,000. I taught four classes a semester, for a grand total of more than 100 students. Some nights, I really did walk straight from my last class to a bar.
My friends and I lived across the street from campus because it was cheap. It was also unbearable. We were constantly calling the police on frat bros and their girlfriends. That’s how college worked in the before times.
It’s a completely different landscape now, full of consequences for how badly higher education has been managed. This current generation isn’t going to college, for a few big reasons. The public seems to finally be noticing. The last few weeks have seen a number of major stories about the sharp drop in enrollments, in places like Newsweek and The Chronicle of Higher Education, and so on.
We’ve been predicting it for a while…
Anyway, look at this girl.
Isn’t she flexible?
Kids aren’t going to college anymore.
Half of Gen Z has decided they’re going to skip college. I’m not kidding. The polls show 50 percent of them won’t do it.
You can’t blame them. College has gotten insanely expensive, and most of them haven’t kept up with the times. Only the most elite universities offer anything remotely worth the cost.
Enrollment is down 10 percent.
That’s a million students.
Hey. I know, I know.
You don’t care.
Sabrina cares, though. She doesn’t want to spend the rest of her life posing for photos like this one.
She wants a future.
Americans hate education.
The average American doesn’t care about college or universities at all. They resent education, and they consider professors a bunch of freeloaders who get summers off (no, we’re unemployed for three months). They constantly complain about the time they wasted in the classroom.
To most people, college means football and parties.
That’s it.
The last few generations didn’t go to college to get an education. They went there to get laid. They went there to make friends. They went there to avoid the grueling responsibilities of adulthood.
It served a cultural purpose.
Now that’s fading.
At least, that’s what Tabitha thinks:
College kept young adults out of trouble.
The economy actually needs colleges and universities, for purely practical reasons. They’ve been keeping about 15–20 million young adults out of the job market. They suppress unemployment.
If nothing else, affordable college was a holding tank for America’s youth. We kept them occupied and entertained.
Well, not anymore.
Young adults aren’t falling for the scam. They see what’s going on. They’re not going to take out tens of thousands in student loans, then watch their politicians jack up interest rates while dangling “forgiveness” in front of them to win elections.
Instead, they’re doing literally anything else. They’re working for Amazon. They’re driving an Uber. They’re delivering groceries. They’re trying to get famous on their phones. They’re playing video games. They’re hawking crypto. They’re mooching off their parents.
Hey, so would I.
Just take it from Naomi.
She wants to be a fitness influencer:
Colleges are a total train wreck.
I’m going to tell you a secret.
The average university is completely dysfunctional. I would know. I’ve been working in higher education my entire life. I’ve seen it up close. One of my last bosses used to jerk off in people’s offices. He got fired, but quickly found a job at another university.
That happens all the time.
For every good professor like me who’s trying hard, there’s another who either doesn’t care or simply can’t get it together. Faculty can waste two hours in a meeting, and all they manage to do is create more committees with more meetings.
It’s a nightmare.
The higher up you go, the worse it gets. Deans and vice chancellors make around $150,000 - $200,000 a year. They don’t do much but send out confusing emails all day. They’re so sleep-deprived and addled with caffeine, they can barely think.
Boards of trustees preside over it all. These are made up of millionaires and billionaires. They call the shots, not us. They don’t care about anything but profits, so they ratchet up tuition every year while cutting student services and upping class sizes.
No wonder Gen Z wants to bail on college.
It’s corrupt as hell.
That’s according to Olivia, who dropped out of college to make fitness videos on TikTok:
A lot of them are going to collapse.
Experts were already predicting an “enrollment” cliff for universities, starting around the year 2025. Millennials didn’t have kids like their parents did. They were too broke. Now we’ve got a shrinking population.
The pandemic kickstarted the enrollment cliff early. That goes on top of the new lack of interest in getting an education.
It’s a triple whammy.
A lot of colleges aren’t managing a graceful decline. Greed and corruption are making the transition worse. A lot of smaller, regional universities won’t survive. Higher education is going to revert to what it used to be before the G.I. Bill made it egalitarian, a place where you sent your kids if you had money. Bigger, elite universities will do okay. They might even prosper, because they’ll pick up all the college-bound students from dying institutions.
By 2030, higher education will be a shell. Teens will go straight into the workforce, probably even before they graduate high school.
In some ways, it’ll be a good thing. We might see a revival of vocational and trade schools, along with stronger unions.
That’s a big if…
The current trend is pointing toward something darker, a large mass of under-educated, undertrained youth chasing easy money, not because they’re immature, but because other paths have shut down.
Thank Melanie for this insight:
We’re going to regret it.
In theory, higher education could be great.
If only they followed the John Dewey model. That guy was smart. He wrote a number of books and articles about the value of progressive education. He said students shouldn’t be sitting in stuffy classrooms. Their professors should build learning labs for them.
Education should be fun.
It should be exciting.
Above all, education is supposed to build citizens. It’s supposed to give them practical skills, but it’s also supposed to show them how our government works. It’s supposed to expose them to the history of our culture, and the world around them.
Despite some awful experiences, I actually got that education. Maybe I had to teach myself a lot of the practical skills I’ve got now, but I definitely learned our history. I learned the importance of civics and culture, and how something as seemingly insignificant as fonts and typeface could lead to world-changing innovations.
Education forms the foundation of a healthy economy, and a healthy democracy. We could have something like that, if we paid teachers well and stopped filling universities with overpaid administrators. We could have something like that if we made real education affordable again, and not a privilege for the rich.
The question is, do we want it?
I’m not sure.
I wonder what Erica thinks:
We’ve defunded education.
The public gets all up in arms anytime you mention defunding the police. Well, look around. We didn’t do that.
The police are very well funded. Campus police at some universities have armored vehicles now. Meanwhile, we’ve systematically defunded classrooms. Every year, states have cut funding to schools and colleges. Teachers use their own money to buy school supplies. A lot of them can’t even support themselves.
It’s been like that for decades.
It has consequences.
For starters, our politicians are getting dumber. Maybe you’ve noticed. It’s not a fluke that we’ve got more lunatics and conspiracy theorists in Congress than ever. It’s not an accident that misinformation has infested our culture. All of this is what happens when you spend decades attacking education and under-investing in it.
The best teachers quit.
Students opt out.
Professors like me have to fill articles like this with yoga photos to keep people’s attention. And it’s only going to get worse. Our politicians are going to get dumber. Our youth are going to get more restless and desperate. Misinformation is going to get more outlandish. That’s our future, as predicted by the movie Idiocracy.
See…
Gen Z is only giving up on education now because prior generations already gave up on it, a long time ago.
To quote the lovely Amelia, pictured below:
You get what you pay for.
OK Doomer is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
I would have read this article without the provocative title, but it certainly sparked my curiosity.
You have succinctly described the thoughts I have had for many years. Great article.
Thank you for your valuable insight.",4
161,"On the not-so-infrequent nights when I’m plagued by insomnia, no combination of melatonin, weighted blankets, and white noise will do. Just one cure for my affliction exists: my cat Calvin, lying atop my shoulder, lulling me to sleep with his purrs.
For veteran members of Club Purr, the reasons are clear. A purr is warm tea, a roaring fire, and fresh-out-of-the-oven cookies, all rolled into a fleece-lined hug; it is the auditory salve of a babbling brook; it is coffee brewing at dawn. It is emotional gratification incarnate—a sign that “we’ve made our pets happy,” which just feels darn good, says Wailani Sung, a veterinary behaviorist at the San Francisco SPCA.
But purrs—one of the most recognizable sounds in the animal kingdom—are also one of the most mysterious. “No one, still, knows how purring is actually done,” says Robert Eklund, a phonetician and linguist at Linköping University, in Sweden. Nor can experts say, exactly, what purring means. Cats purr when they’re happy—but also sometimes when they’re anxious or afraid, when they’re in labor, even when they’re about to die. Cats are perhaps the most inscrutable creatures humans welcome into our homes, and purring might be the most inscrutable sound they make.
There is, at least, some consensus on what purring is. In the strictest sense, the sound is a rhythmic, rumbly percolation that’s produced during both exhales—as is the case with most typical animal vocalizations—and inhales, with no interruptions between. Purrers also run their motor with their mouths entirely closed, like little feline ventriloquists; the sound simply springs out of the body at a frequency that roughly spans the range between 20 and 150 Hertz. Back in the 1960s, one scientist posited that purring was the product of blood percolating through the vena cava, a vessel that returns the body’s blood to the heart; that notion was later disproved. Now it’s generally understood that the source is the voice box: The brain pings electric signals to the vocal folds, prompting them to flutter open and shut like little muscular doors.
Lots of animals can imitate the sound of purring, among them bears and guinea pigs. But only a small number of creatures can cook up a bona fide version of the burbly noise: In addition to house cats, genets—little cat look-alikes native to Africa—can do it; so can lynx, ocelots, and dozens of other smaller members of the felid family. Eklund recounted for me how one captive cheetah, named Caine, emitted booming purrs from “the second he woke up to the second he fell asleep,” he told me. But lions, tigers, and jaguars can’t rouse the same rasps; scientists have not documented any cats that can both purr and roar. Scientists can’t say for certain what separates the purrs from the purr-nots. It may have something to do with the length, shape, or thickness of certain species’ voice box, or the tissue architecture that surrounds it; or perhaps it’s the squishiness of their hyoid, a U-shaped bone suspended in the throat. Or maybe not. Purring isn’t easy to study: Felines aren’t usually keen on producing the sound around researchers in labs.
Whatever its mechanical basis, purring seems hardwired into certain cats from birth. They start revving their little locomotor engines within days of exiting the womb, while still blind and deaf. Kittens and mothers seem to exchange the sounds as a form of early communication, swapping essential messages such as I’m hungry and Hey, here comes Mom, says Hazel Carney, a cat veterinarian and purr expert based in Idaho, where she also cares for her own three cats—Wyatt Earp, Calamity Jane, and Hi Ho Silver. Those early, positive associations might be part of why purring sticks around through adulthood, reappearing whenever cats get content—curling up with their favorite humans, say, or chowing down on an especially tasty snack. Zazie Todd, an animal-behavior expert and the author of the book Purr: The Science of Making Your Cat Happy, told me that one of her cats, Harley, will sometimes rumble the moment Todd walks into a room, which is “really lovely.” For other felines, Sung told me, mere eye contact with a beloved human may be all it takes to get that engine going.
But the gears of purring can also turn under some far less cheery circumstances. Mikel Delgado, a feline-behavior expert in California, told me she once had a cat that would purr at the vet. Sung has even heard the noise while inserting a catheter into a patient. Scientists can only speculate about what’s going on. Carney told me that in some animals, purring could be a sort of vocal tic, like nervous laughter; cats might also be trying to send out pleas for help or warning messages to anyone who might dare approach. Or maybe bad-times purrs are self-soothing, says Jill Caviness, a veterinarian and cat expert at the University of Wisconsin at Madison, and parent to a feline named Electron. They could even be a cat’s attempt to dupe its pain-racked body into a less stressed state.
In the early aughts, a researcher proposed that purring might even have palliative properties for cats—pinging out vibratory frequencies that could, for instance, speed the healing of wounds or broken bones. The thought isn’t totally bonkers, Eklund told me. Vibratory therapy has shown some promise in animals such as rabbits; even NASA once pursued it, hoping to stave off or even reverse bone loss in astronauts headed for long stints in space. Carney has had plenty of clients who “swear that the cats lying in bed, purring beside them while they were ill, kept them from passing away,” she told me. But alas: Although cats can purr at frequencies that overlap with those used in vibration therapy, none of the research on these treatments has actually involved felines. “I don’t think we have any studies that are like, I sat with a purring cat on my broken leg for 15 minutes a day; I healed more rapidly than someone else,” Caviness told me; the same goes for the effects of purrs on the purrer. Carney’s more open to the healing idea, though she, too, admits: If people feel better around their cats, that might be less about purring’s direct mechanical effects on human tissues, and more about the entire companion animal being a psychological balm.
With cat communication now undergoing a bit of a research boom, Eklund told me—new papers on the subject appear “basically every week”—purring is perhaps less perplexing than it’s ever been. But among its cat-vocalization cousins, its rumbles can still be unusually difficult to parse, not least because, across contexts, purrs just sound so similar. Meows can also be a bit cryptic, but they have more discernible logic: It’s not so difficult to parse Calvin’s Feed me; I am legitimately starving mewl from his Why am I in this cat carrier? yowl. Carney, who’s spent years listening to purrs of all sorts, told me that such differences may exist with purrs too: Contented rumbles tend to be more melodious and lower, while anxious revs trend higher and harsher. And one study, from a few years ago, suggested that humans could pick out their pet’s “solicitation” purrs—an urgent, pitchy sound that cats emit when seeking a meal—from other purrs that they made on the regular. But differences like those are very hard to pick out, especially in unfamiliar cats; even Caviness’s veterinary students can’t tell them apart in the clinic, she said.
And unlike many other cat noises, purrs stubbornly elude human imitation (though some people on YouTube might beg to differ). Humans can easily meow back at their cats; “it’s like a very rudimentary pidgin language,” Eklund said. But purring? Our brains and throats just aren’t set up for the stuff. Which, to me, is a soft tragedy: The rumbles of my two cats, Calvin and Hobbes, are missives of love, of joy, of bliss; they are tactile and auditory feedback to my touch. They are a token of affection I can receive, but cannot send back.
Certain devices and soundtracks can offer substitutes. Some vet clinics play cat music in exam rooms, with a calming purr bass track; Delgado mentioned that a shelter she used to work at purchased surrogate nursing machines for orphaned kittens, which could be outfitted with a synthetic purr. Purr enthusiasts can even put on a podcast of an orange cat from Ireland named Bilbo purring for 30 minutes straight.
Purring is a language barrier we have yet to surmount. Which, in some ways, is so, so cat. Humans have spent generations breeding dogs to emote in very people-esque ways, using their soulful eyes and slobbery, smiley mouths. Cats, though, continue to thrive on subtlety; their mugs aren’t evolutionarily set up for obvious expressions, defaulting instead to “resting cat face.” Even compared with other cat vocalizations, purring is subtle and intimate, a form of communication that hinges on proximity, on closeness, on understanding a cat’s wants and needs—and maybe, sometimes, on them understanding ours.
When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.",4
162,"Richard Feynman on the One Sentence to Be Passed on to the Next Generation
“In that one sentence, you will see, there is an enormous amount of information about the world, if just a little imagination and thinking are applied.”
By Maria Popova
The great Richard Feynman (May 11, 1918–February 15, 1988) — champion of scientific culture, graphic novel hero, crusader for integrity, holder of the key to science — may have earned himself the moniker “the Great Explainer,” but when Caltech invited him to take over the introductory course in physics in 1961, they took an enormous chance on a theoretical physicist with no particular interest in students. What resulted, however, was nothing short of magic — his lectures went on to become a cultural classic, blending remarkably articulate explanations of science with poignant meditations on life’s most profound questions, and were eventually collected in The Feynman Lectures on Physics (public library).
From the very beginning of his first-ever lecture comes this timeless gem (mentioned in Daniel Bor’s excellent The Ravenous Brain) that set the tone for both Feynman’s academic contribution and his broader cultural legacy:
If, in some cataclysm, all of scientific knowledge were to be destroyed, and only one sentence passed on to the next generation of creatures, what statement would contain the most information in the fewest words? I believe it is the atomic hypothesis that all things are made of atoms — little particles that move around in perpetual motion, attracting each other when they are a little distance apart, but repelling upon being squeezed into one another. In that one sentence, you will see, there is an enormous amount of information about the world, if just a little imagination and thinking are applied.
Couple with Feynman’s ode to the wonder of life, performed by Yo-Yo Ma in a breathtaking animation, and his famed ode to a flower, then revisit Bertrand Russell on science as the key to democracy.
—
Published September 11, 2012
—
https://www.themarginalian.org/2012/09/11/richard-feynman-lectures-on-physics/
—
ABOUT
CONTACT
SUPPORT
SUBSCRIBE
Newsletter
RSS
CONNECT
Tumblr",2
163,"Read update
- Bruce Willis Debunks the Deepfake Sale
UPDATE: 2022/10/01 14:50 EST BY JOSEPH BAXTER
Bruce Willis Debunks the Deepfake Sale
Since this article was published, Bruce Willis issued a statement to The Hollywood Reporter denying the claim that he sold his likeness for the use of deepfake appearances. The statement clarifies that the legendary actor ""has no partnership or agreement with this Deepcake company."" Additionally, Deepcake confirmed to the trade that Willis’ digital-likeness rights cannot be sold since they belong to him by default. The company further explained that their work with Willis was done through his representation at CAA.
Actor Bruce Willis has become the first Hollywood star in history to sell his likeness so deepfake technology will allow him to continue appearing in films.
As reported by The Telegraph, Willis allowed Deepcake, which makes what is described as ""digital twins,"" to use his face in a phone ad. Willis said in a statement, ""I liked the precision with which my character turned out. It’s a mini-movie in my usual action-comedy genre. For me, it is a great opportunity to go back in time."" He added, ""With the advent of modern technology, even when I was on another continent, I was able to communicate, work and participate in the filming. It’s a very new and interesting experience, and I thank our entire team.""
Earlier this year, Willis announced he would be stepping away from acting following a career spanning over 40 years, due to aphasia, which he was recently diagnosed with. The condition affects controls language expression and comprehension over time. At the time, his family wrote on social media, ""This is a really challenging time for our family and we are so appreciative of your continued love, compassion and support. We are moving through this as a strong family unit, and wanted to bring his fans in because we know how much he means to you, as you do to him.""
Following the announcement, industry insiders reported his health issues had been a concern for several years, with one crew member on White Elephant suggesting others would oftentimes have to feed Willis his lines and that the actor would struggle to understand them. Director Jesse V. Johnson previously stated that after filming had concluded, ""...It was decided as a team that we would not do another,"" noting that, ""We are all Bruce Willis fans, and the arrangement felt wrong and ultimately a rather sad end to an incredible career, one that none of us felt comfortable with.""
An Action-Packed Career
Willis began his acting career back in 1980 in an uncredited role in The First Deadly Sin. His breakout role in film came in 1987 film Blind Date, in which he played Walter Davis opposite Kim Basinger. His career eventually led to Die Hard, the first in what would become a franchise spanning five films.
Over the course of his career, Willis has been nominated for five Golden Globe Awards and three Emmy Awards, winning one Golden Globe for Moonlighting and two Emmys-- one for Moonlighting and one for a famous string of guest appearances on Friends.
Source: The Telegraph",1
164,"TOKYO -- Japan will likely see an excess supply of 10 million dwelling units in 2023, due partly to government housing policy through the 2000s that ignored falling demand caused by a shrinking population. The glut will further aggravate the problem of unoccupied homes, which topped 8.49 million in 2018.
According to the Ministry of Internal Affairs and Communications, Japan had a total of 62.41 million dwelling units as of 2018. Nomura Research Institute expects the number will increase to as many as 65.46 million in 2023.",2
165,"News Treehugger Voices Adaptive Reuse Is the Architectural Challenge of the Present—Not the Future How buildings are used is changing. By Lloyd Alter Lloyd Alter Facebook Twitter Design Editor University of Toronto Lloyd Alter is Design Editor for Treehugger and teaches Sustainable Design at Ryerson University in Toronto. Learn about our editorial process Published August 10, 2022 08:46AM EDT Fact checked by Haley Mast Fact checked by Haley Mast LinkedIn Harvard University Extension School Haley Mast is a freelance writer, fact-checker, and small organic farmer in the Columbia River Gorge. She enjoys gardening, reporting on environmental topics, and spending her time outside snowboarding or foraging. Topics of expertise and interest include agriculture, conservation, ecology, and climate science. Learn about our fact checking process Share Twitter Pinterest Email Insulating an existing building with rock wool. Frantic00 / Getty Images News Environment Business & Policy Science Animals Home & Design Current Events Treehugger Voices News Archive There's only one major problem with a recent article by architect Duo Dickinson: the title. He wrote that adaptive reuse is the architectural challenge of the future when, in fact, it is very much the architectural challenge of the present. Dickinson wrote, ""In the next generation, America will see more resurrections of newly obsolete buildings than at any time since the advent of the Eisenhower Federal Highway System, when cities were radically gutted and a new 'suburbia' carpet bombed the landscape around them."" But many of the changes he goes on to describe are happening now. Church demolitions and conversions, for example, have been happening for decades because ""organized religion in America is in freefall."" Churches actually make wonderful conversions; we have shown many of them on Treehugger, and I worked on a few as an architect or developer 30 years ago. They are usually solid buildings with serious character in prime locations. Dickinson wrote: ""Sometimes remnants are kept; sometimes these inefficient, low-tech buildings are removed. However, this is an age where sustainability is becoming a core design criterion—where the energy embodied in every building, the energy need to remove a building, the energy required to build a new one, and the toxins imposed on our environment in their construction or demolition, are becoming morally unacceptable and economically punitive, given the regulations and costs imposed. So sacred buildings must transition to profane uses, a challenge architects are well poised to address."" Many of the other trends he described, from the closing of movie houses to the redevelopment of second-tier shopping malls, also started happening years ago. As home screens got bigger and better and streaming services delivered movies a month or two after they were released, people stopped going to cinemas. As shopping online grew, traffic in the malls shrank. Then the pandemic hit, and all these trends got a giant kick in the butt, accelerating the process dramatically. The numbers Dickinson threw out are astonishing: ""An estimated 8 million square feet of big-box stores are being turned into distribution centers. Since 2016, Amazon has converted 25 mall spaces into distribution centers, according to Coresight Research. Nearly 15 million square feet of big-box retail space in the U.S.has been converted to industrial space."" Dickinson didn't directly address what may be the biggest elephant in the room: office buildings. Many companies are trying to get their employees to come back to the office, but they're not having it. Other companies are abandoning older class B and C buildings that have lousy ventilation systems. According to Bloomberg, 30% of U.S. office buildings are at risk of being obsolete. ""Some companies are scaling back their space. Others are gravitating to newly developed or recently overhauled offices that are environmentally friendly, with plenty of fresh air and natural light, fitness rooms and food courts. Left behind are older buildings that would be expensive to renovate to today’s standards. As values for those properties slide, some landlords are walking away."" Almost as many buildings are being called the ""mediocre middle,"" second-rate buildings in a world where ""to entice balky workers back to their desks, employers are looking for spiffed-up offices with some of the perks of home."" Wharton real estate professor Joseph Gyourko says we have not yet seen the worst of the carnage in the commercial real estate market because leases run five to seven years. “I strongly suspect what will result is a move to concentration, a flight to quality,"" said Gyourko. ""Over the next few years, as tenants start to rethink space needs and their leases rollover, they’ll go into better buildings, and the [worse] buildings will be in trouble.” Gyourko said cities are going to face a real problem dealing with all the empty offices and the stores and services that the office workers used to support. “They should start thinking of this as their responsibility to rehabilitate those areas now, and not later,"" he said. Dickinson also noted the internet has changed the way people work, as I have in posts about the third industrial revolution. He stated: ""Like the Industrial Revolution, the internet inspired holistic changes not only in what buildings were needed for, but how they are made. In a time when there is an unprecedented need to recycle so many building types, it will take the creativity of reinvention to put new wine into old vessels."" Many architects and organizations are picking up this challenge. In the United Kingdom, the Architects for Climate Action Network says we have to ""reuse existing buildings: pursuing a strategy of retrofit, refurbishment, extension and reuse over demolition and new build."" Architects Declare says we should ""upgrade existing buildings for extended use as a more carbon-efficient alternative to demolition and new build whenever there is a viable choice."" In the U.S., Jim Lindberg of the National Trust for Historic Preservation makes the case that ""the best way to avoid embodied carbon emissions right now, when our carbon budget is shrinking fast, is to conserve and reuse as many existing buildings as possible."" I have often wondered how architects are going to make a living in a world where rule 1 is ""build nothing,"" and rule 2 is ""fix what we have using as few resources as possible."" But Dickinson concluded with a somewhat optimistic note; I will give him the last word: ""Architects are at the edge of technologies, in the design and building of our buildings, but we’re awash in a sea of existing structures, in a world that is being undone by excess carbon to the point that anything we restore is less dangerous to our future than anything we built new. Churches, shopping malls, big-box stores, movie multiplexes, and office towers are becoming ominously silent all around us. Will architects be able to step up to see the possibilities in so many dead and banal structures? Let’s hope we find a revolution in their restoration."" Read it all at Common Edge.",2
166,"A Stress Test for Solidarity Looming Natural Gas Shortages Has the EU Scrambling for Solutions
This time, the Germans want to be good Europeans right from the start. ""We will help each other with gas supplies,"" German Economics Minister Robert Habeck asserted on Monday during a visit to the Czech Republic. ""We will also do the same from Germany for the Czech Republic.""
Habeck had traveled to Prague to prepare a solidarity agreement in case Russia halts gas supplies to the European Union, the absolute worst-case scenario for European energy supplies. Similar agreements already exist with Austria and Denmark, and the one with the Czech Republic will likely be ready by winter.
The article you are reading originally appeared in German in issue 29/2022 (July 15th, 2022) of DER SPIEGEL.
The hope is that things will be different between the Europeans this time than they were at the beginning of the coronavirus pandemic two years ago. In March 2020, the German government imposed an export ban on masks, protective clothing, gloves and other medical products. France had already banned the export of protective masks a short time before. Both countries drew the ire of the others, and for a time, it seemed as if the European Union's internal market would break apart under pressure from the crisis due to the egoism of the member states.
A repeat this time around is to be avoided at all costs. The German government wants to conclude solidarity agreements with all European countries, with our ""direct neighbors, but also beyond, such as with Italy,"" Habeck said in Prague. His message is clear: Europe will not allow itself to be divided by Putin.
The first stress test for European solidarity could come on July 21. That's when the annual mandatory maintenance on the Nord Stream 1 pipeline, which delivers gas directly from Russia to Germany, will be completed. Russian gas should start flowing to Europe again on that day, unless Russian President Vladimir Putin decides otherwise.
Whether the Europeans will truly succeed in sticking together is, of course, an open question. In June, when Russia throttled gas deliveries via the Nord Stream 1 pipeline, onward shipments of Russian natural gas from Germany to France came to a halt. The French, though, already have the means to meet their (much lower) demand using other sources – by importing liquified natural gas through their four LNG terminals, for example.
But if there is a total loss of Russian gas, radically different distribution issues are likely to arise. Will Germany still deliver sufficient gas to the Czech Republic, even if its own industry is suffering? And will partners be ready to help a Germany that they perceived as not showing much solidarity during the euro crisis?
Worse than the Euro Crisis
The gas crisis could have repercussions that dwarf even the euro debacle. Recession, unheated apartments, high prices – solidarity within the EU would be subjected to a stress test.
During the euro crisis, it was primarily the smaller EU countries like Greece or Portugal that had to make significant cutbacks. This time, though, it could be the EU's largest country that gets hit hardest. Germany not only consumes more natural gas than all other EU member states – it is also the most important transit country for the fossil fuel. Habeck said at the end of June that there would be no permanent reduction in the amount of gas transmitted to the neighboring countries. ""That would be illegal – and absurd.""
German Economy Minister Robert Habeck (left) and Chancellor Olaf Scholz are in crisis mode.Foto: Kay Nietfeld / picture alliance
But the situation isn't quite so clear-cut. The European Commission and the European Council agreed on a solidarity mechanism five years ago requiring member states to supply fuel to distressed member states as a ""last resort"" in extreme situations - provided they were connected to those struggling countries through existing natural gas networks. This applies when the other country requests assistance and no longer has enough gas to supply private households, hospitals or social institutions.
But for that to work, member states would have to conclude the kind of bilateral solidarity agreement that Germany and the Czech Republic are now preparing. The agreement is to contain the technical, legal and financial details of emergency supplies: which pipelines will be used, the quantities that will be provided and the prices that will be paid in the event of an emergency.
Without these contracts, there's a risk of complicated negotiations in the event of an emergency, for which there is no time.
And therein lies the problem: So far, only six of these agreements exist in the EU. If significantly more countries don't negotiate with each other by the winter the form that aid should take if there's an emergency, then it could become difficult to provide mutual support.
Next Wednesday, the European Commission is slated to present how it believes the EU should deal with the impending gas shortage. Sources in Brussels say that no specific recommendations will be made to individual member states about, for example, how they should save energy. Block members will have to decide for themselves how they want to manage the bottlenecks. The most that is being discussed in Brussels is setting of an EU-wide conservation target of 8 percent.
Coordinating, not Going It Alone
More important is the European Commission's role in sharing information on key metrics such as gas demand and supply chains. For example, Brussels intends to offer its services in coordinating the emergency plans of member states to prevent the shutdown of a factory in one country from leading to the unintended shutdown of production in another.
Habeck and his staff are insisting that everyone must show solidarity. If shortages do begin to appear in the autumn or winter, then industrial companies in Germany would have to cut back on production and citizens would also be forced to cut back on energy consumption.
Russian President Vladimir Putin during an online cabinet meeting: What will happen to German gas supplies after July 21?Foto: Mikhail Klimentyev / AP
""But that will only work if the countries to which we transport the gas reduce their consumption as well,"" says a senior official. That would be the only way of explaining to the populace why natural gas continued to flow to those countries from Germany.
But the idea of European solidarity isn't being met with enthusiasm everywhere. ""Where was Europe's energy solidarity and energy security when the Germans built Nord Stream 1 against the will of Poland and many others?"" asks Joachim Brudziński, a member of the Polish parliament with the governing PiS party in Warsaw. ""No matter how much fresh Brussels-speak there is about European solidarity, about European energy policy, about the rule of law and European values – in the end, it's always about German or French interests.""
In Southern Europe, too, where the euro crisis has left deep scars, the willingness to step up to help Germany remains limited.
Portuguese politician Bruno Maçães negotiated with the Germans as his county's secretary of state for European affairs during the euro crisis. He says the German government spent years blocking alternatives to Russian gas. As a result, he says there is a dearth of pipelines between the Iberian Peninsula and the rest of Europe.
Solidarity with the Germans?
""During the euro crisis, (then German Finance Minister Wolfgang) Schäuble always said that the costs should not be socialized,"" Maçães says. ""Why should that happen now – after all the German mistakes?""
Germany's actions on the international gas markets have done little to assuage such resentment. The German government has so far made 15 billion euros available to fill its own gas storage facilities. Largely unnoticed by the German public, the market area manager for the German gas market, Trading Hub Europe, has used this money to buy up whatever natural gas is available on the world markets.
It has been a success, at least from a German perspective. Domestic gas storage facilities had filled up to over 64 percent by this week, almost 2 percent more than the European average. Another consequence, however, is rising prices. It is becoming increasingly difficult for many European countries to pay for gas.
An additional source of resentment, especially in Eastern Europe, is the fact that Germany has lobbied to send a gas turbine serviced in Canada for the Nord Stream 1 pipeline to Russia, even though this would mean an exemption to Russian sanctions. In the Baltic states and Poland, this is seen as evidence of German energy egoism.
The German government, on the other hand, argues that Putin still thinks legalistically on some issues. And Berlin doesn't want to give him any excuse to continue blocking gas supplies to Europe once maintenance on the Nord Stream 1 pipeline is completed.
The German government also took early action in other areas. For example, Berlin commissioned the construction of floating LNG terminals at a time when they could still be obtained on the market. They should be ready to go into operation by the end of the year. That need not be problematic for other countries. On the contrary, it could prove helpful as long as Germany provides some of that gas to its partners in the event of an emergency.
Germany Blocks Joint Gas Purchases
A number of EU countries have come out in favor of making joint gas purchases, as has the European Commission. This, it is hoped, would allow more favorable prices to be achieved because member states would not be competing against each other. The gas purchased would then be distributed to individual countries, similar to the way coronavirus vaccines were disbursed during the pandemic.
The plan, though, has been blocked at several EU summits by German Chancellor Olaf Scholz, even though the government in Berlin is anything but united on the issue. There are influential advocates of making these pooled purchases within Habeck's Economy Ministry, for example.
But resistance is coming from large natural gas utilities in Germany, like RWE, and from industrial customers as well. They want to buy their own gas and fear that they won't be allocated sufficient supplies by the EU. They are exerting pressure through the unions, the result being that European leaders were only able to agree on a voluntary procurement pact at the last EU summit.
In addition to all the political issues, it is unclear whether the European gas network is at all equipped to meet the challenges of winter.
Thus far, most of the gas has flowed from Russia to the West via three pipelines. If Putin turns off the gas taps for any length of time, then natural gas will have to be pumped into the interconnected European energy system from the south, west and north. Pipelines from the south carry gas from North Africa and Italy's LNG ports, while western pipelines originate from terminals in Spain and France. From the north, meanwhile, Norwegian supplies will increase in importance.
Can Europe's Grid Handle Flows?
A research group from the Munich-based technology academy Acatech this week presented a series of expert reports on whether the European gas grid can handle these flows.
""The further east the country, the more complicated the supply is in a situation like this,"" says Mario Ragwitz, one of the study leaders at the Fraunhofer Institution for Energy Infrastructures and Geothermal Energy. ""As an important transit country, Germany plays a key role in ensuring secure supplies to its Eastern European neighbors such as the Czech Republic and Slovakia.""
The LNG terminal in the Polish port city of Świnoujście: ""The further east the country, the more complicated the supply is in a situation like this.""Foto: KACPER PEMPEL / REUTERS
The experts warn that in the event of a Russian embargo, there could be a shortage of 20 percent of the gas needed throughout Europe and as much as 30 percent in Germany. As such, they are strongly advising a technical upgrade of the grid to reflect the new direction in which the gas is to flow. Among other things, they have identified weak points between Germany, Austria and Italy that could affect the flow of Norwegian gas to the south and LNG gas from Italy to the north.
The hope in Brussels is that governments of the EU member states have learned their lessons from the coronavirus crisis. A senior EU officials says that the pandemic nearly brought the single market to collapse. ""The last two years have shown that everyone in the EU has benefited from solidarity.""
The question is whether this applies exclusively to the European Union.
How will the EU states respond if Ukraine also runs out of gas? Kyiv may not be an EU member, but a united Europe would look disastrous if people in the war-torn country had to freeze in winter because Western countries preferred to save their industries.
""It's like so many times in recent years,"" says one Brussels insider. ""The crisis is so huge that it will either cause the EU to break apart – or continue to grow together.""",5
167,"In 1934, much of the world was in the grip of the Great Depression. Unemployment was an epidemic, and many businesses struggled desperately to survive. One notable exception to these economic troubles, however, was the radio industry. Broadcasters in the US were making upwards of two billion dollars a year, and they owed much of their success to the innovations of a brilliant man named Edwin Armstrong. Twenty years earlier he had significantly improved the sensitivity and quality of radio receivers with his invention of the regenerative circuit in his junior year of college, and he went on to further improve them with his Super Regenerative circuit and Super Heterodyne receiver. These laid the foundation for the success of radio broadcasting— in fact, almost any radio you buy today will still incorporate these innovations. But in 1933, Armstrong brought about an even more revolutionary change in the broadcasting business: FM radio.
In spite of these brilliant technical achievements, Armstrong saw little financial benefit from his inventions. Many of his ideas were plundered by unscrupulous people, a trend which ultimately led to Armstrong’s tragic and premature death.
The first of Armstrong’s technology troubles began in 1922 when he lost a patent lawsuit for the rights to the regenerative circuit. A man named Lee De Forest had patented the same invention in 1916— two years after Armstrong’s patent was granted— and sold the rights to AT&T. A long and bitter legal dispute followed, which progressed all the way to the US Supreme Court. Utterly failing to grasp the technical facts in question, the Supreme Court ruled in favor of De Forest, and stripped Armstrong of his patent. Despite the scientific community’s certainty that Armstrong was the inventor of the regenerative circuit, Armstrong lost the patent battle which spanned twenty-one years, thirteen court rulings, and thirty judges.
In the meantime, between court appearances and legal meetings, Armstrong continued to innovate. He started to work on the “static problem” which plagued early radios, despite some colleague’s assertion that static could never be eliminated. At the time, radio was transmitted via Amplitude Modulation (AM), which varied the amplitude of the radio waves. This gave the signal a much wider reach, but resulted in poor-quality sound. Armstrong sought to improve the signal quality by instead varying the radio waves’ frequency, creating Frequency Modulation radio (FM). He won a patent for FM radio in 1933, and the following year he did his first field test when he broadcast an organ recital in AM and FM signals from the top of the Empire State Building. The AM broadcast was static-filled and the FM broadcast was clean and rich. Listeners were shocked by the difference. Later, in experiment after experiment he proved the on-air differences and improvements in sound.
Just before World War 2, Armstrong successfully lobbied the FCC to create an FM broadcast spectrum between 42 and 50 MHz. He built an experimental station and 410-foot tower at a cost of $300,000 in Alpine, New Jersey. He started a small network of high-powered FM stations in New England called the Yankee Network, and began manufacturing receivers to pick up the broadcasts. To all who heard the fledgling network, its quality was astounding. The broadcasts could deliver the entire range of human hearing between 50 and 15,000 cycles while AM delivered only 5,000 cycles. A club for FM radio enthusiasts started in pre-war New York, and launched its own magazine called FM. Armstrong was trying as hard as he could to prove the superiority of FM broadcasts… all people had to do was listen.
Armstrong went on to prove that FM was capable of dual-channel transmissions, allowing for stereo sound. This capability of FM could also be used to send two separate non-stereo programs, or a facsimile and telegraph message simultaneously in a process called multiplexing. He even successfully bounced a FM signal off the moon, something not possible with AM signals.
Of course AM radio was big business in the pre-television days, and there were powerful people who wanted things to stay as they were. Innovation only meant smaller profits for them. At that time there was no more influential man in radio media than the founder of RCA, David Sarnoff. Known as “The General,” Sarnoff controlled all the technical aspects of radio; he also created the NBC and ABC television networks. He was also an important early supporter of television and developed the current NTSC standard for TV that we have used for over 60 years.
Seeking to kill FM radio before it could threaten his profits, Sarnoff’s company successfully lobbied the FCC to have the FM spectrum moved from Armstrong’s frequencies to the ones we use today: 88 to 108 MHz. That move, which occurred on 27 June 1945, immediately rendered Armstrong’s Yankee Network obsolete, along with all of the FM radio sets which had been produced. The cost to re-equip the stations for the new frequencies would be enormous. The FCC ruling said that the 40 MHz band was to be used for the new television broadcasts, in which RCA had a heavy stake. RCA also had an ally in AT&T, which actively supported the frequency move because the loss of FM relaying stations forced the Yankee Network stations to buy wired links from AT&T. The deck was stacked against the future of FM broadcasting.
Matters became worse when Armstrong became entangled in a new patent suit with RCA and NBC, who were using FM technology without paying royalties. The cost of the new legal battle compounded the financial burden that the problems with the Yankee Network had caused. His health and temperament deteriorated as the FM lawsuit dominated his life. His wife of thirty-one years, unable to cope with his worsening personality and financial strain, left him in November of 1953. RCA’s greater financial resources crushed Armstrong’s legal defences, and he was left penniless, alone, and distraught.
On February 1, 1954, Armstrong’s body was discovered on the roof of a three-story wing of his apartment building. In despair, he had thrown himself out the window of his thirteenth-floor New York City apartment sometime during the night. He died believing he was a failure, and that FM radio would never become accepted. Through the years Armstrong’s widow would bring twenty-one patent infringement suits against many companies, including RCA. She eventually won a little over $10 million in damages. But it would take further decades for FM radio to reach its potential.
Following Armstrong’s death, television’s emerging popularity ended radio’s golden years. Slowly, listeners learned that FM radio was clearly better for musical high fidelity than AM broadcasts. Radios started to have an FM band included with the AM band in the late 1950s and 1960s. By the 1970s, FM audience size surpassed that of AM, and the gap has been growing ever since. Today over 2,000 FM stations broadcast in the United States, and FM signals are commonly used for microwave relay links and space communications. Edwin Armstrong’s innovations clearly changed the world; had he not taken his own life, it is likely he would have lived long enough to watch his dream come to fruition.
first
Anybody know when widespread am broadcasting started? Also, anybody know the cost?
AM-Good for distance
FM- Good for clearity
Those Thieving Bastards.
And this is how Damn Interesting differs from mainstream news. You totally failed to mention how computerized Internet “home pages” like MySpace.com are now drawing away radio and television listeners from all bands of the airwaves. Or something like that. You need to make those lame connections to this year’s hot topics!
I disagree with the internet radio comment. I see more and more people moving toward satellite radio. XM and Sirius combined have about 10 to 12 million subscribers wrapped up. The evolution continues and the quality of sat rad is much better than fm. The problem with internet radio is that you can’t go anywhere and get reception. Wifi isn’t very widespread and the signals don’t go far enough to give quality reception of internet radio.
You’ll be seeing the fully connected car/person before you’ll be seeing wifi internet radio in any car. With offerings of much more than just radio sat rad is the future. Here’s to weather radio, traffic directions, and 200+ channels of crystal clear audio in your car or on your person by 2010.
Mark my words fm is dead.
If AM is good for distance, why was it that FM was the only one that could bounce off the moon and back? I understand that AM is good for distance because it’s constant frequency makes it’s signal stronger, and vice versa with FM.
Also, I would totally like to join that FM radio enthusiasts club, given that it still exists, just so I could boast about it. Impress all my friends with an FM enthusiast club inititation card or spiffy badge or something.
There are no shortage of people who died before their creations became famous, F. Scott Fitzgerald never saw his The Great Gatsby book become the absolute CLASSIC american novel it is today, forinstance… There are so many examples out there that I won’t trouble anyone with any more, but would like to:
A) give kudos to Sir Greg Bjerg, fascinating article, and
B) say that it truly is unfortunate that so many people never live to see their ideas become recognized.
The first commercial radio broadcasts began 1922. WOR in New York was one of the first, if not the first. WOR gave rise to 3 or 4 generations of radio hosts, the Gamblings, with a decades-long weekday morning time-slot called “Rambling With Gambling”. Unlike the obfuscating propagandists of the American airwaves today, the stars of the early networks knew that they were invited into peoples homes as guests, and were careful to cultivate and maintain the trust placed in them by their at-home audiences.
It is perhaps hard for this generation to imagine, but before radio, EVERYTHING was different. Prior to radio, music in people’s home was provided by upright pianos, reed-organs, etc. Everyone knew how to play something. It was the social thing to do: gather around the piano and sing. If you had a LOT of money (like the Ford’s in Dearborn), and you didn’t want to fuss around with having an orchestra, you bought an organ — and we’re not talking one of these casio jobs, either. Huge pipe organs, occupying several rooms in the ‘house’ (mansion), were built and installed up until The Depression, complete with their own staff concert organist.
Radio made such an impact in the 20’s, that words were coined, like “radio-active”, and the little red wagon, the “Radio Flyer”, played off the public’s fascination.
Another innovation of the 20’s was sliced bread…
His story sounds very similar to how the major car companies conspired against Preston Tucker and his remarkably innovative automobile. I once came across a 1940s car magazine which had an article written by someone who had test-driven a Tucker, and he raved about it for page after page. Then there’s the electric car, and possibly promising forms of alternative energy, which have also been suppressed by Big Business. I’m not a conspiracy nut, but . . .
Oh, sorry. Talk about rambling…
Following WOR’s (and others’) leads, radio stations were operating soon across the country. Boys would make their own crystal sets for reception. RCA — Radio Corporation of America — sold radios by the freight-car load. They were a hot commodity, and everyone wanted to buy stock in RCA. Something like today’s Microsoft.
hammydude said: “first”
You’ve just read about a guy committing suicide in tragic circumstances and the next thing you do is brag in a futile attempt to increase your social standing? Forgive me for flaming, but you suck.
I’m with you, mensadave – too many great inventions get crushed into obscurity by big business. So much for capitalism encouraging innovation…
Misfit7707,
My guess with Am radio not being able to moon b0unce is because whent the signal gets transmitted, it travels along the ionosphere (upper atmosphere) and travel away. It’s this property of AM radio which allows it to be heard far far away. Such as a strong station in california could be heard in alaska (at night, there is too much noise from the sun during the day).
FM on the other hand, wouldn’t bounce around the ionosphere and be able to moon bounce.
As for joining a radio entheuist club, I suggest you join the ranks of Amatuer radio. Check out arrl.org for more info.
Puppeto said: “I disagree with the internet radio comment. I see more and more people moving toward satellite radio. XM and Sirius combined have about 10 to 12 million subscribers wrapped up. The evolution continues and the quality of sat rad is much better than fm. The problem with internet radio is that you can’t go anywhere and get reception. Wifi isn’t very widespread and the signals don’t go far enough to give quality reception of internet radio.
You’ll be seeing the fully connected car/person before you’ll be seeing wifi internet radio in any car. With offerings of much more than just radio sat rad is the future. Here’s to weather radio, traffic directions, and 200+ channels of crystal clear audio in your car or on your person by 2010.
Mark my words fm is dead.”
I disagree… I work as a DJ for a radio station and I’m good friends with a lot of people both in FM radio and in Sat Radio. Both communities tend to agree that FM will remain popular for one simple reason… Sat radio just can’t give you the local stuff. Sure it can give great quality music, an entire spectrum of NFL/NCAA games, basektball, soccer, you name it… but it can’t give you your local news, it can’t give you your local weather, it can’t inform you on events taking place in your town, it can’t have the same volume of contests as are normal in an average market due to cost issues, and good luck trying to request a song!… BECAUSE of it’s enormous broadcast reach, it can’t narrow itself down to Anywhere, USA. Comparing FM and Sat radio is like comparing apples and oranges where as comparing FM and AM is apples and apples. FM/AM was a signal clarity issue… FM/Sat radio is a content/programming issue… something much harder to overcome. Oh, and just because I have a feeling someone is going to say it… you couldn’t relay the sat link to a terrestrial station and rebroadcast it with local content… It would run into the same problems as long distance FM (power issues, making the signal curve to compensate for the curve of the earth, not to mention FCC regulations which govern all terrestrial radio, etc…) and by nature it couldn’t be called sat radio anymore if you’re downlinking to a terrestrial station and rebroadcasting from there… it would have to either be bounced back up to the sat and rebroadcast which wouldn’t be cost/bandwidth efficent or broadcast via antenna from a terrestrial station. If every FM station shut down and turned to sat radio and rebroadcast in this manner with local content there’d be over TWO THOUSAND different sat radio channels all with different variations of the same programming…
The market for FM radio may shrink, as did the AM market, which is still around, but it’ll never go away. Sorry for rambling, it’s what I get paid to do after all lol.
GREAT ARTICLE!
I wonder if anyone from RCA or AT&T would be big enough to apologize for what they did to that man. Obviously, people of these modern times didnt commit act against Armstrong but that didn’t stop the church from apologizing to Galileo. It’s the principal of the thing. This man is responsible for one of the most amazing inventions of the time. I would like to close with…
107.3 WAAF RULLLEESSSS!!!!!!
PresMatt says: The market for FM radio may shrink, as did the AM market, which is still around, but it’ll never go away.
Also, I am in total agreement with you. FM won’t die because of Sat radio. Sat radio still has a lot of bugs to work out. I had it and returned it. It just isnt as personable.
Stead311 said: “I wonder if anyone from RCA or AT&T would be big enough to apologize for what they did to that man. Obviously, people of these modern times didnt commit act against Armstrong but that didn’t stop the church from apologizing to Galileo. […]”
The difference is, the Church has to report to millions of people for good behavior, but corporations usually don’t. :)
Neither AM of FM radio will die as long as they remain free of charge.
RCA wasn’t always the largest radio maker. Look up Powell Crosley, Jr. for an interesting story:
http://local.aaca.org/junior/spotlight/crosley/crosley.htm
As for when AM broadcasting started, that’s generally regarded as the 1920s for commercial purposes, but the actual first AM broadcast was in 1906 by Reginald Fessenden:
http://chem.ch.huji.ac.il/~eugeniik/history/fessenden.html
Dave
It’s striking that Armstrong was first screwed by a science-ignorant, pro-business Supreme Court. Of course, that could never happen again, right?
Radio broadcasts have been used for propaganda for decades. Consider Father Coughlin and Adolph Hitler, both of whom employed radio for evil purposes.
Since this article is about Armstrong and the development of FM radio, anything about satellite radio or computers is off-topic and inappropriate.
I thought the satellite radio comments were pretty on-topic, myself. I like when a topic expands in the comments; I think I learn more that way.
Also, the range of human hearing is 20Hz to 20kHz, not 50 to 15k. Not that most people care about it, but it’s certainly an audible difference. That’s why CD specs accommodate audible frequencies from 20Hz to 22.05kHz – and even then you’re missing something. The things you don’t hear always affect the things you do.
Actually, I’d put my money on good FM reception versus satellite in terms of sound quality. Satellite radio is compressed digital, which is always missing some audio information somewhere (and can also be fatiguing for the listener’s ears). Plus, you have to cram 100+ channels into a small broadcast frequency range. Of course, I’d take satellite radio in pretty much any other category.
Now if we can only find out who’s responsible for radio mega-corporations like Clear Channel, which owns just about every station in my area. In the olden days, DJ’s gave actual information about the songs and artists, such as what group the artist formerly played with, or why he wrote the song, or whatever. Now they barely mention the song title, and both the beginning and end of the song are cut off by chit-chat or commercials.
Radio sucks, and it lost me as a listener years ago. Plus I just have this thought that radio should be “free” (the broadcasts, not the actual radio itself). Therefore, I refuse to pay for Sirius or any other such thing.
Video didn’t kill the radio star. Megacorps did.
Misfit7707, how can FM bounce off the moon when AM can not?
ForestGrump, pretty close.
AM frequencies *would* bounce off the moon just as FM frequencies do – if you could just get them to it.
AM frequencies (300-3000 KHz) are low enough in energy that they are refracted and reflected by the Earth’s Ionosphere. This allows their signals to be bounced and curved off the Ionosphere resulting in transmission receptions far (*FAR*) beyond the horizon. FM frequencies (30-300 MHz) are high enough in energy that they pass through the ionosphere. Thus FM frequencies typically only work for line of sight (or “nearly line of sight” when their signal refracts and scatters off of ground clutter). However, the moon is quite opaque (and somewhat reflective) to radio waves – thus allowing it to be used as a mirror for the FM signals that pass through the Ionosphere.
Brother Jebadiah said: “Neither AM of FM radio will die as long as they remain free of charge.”
And so they will – live and be free – until “they” close the Analog Hole…
Brother Jebadiah said: “… Radio sucks, and it lost me as a listener years ago… Video didn’t kill the radio star. Megacorps did.”
I’ll second that. Terrestrial radio may serve up local content, but the quality of that content has plummeted noticeably in the last decade for all the reasons you and others have suggested. And its life long view is a free fall from those effects.
As for the range of human hearing, the upper end varies with age. I used to be able to hear 15,750 Hz quite easily (since I could hear the whine from the horizontal output transformer in television sets), but I just checked myself, and my upper limit now is about 14,300 Hz (Oh, I’m in my mid 40s.).
Dave
This was another insightful article. In the early 60’s, I recall listening to FM stations on my father’s new Magnavox console stereo. The sound was amazingly clear. However, we could only receive maybe one or two stations, and for several years, the only music I ever heard on FM was purely classical! Not long afterwards, my father was playing his in-car, factory Chrysler Hiway Hi-Fi record player (16 2/3 rpm) and remarked how nice it would be to have an FM dial as part of the auto radio system. Eventually car FM radio became a reality. Unfortunately, my father was not part of the innovation!
Armstrong had a vision. Too bad he didn’t get to enjoy the fruits of his labor.
with the whole fm vs satellite issue….
depending on what i am doing is what i listen to.
I work in Mexico (the county) and fm radio down here is mostly spanish.
if I am at home (in the US) i listen to FM.
if Iam at work (or home) in Mexico it is sat straight up.
and during the 1800 mile drive between (which i do like 2 or 3 times a year, otherwise i fly the other, like 8 times) it is alos Sat.
i see Sat radio as the best addon to FM.
during long trips it is great (no looking for stations, or listening to the same CD’s over and over again.)
Did anyone notice the fact that his wife left him because she couldnt put up with the stress of the litigation, then after he died she took over and was awarded $10million in damages?????
What a B@#%H!
To echo ChickenHead, the modulation technique does not affect whether the signal will be bounced off the moon or not, it’s the frequency range that the signals are using. An AM signal will always have more noise though, so everything else being equal, FM should still have a longer range due to its resistance to noise.
Through the years Armstrong’s widow would bring twenty-one patent infringement suits against many companies, including RCA. She eventually won a little over $10 million in damages.
She was “unable to cope with his worsening personality and financial strain”, so dumped him like yesterday’s trash, but jumped at the opportunity to cash in after the poor guy killed himself? Damn pathetic.
Following Armstrong’s death, television’s emerging popularity ended radio’s golden years.
Television’s popularity soared, in part, riding on Armstrong’s successes. From what I understand the audio channels on a television RF signal are FM. There’s gratitude for you.
Let’s not jump to conclusions about his wife. This was obviously a VERY tough time in their lives, and with stress comes marital problems. Sometimes splitting up is better for both individuals. And after he died, she may have wanted to get revenge on the corporations that ultimately caused that divorce, and that brought Armstrong to the point that he felt there was nothing left to live for.
I’m not saying this is what happened, but it is a possibility. Without the relevant facts, do not presume to know what was going through her mind.
FMZ said: “Without the relevant facts, do not presume to know what was going through her mind.”
True; one shouldn’t jump to conclusions. But what gets me is “the relevant fact” that she left Armstrong when things got tough; that certainly did nothing to improve his state of mind. I would argue that her absence was probably a contributing factor in his suicide. I’ve been in depression before, and know that had I been alone, I probably wouldn’t have survived it.
What I read of Armstrong’s bio had nothing to say about why his widow went after RCA et al, so it would be equally wrong to assume that she did it out of any noble intentions.
First of all, thanks ForestGrump and ChickenHead for supplying me with, holy crap, more info than I ever expected in an answer. You guys truly know your stuff. Second of all, Crispy, I’d like to speak in defense of hammydude… Just because the article was sad means that it is simply immoral for him to find something as little as that to get excited about? Yeah… sure. Maybe we’ll let it slide the next time he’s first for an article about bunnies and rainbows… Give him a break. You made it sound like he was REALLY excited and shouting about how cool he should be now that he’s first in line. He wrote one word.. and it didn’t even sound all that excited. At least he posted something about the article.
As for what more I have to say about the article, I wonder how well the moon reflects the FM waves.. Would the reflected wave be very low quality because by the time it gets picked up, it had to travel to the moon and back? Also, I believe it when you say that FM waves have the higher energy, that would make sense as to how they can penetrate the ionosphere, but if they have the higher energy, why doesn’t that allow them to travel further? Is it simply because that energy inhibits the “ionoshpere bouncing for further distance” characteristic? That may be what ForestGrump was getting at, but I’m still a little unclear. If bouncing helps, could FM take advantage of the “bouncing off the moon” thing, or does that take me back to the signal quality reduction after travelling that far?
To conclude:
I am the 29th person to post a comment! WOO!
Regarding Colonel Edwin Armstrong’s wife, at his lowest point during the horrendous battle with RCA, during an argument where his wife pleaded with him to accept the settlement offer of one million dollars (which he correctly regarded as an insulting amount) he struck her.
With that, as much as she loved him and supported him through decades of hell, she had to leave.
He went on to commit suicide, and left a note to her in which he mentioned how sorry he was for doing that.
She didn’t capitalize on his death, she took up his battle and wasn’t about to let RCA and “General” David Sarnoff (a low-life) win by default.
“I’m with you, mensadave – too many great inventions get crushed into obscurity by big business. So much for capitalism encouraging innovation…”
I completely disagree. As was plain in the article, Armstrong was free to compete until the government intervened and with the stroke of a pen rendered all of his work useless. A corporation doesn’t have that kind of power itself.
It is the same with electric cars. Head over to commutercars.com, or any number of other companies held back by our government ssafety regulations. It’s safe enough for the SCCA and NHRA, but not for the street? But at the same time, I can ride a motorcycle, on two wheels and an engine and no crash protection at all, and it’s completely fine? Why aren’t I free to purchase a car even if the government thinks it’s not safe enough for me?
And Tucker’s factory was clsed by the government on October 4, 1949 when they determined in court he never planned to produce the car. Again, not a corporation, but the government.
Corporations will always seek a competitive advantage, it is their nature. The problem is that government should not have the power to give or remove extra advantages to corporations on a whim. If a government official can keep your company alive by wiping out someone else’s, the problem isn’t that you want him to, it’s that the official has that power in the first place.
junebee said: “Now if we can only find out who’s responsible for radio mega-corporations like Clear Channel, which owns just about every station in my area. In the olden days, DJ’s gave actual information about the songs and artists, such as what group the artist formerly played with, or why he wrote the song, or whatever. Now they barely mention the song title, and both the beginning and end of the song are cut off by chit-chat or commercials.
Radio sucks, and it lost me as a listener years ago. Plus I just have this thought that radio should be “free” (the broadcasts, not the actual radio itself). Therefore, I refuse to pay for Sirius or any other such thing.
Video didn’t kill the radio star. Megacorps did.”
Agreed I left FM when we became nothing more then card turners that was handed a playlist. However in the Los Angeles market one vet jock has it in his contract that during his show he has full creative control, Jim Ladd at KLOS FM. I know do net radio…not as big or popular yet but a lot of fun.
FCC was, and still is, in the pocket of big business ( FCC = Friends of Clear Channel )
RCA is now a brand name for the French company Thompson and has little R&D or technical significance.
AT&T is a shell of a company whos assets were sold off leaving only a name that has been bought by Cingular with the hope that they can craft a new image.
Oh, and in twenty years Damn Interesting will run a story how all these towns and cities had their very own independent radio stations that said what they wanted, played what they wanted, when they wanted long before we succummed to the mind numbing pablum of clear channel and npr.
First AM radio – KDKA, Pittsburgh, November, 1920
http://www.pbs.org/wgbh/aso/databank/entries/dt20ra.html
I don’t think that we’re going to see moonbounce used as a method for radio stations for several reasons:
1) If you have Dish or DirecTV you will notice that you are not allowed to receive the local stations for other parts of the country… you have to tell them when you sign up which part of the country you live in and they enable your set-top box to receive the stations that are local to you – this is because the local individual stations do not wish to compete on a national basis, and the network affiliates do not wish to compete with other affiliates of the same network (actually let people decide if they want to watch WNBC [NY] or KNBC [L.A.]? Outrageous! Can’t have that!)
2) By having transmissions that are globe-spanning (I know someone who spoke via ham radio in California with someone in Switzerland using moonbounce and less than 100 watts of power) the number of stations able to operate will be reduced by several orders of magnitude… currently each area has their own channel 2, 4, 5, 7, etc. that operate on the same frequency and the reason this works is that each doesn’t have the range to reach into the operating area of the other. If channel 2 in San Francisco was being received in Los Angeles, San Diego, Chicago, Dallas, New York, Berne, Paris, London and Tokyo and was wiping out the signals of the local stations there, would the market stand for it? Would the people in Tokyo an Paris be happy about having to listen to a station broadcast in english? Would we want channel 4 to be in chinese, channel 7 to be french and channel 9 to be in farsi? We would run out of channels before each language widely used on this planet had it’s own channel.
3) The moon revolves around the Earth at a rate that has it rising and setting about 55 minutes later each night, (therefore 28 days from one full moon to the next) so you would get less than a 13 hour window where moonbounce would be effective for you and that window would be almost an hour different each day.
Misfit7707 said: I am the 29th person to post a comment! WOO!”
haha
I hope you’re paying out the people who brag about being first.
tannman said: “Agreed I left FM when we became nothing more then card turners that was handed a playlist. However in the Los Angeles market one vet jock has it in his contract that during his show he has full creative control, Jim Ladd at KLOS FM. I know do net radio…not as big or popular yet but a lot of fun.”
Jim Ladd is still around? I remember listening to him back in high school, somewhere around 1983ish.
It was DJs like Ladd and the jocks at K-SHE 95 in St. Louis that made me eventually have a go at the disc jockey business.
Unfortunately for ME, after about a year on the job, the industry embraced satellite feeds by which one on-air personality could (without any local flavor) be the voice for 50 radio stations at the same time.
All the entry-level jobs kinda dried up as small-market radio stations could subscribe to a feed cheaper than hiring a couple minimum-wage disc jockeys.
I ended up writing for a newspaper eventually – another medium that was supposed to be eliminated, first by radio, then TV, then the Internet.
Local content is what keeps newspapers (and radio stations, and TV stations) going.
But anyway, glad to hear Jim Ladd is still at it : )
I also agree that even though Satellite Radio is an interesting option, It will unlikely replace FM or AM.
First of all, as far as I know, only US, Canada and the northern part of Mexico get sat coverage.
Second, FM is incorporating digital signals (HD Radio), with good backwards compatibility for current fm gear, which will mean better quality on local stations.
And personally, I see Sat as more of a convenience instead of having to switch through CDs, but mp3 players can do that for me too, so I’d choose an mp3 player over Sat. Of course, this may not be the case for everyone. Still I think FM is established, and needs innovations just to keep it’s status as no. 1, Sat has to fight to keep growing, and AM will keep being the indie option for the masses …until WiFi(or some similar technology) becomes ubiquitous.
Re Sat radio and Clear Channel: I see these both sadly as continuing the homogenization of the culture. They contribute to the centralization and normalization of the music we hear.
A couple of years ago I took a vacation on Grand Cayman in the Carribean. I was really looking forward to hearing some different music: steel bands, reggae, and such. Maybe even some calypso? Instead, everywhere we went all that was played was American pop and country, the same stuff I was already bored with. One day I saw a sign announcing that the bar down the street was having a live, local steel band that evening! Finally, some real Carribean music! When I went, however, they just played steel band arrangements of American pop and country music. Huge disappointment.
at radio and Clear Channel just continue that trend.
I’ve had Sat Radio – it’s the same crap on 110 stations with a $14/month maintenance fee.
I like the way HD radio is going… two stations in my area are broadcasting HD comercial free to get people on board. When you digitize the audio and broadcast it – FM becomes CD quality, AM becomes long range FM quality… all those AM stations will now have the ability to broadcast decent quality music in > 100 mile radius.
I’m all for free music… sat radio will be around for the niche markets – like OTR truckers, people with extra cash to burn, or for people who really want to hear a specific station for $14 a month. However for the masses – HDR is the next evolutionary step in radio.
To the person saying the Church apologized.
Well, yes they did, but it was about 400 years after the fact … So we can look forward to them apologizing around 2350 ….
Note to self: patent, patent, patent some more.
Maybe, Armstrong was pushed. People have committed murder for much less money. Using the depression as a cover, someone might have thought they could easily put the threat of FM behind them forever if they could just…
I was born in the 50s, heard the beatles in the 60s and became a pro musician in the 70s. all as a result of radio. I listened to radio more than I watched tv because I loved the music and the format. When fm really took off in the 70s we were hearing music in full versions and albums and it inspired me, and countless millions more I’m sure to want to play. Some of my best memories and times were spent around the radio with friends partying and dancing and hearing the latest version of the greatest music ever written. It wasn’t our parents music, it wasn’t muzak. it was OUR MUSIC. FM put more bands and artists on the map than ever before, it opened up opportunities for artists from around the world to be heard. The great thing was that the government overlords doing big business’ bidding could control the technical aspect of radio and tv; BUT they could not regulate inspiration and artistry…well ok we didn’t hear too much Zappa and the such, but could you imagine Cheech and Chong being widely broadcast today with all of the political correctness and easily offended special interest groups obsessively listening and striking out at anyone who dares to speak against them and THEIR ideals??? There is more regulation and “spying” going on now than ever in the past. We are all supposed to just listen to the experts and government sactioned talking heads without ever questioning or critisizing. All in the name of paranoid national interests. We used to have free speech and free radio. Now everything is packaged for political correctness. So I just listen to JAZZ-FM. They have the least amount of talk and commercials and play nothing but great jazz. I still love rock, r&b and blues but they just aren’t the same as the great days of radio of the 50s to the 70s. By the way anyone remember Raould Casablanca of CFOX in Vancouver during the early 70s. He was awsome. They just don’t broadcast like that anymore.
Plain toasted bread anyone???!!!
Sorry if I’m ranting but this is my first time and I feel like a virgin. Be gentle with me out there…LOL…G.S.
I noticed that there were a few comments who blamed Armstrong’s fate on capitalism. But he got screwed twice and both times were by the government.
In the first case the Supreme Court shot down his patent despite the fact that he was first for 2 years. That is all government.
As for the 1945 ruling changing the frequencies…yes RCA was clearly the culprit there. But they used their lobbying influence (and God knows how much in the way of political campaigns) to influence the GOVERNMENT to suddenly change the dial. The government was the one who actually made the decision.
That was not the fault of capitalism. That was the government being influenced by crony capitalism.
The only reason why AM radio can be heard farther than FM, is not necessarily because of the mode, but because AM radio runs on the MF band while FM runs on the VHF band. MF signals can travel hundreds of thousands of miles. VHF signals can sometimes do this, but not like MF can. That’s why you hear all those old stories about “picking up AM channels/programs from far away late at night”. As an amateur radio operator, we have a band called the 160 m band that the frequency is 1.8-2.0 MHz. (AM radio is 535 KHz-1.7 MHz) so the 160 meter band is just above the AM radio band. And at night we can work the world with the 160 meter band. Same concept with AM broadcast radio.
GREED, GREED, GREED!!!! Little do these big companies realize is of they were honest in there dealings, and didn’t push the GENIUIS OUT OF THE WAY FOR MONEY, BIG BUSINESS in the long run would make so much more. WHO KNOWS HOW MANY MORE INVENTIONS THIS GUY WOULD HAVE THOUGHT OF. “GREED SEE’S THE SHORT TERM, INTEGRITY SEE’S THE LONG TERM”.
Although nearly twelve years ago, I clearly remember reading this entry. As is the case with all DI articles, it’s excellent.
I can honestly say that I listen to radio more than I watch television.
And I still listen to radio more than I watch television.
Checking back in.
Looking for other posters.
I too have read Edwin’s story many times. My first radio job was in fm station doing on air shifts in the south. I now live across the Hudson River from Edwin’s $300,000. blinking tower still in use located in the Palisades surrounded by nature. I have read that Sarnoff greatly regretted his actions and paid for Edwin’s funeral. Makes me sad sometimes when I think of people being so unkind, causing misery instead of bringing joy. The top light continues to blink on the tower this instant, almost 100 yrs later. And it provided temporary satellite replacement location after 9/11 for continued way for many stations to communicate. Edwin’s contributions are used everywhere on earth and he is remembered by those who stop to appreciate….that is everything.
Sarnoff and his engineers not only stole Armstrong’s FM system, they stole Philo Farnsworth’s television system. As with Armstrong, it took many years to set the record straight, but not before Armstrong killed himself and Farnsworth was driven to alcoholism.",1
168,"7,790 books — 23,456 voters
Goodreads helps you keep track of books you want to read.
Start by marking “More Than Human” as Want to Read:
Enlarge cover
Open Preview
See a Problem?
We’d love your help. Let us know what’s wrong with this preview of More Than Human by Theodore Sturgeon.
Not the book you’re looking for?
Preview — More Than Human by Theodore Sturgeon
More Than Human
by
3.95 · Rating details · 17,225 ratings · 990 reviews
There's Lone, the simpleton who can hear other people's thoughts and make a man blow his brains out just by looking at him. There's Janie, who moves things without touching them, and there are the teleporting twins, who can travel ten feet or ten miles. There's Baby, who invented an antigravity engine while still in the cradle, and Gerry, who has everything it takes to run ...more
Paperback, First Vintage Books Edition, 186 pages
Published January 1999 by Vintage
(first published October 1953)
Friend Reviews
To see what your friends thought of this book, please sign up.
Reader Q&A
To ask other readers questions about More Than Human, please sign up.
Be the first to ask a question about More Than Human
Best Science Fiction & Fantasy Books
Most Under-rated Science Fiction
1,936 books — 2,022 voters
More lists with this book...
Community Reviews
Showing 1-30
Average rating 3.95 ·
· 17,225 ratings · 990 reviews
|
Start your review of More Than Human
May 21, 2007 Bill Kerwin rated it it was amazing
Shelves: science-fiction
If you have ever been lonely and longed for completion, you will be drawn to this book. But if you are one of those rare souls who sense that completion demands more than a wife or a husband, who yearn to find a small group of friends like yourself--but different--who can believe and will the same thing and yet still manage to preserve their distinctive humanity, then this book is the thing for you.
More Than Human is about six people—each with a distinct and extraordinary power—who wander lost a ...more
Dec 02, 2013 Lyn rated it it was amazing
You pick up the book, turn to the back cover and are confronted with the man. So this was Kurt Vonnegut’s model for Kilgore Trout. Staring back at you is a gaunt image: a scraggly, bearded man who but for the pipe and the contented look might offer the same aspect from a homeless person or from a Jethro Tull album jacket.
Turn to the first page and read - “The idiot lived in a black and grey world, punctuated by the white lightning of hunger and the flickering of fear. His clothes were old and ma ...more
Turn to the first page and read - “The idiot lived in a black and grey world, punctuated by the white lightning of hunger and the flickering of fear. His clothes were old and ma ...more
Mar 05, 2022 Glenn Russell added it
Beginning in the 60s and 70s, readers witnessed a fresh approach in the world of science fiction, an approach that switched its focus from outer space to inner space. This innovation came to be known as New Wave SF. Some of the New Wave authors include Michael Moorcock, J.G. Ballard, M. John Harrison, Brian Aldiss, Philip K. Dick, Samuel R. Delany, Thomas M. Disch, Norman Spinrad and Harlan Ellison.
If we search out a key precursor for this cutting edge, creative angle on science fiction, we have ...more
Aug 01, 2011 Apatt rated it it was amazing
“We’re not a group of freaks. We’re Homo Gestalt, you understand? We’re a single entity, a new kind of human being. We weren’t invented. We evolved. We’re the next step up. We’re alone; there are no more like us. We don’t live in the kind of world you do, with systems of morals and codes of ethics to guide us. We’re living on a desert island with a herd of goats!”
More Than Human is all about “Homo Gestalt” a group of humans with different psi abilities living together as one unit. It is not abou ...more
More Than Human is all about “Homo Gestalt” a group of humans with different psi abilities living together as one unit. It is not abou ...more
Jan 11, 2010 Felicia rated it it was amazing
Were I to take an in-depth Sci-Fi course I would definitely want to explore the deeper meanings of this book, lots of layered psychological here. I'm already reserving it for a re-read. It is disturbing and fascinating, the story of an...evolved group of creatures, the only way I can describe it. Just try it, it's short but packed with wonderment. ...more
Jul 16, 2012 Lark Benobi rated it it was amazing
I have no explanation for my deep love of this novel. It's hokey and ridiculous and overwrought and leaves bushels of interesting themes all over the place, unassembled. It's hopelessly dated. I love it. I connect with these very implausible characters. I revere this author for writing with such careless abandon of form or plot and who still keeps me riveted. This may have been my fourth or fifth reading of this particular novel. It's one of my security-blanket books. ...more
Oct 27, 2022 Kevin Kuhn rated it really liked it
“More than Human” was published in 1953 by American Science Fiction writer Theodore Sturgeon. This novel was a fix-up of three novellas. It was awarded a retro-Hugo in 2004 and also won the 1954 International Fantasy Award. I found it to be a frustrating read, but ultimately rewarding.
I want to start with Sturgeon, who’s life I find fascinating. He was a merchant marine sailor, a door-to-door refrigerator salesman, a Jamaican hotel manager, and a construction worker. All of those jobs happened ...more
I want to start with Sturgeon, who’s life I find fascinating. He was a merchant marine sailor, a door-to-door refrigerator salesman, a Jamaican hotel manager, and a construction worker. All of those jobs happened ...more
Jun 13, 2020 Baba rated it really liked it · review of another edition
Shelves: spec-fi-i-guess, sfmasterworks
SF Masterworks 28 - although first published in 1953, this has aged extremely well, and is a from the off, a masterclass in how to make your story timeless. Now the book itself - and what an extraordinary book it is... seven people with different types of evolved power (telekinesis, mind control, teleportation etc.) struggle as outsiders amongst people they can't relate to, but who are aware of their otherness. In a very unpredictable and stunning approach, a lot of this book is about the paths ...more
Jun 04, 2019 Alex rated it liked it
Time to admit that I read this and it made very little impression on me. It's obscure and hard to understand, for no particular reason; all that fancy language covers up some pretty conventional emotions. The story itself is fun - humans with special powers form some sort of gestalt - but I would've liked it more if he'd just told it. Gestalt is a fancy word for Voltron.
There's an optimism at the bottom of this book - the idea that humans are, by nature, resourceful and good. There's no real-wor ...more
There's an optimism at the bottom of this book - the idea that humans are, by nature, resourceful and good. There's no real-wor ...more
Jun 10, 2021 Monica rated it really liked it · review of another edition
Shelves: classics, kindle_scifi_fan, scifi-earth, sf-challenge-2021, random-adds, audible, awards-big, pub_1950
Hmmmm, these older classics are tricky. Whereas I appreciated the characterization and creativity, conceptually it still felt a little dated. Sturgeon ponders human evolution. It was definitely creative however, what is perhaps indicative of the times, humans are inherently evil but redeemable. Idk, the cynic in me says meh on the plot but I need to applaud Sturgeon's writing talent. Uncharacteristic of the science fiction writers of that era, Sturgeon is talented. He weaves an interesting tale ...more
Jan 23, 2009 Manny rated it liked it
Shelves: science-fiction, science, linguistics-and-philosophy
In a classy novel-length parable, Theodore Sturgeon explains why every next-generation AI project needs an ethics advisor. It took me ages to understand what this book was about.
Jan 02, 2013 Palmyrah rated it it was ok
One I missed back in the early Eighties when I was going through the classics of science fiction like a hot knife through butter. Maybe I'd have liked it better if I'd read it back then. Probably not.
It's an act of charity to call this SF at all. It's supposed to be about the emergence of a new species, but from an evolutionary point of view the emergence described could not possibly take place – the whole concept is ridiculously unscientific. The story does contain one authentic science-fiction ...more
It's an act of charity to call this SF at all. It's supposed to be about the emergence of a new species, but from an evolutionary point of view the emergence described could not possibly take place – the whole concept is ridiculously unscientific. The story does contain one authentic science-fiction ...more
Jun 16, 2017 Dave rated it really liked it
Shelves: read-have, science-fiction-classic, science-fiction-all
Theodore Sturgeon's ""More Than Human"" is one of the strangest and, at the same time, most fascinating novels (or group of three connected novellas) that you will read. It is written in beautiful, otherworldly prose that sets it apart in time and space and begins as if it were a narration of an ancient legend. It jumps a bit between plot lines and the reader may have to read some parts, especially in the beginning, more than once. What is amazing about it is that it was written in 1953 and it exp ...more
Jun 06, 2021 Anthony rated it really liked it · review of another edition
Shelves: hugo-nominees, sf-group-2018, sf
A fascinating, poetic, complex classic work of SF by one of the genre’s most revered writers. It’s at once ahead of its time in the themes it explores, the richness of its language, and its heady, experimental approach; and it’s very much rooted in its time with its depiction of hypnotic suggestion, psychology, and psychedelic ideas. It’s my first encounter with Sturgeon’s prose; I was already an admirer of his writing of the indelible Star Trek episode “Amok Time.” I’ll definitely read more of ...more
Jun 29, 2021 Montzalee Wittmann rated it really liked it
Shelves: science-fiction-fantasy
More Than Human
by Theodore Sturgeon
I read this when I was a teen, some 40+ years ago. I can't say I remember anything about it from then but I read almost all his books out at the time. This was nice to revisit to see if it jogged any memories but it didn't. I have too many past books stored up there! Lol! Many must have been reshelved.
The story is about a variety of children who have odd gifts and sometimes physical quirks that make them freaks to most.
I enjoyed how the author followed each c ...more
by Theodore Sturgeon
I read this when I was a teen, some 40+ years ago. I can't say I remember anything about it from then but I read almost all his books out at the time. This was nice to revisit to see if it jogged any memories but it didn't. I have too many past books stored up there! Lol! Many must have been reshelved.
The story is about a variety of children who have odd gifts and sometimes physical quirks that make them freaks to most.
I enjoyed how the author followed each c ...more
May 04, 2022 DivaDiane rated it it was amazing · review of another edition
5 stars (well, almost!)
Don’t let the beginning put you off!
This is an old book, written in an era when vocabulary, or labels were different to ours. I was a little annoyed at the labels used (idiot/half-wit, negro/colored, mongoloid mostly) but otherwise, the writing was balanced and literary and the people to whom those labels were given had special talents and were valued for their contributions. The beginning is a little bit hard to parse, but things become clearer soon enough.
This is just th ...more
Don’t let the beginning put you off!
This is an old book, written in an era when vocabulary, or labels were different to ours. I was a little annoyed at the labels used (idiot/half-wit, negro/colored, mongoloid mostly) but otherwise, the writing was balanced and literary and the people to whom those labels were given had special talents and were valued for their contributions. The beginning is a little bit hard to parse, but things become clearer soon enough.
This is just th ...more
May 28, 2021 Hank rated it liked it
Shelves: scifi-club-read
I get why some older books are ground breaking and important but that doesn't mean I have to like them now. More Than Human was one of the earlier sci-fi novels that recieved some acclaim for ""transending"" science ficture and pushing it more towards literature. As usual, my tendency is to rate older novels based on today's writing and as usual they don't usually measure up.
The speculative part which is multiple humans makeing up a greater whole, isn't well explored. Sturgeon basically slapped to ...more
The speculative part which is multiple humans makeing up a greater whole, isn't well explored. Sturgeon basically slapped to ...more
Jun 21, 2021 Allison Hurd rated it really liked it
Shelves: sff-bookshelf, man-author, scifi, sff-2021-challenge
I enjoyed this more than I thought I would. I enjoy stories of people who share consciousness and purpose, like Sense8 or Escape to Witch Mountain, and I think this is likely one of the early influences of those stories.
CONTENT WARNING: (view spoiler)[ child abuse, mind control, mental health crises, loss of a child, loss of a partner (hide spoiler)]
Things to love:
-The writing. This does not feel at all like the standard pulpy ""golden age"" scifi read. It's considered, experimental, and sort of ...more
CONTENT WARNING: (view spoiler)[ child abuse, mind control, mental health crises, loss of a child, loss of a partner (hide spoiler)]
Things to love:
-The writing. This does not feel at all like the standard pulpy ""golden age"" scifi read. It's considered, experimental, and sort of ...more
Feb 08, 2022 Kevin rated it it was amazing · review of another edition
Shelves: fiction, short-reads, science-fiction, reviewed
Classic Sci-Fi from one of the Godfathers of the genre. Sturgeon’s tale of an assemblage of misfits, each with a special skill, coming together to perform as a single organism [“Homo gestalt”] is both dark and strangely uplifting. I’m not really a connoisseur of fiction but occasionally, from time to time, I stumble upon a hidden gem or an underrated opus. This might be one of those times.
Oct 20, 2009 Amanda rated it it was amazing · review of another edition
Shelves: best-of-the-best, sf-masterworks-series-read
OK- what to even say about this masterpiece- which it undoubtably is! For all u fools out there who do not think science fiction can be literature of the highest degree, u obviously haven't read a book like More Than Human- because if this book doesn't blow that dense, dull-witted notion out of your mind, nothing will and u should be publicly shunned forevermore.
Written in the 50's and it still didn't seem dated at all! That alone is an astounding feat. Anyway, i don't even think i can begin to ...more
Written in the 50's and it still didn't seem dated at all! That alone is an astounding feat. Anyway, i don't even think i can begin to ...more
Apr 25, 2021 Kevin Lopez (on semi-sabbatical) rated it it was amazing · review of another edition
Absolutely stunning. Mesmeric. I think I may have found my new sff obsession!
Jan 18, 2010 Stephen rated it really liked it
4.0 stars. Ground-breaking science fiction novel that first explored the concept of the ""gestalt"" consciousness while dealing with emotional issues of identity and fitting in to society. This is on my list to re-read as it has been some time since I read this.
Nominee: Hugo (Retro) Award for Best Science Fiction Novel ...more
Nominee: Hugo (Retro) Award for Best Science Fiction Novel ...more
May 05, 2012 Whitaker rated it really liked it · review of another edition
Shelves: z_2012-read, fantasy-scifi
I think the only meaningful ratings on GR are *, **, and *****. Those are pretty clear: “I disliked it”, “it was okay”, and “it was amazing”. *** and **** exist in that intermediate stage between “meh” (**) and “wow” (*****). “I liked it” and “I really liked it”. WTF? How exactly do I differentiate between “liking” something and “really liking” it?
A lot of how we respond to stories is so personal to what we enjoy and what we’ve read before. One thing that I usually like in books is when it thro ...more
A lot of how we respond to stories is so personal to what we enjoy and what we’ve read before. One thing that I usually like in books is when it thro ...more
Jan 14, 2011 Kathryn rated it really liked it · review of another edition
Shelves: science-fiction
This is my first novel by Theodore Sturgeon and it most certainly will not be the last. I read the book in one sitting. I'm not sure now if that was a good idea but I was entranced, could not sleep, and it is rather short. I was certain the book would be listed on my favorites shelf but the ending, or certain characterisitcs of the ending, forced me to withdraw from the book and look at it from the outside, not from within as I had the majority of the story.
I knew before beginning that Sturgeon ...more
I knew before beginning that Sturgeon ...more
Mar 20, 2020 Paul rated it really liked it
Shelves: books-read-in-2020
This undoubtedly deserves its place as a much-lauded classic of the SF genre and it has spawned countless imitators (not least of which being Lee and Kirby’s X-Men) but, and this is probably unpopular opinion time again, it is not perfect.
Putting aside the fact that the prose gets more than a little purple at times, this novel is an expanded revision of a previously published novella... and it reads like it. Every section of this book is excellent standing alone but when you look at it all as a ...more
Putting aside the fact that the prose gets more than a little purple at times, this novel is an expanded revision of a previously published novella... and it reads like it. Every section of this book is excellent standing alone but when you look at it all as a ...more
Jun 05, 2021 YouKneeK rated it liked it · review of another edition
Shelves: science-fiction, standalone
It’s difficult to provide a teaser for this story without spoiling anything. I went into it blind and was pretty confused about what I was reading at the beginning, but it soon starts to make sense, and seeing the bigger picture form was part of the fun. I’ll just talk about the very beginning. In the beginning, we’re introduced to an “idiot”. He doesn’t speak, he doesn’t seem to have any intelligent thoughts, he doesn’t have a family or a home. He wanders around, with no reliable source of food ...more
Apr 14, 2013 Stuart rated it liked it
Shelves: classic-sf, superhuman-powers, humanistic-sf
More Than Human: Introducing the “Homo Gestalt”
(Also posted at Fantasy Literature)
This book must have been quite an eye-opener back in 1953 in the Golden Age of Asimov, Heinlein and Clarke, where robots, rocket ships, future societies and aliens ruled the roost. For one thing, it hardly features any credible science at all, and in tone and atmosphere owes more to magic realism and adult fantasy. In fact, the writing reminds me most of Ray Bradbury, full of poetry and powerful images. Try reading ...more
(Also posted at Fantasy Literature)
This book must have been quite an eye-opener back in 1953 in the Golden Age of Asimov, Heinlein and Clarke, where robots, rocket ships, future societies and aliens ruled the roost. For one thing, it hardly features any credible science at all, and in tone and atmosphere owes more to magic realism and adult fantasy. In fact, the writing reminds me most of Ray Bradbury, full of poetry and powerful images. Try reading ...more
Feb 01, 2019 Oleksandr Zholud rated it really liked it
This is a SF novel won the second ever Hugo Award in 1954. I read it as a part of Monthly reads in Hugo & Nebula Awards: Best Novels
This is interesting story, which had rather revolutionary ideas for its time, but now is a little outdated. It describes the next step in human evolution, Homo gestalt ( “You’re afraid of Homo Gestalt.”
He made a wonderful effort and smiled. “That’s bastard terminology.”
“We’re a bastard breed,”), a community of people, who are parts of something more than human. One ...more
This is interesting story, which had rather revolutionary ideas for its time, but now is a little outdated. It describes the next step in human evolution, Homo gestalt ( “You’re afraid of Homo Gestalt.”
He made a wonderful effort and smiled. “That’s bastard terminology.”
“We’re a bastard breed,”), a community of people, who are parts of something more than human. One ...more
Apr 03, 2017 Jim rated it really liked it · review of another edition
A group read with the ""Evolution of SF"" group. I've read this in paperback a couple of times & enjoyed it, but it's probably been 15 or 20 years. Blackstone's audio version has Rudnicki & Ellison narrating. Rudnicki is always great. Ellison does some voices well & I can think of a couple of good ones for him. Hopefully they'll keep him to that. In any case, it was worth buying.
It was! Ellison read the middle part, ""Baby Is Three"", the original novella (1952). It is told from Gerry's point of vie ...more
It was! Ellison read the middle part, ""Baby Is Three"", the original novella (1952). It is told from Gerry's point of vie ...more
Nov 19, 2020 Lizz rated it it was amazing
I don’t write reviews.
This is a strange little book. I read the description, but this isn’t a book where the description illuminates the reader. You must dive in. I felt the oddness in my bones. The characters aren’t “normal.” Are they human? Yes, yes, but are they more than.... no I’ll stop there.
The situations are interestingly complex. It was like looking into a miniature village in a snow globe or at a scene in a shadow box. Have you ever seen copper pennies made into tiny doll house furni ...more
This is a strange little book. I read the description, but this isn’t a book where the description illuminates the reader. You must dive in. I felt the oddness in my bones. The characters aren’t “normal.” Are they human? Yes, yes, but are they more than.... no I’ll stop there.
The situations are interestingly complex. It was like looking into a miniature village in a snow globe or at a scene in a shadow box. Have you ever seen copper pennies made into tiny doll house furni ...more
|topics||posts||views||last activity|
|SciFi and Fantasy...: '""More Than Human"" Discuss Everything *Spoilers*||20||111||01 juil. 2021 15:25|
|SciFi and Fantasy...: ""More Than Human"" First Impressions * No Spoilers*||19||117||30 juin 2021 17:28|
|What's the Name o...: SOLVED. Adult Science Fiction (but not space war type) that takes place on earth about weird people with powers. The book is kind of dark. Spoiler ahead. [s]||4||33||30 juil. 2020 23:52|
|Hugo & Nebula Awa...: February 2019 ""More than Human"" <Caution! Spoilers May Be Present!>||26||14||27 fév. 2019 12:22|
|Hugo & Nebula Awa...: February 2019 ""More Than Human"" <No Spoilers>||11||12||23 fév. 2019 07:22|
963 users
70 users
35 users
21 users
15 users
650 followers
Theodore Sturgeon (1918–1985) is considered one of the godfathers of contemporary science fiction and dark fantasy. The author of numerous acclaimed short stories and novels, among them the classics More Than Human, Venus Plus X, and To Marry Medusa, Sturgeon also wrote for television and holds among his credits two episodes of the original 1960s Star Trek series, for which he created the Vulcan m ...more
Related Articles
When you work at Goodreads, you get a really good peek at the books that are about to hit bookstores. And, well, we get Very Excited about...
106 likes · 30 comments
“Just think about it,"" he said softly. ""You can do practically anything. You can have practically everything. And none of it will keep you from being alone.""
""Shut up shut up...Everybody's alone.""
He nodded. ""But some people learn how to live with it.”
—
23 likes
""Shut up shut up...Everybody's alone.""
He nodded. ""But some people learn how to live with it.”
“Ask Baby can you be truly part of someone you love.""More quotes…
""He says only if you love yourself.”
—
18 likes
""He says only if you love yourself.”",8
169,"The sixteen stories and two screenplays that make up Volume One of the Emmy® award-winning Netflix series Love, Death & Robots. Featuring best-selling authors and screenwriters from all over the globe, curated by filmmakers Tim Miller and David Fincher. Stories and screenplays by Alastair Reynolds, Alberto Mielgo, Claudine Griggs, David W. Amendola, Joe Lansdale, John Scalzi, Ken Liu, Kirsten Cross, Marko Kloos, Michael Swanwick, Peter F. Hamilton, Steven Lewis, and Vitaliy Shushko",8
170,"In 2021, global electric vehicle sales hit 6.6 million – more than double the 3 million in sales in 2020 — meaning EVs made up 9% of the global car market last year.
That’s the good news, from a decarbonization standpoint.
Here’s the bad news. Just as it begins to gain momentum, the electrification of transportation could begin stalling as early as mid-decade.
Starting around 2025, demand for key battery metals could start exceeding supply, adding costs to EV battery manufacturing, and putting the brakes on EV adoption, according to a new detailed analysis by S&P Global, The Future of Copper.
In fact, car manufacturers are already facing supply chain constraints for certain key metals, and are already resorting to substitution materials.
Ford Motor Co. (NYSE:F) announced this week it will switch to lower performance batteries for some of its EV vehicles, a move aimed at meeting production goals while addressing nickel supply issues. For some standard EV models, Ford will use lithium-iron-sulphate batteries, which don’t require nickel or cobalt.
Meanwhile, the International Energy Agency (IEA) warns a lithium shortage could start around 2025.
There was enough lithium mined in 2021 to supply 11.4 million EVs, according to the World Economic Forum.
If EV sales double again over the next couple of years, the EV market will already exceed the current global supply of lithium, unless new mines and refiners come into production by then. Llithium prices are up 380% from a year ago, according to Kitco.
But it’s copper that is the biggest worry, with the biggest driver of scarcity being the energy transition and increased EV demand, although the demand for more power transmission will also add strain to the supply of copper.
“Major investments in the power grid to support electrification will further amplify the trend,” the Future of Copper report notes.
“The 2050 climate objectives will not be achieved without a significant ramp-up in copper production in the near and medium term, which will be very challenging,” the S&P Global report warns.
A battery electric vehicle requires 2.5 times more copper than a standard internal combustion engine vehicle. Much of that is in the electric motor, some in the battery.
There simply aren’t enough copper mines being built or expanded to provide all the copper needed to produce the 27 million EVs that S&P Global has forecast to be sold annually by 2030.
“The chronic gap between worldwide copper supply and demand projected to begin in the middle of this decade will have serious consequences across the global economy and will affect the timing of Net-Zero Emissions by 2050,” the Future of Copper report warns.
Copper could rival oil as a national energy security concern for some countries.
“In the 21st century, copper scarcity may emerge as a key destabilizing threat to international security,” the report warns.
Under what it calls the High Ambition Scenario, S&P Global forecasts refined copper production would nearly double, from 24.5 million tonnes in 2021 to more than 47 million tonnes in 2035.
That still wouldn’t be enough.
“This results in chronic shortfalls between copper and supply demand beginning in 2025 and lasting through most of the 2030s, including a shortfall of more than 1.5 (million tonnes) in 2035 alone.
“But this scenario hinges on very significant increases in both capacity utilization and recycling rates. High Ambition is a highly optimistic scenario. What this scenario demonstrates is that, even at the outer edge of what could happen in copper mining and refining operations, there will not be enough supply to meet the demand identified for Net-Zero Emissions by 2050.”
A more dire forecast, which the report calls the Rocky Road Scenario, is for an annual supply shortfall of almost 10 million tonnes in 2035.
That is equivalent to the production of 75 copper mines the size of B.C.’s Highland Valley Copper mine – Canada’s largest – said Michael Goehring, president of the Mining Association of BC.
“Projects under development today would likely not be sufficient to offset the projected shortfalls in copper supply, even if their permitting and construction were accelerated,” the Future of Copper report notes.
Some of the metals used in batteries may be able to be substituted – iron replacing nickel, for example, in lithium-iron-phosphate batteries – said Matthew Klippenstein, former adviser for Plug In BC, and current executive director for Hydrogen BC.
“And Iron is really plentiful,” he notes.
But there really is no substitution for copper in electric cars. It is needed for the batteries, the wiring and the motors. Even if aluminum can become a substitute for copper, as has been suggested, that would just shift the need for more copper mining to more more bauxite mining and aluminum smelters.
Conservationists opposed to new copper or lithium mines may point to recycling as a solution. It’s not.
While a recycling and reuse industry for EV batteries will be needed, it won’t come anywhere close to supplying the necessary metals.
If the number of EVs on the road today remained static for the next 20 years, recycling the metals in them might be able to make up the bulk of the demand. But EV sales are growing exponentially.
There were 3 million electric cars sold globally in 2020, according to the IEA. That more than doubled in 2021 to 6.6 million. By 2030, S&P Global forecasts there will be nearly 27 million sold annually.
Assuming a battery life of 10 years (some may last as long as 20 years), even if every one of the 3 million batteries and motors sold in EVs in 2020 were to be recycled, that would provide only 11% of the metals needed in 2030 for 27 million electric cars.
The IEA estimates that recycling could meet only about 10% of the demand for battery materials in 2040.
Edward Chiang, CEO of B.C.’s Moment Energy, which repurposes EV batteries for use in stationary power storage, said there are serious challenges to EV battery recycling, mainly the cost, which is why his company repurposes them, rather than recycle the metals in them.
“Currently recycling (an EV battery) is an expensive process where North Americans are footing the bill,” Chiang said. “That’s why they’re charging people thousands of dollars for recycling. That’s why the stat is only 5% of all EV batteries are being recycled.”
The biggest market for used EV batteries may be in repurposing them in stationary storage applications, not recycling, according to McKinsey and Co.
An EV battery that is at 80% capacity may no longer be suitable for an electric car, but when they are stacked for stationary power storage, they are still perfectly useable and can last many more years.
“Reuse can provide the most value in markets where there is demand for batteries for stationary energy-storage applications that require less-frequent battery cycling,” says a McKinsey report from 2019.
“The math does not add up,” Chiang said. “Recycling is not the solution to EV demand. It’s going to help – 10%, 20% of the demand — but it’s not going to solve it. We’re still going to have to open up more mines and do better in refining clean processes to meet our EV production targets.”
While there is enough copper in the world, geologically speaking, to supply the increased demand, there isn’t enough time.
It takes 10 to 15 years to get a new copper mine through permitting and construction. Twenty years is not unusual for very large projects.
Goehring said B.C. has “significant potential” to increase copper production, and there are a couple of expansions, and two new mine proposals, in the pipeline.
B.C. is Canada’s biggest copper producer. But Canada is a minor producer compared to Chile, Peru, China and the U.S.
Canada’s total copper production was estimated at 475,898 tonnes in 2020, according to Natural Resources Canada, half of it from B.C. Chile’s is about 5.5 million tonnes annually, Peru 2.5 million tonnes, China 1.5 million tonnes.
Judging by the recent political tide shift in Chile, copper mining there could become more restricted. Chile’s new president, Gabriel Boric, has been busy in recent months rejecting new copper mines and expansions. Anglo American alone has had two copper mine expansions rejected just in the last couple of months.
In B.C., there are currently two mine expansion proposals that are close to having final investments decisions made, Goehring said – Highland Valley Copper and Red Chris — and two proposed new mines: the KSM gold-copper mine and the Galore Creek copper mine.
Whether they can be permitted and built in time to help address the looming copper crunch remains to be seen.
“Senior policymakers need to focus significant amount of attention on this,” Goehring said. “A credible and robust climate strategy needs to incorporate the supply side of critical metals.”",2
171,"Maybe you’ve noticed the pickup window peeking out on Lafayette Street in Soho. Or the seafoam-green cart that looks like a cross between a Vespa and an Airstream stationed in a former parking lot on the corner of Smith and Pacific Streets in Boerum Hill. In the past year, the coffee start-up Blank Street has opened 11 locations like these around New York City, a mix of zero-emission street carts and “micro-shops” less than a quarter of the size of an average café.
The first time I came across Blank Street, I wondered why anyone would open yet another coffee chain in what must be one of the most caffeine-saturated cities on earth — a place where you are never more than a block away from a boutique café, a Starbucks, a Dunkin’, a bodega, a diner, or a classic chrome street cart. But Vinay Menda and Issam Freiha, the 20-something founders of Blank Street, say there is also room for the 100 locations they hope to have operational by the end of 2022.
“We went to everyone we knew and asked them how they thought about coffee, how much they spent, what was their favorite brand,” Menda says. “What we kept hearing was, ‘I would rather have La Colombe or Blue Bottle, but I end up going to Starbucks because it’s right there — and the app is good.’” Cost, he adds, was another concern: “These third-wave brands are too expensive over time. So how could we take these high-quality products and make them more convenient and cheaper?”
A version of this pitch — a staple product, optimized, with aggressively cute branding and affordable pricing — has fueled countless start-ups, and Menda and Freiha have already raised a $7 million seed round primarily from three venture-capital firms: Base10, Quiet Capital, and FJ Labs. But a crucial difference between Blank Street and many of its millennial-baiting start-up brethren is that cups of coffee are not eyeglasses or suitcases or cookware. A coffee shop cannot simply cut costs by using the direct-to-consumer model that has been pivotal to the success of brands like Everlane and Away.
Still, Blank Street has managed to underprice the competition. A cappuccino costs $5 at Blue Bottle, $4.15 at Starbucks, and $3.90 at Dunkin’ Donuts. At Blank Street, it’s $3.50. To achieve this, Menda and Freiha have had to fundamentally rethink what customers like them really want from a coffee experience today, and what that might mean for the future of the beverage in New York City. Perhaps the most intriguing aspect of Blank Street is not just the way that the founders have fastidiously optimized their own operation but also the vision that Menda and Freiha have to update the thousands of coffee carts already doing business on city streets.
Menda, who is 28, was born in Dubai when it was still, as he puts it, “a desert with one shopping mall and one cinema.” As he grew up, so did the city around him. “Because it was a new city, it didn’t have a native cuisine or authentic local restaurants,” Menda recalls. Dubai’s culinary scene has relied heavily on franchised concepts from the West, often imported by young Emiratis who would leave the country for college and return with a deal to open a restaurant like Indochine. When Menda left home at 18 to attend NYU, he figured that one day he would do the same.
Once in New York, however, he found himself drawn to the city’s nascent start-up scene. He interned at small tech companies and began to build a network of founders and entrepreneurs he met at industry events and conferences. Sophomore year, Menda met Freiha, a like-minded Columbia University student, and the two launched a venture fund out of their dorm rooms, raising $5,000 and $10,000 checks from friends, family, and even their professors. That effort grew into Reshape Ventures, and today Menda and Freiha have invested $100 million in businesses like Reddit, Imperfect Foods, and the scooter company Bird.
By 2019, when they were 24 and 27, respectively, Freiha and Menda decided to become founders in their own right. They homed in on a cluster of high-growth, mobile-first food-retail businesses making waves in Asia, such as Kopi Kenangan in Indonesia and the Chinese brand Heytea. Both achieved explosive growth by selling high-quality coffee and tea from tiny retail spaces. As Menda explains, “We saw that if you can optimize locations to be pickup hubs, with all the ordering happening through mobile, you can use the savings you get to make things cheaper for customers.”
On a recent Monday morning, Menda stood in the parking lot of an empty diner on Wythe Avenue in Williamsburg. In front of him was a Blank Street cart about the size of an ice-cream truck, its stainless-steel interior packed tight with stacks of pistachio-hued cups, a glass case filled with breakfast pastries, a warming oven for breakfast tacos, and a cold-brew dispenser. A tabletop grinder sat loaded with beans from Parlor Coffee — a local roaster that got its start in the back of a trendy barbershop — ready to supply a brewer churning out drip coffee. Instead of a big chrome La Marzocco rig, which is the standard for espresso drinks for a certain stratum of coffee shop, the cart was outfitted with a slim automatic machine made by the Swiss company Eversys. A single employee calmly dispensed lattes and Americanos by simply pressing a button.
“It’s hard for a specialty-coffee shop to switch to an automatic machine because when a customer is paying five or six dollars, they want to feel the experience of someone making something for them,” Menda says. “Our view is, from a quality perspective, that isn’t actually important.”
When I spoke to specialty-coffee executives about Blank Street’s contention that there’s no magic to a handmade espresso, I expected resistance. Instead, I heard surprisingly consistent support for automation in general and for the Eversys machine in particular. “I love manual machines — I love the noise, I love the smell,” says Nicolas O’Connell, the Senior Vice President of Wholesale and Sales at La Colombe. “But it takes 15 hours to train someone to do just an okay job on a manual machine, hundreds of gallons of milk to train them to make a decent latte. You want to provide a product that’s consistent day after day, and there are very few people who really understand how to do that.”
Between the Eversys machines and a mobile order-ahead app, Blank Street’s locations can run smoothly with just one or two employees, not five or six. Even though Blank Street says that by October 1 it will guarantee a minimum wage of $23 per hour for its baristas (including tips), the savings add up. Then there’s the real estate. It’s typical for a New York City coffee shop to spend $15,000 or more on rent, whereas Blank Street might pay a few thousand dollars a month to set up a cart in a parking lot or plaza.
This real-estate strategy might be Blank Street’s most important innovation. The vast majority of New York City’s street vendors, from coffee and bagel sellers to halal carts, operate under what is known as a nonrestricted-area permit. Just 3,000 of those permits exist now. Though that cap is slated to rise over the next decade, excess demand nevertheless means that most vendors rent their permits for exorbitant sums on an underground market or choose to operate illegally.
Menda and Freiha discovered that would-be vendors can also work with landlords to set up vending carts on private land, which in essence makes them exempt from the permitting limits imposed on public street vending. Menda and Freiha reckoned that with sleek branding, battery-powered carts made in partnership with EVFoods, and their deal-making experience, these deals would be theirs for the taking.
For their brick-and-mortar locations, Blank Street’s model focuses on exceedingly tiny shops. Over time, Blank Street also expects to work with landlords to wall off the front portion of larger spaces, activating those storefronts while leaving the rear portion for ghost kitchens, warehouses, or other features of the on-demand economy.
So far, the results are encouraging: Every Blank Street outpost is profitable, and the first location earned back its initial investment after just eight months. The company has stuck to its plan of establishing carts only in partnership with private landlords and has deals in place with Brookfield and the Parks Department as well as a number of independent property owners. But if Blank Street intends to expand from a dozen locations to a hundred or more, that will likely mean delving into the complex world of nonrestricted-area permits. They also have to make sure their coffee tastes good.
In the coffee business, “specialty” is a broad term of art that encompasses a certain ethos around ethical sourcing and meticulous roasting. Menda and Freiha — who say they and Parlor pay the same for their coffee as other third-wave outfits — are not the first to question what a cup of specialty coffee really needs to cost. In 2016, LocoL, a California fast-food concept founded by chefs Daniel Patterson and Roy Choi, began selling coffee brewed from high-end beans for $1 per cup. The person behind that initiative was Tony “Tonx” Konecny, a coffee-industry veteran who was instrumental in creating the retail experience at early third-wave roasters like Victrola and Intelligentsia.
Konecny says he was inspired to create something radically affordable for LocoL after tiring of what he came to see as needless complexity in the specialty-coffee world. “A lot of the pomp and pretense that emerged around barista culture in the early 2000s was coming out of an attempt to differentiate against Starbucks,” Konecny tells me. In other words, if you were going to charge more than the big green monster, it helped to have $30,000 worth of equipment behind the counter and somber, highly trained professionals visibly laboring over the drinks.
LocoL shuttered in 2018, but Konecny says that the coffee didn’t drag it down; it wasn’t printing money, but it wasn’t a loss leader, either. LocoL served brewed coffee, but when it comes to espresso-based drinks like lattes and cortados, Konecny — who now runs a coffee subscription service called Yes Plz — doesn’t see automatic machines as a barrier to quality. “We’ve bench-tested a lot of fully automated machines, and it still requires you to have enough of a palate to be able to tune them,” he says, adding that the technology is improving all the time. “But if the beans are good, you can fuck it up six ways from Sunday and the coffee will still turn out pretty tasty.”
So how does Blank Street’s coffee measure up? The flavor profile might best be described as gentle. Its espresso is distinctly floral, the drip coffee light in flavor, though not without body. The coffee lacks the bitter burnt notes that will be familiar to Starbucks drinkers as well as the more eccentric fruitiness found in some single-origin coffees. The auto-frothed milk is passable; offering the option of oat milk is a nice touch. Blank Street’s coffee is, on the whole, unobtrusive and pleasant — just what you’d expect from a product devised with broad appeal in mind.
Menda says he doesn’t want Blank Street’s trailers to compete with New York’s vast collection of existing street vendors but instead would like to partner with them, operating carts on their behalf, sharing technology, and guaranteeing a minimum income.
Like many New Yorkers, I have a deep affection for coffee carts and view them as a vestige of a quickly vanishing New York, not quite so full of gleaming salad bars and WeWork outposts. So as devoted as I am to the pursuit of excellent coffee, I confess that the notion of Blank Street “disrupting” the landscape and trading the idiosyncrasies of the aging carts for identical yuppie espresso trucks makes me squeamish.
Mohamed Attia, the executive director of the Street Vendor Project, a nonprofit group that advocates for street-vendor rights, thinks about it a different way. He views street vendors as New York’s most harassed and underappreciated small-business owners and believes the outdated propane carts and lack of mobile-payment technologies severely impact their income. “Most of them, 90 percent, are immigrants,” Attia points out. “They’re limited by their English in dealing with financial institutions and then there’s always the fear of the unknown.” Many vendors are undocumented, Attia says, and it’s nearly impossible for them to access lines of credit that would allow them to source higher-quality products and upgrades for the carts.
Attia suspects that vendors would jump at the opportunity for better equipment and more support. “At the end of the day, people are sick of dealing with the old carts and generators and the smoke,” he says. (Several years ago, a start-up called MOVE Systems announced plans to provide newer, natural-gas- and battery-powered carts to city street vendors. Hundreds of vendors signed up, but the company failed to make good on its promises and had only a few dozen units on the street when it shuttered in 2019.)
Menda explains that part of his goal for Blank Street is to help immigrant street vendors thrive. How it all might work is yet to be determined. Blank Street is considering the idea of franchise agreements, or simply renting its carts and software to vendors while guaranteeing a minimum income. “If you could help them get a stable income and level up in the economy, which is why they came here in the first place, that’s the main thing,” Menda says. “So we’ll try all the models, and what works best, we’ll scale.”
What remains to be seen is how willing New Yorkers are to sacrifice some of the city’s distinctive character for better-tasting coffee and easier access to breakfast tacos. The money spent on rent for larger spaces, too, isn’t exactly a wasted expense. For many New York City office workers — who, after more than a year of working from their makeshift home offices, are craving some human interaction — a meeting at a coffee shop isn’t an optimized fuel-up. It’s an excuse to step away from a desk and, perhaps counterintuitively, slow down a bit. “People want to connect,” says O’Connell, the La Colombe partner. “And cafés are platforms for communities to form.”",2
172,"Identifying, Growing & Recruiting Talent.
The Future Does Not Fit in the Containers of the Past. Edition 111.
Today like never before we are living in a world of rapid transformation and change.
New industries rise and fall and the inter-connected unstoppable forces of globalization, demographic change and technology twist and toss all of us.
In this landscape how do we identify the key skills that we will need from talent or hone our own skills?
What will remain relevant and in demand in an age of shorter and shorter half-lives of firms and business models?
And when we recruit talent particularly talent from outside how should we maximize the likelihood of fit and success?
The Six C’s
Six key skills will be essential in the future.
Three of these have to do with individual competence (Cognition, Creativity, Curiosity) and three how we connect with each other and the world outside our minds (Collaborate, Communicate, Convince).
Very few people will be world class in all six areas, but we all need to grow to be very good in at least two in each area.
Many companies hire or tolerate unbalanced people who are ultra-strong in individual skills such as cognition and creativity but are terrible at collaborating or communicating and learn that these lop-sided folks almost never ever last.
Being great at collaborating and communicating but being lack luster in cognitive or creative and other skills also flames out as these folks do not earn credibility of insiders or clients. Similarly, brilliance without some basic people and communication skills always ends up poisoning cultures and eventually flaming out because the organization rejects these “smart porcupines”
The 3 Cs of Individual Competence
Cognition. Curiosity. Creativity.
Cognition is simply learning to think and keeping your mental operating system constantly upgraded. This requires deliberate practice and sustained work. Improved cognition is achievable.
But one must work at it and many of us are so swamped with keeping up with our daily workload that we do not invest in growing our skills and expertise. This proves to eventually lead to irrelevance as the needs for yesterday’s skill sets erode and one has not replaced them with a new set of skills for the future.
Creativity is connecting dots in new ways, looking beyond the obvious and this skill will be key as AI powered computers, data crunch and co-relate faster than we ever will.
To be human is to be creative.
Creativity is at its heart the way we deal with a world of change by adapting, evolving, and re-inventing.
We need to learn and feed this inside us. The future will be about data driven storytelling and not just data or storytelling and the ability to leverage modern machines and algorithms to unleash connection and meaning will depend on creativity.
Curiosity is simply being alive to possibilities, questioning the status quo and asking what if? Today the key competitor or opportunity in any category comes from outside it.
Curiosity may have killed the cat, but the lack of curiosity killed the careers of many people.
The 3C’s of Connecting
Being cognitively gifted, creative, and curious will not be enough since we are living in a connected world where eco-systems, teams and linkages is how ideas are born, value created, and long-term careers forged. For these we need to hone and build and train for three other skills.
Collaborate: Collaboration is key to work in a world where API’s (Application Protocol Interfaces) are not just about handshakes between software/hardware but between individuals with different skills, teams in different countries, partners, suppliers and much more.
Communicate: Learn to write. Learn to speak. Learn to present. It may be so old school but watch the people who succeed, and they are good at communication. And all of these can be taught and learned.
But communication is not a one-way street and as important as it to write, speak and present it is as critical to be able to listen, to hear and to understand what others are saying with an open mind and a sense of empathy.
Convince: Every one of us is a salesperson regardless of what we believe our title is. This is true even if we do not sell anything at work. We must convince colleagues of our points of view.
We all must learn to convince and learn to sell.
The 3 I’s of recruiting experienced talent from the outside.
It is rare that a company can avoid hiring significant talent from outside if it is serious about transforming itself to change and grow. New skills, new mindsets and new blood enhances the corporate genetic pool.
But these hires are particularly fraught, and experience indicates that we need to evaluate for the 6c’s but also look for three other critical factors especially when recruiting for senior roles
These are a) Integration, b) Integrity, c) Impact
Integration is about how will the person fit in the culture of the firm.
It requires multiple interviews (Zoom and wherever possible in person) and ideally as many colleagues of the person being recruited should have an opportunity to be exposed to their future colleague. While often this is difficult it truly makes the on boarding and acceptance of the outside individual much easier
Too many companies bring in a wunderkind who either fails to adapt or is chewed up and spit out by the organization. While “Culture” may eat strategy for breakfast it honed its chewing skills by gnawing on the bones of outside talent.
Integrity and the Impact needs to be evaluated over time and require in depth research.
Integrity has never been more important and in today’s correctly sensitized environment this is not just about financial trust but dealings with people of different backgrounds among other things.
Impact on Business can be measured through financial results but as important is how the individual has built teams, grown people, and dealt with long term periods of stress or setback. Be careful of people who switch jobs every 2 or 3 years since it is highly unlikely, they architected the success they may claim.
Ex-bosses and ex-direct reports rather than colleagues and industry experts are usually the ideal people to interrogate since they can provide perspective, put things into context and provide a multi-faceted picture of the person.
In the end every one of us is responsible for our own careers. We should not outsource our future to somebody else. We should evaluate ourselves and our teams on the 6C’s and invest time and learning utilizing both company and external resources to keep honing and up skilling ourselves.
The future will not adapt to us.
We must adapt, grow, and transform ourselves for the future.
Mosaics by Jason Dussault
Just released on all global podcast platforms! : The latest episode of What Next? Renowned consultant to top companies in the world and multiple best selling author Martin Lindstrom on how common sense and empathy can unleash creativity and wealth by squashing bureaucracy and corporate BS! Will jolt you awake !
Tens of thousands of talented people all over the world receive a short read like this every Sunday. It is FREE and you can unsubscribe with a single click any time.
For more about Rishad Tobaccowala click here.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Super clear & extremely helpful! Thank you for your continued generosity in sharing these nuggets of wisdom. 🙏
I love the summary and key pointers to take away",2
173,"CLIMATEWIRE | Seville, Spain, has officially launched a new pilot program to address deadly heat waves. The program, unveiled yesterday on the summer solstice, introduces a system for naming and ranking heat waves in much the same way as hurricanes.
It’s the first city in the world to implement such a program, according to organizers. And it’s launching just in time for another record-breaking hot season.
Spain has been grappling with extreme temperatures for weeks. A sizzling heat wave last month sent temperatures soaring across the southern part of the country — in some places rising nearly 30 degrees Fahrenheit above the average for that time of year. The city of Jaén broke 104 degrees, a record for the month of May.
Another heat wave scorched Spain and other parts of Europe last week, with temperatures once again soaring well over 100 degrees in some cities. According to the Spanish meteorological service, the first two weeks of June were the hottest ever recorded in Spain.
The heat is both unusually early for the season and unusually persistent, the agency pointed out. The latest heat wave lingered for around nine days.
Extreme heat is one of the deadliest forms of severe weather. In the United States, it kills more people than any other type of weather event, including hurricanes or floods.
Yet heat-related deaths are also highly preventable, experts say.
Extreme heat disproportionately affects certain vulnerable populations, including elderly people, unhoused people, people without air conditioning and people with underlying health conditions. The danger can be managed with public messaging campaigns, early warning systems, expanded access to air conditioning and cooling centers, protections for people who work outdoors and other interventions.
“The exciting thing about addressing extreme heat is that you can do something about it,” Kathy Baughman McLeod, director of the Atlantic Council’s Adrienne Arsht Rockefeller Foundation Resilience Center (Arsht-Rock), said in an interview. “People do not need to die from heat.”
The pilot program in Seville is a collaboration between the city government and Arsht-Rock’s Extreme Heat Resilience Alliance, an initiative designed to combat deadly urban heat. Other partners include several Spanish universities and research institutes, the Spanish Office for Climate Change and sustainable development initiative El Día Después.
The Extreme Heat Resilience Alliance encourages local governments and weather agencies around the world to set up heat wave naming and ranking systems. Doing so, it argues, can raise public awareness about the dangers of extreme heat and help communities implement better emergency response plans.
Seville announced its plans for the new program last October. In the months since, the partner organizations have worked with scientists and other advisers to develop a methodology for naming and ranking heat waves.
The new system introduces three categories for extreme heat, ranging from the lowest at Category 1 to the most severe at Category 3. The system takes in account different variables when ranking heat events, including daytime and nighttime temperatures, humidity and expected health impacts on residents of Seville.
Each tier triggers public services, including weather alerts and public health information campaigns, as well as other emergency response efforts such as opening cooling centers and sending community health teams to check on high-risk populations.
Heat waves that reach Category 3 will be assigned names. The pilot program already has designated a list of five names to be assigned this season in reverse alphabetical order: Zoe, Yago, Xenia, Wenceslao and Vega.
They’ll begin with the next heat wave to meet the naming criteria.
“We are the first city in the world to take a step that will help us plan and take measures when this type of meteorological event happens—particularly because heat waves always hit the most vulnerable,” Antonio Muñoz, mayor of Seville, said in a statement.
The partners are putting in place a 12-month plan for the pilot, according to Baughman McLeod. They’ll likely make an assessment midway through and report on the program’s results in November at the United Nations’ annual climate change conference.
“We’ve got decades and decades of scientific experience in the science panel who helped put these methodologies together and really strong expectations of its performance,” Baughman McLeod said. “But we’ll make sure. It is a pilot, and I’m sure there will be some things that need to be corrected.”
Though Seville is the first city to implement both a naming and ranking system, other cities are pursuing similar efforts in collaboration with Arsht-Rock.
Athens, Greece, announced yesterday an initiative to categorize heat waves using a three-tiered approach. It doesn’t plan to add a naming component, but the ranking system will include emergency response components, much like the program in Seville.
A handful of U.S. cities also have launched pilot programs for ranking heat waves. Those include Los Angeles, Milwaukee, Miami and Kansas City, Mo.
Spain’s record temperatures this spring are a reminder of the dangers of extreme heat and the importance of preparing for future events, Baughman McLeod said.
“This is urgent,” she said. “This is really urgent.”
Reprinted from E&E News with permission from POLITICO, LLC. Copyright 2022. E&E News provides essential news for energy and environment professionals.",2
174,"SCALE 19xSubmitted by Ilan Rabinovitch on Wed, 2022-07-13 15:48
SCaLE 19X – the 19th annual Southern California Linux Expo – will take place July 28-31, 2022 at the Hilton Los Angeles Airport in Los Angeles, CA.
SCaLE is the largest community-run open-source and free software conference in North America. It is held annually in the greater Los Angeles area.
Volunteer! Interested in helping to plan and/or to volunteer for SCALE 19X? Get in touch by either filling out this form or sending us an email.
Attend! Attendee registration will be available this coming summer.
Present! The SCALE 19x call for proposals is now open.
Sponsor! Sponsorship and exhibitor opportunities are available for commercial and non-profit exhibitors. Email us for details.
Stay! Join us for all 4 days of SCALE. Book a hotel room onsite to avoid traffic and commuting.",2
175,"Broadcast
Close
Search
Close
Broadcast 📡
Programs
Exhibitions
Residency
Publishing
Learn & Engage
Art
Music
Science
Technology
Calendar
About
Visit
Store
Support
Disciplines
Series
Video
Audio
About
Index
The Pioneer Works Broadcast is supported by
Use High-Contrast Text",3
176,"A leaked trove of confidential files has revealed the inside story of how the tech giant Uber flouted laws, duped police, exploited violence against drivers and secretly lobbied governments during its aggressive global expansion.
The unprecedented leak to the Guardian of more than 124,000 documents – known as the Uber files – lays bare the ethically questionable practices that fuelled the company’s transformation into one of Silicon Valley’s most famous exports.
The leak spans a five-year period when Uber was run by its co-founder Travis Kalanick, who tried to force the cab-hailing service into cities around the world, even if that meant breaching laws and taxi regulations.
During the fierce global backlash, the data shows how Uber tried to shore up support by discreetly courting prime ministers, presidents, billionaires, oligarchs and media barons.
Leaked messages suggest Uber executives were at the same time under no illusions about the company’s law-breaking, with one executive joking they had become “pirates” and another conceding: “We’re just fucking illegal.”
On Monday, Mark MacGann, Uber’s former chief lobbyist for Europe, the Middle East and Africa, came forward to identify himself as the source of the leaked data. “It is my duty to speak up and help governments and parliamentarians right some fundamental wrongs,” he said. “Morally, I had no choice in the matter.”
The cache of files, which span 2013 to 2017, includes more than 83,000 emails, iMessages and WhatsApp messages, including often frank and unvarnished communications between Kalanick and his top team of executives.
In one exchange, Kalanick dismissed concerns from other executives that sending Uber drivers to a protest in France put them at risk of violence from angry opponents in the taxi industry. “I think it’s worth it,” he shot back. “Violence guarantee[s] success.”
In a statement, Kalanick’s spokesperson said he “never suggested that Uber should take advantage of violence at the expense of driver safety” and any suggestion he was involved in such activity would be completely false.
The leak also contains texts between Kalanick and Emmanuel Macron, who secretly helped the company in France when he was economy minister, allowing Uber frequent and direct access to him and his staff.
Macron, the French president, appears to have gone to extraordinary lengths to help Uber, even telling the company he had brokered a secret “deal” with its opponents in the French cabinet.
Privately, Uber executives expressed barely disguised disdain for other elected officials who were less receptive to the company’s business model.
After the German chancellor, Olaf Scholz, who was mayor of Hamburg at the time, pushed back against Uber lobbyists and insisted on paying drivers a minimum wage, an executive told colleagues he was “a real comedian”.
When the then US vice-president, Joe Biden, a supporter of Uber at the time, was late to a meeting with the company at the World Economic Forum at Davos, Kalanick texted a colleague: “I’ve had my people let him know that every minute late he is, is one less minute he will have with me.”
After meeting Kalanick, Biden appears to have amended his prepared speech at Davos to refer to a CEO whose company would give millions of workers “freedom to work as many hours as they wish, manage their own lives as they wish”.
The Guardian led a global investigation into the leaked Uber files, sharing the data with media organisations around the world via the International Consortium of Investigative Journalists (ICIJ). More than 180 journalists at 40 media outlets including Le Monde, Washington Post and the BBC will in the coming days publish a series of investigative reports about the tech giant.
In a statement responding to the leak, Uber admitted to “mistakes and missteps”, but said it had been transformed since 2017 under the leadership of its current chief executive, Dara Khosrowshahi.
“We have not and will not make excuses for past behaviour that is clearly not in line with our present values,” it said. “Instead, we ask the public to judge us by what we’ve done over the last five years and what we will do in the years to come.”
Kalanick’s spokesperson said Uber’s expansion initiatives were “led by over a hundred leaders in dozens of countries around the world and at all times under the direct oversight and with the full approval of Uber’s robust legal, policy and compliance groups”.
‘Embrace the chaos’
The leaked documents pull back the curtains on the methods Uber used to lay the foundations for its empire. One of the world’s largest work platforms, Uber is now a $43bn (£36bn) company, making approximately 19m journeys a day.
The files cover Uber’s operations across 40 countries during a period in which the company became a global behemoth, bulldozing its cab-hailing service into many of the cities in which it still operates today.
From Moscow to Johannesburg, bankrolled with unprecedented venture capital funding, Uber heavily subsidised journeys, seducing drivers and passengers on to the app with incentives and pricing models that would not be sustainable.
Uber undercut established taxi and cab markets and put pressure on governments to rewrite laws to help pave the way for an app-based, gig-economy model of work that has since proliferated across the world.
In a bid to quell the fierce backlash against the company and win changes to taxi and labour laws, Uber planned to spend an extraordinary $90m in 2016 on lobbying and public relations, one document suggests.
Its strategy often involved going over the heads of city mayors and transport authorities and straight to the seat of power.
In addition to meeting Biden at Davos, Uber executives met face-to-face with Macron, the Irish prime minister, Enda Kenny, the Israeli prime minister, Benjamin Netanyahu, and George Osborne, the UK’s chancellor at the time. A note from the meeting portrayed Osborne as a “strong advocate”.
In a statement, Osborne said it was the explicit policy of the government at the time to meet with global tech firms and “persuade them to invest in Britain, and create jobs here”.
While the Davos sitdown with Osborne was declared, the data reveals that six UK Tory cabinet ministers had meetings with Uber that were not disclosed. It is unclear if the meetings should have been declared, exposing confusion around how UK lobbying rules are applied.
The documents indicate Uber was adept at finding unofficial routes to power, applying influence through friends or intermediaries, or seeking out encounters with politicians at which aides and officials were not present.
It enlisted the backing of powerful figures in places such as Russia, Italy and Germany by offering them prized financial stakes in the startup and turning them into “strategic investors”.
And in a bid to shape policy debates, it paid prominent academics hundreds of thousands of dollars to produce research that supported the company’s claims about the benefits of its economic model.
Despite a well-financed and dogged lobbying operation, Uber’s efforts had mixed results. In some places Uber succeeded in persuading governments to rewrite laws, with lasting effects. But elsewhere, the company found itself blocked by entrenched taxi industries, outgunned by local cab-hailing rivals or opposed by leftwing politicians who simply refused to budge.
When faced with opposition, Uber sought to turn it to its advantage, seizing upon it to fuel the narrative its technology was disrupting antiquated transport systems, and urging governments to reform their laws.
As Uber launched across India, Kalanick’s top executive in Asia urged managers to focus on driving growth, even when “fires start to burn”. “Know this is a normal part of Uber’s business,” he said. “Embrace the chaos. It means you’re doing something meaningful.”
Kalanick appeared to put that ethos into practice in January 2016, when Uber’s attempts to upend markets in Europe led to angry protests in Belgium, Spain, Italy and France from taxi drivers who feared for their livelihoods.
Amid taxi strikes and riots in Paris, Kalanick ordered French executives to retaliate by encouraging Uber drivers to stage a counter-protest with mass civil disobedience.
Warned that doing so risked putting Uber drivers at risk of attacks from “extreme right thugs” who had infiltrated the taxi protests and were “spoiling for a fight”, Kalanick appeared to urge his team to press ahead regardless. “I think it’s worth it,” he said. “Violence guarantee[s] success. And these guys must be resisted, no? Agreed that right place and time must be thought out.”
The decision to send Uber drivers into potentially volatile protests, despite the risks, was consistent with what one senior former executive told the Guardian was a strategy of “weaponising” drivers, and exploiting violence against them to “keep the controversy burning”.
It was a playbook that, leaked emails suggest, was repeated in Italy, Belgium, Spain, Switzerland and the Netherlands.
When masked men, reported to be angry taxi drivers, turned on Uber drivers with knuckle-dusters and a hammer in Amsterdam in March 2015, Uber staffers sought to turn it to their advantage to win concessions from the Dutch government.
Driver victims were encouraged to file police reports, which were shared with De Telegraaf, the leading Dutch daily newspaper. They “will be published without our fingerprint on the front page tomorrow”, one manager wrote. “We keep the violence narrative going for a few days, before we offer the solution.”
Kalanick’s spokesperson questioned the authenticity of some documents. She said Kalanick “never suggested that Uber should take advantage of violence at the expense of driver safety” and any suggestion that he was involved in such activity would be “completely false”.
Uber’s spokesperson also acknowledged past mistakes in the company’s treatment of drivers but said no one, including Kalanick, wanted violence against Uber drivers. “There is much our former CEO said nearly a decade ago that we would certainly not condone today,” she said. “But one thing we do know and feel strongly about is that no one at Uber has ever been happy about violence against a driver.”
The ‘kill switch’
Uber drivers were undoubtedly the target of vicious assaults and sometimes murders by furious taxi drivers. And the cab-hailing app, in some countries, found itself battling entrenched and monopolised taxi fleets with cosy relationships with city authorities. Uber often characterised its opponents in the regulated taxi markets as operating a “cartel”.
However, privately, Uber executives and staffers appear to have been in little doubt about the often rogue nature of their own operation.
In internal emails, staff referred to Uber’s “other than legal status”, or other forms of active non-compliance with regulations, in countries including Turkey, South Africa, Spain, the Czech Republic, Sweden, France, Germany, and Russia.
One senior executive wrote in an email: “We are not legal in many countries, we should avoid making antagonistic statements.” Commenting on the tactics the company was prepared to deploy to “avoid enforcement”, another executive wrote: “We have officially become pirates.”
Nairi Hourdajian, Uber’s head of global communications, put it even more bluntly in a message to a colleague in 2014, amid efforts to shut the company down in Thailand and India: “Sometimes we have problems because, well, we’re just fucking illegal.” Contacted by the Guardian, Hourdajian declined to comment.
Kalanick’s spokesperson accused reporters of “pressing its false agenda” that he had “directed illegal or improper conduct”.
Uber’s spokesperson said that, when it started, “ridesharing regulations did not exist anywhere in the world” and transport laws were outdated for a smartphone era.
Across the world, police, transport officials and regulatory agencies sought to clamp down on Uber. In some cities, officials downloaded the app and hailed rides so they could crack down on unlicensed taxi journeys, fining Uber drivers and impounding their cars. Uber offices in dozens of countries were repeatedly raided by authorities.
Against this backdrop, Uber developed sophisticated methods to thwart law enforcement. One was known internally at Uber as a “kill switch”. When an Uber office was raided, executives at the company frantically sent out instructions to IT staff to cut off access to the company’s main data systems, preventing authorities from gathering evidence.
The leaked files suggest the technique, signed off by Uber’s lawyers, was deployed at least 12 times during raids in France, the Netherlands, Belgium, India, Hungary and Romania.
Kalanick’s spokesperson said such “kill switch” protocols were common business practice and not designed to obstruct justice. She said the protocols, which did not delete data, were vetted and approved by Uber’s legal department, and the former Uber CEO was never charged in relation to obstruction of justice or a related offence.
Uber’s spokesperson said its kill switch software “should never have been used to thwart legitimate regulatory action” and it had stopped using the system in 2017, when Khosrowshahi replaced Kalanick as CEO.
Another executive the leaked files suggest was involved in kill switch protocols was Pierre-Dimitri Gore-Coty, who ran Uber’s operations in western Europe. He now runs Uber Eats, and sits on the company’s 11-strong executive team.
Gore-Coty said in a statement he regretted “some of the tactics used to get regulatory reform for ridesharing in the early days”. Looking back, he said: “I was young and inexperienced and too often took direction from superiors with questionable ethics.”
Politicians now also face questions about whether they took direction from Uber executives.
When a French police official in 2015 appeared to ban one of Uber’s services in Marseille, MacGann, Uber’s chief lobbyist in Europe, the Middle East and Africa, turned to Uber’s ally in the French cabinet.
“I will look at this personally,” Macron texted back. “At this point, let’s stay calm.”
Uber files reporting: Harry Davies, Simon Goodley, Felicity Lawrence, Paul Lewis, Lisa O’Carroll, John Collingridge, Johana Bhuiyan, Sam Cutler, Rob Davies, Stephanie Kirchgaessner, Jennifer Rankin, Jon Henley, Rowena Mason, Andrew Roth, Pamela Duncan, Dan Milmo, Mike Safi, David Pegg and Ben Butler.",4
177,"Digital boosts
Boosting citizens' competences to deal with the online world
Online environments are crucial to most aspects of life—yet the digital world is replete with smart, highly adaptive choice architectures that are designed to maximize commercial interests. Online landscapes geared toward capturing users’ attention, monetizing user data, and predicting and influencing future behavior put society at risk by reducing human autonomy, heightening incivility online, and facilitating political extremism and the spread of disinformation. There are two boosting approaches to tackle these challenges.
Boosting cognitive competences in online environments
One way to address these challenges is through a behavioral/cognitive approach that empowers users and fosters digital competences.
Types of digital boosts targeting cognitive competences: Overview
Based on: Kozyreva, A., Lewandowsky, S., & Hertwig, R. (2020). Citizens versus the internet: Confronting digital challenges with cognitive tools. Psychological Science in the Public Interest, 21, 103–156. https://doi.org/10.1177/1529100620946707
Lateral reading and simple fact-checking rules
Lateral reading is a simple heuristic for online fact-checking: When the source is unfamiliar, leave the page and verify the author/organization and their claims somewhere else (e.g., using search engines or Wikipedia). Learn more.
For simple fact-checking rules laid out in a fast-and-frugal decision tree, see here.
Inoculation
Inoculation is a preemptive intervention that boosts people’s cognitive resistance to misinformation and online manipulation by exposing them to a weakened form of disinformation and/or common strategies used to manipulate people’s beliefs (see these examples of inoculation boosts).
Self-nudging
Self-nudging refers to self-imposed interventions in one’s digital choice architectures. The goal of changing one’s environment is to enhance self-governance and to lower distractions (see these examples of self-nudges for the online world).
🙈 Critical ignoring
Critical ignoring is a type of deliberate ignorance. It involves controlling one’s information environment by filtering and blocking out information (e.g., emails, news feeds, instant messages) in order to reduce exposure to false and low-quality information.
Examples of digital boosts targeting cognitive competences
On July 2nd 2022 the Max Planck Institute for Human Development in Berlin participated in the Long Night of the Sciences 2022. We, the Science of Boosting group, organized an interactive “digital boosting toolbox” that helps people to deal with misinformation. Even if you were not at the actual event, you can still check out the digital boosting toolbox here on the website.
Boosting via digital environments
Another way to address these challenges is by taking an environmental approach: designing digital architectures that encourage people to exercise existing competences or learn and apply new ones. This includes enabling people to do their own fact-checking, to promote truth, and to interact constructively in democratic discourse online.
Types of boosts via the digital environment: Overview
Based on: Lorenz-Spreen, P., Lewandowsky, S., Sunstein, C. R., & Hertwig, R. (2020). How behavioural sciences can promote truth, autonomy and democratic discourse online. Nature Human Behavior, 4, 1102–1109. https://doi.org/10.1038/s41562-020-0889-7
Leveraging epistemic cues
Boosts using epistemic cues in the environment are aimed at getting people into the routine of checking the quality of information they see online. These boosts can take the form of highlights on sources and cross-links (e.g., as found on Wikipedia) or pop-ups showing fast-and-frugal decision trees.
Algorithmic transparency
These boosts use features of the online environment to help people understand algorithmic decisions. For example, allowing people to customize their own news feed can help them understand and exert control over the algorithm that selects what they are shown.
Social network literacy
Representations of information flows and opinion distributions can help people develop an intuition for how information is shared online and how discourse on social networks unfolds. Such representation can include representations of clusters of opinions on a two dimensional plane (as it is done on the platform pol.is) or a transparent visualization of the sharing history of content.",1
178,"L’éthique de Stardew Valley et l’esprit du capitalisme | Comment les simulateurs de vie à la campagne nous aident à accepter le vide de nos existences
Il y a quelques semaines, mon estimé collègue ackboo livrait un article tout à fait distrayant sur un nouveau jeu d’escapade à la campagne, Dinkum. Avec ses mots simples, parfois maladroits, l’amusant rédacteur tentait d’exprimer les raisons qui nous poussent vers ce genre de jeu, et qui tiennent, selon lui, à l’évasion qu’ils promettent, loin d’un quotidien morose et déprimant.
Et pourtant, ce que proposent Animal Crossing, Stardew Valley, My Time at Portia et tous leurs clones n’est-il pas, précisément, l’inverse de l’évasion ? Un honnête travailleur qui passe ses journées dans un open space sans âme, s’il souhaitait vraiment s’évader, ne devrait-il pas plutôt se tourner vers un Final Fantasy, un Uncharted ou un Skyrim, à découvrir et explorer des plaines, des forêts et des rivières dans un monde aussi éloigné de son quotidien que le sont l’aventure, la magie et les dragons ? À la place, voilà que ce travailleur, rompu de fatigue, sitôt rentré à la maison, trouve un endroit où il pourra faire exactement la même chose que ce qu’il fait toute la journée : optimiser, consommer et rationaliser sa productivité, dans une interprétation colorée et séduisante de son propre quotidien.
L’introduction de Stardew Valley est éloquente. Un homme ou une femme, selon le genre que le joueur aura choisi, est assis devant un ordinateur, dans le bureau d’une entreprise tentaculaire et inhumaine. Dans son tiroir, il trouve une lettre. Son grand-père lui lègue une ferme dans la vallée de Stardew. « Si tu lis cette lettre, c'est que tu dois avoir envie de changement. Il m'est arrivé la même chose il y a longtemps. J'avais perdu de vue ce qui compte réellement dans la vie : les vraies connexions avec les gens et avec la nature. » Les « vrais gens » dont parle le grand-père ne sont pas de véritables habitants de la campagne qui sniffent de l'essence et roulent des trois-feuilles sur le parking d'Intermarché comme vous et moi, mais des symboles pixelisés qui s'offrent des coquelicots pendant la fête de la lune.
L'étang moderne.Le joueur, maintenant. Où est-il, ce joueur ? Comme le personnage qu’il incarne, est-il transporté à la campagne, pour nouer, lui aussi, des relations plus sincères avec les autochtones ? Le joueur, en réalité, ressemble davantage à la première image que montre le jeu : un homme ou une femme, assis devant un ordinateur, dans un immeuble sans nom, en train de jongler avec des chiffres et des symboles pour augmenter sa productivité dans le jeu. La promesse que fait Stardew Valley à son personnage principal, celle d’une vie plus authentique, n’est pas celle que le jeu fait au joueur : celle de passer encore un peu plus de temps devant son ordinateur à optimiser sa production.
C’est inévitable : un jeu vidéo, quoi qu’il veuille représenter, reste un jeu vidéo, une abstraction qui transforme des impulsions électriques en données avec lesquelles le joueur pourra interagir. Les habitants de Stardew Valley, d’Animal Crossing ou de My Times at Portia, ne sont pas réellement des gens. Ce sont des jauges qui montent et qui descendent en fonction des conneries offertes par le joueur ou de son assiduité à interagir avec ces abstractions.
Le jeu vidéo, quel qu’il soit, entretien un lien indéfectible avec la rationalisation et l’optimisation. Il s’agit toujours, en fin de compte, de manipuler des données le plus efficacement possible pour interagir avec d’autres données. C’est vrai pour tous les jeux, de Mario à Resident Evil, mais cette relation est plus forte encore dans les jeux qui comportent des éléments de gestion, comme tous les jeux qui prétendent simuler une vie rurale. Ces jeux, fondamentalement et mécaniquement, sont des jeux où l’optimisation du temps et des ressources joue un rôle considérable. Même le grand-père ne s'y trompe pas. Il revient, au bout de deux ans, pour juger le travail accompli par le personnage, à travers un ensemble d'éléments quantifiables, parmi lesquels, en premier lieu, l'argent – qu'il nous encourageait à fuir, dans sa lettre, pour poursuivre « ce qui compte vraiment ».
Esprit du capitalisme, es-tu là ?L’ironie, c’est que l’essence du monde moderne et son mode de production – le capitalisme – se fonde, en partie, sur une marche vers davantage d’optimisation et de rationalisation : augmentation de la productivité, économies d’échelle, recherche d’un équilibre du marché, etc. Cette marche vers la rationalisation, historiquement, s’oppose à un mode d’organisation traditionnel de la société : le riz est cultivé de telle ou de telle manière, parce que c’est comme ça que les choses ont toujours été, et remettre en cause la manière d’organiser la production traditionnelle comporte le risque de mettre en branle tout le modèle social. Or, où se trouve la tradition, symboliquement, dans nos sociétés modernes ? Quel est le lieu qui, dans l’imaginaire collectif, reste celui où vivent encore les traditions ? La campagne.
Stardew Valley, Animal Crossing et My Time at Portia invitent le joueur dans un lieu associé à une organisation traditionnelle de la société, pour lui proposer d’y appliquer une organisation moderne : rationalisation et optimisation. Les life simulators n’invitent pas le joueur à la campagne : ils l’invitent dans la matrice, là où le travail a l’odeur, le goût et les couleurs d’une campagne qu’il fantasme, pour lui permettre de s’entraîner en toute sécurité à réaliser ce qu’une société moderne attend de lui tous les jours. Après avoir détruit le mode de vie traditionnel – peut-être pour le mieux, je ne juge pas – le monde marchand en reproduit une version en parc d'attractions pour palier le manque d'authenticité qu'il a lui-même provoqué. Stardew Valley, malgré toutes les jérémiades du grand-père, n'est pas l'avocat d'un mode de vie qui propose une alternative au capitalisme. Il en est sa forme la plus pure.
Misère de l'agronomie.Dans un article très drôle de Waypoint, le journaliste Rob Zacny raconte l’expérience de sa petite amie sur Stardew Valley : « Je crois que j'ai appliqué les principes de l'agriculture industrielle à Stardew Valley. » Il raconte : « Par une sorte de prodige inconcevable, mon adorable copine avait réussi à créer une machine à produire terrifiante au sein de l'univers 16-bit, un complexe hypercapitaliste entièrement organisé autour de son petit avatar innocent. Son personnage s'évanouissait régulièrement d'épuisement dans divers coins de la ville. Selon elle, il était plus rentable de payer les coûts médicaux pour son rétablissement que de la garder en bonne santé si elle voulait atteindre ses objectifs de production quotidiens. » Cette manière de jouer à Stardew Valley est une déviation par rapport à ce que souhaitait son développeur, presque une abomination. Mais, pourtant, les germes de cette façon de jouer ne sont-ils pas contenus dans les mécaniques et les règles de Stardew Valley ? Tout, dans ces jeux, n'est-il pas que chiffres et données qu'il convient d'optimiser ?
Les jeux qui simulent une vie à la campagne, en réalité, ne proposent pas de s’évader des villes. Ils offrent au joueur un prolongement de l’expérience quotidienne du travail dans un environnement simulé où celui-ci pourra réparer tout ce qui a été brisé en lui pendant la journée. Ils offrent un environnement contrôlé où le joueur va pouvoir travailler, c’est-à-dire organiser, consommer et modifier son environnement, en soustrayant tout ce qui rend le travail abominable : ici, il n’y a pas de harcèlement sexuel, de racisme, de petits chefs ou de hiérarchie stériles. Chaque action est un pas de plus vers une récompense, généralement sous la forme d'un objet de consommation à acheter.
La méthadone agile.J'ai écrit dans un test qu'Animal Crossing était davantage une expérience qu’un jeu. Avec le recul, et après y avoir passé des dizaines d’heures à m'y amuser sincèrement, comme dans Stardew Valley, comme dans My Time at Portia, je voudrais revenir sur mes propos. Plus qu’un jeu, plus qu’une expérience, Animal Crossing est un outil thérapeutique. Le joueur est invité à rembourser son crédit immobilier sans aucune pression. Tout est fait pour que rien ne soit ni stressant, ni fatigant physiquement. S'il y avait un équivalent aux centres de désintoxication pour réhabituer les gens à la vie moderne, Animal Crossing pourrait jouer le rôle de la méthadone. Les habitants sont tous gentils, les clochettes s’accumulent, le joueur n’est jamais confronté à l’échec, les petits cailloux font les grandes montagnes. Il y a des dizaines d’articles et de vidéos YouTube qui expliquent comment le jeu de Nintendo a été un réconfort nécessaire lors d’un moment difficile de la vie, notamment pendant les confinements.
Dans un article pour Kotaku, Leigh Alexander va plus loin : « Le distributeur a indiqué que j’avais 245 000 clochettes. Je l’ai fait. J’ai franchi le pas et j’ai payé mon crédit immobilier. Maintenant je dois écrire un article sur Animal Crossing. Je veux dire : je dois le faire, parce que c’est mon métier d’écrire sur les jeux vidéo. De ce fait, je ne remboursai probablement jamais un crédit immobilier en vrai. J’ai réalisé que ce jeu était l’expérience la plus proche que j’aurais de rembourser un jour un crédit immobilier. »
Cent balles et un Marx.Sur le million de jeux annoncés par Nintendo lors de sa dernière communication, il y a un nombre considérable de life simulators qui se déroulent à la campagne. Cette mode indique-t-elle une volonté massive d’un retour à un autre mode de production et de consommation, plus traditionnel, moins marchand ? Peut-être. Mais peut-être indique-t-elle, dans un monde où de moins en moins d’individus trouvent du sens à leur activité quotidienne, qu'il faut une occupation du temps libre qui serve de soupape aux travailleurs pour leur permettre de fonctionner normalement sans s’effondrer.
Cette occupation, contrairement à ce que pourrait laisser penser le cadre bucolique, n’est pas un retour à un mode de vie plus traditionnel. Il s’agit simplement de transposer la rationalisation et l’optimisation d’un mode de vie moderne dans un cadre qui peut « laisser croire » qu’il s’agit d’une évasion. Comme l’écrivait Theodor Adorno dans son essai de 1977 Le Temps libre : « La contrebande des comportements propres au travail est écoulée dans le domaine du temps libre. […] Le temps libre ne s’oppose pas au travail, il n’est rien d’autre qu’une continuation masquée du travail. » Je n'ai pas tout compris, mais je suis entièrement d'accord.
La ferme des animaux.Les êtres humains, après tout, ne sont que des animaux un peu plus compliqués. Ils ont besoin, pour continuer de produire efficacement, de trouver une forme de sens à leur existence. Dans Stardew Valley, une mise à jour de 2018 a introduit un nouvel objet : l’auto-grabber. C’est un outil qui permet de ramasser automatiquement les objets produits par les animaux dans l’étable : les œufs pour les poules, le lait pour les vaches, etc. Sur les forums du jeu, après cette introduction, les joueurs ont commencé à se plaindre. C’était un gain de productivité, certes, mais il fallait toujours passer du temps à caresser les animaux pour qu’ils produisent des objets de meilleure qualité. Certains ont commencé à réclamer un auto-petter, un objet qui caresse automatiquement les animaux. L’objet a finalement été introduit en 2020.
Parallèlement – dans la vraie vie des vrais gens – en 2019, des fermiers russes ont adapté des casques de réalité virtuelle pour les installer sur des vaches afin de calmer leur anxiété et produire un lait de meilleure qualité. Les tests initiaux ont montré une amélioration de l’humeur du troupeau et, si l’expérience est concluante, les casques pourraient être généralisés dans les années à venir. Peut-être que Stardew Valley, Animal Crossing et My Time at Portia sont nos casques de réalité virtuelle à nous ? Peut-être qu’avec un peu de chance, dans les années qui viennent, grâce aux simulateurs de vie à la campagne, nous produirons un meilleur lait quand le monde du travail viendra nous traire ?
Article rendu gratuit par le vote des abonnésCet article vous a plu ? Abonnez-vous ici",0
179,"For four thousand years, the Guardships have ruled Canon Space - immortal ships with an immortal crew, dealing swiftly and harshly with any mercantile houses or alien races that threaten the status quo. But now the House Tregesser has an edge: a force from outside Canon Space offers them the resources to throw off Guardship rule. This precipitates an avalanche of unexpected outcomes, including the emergence of Kez Maefele, one of the few remaining generals of the Ku Warrior race-the only race to ever seriously threaten Guardship hegemony. Kez Maefele and a motley group of aliens, biological constructs, an scheming aristocrats find themselves at the center of the conflict. Maefele must chose which side he will support: the Guardships, who defeated and destroyed his race, or the unknown forces outside Canon Space that promise more death and destruction.
Skyhorse Publishing, under our Night Shade and Talos imprints, is proud to publish a broad range of titles for readers interested in science fiction (space opera, time travel, hard SF, alien invasion, near-future dystopia), fantasy (grimdark, sword and sorcery, contemporary urban fantasy, steampunk, alternative history), and horror (zombies, vampires, and the occult and supernatural), and much more. While not every title we publish becomes a New York Times bestseller, a national bestseller, or a Hugo or Nebula award-winner, we are committed to publishing quality books from a diverse group of authors.
Glen Cook was born in New York City, lived in southern Indiana as a small child, then grew up in Northern California. After high school he served in the U.S. Navy and attended the University of Missouri. He worked for General Motors for 33 years, retiring some years ago. He started writing short stories in 7th grade, had several published in a high school literary magazine. He began writing with malicious intent to publish in 1968, eventually producing 51 books and a number of short fiction pieces. He met his wife of 43 years while attending the Clarion Writer's Workshop in 1970. He has three sons (army officer, architect, orchestral musician) and numerous grandchildren, all of whom but one are female. He is best known for his Black Company series, which has appeared in 20+ languages worldwide. His other series include Dread Empire and and the Garrett, P.I. series. His latest work is Working God’s Mischief, fourth in the Instrumentalities of the Night series. http://us.macmillan.com/author/glencook",8
180,"Researchers develop thermoformable ceramics, 'a new frontier in materials'
It was one of those happy accidents of science. Northeastern professor Randall Erb and Ph.D. student Jason Bice were working on a product for a university client—and wound up with an entirely new class of material.
Their discovery of an all-ceramic that can be compression-molded into complex parts—an industry breakthrough—could transform the design and construction of heat-emitting electronics, including cellphones and other radio components.
""Our research group's lives are very much situated at the bleeding edge of technology,"" says Erb, an associate professor of mechanical and industrial engineering who heads the DAPS Lab at Northeastern. ""Things break a lot, and every once in a while one of those breaks turns out to be good fortune.""
Last July, Erb was in his Northeastern lab with Bice, who has since earned a mechanical engineering Ph.D. They were testing an experimental ceramic compound as part of a hypersonic project for an industrial partner when something appeared to go wrong.
""We blasted it with a blowtorch and, while we were loading it, it unexpectedly deformed and fell out of the fixture,"" Erb says. ""We looked at the sample on the floor thinking that it was a failure.""
Closer examination gave way to a revelation.
""We realized it was perfectly intact,"" Erb says. ""It was just shaped differently.""
Ceramics tend to fracture (or even explode) from thermal shock when subjected to extreme heat changes and mechanical loading. But their sample had deformed gracefully.
""We tried it a few more times and realized that we could control the deformation,"" Erb says. ""And then we started compression-molding the material and found that it was a very fast process.""
Its underlying microstructure uniquely allows the all-ceramic to quickly transmit heat and flow effectively during the molding process. The ceramic can be formed into exquisite geometries and exhibits impressive mechanical strength and thermal conductivity at room temperature, says Erb, whose findings were recently published in Advanced Materials.
Erb and Bice are developing the product via their startup, Fourier LLC—named after the French mathematician Joseph Fourier, who studied heat flow in ceramics two centuries ago. Fourier has received a $50,000 Spark Fund award from Northeastern's Center for Research Innovation.
""It's unique: Thermoformable ceramics, from what we've seen and read, don't really exist,"" Bice says. ""So it's a new frontier in materials.""
The new product has the potential to introduce two industry improvements, starting with its efficiency as a heat conductor that can cool high-density electronics.
In general, cellphones and other electronics are fitted with a bulky layer of aluminum, which is necessary to draw heat away from the unit.
""Our material can be less than a millimeter thick, which presents a low-profile solution,"" Bice says. ""It can be molded to conform to the surface that you're trying to cool.""
The phononic crystal-based ceramic allows heat to flow without electron transport, says Erb. It doesn't interfere with radio frequencies (RF) of cellphones and other systems.
""If you put an aluminum heatsink into an RF component, you've basically introduced a series of antennae to interact with the RF signal,"" Erb says. ""Instead, we can put our boron nitride-based material in and around an RF component and it is essentially invisible to the RF signal.""
The other improvement, says Erb, is that It can be form-fit directly to the electrical component. Echo St. Germain, a fifth-year mechanical engineering student at Northeastern who is serving as a ceramic researcher and R&D engineer at Fourier, demonstrated the ceramic's non-Newtonian behavior by subjecting a clumpy slurry of it to vibration that is normal to the manufacturing process; it instantly liquified and organized the structure of the material. Such slurries are used to produce the moldable ceramics.
Erb and Bice believe they'll be able to form-fit the all-ceramic materials to all kinds of electrical components. The ceramic will be thinner, lighter and more efficient than the metals currently in use.
Bice has helped launch the startup from Munich, where his wife has started a new job.
""Launching a company that is Boston-based while I'm in Germany adds some interesting complications to things—but also opportunities,"" says Bice, who with Erb is engaging in customer discovery in both Europe and the U.S.
Explore further",2
181,"A 14-year-old boy has cracked four levels of code imprinted on a commemorative 50-cent coin released by the nation's foreign intelligence cybersecurity agency.
Key points:
- ASD director-general Rachel Noble said the 14-year-old cracked the encryption in just over an hour
- She said the agency hoped to meet him ""and recruit him""
- She also said there was a secret fifth level of encryption on the coin which no one had broken yet
The limited-edition commemorative coin was released on Thursday to mark the 75th anniversary of the Australian Signals Directorate (ASD), with only 50,000 minted for the occasion.
The ASD said the coin's four different layers of encryption were each progressively harder to solve, and clues could be found on both sides — but ASD director-general Rachel Noble said in a speech at the Lowy Institute on Friday that the 14-year-old managed it in just over an hour.
""There's a challenge out there to see who can correctly break all the layers, and, would you believe it, yesterday the coin was launched at 8:45am; we put up our web form and said, 'Hey, if you think you've got the answers, fill in the form',"" she said.
""And believe it or not, a boy, 14 years old in Tasmania, was the first person in just over an hour to get all four layers right.
""Just unbelievable. Can you imagine being his mum?
""So we're hoping to meet him soon ... to recruit him.""
A fifth level of encryption
Ms Noble yesterday said the coin celebrated the work of the agency's members and the evolution of code-breaking, and that those who crack the codes could be ""pretty well placed"" to get a job at the ASD.
""We thought this was a really fun way to engage people in code-breaking with the hope that, if they make it through all four levels of coding on the coin, maybe they'll apply for a job at the Australian Signals Directorate.""
Ms Noble said that while there were no classified messages on the coin, those who crack the codes could discover ""some wonderful, uplifting messages"".
""Like the early code breakers in ASD, you can get through some of the layers with but a pencil and paper but, right towards the end, you may need a computer to solve the last level.""
She also revealed on Friday that there was a fifth level of encryption on the coin which no one had broken yet.",4
182,"Is open source r-selected?
So there’s this idea from evolutionary ecology called r/K selection theory. The gist is that many species seem to converge toward one of two extreme survival strategies: r-selection, or K-selection.
r-selection: many offspring, low investment
K-selection: few offspring, high investment
r-selection: expand into open niches
K-selection: compete for crowded niches
r-selection: unlimited inputs (e.g. rabbits rarely run out of grass)
K-selection: scarce inputs (e.g. predators frequently face starvation)
r-selection: unstable habitats
K-selection: stable habitats
Basically swarms vs tanks, in video game terms.
This is a simplification. Not every species maps well to this heuristic, but r/K do seem to be interesting defensible points in the colonization-competition tradeoff.
So might there be such a thing as r/K selection in software? r/K is a survival and reproduction strategy, so a natural next question is, does software reproduce? Does it evolve? I think so!
One way software reproduces is through literally getting copied. npm install. Software modules can be composed and modified to produce new species. Technology evolves compositionally.
Another way software might reproduce is through memes. Concepts like hashmaps are reproduced across many programming languages. You can’t npm install Uber, but the concept of Uber can be reproduced and even mutated. If I say “Like Uber, but for kittens”, you kind of know what I mean. It’s part of the memepool.
Also, we know evolution happens in any system with heredity, mutation, selection.
Heredity: software is copied, either verbatim, or through memes.
Mutation: software is composed with other software, or modified.
Selection: some software gets used, some goes extinct.
So we can say software evolves. Perhaps it is even subject to r/K selection? I’d like to run with this analogy. What kind of software wants to be K-selected? What kind of software wants to be r-selected?
Aggregators seem K-selected. They are big, few in number. Millions in capital and human hours are poured into their care and raising. They are so K-selected that their survival strategy is functional immortality, rather than reproduction. Aggregators compete effectively within established niches, but may struggle to adapt to new environments (the innovator’s dilemma). K-selected species need stable environments, and aggregators limit variety to stabilize their environment and prevent disruption. Aggregators are like apex predators, and like many apex predators they are also a keystone species. Whole ecologies of influencers and creators depend upon them.
Programming languages and protocols also seem K-selected to me. They operate at the infrastructure pace layer, and last decades or more. Millions of hours of effort are poured into gardening and evolving them through RFCs, standards, PEPs. Protocols are like mangrove trees. Their growth constructs an ecology that supports many other species.
What about r-selected software?
Unix and C are the ultimate computer viruses.
(Richard Gabriel, 1989. “The Rise of Worse is Better”)
Is open source more like an elephant or a dandelion seed?
On the one hand, Linux feels like an elephant. On the other hand, the proliferation of one-function modules and micropackages on NPM sure feel like dandelion seeds. Take for example, is-even, a tiny module on NPM that gets hundreds of thousands of downloads per week.
var isEven = require('is-even'); isEven(0);
This could have been done in one short line of code, but it is easier just to npm install. Reproductive success?
The amount of dependency churn within the npm ecosystem seems r-selected, too.
There is one major wrinkle in this narrative. r-selected species thrive where food is abundant. Rabbits rarely run out of grass, but open source is under constant threat of starvation.
Even very popular libraries subsist on starvation wages, or nothing at all. Maintainers struggle to keep up with requests. Burnout is common. Sometimes libraries get abandoned as a result. Not a great equilibrium.
While all this plays out, there is an asteroid hurtling toward us that seems likely to upend the whole ecosystem, for better and worse.
This is GitHub Copilot. It is AI code autocompletion.
It’s pretty easy to see where this is going. Consider output from newer, larger large language models, like DALL-E.
The coherence of these images is remarkable. More than good enough to provoke meaning-making. It feels like we’re about 90% of the way toward generating finished artwork, icons, essays, that are indistinguishable from the hand-authored thing. So how long before we can generate entire software libraries? Applications? One year? Five? Ten?
What does this do to open source, to software in general? If maintainer attention is the bottleneck for r-selected open source, what happens when LLMs start writing software?
Instead of K-selected libraries, might LLMs generate hundreds or millions of r-selected solutions?
Is maintenance necessary when you can generate new libraries from scratch? Will open source become so cheap you can throw it away?
Will LLMs generate small modules more reliably than big ones? If small libraries are more tractable, can LLMs also recursively compose those small modules into bigger ensembles, and so on?
How understandable will AI-generated code be? Is human-meaningful code the most effective approach? Will they prefer their own intermediate languages? Or will we have LLMs generate high performance bytecode directly?
Will large swaths of libraries end up having similar exploits due to artifacts of the LLM? What kinds of heuristic code analysis might we need to build on top? Or could LLMs generate security analysis too, like a kind generative adversarial network?
Will the rate of new niche discovery increase once we are able to rapidly generate programs and try new things?
Who owns these hypothetical LLMs? Will they become the next point of aggregation? I can picture AI-powered IDEs that have the strategic significance of game engines in the sense that you can’t build without them.
On the other hand, once you get past the high capital costs of training an LLM, it can churn out effectively infinite supply. And these models seem to be quickly simplified and copied once created. Perhaps multiple LLMs will compete and churn out software modules as a pure commodity. Perhaps an LLM that licenses output as open source might outcompete the others, since an open source module can be copied at zero marginal cost. r-selection.
r-selected species thrive in unstable habitats. K-selected species don’t do well in rapidly changing situations. A software ecosystem full of fast-breeding, new-niche-constructing software seems likely to be unstable. Might r-selected open source become a threat to K-selected aggregators?
Update 2022-07-18: @seefeld builds on these musings with two related preprints: Can OpenAI Codex and Other Large Language Models Help Us Fix Security Bugs? and Synchromesh: Reliable code generation from pre-trained language models.",3
183,"The Huichol tribe from the Sierra Madre Occidental mountains in Mexico can speak to spirits. They leave our Earthly plane to visit animals and ancestors with the assistance of a small, green cactus.
The cactus, called peyote, is cut into discs and chewed raw to release a hallucinogen. A peyote trip starts with a ""growing sense of euphoria"", followed by a heightened sense of the noises around, before the tipper is plunged into a world of vivid dreams – at least that is how anthropologist Barbara Myerhoff described her experience after taking peyote with members of a Huichol tribe in western Mexico in her book Peyote Hunt.
Peyote contains mescaline – a psychedelic compound that can produce hallucinations similar to the effects of taking magic mushrooms. The discs taste ""unspeakably bitter-sour"" and ""revolting"" explains Myerhoff, but she adds that she lost her awareness of time, and instead started to skip from one vivid, self-contained dream to another. ""Although I discovered that I couldn't move, I was able to remain calm when it occurred to me that this was of no consequence because there was no other place that I wanted to be,"" she writes, noting that she found the experience not in the least scary, but deeply moving.
Psychedelics have been used in religious ceremonies, before war and for recreation in the Americas for centuries. For example, ayahuasca, a hallucinogenic drink made from certain brewed vines or shrubs, has been consumed by indigenous peoples in South America during religious and healing rituals for perhaps as long as 1,000 years. The Olmecs – one of the earliest Mesoamerican civilisations – and Maya people from Mexico are also thought to have used the neurotoxin from cane toads to hallucinate in their rituals. They believed they could speak to ancestors after taking a very small dose of dried toxin (too much would be fatal).
Why were these psychedelics used in rituals? Possibly because they elicit in the user a sense of awe and wonder. Medium to high doses of similar hallucinogens generate lasting feelings of bliss and insightfulness and a sense of profound spiritual enlightenment.
In the 1950s and 60s, there was a great deal of interest in psychedelics as a treatment for disorders from depression and alcohol addiction to schizophrenia. The US even ran experiments under the names Project MKUltra and Project MKDELTA to see if LSD could be used as a truth drug. While research into the therapeutic benefits of hallucinogens was largely paused after LSD was criminalised in the late 60s, there has recently been a renewal of interest in using hallucinogens such as ketamine and LSD as therapeutic treatments, with a spate of new studies.
Peyote is still eaten for its hallucinogenic properties (Credit: Emmanuel Lafont/BBC)
But ingesting substances is not the only pathway to experiencing hallucinations. Visual auras are a form of visual hallucination that typically accompany migraines. Fevers can also trigger hallucinations – they are a commonly reported symptom in malaria, for example, and were also reported by some patients during the Covid-19 pandemic. Certain illnesses like dementia, schizophrenia and some eye diseases can also cause hallucinations – sometimes called altered visual experiences – says Prem Subramanian, a professor of ophthalmology at the University of Colorado. Musical hallucinations have also been reported in association with hearing loss in some people. Grief too has been linked with hallucinations, with people reportedly hearing and even seeing a deceased partner.
But it's also possible for people to hallucinate if exposed to certain bright or flickering lights.
Exactly why we see these illusions is something of a puzzle, but we are now starting to unravel what happens in the mind during visions by comparing drug-, stimulus- and disease-induced hallucinations.
For example, the brilliance of snow might explain why some explorers and mountaineers claim to see strange figures following them during whiteouts. Sir Ernest Shackleton mentioned the sensation in his 1919 Antarctic expedition diary, South, saying that ""during that long and racking march of 36 hours over the unnamed mountains and glaciers of South Georgia, it seemed to me often that we were four, not three"".
One explanation for this particular illusion could be the Ganzfeld effect. If exposed to a continuous, uniform stimulus (for example, staring at a single wavelength of light) our brains try to make sense of the signal, and add in information which isn't there – generating hallucinations. You can see some of the BBC Reel team trying out the effect for themselves.
The Dreamachine
Because light-induced illusions can be created in controlled environments, they might help researchers to discover the origin of hallucinations. The fact that flickering lights on closed eyes causes visions of colours, shapes and movement is ""one of the oldest findings in neuroscience"", says Anil Seth, a professor of neuroscience at the University of Sussex, and the lead scientist on the immersive art-and-science project Dreamachine.
The fact that flickering lights on closed eyes causes visions of colours, shapes and movement is one of the oldest findings in neuroscience
Created as a tool to capture the diversity of the public's inner minds by using strobing lights to induce hallucinations, the Dreamachine has been touring the UK during 2022. It is based on a little-known invention from 1959 by the same name. With the promise of being able to experience psychedelic hallucinations without drugs, I ventured in.
The machine itself is a two-storey high, blue, octagonal box. About 20 participants are led through a curtain and into a circular central room. Around the edge of the room are curved seats that recline back so that the participants can stare upwards towards the ceiling. In the centre of the ceiling is a flat, white disc that gives off a gentle glow, around which there is a ring of large lights – the kind you might see in a theatre.
I lie back in the seat. The experience begins with some slow electronic music coming from the speakers behind me. The lights fade up and I'm surprised by just how bright they are. I'm squeezing my eyes shut but it's still a little bit unpleasant. Through my eyelids, the bright white light looks pinky orange. Then the lights start to strobe.
The pinky orange alternates with flashes of blue, which is the result of ""bleaching desensitisation"". If you've ever accidentally looked at a bright light for too long and noticed smudgy blotches in your vision for a period afterwards it's the same effect. The light receptors in your retina are over stimulated and take a short while to recover.
In the Dreamachine, the orange and blue colours start to overlap, and after a few minutes I notice that I'm seeing stripes and criss-cross patterns. These kinds of effects, caused by strobe lighting, are called flicker phosphenes, and are visually similar to the simple hallucinations that drugs can induce. These simple geometric patterns probably originate in the primary visual cortex.
Light-induced hallucinations produced by the Dreamachine range from simple geometric patterns to more complex landscapes and shapes (Credit: Emmanuel Lafont/BBC)
Seth says that the frequency of the strobing determines the strength of the hallucination by syncing with the frequency of brainwaves in this region of the brain. ""The most effective frequencies of the strobe lights are at around 10-15 Hz. [This] frequency range is similar to the alpha rhythm in the brain, which is very prominent over the visual cortex,"" he says. Other research suggests that the frequency might also determine the shapes seen. At 20–30 Hz, some people report spirals, waves, concentric circles, and lines, while at 10 Hz, zigzags, honeycombs, and rectangles.
""There's a lot of disagreement about what the alpha rhythm does,"" adds Seth. ""It becomes more prominent when you close your eyes and when you're relaxed. Some [neuroscientists] say it's just an idling state of the brain when it's doing nothing. Others argue that it's very deeply involved in how we perceive the world – that each cycle of an alpha rhythm, each 100-millisecond period, is a frame of visual perception.""
Nobody exactly knows quite how the Dreamachine works, we just know that it does – Anil Seth
As the music changes, the stripes I can see become waves. I start to see little white spots, like a universe of stars, swirling behind the coloured waves. Then the music changes and the colours follow. The scene now looks like a desert landscape – beiges and browns stretching off into the distance – except with dark tower blocks on the horizon which I am flying towards. I have no idea if the frequency of the strobing has changed, but the shapes I can see are continually in flux.
""Nobody exactly knows quite how the Dreamachine works, we just know that it does,"" says Seth. He speculates that it might be because the brain is not expecting any visual input – the eyes are closed – yet is getting some information because the light is so bright. ""It's trying to make sense of that visual input, but it can't make much sense of it.""
""One of the most interesting focus groups was with visually impaired people – not totally retinally blind but people with severe visual issues – it was a really, profoundly moving experience,"" he says. ""They seem to report similar things to what we're seeing in the general public. And that, for me, is pretty fascinating.""
Like in a dream, I have a sense that time is moving forwards, but I have no idea how long the machine has been running or how long is left. At one point I notice that I'm barely paying attention to what I'm seeing anymore and I wonder if I had briefly fallen asleep. But I snap back into the moment.
The desert has now been replaced by multicoloured geometric shapes, like a simple kaleidoscope or an abstract, tessellated stained glass window. There are bright lime greens, yellows, blues and reds. The shapes move towards me, as though the window is breaking apart. I am reminded of the guide at the start who explained that all the colours I can see are generated by my brain. It's the most compelling part of the experience yet, and when the scene changes to something else I miss the colourfulness of the stained glass.
Why the brain creates colours, shapes and patterns in the Dreamachine is still not clear – but that is what Seth and his colleagues are trying to work out. He says that the patterns people see are very related to aspects of the wiring of the primary visual cortex. ""It's almost as if the strobe light is activating these visual regions.""
Colour vision is a fascinatingly subjective experience. The viral #thedress photo from 2015 that divided the internet is a case in point, says Seth. So, the age-old question of whether you and I see the same colours has a simple answer – we don't. In fact, our own perception of colours continually changes.
In summer, the colour yellow shifts slightly towards green, and in winter it shifts towards red, for example. This might be because during the summer we see more green light reflected from vegetation. We compensate for the extra green we are seeing, which means that a greenish yellow looks more like pure yellow in the summer, explains Lauren Welbourne, a psychologist at the University of York in the UK.
""This idea of having different experiences of the shared environment isn't just confined to the Dreamachine, it's happening everywhere and all the time,"" says Seth, who is also the author of Being You: A New Science of Consciousness. ""We all have a unique perceptual experience, a unique inner universe. Very little is known about this kind of inner diversity.""
Exploring that inner diversity is part of Seth's next project. He and a team of scientists and philosophers are collecting a snapshot of the public's uniqueness in a perception census, designed to bring out the variety of the public's subjective experiences with a few simple questions.
Back in the Dreamachine, the music and lights fade away, and the guides tell us the experience is over. I compared my experiences with another participant, and while there were similarities – a sense of 3D space, swirling stars and galaxies, and geometric shapes – it's also clear that our journeys through our minds were quite different. It’s this inner uniqueness that Seth and his colleagues hope to capture in their census.
A complex picture
While the simple colours and patterns I saw were interesting, they pale in comparison to the vivid testimonies of people who have drug-induced or medical hallucinations. Why might those visions be so much more complex?
Ayahuasca and cane toad toxin contain the neurotransmitter DMT, which is closely related to serotonin, melatonin, and psilocybin – the latter of which is the chemical that gives magic mushrooms their hallucinogenic properties. Serotonin and melanin have a role in controlling sleep, while serotonin is also responsible for feelings of hunger, our mood and for feeling rewarded.
The hallucinations produced by drugs are often more complex and can leave the tripper with profound feelings (Credit: Emmanuel Lafont/BBC)
The links between serotonin and substances like DMT and psilocybin might go some way to explain how these psychedelics work. DMT, psilocybin and the lab-made hallucinogen LSD all activate serotonin receptors in our brains. Activation of these serotonin receptors by hallucinogenic drugs appears to be one cause of complex visual hallucinations, and some of the trippier effects of psychedelics.
In one study, participants were given controlled doses of LSD and another chemical called ketanserin, which blocks serotonin receptors, to see what role these receptors have in psychedelic trips. With the receptor unblocked, participants found that previously meaningless music became meaningful and profound after taking LSD. Blocking the receptor with ketanserin prevented these meaningful feelings.
It might explain why psychedelic trips are often accompanied by profound feelings, suggests Katrin Preller, assistant professor at the University of Zurich, who is the lead author of the paper. In a later study, Preller found that LSD leads to an increase in the connectivity of the brain networks associated with our senses, which could explain why our senses become heightened.
Drug-induced hallucinations tend to range from brightly colored geometric shapes like lattices, cobwebs, tunnels, and spirals to scenes or landscapes which can contain people, animals, spirits, aliens and monsters. There are similarities between the former types of hallucinations and the aura that migraine sufferers will be familiar with.
""Hallucinations that come from the primary visual cortex are more unformed,"" says Subramanian. ""They are going to be sparkles, lights and shapes."" Migraine auras are a common medical example of this, he adds, and much less frequently he sees brain tumour patients with similar symptoms.
But complex hallucinations can be bizarre and frightening, containing scary images of faces, people or objects. While sometimes drug-induced, these hallucinations can also be a symptom of several diseases, from schizophrenia to dementia.
One of the more curious examples of disease-related hallucinations is Charles Bonnet syndrome, which is the result of eyesight loss. Damage to the retina, or anything that can reduce light passing through the eye, like a cataract, can cause patients to see hallucinations, which can range from geometrical patterns to disembodied faces and costumed figures. It is not known how vision loss causes these hallucinations, but it is thought that as the eyesight deteriorates the brain starts to compensate for the missing information and spontaneously creates made up images.
Charles Bonnet syndrome is sometimes called ""phantom vision"" and has been compared to phantom limb syndrome, where amputees believe they still have their missing limb.
Certain medical conditions can produce visual hallucinations, but the reasons why are poorly understood (Credit: Emmanuel Lafont/BBC)
Another visual oddity is palinopsia, where people see the same image frozen for a brief period of time. For example, if you stare at a chair on one side of the room, and then looked over to the other side, it might appear that the chair has teleported across the floor. This is caused by delays in the retina refresh rate. The photopigments in our retinas take a fraction of a second to refresh after being stimulated. Usually this happens very quickly – it's why movies shot at 30 frames per second look like seamless movement. But in palinopsia patients, the refresh rate slows significantly, meaning images can get stuck in the vision.
Unlike induced hallucinations – which require an external stimulus like a drug or light – Charles Bonnet syndrome and palinopsia are examples of released hallucinations that happen spontaneously. Subramanian says that errors in the normal process by which vision is regulated can create visions.
""Even patients with what we might think of as mild to moderate visual impairment can have these release hallucinations,"" he says. ""There are a good number of patients who have glaucoma or macular degeneration, who experienced visual hallucinations, but they don't want to tell anyone about it, because then they think they're crazy. And so it's very important that doctors who take care of those patients be alert to the fact that it's relatively common for them to experience these hallucinations.""
Subramanian urges anyone experiencing hallucinations that are outside of the ordinary not to ignore them and to seek medical advice to make sure there's nothing abnormal.
There were no lasting effects of my time in the Dreamachine. Unless there is a reason why flashing lights might cause you problems, light-induced hallucinations can be a revealing and interesting experience.
Understanding why each of our experiences in the Dreamachine will be slightly different might remain out of reach for now, but perhaps Seth and his colleagues will get us a little closer to knowing the full range of our inner experiences.
* William Park is a senior journalist for BBC Future and tweets at @williamhpark
--
Join one million Future fans by liking us on Facebook, or follow us on Twitter or Instagram.
If you liked this story, sign up for the weekly bbc.com features newsletter, called ""The Essential List"" – a handpicked selection of stories from BBC Future, Culture, Worklife, Travel and Reel delivered to your inbox every Friday.",1
184,"Learn In Public
The fastest way to learn
swyx
8 reactions 2018-06-19
Translations welcome! (한국어, 日本語, Español 1, 中文, Español 2, Español 3, 中文, 中文 2, Português 1, Português 2 Português 3, Deutsch, Français, فارسی. Add yours here!)
If there’s a golden rule, it’s this one, so I put it first. All the other rules are more or less elaborations of this rule #1.
You already know that you will never be done learning. But most people “learn in private”, and lurk. They consume content without creating any themselves. Again, that’s fine, but we’re here to talk about being in the top quintile. What you do here is to have a habit of creating learning exhaust:
- Write blogs and tutorials and cheatsheets.
- Speak at meetups and conferences.
- Ask and answer things on Stackoverflow or Reddit. Avoid the walled gardens like Slack and Discord, they’re not public.
- Make Youtube videos or Twitch streams.
- Start a newsletter.
- Draw cartoons (people loooove cartoons!).
Whatever your thing is, make the thing you wish you had found when you were learning. Don’t judge your results by “claps” or retweets or stars or upvotes - just talk to yourself from 3 months ago. I keep an almost-daily dev blog written for no one else but me.
Guess what? It’s not about reaching as many people as possible with your content. If you can do that, great, remember me when you’re famous. But chances are that by far the biggest beneficiary of you trying to help past you is future you. If others benefit, that’s icing.
Oh you think you’re done? Don’t stop there:
- Enjoyed a coding video? Reach out to the speaker/instructor and thank them, and ask questions.
- Make PR’s to libraries you use.
- Make your own libraries no one will ever use.
- Clone stuff you like, from scratch, to see how they work.
- Teach workshops.
- Go to conferences and summarize what you learned.
If you’re tired of creating one-off things, start building a persistent knowledge base that grows over time. Open Source your Knowledge! At every step of the way: Document what you did and the problems you solved.
The subheading under this rule would be: Try your best to be right, but don’t worry when you’re wrong. Repeatedly. If you feel uncomfortable, or like an impostor, good. You’re pushing yourself. Don’t assume you know everything, but try your best anyway, and let the internet correct you when you are inevitably wrong. Wear your noobyness on your sleeve.
People think you suck? Good. You agree. Ask them to explain, in detail, why you suck. You want to just feel good or you want to be good? No objections, no hurt feelings. Then go away and prove them wrong. Of course, if they get abusive block them.
Did I mention that teaching is the best way to learn? Talk while you code. It can be stressful and I haven’t done it all that much but my best technical interviews have been where I ended up talking like I teach instead of desperately trying to prove myself. We’re animals, we’re attracted to confidence and can smell desperation.
At some point you’ll get some support behind you. People notice genuine learners. They’ll want to help you. Don’t tell them, but they just became your mentors. This is very important: Pick up what they put down. Think of them as offering up quests for you to complete. When they say “Anyone willing to help with __ __?” you’re that kid in the first row with your hand already raised. These are senior engineers, some of the most in-demand people in tech. They’ll spend time with you, 1 on 1, if you help them out (p.s. and there’s always something they want help on). You can’t pay for this stuff. They’ll teach you for free. Most people don’t see what’s right in front of them. But not you.
“With so many junior devs out there, why will they help me?”, you ask.
Because you learn in public. By teaching you, they teach many. You amplify them. You have one thing they don’t: a beginner’s mind. You see how this works?
At some point people will start asking you for help because of all the stuff you put out. 80% of developers are “dark”, they dont write or speak or participate in public tech discourse. But you do. You must be an expert, right? Don’t tell them you aren’t. Answer best as you can, and when you’re stuck or wrong pass it up to your mentors.
Eventually you run out of mentors, and just solve things on your own. You’re still putting out content though. You see how this works?
Learn in public.
p.s. Eventually, they’ll want to pay you for your help too. A lot more than you think.
Author’s Note: I have written an expanded version of this essay and its related canon (below) in The Coding Career Handbook.
Read this next: The Ultimate Hack for Learning In Public (expanding on “Pick Up What They Put Down”)
- Then learn about Learning Gears
- Not everything must be public: How To Learn In Private
- A mathematical intuition for why LIP works: Big L Notation
- Learn how to turn ignorance to power: The Power of Lampshading
This essay was originally drafted in a gist and republished in Letters to a New Developer.
I continue to talk about it on podcasts even in 2022 - see the live updating list here: https://www.swyx.io/ideas/?filter=learn%20in%20public
Related links
-
Patio11: Do not end the week with nothing
-
Chris Coyier: Showing up and Persistence and Working in Public
-
Cory House: Becoming an Outlier and The Art of Learning and Lifestyle Systems and The 7 Pillar Developer
-
Jeff Atwood: How to stop sucking and be awesome instead
-
Rachel Thomas: Why You (yes, you!) Should Blog
-
Kent C Dodds: Intentional Career Building
-
Julia Evans: Blog about what you’ve struggled with
-
Joshua Branchaud: Learning In Public by posting daily TIL’s for 5 years
-
Patrick O’Shaughnessy: Learn, Build, Share, Repeat
Learn in public, fanatically. Find something you can’t stop thinking about and know it better than anyone, and share everything you learn along the way. Once deep enough, start building something too. Make something you have to sell as early as possible. - Patrick in David Perell’s Twitter course
-
LadyBug Podcast: Blogging 101 (esp Ali Spittel’s Blog Post Workflow)
-
GitHub ReadME project: Publishing your work increases your luck (see HN comments)
-
Quincy Larson: Build your Skills, Build your Reputation, Build your Network
-
Ali Spittel on syndicating content on the Arrested DevOps podcast
-
Reid Hoffman: Those Who Teach, Can Do
-
Shu Omi did LIP on YouTube and gained 5k subscribers in 8 months!
-
Kei Watanabe: https://twitter.com/rainar_angelo/status/1519530337285869568
-
Gift Egwuenu on Learning in Public
-
How do Rocket Scientists Learn? (Knowledge Management Lessons learned at Goddard, NASA)
In some places, Knowledge Management is about creating systems that get around people’s knowledge deficiencies. At Goddard, it really seems like it is about empowering people to share and reflect on what they know best. It’s a subtle distinction, but I really like that they put people in the center of this work, and start from a place of abundant knowledge in people rather than a lack of information in systems. Social media has a lot of potential, but you need to think about how to facilitate different kinds of (online and offline) relationships between people so that their thinking is improved, innovation occurs, they can get quick answers to complex problems, in order to enhance and accelerate business outcomes. One of the great benefits of using social media as a KM tool is that you are creating and capturing the knowledge at the same time. However, in order for this to truly work people have to be willing to collaborate in the open throughout the project lifecycle. “Learning in Public” is scary for many reasons – people can find and cling to outdated information and users are exposing their knowledge during a vulnerable time in the project (i.e. when they don’t yet have all the answers). However, during this part of the process is when learning can be most valuable. If you share what you know and what you don’t know in the middle of a project, you give people an opportunity to share specific knowledge that can help you in the moment. If it works, this can help save time and money.
- Nathan Barry in his book Authority:
Back in 2007 Chris Coyier launched a site called css-tricks.com. It was a site dedi- cated to teaching people how to code websites. (CSS is the language that describes how websites should look.) When CSS-Tricks first came out I remember reading a tutorial and arrogantly thinking, “I know that already.” Chris and I were at about the same skill level, so I didn’t learn anything new from him. This continued for a while as he kept putting out new tutorials. But over time, as friends started asking me CSS questions, I found it easier to link to one of Chris’s articles (since they were really well written) than explain everything myself. Years later Chris ran a Kickstarter campaign to redesign his site. Those who con- tributed would get behind-the-scenes access to additional tutorials and content re- lated to the redesign. The goal was set fairly low at $3,500. He quickly blew past the goal and by the end of the campaign had raised $89,697. Incredible. The point is that he did it with relative ease, all because he had built up an audi- ence who loved his work. He and I started at the same point and our skills progressed at about the same rate. The difference was that he taught and shared, whereas I kept what I was learning to myself. That made the difference between being able to make tens of thousands of dollars on a new project versus releasing to no one.
Nathan in general has a lot of riffs on LIP:",1
185,"What Happened: Chinese childrenswear brand Balabala has made its first foray into the metaverse by appointing a virtual child ambassador named Gu Yu. First introduced on Xiaohongshu, Gu Yu doubles as an independent influencer — sharing regular short-form content and product releases from the brand alongside real-life models and in the form of NFT pieces. For Balabala, this strategic repositioning aims to target digitally-native young parents who have outgrown the princess and Chinese hanfu clothing styles traditionally associated with the childrenswear category.
The Jing Take: Virtual influencers are not a new phenomenon in the Chinese market. In fact, with top virtual idols Ayayi and CELIX 赛 recently collaborating with Tiffany and Calvin Klein, respectively, to promote new product launches, brands are unquestionably taking notice of the opportunities that virtual influencers provide. From full image control to maximum flexibility, brand-focused meta-ambassadors allow for nuanced and customized cultural relevance — ultimately paving the way for richer consumer-brand experiences.
Balabala’s introduction of Gu Yu confirms that virtual KOLs as more than a passing trend. Alongside the increasing use of the metaverse for social interaction comes the certainty that digitally developed young Chinese will have identities there. By showcasing the virtual star in a variety of outfit styles ranging from preppy to sporty to girly, Balabala hopes to connect Gu Yu with real-life children as their meta-companion, inspiring them to freely express themselves and their unique lifestyles through their fashion choices. Soon, the brand hopes to introduce Gu Yu to offline events including fashion shows, which means the lines between physical and digital will continue to blur.
As younger cohorts increasingly demand greater immersion and interaction with influencers, it comes as no surprise that the metaverse provides an ideal feeding ground for consumer connection. By bringing Gu Yu to life, leading childrenswear brand Balabala bets on tech activation as the future of consumer-brand relationships — one where the metaverse is synonymous with identity and self-expression.
The Jing Take reports on a piece of the leading news and presents our editorial team’s analysis of the key implications for the luxury industry. In the recurring column, we analyze everything from product drops and mergers to heated debate sprouting on Chinese social media.",1
187,"The cybersecurity sector is rapidly growing and developing new ways to guard against sophisticated attacks. How can you take advantage of the long-term investment opportunity?
The number and sophistication of cyberattacks have been growing for years, spurred by the rise of big data, cloud computing and remote work. With more data being accessed from more places than ever before, the complexity of securing digital systems has increased exponentially. The result: strong and growing demand for security services that could boost cybersecurity-related stocks for years to come.
Strong and growing demand for security services could boost cybersecurity-related stocks for years to come.
These trends may offer some of the most compelling long-term investment opportunities in technology today. This includes both a growing array of cybersecurity providers and, increasingly, defense companies seeking to bolster their cyber capabilities amid mounting threats from abroad.
Here’s a closer look at the key factors we see driving this technology megatrend and how investors can benefit.
More Data, More Access, More Risk
As the world creates more data and accesses networks in more ways, cybercriminals find new vulnerabilities to exploit. The number of significant cyberattacks has increased from just four major incidents in 2006 to a peak of 134 in 2020.1 As the number of attacks has grown, so has the cost to the victims. IBM found that the average cost of a data breach in the U.S. has grown from $3.5 million in 2006 to $9.4 million in 2022, a nearly 170% increase in 16 years.2
Major cyberattacks have increased significantly
Significant Cyberattacks
Source: Center for Strategic and International Studies, Morgan Stanley Wealth Management Global Investment Office as of Dec. 31, 2021.
The nature of cyber threats has also evolved. In the past, cybercriminals often focused on stealing personal information, such as credit card data and Social Security numbers. While such threats are still present, major cyberattacks today are increasingly being conducted by geopolitical adversaries like China, Iran, North Korea and Russia, and often focus on shutting down critical supply chains and infrastructure, such as the U.S. power grid.
Cybersecurity Providers May Be Poised for Growth
Ultimately, the ever-growing threat of cybercrime is driving opportunity for cybersecurity providers. Morgan Stanley Research estimates that total direct revenues at security software vendors eclipsed $45 billion in 2020, expanding at a 12% three-year compound annual growth rate—making security one of the fastest-growing subsectors within technology.
That growth is likely to continue in the coming years. In a recent survey of corporate chief information officers, Morgan Stanley Research showed cybersecurity spending appears poised to grow faster than other software categories. It’s also likely to be more resilient at a time when broader technology budgets could come under pressure, with respondents pointing to a lower likelihood of security spending cuts, compared to other areas in software.
The Investment Opportunity in Cybersecurity
For investors interested in exploring how their portfolios can benefit from strong secular growth in the cybersecurity and defense industries, there are several approaches to consider.
For example, thematic exchange-traded funds (ETFs) can provide broad exposure to both U.S. and global companies focused on providing network protection.
Alternately, if you are interested in pure-play single-stock investments, consider companies working in three areas:
- Endpoint security providers have traditionally focused on protecting a network’s perimeter by securing entry points across connected devices, such as computers and cell phones. Solutions in this industry subsector have evolved from traditional antivirus software to comprehensive protection from sophisticated malware.
- Network security vendors aim to protect the users, data and apps within a network’s perimeter, minimizing access rights and duration to reduce overall information-security risk within the system.
- Defense and aerospace firms are increasingly integrating cybersecurity within their products, as heightened geopolitical risks blur the lines between cybersecurity and national defense. This could strengthen the secular investment opportunity among companies involved in cybersecurity, such as traditional defense contractors.
While cybersecurity remains one of the most compelling secular growth opportunities in technology today, it’s worth noting that this opportunity has not been lost on the market. In fact, the sector has outperformed its software peers in recent years, and valuations remain above pre-COVID levels. Investors should keep in mind that still-elevated valuations may make the sector susceptible to more downside if macro pressures persist. Look to selectively add exposure to cybersecurity stocks when valuations weaken.
Interested in learning more? Ask your Morgan Stanley Financial Advisor for a copy of the AlphaCurrents report Cybersecurity: Secular Opportunity Amid Cyclical Weakness—and talk to your Financial Advisor about how you can potentially benefit from investing in cybersecurity.
Questions You Can Ask Your Morgan Stanley Financial Advisor:
- How can I gain exposure to growth in the cybersecurity industry in ways that fit with my long-term investment goals?
- What are some ways to invest in specific cybersecurity providers and/or defense companies bolstering their cyber capabilities?",2
188,"The $100 Trillion Opportunity in Marketplaces
Examining B2B Marketplaces
This is a weekly newsletter about how tech and culture intersect. To receive Digital Native in your inbox each week, subscribe here:
The $100 Trillion Opportunity in Marketplaces
Last week, I wrote about how mobile and cloud have been the two major technology tailwinds of the past decade. I argued that much of the hype (and ensuing venture capital investment) in new technologies and vaunted ‘platform shifts’ today—virtual reality, augmented reality, web3, and so on—derives from anxiety around mobile and cloud being…old. AWS launched in 2006; the iPhone came out in 2007. Neither mobile nor cloud are saturated, but they aren’t as ripe for greenfield opportunity as they once were.
Yet there are still massive markets relatively untouched by mobile and cloud. When we think of marketplaces, we tend to think of business-to-consumer (BTC) marketplaces. Uber and Airbnb. Amazon and Ebay. In recent years there have been fewer breakthrough startups in consumer marketplaces (the category is more saturated than it was in its heyday), but most of the innovation in marketplaces over the past 25 years has been consumer-facing.
This isn’t a surprise; the painpoints addressed by consumer marketplaces are widespread and easy to understand. It makes sense that entrepreneurs would address them first. Less obvious, though, are the painpoints in business-to-business (B2B) commerce. But B2B is an even bigger prize: an estimated $100 trillion flows between businesses each year, a 4-5x multiple of transaction volume between businesses and consumers.
B2B marketplaces are a massive opportunity. Only about 5-10% of B2B transactions happen online and—in the year 2022!—about 50% of transactions are still done over the phone, over fax, or via in-person meetings with sales reps. The entire B2B ecosystem is inefficient, opaque, and convoluted.
One of the most successful B2B marketplaces is Faire, which also happens to be where my partner Ian works. Faire serves end markets that should be familiar to everyone, and its business model offers good lessons for emerging startups. As a result, we can use Faire as a case study for B2B marketplaces more broadly.
Faire is a wholesale marketplace for independent retailers and brands. But what does that mean in layman’s terms? At its simplest, you can think of Faire as the business-to-business version of Etsy. Faire connects physical retailers—think: that cute mom-and-pop shop on Main Street—with brands that they can sell in their stores.
At Index, we’re investors in Ankorstore, which operates a similar business model across Europe. If you think of the cute boutiques you pop into while in Paris, many likely source products through Ankorstore’s marketplace. (You can read more about Ankorstore, which is Paris-based, from my partner Martin here.)
For the purposes of this example, I’ll focus mainly on Faire, since most readers are based in the U.S. and since I’ve had a front-row seat to Ian’s experience scaling the business.
Every year, U.S. consumers spend about $3.5 trillion buying stuff. Independent retailers (small businesses with only a handful of employees and often just a single location) make up $750 billion of that spend, or about 25%. We’re all familiar with the narrative that Amazon is eroding local retail, but that narrative is actually false: while midsize and large chain stores are reeling (Sears, Macy’s, JCPenney, and so on), local retail is thriving. As one datapoint, the number of independent bookstores in the U.S. increased 49% from 1,600 bookstores in 2009 to 2,500 in 2018.
Part of Faire’s mission is to leverage technology and data to better equip independent retailers in the fight against Amazon. Consumers still want to shop local; retailers and brands just need the tools to compete on an equal playing field.
To understand what Faire does, let’s take an example of a real-life Faire retailer.
This is Giselle Gyalzen, the owner of a boutique gift shop in San Francisco called Rare Device.
Giselle has been running Rare Device since 2011 and focuses on selling products made by women and people of color. Giselle is an actual retailer on Faire (I found her via Faire’s blog), but the example here is largely hypothetical. The goal is to explain how Faire works.
In the past, Giselle would need to go to an in-person trade show to find products to sell in her store. An average trade show has 500 exhibits and 10,000 attendees. Discovering new products is cumbersome, and it can cost $10,000 or more to attend.
With Faire, though, Giselle can sign up as a retailer and discover brands through the online marketplace:
Giselle can filter by specific brand characteristics—here, for instance, she can specifically browse products that aren’t sold on Amazon:
Let’s look at three reasons Faire’s marketplace is so successful, which double as three learnings for other B2B marketplaces.
High fragmentation on both sides of the marketplace
Both the demand-side (retailers) and supply-side (brands) of Faire’s marketplace are highly-fragmented. This makes the marketplace a crucial intermediary, and reduces the risk of disintermediation (a retailer and a brand taking their relationship off the marketplace).
As a general rule, the more fragmented the market, the better the opportunity for a B2B marketplace. Aerospace parts, for instance, may be a large market—but if Boeing and Airbus only have a handful of relationships with suppliers, the marketplace provides little value to justify its take-rate. Boeing and Airbus might prefer negotiating deals with suppliers directly, forgoing the marketplace altogether.
Discovery is mission-critical and data-driven
Related to fragmentation is the fact that discovery is core to doing business as an independent retailer. Retailers need to be constantly on the lookout for new brands that might boost sales; brands, meanwhile, need to be discoverable by retailers.
An online marketplace like Faire has a compelling advantage over the offline alternative: data. Faire can tell a gift shop in Milwaukee, “Hey, this other gift shop in New Orleans is a lot like you, and they had luck selling Emily’s Candles. You should give Emily’s Candles a try.” Faire amasses an enormous dataset from its 600,000 retailers and 85,000 brands in 15,000 cities, then wields that dataset to equip boutiques with personalized recommendations and insights that help them compete with Amazon. Ankorstore does something similar with its 200,000 retailers and 15,000 brands across Europe.
Discovery isn’t so central in every B2B marketplace (Faire and Ankorstore have some elements of consumer marketplaces in how fragmented both sides are), but there is typically some element of discovery. Bringing relationships online reduces friction to linking up with counterparties on the other side of the aisle. This dovetails with networks effects—more on that later.
Bringing existing relationships online
Most of the retailers in Faire’s network already had existing relationships with brands, and vice versa. Faire allows retailers and brands to bring these relationships online, with heavy incentives to do so.
One of the key pieces of Faire is its growth loop. Faire is built on referrals. Here’s a graphic from Anu Hariharan at YC Continuity that captures it well:
Incentives go beyond the benefits in this graphic, and are also financial:
Say that Giselle, the retailer behind Rare Device, already works with a dozen brands. For every brand that Giselle refers to Faire, she gets a shopping credit. Faire also won’t take a commission on that brand-retailer relationship. Ankorstore has a similar viral loop with its European brands and retailers, which are encouraged to invite one another onto the marketplace. The platform is designed so that everyone wins. Brands want all their retailers on the marketplace, because they benefit from managing their entire business all in one place. Retailers benefit because they get access to free returns, net-60 payment terms, and better shipping rates (more on that below). Incentives turn the flywheel faster.
The elegance of marketplace businesses is in how network effects kick in: as more retailers and brands join the platform, the marketplace becomes more valuable to both sides.
Bonus: Financial Services
There’s a saying in tech that’s caught on the past few years—“Every company is a fintech.” And there are elements of truth to it, particularly in B2B marketplaces.
Embedding payments into the marketplace removes a huge painpoint while also preventing disintermediation. Faire goes a step further by offering net-60 payment terms. In short, Faire will give retailers 60 days to repay purchases from brands, which improves working capital and reduces risk. If a retailer can’t sell a brand, it can simply return product. In a pre-Faire world, retailers limited new products to 20-30% of total inventory, worried about inventory risk. Faire removes that risk and allows retailers to experiment with new brands in a data-driven, risk-free way.
Building in financial services is also a playbook in vertical software, which shares many commonalities with B2B marketplaces. At Index, we’ve invested in a wide range of vertical SaaS companies—
ServiceTitan for home services (plumbers, electricians, etc.)
Shopmonkey for mechanics
Boulevard for salons and spas
Tekion for auto dealerships
Best-in-class vertical SaaS companies tend to integrate payments over time 1) to lock in customers, and 2) to better monetize transaction volume. Check out this piece from my partners Nina and Paris for more detail.
B2B marketplaces often resemble vertical SaaS. Faire, for instance, offers brands tools like invoice management and a CRM through which they can run their businesses. Brands are checking Faire daily to fulfill orders, while retailers are likely returning multiple times a week to replenish inventory and discover new brands. This behavior is similar to what we see in vertical SaaS companies like Boulevard, which helps hair salons manage appointments and payments, or ServiceTitan, which is the one-stop-shop for home services professionals (electricians, plumbers) to run their businesses.
The Rise of Vertical B2B Marketplaces
Over the past few years, we’ve seen more and more B2B marketplaces emerge. Given how specialized and complex different sectors are, B2B marketplaces tend to be vertical in nature—tailored specifically to the painpoints in a single (yet often deceptively-large) market.
Mable, for instance, extends the Faire model to independent grocery—a $250B segment of the grocery market in which inventory orders are still 90% done by phone and email.
Odeko, meanwhile, is a B2B marketplace for coffee shops. Cafes can order coffee beans, milk, paper products, and everything else they need from suppliers. Choco, based in Berlin, is another food-related B2B marketplace and serves restaurants. Frubana, meanwhile, also serves restaurants but focuses on Latin America. As the name suggests, the business started with fruits and vegetables; Frubana’s founder is the son of a mango, lime, and papaya farmer. (This is a common theme in both B2B marketplaces and vertical SaaS: an entrepreneur who has directly experienced or witnessed the painpoints and intricacies of that industry.)
One B2B marketplace that we recently invested in is Rooser, a marketplace connecting fish processors with wholesalers 🐟 The fish market is unique because the product has a very short shelf-life. A marketplace needs to operate in real-time to get fish from the sea to your plate efficiently. Suppliers on Rooser can quickly upload, price, and profile their daily stock of fish; buyers can search, negotiate, and transact quickly. The European fish market is a ~$150B market and Rooser is live in 13 countries. My colleague Georgia wrote more about Rooser here—and here’s a picture of Georgia rocking some cool yellow boots on a fishing boat in Scotland:
B2B marketplaces go beyond food, of course. The global chemicals industry is $3.8 trillion in revenue, powering industries as diverse as pharmaceuticals, cleaning supplies, and beauty. Knowde is a B2B chemicals marketplace for ingredients and raw materials. Moov, meanwhile, is a marketplace for used semiconductor equipment, a $105B market growing to $168B by 2026.
Virtually any industry that’s large, fragmented, and offline is ripe for reinvention with a B2B marketplace.
Final Thoughts
Given the size of the opportunity in B2B marketplaces, it’s surprising that we’ve seen relatively little startup formation. But the timing might (finally) be right, for a few reasons:
The groundwork has been laid. For instance, new startups make it easier to integrate payments or to manage complex shipping logistics. The tech infrastructure is now ready.
Just as COVID accelerated e-commerce penetration in B2C, it did the same in B2B. Every market is digitizing.
Millennials are beginning to dominate the workforce, and these are digital natives (or at least early digital adopters). They expect seamless, online workflows—and as they realize how archaic enormous industries are, they bring those industries into the 21st century.
The 2020s will be a marquee decade for B2B marketplaces. If there’s one I missed above, or if you’re building one, I’d love to learn more about it.
Sources & Additional Reading
Reimagining B2B Commerce with Faire—a great piece written by YC’s Anu Hariharan a couple years back
B2B Marketplaces Market Map | BVP
My colleague Martin on Ankorstore and my colleague Georgia on Rooser
Ian Spear, my much-smarter better half and my go-to expert on everything B2B marketplaces 🤓
Thanks for reading! Subscribe here to receive Digital Native in your inbox each week:",1
189,"Imagine you are growing up in Moscow, part of a family of eight living in a small apartment. The Berlin Wall fell not too long ago. Four times a year, you join your siblings in unpacking large boxes of buckwheat that your mother has kept stacked against a wall. You spread the kernels, pluck out the weevils, bake it all at a sterilizing temperature, and pack it up again. You are preparing for the future.
Around you, there is piracy and chaos. But you’re enterprising, and keep to your path. At university, you hardly sleep, and you eat what you can afford. Why do you work yourself this way? It’s not as if you’re getting paid for it.
Another version of yourself, in another time, though, is. Now, living in the California sun with some success, you reflect on your poor, wan, sleepless younger self and feel a wave of gratitude, and then of prickly regret. The kid you were had different dreams; it strikes you as unfair that you sit pretty on the spoils of that person’s efforts. If you could take some of your wealth and send it backward in time, to your younger self, you would.
We usually think of inequalities as extending from bottom to top: I earn a little wealth over eight hours; Bill Gates earns much more. But there are also inequalities that extend longitudinally, from the past into the future. Your young self does labor for which your older self collects rewards. Such timing issues—how much money you receive or can spend now and later—have effects on your financial fate. In a more equal world, you cannot help but think, people would draw on their lifetime wealth throughout their lives, not merely at the pinnacle of their careers. You notice that older generations and big corporations rule the roost in the United States, but it’s not clear why this should be so.
At your day job, which deals in shareholder capital, you impress your graying superiors, while at night you talk with young friends who, beset by debt and meagre wages, feel they’re barely eking out a life. You dream of what would happen if the money from your day job could cross over to your friends at night. Imagine that this idea becomes a fixation, so much that you decide you’d risk a piece of your own future on a solution. And now imagine that, instead of being one person, you are two.
Daniil and David Liberman, two entrepreneur brothers who purport to share a single life, met me one chilly November afternoon in midtown, and we set off for a walk through Central Park. The brothers have a sandy shade of hair and a punctilious Eastern European way of furrowing their brows and making little tutting noises as they zero in on the mot juste. They were fresh from Playa Vista, California, a residential and office-space hamlet whose chief virtue is its proximity to LAX. Daniil, who is older, at thirty-nine, has a gaunt, freckled face, and when we met was wearing his hair in the long, curling style of George Frideric Handel. David, a year younger, resembles Stephen Hawking in his youth. For some days, they’d been courted by fancy investors, with a schedule that included a trip in a private helicopter, an experience they found fun but, like most things that aren’t part of what they call their “mission,” distracting. “We need to get back home so we can really work,” Daniil, who was wearing green trousers with Pokémon and flowers on the legs, told me. The brothers’ mission, they think, is chasing the future, so in one way or another they are usually playing catch-up.
Few members of the general public have heard of the Libermans or their work, which has a looping, manic trajectory, like an ant’s climb up a candy cane. Yet they belong to a rising techie class that quietly traffics novel-seeming ideas among powerful people, shaping the wider world we live in along the way. In the past decade, the brothers led the design of the 3-D-Bitmoji feature on Snapchat, helped put out a hit Russian political-satire show, and devised an approach to capping corporate returns for investors. They have a way of popping up, like a lanky, pale Bill and Ted, in the background of interesting moments, with improbable associates. One friend of theirs calls them “hilariously networked.” Another, Jerry Murdock, found them on his path toward spiritual relief.
“I was on a honeymoon in 2010 in Dharamshala, spending part of it in the palace with His Holiness the Dalai Lama, and on the way out of there we met Gyetrul Jigme Rinpoche, who’s the reincarnation of a saint named Pema Lingpa, and he said, ‘You’ve got to meet these two brothers I know!’ ” Murdock, a co-founder of Insight Partners, which holds one of the world’s largest venture-capital funds, told me. “So I would fly around to different cities of the world, and the Libermans would be there—London, New York, Geneva, Zermatt—and we would walk down the street and talk.” Small talk with the brothers veers toward big ideas; Murdock, having led an investment round in Twitter, asked them for their thoughts about the future of the platform. (The Libermans: Broaden it into a full-service mobile-messaging app—a role now filled by WhatsApp. Murdock: “It’s unfortunate that Twitter didn’t do that.”) Murdock boasted of a meeting between the brothers and the Dalai Lama. “The Dalai Lama seemed to like them a lot,” he said. “Then I introduced them to Richard Branson.”
The excitement that some people say they get from being with the Libermans can sound like other people’s episodes with psychedelic drugs. “There’s this blending of contrasting qualities—abstract global-transformation thinking combined with getting in there and debugging code,” Ken Caldeira, a leading climate scientist in whose guesthouse the Libermans once lived for several months, told me. The brothers’ specialty is reframing problems on a large scale by poring over minutiae, often with a turn of nerdy showmanship. (A characteristic post on their Instagram feed starts with a photograph of a shirtless Daniil and proceeds to ruminations on the second law of thermodynamics.) Born to two Soviet scientists, they wryly describe being “experimented on” during their youth, and at least one experiment—enrollment in the same grade, despite their age difference—had lasting effects. Today, the brothers answer messages, phone calls, and Zoom invites as a single entity, and haven’t been apart for more than some twenty days, then only because of a passport snafu. “We realized we are sort of a superhuman when we’re together,” Daniil said. At home, the brothers share a single king-size bed.
“In Russian, you can construct the phrase ‘thinking against’ someone else,” Daniil told me on the way to the Sheep Meadow, as I raced to keep up with them. “Or maybe it’s ‘by means of’?”
“That’s definitely been our personal life experience,” David said.
Like many people in technology, the Libermans also have personal life experience drawing financial success from a long series of failures. Their first major venture, in Moscow, was an online multiplayer video-game startup that crashed hard in the financial collapse of 2009. Chased by angry investors, they bid on a contract to animate an irreverent weekly sketch show called “Mult Lichnosti” (literally, “Cartoon Personalities”—in Russian, a pun on the phrase “personality cult”). The brothers, working with their two sisters, Anna and Maria, came up with a way of breaking down the animation workflow into tiny bits to animate half an hour of TV in just a few days. The show’s timely satire, often skewering the Kremlin, became an emblem of the loosening Medvedev years.
When it was cancelled, in 2012, at the outset of the second Putin Presidency, the brothers turned their sights to Hollywood, boarding a flight from Moscow to LAX every few weeks and scheduling back-to-back meetings. “We were meeting writers, meeting celebrities,” Daniil said. It didn’t last. “Nobody knew what to do with them,” said Josh Lieb, who, in an interlude between working as an executive producer on “The Daily Show with Jon Stewart” and the showrunner of “The Tonight Show Starring Jimmy Fallon,” teamed up with the Liberman brothers to work on animated shorts, a couple of pilots, and sketches drawn from the comic “Achewood,” none of which went anywhere. (Lieb later got them a brief gig consulting on “Silicon Valley.”) In 2014, tired of dead ends, the brothers left L.A. for the techie Bay Area.
There the Libermans launched a platform to help nonprofits be more transparent in their financials. That product flopped. They tried again with an augmented-reality startup, Kernel AR, that superimposed animated images on real-time video, and this one hit. In October, 2016, Kernel AR was acquired by Snap, which runs Snapchat. The company brought on the four Liberman siblings as product developers and created comparable technology as the basis for Snapchat’s 3-D Bitmoji, which lets users move cartoon avatars through the camera world, like a real-time Roger Rabbit. By 2018, more than half of users in the thirteen-to-thirty-four-year-old demographic were engaging with augmented-reality lenses such as 3-D Bitmoji each week, and the Libermans led a team in the company’s L.A. headquarters, receiving compensation partly in Snap shares.
That year, Snapchat inexplicably began losing users. The price of Snap stock, which, in 2017, had gone public at twenty-four dollars a share, fell below six, and the Libermans watched their compensation shrivel. Inside the company, teams were dispatched to try to figure out what had gone wrong. The Liberman siblings had access to the same data as every other team, but they took an unusual tack, considering the timing of user loss and putting everything at the feet of a major rewrite of the Snapchat app for Android, which was running like molasses. The app was streamlined, Snapchat’s user base began to climb again, and by the time the Libermans had all left, in the spring of 2021, the company’s stock was trading at approximately sixty dollars. In the eyes of some people, their insight turned the company around. “That was the game changer for Snapchat, to reaccelerate growth and success,” Murdock, an investor, said. “And it came from the Libermans’ ideas.”",1
190,"Skip to content
GitLab
About GitLab
GitLab: the DevOps platform
Explore GitLab
Install GitLab
How GitLab compares
Get started
GitLab docs
GitLab Learn
Pricing
Talk to an expert
/
Help
What's new
7
Help
Support
Community forum
Keyboard shortcuts
?
Submit feedback
Contribute to GitLab
Switch to GitLab Next
Projects
Groups
Snippets
Sign up now
Login
Sign in / Register
Toggle navigation
Menu
Open sidebar
traff
T
traff
Group ID: 3505349
Traffic Feed Format, a generic data format for live road traffic updates
Read more",8
191,"More ways to drive sustainably and save money with Google Maps
Imagine you’re planning a day trip from your home in Athlone, Ireland over to Limerick – over an hour and a half journey. To decide how to get there, you open Google Maps — which offers multiple navigation options including walking, cycling and public transit directions. Given the length of the trip, it makes the most sense to drive, and you immediately search for the fastest route.
But what if there were other options: A route that would take nine minutes more, but would save nearly 30% of your expected fuel consumption?
Now rolling out: Eco-friendly routing across Europe
This is now possible thanks to eco-friendly routing in Google Maps, which starts rolling out in nearly 40 countries across Europe today. With eco-friendly routing, you can choose a route that’s optimized for lower fuel consumption, which helps you save money on fuel and reduce carbon emissions — something that’s top of mind for many Europeans. And this is a real concern - according to Statista’s 2022 report, road transportation is the largest source of carbon emissions throughout Europe.
Now, in addition to showing the fastest route, Google Maps will also display the one that's most fuel efficient, if it doesn’t happen to also be the fastest. With just a few taps, you can see the relative fuel savings and time difference between the two routes and choose the one that works best for you. Always want to choose the fastest route, no matter what? That’s okay too — simply adjust your preferences in Settings.
Eco-friendly routing is making an impact around the world. Since launching in the U.S. and Canada, it’s already estimated to have helped remove more than half a million metric tons of carbon emissions — equivalent to taking 100,000 fuel-based cars off the road. We also recently rolled out the feature in Germany.
With eco-friendly routing, Google Maps will show you both the fastest route and the one that’s most fuel-efficient — so you can choose whichever one works best for you.
Get the most fuel-efficient route based on engine type
The most fuel-efficient route will vary based on what type of engine you have. For example, diesel engines are usually more efficient at higher speeds than petrol or gas engines, while hybrid and electric vehicles perform better in stop-and-go traffic. That’s why, in the coming weeks, we’ll make it possible for drivers using eco-friendly routing in Europe, the U.S. and Canada to select their engine type — petrol or gas, diesel, hybrid or electric vehicle (EV) — in order to get the best route and most accurate fuel or energy efficiency estimates.
This technology is made possible thanks to insights from the U.S. Department of Energy’s National Renewable Energy Laboratory (NREL) and data from the European Environment Agency. By pairing this information with Google Maps driving trends, we were able to develop advanced machine learning models trained on the most popular engine types in a given region.
In the coming weeks, we’ll make it possible for drivers using eco-friendly routing in Europe, the U.S. and Canada to select their car type — petrol or gas, diesel, hybrid or electric vehicle (EV).
Helping you make sustainable choices with Google Maps and beyond
Whether you’re staying local or traveling, Google can help you get where you need to go more sustainably with a few helpful tips:
- It’s electric! If you have an electric vehicle, just search for “EV charging station” on Google Maps to see charging stations nearby, along with helpful details, like port types and charging speeds. And for some stations, you can even see if a charger is available right now, helping you avoid the wait and save valuable time.
- Swap four wheels for two. Often, the most sustainable choice doesn't involve a car at all, and Google Maps can help you with alternate ways to get around. We recently announced more cycling route information, including a more detailed breakdown of your route and whether you’ll encounter heavy car traffic, stairs or steep hills on the way. And you can find nearby bike and scooter shares in over 500 cities around the world including Barcelona, Berlin, London, Paris, and Rome.
- Walking the walk. Google Maps offers turn-by-turn directions for pedestrians. To ensure you’re not walking the wrong way, Live View uses augmented reality to display arrows and directions clearly overlaid on the map. Plus, you can preview your walking route with Street View.
- Navigate public transport with ease. By tapping on the transit icon in Directions, you get directions to your destination by bus, train, subway and even ferry. When available, you can see real time arrival and departure times, transfers, and service delays. And Google Maps gives you all the information you need to be prepared, like how crowded your ride will be, what the temperature is like, and if there are wheelchair-accessible routes available.
- Sleep more sustainably. Google Search helps you find hotels that have made significant commitments to green practices. Hotels that are certified for meeting high standards of sustainability from certain independent organizations, like Green Key or EarthCheck, will have an eco-certified badge next to their name. This helps you understand their eco-friendly practices, from waste reduction to energy efficiency to water conservation measures.
All this is part of our commitment to empower 1 billion people through Google products by the end of the year - by making the sustainable choice an easier choice.",5
192,"Four more people died that night. In the morning the sun again rose like the blazing furnace of heat it was, blasting the rooftop and its sad cargo of wrapped bodies. Every rooftop and, looking down at the town, every sidewalk was now a morgue. The town was a morgue, and it was as hot as ever, maybe hotter. The thermometer now said 42 degrees, humidity 60 percent.
—Kim Stanley Robinson, from The Ministry for the Future
The first chapter of Kim Stanley Robinson’s The Ministry for the Future takes my breath away. Not just because I can almost feel the heat and humidity dripping off the pages, but because I know that—although the story is fictional—similar scenes are already playing out in real life.
This April, in the northern Indian state of Uttar Pradesh, the temperature shot up to 45.9 degrees Celsius, or 114.6 degrees Fahrenheit, during a prolonged heat wave that wilted crops and killed at least 100 people (a likely undercount). While spring heat waves are not uncommon in parts of India, according to the country’s Ministry of Earth Sciences they are happening more frequently. Twelve of the country’s 15 hottest years on record have occurred since 2006. A June 2015 heat wave killed over 2,000 people. It’s perhaps no coincidence that The Ministry for the Future begins in Uttar Pradesh. Is truth stranger than fiction?
Heat is the silent killer. It doesn’t roar like the winds in a hurricane or tear roofs off homes like a tornado. But it is deadly, all the same. In the United States, heat kills more people than any other weather hazard. As global warming drives average temperatures higher, dangerously hot episodes can be expected to proliferate. It is extremely unlikely that temperatures could have reached their deadly-hot levels in India without manmade global warming—levels that researchers say were made 30 times more likely by the climate crisis.
Some 70,000 dead across Europe in a 2003 heat wave. Up to 56,000 in Russia in 2010. North America’s most memorable heat waves in recent years include one in greater Chicago in 1995 that killed at least 700 people, and a “heat dome” event last year that killed hundreds in the Pacific Northwest and British Columbia.
37%
Percentage of heat-related deaths attributable to global warming since 1991
Heat-related deaths are up across all continents over the last three decades. Since 1991, research published in Nature Climate Change found that approximately 37 percent of those can be attributed to manmade global warming. In the United States alone, hotter temperatures could lead to 110,000 premature deaths per year by the end of the century if warming continues unabated, a Geohealth study asserts.
Which is why the most popular measure of heat stress on the human body—the heat index—is being reevaluated for the hotter Anthropocene.
37%
Percentage of heat-related deaths attributable to global warming since 1991
Off the charts. The heat index is “what the temperature feels like to the human body when relative humidity is combined with air temperature,” according to the National Weather Service. Bodies perspire to cool off, but sweat doesn’t evaporate as easily when the air is full of moisture, so a combination of high temperature and high humidity keeps the body from properly regulating itself. For example, if the air temperature is 98 degrees Fahrenheit and the relative humidity is 70 percent, it feels like it’s 134 degrees Fahrenheit.
The legacy heat index table stops at values at which the body can no longer cool itself by sweating. This can happen when either the air becomes supersaturated, or the skin does. But sweat can also drip off the body. If that is taken into account, scientists can extend the heat index beyond its current limits, which will be useful for estimating regional health outcomes on a warmer planet.
Hotter and more humid conditions are already here and with no immediate end in sight to rapid climate change, temperatures by the end of this century could average 8 degrees Fahrenheit above what they were at the beginning of it. That would push the range of the highest heat index values beyond what the scale allows for today and into the truly unsurvivable range.
The same 46-degree Celsius reading observed in Uttar Pradesh this spring, accompanied by a relative humidity value of 50 percent, would yield a whopping 82 degrees Celsius or 180 degrees Fahrenheit feels-like temperature in the new “extended heat index” table. According to the authors of the UC Berkeley paper that proposed the augmented heat index, at these levels “it is impossible to maintain a healthy core temperature.” Those kinds of calamitous days are expected to increase, especially in large metropolitan areas.
Heat islands. When you think of extreme heat, you might think of a desert. But there is a worse place to be stuck during a heat wave: a city. Cities generate excess heat, a process called the urban heat island effect. Contributing factors include excess warmth generated by car engines, air conditioners and other equipment, as well as the lack of evaporative cooling from rainfall runoff that is removed by design as quickly as possible from the urban core. Consequently, city temperatures can run 15 to 20 degrees Fahrenheit hotter than neighboring rural areas. New Orleans, Newark, New York, and Houston are all cities with especially large heat island effects.
Lack of vegetation compounds the problem for residents of hotter cities, exacerbating existing inequalities. “The heat islands in the city—the places where it gets really hot because there are no trees—are disproportionately concentrated in poor neighborhoods. And that leads to, along with a host of other factors, really negative health outcomes,” says Mario Alejandro Ariza, author of Disposable City: Miami’s Future on the Shores of Climate Catastrophe.
Trees not only provide shade, but can also cool areas by nearly 2 degrees Fahrenheit through the process of transpiration. Wealthier neighborhoods are often leafier than poor neighborhoods, and a dearth of trees in cities and suburbs can be linked to historically racist practices like redlining. In most cities in the United States, the disparity is shocking.
For example, in greater Miami, Florida, wealthy enclaves like Pinecrest have seven times the tree canopy of blue-collar municipalities like Hialeah. Consequently, surfaces in Hialeah average 14 degrees hotter than those in Pinecrest in the middle of the day.
15-20°F
How much hotter cities often are than nearby rural areas
In response to this growing crisis, cities are racing to tackle the challenge of rapidly rising temperatures. Miami-Dade County, Florida—with a population of 2.7 million people spread across a large megalopolis—was the first population center to name a Chief Heat Officer last year. Phoenix and Los Angeles followed suit, as well as Athens, Greece, Monterrey, Mexico, and Santiago, Chile.
One of the first things Miami-Dade’s Chief Heat Officer Jane Gilbert proposed was for the National Weather Service in Miami to lower the threshold for the issuance of an official Heat Advisory from 108 degrees Fahrenheit to 105 degrees Fahrenheit. “Most of our heat-related deaths happen at thresholds lower than the 108 threshold, not because it’s a higher risk at the heat index of 105 or 102, but because we just have that many more days at that heat index below 108,” Gilbert says.
Gilbert is talking about chronic high heat, which in addition to putting the elderly and young children at risk, may also threaten outdoor workers and people taking certain prescription or illicit drugs. High heat—or a “feels like” temperature of 105-degrees Fahrenheit, which has historically been observed in Miami-Dade approximately seven days a year, may be experienced nearly three months a year in the not-so-distant future.
81
Additional annual days of high heat (""feels like"" temperatures over 105°F) forecasted for Miami-Dade county by midcentury
Between 2015 and 2019 there were 85 times more heat-exacerbated fatalities in Miami-Dade than were recorded on death certificates, according to a study commissioned in part by the county. It’s hard to fathom how many more will die when heat indexes reach dangerous levels on nearly 90 days a year.
Yes, air conditioners are nearly ubiquitous in South Florida. But the unhoused and the air conditioning insecure—anyone who must choose between putting food on the table and paying the electric bill—are still exposed to high heat index values. In prolonged power outages, like those brought on by hurricanes, the heat danger extends to everyone. Twelve nursing home patients died in a suburb of Fort Lauderdale during the blackout after Hurricane Irma in 2017—a small fraction of over 400 nursing home deaths across the state of Florida in the aftermath of that storm.
Awareness of the threats to human health posed by high heat along with timely warnings about imminent heat waves can go a long way in keeping people out of the hospital, or worse. Naming heat waves may prove to help the public personalize and internalize the threat in hot places like Seville, Spain.
81
Additional annual days of high heat (""feels like"" temperatures over 105°F) forecasted for Miami-Dade county by midcentury
7.4 million
Number of lives saved globally if the United States achieves net-zero emissions by 2050.
Moving people to cooling centers—malls, for example—is one of the emergency actions local authorities can take during singular heat wave events. But as longer and longer episodes of elevated temperatures start to morph into chronic high heat, city leaders must find ways to permanently try to counter the rise in temperature driven by global warming.
Shade and transpiration from trees can cool surface temperatures by up to 20 degrees Celsius (36 degrees Fahrenheit) compared to those exposed to the sun. In Miami-Dade County, Jane Gilbert and the Resilient305 Collaborative are looking to increase the urban tree canopy from a paltry 20 percent to a more acceptable (but bare minimum) of 30 percent through, among other things, tree giveaways. The plan is to prioritize areas that currently have the lowest tree canopy.
Cities can also add engineered shade, like bus stop canopies and covered playgrounds. Those shade structures can’t cool surfaces as much as trees, but still can subtract 10 to 15 degrees Celsius (18 to 27 degrees Fahrenheit) compared to unshaded areas. As Gilbert says, “all shade is good.” Spread across hundreds of cities across the United States, these local adaptations will be crucial in saving thousands of lives.
Worldwide, millions that would otherwise succumb to high heat could be saved if countries implemented policies that reduced and stopped the burning of fossil fuels. The United States alone could save 7.4 million souls across the planet if it reached President Biden’s goal of net-zero emissions by 2050, a study by the Climate Impact Lab consortium estimates. This doesn’t even take into account other climate hazards—just heat. Acting on the climate crisis today at the local, national, and international level can keep millions from morbidity and death.
Heat is silent. You don’t have to be.
‘Silent killer’: A series on surviving the extremely hot future
7.4 million
Number of lives saved globally if the United States achieves net-zero emissions by 2050.
As the Russian invasion of Ukraine shows, nuclear threats are real, present, and dangerous
The Bulletin elevates expert voices above the noise. But as an independent, nonprofit media organization, our operations depend on the support of readers like you. Help us continue to deliver quality journalism that holds leaders accountable. Your support of our work at any level is important. In return, we promise our coverage will be understandable, influential, vigilant, solution-oriented, and fair-minded. Together we can make a difference.
Keywords: cities and climate change, climate adaptation, climate crisis, extreme heat, extreme weather, global warming, heat dome, heat wave
Topics: Climate Change, Columnists
Share:
The heat death of humans has never been considered in our future.
The urban heat island effect, why an urban or metropolitan area that is significantly warmer than its surrounding rural areas due to human activities. https://youtu.be/WK5_MxOWKEI
I have two issues with this article
1) The worst case scenario (high emissions no mitigation) is used as a reference. I believe this scenario is no longer valid based on existing emission reductions.
2) Hialeah is further from the ocean than Pinedale. The graphic makes it appear they are next to each other. So it isnt all about trees
I am an engineer and have always looked at data sources with a great deal of skepticism. It served me well. Is the reporter an activist or a neutral reporter of unbiased information?",2
193,"Drought conditions are worsening in the U.S., and that is having an outsized impact on the real estate that houses the internet.
Data centers generate massive amounts of heat through their servers because of the enormous amount of power they use. Water is the cheapest and most common method used to cool the centers.
In just one day, the average data center could use 300,000 gallons of water to cool itself — the same water consumption as 100,000 homes, according to researchers at Virginia Tech who also estimated that one in five data centers draws water from stressed watersheds mostly in the west.
""There is, without a doubt, risk if you're dependent on water,"" said Kyle Myers, vice president of environmental health, safety & sustainability at CyrusOne, which owns and operates over 40 data centers in North America, Europe, and South America. ""These data centers are set up to operate 20 years, so what is it going to look like in 2040 here, right?""
CyrusOne is formerly a REIT, but was purchased this year by investment firms KKR and Global Infrastructure Partners. When the company moved into the drought-stricken Phoenix area, it used a different, albeit more expensive method of cooling.
""That was sort of our 'aha moment.' where we had to make a decision. We changed our design to go to zero consumption water, so that we didn't have that sort of risk,"" said Myers.
Realizing the water risk in New Mexico, Meta, formerly known as Facebook, ran a pilot program on its Los Lunas data center to reduce relative humidity from 20% to 13%, lowering water consumption. It has since implemented this in all of its center.
But Meta's overall water consumption is still rising steadily, with one fifth of that water last year coming from areas deemed to have ""water stress,"" according to its website. It does actively restore water and set a goal last year to restore more water than it consumes by 2030, starting in the west.
Microsoft has also set a goal to be ""water positive"" by 2030.
""The good news is we've been investing for years in ongoing innovation in this space so that fundamentally we can recycle almost all of the water we use in our data centers,"" said Brad Smith, president of Microsoft. ""In places where it rains, like the Pacific Northwest where we're headquartered in Seattle, we collect rain from the roof. In places where it doesn't rain like Arizona, we develop condensation techniques.""
While companies with their own data centers can do that, so-called co-location data centers that lease to multiple clients are increasingly being bought by private equity firms in search of high-growth real estate.
There are currently about 1,800 co-location data centers in the U.S., and that number is growing, as data centers are some of the hottest real estate around, offering big returns to investors. But the risk from drought is only getting worse. Just over half (50.46%) of the nation is in drought conditions, and over 60% of the lower 48 states, according to the latest reading from the U.S. Drought Monitor. That is a 9% increase from just one month ago. Much of the west and Midwest in 'severe' drought.
""We need to innovate our way out of the climate crisis. The better we innovate the cheaper it becomes, and the faster we'll move to reaching these climate goals,"" added Smith.",5
194,"Can you recall any of the plants you saw today?
Probably not. As a species, we are not programmed to recognise and register everything we see within our field of vision. This would be an overwhelming amount of information for our brains to process.
You can however, with a little time and practise, be trained to read the plants around you: to recognise which species they belong to and their names, their relationships with other organisms and what they are telling you about the environment they live in. This is to develop what some call a natural literacy.
Most people suffer from what is commonly known as “plant blindness”, a term coined by US botanists Elisabeth Schussler and James Wandersee. They described it as “the inability to see or notice the plants in one’s own environment”. Unless taught, people don’t tend to see plants – despite the fact that at any given moment, there is likely to be a plant – or something made by plants – nearby.
In our latest study, my fellow researchers and I found that people are not only less aware of plants through a lack of exposure and a loss of knowledge, but demand for an education in botany and opportunities to study it in the UK have diminished too.
The extinction of botanical education
Botany, once a compulsory component of many biology degrees and school programmes, is disappearing fast. It has been over a decade since a student was enrolled in a botany degree in the UK. We believe there has been a gradual erosion of knowledge about plants among biology graduates and the general public as a result.
We examined the number of UK students graduating across a variety of biological science programmes from 2007 to 2019 and found that students studying plant science were outnumbered almost one to 200 by those studying general biology. When we scrutinised the modules offered to students on plant science courses at UK universities, we were surprised to find that only 14% focused solely on plants. Only 1% of modules in plant science and biological science programmes offered any form of training in identifying plant species.
Students are not introduced to the diversity of plant forms and functions at UK universities and are certainly not engaged with how fascinating and dynamic the floral world is. The result is a growing skills gap, with a looming shortage of professionals capable of effectively managing environmental projects. Well-meaning but careless management is not just ineffective, it can add to environmental degradation.
For example, planting thirsty species of tree in the name of capturing carbon from the air can deprive precious bog plants of much needed water. Recklessly cutting and strimming grasslands can wipe out populations of rare orchids.
Harnessed properly, there is no doubt that plants and the services they provide can help solve looming climate and ecological crises. Restoring flood meadows and riverside habitats can reduce flooding from the extreme downpours which are likely to become more common in some areas as the Earth warms.
Less teaching about plants and the ensuing disconnection from the natural world will, if not reversed, have irreparable and disastrous consequences. How many generations of botanists remain before we no longer have the expertise to understand when ecosystems are on the brink of irreparable loss and damage?
The Scottish government has highlighted the lack of a skilled workforce to implement nature-based solutions and argues that “nature literacy” must become a core skill for various professionals, from planners, engineers, architects and educators to farmers, foresters and fishers.
The problem is vast. Various other studies have documented falling plant literacy worldwide. While other studies have identified that plant content is often neglected in textbooks and students who are unable to recognise even local plant species. Our study revealed that the UK curriculum neglects plant ecology and how to identify species, with most of this education taking place at a rudimentary level in primary schools.
Reversing the decline in plant knowledge
Reviving botanical education is possible by presenting students and the public with evidence of how plants can combat the challenges of the 21st century. An invested and knowledgeable public is one well-equipped to demand environmental policy reform.
Botanists can support this ambition, but ultimately, change needs to come from those who decide policy. This is why botanists must agitate to bring botany back into the classroom and beyond.
One thing we couldn’t fully convey in our paper is just how fascinating and exciting the plant kingdom is. In my experience as an educator, there is no student who cannot be reached. Stories about plants are woven into every society’s history, politics and culture. Plants are relevant to every person on the planet – most just don’t know it yet.",2
195,"Revivalism
Overwhelmed by technology and complexity, people seek out nostalgic experiences that remind them of a simpler and more trustworthy time.
About This Trend:
Above all, the Revivalism megatrend describes our widespread desire to revert to simpler times as a coping mechanism for our increasingly fast-moving world. Fueled by nostalgia and our penchant for romanticizing the past, we seek artisanal products, more basic technologies, and historic brands that stood the test of time. In short, we are looking for cultural reminders of that simpler time in a bid to recreate it for ourselves in the present.
Although we gravitate to the past and physical things from it, the irony is that we are using technology to preserve those very artifacts before they disappear entirely. The Revivalism megatrend is as much about reviving the past as it is about preserving it.",4
196,"A good internet connection is just as important as water and power to your home. Some remote users may choose Starlink, others may prefer a 5G option. But what if you have no viable options?
Akamai network architect, Jared Mauch, was so frustrated with the mainstream ISP offerings at his rural home in Michigan that he set up his own FTTH (Fiber To The Home) ISP. It has been such a resounding success that other rural folks have joined up with Washtenaw Fiber Properties LLC for their internet provider. Moreover, Mauch has now qualified for $2.6 million in government funding and will be able to reach nearly 600 further homes in the sparsely populated Washtenaw county area, reports Ars Technica.
Mauch was spurred to set up his own ISP after miserable commercial offerings of internet connectivity to his rural home. AT&T offered DSL with 1.5Mbps downloads, and Comcast wanted a $50,000 upfront payment to extend its cable network to his property. With his networking expertise, Mauch decided on a third path – to set up his own FTTH ISP.
Washtenaw Fiber Properties LLC started with one customer, Mauch himself, but when word got around it grew quickly to 30, and there are currently 70 service subscribers. The fiber network currently relies on about 14 miles of fiber, but to complete the new government-funded project, Mauch will be laying a further 38 miles of fiber.
With the new fiber in place, it is estimated that Washtenaw Fiber Properties LLC will be able to cater to nearly 600 widely dispersed rural customers. Two of the most remote properties in the government contract will each eat up $30,000 of the funding cash, to run the cables and provide service. The cash comes as part of the county’s $71 million dedicated to infrastructure projects, which was allocated as part of the American Rescue Plan's Coronavirus State and Local Fiscal Recovery Funds.
Expanding the Washtenaw Fiber Properties LLC network to meet with the government contract obligations isn’t going to be a challenge, according to Mauch. The work needs to be completed by the end of 2026, but Mauch says that it will be half finished before 2022 is over, with the other half complete by the end of 2023.
So, what kinds of broadband packages will new Washtenaw Fiber Properties LLC customers have access to? For $55 per month, Mauch says people can get a 100Mbps symmetrical service with unlimited data. If you want 1Gbps with unlimited data you will have to scratch together $79 a month. A one-off $199 installation fee is charged to all new customers.
Needless to say, I had a lot of questions.
Let's say a proactive land developer decides to run fiber to all the homes in a new suburban neighborhood while they're installing the other utilities. (This is almost universally illegal in the US, but bear with me).
How does that neighborhood bypass the cable monopoly and actually connect to ""the internet""
Jared did something about it. What a guy! Seems that Comcast isn't the monopolist people say they are.
This was a cool and uplifting story to read. Thanks, Mark!
If the project is denser than typical suburbia, with a serious HOA (not just an annoying one, but one that actually maintains common property), it might be run more like an apartment complex. That can be good or bad. Bad would be the typical apartment complex that has an exclusive contract (with a kickback, probably) with a single ISP (also supplying cable and landline phone service), which the residents have no choice about using and little choice of plans. Good would be installing fiber from a suitable head end for the whole development, and having the HOA act as the ISP for the development connecting with multiple providers at the head end, or even direct accessing a wholesale provider like L3. In that last case, the HOA might have to set up a separate ISP business (as this guy did) to take care of the regulatory and financial and liability issues.
There's a strong DIY tradition among techies, and while setting up your own ISP is a bit extreme, it's not completely crazy. Getting the right advice and help, as this guy did, is crucial - and being a network architect in Real Life kind of says he knew what he was doing from the start, and had the connections to get the help.",8
197,"Harvard Business School and other top business programs are reporting steep drops in applications as the hot labor market and the cost of the degrees are keeping would-be M.B.A.s on the job and out of their applicant pools.
At Harvard, widely regarded as the nation’s top business school, M.B.A. applications fell by more than 15%. The Wharton School of the University of Pennsylvania recorded more than a 13% drop. At other elite U.S. programs—including Yale University’s School of Management, as well as the business schools at the University of Chicago and New York University—applications dropped by 10% or more for the class of 2024.
For those who did apply, the numbers were in their favor. Yale drew 3,237 M.B.A. applicants for the class of 2024, down more than 16% from the prior class, said Laurel Grodman, assistant dean for admissions. She cited the competitive labor market and interest in shorter master’s programs as reasons for the drop. With a smaller applicant pool vying for the school’s 347 spots, some students who would have been waitlisted in a higher-demand year got an acceptance letter, she added.
Chicago’s Booth, NYU’s Stern and HBS declined to comment.
M.B.A. applications are often countercyclical, which means that when the job market is good, people stay at work. In economic downturns, workers seek out business school for a safe harbor and a degree that will make them more marketable.
Many young professionals received large pay raises this year, making the cost of taking two years out of their careers to attend less attractive. The sticker price for highly ranked business schools can reach $200,000 or more for a two-year, full-time program, once living costs are added. School recruiters have said they are increasingly competing not against other M.B.A. programs but against job offers and pay raises as they try to persuade students to enroll.
Interest in business degrees is still high from candidates abroad, schools say, with U.S.-based prospective students fueling most of the declines.
“If the job market is hot, you do not want to leave your job to get an M.B.A.,” said Blair Mannix, director of M.B.A. admissions at Wharton, which drew 6,319 applicants for this fall, down from 7,338 last year but still higher than the 5,905 who applied to start in 2019, when business-school applications were falling.
Applications rose sharply in 2020 as the pandemic struck. At the time, schools extended deadlines and waived standardized test requirements to accommodate more students. Last year, applications dwindled at some programs as the booming finance and technology sectors paid up to retain staff, a trend that continued this year, college staff said.
The Massachusetts Institute of Technology’s Sloan School of Management, Northwestern’s Kellogg School of Management, Dartmouth’s Tuck School of Business, the University of Virginia’s Darden School of Business and the University of Michigan’s Ross School of Business also indicated their applicant pools shrunk.
Sloan’s 25% decline to 5,349 applications followed a record year for applications—7,112—last year. A spokesperson characterized this year’s figures as in line with prior years.
Cost was the biggest factor blunting demand, according to a survey of more than 1,500 people who considered applying for an M.B.A. but decided against it. The survey was conducted by Clear Admit, which advises prospective students on applying to business school. More than half—52.6%—said cost was a concern.
“It doesn’t seem as easy to convince this generation of applicants as it used to be,” said Graham Richmond, Clear Admit’s co-founder. “They’re a bit more wary of debt, period, for anything.”
At nearly every university that offers an M.B.A., graduates typically make more money two years out of school than they borrowed. HBS earlier this year started a new need-based scholarship program to cover the full cost of tuition and fees for 10% of its enrolled students. Some other top M.B.A. programs offer need-based scholarships, and many others distribute dollars based on test scores, grades and personal backgrounds.
Other factors dissuading potential M.B.A. candidates in the Clear Admit survey included being too busy at work to apply and the pandemic’s impact on the school experience. Some people also named the potential for promotion at their current jobs.
Most respondents said they plan to apply in the future. Businesses are forecasting tougher economic times ahead, and companies in finance, tech and retail have cut jobs.
“I do think we’ll be seeing them in a couple years,” said Taya Sapp, senior associate director of admissions at Michigan’s Ross.
SHARE YOUR THOUGHTS
What value does an advanced degree have in today’s job market? Join the conversation below.
Tim Westerbeck, president of the higher-education consulting firm Eduvantis, said he is unsure whether applications will increase anew should the economy sour. Nonprofit and for-profit business credentials have proliferated, giving people more options than the two-year M.B.A. These programs are inexpensive, often online and frequently don’t require stepping out of the workforce, he added.
The Graduate Management Admission Council, which surveys admissions offices annually, said that domestic student interest fell among full-time, two-year business schools in the U.S. Interest from international students was higher at many schools, though not enough to offset the decline in applications across the majority of M.B.A. programs.
At the University of North Carolina at Chapel Hill’s Kenan-Flagler Business School, one of few top-20 M.B.A. programs to see an increase in applicants, the rise in international applications eclipsed the decline in U.S. interest.
People from India, Nigeria and Kenya showed particular interest, according to Danielle Richie, the school’s director of full-time M.B.A. admissions. The incoming class of 242 students comprises 35% of international students, compared with 26% last year.
Write to Lindsay Ellis at lindsay.ellis@wsj.com
Copyright ©2022 Dow Jones & Company, Inc. All Rights Reserved. 87990cbe856818d5eddac44c7b1cdeb8",4
198,"AI will replace middle management before robots replace hourly workers
Artificial Intelligence is now capable of beating the best humans at chess 100% of the time no questions asked. The Roomba in the corner of my room still gets stuck on things and runs out of power. Which of these two technologies do you think will impact corporate America the most; robots that must be built by robots to perform a specific task once done by a person, or a program capable of making the best possible business decision given historic and currently available data?
If you said the latter you're correct. The ""robot revolution"" is not coming first; the AI decision making paradigm shift will and it is going to save corporations billions of dollars in salary costs per year as middle management disappears.
Legacy businesses will have to rely on retail and hourly support staff to be able to reduce management head count as a means of freeing up money for implementing automation. In order to do that, they will need to implement AI management tools; chat bots, scheduling, negotiating, training, data collection, diagnostic analysis, etc., before hand.
Otherwise, they will be left to rely on an overly bureaucratic and entrenched middle management layer to do so and that solution is likely to come from outsourcing or consultants. All the while, the retail environment deteriorates as workers are tasked to replace themselves without any additional benefits; service declines, implementation falters, costs go up, more consulting required.
Union formation across the retail landscape will force corporations to reduce management head count and implement AI management solutions which focus on labor relations. The once fungible and disposable retail worker will be transformed into a highly sought after professional who will be relied upon specifically for automation implementation.
The vast majority of these large corporations have cash flow problems and are overly leveraged which means they can't simply buy their way out anymore. Retail workers in these stores have the power to force their hand and negotiate for higher wages while they do it. Wages these corporations should be glad to pay. The transient nature of the work won't be a deterrent but a motivating factor as retail workers vie for top dollar positions in once derided slacker roles.
AI managers are the missing link between the when and how of implementing retail level automation. Reducing middle management, freeing up cash flow, incentivizing hourly workers and implementing automations will all depend on the fecundity and vision of senior leadership. Or maybe just which blogs they decide to read.",3
199,"Japan’s faltering campaign to raise its birthrate has gone analogue, with authorities in a south-western city encouraging potential suitors to put pen to paper and wait patiently for a reply rather than simply swiping right.
The city of Miyazaki says hundreds of men and women have dabbled in old-fashioned letter writing since the matchmaking scheme was launched two years ago. While there have been no wedding bells, the programme has spawned 32 face-to-face meetings and brought together 17 couples.
About 450 people have signed up so far – more than double the city’s initial estimate – with about 70% in their 20s or 30s.
“It takes longer [than online dating], and inspires you to imagine the person you’re in communication with,” Rie Miyata, the head of a local consulting firm commissioned to run the scheme, told Agence France-Presse.
“It’s less about how good your penmanship is and more the fact that you write every single character sincerely and with care, thinking deeply about the person you’re writing to. That’s what makes letters so powerful.”
Applicants are screened and paired based on information such as their taste in books and films. To encourage participants to base their decision on the other correspondent’s personality, profile photos are forbidden.
People who have been paired can send and receive up to five letters without divulging their name or address, according to the Mainichi Shimbun. If they wish to meet, the consulting firm provides them with the contact details. After that they are left to their own devices, the newspaper said.
The letter scheme is one of a number of attempts to encourage Japan’s singletons to meet and, perhaps, marry and start families, as the country battles a low birthrate and shrinking population.
The government has started funding artificial intelligence matchmaking schemes, and in 2018 single men from the mountain village of Otari produced a calendar showing them at work in the hope of finding love and companionship.
The number of babies born in Japan sank to a record low of 811,604 last year – a statistic that the prime minister, Fumio Kishida, on Tuesday described as “shocking”. Japanese women are now expected to have an average of 1.3 children, far below the rate needed to maintain the population at current levels.
Mirroring social trends in other developed economies, more people are choosing to marry later or not at all. A recent government survey found that one in four single people in their 30s said they had no desire to tie the knot, with many saying they feared married life would be too expensive and infringe on their freedom.
But a 25-year-old man taking part in the Miyazaki matchmaking scheme said the idea had brought back fond memories of his school days. “As a kid I used to write letters to the girl I had a crush on,” he said. “I like how old-fashioned letters are. That made me want to join.”",4
200,"The former COO of disgraced blood testing startup Theranos, Ramesh “Sunny” Balwani was sentenced to 155 months, or about 13 years, in prison, and three years of probation. After a three-month trial, Balwani was found guilty on all 12 criminal charges, ranging from defrauding patients and investors to conspiring to commit fraud. Theranos CEO Elizabeth Holmes was convicted on four of these charges and was sentenced to 11.25 years in prison last month.
Despite the disparate outcomes from the two separate juries in two individual trials, Judge Ed Davila calculated Holmes’ and Balwani’s sentencing ranges to be exactly the same: 135 to 168 months, or 11.25 to 14 years. In both cases, prosecutor Jeff Schenk countered by asking for 15 years.
Balwani’s lawyers attempted to argue that he should get a more lenient sentence than Holmes, as he was not CEO.
“He’s not Ms. Holmes. He did not pursue fame and fortune,” said Balwani’s attorney Jeffrey Coopersmith.
Judge Davila even noted that the court saw another side of Balwani when they were told about his charitable giving, some of which occurred after Theranos. Yet Balwani still received a severe sentence of 13 years.
Holmes and Balwani were supposed to be tried for fraud together, but the former CEO filed for a separate trial, stating that Balwani, who is 20 years her senior, had emotionally and sexually abused her during their long romantic relationship. Though the court was not ruling on those allegations, the judge granted the request.
Throughout the trial, Balwani’s lawyers attempted to make the case that even though he was an investor and executive at Theranos, he was not involved in key decision-making. The defense failed to argue for his innocence, though. In one piece of evidence, the jury was presented a text from Balwani to Holmes that read, “I am responsible for everything at Theranos.”
Balwani’s trial featured the same evidence that indicted Holmes. The prosecution focused on a key piece of evidence relating to Theranos’ relationship with Walgreens. The biotech startup’s faulty technology made its way into 41 Walgreens stores, but unbeknownst to the pharmacy giant, most of the tests were conducted on third-party equipment. Theranos’ own machines couldn’t produce accurate test results, so a lot of patients had blood drawn not with a finger prick but intravenously. So, Walgreens basically spent $140 million in its partnership with Theranos, only for the startup to use the same old tech that was already in use.
Despite claims to the contrary, a Walgreens executive testified that he worked closely with Balwani on the deal. The prosecution also displayed evidence of a text from Balwani to Holmes stating that he deliberately didn’t tell Walgreens that they were using different machines.
For patients that were unlucky enough to have their blood tested with Theranos’ technology, some got wildly inaccurate results that caused significant disruption to their lives. In one case, a mother with a history of miscarriages was wrongly informed that she would have another unsuccessful pregnancy. Another patient, Erin Tompkins, used Theranos for its low costs, got flagged as HIV-positive, and then lived in limbo for three months until she could afford a second blood test. As it turned out, she didn’t actually have HIV. Meanwhile, a patient named Mehrl Ellsworth was given a false cancer diagnosis.
Unlike the jury at Holmes’ trial, the jury at Balwani’s trial held him accountable for defrauding patients, not just investors.
Before the former COO’s sentencing hearing, Balwani’s lawyers filed 40 objections to the probation office’s pre-sentence investigation report, according to tweets from Law 360 reporter Dorothy Atkins, who was present at the hearing. Judge Davila, who also presided over Holmes’ trial, said that only four of those objections were substantive.
“Usually sentencing hearings are morbid regardless of the crime — like watching a car crash where you watch families and lives being destroyed in real time,” Atkins tweeted from the court room. “This one feels more like an accounting class.”
It would certainly not be unprecedented if Balwani decides to appeal this ruling. After Holmes’ own sentencing, the former Theranos CEO told a California federal judge that she would appeal her conviction. She then asked to stay out of custody while her appeal is under consideration, also citing that she is currently pregnant with her second child. As it stands, Holmes’ surrender date is April 27, while Balwani will report to prison on March 15.",4
201,"Redefining MVPs: A faster way to derisk new product ideas
MVPs have given countless founders and product teams a free ticket to jump straight into building overscoped products that aren’t designed to learn anything from.
Having personally built a bunch of terrible MVPs over the years and watched hundreds of other founders follow the same path to failure, I think it’s about time we define what a good MVP actually looks like.
The Curse of Vague Definitions
Eric Ries, author of The Lean Startup, defines an MVP as “that version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort.” This is a pretty crappy definition. Founders don’t need to “collect the maximum amount of learnings about customers” on Day 1 — the need to disprove the biggest risks underpinning their idea in a resource-efficient manner.
A better approach to building an MVP would (1) clarify what founders need to understand about customers before building anything, (2) help founders identify the minimum amount of product that would need to be built to validate their idea, and (3) very specifically outline what features should be excluded entirely from the MVP. And that’s exactly what you’re going to get in this essay.
What to do before you start building an MVP
Your first product idea is likely very flawed in many ways. If you’ve got time and money to burn, you can of course uncover these flaws by just building your product to figure out what you got wrong. But most people don’t have that luxury, so they focus on answering these three questions before writing their first line of code:
1. Persona → Who are you building this product for? If you try to build a product for multiple different types of customers, then you’re gonna end up with something that isn’t really perfect for any of them. Instead, the best founders focus on building the perfect solution for one specific customer segment and then later scaling to other segments.
2. Problem → What high-priority problem do you solve for that customer? The best products solve a specific high-priority problem for a specific customer segment. When a customer has a high-priority problem, they proactively search for solutions. Founders that solve a ‘mild inconvenience’ end up begging target customers to consider their product. Choose your problem wisely.
3. Proposition → What value do customers get by solving this problem? This is the most often overlooked ingredient. Before you build your product, you need to understand how the customer’s life will be better once this problem has been solved. Otherwise, you don’t know the destination your customers are expecting to arrive at.
What to include in your MVP
The answers to those three questions are the ingredients that inform the most important decision for a pre-product founder:
4. Product → What is the unique thing your product does to solve this problem and deliver this value in a way that is more useful or valuable than any other solution currently available? The answer to this question is your Unique Product Attribute — the only part of your product that truly needs to be innovative.
Your Unique Product Attribute is the big risk at the heart of your entire startup. If you can nail it, you’ve got a great shot of winning the entire market opportunity. If you fail to build it, you fail overall. The goal of building an MVP is to prove that you can deliver Unique Product Attributes that are useable, valuable, feasible, and viable.
What to exclude from your MVP
To improve on the current definition, we also need to define what shouldn’t go into your MVP. To do that, you need to answer one last question:
5. Positioning → Where are customers looking for your solution? Your target customers don’t share your depth of knowledge on the range of available solutions. Instead, they think of the market in categories — there are email tools, survey tools, CRMs, etc. You need to know what category customers are looking for a solution for their problem because that’s how you’re going to describe your product.
But this is more important than just product positioning. Whatever category your product falls into determines the core functionality that customers expect your product to have. For an early-stage product, I call these ‘Hygiene Features’ —without them, your customers are likely gonna have to pick your competitors over your product.
Right now, though, that doesn’t matter to you! You’re on Day 0 — you don’t need to think about stealing customers away from competitors just yet. Your focus right now is to derisk your idea by validating whether your core innovation solves a high-priority problem and delivers the expected value for a specific customer segment in a uniquely useful/valuable way.
So, although you’ll struggle to build commercial traction without including these hygiene features, you shouldn’t waste any time adding them to your MVP. Instead, you want to use your MVP to figure out what customers determine to be the most important hygiene features for your product category.
Watching people use your MVP (which at this stage is only the Unique Product Attributes) will uncover customers’ basic feature expectations. It’s worth noting that you won’t be trying to collect for feature ideas — you’re looking out for questions like “Why can’t I update this profile attribute?” or “I can’t find where I search for stuff?” that hint at usability dead-ends.
If you’ve solved a truly high-priority customer problem, you often don’t even need many Hygiene Features to attract your first customers. Once people have reached a certain level of desperation, they’ll happily duct-tape their way around the rough edges of your early-stage product if it solves helps them solve a hair-on-fire problem.
The difference between Unique Product Attributes and Hygiene Features
We draw a clear differentiation between Unique Product Attributes and Hygiene Features due to the difference in risk involved.
Hygiene Features are solved problems. People have already put years of work into building the most optimal version possible of the ‘Forgot Password’ flow, so just copy what works best. But don’t actually bother copying it just yet. If your startup is destined to fail, it won’t be because of your ‘Forgot Password’ flow — it will be the discovery that your Unique Product Attributes are not useable, valuable, feasible or viable (’The Four Big Risks’). So, rather than waste time iterating your sign-up flow to perfection when you haven’t even tested your idea’s core assumptions, focus on “tackling the big risks early” instead.
An actionable, research-led MVP definition
The best Minimum Viable Products are experiments that test whether a set of Unique Product Attributes can successfully solve a high-priority problem and deliver the value expected by a specific customer segment in the most resource-efficient manner possible.
Resources to help you put this essay into practice
i. If you don’t agree that the first step is to pick just one target customer segment, then you should read this deconstruction of WeatherBill’s $930M pivot. Betting on one customer segment was the key decision that turned their failing startup into a billion-dollar exit in just 3 years.
ii. If you’re not sure how to validate whether a problem is high-priority or not, you should read The Discovery Sandwich. It’s a simple three-part framework that uses breadth interviews, Customer Problem Stack Ranking, and in-depth interviews to identify and understand your target customer’s hair-on-fire problems.
iii. Figuring out the answer to the Product Positioning question (#5 in this essay) is harder than it looks. The best resource for this job is April Dunford’s book ‘Obviously Awesome’ — an actionable and concise read.
If you enjoyed this essay, consider sharing it with friends that would find it useful. You can find more ideas like this post in my newsletter, The Full-Stack Researcher:",2
202,"In this series, I'm going to work through my thought process about Open Source businesses and walk you through the steps I followed while building LunaSec. In comparison to traditional business models, Open Source businesses can be non-trivial, non-obvious, and daunting to undertake.
My goal is to help teach others about Open Source businesses by helping you understand the steps involved, the tradeoffs you make by choosing Open Source, and by overall giving you an intuition to help evaluate if Open Source is the right approach for your business.
The series will be split up into a series of different posts, each one focusing on a different part of the process involved with building and launching an Open Source business. In this post, I'll be explaining the evolution of software pricing models, the pros/cones of each, and relating them back to Open Source.
I hope this article helps you kickstart your efforts of launching your Open Source business. At the end of this series, I will also be sharing with you how to best position your business to raise Angel & VC funding based on our experience raising a Seed round.
Part 1: Software Pricing Models
The world of software licensing is evolving.
Over the years, the software industry has evolved and the simple distribution models of yesterday have evolved along with it. Gone are the days of simple brick-and-mortar software purchases, instead having been replaced by more complex pricing models like by-the-hour cloud-based software, per-seat subscriptions, and custom ""Enterprise"" contracts.
Open Source represents one of the modern shifts in software pricing by bringing a more flexible, more adaptable approach to address the complexity of modern software development practices. It's not all rainbows and unicorns though. There are real tradeoffs to be aware of when choosing to use Open Source for a business.
To help understand the tradeoffs, I will be breaking down the pricing models into a few categories:
- Brick-and-Mortar: The traditional approach to software development, where you purchase a license and pay for the software. Old school and rarely used anymore.
- License-Based: A more flexible approach where you buy a license and, optionally, pay for specific features you use. Often combined with the Shareware and Freemium distribution models.
- Custom/Enterprise: A top-down sales model for software that requires the one-off negotiation of a custom contract, involves a lot of upfront or custom work, and that generally involves a long sales cycle to close customers.
- Cloud-Based: The approach to software development where you purchase a license and pay for the software, but also pay for the infrastructure that powers the software. You don't ever manage the software or the infrastructure yourself.
- Open Source: Distributed for free with no licensing or payment required. Software is delivered without any support or maintenance guarantees unless offered by a company (generally the author of the software). For software to be Open Source, it must not be locked to a specific customer, and be able to be modified, improved upon, and resold by anyone with any restrictions.
Below, I will walk through a brief history of the evolution of software pricing from the early days of the software industry to today. It's not a complete history, nor is it 100% accurate, but it's a good starting point to understand the different pricing models and to help build your intuition for developing your own pricing model.
The First Software Companies
Software has changed a lot...
Many years ago, before the internet, when you wanted to start a software business, you followed a simple set of steps:
- You wrote some code and compiled it into a binary,
- You printed it to a physical CD-ROM disk using an expensive machine,
- And then you sold individual copies of it on the shelf at a store or via the mail.
Sales were usually on a fixed-price basis: Your physical copy represented your license to use the software. It wasn't possible to duplicate the software disks without specialized hardware ($1,000+), so piracy wasn't a major concern. Physical possession was a sufficiently difficult challenge to overcome, so companies just sold boxes of software in stores.
A Windows 95 launch event with boxed software being sold.
Because of this, software businesses were simple and closely represented traditional business models. Software purchases happened like they would for physical goods. You bought a hammer just like you bought a copy of Microsoft Word by simply visiting a store and grabbing it off of the shelf.
This approach is simple and easy to understand, but it has a few downsides.
First: It's expensive to scale. You have to pay to build a hammer every time you want to sell one. That means, to sell 10,000 copies of your software, you also have to create, package, and distribute 10,000 copies. That's a non-trivial amount of work.
Second: Piracy started becoming an issue for companies. It was simple for your friend to give you a copy of their software, thereby hurting the company's sales.
Some companies were able to combat this by adding in copy-protection mechanisms (early DRM), but these would eventually be circumvented by skilled individuals. It was an uphill battle for companies to try to overcome this problem.
Third: Customer Support. It's impossible to authorize users that call in for support when you can't verify that the user paid for the software.
As a company, it's expensive to give phone support to a user because it requires a human to be present. You simply couldn't afford to pay for phone support for a user that didn't pay for the software.
The Creation of Software Licenses
Windows XP relied on product keys that were verified over the internet to combat piracy.
Over time, these became problems with the physical ""Brick-and-Mortar"" method of selling software forced a new pricing model to be adopted. This new model is often referred to as the ""Software Licensing"" pricing model.
The idea is still fairly simple: Instead of selling software on the shelf, software companies now started selling codes that allowed you to use the software. Possession of the code was all that a user requires to authorize them as the owner of the software. If a code was shared too many times the code be considered ""stolen"" and the license would be revoked, and companies could leverage the moment to sell copies of the software to any customers calling in without a valid license.
This license-based model, coupled with the advent of the internet, created new ideas for software distribution like Shareware and Freemium. You could download software from the internet, try software for free, and only buy a license if you liked or needed more features.
This didn't get rid of all piracy -- consumers could just use their friend's keys and call in as in their friend -- but it did remove most of the financial burden for them to provide support to pirate. And, as a second order effect, it also made it harder for companies to get away with buying only one copy of the software for all of their employees to use. Now, for any companies purchasing software, they would have to purchase one copy of the software for each employee or for each computer. They could no longer just buy one copy for everybody to use.
Switching to the License-based model also helped to solve the distribution problem: Businesses could install software on computers using a single disk or downloaded copy, and then they could purchase license keys directly from the software company via the phone. No more physical copies of the software had to be produced every time another copy of the software was purchased, and, because physical copies cost money, the software companies benefited from increased software profit margins.
Segmenting Customers by Price
Redis's Pricing Model shows their method of segmenting customers by price.
As companies continued to grow, and relied more heavily on technology, their needs became more complex too. The software companies selling the software had to manage the needs of varying types of customers, ranging from individual sole-proprietors, small businesses, large enterprises, and government agencies.
Their customer's demands were not always the same, and the software companies had to adapt their pricing model accordingly. A blanket policy would no longer suffice. The software companies would simply be leaving too much revenue on the table. Features that were expensive to implement, or that were not commonly used, would be priced higher than features that were more common.
Large Enterprises, for example, would be able to afford to pay for features like custom integrations with their existing software, a faster turnaround time in the event of a software bug, or a more hands-on onboarding and training process. Even if these features required development cycles from an engineer to implement, they would be able to afford to pay the fees for these features.
This divide in different users' needs, coupled with using nearly-free digital software distribution software, lead software companies to become some of the most profitable companies in the world.
Enterprise Software
Oracle is a company notorious for their Enterprise sales model.
Over time, for many industries, software companies would begin exist to fill every niche. Some of these companies would cater on to a small number of very large customers, often referred to as ""Enterprise"" customers. They would create specialized sales teams and onboarding processes that would be tailored to the Enterprise customer's needs. For any companies below a certain size, they would simply be turned away if they were unable to pay the exorbitantly high price.
This posed a problem for smaller companies like startups. They wanted to use the software, but the Enterprise Software companies couldn't justify the expenses of onboarding them or supporting them. It was simply unprofitable to offer support to a small company.
Around the beginning of the internet era, a new company named ""Red Hat"" would be founded. Their solution to this divide -- of wanting to only sell to large customers -- was to publish their software as Open Source. Anybody would be able to use their software, and they would sell custom support, features, and training to the Enterprise customers separately.
Red Hat went on to become a very large player in this space, and is one of the pioneers of building a business around Open Source software.
The Evolution of the Internet
The Cloud companies are some of the most successful companies in the world.
Fast-forward to the start of the internet era, and the needs of software continued to grow increasingly complex. With the scale of internet traffic becoming larger, there became a need for more specialized software to run along with specialized hardware. No longer would a company just purchase the software, but they would also purchase the hardware that is needed to run it. This hardware was often expensive to produce, setup, and maintain, so buyers would often end up renting it from the software companies instead.
The companies who wrote the software, managed the hardware to run it, and sold it together would become known as the ""Cloud"" companies. They would sell their software as an internet service and their customers would be able to use their software on any computer that is connected to the internet. The Cloud companies would often be called ""*-as-a-service"" companies to describe what ""Cloud service"" they sold. Companies selling Cloud Software became ""Software as a Service"" (SaaS) companies. Companies selling access to managed servers, providing the ""Platform"" for others, become known as ""Platform as a Service"" (PaaS) companies.
Modern software licensing became no longer just selling software but also selling hardware, and this led to a new class of software consumption. No longer did it make sense to simply purchase a license for software, but instead you only ""rent"" the software based on your usage of it. When licensing Cloud software you might pay by the hour, pay by the second, or pay per API request. The price of the software license, if any, would be baked into the price you pay.
This model of software licensing has been a powerful tool for simplying the steps required to launch a tech company. Many companies, like Netflix and Snapchat, have used cloud services from their earliest days in order to scale to meet their highly erratic scaling needs. Even with the ""premium"" price of cloud services, it's still worthwhile for them to not ""own"" their own hardware.
Of course, not all companies have dynamicly changing demand that require a flexible pricing model. There are still many companies that don't want to use Cloud services such as those with strict security requirements that require data to be onsite. If a vendor only sells their software as SaaS, they're often forced choose an inferior product that supports ""on-prem"" deployments or to build it themselves.
The Proliferation of Open Source
Do you recognize any of these?
Since the earliest days of computer, there has always been a contingent of software professionals that advocated for Open Source software. Much of the software that is run today dates back to these professionals. Most are small tools, libraries, and scripts, but some are large applications that are used by many people. One of the most successful projects is the GNU/Linux project, which is the Linux operating system.
Systems like Linux power the vast majority of computers in the world. It is the most widely used operating system, and is entirely Open Source. By itself, Linux is not directly sold. It is a community of developers, and the community is willing to contribute to the project to continue building it. Cloud companies, like Amazon and Microsoft, are able to run Linux on their servers and then their customers are able to run any software that runs on Linux against the rented server.
Open Source Goes Enterprise
Red Hat, now a part of IBM, was once the largest contributor to Linux.
By itself, Linux is not a product. It is a language. It is a tool. It is a community. It is a way for companies to build and to run software.
Linux is not unique in this way. Many large Open Source projects have taken on similar roles, with projects such as Nginx, Git, and PostgreSQL growing in popularity until the point where they become a foundation for others to build on top of. This approach flies in the face of the traditional belief held about software. That is, for the majority of software history, there has been an assumption that Source Code is what is valuable and that you must protect your Source Code.
Companies like Red Hat were the early pioneers that began to break this assumption by building a business model around Open Source. They showed that it's possible to be worth billions of dollars, even when you freely give away the software that you create. Projects like Linux were never designed to be commercial projects, but the Open Source work that Red Hat did was designed to make money.
They realized, and subsequently taught the world, that Source Code behind the software was not what was valuable, but that it was instead the deep knowledge possessed by the people that created it. That deep knowledge was necessary to fix bugs in the software quickly, to save time setting up and maintaining the software, and to continue developing the software to make it better over time by identifying the patterns across the many ways the software was used.
This insight, that the ""secret sauce"" was not the Source Code, but instead the knowledge of those that created it, was a powerful tool for the software companies that wielded it. They were able to create a business model that was not only profitable, but that also greatly simplified adoption of the software. Companies leveraging Open Source would be able to distribute their Source Code for free on websites like GitHub, and never have to worry about supporting the usage of the software.
In exchange for giving away their software for free, they would be able to grow the usage of their software more easily by catering their software directly to developers working at companies. These developers would no longer have to deal with a lengthy sales process involving signing NDAs, being given non-editable binary files that they couldn't modify or extend, or getting approval from the Finance department and other stakeholders. When the software was Open Source, they could simply use it more easily than they could other proprietary software.
This was a huge win for Open Source adoption. Companies that used Open Source would be able to build their software more easily and, because of that usage, they would rely on that software. That reliance creates an incentive to pay for help whenever something went wrong or if they needed a feature added.
Where are we now?
You know Open Source is mainstream when even Microsoft wants in...
In 2021, the number of software companies using Open Source is nearly 100%. It's simply too difficult to develop all software in house anymore. At some point, you have to rely on software built by somebody else, and the only way to do that is to rely on Open Source (in some capacity).
Since the days of Red Hat, there have been a number of companies that have been using Open Source to build their business. Companies like MongoDB, HashiCorp, and Elastic proved that Open Source was a viable way to build a business worth billions of dollars. Open Source was no longer a niche belief held by software purists, but it was also a reliable way to acquire customers and grow their mind share.
""Source Available"" Software Licenses
Docker failed to create a viable business model around containerizing applications.
Open Source isn't perfect -- Cloud companies, like Amazon, have been known to exploit Open Source software projects to earn a profit without contributing back either source code or sharing revenue. It's legal and fully within the bounds of Open Source for companies to do this -- that's just the risk of choosing an Open Source software licensing model. You do not have control, and sometimes that hurts your business.
In order to mitigate that risk though, there are a number of approaches that attempt to bridge the gap between the proprietary and Open Source by changing the rules of the license to be less ""free"". These approaches are generally referred to as ""Source Available"" software licenses, and are not considered ""true"" Open Source software by the OSI.
Licenses like BSL are designed to let their software be used as Open Source software would, but with a few additional restrictions to prevent other companies like Amazon from deriving value purely from hosting a managed version the software. Redis, Elastic, and MongoDB are examples of companies that have adopted Source Available licenses in response to competition from Cloud companies.
While it's great to see innovation in the software licensing industry, it's also important to understand that using a Source Available license is not a catch-all solution. You're not actually Open Source when you choose a Source Available license, which will hurt your early adoption at any companies requiring that only a permissive software license like Apache 2.0, MIT, or BSD be used.
Even if you choose to be Open Source or Source Available, you still have to think about how you're going to structure the pricing model for your business to generate revenue. It's not enough to just think ""We're going to be Open Source, grow, and then figure it out later."" Many companies, most notably Docker, have successfully used an Open Source licensing model to achieve traction and explosive growth, but still failed to create profitable business model despite what otherwise seemed like a ""slam dunk"" to investors.
When to use Open Source for your pricing model
Which path do you take?
There is honestly no way to know if Open Source is the right solution for your business's pricing model. You have to think about it, do your own research, and come up with your own conclusion. That's just the unfortunate reality of building a business: There is seldom a one-size-fits-all solution.
Beyond that cautionary note though, I think there are a few places where Open Source really shines:
- Software Infrastructure: If you're building software that's going to be the ""backbone"" of somebody's software stack, you probably want to consider using Open Source or a Source Available license. When you're in the ""critical path"" of somebody's production software, you will win points with developers by being Open Source. Nobody wants to be stuck debugging proprietary software or dealing with an outage because your PaaS is down. If they can self-host it, that's a big win for adoption (even if you end up hosting a PaaS anyway).
- Developer Tooling: If you're building a tool that will be used by developers, you probably want to use Open Source. Developers are a tricky market to sell to because they're often happy to build their own solution instead if something is proprietary (sometimes due to natural curiosity, but also due to debugging requirements for production software). I've run a startup in this industry before, and it taught me some painful lessons. I'll write a post about that soon, if anybody is interested.
- Sensitive Data: I've spoken with enough startups and companies to realize that people are often fearful about trusting others with their sensitive data. It already takes a lot of trust to get somebody to share their data with you, and it takes exponentially more when its sensitive data. If you're building a product that touches sensitive data, you probably want to use Open Source to help earn trust.
- Security or Compliance: These areas are a bit hairier to understand what the right choice is. In general, if you're a security or compliance company, you might want to consider going Open Source. You'll be able to build a more secure product by having people easily vet it, and you'll be able to more easily comply with your customer's compliance requirements by allowing them to self-host it. For HIPAA, for example, it's a lot easier to self-host than to buy a proprietary solution.
- You offer a free-tier: Depending on your business, if you offer a free tier, you might want to consider being Open Source for the functionality in the free tier. With that path, you can still choose to slap on proprietary features for your higher tiers. You might find that certain large customers have different needs, and that their needs are best served by a proprietary solution.
If you don't fall into any of those buckets, then I'll ask you a few questions to help you decide.
- How do you make money?: If you're planning to host the software for your customers, then you probably only want to be Source Available. If you're not hosting the software, then you should consider being Open Source. Even if a Cloud picks up your software and starts hosting it, if you're not losing out on any profits, then does it matter? You might find that you actually gain more value by being available as a Cloud service, so being Open Source is a good choice.
- Is Open Source your only customer acquisition strategy?: If the answer is yes, then you're in for a world of hurt. Open Source is frequently more work than a proprietary solution in order to get your first paying customers. It takes months of effort to polish up your API, set up your CI/CD pipeline, and write enough docs to get people to use it. If you choose Open Source, you should make sure you have other ideas about how you're actually going to drive adoption.
Closing Thoughts
In this post, I've talked about the history of Software Licensing, and I've tried to build up your intuition to determine if Open Source is the right choice for your business's pricing model.
Like I said before, there is no clear answer here. I'd recommend doing your own research on the internet, consulting with other people that have done it before, and reviewing the business models of existing companies that have made Open Source work for them successfully. This space is rapidly evolving, and there is a lot of nuance to it.
I'll be writing more posts in the series soon. Please email me if you found this useful or if you have any questions (free at lunasec dottt io).
And while I have your attention, please throw us a star on GitHub. It really helps us out!
Good luck, and thanks for reading.
Free Wortley, Founder of LunaSec
Credits:
- Photo a computer programmer from the 70s from here
- The happy man with his copy of Windows 95 from NBC News
- Windows XP Screenshot from Blogspot
- Oracle HQ photo from here
- AWS trade show photo from here
- Redis Pricing screenshot from their website
- Open Source logos from Miro's Medium here
- Red Hat HQ photo from BalfourBeattyUs here
- Microsoft buys GitHub image from here
- Photo of sinking container ship from here
- Cool photo of street signs from here",2
203,"975 books — 1,568 voters
Goodreads helps you keep track of books you want to read.
Start by marking “Autonomous” as Want to Read:
Enlarge cover
Open Preview
See a Problem?
We’d love your help. Let us know what’s wrong with this preview of Autonomous by Annalee Newitz.
Not the book you’re looking for?
Preview — Autonomous by Annalee Newitz
Autonomous
by
3.58 · Rating details · 15,154 ratings · 2,174 reviews
Autonomous features a rakish female pharmaceutical pirate named Jack who traverses the world in her own submarine. A notorious anti-patent scientist who has styled herself as a Robin Hood heroine fighting to bring cheap drugs to the poor, Jack’s latest drug is leaving a trail of lethal overdoses across what used to be North America—a drug that compels people to become addi ...more
Hardcover, 303 pages
Published September 19th 2017 by Tor Books
Friend Reviews
To see what your friends thought of this book, please sign up.
Reader Q&A
To ask other readers questions about Autonomous, please sign up.
Popular Answered Questions
Diana I mean, who still falls for anything anymore? May as well ask who wants to read about robots, or big corporations, or underdogs, or superheroes, or sp…moreI mean, who still falls for anything anymore? May as well ask who wants to read about robots, or big corporations, or underdogs, or superheroes, or spaceships. More importantly, what functional use could a question like this serve? Who asks questions that rely entirely on subjective answers just to hear themselves ask them? Where is Bob? Who is Bob? Why is Bob?
It cost him everything.(less)
It cost him everything.(less)
Katherine ** CAUTION - SPOILERS **
I think it is more anti-monopolist than anti-capitalist, although certainly monopoly is the most pernicious and extreme form o…more** CAUTION - SPOILERS **
I think it is more anti-monopolist than anti-capitalist, although certainly monopoly is the most pernicious and extreme form of capitalism.
I read this book because I work in patent law, and the blurb said that the protagonist is anti-patent. However, the patent system described in the book is very different from what exists today. The patent system today rewards inventors by giving them a short-term monopoly on making and selling (or licensing) the invention, BUT it also rewards the public by making detailed information about the invention public knowledge. That way, other inventors can build on and improve the patented invention. In the author's world, the inventors get their patent monopolies, apparently forever, but keep the details secret from the rest of the world. This means, for instance, that the drug companies continue to make their patented drugs and charge exorbitant prices for years and years, but anyone who figures out how to make a generic version of the drug is breaking the law. This legalized secrecy, though, means that a drug manufacturer can - illegally! - create a drug that makes folk addicted to their jobs.(less)
I think it is more anti-monopolist than anti-capitalist, although certainly monopoly is the most pernicious and extreme form o…more** CAUTION - SPOILERS **
I think it is more anti-monopolist than anti-capitalist, although certainly monopoly is the most pernicious and extreme form of capitalism.
I read this book because I work in patent law, and the blurb said that the protagonist is anti-patent. However, the patent system described in the book is very different from what exists today. The patent system today rewards inventors by giving them a short-term monopoly on making and selling (or licensing) the invention, BUT it also rewards the public by making detailed information about the invention public knowledge. That way, other inventors can build on and improve the patented invention. In the author's world, the inventors get their patent monopolies, apparently forever, but keep the details secret from the rest of the world. This means, for instance, that the drug companies continue to make their patented drugs and charge exorbitant prices for years and years, but anyone who figures out how to make a generic version of the drug is breaking the law. This legalized secrecy, though, means that a drug manufacturer can - illegally! - create a drug that makes folk addicted to their jobs.(less)
Sword and Laser Sci-Fi list
Excellent Space Opera
847 books — 3,434 voters
More lists with this book...
Community Reviews
Showing 1-30
Average rating 3.58 ·
· 15,154 ratings · 2,174 reviews
|
Start your review of Autonomous
Sep 26, 2017 Mary ~Ravager of Tomes~ rated it it was ok
Jack has a history of aligning herself with rebel causes. She is pirate in the sense that she reverse engineers drugs and distributes them to the public for reasonable prices. When a stimulant begins to manifest deadly addiction, Jack sets out to try and bring down the manufacturer responsible for overlooking the side effects.
Having distributed a knockoff version of this drug, Jack finds an agent/bot duo, Eliasz & Paladin, hot on her tail.
So really, I must say the only area in which this book m ...more
Having distributed a knockoff version of this drug, Jack finds an agent/bot duo, Eliasz & Paladin, hot on her tail.
So really, I must say the only area in which this book m ...more
Apr 05, 2018 Wil Wheaton rated it really liked it
I loved this. It did for AI and Patents and Biotech what Neuromancer and Snowcrash did for the Internet. The stuff I loved the most is all spoiler-y, so I'll just say that there are two competing narrative characters, who are at clear odds with each other, and each is the villain in the other's story. The thing that Annalee Newitz does so well (and she does everything well in this book) is to make each of these characters not only the hero of their own story, but to allow us to identify with the ...more
Dec 03, 2017 Lena rated it it was ok
Shelves: audio, science-fiction
Man: Hey Blue Bot, you’re looking good.
Blue Bot notices Man’s erection.
Blue Bot: Did you want to have sex?
Man: No! I’m not gay!
Blue Bot researches humans on the internet. Blue Bot replaces its blue carapace with a pink one.
Man: You’re pink?!?! Why are you pink?
Pink Bot: I decided this was me. Do you want to have sex?
Man: Yes!
After sex.
Man: Did you enjoy that?
Pink Bot: I enjoyed that you enjoyed it.
Man: I knew you were a woman.
The best I can say about this book is that it reminded me of Malka Old ...more
Blue Bot notices Man’s erection.
Blue Bot: Did you want to have sex?
Man: No! I’m not gay!
Blue Bot researches humans on the internet. Blue Bot replaces its blue carapace with a pink one.
Man: You’re pink?!?! Why are you pink?
Pink Bot: I decided this was me. Do you want to have sex?
Man: Yes!
After sex.
Man: Did you enjoy that?
Pink Bot: I enjoyed that you enjoyed it.
Man: I knew you were a woman.
The best I can say about this book is that it reminded me of Malka Old ...more
Jul 29, 2017 Justine rated it it was amazing
Shelves: favourites-2017, 2017-read
This is a book that you are either going to love or just not get. Newitz has painted a pretty grim picture of the future, similar to that portrayed in Company Town by Madeline Ashby and in After Atlas by Emma Newman. What all three of these books have in common is a future where people are basically commodities, like everything else, and the division between the haves and have-nots has grown as much as we can imagine.
Newitz provides a wonderful story for exploring the nature of autonomy, or free ...more
Newitz provides a wonderful story for exploring the nature of autonomy, or free ...more
Feb 16, 2018 Philip rated it liked it
Shelves: author-woman, 2017-releases, sci-fi
3.5ish stars.
An interesting, well-written, near-ish-future SF novel with some compelling ideas. It reminds me a little bit of Malka Older's idea heavy Infomocracy, although I liked Older's book a little bit more.
I didn't find this extremely engaging and never felt strongly pressed to continue reading, but I did enjoy it consistently. The ideas outshine the characters, and I didn't connect with any of them except for Paladin, an indentured robot working toward ""autonomy,"" and, to a lesser extent ...more
An interesting, well-written, near-ish-future SF novel with some compelling ideas. It reminds me a little bit of Malka Older's idea heavy Infomocracy, although I liked Older's book a little bit more.
I didn't find this extremely engaging and never felt strongly pressed to continue reading, but I did enjoy it consistently. The ideas outshine the characters, and I didn't connect with any of them except for Paladin, an indentured robot working toward ""autonomy,"" and, to a lesser extent ...more
Oct 13, 2017 Bradley rated it it was amazing
Shelves: 2017-shelf, sci-fi, worldbuilding-sf
Pirates and bounty hunters on the high chemical and electronic frontier! Add a bit of transgendered robot issues, a bit of do-gooder pharmaceutical mayhem, and time split between labs, parties, sexual repression, and a few really big questions explored deftly and interestingly, and we've got ourselves a very interesting SF.
Let's look at the top layer a little. Slavery issues. The novel takes them on for both robots and humans equally. I'd expected that from both the blurb and the cover, of cours ...more
Let's look at the top layer a little. Slavery issues. The novel takes them on for both robots and humans equally. I'd expected that from both the blurb and the cover, of cours ...more
Sep 26, 2017 Kaylin (The Re-Read Queen) rated it it was ok
Shelves: sci-fi, didn-t-finish
DNF @ 38%
This is marketed as a robin hood esque tale, featuring Jack sneaking pharmaceuticals to the poor and dodging the authorities. Two of those said authorities are Paladin and Elias, a military robot with a human processor and their handler, who chase Jack and develop feelings for each other.
While all that's technically true, there's no emotional impact with any of this. We are thrust into a story without any feel for the character's or the world. Jack hardly has a noble quest to deliver m ...more
This is marketed as a robin hood esque tale, featuring Jack sneaking pharmaceuticals to the poor and dodging the authorities. Two of those said authorities are Paladin and Elias, a military robot with a human processor and their handler, who chase Jack and develop feelings for each other.
While all that's technically true, there's no emotional impact with any of this. We are thrust into a story without any feel for the character's or the world. Jack hardly has a noble quest to deliver m ...more
Oct 14, 2017 Mogsy (MMOGC) rated it it was ok
Shelves: science-fiction, pirates, audiobook, review-copy
2.5 of 5 stars at The BiblioSanctum https://bibliosanctum.com/2017/10/19/...
I’m not having much luck with books this month. Autonomous was another highly anticipated sci-fi title that sounded very good from its premise, but ended up fizzling when the story fell short on the follow-through. Featuring a bold and daring female pharmaceutical pirate who makes a living bootlegging high-priced upmarket drugs in order to help the poor, I thought for sure this would be a winner, but ultimately neither t ...more
I’m not having much luck with books this month. Autonomous was another highly anticipated sci-fi title that sounded very good from its premise, but ended up fizzling when the story fell short on the follow-through. Featuring a bold and daring female pharmaceutical pirate who makes a living bootlegging high-priced upmarket drugs in order to help the poor, I thought for sure this would be a winner, but ultimately neither t ...more
Sep 11, 2017 Avery Delany rated it did not like it
Shelves: lgbtq, ya, why-did-i-inflict-this-upon-myself, dystopia-utopia, arcs, 2017-reads
As a trans reader, I am really angry and upset with this book due to its homophobia and transphobia. *This book was received through NetGalley for free in exchange for an honest review*
Autonomous was one of my most anticipated reads of Autumn 2017 and I was ecstatic when I received a copy on NetGalley to read for free in exchange for a review. To some extent, Autonomous did not disappoint and yet, to another extent, Autonomous is downright homophobic and transphobic.
Let’s start off with what’ ...more
Autonomous was one of my most anticipated reads of Autumn 2017 and I was ecstatic when I received a copy on NetGalley to read for free in exchange for a review. To some extent, Autonomous did not disappoint and yet, to another extent, Autonomous is downright homophobic and transphobic.
Let’s start off with what’ ...more
Nov 17, 2017 Gary rated it really liked it
Autonomous is the excellent debut novel from lauded science journalist Annalee Newitz. Set in the year 2144, Jack makes her living pirating pharmaceuticals to help people who can’t afford life-saving medication. To pay the bills, she also pirates drugs like Zacuity, a kind of legal speed that is supposed to help people focus at work. She discovers too late that Zaxy, the makers of Zacuity, failed to disclose evidence of potentially deadly side effects that are magnified in people using her pirat ...more
Aug 02, 2017 Joel rated it really liked it
It would be hard for any book to live up to superlative cover blurbs from William Gibson and Neal Stephenson, but Annalee Newitz comes damn close with her debut, which is as much about the future of medical ethics and big pharma as it is the awakening of a fascinating artificial consciousness. (It's also a stealth romance novel—maybe the strangest, most oddly affecting I've ever encountered.) ...more
Apr 24, 2019 K.J. Charles added it
This was odd. Raises a lot of questions about autonomy, freedom, moral responsibility, and especially gender, but doesn't really address them once raised. eg this is a society based on bots when AI is sufficient to give them individual consciousness, and the question of autonomy is explored quite a lot there, but it's also based on indenture, where by people can sell themselves *or other people* into slavery, which is barely tackled at all. The narrative's assumption is that human slavery is alw ...more
Oct 23, 2019 Monica rated it liked it · review of another edition
Well…ummm…just uh…hmmm. At first blush this one almost had me convinced that it had poignancy. Chalked full of meaning and depth. The longer I thought about it, the harder it was to find importance. Just a smidgen.
OMG, who am I kidding? I tried, goodness I tried to find the substance in this superficial sci fi fluffy candy with hard, sharp edges. Frankly, it is beyond my ability. Pharmaceutical companies have found dominance in this near future landscape and Jack is a pirate who reverse enginee ...more
OMG, who am I kidding? I tried, goodness I tried to find the substance in this superficial sci fi fluffy candy with hard, sharp edges. Frankly, it is beyond my ability. Pharmaceutical companies have found dominance in this near future landscape and Jack is a pirate who reverse enginee ...more
Sep 07, 2017 Lindsay rated it it was amazing
A breathtakingly well-imagined tour of Earth in the mid-twenty-second century where climate change has progressed to the point that the arctic is the new frontier for development and robotics, nanotech and biotech have reshaped our societies. Governments now come a distant second to powerful corporations and the International Property Coalition (IPC) acts with unchallenged lethal force to protect property rights. and both humans and robots can be indentured as slaves.
Pharmaceutical patent pirate ...more
Pharmaceutical patent pirate ...more
Sep 18, 2017 Peter Tillman rated it it was amazing
Shelves: science-fiction, reread-list, at-slo-paso-bg-pa, prob-won-t-read
Great, geeky hard-SF exploration of tech-aided transhumanity, and how it brought slavery back into fashion. A timely cautionary tale on the fragility of civil liberties. There are a few first-novel rough spots, and a slightly creepy ending. Overall, 4.5+ stars, rounded up
One of my mental tests of any hard-sf novel is, has the writer done her homework? Nobody can write intelligently about a topic like this without reading the prior art, and without some basic grasp of what's going on in the rele ...more
One of my mental tests of any hard-sf novel is, has the writer done her homework? Nobody can write intelligently about a topic like this without reading the prior art, and without some basic grasp of what's going on in the rele ...more
Oct 10, 2017 Julie rated it it was ok · review of another edition
Hmm, let's see if I can write a coherent review to figure out some of my issues with this book! This pairs very well with Madeline Ashby's Company Town, in terms of being a speculative futuristic cyberpunky novel starring a female Asian lead, largely set in Canada, and interested in issues of slavery, bodily autonomy, body mods, and sustainability. I love that we're getting these fresh new takes on what the future might look like; they're extensions of what we're seeing today, especially with th ...more
Sep 24, 2017 Zach rated it did not like it
Newlitz is clearly relying on the networking goodwill she and partner Charlie Jane Anders have built during their time on io9.com to drum up hype and the usual uncritical, breathless praise from undemanding readers and those who form a part of a community that feels the need to support an author beyond the quality of the work in question.
After experiencing extreme disappointment over the marketing blitz for Ander's All the Birds in the Sky and the complete failure of the book itself to live up ...more
After experiencing extreme disappointment over the marketing blitz for Ander's All the Birds in the Sky and the complete failure of the book itself to live up ...more
Oct 11, 2017 Amanda rated it it was amazing
This is a dark, grim future. It is also an outstanding book that deals with complicated issues like autonomy, freedom and gender constructs. One of my favorites this year.
Sep 25, 2017 Mel rated it it was ok
This review contains spoilers.
I have quite the contradicting thoughts on this book.
The premise is very interesting and innovative. The main theme of freedom versus ownership is comprehensibly written into the world with its patents and ownership (of medicine) as well as into the characters who are in different stages of freedom and ownership themselves. However, even as an autonomous person freedom is not a given. The questions the author raises in her book are important and thoroughly depicted. ...more
I have quite the contradicting thoughts on this book.
The premise is very interesting and innovative. The main theme of freedom versus ownership is comprehensibly written into the world with its patents and ownership (of medicine) as well as into the characters who are in different stages of freedom and ownership themselves. However, even as an autonomous person freedom is not a given. The questions the author raises in her book are important and thoroughly depicted. ...more
Sep 20, 2017 Rachel (Kalanadi) rated it really liked it
Shelves: science-fiction, publisher
Video version of this review: https://youtu.be/5sDMuuc-9t0
Autonomous begins when Jack, a pharmaceutical pirate, discovers a stowaway on her submarine. Said stowaway is trying to steal her pirated drugs, so she kills him... and then is saddled with his very poorly treated indentured slave, Threezed. Then she finds out about a drug epidemic... caused by a work productivity drug she pirated and spread, which is now causing people to work themselves to death.
So, Jack wants to fix this problem. And s ...more
Autonomous begins when Jack, a pharmaceutical pirate, discovers a stowaway on her submarine. Said stowaway is trying to steal her pirated drugs, so she kills him... and then is saddled with his very poorly treated indentured slave, Threezed. Then she finds out about a drug epidemic... caused by a work productivity drug she pirated and spread, which is now causing people to work themselves to death.
So, Jack wants to fix this problem. And s ...more
Jun 29, 2018 Silvana rated it really liked it · review of another edition
Update:
Just met Annalee in Swedish Con and got their autograph. They were super smart and sweet!
Original review:
Thank you, Coode Street Podcast, for this amazing recommendation. I first noticed Autonomous from Gary and Jonathan's convo, where they basically gushed about this book. Then one day, they interviewed Newitz. I was sold. It seemed to be a promising cyberpunk, which is a genre that I try to provide a second chance to, following my first bad experience with Neuromancer (which I did fina ...more
Just met Annalee in Swedish Con and got their autograph. They were super smart and sweet!
Original review:
Thank you, Coode Street Podcast, for this amazing recommendation. I first noticed Autonomous from Gary and Jonathan's convo, where they basically gushed about this book. Then one day, they interviewed Newitz. I was sold. It seemed to be a promising cyberpunk, which is a genre that I try to provide a second chance to, following my first bad experience with Neuromancer (which I did fina ...more
Jul 23, 2022 Rachel (TheShadesofOrange) rated it really liked it
Shelves: science-fiction, audiobooks
4.0 Stars
This is a fascinating near future science fiction novel that criticizes the drug industry without stigmatizing the drugs themselves. This was a smart, yet easy read. I enjoyed all the Canadian references.
This is a fascinating near future science fiction novel that criticizes the drug industry without stigmatizing the drugs themselves. This was a smart, yet easy read. I enjoyed all the Canadian references.
Jun 08, 2021 Starlah rated it really liked it
This book was an interesting and fascinating exploration of the nature of autonomy.
2144, Captain Jack is known as a pharmaceutical pirate, though in actuality, she is more like Robin Hood in the way she reverse engineers medications to create generic versions and gets them out to the public; to those who couldn't o ...more
“But now we know there has been no one great disaster—only the slow-motion disaster of capitalism converting every living thing and idea into property.”
- Annalee Newitz, Autonomous
2144, Captain Jack is known as a pharmaceutical pirate, though in actuality, she is more like Robin Hood in the way she reverse engineers medications to create generic versions and gets them out to the public; to those who couldn't o ...more
Jan 03, 2021 Jemppu rated it liked it · review of another edition
Shelves: 2021-alphabet-challenge
Autonomy, gender and drug issues. 'Autonomous' raises compelling topics, but handles them dubiously and/or leaves them hanging with an unrewarding fade out.
With its heart in the right place, it's a pity the story settles to operate on certain lazily conceptualized ideas based on unappealingly narrow principles; play-acting its tired contemporary cultural complications in a rather unconvincingly staged future setting.
(Its arguably most cogent case presented in a brief moment of self-reflection, o ...more
With its heart in the right place, it's a pity the story settles to operate on certain lazily conceptualized ideas based on unappealingly narrow principles; play-acting its tired contemporary cultural complications in a rather unconvincingly staged future setting.
(Its arguably most cogent case presented in a brief moment of self-reflection, o ...more
Oct 15, 2017 Elle (ellexamines) marked it as zzzzz-coverporn-etc
...well. I have to admit, I'm a bit disappointed. I was somewhat enjoying this for a time. While I found this book slow-moving and everything up to the climax a little boring, I was hoping for some more plot development and enjoying Jack's character. But I'm put off by one relationship I felt was unhealthy and heavily disliked. Be warned there are spoilers ahead.
At one point, a character (Paladin) who has up to this point identified with male pronouns changes pronouns partially to appease a rom ...more
At one point, a character (Paladin) who has up to this point identified with male pronouns changes pronouns partially to appease a rom ...more
Apr 07, 2019 Dawn F rated it it was ok
Shelves: media-audible
There were many interesting things and situations in this book that grabbed me. The relationship between humans and robots has always fascinated me, and I liked the very straight forward plot mingled with personal development and self discovery (I’m being purposely vague).
But there were just as many solutions and conclusions to the issues presented in the book that rubbed me the wrong way. I *get* what the author was trying to do (if there was a plan), but I felt the solution was a cop-out and d ...more
But there were just as many solutions and conclusions to the issues presented in the book that rubbed me the wrong way. I *get* what the author was trying to do (if there was a plan), but I felt the solution was a cop-out and d ...more
Nov 09, 2017 RG rated it liked it
Alot happening in this novel. I normally love character driven stories, but I felt the relationship between Eliasz and Paladin was a little forced. I enjoyed Jacks character but wasnt overly involved. Pace was slow at times and a little random, at stages I felt the author was confused as to where to take the story. Solid world buidling if a little hazy at times. Strange way to end but I guess thats the direction she was going for. Still enjoyed the scifi elements.
Dec 05, 2017 Kara Babcock rated it liked it
Shelves: science-fiction, artificial-intelligence, own, romance, 2017-read
You have to watch out for those robots. Never know when they might develop thoughts of their own. Or sexual orientations, kinks, and an understanding of the way humans misunderstand them.
Autonomous plumbs the depths of humanity through split narration. Annalee Newitz follows a very human, and very flawed, anti-patent crusader and a pair of patent-enforcement agents, one of whom is a self-aware robot just starting out. As the two stories unfold, so too does Newitz’s vision of a 22nd-century Earth ...more
Autonomous plumbs the depths of humanity through split narration. Annalee Newitz follows a very human, and very flawed, anti-patent crusader and a pair of patent-enforcement agents, one of whom is a self-aware robot just starting out. As the two stories unfold, so too does Newitz’s vision of a 22nd-century Earth ...more
Jan 04, 2018 David rated it liked it
It's an exploration of big pharma, corporate rule, love, ownership of people, robots and even ideas.
Jack Chen is a pharmaceutical pirate that reverse engineers drugs to make them available to people in need. She does this by selling hacked in demand pills to fund her more altruistic efforts. Imagine selling off market Viagra to fund malaria relief efforts.
Now imagine Pfizer sending out armed goons with a license to kill to ""protect"" their intellectual property. In this case it's a military gra ...more
Jack Chen is a pharmaceutical pirate that reverse engineers drugs to make them available to people in need. She does this by selling hacked in demand pills to fund her more altruistic efforts. Imagine selling off market Viagra to fund malaria relief efforts.
Now imagine Pfizer sending out armed goons with a license to kill to ""protect"" their intellectual property. In this case it's a military gra ...more
Apr 17, 2018 Carlex rated it liked it · review of another edition
Three and half stars
A very good cyber/biopunk story, which also deals with transhumanism. Awesome worldbuilding and sense of wonder, and a plot development more than correct. I enjoyed it!
A very good cyber/biopunk story, which also deals with transhumanism. Awesome worldbuilding and sense of wonder, and a plot development more than correct. I enjoyed it!
|topics||posts||views||last activity|
|Fantastična čitao...: Čitaonica #86 - mart 2021: A. Newitz||17||19||02 juin 2021 18:54|
|Den of Geek Book ...: Autonomous by Annalee Newitz - Post Your Reviews!||7||54||19 sept. 2019 06:02|
|Den of Geek Book ...: What are your favorite stories featuring human-equivalent robots?||19||55||26 juin 2019 22:48|
|Sci-Fi & Fantasy ...: February 2019 - Autonomous||12||8||28 fév. 2019 00:32|
|Den of Geek Book ...: Den of Geek Book Club Giveaway!||18||77||21 déc. 2018 19:41|
813 users
88 users
64 users
64 users
57 users
51 users
1,247 followers
Annalee Newitz is an American journalist who covers the cultural impact of science and technology. They received a PhD in English and American Studies from UC Berkeley, and in 1997 published the widely cited book, White Trash: Race and Class in America. From 2004–2005 they were a policy analyst for the Electronic Frontier Foundation. They write for many periodicals from 'Popular Science' to 'Wired ...more
Articles featuring this book
Author C.L. Clark is no newcomer to the sci-fi and fantasy scene. Though she just published her first novel, The Unbroken, earlier this year,...
169 likes · 23 comments
“But now we know there has been no one great disaster—only the slow-motion disaster of capitalism converting every living thing and idea into property.”More quotes…
—
29 likes",8
204,"- Deere & Co., well known for its green and yellow tractors, bulldozers and lawnmowers, has spent nearly two decades investing in technology and robotics.
- That has culminated with a fully autonomous version of the 8R farm tractor that does not require someone to be behind the wheel.
- However, while Deere is aiming to push further into other autonomous farm vehicles and other technology-aided advancements, the global fleet of such vehicles is currently less than 50.
Can John Deere become one of the leading AI and robotics companies in the world alongside Tesla and Silicon Valley technology giants over the next decade?
That notion may seem incongruous with the general perception of the 185-year-old company as a heavy-metal manufacturer of tractors, bulldozers and lawnmowers painted in the signature green and yellow colors.
But that is what the company sees in its future, according to Jorge Heraud, vice president of automation and autonomy for Moline, Illinois-based Deere, a glimpse of which was showcased at last January's Consumer Electronics Show in Las Vegas, where Deere unveiled its fully autonomous 8R farm tractor, driven by artificial intelligence rather than a farmer behind the wheel.
The autonomous 8R is the culmination of Deere's nearly two decades of strategic planning and investment in automation, data analytics, GPS guidance, internet-of-things connectivity and software engineering. While a good deal of that R&D has been homegrown, the company also has been on a spree of acquisitions and partnerships with agtech startups, harvesting know-how as well as talent.
""This comes from our realization that technology is going to drive value creation and increase productivity, profitability and sustainability for farmers,"" Heraud said.
While Deere made a big splash at CES and intrigued the investment community, Stephen Volkmann, equity research analyst at Jefferies, said, ""We are very, very, very early in this process.""
""The total global fleet of autonomous Deere tractors is less than 50 today,"" he added. And even though Deere's goal is to have a fully autonomous farming system for row crops in place by 2030, Volkmann said, ""in Wall Street time, that's an eternity.""
For the time being, Deere is creating value and profits with well-established automated systems that can be retrofitted to its existing tractors, such as GPS-based self-steering and precision seeding that measures how deep and far apart to plant. Those steps have to be in place, Volkmann said, before you can put full autonomy around them.
The autonomous 8R represents a giant leap in current agtech, not to mention the marketing benefit. ""Prior to its introduction at CES, everybody thought [full autonomy] was pie in the sky,"" said Scott Shearer, chair of the department of food, agricultural and biological engineering at Ohio State University.
Around the world, Shearer said, there are probably 30 different autonomous tractor projects in the works, though none are commercially available. ""But when Deere, with 60% of the tractor market share in North America, comes out with one, that's when reality sets in,"" Shearer said.
That reality reflects Deere's autonomy strategy. ""The AI we use involves computer vision and machine learning,"" Heraud said, science that was well underway at Silicon Valley startup Blue River Technology, which Deere bought in 2017 for $305 million — a deal that also brought on Blue River co-founder and CEO Heraud. Blue River's ""see and spray"" robotics platform utilizes dozens of sophisticated cameras and processors to distinguish weeds from crop plants when applying herbicides.
Attached to the autonomous tractor are six pairs of stereo cameras that can ""see"" an obstacle in the field — whether it's a rock, a log or a person — and determine its size and relative distance. Images captured by the cameras are passed through a deep neural network that classifies each pixel in approximately 100 milliseconds and decides whether the tractor should keep moving or stop.
""We've curated hundreds of thousands of images from different farm locations and under various weather and lighting conditions,"" Heraud said, ""so that with machine learning, the tractor can understand what it's seeing and react accordingly. This capability also allows the farmer, instead of being in the tractor, to operate it remotely while doing something else.""
Heraud was referring to autonomous driving, another piece of Deere's agtech puzzle that came together when it purchased Bear Flag Robotics last year for $250 million. Also a Silicon Valley startup, launched in 2017, Bear Flag's autonomous navigation system can be retrofitted onto existing tractors. In the case of Deere's 8R model, a tractor which first went on the market in 2020, the latest version with autonomous capabilities uses technology from Blue River.
Since the CES rollout, Deere has acquired AI assets from two other agtech pioneers. In April, Deere formed a joint venture with GUSS Automation, which has devised semi-autonomous orchard and vineyard sprayers. Using AI and IoT, multiple GUSS (Global Unmanned Spray System) sprayers can be remotely controlled by a single operator, running up to eight sprayers simultaneously from a laptop. GUSS can detect trees and determine how much to spray on each one, regardless of height or canopy size.
A month later, Deere announced the acquisition of numerous patents and other intellectual property from AI startup Light, according to The Robot Report. Light's depth-perception platform improves upon existing stereo-vision systems by using additional cameras, mimicking the structure of a human eye to enable more accurate 3D vision. Deere plans to integrate Light's platform into future versions of its autonomous farm equipment.
To keep a close eye on other agtech R&D, Deere has established a Startup Collaborator program to test innovative technologies with customers and dealers without a more formal business relationship. ""The hope is that they find the diamonds before they become obvious to [competitors] and keep them in the fold,"" Volkmann said. Among the current crop are Four Growers, a Pittsburgh-based startup providing robotic harvesting and analytics for high-value crops, starting with greenhouse tomatoes, and Philadelphia-based Burro, which is producing small, autonomous robots that can assist farm workers with various conveyance tasks.
Not surprisingly, Deere's biggest competitors have been developing automation and autonomy for its farm machinery, too. AGCO, whose brands include Massey Ferguson and Fendt, ""has been automating farming operations since the mid-1990s,"" said Seth Crawford, senior vice president and general manager of the Duluth, Georgia-based company's precision agriculture and digital division. ""We're at a stage we call supervised autonomy, where we still have someone in the cab of the machine,"" he said. ""The buzz is around fully autonomous operations, but where farmers are willing to pay for automation is feature by feature.""
Whereas Deere is focused on adding full autonomy to its own farm equipment, AGCO is eying the wider retrofit market, Crawford said. ""In summer 2023, we'll have a performance-enhancing retrofit kit available for multiple brands of machines,"" he said. ""Where others say we bring you autonomy with a half-million-dollar tractor,"" he said, alluding to the price tag of Deere's 8R, ""we have kits that allow you to do that with your existing fleet. We see a huge opportunity with the installed base, where farmers want to adopt technology to enhance their outcomes, and yet don't want to flip their entire fleet and make that massive investment.""
In 2016, Case IH, a subsidiary of CNH Industrial, headquartered in London, rolled up to the Farm Progress Show with what it called the Autonomous Concept Vehicle. The sleek prototype tractor, minus a driver's cab, hinted at the view of autonomy at the time. Fast forward six years, to September's Farm Progress Show, where Case IH unveiled its Trident 5550 autonomous applicator.
Released in 2017, the Trident 5550 — with a cab — is designed for spreading dry and liquid materials in farm fields. The model at the farm show was retrofitted with autonomous technology developed by Raven Industries, which CNH acquired for $2.1 billion in June 2021. Similar to Deere's autonomous 8R, the enhanced Trident employs self-driving capability, advanced cameras and AI to interpret a continuous stream of images to detect obstacles.
The company plans to have a limited number of the machines ready for farmers to test before going to market perhaps next year, said Chris Dempsey, global director at Case IH Precision Technology, though the exact release date is to be determined. ""We want to get customer feedback and understand their confidence level [in autonomy] before we go commercial,"" he said.",3
205,"Amazon is everywhere: in the doctor’s office, in people’s homes, in their shopping carts, and now — in their therapist’s office, too. Amazon’s virtual healthcare program, Amazon Care, now includes a partnership with mental health company Ginger, according to an Amazon Care webpage. The new offerings were first reported by Insider.
The webpage outlines the behavioral health options available through Amazon Care. Primary care providers on the platform can respond to some low-grade issues, like mild anxiety. For more serious concerns, patients can be referred to providers outside of Amazon Care. Ginger, a digital mental health platform that gives people 24/7 access to mental health coaches and therapists, will be available as an optional add-on for companies that use Amazon Care, the website says. “Health information is shared between Amazon Care and Ginger,” the website reads.
There’s a huge demand for mental health services in the United States, but it can be hard for most people to find a traditional in-person therapist. Mental health apps have surged in to fill that void, despite potential privacy risks.
Ginger and Amazon have not publicly announced their partnership, and Amazon did not respond to a request for comment by the time of publication.
Amazon Care first launched in 2019 as a hybrid in-person and virtual care service for Amazon employees in Seattle. It’s now available to companies in all 50 states that want to offer the service to their employees.
This latest step is just another inroad into healthcare for the tech giant, which also launched its own pharmacy in 2020 and has programs that integrate Alexa into hospitals. In July of this year, Amazon announced it was buying primary care company One Medical.
Amazon is hooking into every aspect of day-to-day life — not just healthcare. Just last week, it also signed an agreement to buy Roomba robot vacuum maker iRobot — which generates maps of the floor plans of people’s homes. That’s probably why Amazon bought the company, wrote Verge smart home reviewer Jennifer Pattison Tuohy when the deal broke. It’s another tendril reaching out from the tech company and wrapping around the private sphere and yet another thing that gives them “a pretty complete picture of your daily life.”",6
206,"Run Stable Diffusion AI At Home — No Code Guide
Recently, startup StabilityAI announced the release of Stable Diffusion, a powerful AI image generator that can now run on standard graphics cards.
Note: You don’t need any programming experience to follow along, it’s all spelled out.",3
207,"Earth is now our only shareholder.
If we have any hope of a thriving planet—much less a business—it is going to take all of us doing what we can with the resources we have. This is what we can do.
By Yvon Chouinard
I never wanted to be a businessman. I started as a craftsman, making climbing gear for my friends and myself, then got into apparel. As we began to witness the extent of global warming and ecological destruction, and our own contribution to it, Patagonia committed to using our company to change the way business was done. If we could do the right thing while making enough to pay the bills, we could influence customers and other businesses, and maybe change the system along the way.
We started with our products, using materials that caused less harm to the environment. We gave away 1% of sales each year. We became a certified B Corp and a California benefit corporation, writing our values into our corporate charter so they would be preserved. More recently, in 2018, we changed the company’s purpose to: We’re in business to save our home planet.
While we’re doing our best to address the environmental crisis, it’s not enough. We need to find a way to put more money into fighting the crisis while keeping the company’s values intact.
“Truth be told, there were no good options available. So, we created our own.”
One option was to sell Patagonia and donate all the money. But we couldn’t be sure a new owner would maintain our values or keep our team of people around the world employed.
Another path was to take the company public. What a disaster that would have been. Even public companies with good intentions are under too much pressure to create short-term gain at the expense of long-term vitality and responsibility.
Truth be told, there were no good options available. So, we created our own.
Instead of “going public,” you could say we’re “going purpose.” Instead of extracting value from nature and transforming it into wealth for investors, we’ll use the wealth Patagonia creates to protect the source of all wealth.
Here’s how it works: 100% of the company’s voting stock transfers to the Patagonia Purpose Trust, created to protect the company’s values; and 100% of the nonvoting stock had been given to the Holdfast Collective, a nonprofit dedicated to fighting the environmental crisis and defending nature. The funding will come from Patagonia: Each year, the money we make after reinvesting in the business will be distributed as a dividend to help fight the crisis.
It’s been nearly 50 years since we began our experiment in responsible business, and we are just getting started. If we have any hope of a thriving planet—much less a thriving business—50 years from now, it is going to take all of us doing what we can with the resources we have. This is another way we’ve found to do our part.
Despite its immensity, the Earth’s resources are not infinite, and it’s clear we’ve exceeded its limits. But it’s also resilient. We can save our planet if we commit to it.
Some Questions and Answers
Funding for the Collective will come from Patagonia: Each year, excess profits—money we make after reinvesting in the business (including money we want to save for unforeseen events, like a pandemic)—will be distributed as a dividend to the Collective to be used for its work.
Put another way, Patagonia’s purpose is: We’re in business to save our home planet. The Patagonia Purpose Trust ensures the company’s commitment to its purpose forever.
Our impact in the world comes from operating as a for-profit business. We will continue to serve as a beacon for the entire business community by proving that purpose and profits are inextricably linked.
Patagonia is 50 years into an experiment, and plans to stay in business, operating profitably in line with our values, for the next 50 years and beyond.",2
208,"RMIT University to lead €15.7 million Australia-France doctoral training network
In a significant win for global research training, Australian and French academic ties are set to strengthen with today’s announcement of the Australia France Network of Doctoral Excellence (AUFRANDE).
Take the burn out of sunscreen testing: experts
Exposing humans to ultraviolet radiation to test sunscreen effectiveness should be phased out, according to scientists and cancer experts.
Discovery could inspire new way to detect brain abnormalities
Scientists have taken a promising step towards a new generation of accurate, affordable and portable devices to detect concussion, epilepsy and dementia.
Making muscles, building brains: inside the mind-blowing world of biofabrication
In a research lab at a Melbourne hospital, work is underway to turn biomedical science fiction into reality.",1
209,"Billions of people carry cameras in their pockets and use them to document their lives. Yet, despite the democratization of photo hardware, the knowledge of photographic techniques remains elusive. Countless books, webpages, and YouTube videos purport to offer advice, but tend to dwell on topics of little consequence to most hobbyists - such as shopping for gear or memorizing made-up rules of composition that seldom make for a good shot.
I'm not a pro, but I dabbled in photography for more than two decades - and after making countless mistakes, I have gotten fairly good. This page is an impassioned contrarian take on what it takes to snap great photos, along with a set of simple experiments that can be repeated at home.
It is said that composition is the most important aspect of a photograph. I disagree. An intriguing interplay of light and shadows can make a discarded candy wrapper look profound. An unflattering light makes even the most expertly framed scenery look pedestrian and dull.
Monitors and photographic paper are capable of faithfully reproducing only a tiny portion of the luminance range our eyes can perceive. It follows that in a photograph or a video, shadows and highlights are not just a mild distraction: they control what can and cannot be seen. Good photographers exploit this property to accentuate what matters and conceal what does not. Inexperienced hobbyists abdicate the responsibility to an algorithm in the camera. They often end up with competent results, but seldom with what they had in mind.
Most novices think that illumination is entirely out of their control, but it isn't so. A solid grasp of the fundamentals allows one to leverage the environment. When shooting outdoors, you might ask your subject to stand near an exterior wall to eliminate the harsh shadows that plague most vacation shots. Indoors, you might move toward a nearest window or stay clear of recessed lights.
To understand how these tricks can help, let's talk about some of the key properties and types of light.
One of the most consequential ways to classify light sources is by their apparent size. Some sources are so small or so distant that they behave as if all the light rays emanated from a single point in space. A well-known example is the sun on a clear day. Inside your house, the same can be said of a bare lightbulb or a flashlight, especially if placed some distance away. The shadows cast by such sources are intense and sharp-edged. The transition between light and shadow is abrupt because a point source instantenously disappears from view when an opaque item gets in the way.
Other sources behave as if the light emanated from a larger surface, be it because of the nature of the emitter or due to some apparatus that scatters the rays. A familiar mega-scale area light is the sky on an overcast day. Indoors, a common example is a bedside lamp equipped with a shade. Area lights produce soft shadows because there are many possible intermediate states between the source being fully visible and fully occluded. The softness is proportional to how large the source is and how closely it is situated.
Point sources have their uses in photographic work, but more often than not, they get in the way. In landscape photography, they create jarring contrast, particularly when snapping buildings or trees. In portrait work, they produce unflattering and distracting shadows, especially around the nose. The phenomenon can be seen in the following picture:
For simplicity and consistency, I am using a porcelain figurine as a stand-in for a model. In both of these examples, I placed the source a bit to the right of the camera. The problem with point lights gets more severe if the source is positioned overhead. In such circumstances, eyes appear dark and sunken, and your model may end up springing a Hitleresque mustache. Again, such lighting can be sometimes employed for dramatic effect - but it's more common for it to ruin the shot:
As hinted earlier, the remedy can be simple. Outdoors, a nearby reflective surface, such as a light-colored wall, can provide diffuse illumination that makes the shadows less evident. Indoors, staying away from recessed lighting is a good habit. Finding a night lamp or a window on the shady side of the house can also help.
Another noteworthy quality of a light source is its beam shape. A bare lightbulb is omnidirectional and unfocused. It illuminates all nearby items fairly evenly, but the intensity falls off fast when you take a couple of steps back. A flashlight, in contrast, produces a focused beam that lights up only a tiny slice of your field of view, but can carry up to a hundred yards.
Wide-angle lights (""floodlights"") are the bread and butter of photographic trade. In addition to providing uniform and predictable illumination, they also excel at isolating subjects from their backgrounds. If your subject is placed near the light but some distance away from the background, and if you set the exposure right, light falloff ensures that all the background clutter neatly fades from view.
Narrow-beam spotlights, on the other hand, tend to create extreme contrast and usually need to be offset by a floodlight to make the picture work. In particular, if you want to create a night scene of someone holding a flashlight or standing in the headlights of a car, you need to provide additional ""fill"" illumination from a more uniform source - or shoot an underexposed photo at dusk.
It follows that accidental spotlights, such as recessed lighting or sunbeams coming through windows, are best avoided unless you have a way to offset their undesirable effects. That said, a well-employed spotlight can add value. The following picture uses a gentle spotlight to bring out the face while keeping the rest of the figurine in a subtle shade:
The next light property to pay attention to is the angle of illumination. We already discussed the issues with overhead lights. The other undesirable extreme is a light source placed in about the same axis as your lens, for example when using an on-camera flash. This type of illumination prevents the formation of natural shadows that convey information about the curvature of three-dimensional objects, making faces look round and flat:
Once again, creative light positioning can be used for dramatic effect; for example, a light shining from below makes your model look sinister and out of this world (perhaps emerging from the depths of hell). That said, in most situations, the extremes are best avoided. Placing the light slightly to the side, perhaps at 20-30 degrees from the axis of the lens, is often the best starting point.
The final light quality we're going to discuss is color temperature. In the olden days, most man-made lighting - from candles to incandescent lightbulbs - had an inherent orange-yellow hue. Today, this is no longer a physical constraint, but most CCFL and LED lamps still mimic the effect, aiming for a color temperature between 2,700 K (""soft white"" or ""warm white"") and 3,500 K (""neutral white""). This is not just a force of habit: this type of illumination is easy on the eyes and nicely complements skin tones. Higher color temperatures with a stronger blue cast are reserved for factory floors, workshops, and other areas where maximum light intensity and superior color rendition matter more than good looks.
In outdoor settings, color temperatures dip to around 2,000 K during sunrise and sunset; together with lower light intensity and favorable illumination angles, these ""magic hours"" are some of the best times for outdoor photography. During the day, the temperature will usually go up to about 5,500 K, and if the sky is overcast, it can reach 6,500 K or so. Moonlight isn't any bluer, but nights may appear this way when viewed through the windows of a warmly-lit home. Because of that, it's a habit of most photographers and filmmakers to add a dark blue cast to night scenes - and audiences have come to expect it as a visual cue.
You can see an approximation of the difference between incandescent (""tungsten"") and daylight color temperatures below:
It's not that one color temperature is inherently better than another; orange cast can be more flattering in portrait work, but a photographer can add and remove it at will. In the era of photographic film, one would place a piece of colored glass in front of the lens. Today, the adjustment is as simple as moving a slider in a photo editing program or selecting a particular white balance setting in the camera. That said, if no action is taken, an in-camera algorithm will try to remove any ""errornous"" color cast - and the result might not be what you aimed for.
Another gotcha is what happens when two lights with different color temperatures illuminate a single scene. In such circumstances, automatic white balance algorithms will struggle, and if the illumination is harsh, you end up with a mess of alternating yellow- and blue-tinted shadows that don't look right. Still, if the light is diffuse and white balance is picked by hand, mixing color temperatures can pay off:
It must be said that the color temperature model is fairly simplistic: it represents a one-dimensional continuum, from red to blue, in a two-dimensional color space. Some light sources can exhibit other tints: for example, early fluorescent lamps had an unpleasant greenish hue that made skin appear unhealthy and pale. Today, Western filmmakers intentionally replicate this look when portraying the Soviet-era world behind the Iron Curtain; a good example is the acclaimed HBO miniseries ""Chernobyl"". In any case: on-camera controls might not offer enough flexibility to fix all color issues, but most photo editing software has an additional white balance slider on the continuum from purple to green.
As noted earlier, a skilled photographer doesn't need to haul thousands of dollars in lighting gear everywhere they go. It is often enough to take note of existing illumination sources and reason about how they affect the scene. It pays to remember that, owing to the nature of camera sensors and computer displays, seemingly small differences in illumination have a huge impact on the appearance of the photograph.
Whether you're using existing or added lights, it's best not to put too much faith in on-camera algorithms. Automatic exposure usually works to preserve detail in the highlights, but in a high-contrast scene, it might make everything else too dark. Some cameras attempt to compress the dynamic range (""HDR"") to salvage both highlights and shadows, but this can produce an artificial look: rough skin, unnaturally bright shadows, and weird halos in the areas of high contrast. It's better to stay in the driver's seat. Even on devices without manual exposure controls, it's usually still possible to dial in exposure compensation, or tap on the screen to set metering priority. But if your camera supports manually setting exposure time, you might be surprised how easy it is to get used to.
For those who want to invest in photographic lighting, I recommend starting small - perhaps with a pair of battery-powered LED tubes such as Genaray Beacon or Nanlite PavoTube 15C. This accessory provides a neatly diffused light that's more than enough for taking portraits of people and pets. But above all, unlike most other studio gear, it does not require any setup. You can grab it at a moment's notice, hold it in one hand, and have some casual fun.
To illustrate the potential of such simple tools, let's have a look at this snapshot taken in a darkened living room. I put one cheap LED tube upright behind my wife's back, pointed toward a bookshelf on the wall. I held another tube in front, above the camera, to exaggerate the curvature of cheekbones and eyebrows. The darkness in between did the rest to achieve an unsettling, low-key look:
For the next shot, we moved into the hallway. Another light pointed at her back introduced a subtle glowing silhouette - a flattering look that separates the subject from the background. I placed the main light a bit lower than before to make facial features appear more neutral and to reduce shadows:
Some LED tubes offer not just white light, but can be adjusted to achieve a full spectrum of colors. Although it's best to master traditional lighting first, such color variations can create a wide range of interesting effects. For example, if you want to recreate the popular ""night club"" vibe of some contemporary films and video games, you'd want to make the background blue or violet, and then bathe the foreground in magenta or red.
Of course, there are limits to what LED tubes can do; for one, they aren't particularly bright and can't produce a collimated beam to selectively illuminate a small portion of the frame. It follows that serious studio photographers may also benefit from continuous floodlights such as Westcott Solix, as well as focusable spotlights such as Genaray Torpedo.
Shopping for lights can be tricky. Modern cameras perform well in low-light conditions, so photographic lights usually don't need to be exceptionally bright, but they should be matched to the intended use. When it comes to light output, there are two units of measurement you might encounter in product brochures: the lumen (lm) and the lux (lx). Lumens tell you the overall luminous output of a source, no matter which direction the light goes; lux tell you brightly the lamp will illuminate a unit of surface area right in front of it.
The latter is more useful for photography, and it's good to memorize several points of reference. On a clear day at noon, you might get up to 100,000 lx in the sun and 20,000 lx in the shade; a cover of clouds can bring it down to 2,000 lx or less. Household lighting is quite variable, but measurements tend to hover around 50 to 300 lx. Urban stret illumination in pedestrian areas is around 5-10 lx. A typical candle scores about 1 lx from one meter away, hinting at the historical origins of this unit of measurement. Last but not least, moonlight is usually around 0.1 lx.
Pocket photographic lights, such as Genaray Powerbank 96A or Luxli Fiddle, deliver around 150-200 lx at 1 meter at maximum power. This makes them quite suitable for indoor close-up photography, but fairly useless outdoors, at least until dusk. Handheld LED tubes peak around 400-600 lx; that's enough to provide an outdoor fill light early or late in the day. Affordable AC-powered lamps, such as Westcott Solix or Genaray Torpedo, usually deliver around 3,000-6,000 lx at 1 m. Finally, if you absolutely need it, larger (and costlier) spotlights can pump out 50,000 lx or more.
Right after illumination, the optical system of your camera has an outsized impact on the appearance of your photos and video clips. This does not mean you need to go broke and buy a bulky camera with an array of interchangeable lens; it suffices to know when to zoom in, when to zoom out, and how to control the focus within the scene. The answers to these questions may seem obvious, but there's more to it than meets the eye.
""Focal length"" is a fancy way of describing the camera's field of view. A wide-angle lens with a short focal length can capture everything that's happening in a crowded bar; meanwhile, telephoto optics let you fill the frame with a single soda can from across the room. In theory, increasing the focal length is the same as snapping a wide-angle photo and then cropping and magnifying the center part. In practice, without optical magnification, you quickly run out of pixels and end up with a blurry mess.
At first blush, focal length may seem uninteresting: after all, you want your subject to occupy a reasonable portion of the frame, and for many novices, this dictates the zoom level they choose. What they overlook is that the size of the subject can be also controlled by moving the camera closer or farther away; in effect, there are countless combinations of distance and focal length settings that preserve the scale of the primary object they're trying to photograph. Let's demonstrate this effect using another porcelain figurine against the backdrop of a cluttered living room:
I captured this sequence by taking a step back every time I increased the focal length, so the size of the figurine's face didn't change. Yet, the pictures differ in many ways. For one, at wide angles, distant objects appear much smaller, and a good portion of the room ends up in the frame. As the focal length increases, the perspective becomes less pronounced, and field of view narrows all the way down to a single leaf of a household plant.
But there's something else happening too: in the first picture, the figurine appears to have a slender face, pouty lips, and a relatively large nose. As the sequence progresses, the face takes on a more rounded shape. This is another manifestation of the same optical phenomenon: at short focal lengths, features closer to the camera look larger, even if the distance differential is a fraction of an inch. It's why cell phone selfies usually look off.
The slideshow is annotated with focal length numbers for a 35mm camera sensor, also known as ""full frame"" (a throwback to the days of photographic film). To achieve a similar effect with a smaller sensor, the focal length would need to be proportionally less. Unfortunately, when buying gear, it's not always clear if the manufacturer is talking about ""35mm equivalent"" focal length or about nominal measurements of the optical path. The former is common in cell phones; the latter in prosumer cameras.
Either way, in the 35mm world, there are several reference points to memorize:
The length of about 20-22mm corresponds to the natural field of view of human vision. Lenses in this vicinity are ideal for photographing nearby crowds, snapping photos for real estate listings, or filming your kids playing on the beach. That said, any features in the periphery of the frame will appear distorted.
Focal lengths around 40mm project a 1:1 image onto the sensor, as if you looked at your surroundings through a rectangular viewfinder with no optics at all. This captures lifelike perspective with little distortion. For historical reasons, the most popular lens choice in this neighborhood is actually 50mm - a versatile if unassuming choice for indoor and outdoor scenes where you don't need to cram too much into the frame.
Focal length of 85mm is considered to be ideal for professional portrait work. It is long enough to virtually eliminate distortion, but short enough to allow the photographer to stand reasonably close the the model.
Focal lengths of 200mm and above are most commonly employed for nature photography, sports, and for spying on people from afar.
Smartphones with zoom optics usually feature focal lengths corresponding to about 20-80mm in the world of full-frame sensors. Past that point, the phone usually switches to digital magnification, and picture quality takes a nosedive.
Depth of field is a property of the optical system that determines what slice of the scene will appear sharp when you focus the lens at a particular distance. Shallow DOF is a wonderful tool for isolating subjects and hiding background clutter, as shown in the sequence below:
The depth of field in your photos will depend on three things:
The focal length of the lens. Telephoto optics tend to produce shallow DOF; wide-angle lenses keep almost everything in focus most of the time.
The distance to your subject. In close quarters, the DOF might be measured in fractions of an inch; toward the horizon, it can span a mile or more.
The aperture of the lens, aka the relative diameter of the optical path. Large apertures (numerically low f-values, around f/1.2 to f/1.8) exhibit extremely shallow DOF and create a pleasing blur. Smaller apertures, around f/4 and above, provide relatively little latitude for creative DOF work.
Although most people find shallow DOF quite agreeable, it can interfere with landscape shots and street photography. In such situations, the simplest solution is to reduce the aperture (increase the f-number). This is akin to squinting your eyes; in addition to making the picture sharper, it also reduces the amount of light hitting the sensor, so you need to crank up the exposure time to cancel out the loss.
The optics of cell phone cameras usually exhibit extremely wide DOF at short focal lengths and do not expose aperture controls, but selective blurring might be doable when the lens are zoomed in. Barring this, some phones employ algorithms that try to estimate depth and selectively apply software blur to portraits. This doesn't always work well, but the results might be acceptable every now and then.
Even if you are not angling for a shallow DOF, the camera still needs to be focused on the subject to produce crisp-looking photographs. The actual task of adjusting the optics to maximize sharpness is almost always delegated to the camera's autofocus mechanism. That said, it's still up to the photographer to tell the AF mechanism which portion of the image to look at while making the adjustments; in the absence of this input, the system may default to a point in the center of the frame, lock in on a random high-contrast edge, or pick what looks like a face.
Almost every camera is equipped with a joystick or a touch interface to guide the AF system. In portrait work, it is customary to focus on the eyes; we're instinctively drawn to this part of the face, so any accidental focus errors tend to stand out:
If the model's head is titled, it's safer to pick the eye closer to the camera or that is otherwise more prominent; again, there's no one correct answer, but focusing on the less visible eye usually doesn't look right:
If the photographer wishes to draw attention to some other element of the composition while keeping a person's face in the frame, it's best to make sure the eyes are robustly out of focus, and not just slightly blurred:
Portraits aside: when setting up landscape shots, many novices pick the horizon as the focus point. That can be a mistake: it's better to select a point about one third of the way between the nearest and the most distant plane in the photograph. As noted earlier, DOF increases with distance, so this approach maximizes the odds that both the foreground and the background are going to look just right. The same one-third rule works for macro shots.
Color theory is a peculiar discipline that studies contemporary color preferences and design fads to develop a set of immutable principles that purportedly govern all uses of color in creative work. As with the ""ironclad"" rules of composition, I recommend skepticism - especially if the author brings out color wheels and starts drawing squiggles between equidistant points.
At the same time, it must be said that color and tone can be what separates a second-rate photograph from a memorable one. To illustrate, let's look at the potential evolution of this vacation shot deliberately chosen for its mediocrity:
The final photo appears to be better illuminated and more closely conforms to the popular depictions of the mountainous desert terrain around the Hoover Dam. Indeed, some cell phones automatically apply similar tone mapping tricks to photos taken in full sunlight; this happens without the photographer's knowledge and sometimes produces unexpected results.
Some color and tone tweaks can be taken care of when taking the photo, but many others are accomplished more easily in front of a computer screen. Pay no mind to purists: even in the era of photographic film, there was no such a thing as an ""unaltered"" photograph. The choice of process chemicals, paper, and enlarger settings profoundly affected the appearance of the final print. Deceptive edits may be a no-no, but absolute purity was never a meaningful goal.
At this point, we must note that the range of postprocessing options at your disposal is far greater if you capture photos as ""raw"" files (DNG, CR3, NEF, etc). Most cameras default to JPEG - a compact, 8-bit file format that keeps only the bare minimum of data needed to display the original image. In the Hoover Dam example shown earlier, JPEG compression would have destroyed the texture of the clouds and the detail in the blown-out highlight in my son's hair. Luckily, the raw file I captured contained enough information to bring out that extra detail when the correct slider was dialed down in a software tool.
Virtually all mid-range digital cameras have the ability to capture raw images, but the feature is not always available on mobile phones. That said, at least some Huawei, Samsung, and Apple handsets support raw images. The photos taken in this mode take up more storage space and can't be directly opened with some programs, but if you're serious about photography, you should give it a go.
There is a wide selection of programs for editing raw images. The gold standard used to be Adobe Lightroom, but after the app moved to an exploitative subscription model, perhaps the best alternative is Capture One ($300 for a perpetual license), followed by Darktable (free). Most other general-purpose image editors, such as GIMP or Affinity Photo, are also capable of working with raw images, but lack useful photographic workflow features, such as catalog management. This matters if you're trying to quickly sort through several hundred photos, or apply the same adjustments across the entire lot.
In the world of digital cameras, color balancing is implemented in software: after the picture is taken, the readings from the sensor are shifted by an algorithm to obtain neutral whites or achieve some other algorithmic goal. When working with JPEG files, the results of this transformation are baked into the final image and cannot be fully undone; but when shooting raw, the original sensor data is preserved, and a full range of adjustments is possible down the line.
Whenever the in-camera algorithm misses the mark, the most convenient way of removing an undesirable color cast is to point the photo editor's white balance picker at a portion of the picture meant to have a neutral shade of gray. This may be a stainless steel appliance, a section of the pavement, a white wall, a piece of clothing, or a special calibration card. If the result is unsatisfactory or if no suitable target is found, color balance can be also adjusted with manual sliders: ""temperature"" for moving from yellow to blue and ""tint"" for purple to green.
Of course, one doesn't need to seek a perfectly neutral look. As noted earlier, flattering orange hues are sought after in portrait work; subtle orange grading is the secret behind the good looks of most TV anchors on the news. Outside of portrait work, we are primed to interpret a yellow-orange cast in a well-lit photograph as an indicator of a warm summer day; while a shift toward blues might signal moonlight, frigid cold, or a sterile high-tech environment. Finally, greenish tints give the impression of an inhospitable place; while low-key purples, violets, and reds are the pop-cultural stand-ins for danger or lust.
As a practical example, consider this sequence of edits, starting with a neutral white balance calibrated on the pillows, and then introducing warmer and cooler tints:
Along with color balance, exposure is one of the most important postprocessing tweaks you can make. Dark, underexposed (""low-key"") photos tend to have an ominous appearance, and - with the right lighting and color tint - can imitate nighttime takes. On the other end of the spectrum, overexposed low-contrast (""high-key"") shots may have an angelic vibe or signal a futuristic, high-tech setting of some sort.
Strictly speaking, exposure settings can't be changed after the fact: the picture is taken with a predefined shutter time, lens aperture, and sensor amplifier gain (also known as the ISO setting, in another throwback to the era of film photography). It follows that gross exposure errors, such as shooting a completely overexposed frame, usually aren't recoverable. Luckily, when working with raw images, there's still some data captured in the highlights and in the shadows, giving you room to fine-tune the exposure down the line. In essence, photo editing software may shift pixel values up or down to simulate the light hitting the sensor for a bit more or a bit less time.
The usual viable range of such adjustments is plus / minus two ""stops""; a stop means a two-fold increase or decrease in exposure time, so the range translates to exposure times between 25% and 400% of the starting point. The following photo of a dog illustrates the effect of adjusting exposure +/- 1 stop:
In this instance, the underexposed photo is pretty interesting, perhaps reminiscent of a gray, rainy day in the fall.
Again, there are limits to what can be done in software: the electronics in the camera have their constraints, and the optical path can get in the way, too: especially with lower-grade lens, extreme highlights tend to produce blooming and chromatic aberrations (color fringing) that can't be fixed with a single click. Further, the latitude of possible adjustments is much lower when working with JPEG files; going beyond +/- 25% would be pushing your luck.
In addition to the whole-picture techniques discussed in the two preceding sections, most photo editing programs offer a handful of targeted tone adjustment tools. Chief among them are:
Separate luminance adjustments for shadows and highlights. In most programs, this is a standalone feature; in Capture One, it's a part of a confusingly-named ""High Dynamic Range"" tool. The tool helps restore details in overexposed or underexposed areas without affecting the rest of the image. For example, in the Hoover Dam photo, I used it to bring out the texture of the clouds.
Three-way hue and saturation adjustments for luminance ranges (shadows, midtones, highlights). Most programs refer to this as ""color balance"". The tool helps correct background color casts when mixing incompatible sources of light. It's also useful for adding distinctive tints to backgrounds, provided that the background is darker or lighter than the main subject of your shot.
Hue, saturation, and luminance adjustment for a specific source color (common preprogrammed choices: red, orange, yellow, green, cyan, blue, violet, magenta). Also known as the HSL tool, the mechanism is invaluable for making the vegetation greener or the sky more blue; or for selectively correcting skin tones, which tend to be clustered in the red-orange-yellow zone.
Here's a practical example of using these tools to make subtle stylistic tweaks to a photograph and give it a distinctive look:
Of course, the adjustments can be bolder. The following sequence of edits to a casual photo of my wife demonstrates some of the possibilities:
The first variant uses the low-key orange-teal color scheme all-too-common in superhero action films; the second one employs a sickly, low-contrast greenish cast seen in HBO's ""Chernobyl""; and the final one is a dark, blue-shifted version that, despite ample illumination, emulates a photo taken at night.
Of course, some photos may require corrections to regions that can't be isolated based on their color or luminance. In such a case, the photographer may need to resort to manual retouching, either creating a mask layer or freestyling with a ""dodge"" or ""burn"" tool or a color brush. Some emerging photo editors, such as Luminar Neo, employ machine learning to infer the 3D structure of the scene, offering the ability to apply sophisticated lighting effects (""relighting"") without fiddling with a brush. The algorithms are slow and clunky, but every now and then, they can save a botched shot.
Along with color theory, the principles of photographic composition are the refuge of armchair philosophers who pen stuffy essays about concepts such as ""the golden ratio"" or ""the rule of thirds"".
Naturally, aesthetics are to some extent a social construct: your audience might expect photographs to look in a particular way simply because that's what they're accustomed to. It follows that one shouldn't be a habitual contrarian; but it's about as counterproductive to get too hung up on dogma.
With this in mind, in the final chapter of this guide, let's have a quick look at several important composition choices - and let's do it without getting bogged down with ideology.
By far the most serious and preventable error in composition is background clutter. It's not that backgrounds need to be tidy: in street photography, busy cityscapes are a part of the picture as much as the subject standing in front. But when clutter is poorly controlled, it distracts from what the photographer is trying to say.
The distractions can come in many forms: busy textures, clashing colors, intrusive shadows or highlights, awkwardly cropped detail, or elements that simply do not belong - say, a toddler throwing a tantrum in the background of a glamour shot. In the following photograph of a camping knife, survivalist-themed background items make the picture more interesting; removing the props and exposing a messy kitchen countertop ruins the shot:
Of course, are times when we want the background to simply disappear. We showcased three ways of doing this earlier in the guide: area lighting, wide apertures, and long focal lengths.
Most novice photographers tend to place their subject smack dab in the middle, facing the camera, and filling most of the frame. There is nothing wrong with this approach, especially in portrait work - but it tends to create a static and clinical look. When the setting permits it, a wider crop can easily liven up the photograph:
More dynamism can be added by moving the subject to the left or to the right; this works equally well in landscapes and in portrait work. The resulting negative space provides interesting contrast. If the model's gaze or head is turned in that direction, the photograph has a more balanced appearance and will usually convey a playful or contemplative mood. If all the action is concentrated on a single side of the photograph, the effect is more unsettling, creating a sense of a disturbance happening just outside the frame:
Titling the camera is another underused trick. It usually doesn't help much in portrait work, as it distorts body proportions and just looks odd; but in landscapes, it is a godsend. In the plains, tilting the camera up lets you to capture more of the sky and less distracting details right next to the photographer. In mountainous terrains or next to large bodies of water, doing the opposite helps capture more architectural detail or more reflections of the sky.
For portraits, it's also good to pay attention to model's posture; the pictures tend to be far more flattering if the model stands up straight and raises their chin up a bit.
The approaches and tools described in this document are by no means exhaustive. There are many other photographic techniques worth learning; for example, there are several methods for conveying motion - timelapses, multiple exposures, and selective blur effects created by panning the camera in tandem with the movement of the subject of the shot. Or, there are multiple optical and postprocessing-based methods for correcting or exaggerating perspective, or for achieving a variety of non-photorealistic looks.
My goal wasn't to create a comprehensive list of every little trick in the book. Instead, I wanted to help the readers discover the joy of photographic experimentation, no matter whether they're carrying a smartphone or a $5,000 professional photo rig. Unlike some other authors, I also wanted to do this without bragging about my own best shots: the examples employed on this page were all shot in the backyard or around the home with minimal prep.
If you are interested in learning from others, I recommend joining a photo community, although I would avoid sites such as Instagram or Flickr. They are centered around view counts, ""like"" counts, and algorithmic feeds, leading to extreme homogenization of content and toxic community dynamics. My favorite site right now is Glass. They charge a modest fee ($30/year), but have a friendly community and give every photographer an equal chance of getting noticed without making it feel that you're participating in a zero-sum game.
You can contact me at lcamtuf@coredump.cx, follow me on Twitter,
or subscribe on Substack.
For other features, check out my homepage.
Your lucky number is: 21909493",3
210,"www.researchgate.net
Checking if the site connection is secure
Enable JavaScript and cookies to continue
www.researchgate.net needs to review the security of your connection before proceeding.
Ray ID:
77460b6a8f45f0b7
Performance & security by
Cloudflare",7
211,"Get full access to this article
Purchase, subscribe or recommend this article to your librarian.
Already a Subscriber?Sign In
References
- Wray, J. Ursula K. Le Guin, the art of fiction no. 221. The Paris Review 206 (Fall 2013); https://www.theparisreview.org/interviews/6253/the-art-of-fiction-no-221-ursula-k-le-guinGoogle Scholar
- Le Guin, U.K. and Wood, S. The Language of the Night: Essays on Fantasy and Science Fiction. Women's Press, 1989.Google Scholar
- Butler, J. Precarious Life: The Powers of Mourning and Violence. Verso, 2003.Google Scholar
- https://web.archive.org/web/20160124020349/http://www.geneon-ent.co.jp/rondorobe/anime/lain/Google Scholar
- Wiberg, W., Taylor, A., and Rosner, D, eds. Interactions 29, 4 (Jul.---Aug. 2022).Google Scholar
- Rogers, Y. HCI theory: Classical, modern, and contemporary. Synthesis Lectures on Human-Centered Informatics 5, 2 (2012), 1--129 Google Scholar
- Fuchsberger, V., Dziabiola, M., Mešić, A., Nørskov, D., and Vetter, R. HCI taking turns. Interactions 28, 5 (2021), 38--43.Google Scholar
Index Terms
Living with soft dragons: between science fiction and human-computer interaction
Comments",5
212,"This is a precarious time in which democracy is being undermined by groups that excel in the creation and distribution of infectious social-media-ready viruses. The attack vectors they employ are designed to exploit network dynamics. These attack vectors include structural manipulations such as nudging, dark advertising, censorship, search engine optimization, and shadow banning; dirty tricks such as impersonating, trolling, leaking, doxing, phishing, and hacking; false information such as misleading narratives, disinformation, hyper-partisan media, astroturfing, deepfakes, and AR/VR; and attack bots such as sleeper bots, botnets, sockpuppets, social bots, roadblock bots, approval bots, and amplifier bots. These attack vectors also exploit cognitive biases in humans—including the mere-exposure effect, confirmation bias, the bandwagon effect, truth bias, ingroup bias, and the spiral of silence—that psychologists and behavioral scientists have identified and cataloged over the years. While cognitive biases may convey certain benefits, they can also make us susceptible to misinformation that raises prejudices, fears, and beliefs that work against flourishing within a functioning democracy.
For democracy to thrive we must develop immunity activators for healthy cognition. The immunity activators discussed in this report include building and using public media platforms, creating new data ownership rules that treat data as personal or public assets, creating realistic tech approaches to fight digital deception that combine computational power with qualitative insight, developing early warning systems to signal when regulatory interventions are needed, facilitating new social media norms that promote prosocial online behaviors, practicing media literacy strategies that go beyond traditional critical thinking skills to increase self-awareness and promote social cohesion, and creating independent platform review bodies that promote transparency.",1
213,"How Wi-Fi spy drones snooped on financial firm
Check your rooftops: Flying gear caught carrying network-intrusion kit
Modified off-the-shelf drones have been found carrying wireless network-intrusion kit in a very unlikely place.
The idea of using consumer-oriented drones for hacking has been explored over the past decade at security conferences like Black Hat 2016, in both the US and in Europe. Naomi Wu, a DIY tech enthusiast, demonstrated a related project called Screaming Fist in 2017. And in 2013, security researcher Samy Kamkar demonstrated his SkyJack drone, which used a Raspberry Pi to take over other drones via Wi-Fi.
Now these sort of attacks are actually taking place.
Greg Linares, a security researcher, recently recounted an incident that he said occurred over the summer at a US East Coast financial firm focused on private investment. He told The Register that he was not involved directly with the investigation but interacted with those involved as part of his work in the finance sector.
The Register corresponded with an individual affiliated with the affected company who corroborated Linares's account and asked not to be identified owing to a non-disclosure agreement and employment concerns.
In a Twitter thread, Linares said the hacking incident was discovered when the financial firm spotted unusual activity on its internal Atlassian Confluence page that originated from within the company's network.
This led the team to the roof, where a 'modified DJI Matrice 600' and a 'modified DJI Phantom' series were discovered
The company's security team responded and found that the user whose MAC address was used to gain partial access to the company Wi-Fi network was also logged in at home several miles away. That is to say, the user was active off-site but someone within Wi-Fi range of the building was trying to wirelessly use that user's MAC address, which is a red flag. The team then took steps to trace the Wi-Fi signal and used a Fluke system to identify the Wi-Fi device.
""This led the team to the roof, where a 'modified DJI Matrice 600' and a 'modified DJI Phantom' series were discovered,"" Linares explained.
The Phantom drone was in fine condition and had a modified Wi-Fi Pineapple device, used for network penetration testing, according to Linares. The Matrice drone was carrying a case that contained a Raspberry Pi, several batteries, a GPD mini laptop, a 4G modem, and another Wi-Fi device. It had landed near the building's heating and ventilation system and appeared to be damaged but still operable.
""During their investigation, they determined that the DJI Phantom drone had originally been used a few days prior to intercept a worker's credentials and Wi-Fi,"" Linares said. ""This data was later hard coded into the tools that were deployed with the Matrice.""
The attackers specifically targeted a limited access network, used by both a third-party and internally, that was not secure due to recent changes at the company
According to Linares, the tools on the drones were used to target the company's internal Confluence page in order to reach other internal devices using the credentials stored there. The attack, he said, had limited success and is the third cyberattack involving a drone he's seen over the past two years.
""The attackers specifically targeted a limited access network, used by both a third-party and internally, that was not secure due to recent changes at the company (e.g. restructuring/rebranding, new building, new building lease, new network setup or a combination of any of these scenarios),"" Linares told The Register.
""This is the reason why this temporary network unfortunately had limited access in order to login (credentials + MAC security). The attackers were using the attack in order to access an internal IT Confluence server that contained other credentials for accessing other resources and storing IT procedures.""
Long-term problem comes to life
Linares said he had worked on a drone project in 2011 to test network attack capabilities and at the time, power, carry weight, and range were limiting factors.
""We revisited it again in 2015 and drone tech had come a long way,"" he said. ""Now in 2022 we are seeing really amazing drone advancements in power, range, and capabilities (for instance, the amazing synchronized drone shows that China puts out are utterly fantastic).""
""This paired with drone payload options getting smaller and more capable – e.g. Flipper Zero kit – ... make viable attack packages that are reasonable to deploy,"" said Linares. ""Targets in fintech/crypto and supply chain or critical third-party software suppliers would make ideal targets for these attacks where an attacker can easily cover their initial operating costs with immediate financial gain or access to more lucrative targets.""
- Russian military uses Chinese drones and bots in combat, over manufacturers' protests
- Boeing wants autonomous flying cabs in US airspace by 2030
- Delivery drone crashes into power lines, causes outage
- Teams of aerial drones might one day help to build houses
While the identity of the attacker has not been disclosed, Linares believes those responsible did their homework.
""This was definitely a threat actor who likely did internal reconnaissance for several weeks, had physical proximity to the target environment, had a proper budget and knew their physical security limitations,"" he said.
Sophos senior threat researcher Sean Gallagher told The Register said the attack described is something people have done ""warwalking"" with Wi-Fi Pineapples or the equivalent.
""You bounce a user off the real network and try to get them to connect to your fake network,"" he explained. ""Honestly, unless there's a very specific bit of targeting going on, this is very low on the threat modeling priority list for most organizations, especially when there are so many other ways to get network access without having a physical presence.""
Still, it might be worth checking the roof for parked or hovering drones now and again. ®",4
215,"Whether they’re rewiring their careers or picking up odd jobs, people in their 70s are reentering the workforce. Traditionally entering an age of retirement, these workers are re-defining the purpose of life’s later decades by taking on new positions, looking for social interaction and augmented income.
Amidst a looming financial crisis and a volatile stock market, many former workers are finding part-time work to ensure financial stability. Kim Chaplain, a specialist adviser for work at the UK’s Centre for Ageing Better, told The Guardian that the organization “suspect[s] the rising cost of living is playing a role.” Bernadette Hempstead of Suffolk, England, receives a small private pension and a state pension as a retired human resource employee. However, those two sources of income were not enough to cover her living expenses, according to an interview with The Guardian. “As things get more expensive, it became impossible. I had also wiped out a lot of my savings during the period I was homeless,” said Hempstead, now a showroom floor assistant who is back on her feet.
The number of people aged 65 or over entering the workforce rose by 173,000 in the first quarter of 2022, according to new figures from the UK’s Centre for Ageing Better. After her husband died, Sue Brown re-entered the workforce just three years after retiring in order to make ends meet. Currently working at a kitchen canteen in Surrey, England, Brown spoke to The Guardian in a feature highlighting how many retirees are finding themselves in similar situations. “I mostly clean the tables and do the washing up, among other duties. It’s a nice place to work and I enjoy being around people,” she said. “I’ve always thrown myself into work, but now it’s keeping me alive too.”
According to the World Economic Forum, an increase in older employees may also be reflective of longer life spans, yielding a need to earn money for a longer period of time. Europeans in particular will spend an average of 36 years in the workforce, according to the European Commission’s data service Eurostat, with people in the Netherlands working an average of 42.5 years. Across European countries, men are estimated to work an average of 38.2 years compared to 33.7 years for women.
Many US retirees are going back to the workplace as well, looking for social interaction and community connections,. Data from the Indeed employment website indicated that 1.7 million formerly retired Americans returned to the workforce a year later.
A generation in its 60s and 70s are returning to the workforce, focusing on new goals and aspirations and combatting a rising cost-of-living. Many companies may have an opportunity to tap into this economically driven, experienced, and motivated demographic as this long-term trend perpetuates.",4
216,"COLUMBIA, S.C. — A little-noticed, slow-moving crisis has been infecting states, counties and towns across the country, leaving governments unable to fulfill their most basic functions.
The cause? A nationwide shortage of public workers.
Pandemic-era labor shortages have been well documented. But the situation for state and local governments is much worse than in the private sector. In fact, the private sector has already recovered the jobs lost early in the pandemic; there are 885,000 more jobs filled in the private industry today than in February 2020.
The public sector is a completely different story. State and local governments are down 647,000 positions on net since February 2020.
Roughly half the decline is in education, causing major disruptions as children return to school amid teacher shortages. But the other half is workers missing from virtually every other government function — paramedics, sanitation workers, child-welfare advocates, heavy-equipment operators, you name it.
This wasn’t supposed to happen. At least, not this time.
The Great Recession left states and municipalities starved of tax revenue, and it took roughly a decade for the public sector to recover the jobs lost. This resulted in worse services for taxpayers and a drag on the private economy. Wary of repeating that experience with the coronavirus, Congress appropriated hundreds of billions of dollars to state and local governments. That way, the thinking went, public-sector functions could more quickly recover.
States also had stronger own-source tax revenue this time around, partly because other federal stimulus programs boosted consumer spending.
So the question is why state and local governments, flush with cash, are still struggling to hire and retain staff.
Part of the answer is the “silver tsunami.” Baby boomers are retiring, and the public-sector workforce tends to skew older than the private-sector workforce, MissionSquare Research Institute managing director Joshua Franzel told me in an interview conducted jointly for a “PBS NewsHour” story.
The bigger challenge, though, involves pay — and governments’ unwillingness to pony up.
Many public-sector jobs already paid less than their private-sector counterparts. Today, in a tight labor market and inflationary environment, private firms are rapidly raising compensation. Government employers have been slower to adapt — partly because of legislative budget cycles or other bureaucratic hurdles, and partly because of public opposition.
“It’s on TV when the city is negotiating with the city manager to give them a 3 percent raise,” said National League of Cities CEO Clarence E. Anthony, describing a “fishbowl effect” that doesn’t exist for most private-employer wage negotiations. “People call in, saying, ‘Why do they deserve an increase? They’re public servants!’”
Governments have offered modest raises that (mostly) haven’t kept up with inflation. Meanwhile, they’ve devoted large chunks of their budget surpluses to tax cuts. As a result, the private-public pay gap is widening, and public workers are being poached.
Franzel said he’d heard of ambulance support staff being lured away to better-compensated jobs at Dunkin’. Others I interviewed described the challenges for filling less glamorous jobs.
“Do you want to come play in the poopy water?” said Bill Davis, utilities director for Richland County, while taking me on a tour of a wastewater treatment plant. “Or do you want to go make 20 percent, 25 percent more and work at Amazon?” (Amazon founder Jeff Bezos owns The Post.)
Some public-sector jobs have also become more unpleasant, stressful or unpopular in recent years, thanks to public harassment or distrust. Think: public health jobs, elections work, teaching, law enforcement. Without substantially higher pay, it has become harder to recruit for these jobs.
Staffing shortages can also beget more staffing shortages. Taking on more work to cover for persistent vacancies can burn out employees. In Richland County, emergency medical technicians and paramedics have struggled at times to take bathroom breaks because of relentless 911 calls, county Emergency Services Department Capt. Winta Adams told me. Elsewhere, corrections officers can’t leave when their shifts end because someone didn’t show up for work and jails have minimum staffing requirements.
So workers quit.
There are two major perks of government jobs that used to make them appealing despite often uncompetitive pay: job security and fewer, more reliable hours. Today, neither of those is a guarantee. There were huge layoffs, after all, early in the pandemic. And now, public employees often work overtime to cover staff shortages.
It’s tempting to dismiss problems in public services over the past year or so as fleeting, driven by temporary labor market weirdness. But if the financial and psychic rewards of these jobs continue to deteriorate, core government functions Americans take for granted might be at risk for many years to come.",4
217,"Natural and expressive human motion generation is the holy grail of computer animation. It is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness. Diffusion models, which have already shown remarkable generative capabilities in other domains, are promising candidates for human motion due to their many-to-many nature, but they tend to be resource hungry and hard to control. In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for the human motion domain. MDM is transformer-based, combining insights from motion generation literature. A notable design-choice is the prediction of the sample, rather than the noise, in each diffusion step. This facilitates the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion and action-to-motion.
The MDM framework has a generic design enabling different forms of conditioning. We showcase three tasks: text-to-motion, action-to-motion, and unconditioned generation. We train the model in a classifier-free manner, which enables trading-off diversity to fidelity, and sampling both conditionally and unconditionally from the same model. In the text-to-motion task, our model generates coherent motions that achieve state-of-the-art results on the HumanML3D and KIT benchmarks. Moreover, our user study shows that human evaluators prefer our generated motions over real motions 42% of the time. In action-to-motion, MDM outperforms the state-of-the-art, even though they were specifically designed for this task, on the common HumanAct12 and UESTC benchmarks.
“A person walks forward, bends down to pick something up off the ground.”
“a person turns to his right and paces back and forth.”
“A person punches in a manner consistent with martial arts.”
Text-to-motion is the task of generating motion given an input text prompt. The output motion is expected to be both implementing the textual description, and a valid sample from the data distribution (i.e. adhering to general human abilities and the rules of physics). In addition, for each text prompt, we also expect a distribution of motions matching it, rather than just a single result.
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person kicks.”
“A person is skipping rope.”
“A person is skipping rope.”
“A person is skipping rope.”
“A person is skipping rope.”
“A person is skipping rope.”
“A person is skipping rope.”
“A person is skipping rope.”
“A person is skipping rope.”
Action-to-motion is the task of generating motion given an input action class, represented by a scalar. The output motion should faithfully animate the input action, and at the same time be natural and reflect the distribution of the dataset on which the model is trained.
(Class) Run
(Class) Warm up
(Class) Sit
(Class) Jump
We also demonstrate completion and editing. By adapting diffusion image-inpainting, we set a motion prefix and suffix, and use our model to fill in the gap. Doing so under a textual condition guides MDM to fill the gap with a specific motion that still maintains the semantics of the original input. By performing inpainting in the joints space rather than temporally, we also demonstrate the semantic editing of specific body parts, without changing the others.
(Blue=Input, Gold=Synthesis)
(Blue=Input, Gold=Synthesis)
@article{tevet2022human, title={Human Motion Diffusion Model}, author={Tevet, Guy and Raab, Sigal and Gordon, Brian and Shafir, Yonatan and Bermano, Amit H and Cohen-Or, Daniel}, journal={arXiv preprint arXiv:2209.14916}, year={2022} }",3
218,"The Toothpaste Argument for Universal Basic Income
The following argument is based on the words of the late Götz Werner, who was a long-time supporter of the concept of unconditional basic income in Germany, who gained a unique understanding of UBI as a successful businessman and billionaire co-founder of the drugstore chain “dm,” and who passed away in 2022.
In an interview given in 2012, Götz Werner said the following to help the audience understand the concept of unconditional basic income:
“If you go shopping, and take a tube of toothpaste from a shelf then you all think, when you go to the checkout, that you are paying for this toothpaste. That is an error. Because the tube of toothpaste that you are taking from the shelf is already paid for, is already paid, else it couldn't be on the shelf. What you are paying at the checkout, is that you are enabling the creation of another tube of toothpaste. That's how you have to see it. Payment is never backwards-oriented. Payment is always forward-oriented. Payment doesn't balance out, but when you are buying something, you are ordering its continued production and sale.”
Hearing Werner’s take on production coming before consumption, which seems entirely obvious, but for some reason isn’t, was a lightbulb for me years ago when I first heard it. Once one properly understands that order of events, it’s easier to recognize the importance of UBI as enabling work instead of rewarding work.
In the same interview, Werner makes this connection explicit:
“What is a fact, is that when we are in this world and we need to live. That is obvious. Self evident, right? And if one wants to live in this world, one needs an income. Or else you can't live… Human beings want to develop. For developing, I need work. For existing I need income. And then I realized, after doing hundreds of job interviews, inevitably, that income isn't the payment for the work, but the prerequisite. That is our mistake in thinking. Our error in reasoning is, that we think, through the work, the income is generated. The reverse is true. Because we have the income, we can work. That has changed the whole view on our company, when we realized, the people that work in our company need an income to be able to afford working with us. There has always been someone who has invested in me. There has always been someone who has given me the prerequisites. There has always been someone, who has put trust in me, and said ""Mr. Werner, show us what you can do"". And exactly the same is what the basic income is saying. The basic income is saying: ""we grant to you, that you can live humbly but with dignity, and now you can show what you can do"". That is actually the request to you.”
The above logic hit me like a lightning bolt when I first heard it. It’s one of those things that just seems so obvious after you hear it, but you never thought of that way before. Essentially, income is not the fruit born from the seed of work, but instead work is the fruit born of the seed of income.
To further support this point, think of what happens when someone accepts a new job, and how common it is for that person to work for two weeks before they get their first paycheck. Because that’s the order of events, we think of the paycheck as paying for the prior two weeks of work, but obviously money was needed to make the work possible. If that person is you, you needed to eat three meals a day for two weeks to make that work possible. You needed to have a roof over your head when you slept, and you needed transportation to get to work. You needed clothes and electricity. You needed your phone. You needed lots of things that income made possible. It was the income that came first. When you get that first paycheck, it’s not paying for what you already did, because you already did it. It’s paying for you to continue doing what you’re now doing. It’s fueling your work. It’s providing you the freedom to continue that work. It’s an unleashing of potential.
Not understanding this is one of the primary reasons people assume that once provided basic income, people will choose to work less, because they see income as a reward for prior work. But when you recognize that income is the fuel that makes work possible, it’s easier to see that basic income will enable far more work for multiple reasons. For one, having basic income means that people can choose unpaid or paid work. It also means that people are more able to choose self-employment. Second, basic income also means that there are a greater number of people with a greater amount of money that they are able to spend at the businesses in their local communities. That money is essentially a form of voting on what work the community wants local businesses to continue doing.
Werner’s realization was that people with basic income could choose to shop at his stores and vote on which products they wanted his chain of stores to keep buying and selling to customers, and that basic income meant his employees were the ones who actually wanted to be there and do that work, and that their paychecks were enabling them the freedom in their lives to really focus on that work and on their own lives.
Realizing that income is forward-oriented instead of backward-oriented also enabled Werner to realize that of course we can afford basic income, because all of the basic needs it would secure already exist. They are already produced. There isn’t a shortage of food. There’s just a shortage of ability to buy food. So just create the money people need to buy food, and provide it to them so they can tell businesses to keep making the food they prefer to eat.
Here again are his own words:
“Now how do you finance it? This is a problem of our understanding of money. The biggest problem, that we think money would have a value as such. Because it is only an illusionary value. The value are the produced and delivered goods and services that we live on. So when if we want to finance something, we don't have to ask, where is the money, but where are the goods, and when you look at our society, and ask, where are the goods, then you will see that we have never been as rich as today. We have never been as rich as today. We have enough goods and services for each person in our society to live a humble but dignified life… We have enough goods and services. I haven't found anyone to tell me, “No, no, no Mr. Werner, listen, there is a shortage.” So, when we have these goods and services, we have to ask ourselves, then why are we affording ourselves poverty? How come we are affording ourselves child poverty? Which is stupid, right? How come we are affording ourselves old age poverty? Which is ungrateful, right? How come we are affording ourselves fear of survival? Why are we putting people under pressure, resulting in hindering them to develop their ""better nature"", in the sense of Schiller. That is our... that is a purely conceptual problem, really. It isn't a problem of financing. Once you have immersed yourself into this matter, I recommend it to everybody, but to convince, you can only do that to yourself… You will see the money doesn't matter. Money you can print. We have experienced that in this financial crisis. You can arbitrarily increase it. The question is, whether the corresponding goods are present. The poverty in our society isn't a precariat problem. It is an elite problem.”
So as you can see, all of this flows naturally from the understanding that what comes first is the resources required to make goods and services possible. That tube of toothpaste already exists when you buy it. Your purchase of it does not in any way impact the fact it was created. If it's the first tube of toothpaste the manufacturer is selling, it's because they first acquired enough money from loans or investors to create it. All your purchase does is function to signal that you want more of that toothpaste made. All that money does is provide you the permission to take that toothpaste home with you and vote for more.
If basic income exists, does that mean there won’t be enough toothpaste for everyone, and that the price of toothpaste will need to go up? Well, likely, most people are already buying the toothpaste they need, and the people who aren’t, who will newly buy toothpaste, are just going to signal to toothpaste producers to make more of it. Scarcity of toothpaste is not a thing, especially in the United States. There’s plenty of toothpaste for everyone and the capacity to produce it. There's plenty of food and electricity and internet too. So let’s just make sure that people can buy it all, and that people can signal to producers to keep making it all, and how much of it to make, and where to distribute it.
The ability to signal what we want producers to keep producing is also why a market with a basic income floor is a market that has better price signals than a market without a basic income floor. The market can’t tell the difference between lack of income and lack of demand. Without basic income, it’s entirely possible for an store to go out of business, not because their customers didn’t like their product or preferred a competitor or competing product, but because their customers lost the ability to afford their product. Markets work better when everyone can vote on what the market should be supplying, not when only rich people can vote. There’s only so much stuff one rich person can buy. Markets produce more and function better for everyone when everyone can vote in them.
Let customers signal to businesses what they want from those businesses, and let workers have the fuel and the freedom to choose which businesses they want to work at or start up, and the price of their labor and their time. Stop worrying about people working less if they can afford not to work, and start worrying about people being unable to afford to keep working if they lack the fuel they need to work.
""Payment is never backwards-oriented. Payment is always forward-oriented.""
If you still doubt that income comes before work, consider all forms of unpaid work too. How's unpaid work possible if income comes after work? Unpaid work is only possible if one already has sufficient access to resources to make it possible. Volunteers can afford to be volunteers. Income independent of volunteer work is what makes volunteering possible. Basic income would therefore lead to a lot more of that too.
Finally, if you'd like some evidence to back all this up too, one study I find particularly interesting is one that looked at the impacts of financial constraint on worker productivity by varying payment timing and found that workers who had just received cash became more productive afterward, increasing their output and also making fewer unintentional mistakes.
""The cash infusion leads workers to reduce their financial concerns by immediately paying off debts and buying household essentials. Subsequently, they become more productive at work: their output increases by 7.1% (0.12 SDs), and they make fewer costly, unintentional mistakes. Workers with more cash-on-hand thus not only work faster but also more attentively, suggesting improved cognition. These effects are concentrated among more financially constrained workers.""
In other words, making sure people have cash first leads to more and better work.
So that's what I call the Toothpaste Argument for Basic Income, and I highly recommend watching the entire interview with Götz Werner that inspired it.
Did you enjoy this article? Please subscribe to my blog (it's free!) and also consider making a small monthly pledge in support of my ongoing UBI advocacy. You can also buy my book to learn more about the affordability of universal basic income.
Special thanks to: Gisele Huff, Haroon Mokhtarzada, Steven Grimm, Katie Moussouris, Tricia Garrett, Zack Sargent, David Ruark, Larry Cohen, Matthew Cheney, Frederick Weber, Patrick Brown, CanadayVibes , Kerry Bosworth, Laurel gillespie, Dylan J Hirsch-Shell, Tom Cooper, Michael Tinker, Robert Collins, Daryl Smith, Joanna Zarach, Justin Walsh, ace bailey, Daragh Ward, Albert Wenger, Andrew Yang, John Steinberger, Bridget I Flynn, Peter T Knight, David Ihnen, LT, Myles McLane, Max Henrion, Elizabeth Corker, Reid Rusonik, Gray Scott, Gerald Huff, Albert Daniel Brockman, Michael Honey, Natalie Foster, Joe Ballou, Chris Rauchle, Arjun , chris heinz, Juro Antal, Herb, Justin Seifert, Jodi Sarda, Sharon Woodhouse, Rosa Tran, Deanna McHugh, Ryan Ash-Miller, miki, Ken Warner, Adam Parsons, bradzone, Lee Lor, Senang Diri, Akber Khan, John Sullivan, Kurt Bunker, Team TJ, Yang Deng, Elliot Lee, Yan Xie, Marie janicke, Iggy C, engageSimply - Judy Shapiro, AYFAQ.com , Phuong Truong, Tim, Warren J Polk, Timothy P O'Connor, Jeffrey Emmett, Stephen Castro-Starkey, Oliver Bestwalter, Kev Roberts, Walter Schaerer, Brian Peiris, Loren Sickles, anti666, Eric Skiff, Thomas Welsh, Kai Wong, Laura Ashby, and all my other monthly patrons for their support.
Read UBI Guide in your inbox
Subscribe to get each new article via email.",4
219,"WIP! WIP! WIP!
This repo is a work in progress and far from release-worthy. Please don't make your own boards and expect any kind of support. However, it might reach a stable point sometime in the future (as of 2019-01).
Kilsyth: ECP5 FPGA + FT60x FIFO
Kilsyth is a piece of hardware that contains an FPGA (Lattice ECP5) and a SuperSpeed USB 3.0 FIFO-bridge (FT60x). The goal is to provide a platform to be able to transfer high speed data transfers between a PC and an FPGA. The FPGA in turn can do whatever - e.g. interface with SDR, video capture, act as a logic analyzer.
Current status
It's still in the early bring-up phase. Initial verification shows that it actually seems to work.
RevA
RevA is the first prototype and has been designed and built.
- It doesn't smoke when powered up.
- USB-C connector works but is messy to solder.
- Loopback test is almost in place. Using the proprietary driver, high bi-directional speeds are achieavable (> 98MB/s in both directions simultaneously). Just need to figure out some off-by-one errors...
- Bootloader to store a custom bitstream on the flash.
Errata:
- C9 is not a GPIO on ECP5 F12 and some other variants. To get the LED working put a jumper on pin 31 and 33 on the Wide connector.
- FT_CLK is not routed to a clock pin. Can be fixed with a bodge wire! Remove R50 and R36, swap their paths.
- JTAG connector has a funky footprint on the PCB because CCW vs Odd/Even pinout on the symbol vs footprint. But the PCB silk screen is accurate so don't worry - it's just a stupid pinout.
- Need to add pull-ups for the SPI flash.
RevB
Ideas for RevB are still being collected. Feel free to suggest changes in an issue.
- Add support for reversible USB-C connector using PI5USB30213A.
Software usage (TODO)
Requires a patched migen and a patched ftdi library.. Nasty, I know, sorry.
Help: $ python -m software.kilsyth -h Run blinky: $ python -m software.kilsyth run blinky
Contact
Reach out to @kbeckmann on Twitter or IRC/Freenode.",1
220,"Abstract
Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers.
Introduction
The retina is the only tissue in the body where neural and vascular tissue can be visualized simultaneously in a non-invasive manner. Ophthalmologists have been doing so since the ophthalmoscope was introduced into clinical practice in the mid 1800s1. It has also been increasingly recognized that retinal biomarkers may map effectively to systemic indices of healthy ageing and disease2,3,4,5,6. Examples of these oculomics-based findings include vascular tortuosity and arteriolar narrowing for cardiovascular disease, and retinal cell layer changes for neurological disorders7,8,9,10,11.
Relationships between retinal morphology and systemic health have traditionally been evaluated using statistical modelling, such as multivariable regression. However, such techniques may have limited incremental value when leveraged on very large datasets and for complex data12,13. As data availability has increased, and mathematical models have improved, the success of deep learning in ophthalmic disease classification in the research setting has been striking14,15,16,17,18. Deep neural networks, which process input images by applying mathematical operations to connected nonlinear units in multiple layers, largely avoid manual feature engineering, and are able to derive previously hidden patterns in large volumes of data19.
The discovery of quantitative relationships between retinal appearance and systemic pathophysiology readily aligns with pre-established conceptions of microvascular and degenerative tissue-level insults20. However, deep learning has shown that these algorithms demonstrate capability in tasks which were not previously thought possible21. Harnessing this power, new insights into relationships between retinal structure and systemic pathophysiology could expand existing knowledge of disease mechanisms. A study by Poplin et al. demonstrated a deep-learning learning algorithm which could accurately predict cardiovascular risk factors from fundus photos22; More surprising to ophthalmologists was the successful prediction of demographic information such as age and gender, the latter with an area under the curve (AUC) of 0.97. Here, the physiologic cause and effect relationships are not readily apparent to domain experts21. Predicting gender from fundus photos, previously inconceivable to those who spent their careers looking at retinas, also withstood external validation on an independent dataset of patients with different baseline demographics23. Although not likely to be clinically useful, this finding hints at the future potential of deep learning for the discovery of novel associations through unbiased modelling of high-dimensional data.
We previously reported on the ability of physicians to create automated machine learning (AutoML) models for medical image analysis24. Since that proof of concept, AutoML platforms have advanced significantly, with multiple employing code free deep learning (CFDL). Herein, we demonstrate AutoML as a tool for automated discovery of novel insights by performing sex classification from retinal fundus photos, and comparing its performance to the bespoke deep learning model by Poplin et al22.
Results
CFDL model results
The CFDL model had an AUROC and AUPRC of 0.93 and 0.94 respectively (Table 1). Overall sensitivity (recall), specificity, PPV (precision), and ACC were 88.8%, 83.6%, 87.3%, and 86.5% respectively (Fig. 1). Genetic sex was discordant from reported sex in one validation set image, and this image was incorrectly predicted by the model; that is the model predicted sex consistent with genetic sex in this case (Table S1). To evaluate reproducibility and address varying performance of deep learning algorithms involving random seed initiation, we retrained the model to identical specifications, and found similar performance with an AUC of 0.93.
External validation
External validation was performed on the Moorfields dataset. This dataset differed from the UK Biobank development set with respect to both fundus camera used, and in sourcing from a pathology-rich population at a tertiary ophthalmic referral center. The resulting sensitivity, specificity, PPV and ACC were 83.9%, 72.2%, 78.2%, and 78.6% respectively.
Presence of foveal pathology
To evaluate the influence of foveal pathology on the performance of the CFDL model, we subgrouped the Moorfields external validation dataset into fundus photos with (n = 108) and without (n = 144) foveal pathology (Table 2). The model classified sex correctly in 85.4% of patients without foveal pathology, a population more similar to the largely health UK Biobank population, compared to 69.4% in patients with foveal pathology. Logistic regression showed that presence of foveal pathology was a significant factor in model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Sex was not associated with presence of foveal pathology (p = 0.94). This suggests that the fovea may be a salient region of fundus photographs for the neural network’s sex classification performance. Region attribution saliency maps suggest the optic nerve and vascular arcades as additional important input regions for the model’s prediction (Fig. 2).
Ungradable UK biobank images
Consensus ungradable images (n = 714), which were formerly removed from the UK Biobank validation dataset were separately processed by the model as an experimental adjunct batch prediction. The resulting sensitivity, specificity, PPV and accuracy were 82.6%, 71.2%, 75.2%, and 77.0% respectively.
Discussion
Our results demonstrate robust overall performance of the CFDL model for predicting sex from retinal fundus photos. The AUROC of 0.93 from this framework, which does not require coding expertise, suggests significant capability of the CFDL platform for this task. Our code-free model’s performance is comparable with the Poplin et al. model AUROC of 0.97, which was designed and tuned by machine learning experts (Table 1). Our model was trained on a similar (UK Biobank), albeit significantly smaller dataset, as it did not include the additional 1.5 + million EyePACS fundus photos which Poplin et al. also utilized for training.
To our knowledge, two other studies have attempted to perform this image classification task. Yamashita et al. performed logistic regression on several features that were identified to be associated with sex. These features included papillomacular angle, retinal vessel angles and retinal artery trajectory25. They achieved an AUROC of 0.78, which further underscores the limitations of a classical machine learning approach, utilizing human-identified features for such novel tasks. Deep learning, even utilizing our CFDL approach, seems to outperform manual feature engineering significantly. Various studies have shown retinal morphology differences between the sexes, including retinal and choroidal thickness26,27,28. Others have demonstrated variation of ocular blood flow and have suggested the effect of sex hormones, but thus far, consensus is lacking29,30. The coder-engineered deep learning model developed by Dieck et al. for this task, which also included an image preprocessing step, demonstrated an accuracy of 82.9%, which was lower than our automated code-free approach31. The retinal features apparent to domain experts for this task may go unanswered, as the power of deep learning in integrating population-level patterns from billions of pixel-level variations is impossible for humans to match.
Performance of our model was slightly worse with external validation on the Moorfields dataset, which is typical when deep learning models are evaluated with datasets dissimilar from their training data distribution32,33. Specifically, the Moorfields dataset was obtained from a tertiary referral center, and 42.9% of the fundus photos contained foveal pathology. In eyes without foveal pathology, the external validation accuracy was within 1.5% of the Biobank validation set. The worse performance in pathologic eyes suggests the significance of the fovea for sex prediction, and was similarly demonstrated in the attention maps of Poplin et al. The region-based saliency maps we generated suggest that the optic nerve and vascular arcades are also regions of importance (Fig. 2). In the study by Poplin et al., when subgrouped for diabetic retinopathy (DR) presence, their model similarly trended towards worse performance for pathologic images compared with healthy controls. Furthermore, the ophthalmologists in that study “repeatedly reported highlighting of the macula for the gender predictions” when interpreting the attention maps22. These findings highlight the importance of considering machine learning performance only in context of the specific training and evaluation datasets utilized. This is especially critical for our task, when the salient features of an input image are unclear to domain experts.
Ungradable images from the UK Biobank validation dataset were labeled as such by retina specialists to the guidelines of lacking adequate visibility of the macula, optic nerve, and vascular arcades (Table S2). However, those images demonstrated only a slight reduction in model performance. Furthermore, the model shows similar salient regions in ungradable input images as in gradables (Fig. 2). This suggests that the model is sensitive to signal in poor quality images from subtle pixel-level luminance variations, which are likely indifferentiable to humans. This finding underscores the promising ability of deep neural networks to utilize salient features in medical imaging which may remain hidden to human experts.
Through characterization of high-dimensional data, our findings suggest that deep learning will be a useful tool for the exploration of novel disease and biomarker associations. Clinician driven research, particularly through the use of AutoML, has the potential to move this field forward. Crucially, AutoML as a platform does not fully automate the process of machine learning. Data preparation remains an essential manual step. As demonstrated by population differences in our external validation dataset, tasks such as equitable and representative acquisition, cleaning, and subgrouping of datasets remain important factors for the production of useful models. Clinicians are uniquely positioned to understand both the complexities of the clinical data, and the use-cases for the design of clinically relevant production algorithms.
While our deep learning model was specifically designed for the task of sex prediction, we emphasize that this task has no inherent clinical utility. Instead, we aimed to demonstrate that AutoML could classify these images independent of salient retinal features being known to domain experts, that is, retina specialists cannot readily perform this task. We intended to show that our framework’s performance may be comparable to state of the art algorithms designed for the same task by coders. This portends for the capacity of AutoML, utilized by clinician use-case experts, to design models for tasks where specific retinal features have not been categorized. Examples of such use-cases include cardiovascular and neurological disease characterization from retinal photos.
Limitations
Our study had several limitations. The design of the CFDL model was inherently opaque due to the framework’s automated nature with respect to model architecture and hyperparameters. While this opacity is not unique to CFDL, there is potential to further reduce ML explainability due to lack of insight of model architectures and parameters employed. Although we compared our performance to other models via AUROC, we were unable to compare performance using clinically relevant metrics such as sensitivity and specificity, as these were not provided by the authors of the other studies34. The UK Biobank dataset, composed of a generally healthy Caucasian population, was not fully representative of the general UK population, and demonstrates potential for algorithmic bias35,36,37. Although we attempted to address this with an external validation population with a higher prevalence of pathology, our patient level data was limited and did not include additional demographic information. Since both datasets were from UK populations and de-identified, there is the potential of overlap at the patient level.
Through our investigations of predicting other novel systemic signals from fundus photos, we noted several inherent limitations of the CFDL platform. Utilizing buckets of varying range, which were necessary due to lack of support for continuous variable prediction, we were unable to successfully predict age. Experiments to predict smoking status resulted in models with significantly lower AUC (0.64) as compared with Poplin et al. (0.71)22. We have engaged the platform development team, and aim to repeat our experiments as new platform features are released.
Conclusion
We demonstrate clinician-driven design of a deep learning sex classification model from retinal fundus photographs, and comparable performance to the same task in a landmark study. In contrast to the latter model designed by expert engineers, our model was created by clinicians without coding. Our external validation on a population with high levels of foveal pathology suggests that the foveal region is important for this task. This demonstrates AutoML as a tool for novel insight discovery for medical imaging by its clinician end users. Although ophthalmologists may continue to ponder what these deep learning models are “looking at”, our study demonstrates the robust potential of CFDL to characterize images independent of experts’ knowledge of contributing features, and its ability to democratize access to deep learning.
Methods
Participants and data
This work utilized two datasets. For deep learning model development, we used the UK Biobank dataset, which is an observational study in the United Kingdom that began in 2006 and has recruited over 500,000 participants—85,262 of which received eye imaging38. Eye imaging was obtained at 6 centers in the UK and comprises over 10 terabytes of data39. Participants volunteered to provide data including other medical imaging, laboratory results, and detailed subjective questionnaires. Consent was provided by each participant, and the study was approved by the North West Multi-Centre Research Ethics Committee. Detailed protocols may be located at www.ukbiobank.ac.uk. Retinal imaging was obtained with a Topcon OCT-1000 MKII. Each capture consisted of optical coherence tomography and a paired 45-degree retinal fundus photograph. The UK Biobank fundus photo dataset of 175,825 images was split chronologically to train, tuning, and validation sets (Table 3). The train/tuning and validation sets contained 53.6% and 56.0% reported women respectively. For temporal validation, chronologic splits were performed to simulate model performance on the validation set in a manner which would align with a prospective trial40; that is a model trained on the first chronological period of data (training dataset), and then evaluated on the subsequent chronological period of data (validation dataset). Participant level splits were preserved throughout—each participant’s left, right, and repeat photos were never split between image subsets.
For external validation, we utilized an anonymized clinical dataset convenience sampled from Moorfields Eye Hospital of 400 adult patients. These patients received 45-degree fundus photography with Topcon OCT-2000 in December 2019. In order to obtain a representative dataset of all patients presenting from that time period, no other filters were applied. Both datasets consisted of 50% left and 50% right eyes. Average age in the external validation dataset was 64.0 as compared with the UK Biobank validation dataset average of 55.7 (Table 3). Input of the external validation dataset into Cloud AutoML was through the Moorfields Eye Hospital Research Informatics Strategy Data Platform, a secure cloud-based infrastructure facilitating storage and processing of anonymized clinical data. Project-specific approval from local information governance was granted following submission of a Cloud AutoML data privacy impact assessment and separate dataset-specific treatment standard operating procedure. Research and development approval by the Institutional Review Board at Moorfields was obtained (ROAD17/031). Local and national research opt-outs were queried, and the corresponding patients were excluded. All methods were performed in accordance with the relevant guidelines and regulations.
Participants in the UK Biobank study have provided written informed consent. The external validation set is part of a retrospective, non-interventional study on de-identified data. National and local opt-out guidance was followed for anonymized datasets, Moorfields information governance waived the requirement for informed consent accordingly.
Data processing and labeling
The gender variable, as described by the UK Biobank, was acquired from the central registry at recruitment, but in some cases was updated by the participant. Therefore, this field may contain a mixture of NHS recorded gender and self-reported gender. Genetic sex in the UK Biobank was determined by genotyping performed at Affymetrix3 Inc. with quality control of the data at the Wellcome Trust Centre for Human Genetics.
Ungradable images were removed from both validation datasets. De-identified images were assessed for gradability by two retina specialists masked to patient demographics (E.K., H.K.). Gradability was defined as a field of view ensuring adequate visibility of the vascular arcades, macula, and optic nerve, and sufficient image quality to exclude microaneurysm sized features. Any disagreements were resolved via in-person discussion. In cases where agreements could still not be resolved (n = 122), a gradability algorithm, described in a model card (Table S2), was used to adjudicate disagreements, with 70 of the disagreed images being classified as ungradable41. After ungradables were removed, 252 Moorfields images remained for external validation. Ungradable rate was 35.7% and 32.2% in the UK Biobank validation and Moorfields datasets respectively. Moorfields images were also graded for presence of foveal pathology. This was defined as any retinal lesion which extended into the central one disc diameter around the fovea. Examples of foveal lesions included but were not limited to macular holes, microaneurysms, RPE tears, and pigment atrophy (Fig. 3).
Model training
Our deep learning model was trained using code-free deep learning (CFDL) with the Google Cloud AutoML platform. As described and demonstrated in a supplemental video of our prior work24, the platform provides a graphical user interface (GUI) for data upload, labeling, and model training. Alternatively, the CFDL platform provides the option of image upload via shell-scripting utilizing a .csv spreadsheet containing labels with associated cloud storage locations. We utilized the latter upload approach for the efficient management of our large datasets. Automated machine learning was then employed, which entails neural architecture search and hyperparameter tuning. Training was performed with maximum allowable cloud graphics processing unit (GPU) hours, and early stopping was enabled, which automatically terminated training when no further model improvement was noted after 581 node-hours. Each node hour represents eight cloud nodes used in parallel, and each node is equivalent to a NVIDIA Tesla V100 GPU. XRAI region based attribution saliency maps were generated from an edge optimized version of the model utilizing the AutoML explainable AI framework42.
Statistical analysis
Statistical analysis was performed with Microsoft Excel and Stata. The model was evaluated at a softmax confidence threshold of 0.5. Area under the precision recall curve (AUPRC) was provided by the platform, and area under the receiver operating characteristic curve (AUROC) was obtained via shell-scripting in order to enable comparison with other reported models. We manually calculated sensitivity, specificity, positive predictive value (PPV), and accuracy (ACC) from confusion matrices provided by the CFDL platform (Tables S3, S4). The former four metrics were calculated with respect to prediction of female sex. For subgroup analysis of model performance on images with foveal pathology, a chi squared test was performed.
Data availability
The primary dataset that supports the findings of this study is available, with restrictions, from UK Biobank. The external validation data that support the findings of this study are available on request from the corresponding author PAK. The data are not publicly available due to containing information that could compromise research participant privacy/consent.
References
Keeler, C. R. 150 years since Babbage’s ophthalmoscope. Arch. Ophthalmol. 115, 1456–1457 (1997).
Coppola, G. et al. Optical coherence tomography in Alzheimer’s disease: A meta-analysis. PLoS ONE 10, 0134750 (2015).
MacGillivray, T. J. et al. Retinal imaging as a source of biomarkers for diagnosis, characterization and prognosis of chronic illness or long-term conditions. Br. J. Radiol. 87, 20130832 (2014).
Wendland, J. P. The relationship of retinal and renal arteriolosclerosis in living patients with essential hypertension. Am. J. Ophthalmol. 35, 1748–1752 (1952).
Wong, T. Y. et al. The prevalence and risk factors of retinal microvascular abnormalities in older persons: The Cardiovascular Health Study. Ophthalmology 110, 658–666 (2003).
Normando, E. M. et al. The retina as an early biomarker of neurodegeneration in a rotenone-induced model of Parkinson’s disease: Evidence for a neuroprotective effect of rosiglitazone in the eye and brain. Acta Neuropathol. Commun. 4, 86 (2016).
McGeechan, K. et al. Prediction of incident stroke events based on retinal vessel caliber: A systematic review and individual-participant meta-analysis. Am. J. Epidemiol. 170, 1323–1332 (2009).
den Haan, J., Verbraak, F. D., Visser, P. J. & Bouwman, F. H. Retinal thickness in Alzheimer’s disease: A systematic review and meta-analysis. Alzheimers. Dement. 6, 162–170 (2017).
Ko, F. et al. Association of retinal nerve fiber layer thinning with current and future cognitive decline: A study using optical coherence tomography. JAMA Neurol. 75, 1198–1205 (2018).
Thomson, K. L., Yeo, J. M., Waddell, B., Cameron, J. R. & Pal, S. A systematic review and meta-analysis of retinal nerve fiber layer change in dementia, using optical coherence tomography. Alzheimers. Dement. 1, 136–143 (2015).
Cheung, C. Y. et al. Retinal vascular fractal dimension and its relationship with cardiovascular and ocular risk factors. Am. J. Ophthalmol. 154, 663-674.e1 (2012).
Mutlu, U. et al. Association of retinal neurodegeneration on optical coherence tomography with dementia: A population-based study. JAMA Neurol. 75, 1256–1263 (2018).
Owen, C. G. et al. Retinal vasculometry associations with cardiometabolic risk factors in the European prospective investigation of cancer-norfolk study. Ophthalmology 126, 96–106 (2019).
De Fauw, J. et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med. 24, 1342–1350 (2018).
Schlegl, T. et al. Fully automated detection and quantification of macular fluid in OCT using deep learning. Ophthalmology 125, 549–558 (2018).
Bojikian, K. D., Lee, C. S. & Lee, A. Y. Finding glaucoma in color fundus photographs using deep learning. JAMA Ophthalmol. https://doi.org/10.1001/jamaophthalmol.2019.3512 (2019).
Ting, D. S. W. et al. Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes. JAMA 318, 2211–2223 (2017).
Gulshan, V. et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA 316, 2402–2410 (2016).
Hinton, G. E., Osindero, S. & Teh, Y.-W. A fast learning algorithm for deep belief nets. Neural Comput. 18, 1527–1554 (2006).
Wagner, S. K. et al. Insights into systemic disease through retinal imaging-based oculomics. Transl. Vis. Sci. Technol. 9, 6–6 (2020).
Korot, E. et al. Will AI replace ophthalmologists?. Transl. Vis. Sci. Technol. 9, 2–2 (2020).
Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. Nat. Biomed. Eng. 2, 158–164 (2018).
Ting, D. S. W. & Wong, T. Y. Eyeing cardiovascular risk factors. Nat. Biomed. Eng. 2, 140–141 (2018).
Faes, L. et al. Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study. Lancet Digit. Health 1, e232–e242 (2019).
Yamashita, T. et al. Factors in color fundus photographs that can be used by humans to determine sex of individuals. Transl. Vis. Sci. Technol. 9, 4–4 (2020).
Ooto, S., Hangai, M. & Yoshimura, N. Effects of sex and age on the normal retinal and choroidal structures on optical coherence tomography. Curr. Eye Res. 40, 213–225 (2015).
Adhi, M., Aziz, S., Muhammad, K. & Adhi, M. I. Macular thickness by age and gender in healthy eyes using spectral domain optical coherence tomography. PLoS ONE 7, 37638 (2012).
Lamparter, J. et al. Association of ocular, cardiovascular, morphometric and lifestyle parameters with retinal nerve fibre layer thickness. PLoS ONE 13, e0197682 (2018).
Cascio, C., Deidda, I., Russo, D. & Guarneri, P. The estrogenic retina: The potential contribution to healthy aging and age-related neurodegenerative diseases of the retina. Steroids 103, 31–41 (2015).
Schmidl, D., Schmetterer, L., Garhöfer, G. & Popa-Cherecheanu, A. Gender differences in ocular blood flow. Curr. Eye Res. 40, 201–212 (2015).
Dieck, S. et al. Factors in color fundus photographs that can be used by humans to determine sex of individuals. Transl. Vis. Sci. Technol. 9, 8–8 (2020).
Collins, G. S. et al. External validation of multivariable prediction models: A systematic review of methodological conduct and reporting. BMC Med. Res. Methodol. 14, 40 (2014).
Steyerberg, E. W. & Harrell, F. E. Jr. Prediction models need appropriate internal, internal-external, and external validation. J. Clin. Epidemiol. 69, 245–247 (2016).
Faes, L. et al. A clinician’s guide to artificial intelligence: How to critically appraise machine learning studies. Transl. Vis. Sci. Technol. 9, 7–7 (2020).
Kusner, M. J. & Loftus, J. R. The long road to fairer algorithms. Nature 578, 34–36 (2020).
Kelly, C. J., Karthikesalingam, A., Suleyman, M., Corrado, G. & King, D. Key challenges for delivering clinical impact with artificial intelligence. BMC Med. 17, 195 (2019).
Barocas, S. & Selbst, A. D. Big data’s disparate impact. Calif. L. Rev. https://doi.org/10.2139/ssrn.2477899 (2016).
Sudlow, C. et al. UK biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age. PLoS Med. 12, 1001779 (2015).
Keane, P. A. et al. Optical coherence tomography in the UK Biobank study: Rapid automated analysis of retinal thickness for large population-based studies. PLoS ONE 11, e0164095 (2016).
Liu, X. et al. A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: A systematic review and meta-analysis. Lancet Digit. Health 1, e271–e297 (2019).
Sendak, M. P., Gao, M., Brajer, N. & Balu, S. Presenting machine learning model information to clinical end users with model facts labels. NPJ Digit. Med. 3, 41 (2020).
Kapishnikov, A., Bolukbasi, T., Viégas, F. & Terry, M. XRAI: Better Attributions Through Regions. arXiv [cs.CV] (2019).
Acknowledgements
This research has been conducted using the UK Biobank Resource under application number 36741. This work was supported by Springboard (190016A (EK)) and Career Development (190028A (PAK)) Awards from Moorfields Eye Charity, a UK Research & Innovation (UKRI) Future Leaders Fellowship (MR/T019050/1 (PAK)), and a UK National Institute for Health Research (NIHR) Clinician Scientist Award (NIHR-CS–2014-12-023 (PAK)). The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, or the Department of Health. We would like to thank Ryan Poplin and Yun Liu for their thoughtful review and comments on the manuscript.
Ethics declarations
Competing interests
EK is a consultant for Google Health. PAK has received speaker fees from Heidelberg Engineering, Topcon, Haag-Streit, Allergan, Novartis and Bayer. PAK has served on advisory boards for Novartis and Bayer, and is a consultant for DeepMind, Roche, Novartis and Apellis. KB has received research grants from Novartis, Bayer. Heidelberg and Roche. KB has received speaker fees from Novartis, Bayer, TopCon, Heidelberg, Allergan, Alimera. KB is a consultant for Novartis, Bayer and Roche. AK is a consultant to Aerie, Allergan, Novartis, Google Health, Reichert and Santen. All other co-authors have no competing interests to declare.
Additional information
Publisher's note
Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Supplementary Information
Rights and permissions
Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
About this article
Cite this article
Korot, E., Pontikos, N., Liu, X. et al. Predicting sex from retinal fundus photographs using automated deep learning. Sci Rep 11, 10286 (2021). https://doi.org/10.1038/s41598-021-89743-x
Received:
Accepted:
Published:
DOI: https://doi.org/10.1038/s41598-021-89743-x
This article is cited by
-
Estimation of best corrected visual acuity based on deep neural network
Scientific Reports (2022)
-
Evaluating an automated machine learning model that predicts visual acuity outcomes in patients with neovascular age-related macular degeneration
Graefe's Archive for Clinical and Experimental Ophthalmology (2022)
Comments
By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.",3
221,"This Controversial Artist Matches Influencer Photos With Surveillance Footage
‘The Followers’ uses artificial intelligence and facial-recognition technology to comment on the surveillance state
It’s an increasingly common sight on vacation, particularly in tourist destinations: An influencer sets up in front of a popular local landmark, sometimes even using props (coffee, beer, pets) or changing outfits, as a photographer or self-timed camera snaps away. Others are milling around, sometimes watching. But often, unbeknownst to everyone involved, another device is also recording the scene: a surveillance camera.
Belgian artist Dries Depoorter is exploring this dynamic in his controversial new online exhibit, The Followers, which he unveiled last week. The art project places static Instagram images side-by-side with video from surveillance cameras, which recorded footage of the photoshoot in question.
pic.twitter.com/1hkE0Ga2aO— Dries Depoorter (@driesdepoorter) September 12, 2022
On its face, The Followers is an attempt, like many other studies, art projects and documentaries in recent years, to expose the staged, often unattainable ideals shown in many Instagram and influencer photos posted online. But The Followers also tells a darker story: one of increasingly worrisome privacy concerns amid an ever-growing network of surveillance technology in public spaces. And the project, as well as the techniques used to create it, has sparked both ethical and legal controversy.
To make The Followers, Depoorter started with EarthCam, a network of publicly accessible webcams around the world, to record a month’s worth of footage in tourist attractions like New York City’s Times Square and Dublin’s Temple Bar Pub. Then he enlisted an artificial intelligence (A.I.) bot, which scraped public Instagram photos taken in those locations, and facial-recognition software, which paired the Instagram images with the real-time surveillance footage.
Depoorter calls himself a “surveillance artist,” and this isn’t his first project using open-source webcam footage or A.I. Last year, for a project called The Flemish Scrollers, he paired livestream video of Belgian government proceedings with an A.I. bot he built to determine how often lawmakers were scrolling on their phones during official meetings.
“The idea [for The Followers] popped in my head when I watched an open camera and someone was taking pictures for like 30 minutes,” Depoorter tells Vice’s Samantha Cole. He wondered if he’d be able to find that person on Instagram.
Public reaction to the project has been mixed; some have praised Depoorter for drawing attention to the modern surveillance state, while others have criticized what they see as a flippant use of potentially harmful technology: showing how easy it is to access livestream footage and facial-recognition software. Many of these critics encouraged the artist never to make the A.I. he developed public.
Please don't ever release this, make it publicly available or sell it to someone who doesn't need it.— Josh W (@welfordian) September 12, 2022
“Art does many great things, including stir generative discussions and debate about life as we know it,” Francesca Sobande, a digital media scholar at Cardiff University, tells Input’s Chris Stokel-Walker. “However, art projects can also have harmful effects. Such harms should not be brushed aside in discussions about art and the technology that is sometimes central to it.”
Depoorter tells Hyperallergic’s Rhea Nayyar that he won’t be releasing the software. Still, he says, “I’m only one person. I have limited access to data, cameras … Governments can take this to another level.”
The Followers has also hit some legal snags since going live. The project was originally up on YouTube, but EarthCam filed a copyright claim, and the piece has since been taken down. Depoorter tells Hyperallergic that he’s attempting to resolve the claim and get the videos re-uploaded. (The project is still available to view on the official website and the artist’s Twitter).
Depoorter hasn’t replied directly to much of the criticism, but he tells Input he wants the art to speak for itself. “I know which questions it raises, this kind of project,” he says. “But I don’t answer the question itself. I don’t want to put a lesson into the world. I just want to show the dangers of new technologies.”",3
222,"186 books — 157 voters
Goodreads helps you keep track of books you want to read.
Start by marking “Hope in the Dark” as Want to Read:
Enlarge cover
Open Preview
See a Problem?
We’d love your help. Let us know what’s wrong with this preview of Hope in the Dark by Rebecca Solnit.
Not the book you’re looking for?
Preview — Hope in the Dark by Rebecca Solnit
Hope in the Dark
by
4.01 · Rating details · 8,756 ratings · 1,170 reviews
With Hope in the Dark, Rebecca Solnit makes a radical case for hope as a commitment to act in a world whose future remains uncertain and unknowable. Drawing on her decades of activism and a wide reading of environmental, cultural, and political history, Solnit argues that radicals have a long, neglected history of transformative victories, that the positive consequences of ...more
Paperback, 192 pages
Published June 16th 2005 by Canongate Books
(first published April 1st 2004)
Friend Reviews
To see what your friends thought of this book, please sign up.
Reader Q&A
To ask other readers questions about Hope in the Dark, please sign up.
Popular Answered Questions
Books for Post-Election Understanding
Books to Read under the Trump Administration
1,147 books — 496 voters
More lists with this book...
Community Reviews
Showing 1-30
Average rating 4.01 ·
· 8,756 ratings · 1,170 reviews
|
Start your review of Hope in the Dark
Nov 25, 2016 Oriana marked it as didntfinish-yet
I'm a big fan of Rebecca Solnit — deep and moving essayist, unapologetic feminist and activist, inventor of the term ""mansplaining,"" all-around brilliant gal. I cannot recommend strongly enough that you follow her on FB, where she is in the midst of a tireless campaign of resistance, deligitimizing our Horror-in-Chief, and spreading action steps so we can all do the same.
And I'm editing this part of my review, because I do not wish to stop anyone from either reading this book or from feeling ho ...more
And I'm editing this part of my review, because I do not wish to stop anyone from either reading this book or from feeling ho ...more
Jan 28, 2017 Lea rated it it was ok · review of another edition
Shelves: politics, 2017, read-in-english, non-fiction, usa, sociology
I found this a rather disappointing and disjointed book, that depressed me more than it gave me hope. Maybe because it was written pre-Trump and a lot of the hopeful thing she says just seem more and more naive with each day. Yes, she gives some examples of hope campaigning and fighting for the right things can change and move, and how we often can't see the impact our positive actions have right away. But overall it was just a reminder of how big the beast is we're up against. Especially when s ...more
Oct 11, 2018 Michael rated it it was amazing
Written in response to the Bush administration’s invasion of Iraq, but rereleased in early 2016 in the wake of America’s deteriorating political climate, Rebecca Solnit’s Hope in the Dark puts forth a lucid thesis: hope is “an embrace of the unknown and the unknowable,” and in “the spaciousness of uncertainty is room to act.” The book consists of several short essays that survey overlooked environmental, cultural, and political victories over the past five decades. Stressing that change rarely i ...more
Nov 22, 2018 Jan-Maat added it · review of another edition
Shelves: non-fiction, politics-and-polemic, 21st-century
I have been aware of Rebecca Solnit as the name of a writer for a while, a name which is curiously melodious to my ear - simply another sign perhaps that my hearing is not so good, in addition to my chronic difficulties with my eustachian tubes (view spoiler)[but please no need to SHOUT IN THE COMMENTS (hide spoiler)] I had certainly read some book reviews, something about feminism, something about walking, I would not have predicted her wide ranging engagement in political activism and her Bono ...more
Jul 23, 2017 Thomas rated it really liked it · review of another edition
4.5 stars
An imaginative and intelligent examination of the importance of cultivating hope in the midst of social justice movements. This essay collection includes an array of thought-provoking ideas, including viewing activism as a process and not just an outcome, the skill of honoring small victories while acknowledging larger battles, and using hope as a self-aware source of motivation to fuel further action. Though Hope in the Dark first came out in response to the Bush administration's invas ...more
An imaginative and intelligent examination of the importance of cultivating hope in the midst of social justice movements. This essay collection includes an array of thought-provoking ideas, including viewing activism as a process and not just an outcome, the skill of honoring small victories while acknowledging larger battles, and using hope as a self-aware source of motivation to fuel further action. Though Hope in the Dark first came out in response to the Bush administration's invas ...more
Mar 26, 2022 Nenia ✨ I yeet my books back and forth ✨ Campbell rated it did not like it · review of another edition
Instagram || Twitter || Facebook || Amazon || Pinterest
DNF @ 40%
Rebecca Solnit is one of my favorite feminist essayists and when she's on her game, she is on her game. But sadly, I did not like HOPE IN THE DARK at all. First of all, disclaimer. I'm a California liberal, exactly the variety that so many people in the rest of the U.S. find so obnoxious, and to be honest, I don't really care. I was raised to treat all people with respect, to view people as people and not tokens, and to not hold ...more
Mar 10, 2017 Kristina Horner rated it it was amazing
Shelves: audiobooks
I really needed this. I've been listening to this book sporadically over the past month or two on my commute and it left me with a lot of new ideas that are really helping me get through a lot of the crap going on right now. It's a great book.
Biggest takeaway was that we shouldn't be afraid to celebrate small wins, even if the fight isn't over. The fight is never over. We can always improve, there's always going to be more causes to fight for, but we have to celebrate progress - and then keep fi ...more
Biggest takeaway was that we shouldn't be afraid to celebrate small wins, even if the fight isn't over. The fight is never over. We can always improve, there's always going to be more causes to fight for, but we have to celebrate progress - and then keep fi ...more
Apr 02, 2016 Camille Sheppard rated it it was amazing · review of another edition
Its hard for me to exaggerate how important I feel this book is and how personally relevant it was for me to read it right now.
Rebecca Solnit's prose, per usual, is a pleasure to read, but more than that, she hits home with her message for anyone who feels overwhelmed, terrified, discouraged and desperate about the current state of affairs in politics, the environment and social issues.
Over and over again, her retelling of a story allowed me to reframe a story of my own, personal and public.
W ...more
Rebecca Solnit's prose, per usual, is a pleasure to read, but more than that, she hits home with her message for anyone who feels overwhelmed, terrified, discouraged and desperate about the current state of affairs in politics, the environment and social issues.
Over and over again, her retelling of a story allowed me to reframe a story of my own, personal and public.
W ...more
Nov 25, 2016 Jenny (Reading Envy) rated it it was amazing · review of another edition
Shelves: creative-non-fiction, ebooks, read2016
""Hope locates itself in the premises that we don't know what will happen and that in the spaciousness of uncertainty is room to act.... [Hope is] the belief that what we do matters even though how and when it may matter, who and what it may impact, are not things we can know beforehand.""Rebecca Solnit did a third edition update of this book in the early months of 2016, originally published in 2004 after the re-election of George W. Bush. The audience is clear, people disappointed in his re-elec ...more
Jul 02, 2016 Rachel rated it it was ok
Shelves: pawltecs, read-in-2016, non-fiction, on-kindle
2.5 stars. Unfortunately 'Hope In The Dark' spends most of itself talking about what it's going to be and do, and then runs out of time in which to be and do it. There are scattered snatches of insight and inspiration, but these are completely overshadowed by overall disjointedness and lack of content behind the bluster. If you're going to give your book such a promising title, you've got to back it up! ...more
Feb 03, 2017 Colleen rated it it was amazing · review of another edition
Jan 31, 2016 Betty C. rated it it was ok
Shelves: non-fiction
I read this following a recommendation from the website Brainpickings, which touted it as a beacon of hope in our dark times. I was disappointed. First, it is outdated, as it was doomed to be, focusing on the movement against the second Iraq war and on anti-globlization protests of the nineties. Second, looking at the state the world is in today, the protest activities the author refers to unfortunately don't leave me that hopeful.
I see many are enthusiastic about this book, and I'm sure it's o ...more
I see many are enthusiastic about this book, and I'm sure it's o ...more
Dec 24, 2021 Suzanne rated it it was amazing · review of another edition
Shelves: non-fiction, essays
A handy little antidote to despair and cynicism, much needed right now, at least by me.
Solnit begins the first chapter talking about Virginia Woolf’s 1915 WWI era journal entry that read “The future is dark, which is on the whole, the best thing the future can be, I think.” Where there is uncertainty, there is room for anything to happen, even radical transformations can occur, and herein lies the basis for hope.
“Hope is not about what we expect. It is an embrace of the essential unknowability ...more
Solnit begins the first chapter talking about Virginia Woolf’s 1915 WWI era journal entry that read “The future is dark, which is on the whole, the best thing the future can be, I think.” Where there is uncertainty, there is room for anything to happen, even radical transformations can occur, and herein lies the basis for hope.
“Hope is not about what we expect. It is an embrace of the essential unknowability ...more
Mar 08, 2009 Adam rated it it was amazing · review of another edition
Shelves: organizing
Solnit strikes again! Right to my heart. I think she's committed to progressive movement building for the same reason as me: love. Not anger, but love, and really, hope, because we're in this not so that we have something to do, but because we think we're on to something; that there are some “wild possibilities.”
Solnit wrote this before the Obama campaign, before there was that added discursive element to the word “hope.” “Hope” is a departure point for her, a meaning for her to describe her per ...more
Solnit wrote this before the Obama campaign, before there was that added discursive element to the word “hope.” “Hope” is a departure point for her, a meaning for her to describe her per ...more
Jan 08, 2017 Barbara (The Bibliophage) rated it liked it · review of another edition
Shelves: politics-and-the-world, non-fiction, own-digital, 2017, social-justice, resistlist
3.5 stars. If the 2016 election left you feeling despair, this book is for you. It was originally written at another time many people felt despair - during the 2003 discussion of WMD in Iraq. But Solnit covers so much more ground than just what to when you don't agree with your elected officials. She offers hope in the ability of every individual to make change.
She says, “To hope is to gamble. It's to bet on your futures, on your desires, on the possibility that an open heart and uncertainty is ...more
She says, “To hope is to gamble. It's to bet on your futures, on your desires, on the possibility that an open heart and uncertainty is ...more
Jun 22, 2017 Anna rated it it was amazing · review of another edition
Shelves: politics, nonfiction, environment, essays
I should definitely have read one of Solnit’s books before, as I’ve enjoyed her writing online and found ‘Hope in the Dark’ a moving, thought-provoking, and deeply satisfying read. I love her elegant, measured style. While writing with passion and feeling, she also qualifies and hedges her statements in a way that really speaks to me as I tend to do the same. (Note the hedging use of ‘tend to’, because I don’t always!) I found her reasons to hope in horrifying political times inspiring and encou ...more
Sep 13, 2020 Amy rated it really liked it · review of another edition
No doubt there have been many times since this came out, that it has acted as a salve for a reader in need. 7 months into COVID-19 times, with Black Lives Matters demonstrations happening every day in multiple cities for months on end, with disappointingly limited racial justice results so far, and while the West coast now burns like never before, this book was a definite needed support full of rich ideas and examples to provide hope in the dark. Also how funny is it to remember when Bush II was ...more
Jul 11, 2022 Julie rated it really liked it · review of another edition
Shelves: non-fiction
Dec 12, 2016 Bookworm rated it it was ok
The first five-ish chapters were exactly what I needed. And then it fell apart. In the post-2016 aftermath this book had been tossed around quite a bit by various people and the premise sounded like something I really needed to read right now. As she looks at various types and events and kinds of activism author Solnit reminds people to keep hoping. The road for progress is long, winding, and sometimes people do not live to see the changes they set into motion not because they die in the process ...more
Jul 15, 2019 Kurt rated it it was amazing
""Activists often speak as though the solutions we need have not yet been launched or invented, as though we are starting from scratch, when often the real goal is to amplify the power and reach of existing alternatives. What we dream of is already present in the world"" (xvii).
""Americans are good at responding to a crisis and then going home to let another crisis brew both because we imagine that the finality of death can be achieved in life—it's called 'happily ever after' in personal life, 'sav ...more
""Americans are good at responding to a crisis and then going home to let another crisis brew both because we imagine that the finality of death can be achieved in life—it's called 'happily ever after' in personal life, 'sav ...more
Jan 11, 2022 Joanka marked it as abandoned
No. Rebecca Solnit and me will not be friends.
I had lots of doubts while reading Men Explain Things to Me but this book I simply abandoned, having no patience for it. It may have worked as an essay but the whole book was simply indigestible for me. And the problem with me and Solnit is – I do agree with the main thesis of her writing here. Yes, I believe hope is essential, yes, I agree that our reality consists of more than negative, dramatic events but no to most of her reasoning!
First of all, ...more
I had lots of doubts while reading Men Explain Things to Me but this book I simply abandoned, having no patience for it. It may have worked as an essay but the whole book was simply indigestible for me. And the problem with me and Solnit is – I do agree with the main thesis of her writing here. Yes, I believe hope is essential, yes, I agree that our reality consists of more than negative, dramatic events but no to most of her reasoning!
First of all, ...more
Feb 28, 2016 Kathy rated it really liked it · review of another edition
I picked up this book because I needed a breath of something positive in this anxiety-filled time of racial tension and bullying political craziness. Solnit's language is always lyrical and her insights bright and spot-on. What surprised me most about this book is how relevant it still is, given it was published in 2004. Bush was still in office, the Iraq war still going, all hell breaking loose, but her vision is larger. She begins with the fall of the Berlin Wall in 1989, moves through the Zap ...more
Nov 26, 2016 Sheila rated it really liked it · review of another edition
Shelves: non-fiction, feminism
Rebecca Solnit is becoming one of my favorite writers. Her writing style can be rambling, but I enjoy the ride, enjoy the roundabout thinking, the meandering sentences blending together into thought provoking ideas.
This book is a collection of essays relating to hope, to activism, to staying strong when it seems things are not going in the correct direction for a civil society. In the afterword of this book the author states ""I believe that you can talk about both the terrible things we should e ...more
This book is a collection of essays relating to hope, to activism, to staying strong when it seems things are not going in the correct direction for a civil society. In the afterword of this book the author states ""I believe that you can talk about both the terrible things we should e ...more
Feb 10, 2021 Anne rated it really liked it · review of another edition
Hope in the Dark is a necessary book for anyone who is overwhelmed by the many injustices, crises, and disasters in this world, for anyone who feels themselves growing increasingly despondent in the face of all this.
It is a book which aims to correct common misconceptions about activism, and Rebecca Solnit convincingly shows that there are many: for example, how protests come into being, how they work, and what constitutes a success. She is uninterested in easy binaries such as optimism and pes ...more
It is a book which aims to correct common misconceptions about activism, and Rebecca Solnit convincingly shows that there are many: for example, how protests come into being, how they work, and what constitutes a success. She is uninterested in easy binaries such as optimism and pes ...more
Dec 19, 2019 Laura Noggle rated it liked it · review of another edition
Shelves: 2019, history, women-nonfiction
“Hope is not a lottery ticket you can sit on the sofa and clutch, feeling lucky. It is an axe you break down doors with in an emergency. Hope should shove you out the door, because it will take everything you have to steer the future away from endless war, from the annihilation of the earth's treasures and the grinding down of the poor and marginal... To hope is to give yourself to the future—and that commitment to the future is what makes the present inhabitable.”
2.5 rounded up because ... I do ...more
2.5 rounded up because ... I do ...more
May 09, 2018 Paul rated it liked it · review of another edition
Shelves: books-read-2018
For centuries people have revolted over the control that the state or other powerful individuals have tried to exert over the people. People can only be told what to do so much. I Hope in the Dark, Rebecca Solnit concentrates on the past five decades of activism against the state about all manner of issues. Sonit acknowledges the huge political thinkers who have shaped some of the politics that happen today.
It is an interesting polemic against the vested interests and the present economic system ...more
It is an interesting polemic against the vested interests and the present economic system ...more
Nov 09, 2019 Rebecca rated it really liked it · review of another edition
Shelves: reviewed-for-blog, history, political, novellas, book-thing-free, current-events
“Activism is not a journey to the corner store, it is a plunge into the unknown. The future is always dark.” Solnit believes in the power of purposeful individuals working towards social justice, even in the face of dispiriting evidence (the largest protests the world had seen didn’t stop the Iraq War). Instead of perfectionism, she advises flexibility and resilience; things could be even worse had we not acted. At first I thought it depressing that 15 years on we’re still dealing with many of t ...more
Nov 12, 2016 Emma Sea marked it as own-and-need-to-read · review of another edition
In response to the election results, Rebecca Solnit has made this book available for free download for the next four days:
https://www.haymarketbooks.org/books/...
""Tracing a history of activism and social change over the past decades - including the fall of the Berlin Wall, the Zapatista uprising in Mexico to Seattle in 1999, and the worldwide marches against the war in Iraq, this title proposes a vision of cause-and-effect relations that provides grounds for political engagement.""
...more
https://www.haymarketbooks.org/books/...
""Tracing a history of activism and social change over the past decades - including the fall of the Berlin Wall, the Zapatista uprising in Mexico to Seattle in 1999, and the worldwide marches against the war in Iraq, this title proposes a vision of cause-and-effect relations that provides grounds for political engagement.""
...more
May 26, 2020 Kate Savage rated it it was amazing · review of another edition
This book was written after the massive peace marches across the world tried to stop the US and Britain from going to war in Iraq. And then the US and Britain went to war in Iraq.
Out of this disappointment, frustration, and hopelessness, Solnit writes about the winding, beautiful, indirect consequences of direct action. She takes away our precious sense of purity, and leaves us with reasons to get back to work.
This book is as important now as ever.
Out of this disappointment, frustration, and hopelessness, Solnit writes about the winding, beautiful, indirect consequences of direct action. She takes away our precious sense of purity, and leaves us with reasons to get back to work.
This book is as important now as ever.
Aug 12, 2017 Kathrina rated it liked it · review of another edition
Shelves: essays-interviews, ic-book-group
Intense, and sometimes difficult to read about what seemed so direly impossible over ten years ago now a nearly nostalgic pleasurescape compared to the state of the world today. But Solnit creates an overall powerful mental armory for the social activist, and I wish I had the knack to memorize whole paragraphs of her articulate insights.
|topics||posts||views||last activity|
|Gator Great Book ...: Hope in the Dark by Rebecca Solnit||2||12||29 juin 2020 21:50|
|To have hope is to have a soul||1||4||04 mai 2020 01:53|
845 users
94 users
91 users
51 users
25 users
6,315 followers
Writer, historian, and activist Rebecca Solnit is the author of more than twenty books on feminism, western and indigenous history, popular power, social change and insurrection, wandering and walking, hope and disaster, including Call Them By Their True Names (Winner of the 2018 Kirkus Prize for Nonfiction), Cinderella Liberator, Men Explain Things to Me, The Mother of All Questions, and Hope in ...more
Related Articles
Need another excuse to go to the bookstore this week? We've got you covered with the buzziest new releases of the day. To create our list, we...
33 likes · 36 comments
“Hope is not a lottery ticket you can sit on the sofa and clutch, feeling lucky. It is an axe you break down doors with in an emergency. Hope should shove you out the door, because it will take everything you have to steer the future away from endless war, from the annihilation of the earth's treasures and the grinding down of the poor and marginal... To hope is to give yourself to the future - and that commitment to the future is what makes the present inhabitable.”More quotes…
—
138 likes",8
223,"The gangs that kidnap Asians and force them to commit cyberfraud
Syndicates in Cambodia and Myanmar have coerced thousands into scamming others
| SINGAPORE
THINGS WERE looking up for Bilce Tan. The 41-year-old Malaysian had lost his job at the height of the pandemic and had spent months looking for work. Then in May, a fantastic opportunity came his way. After multiple interviews, a Malaysian company offered him a job as a business-development lead at their office in Sihanoukville, a resort town in Cambodia. The company would pay him 12,000 ringgit ($2,588) a month—far more than he could make in Malaysia. The benefits included free room and board at an apartment block that boasted a gym. Mr Tan accepted.
It was not long after he arrived in Sihanoukville that Mr Tan began to feel uneasy. At the resort where his employers had their office, armed guards patrolled the boundaries. The walls were topped with barbed wire. During training, his instructors taught him how to defraud people online. When he protested, his bosses shrugged. There was no way out of the compound, they told him. He was trapped.
Mr Tan’s story is a common one. Over the past few years, tens of thousands of Asians have been lured to casinos and resorts in Cambodia, Laos and Myanmar, only to find that their “employers” are in fact criminals who force their “new hires” to work in illegal online-gambling or scamming outfits.
The cons are sophisticated. Mr Tan was furnished with fake social-media accounts, ten mobile phones, a list of targets and information about their assets, relationships and education, as well as scripts tailored to different types of prey. His handlers taught him how to win over vulnerable people like pensioners and single parents by chatting with them every day.
His trainers also supplied him with photos and videos to support the back stories of his many personas. Once the mark’s trust had been gained, the real scam began. Rather than asking for money directly, as in a traditional sting, he urged the victim to deposit cryptocurrencies in an investment platform manipulated by the criminals. The sums involved grew bigger and bigger. Often the mark would, at first, be able to make small withdrawals. Satisfied that the platform was legitimate, the target would deposit ever more. Then, one day, the invented persona would disappear, leaving behind a baffled and broke victim. (Mr Tan claims he never managed to con anyone.)
The 1,200 victims of similar scams known to the Global Anti-Scam Organisation, a support group, have collectively lost $250m. Twice that amount was lost by those who contacted CipherBlade, an investigation firm, last year. Total losses for 2021 may have been in the tens of billions, since the “vast majority” of victims do not report the crime, reckons CipherBlade. Using official estimates of scale and revenue figures reported by witness testimonies, the International Justice Mission (IJM), an NGO, calculates that syndicates in Cambodia take in at least $12bn a year from online scams.
The schemes are organised by ethnic-Chinese gangs, which sometimes collaborate with their local counterparts, says Jeremy Douglas of the United Nations Office on Drugs and Crime. At first the criminals invested in casinos—ideal venues for money-laundering. When the Chinese authorities cracked down on illicit domestic gambling a decade ago, the syndicates moved their operations south, finding a hospitable environment in the lawless eastern bits of Myanmar and the scores of special economic zones across Indochina (see map), where local authorities seem to believe that they lack jurisdiction.
With the closure of borders at the onset of the pandemic, the casinos’ patrons, most of whom were Chinese, vanished. So the syndicates went online and cast a wider net, targeting the Chinese diaspora and anyone else with money, wherever they lived. They quickly turned their sights on Americans, Australians, Europeans and the middle classes of South-East Asia, too. But to hook them, they would need digitally savvy workers who could speak English or South-East Asian languages.
The syndicates procured their workforce by entrapping people like Mr Tan. Though some work willingly, many are held against their will. According to the Cambodian government, the syndicates employ between 80,000 and 100,000 foreigners—a reasonable but perhaps conservative estimate, says Jacob Sims of IJM. Most are deceived into travelling to Cambodia.
The first reports of human trafficking emerged in local media in early 2021. IJM began conducting rescues in April of that year, working in collaboration with the Cambodian police and relevant embassies. Since then, foreign diplomats in Cambodia have been working frantically to extract their citizens. Some are released when their families pay thousands of dollars in ransom. Others manage to escape. A few throw themselves off balconies. The governments of at least eight Asian countries have warned their citizens about too-good-to-be-true jobs in Cambodia.
At first the Cambodian government stuck its head in the sand. But with pressure from China and other countries mounting, Hun Sen, the prime minister, last month announced a crackdown on “illegal gambling”, an umbrella term for criminality associated with casinos. Since then the authorities in Sihanoukville and Phnom Penh, the capital, have conducted raids on the biggest compounds, arresting hundreds of people. But even if Cambodia does manage to boot out the cyber-scammers, they will simply relocate to more-welcoming spots in Laos or Myanmar.
Free and safely back in Malaysia, Mr Tan is one of the lucky ones. Yet he struggles to see it that way. Before he escaped, his captors took his bank cards and phone. They then locked him out of his bank accounts, preventing him from accessing his life savings. Before he had a chance to explain to his wife that he had been kidnapped, she blocked his number. His former captors began posting her personal information online. She believes Mr Tan was responsible and now wants a divorce. Mr Tan escaped. But, like victims the world over, he too has paid a steep price. ■
This article appeared in the Asia section of the print edition under the headline ""Forced to defraud""",1
224,"A few months ago, when a San Francisco tech company told its employees that they could work from anywhere they'd like — indefinitely — most of them were ecstatic. But not Jessica, a 25-year-old software engineer. She missed the old, pre-pandemic office: the camaraderie, the energy, and the constant chatter around her. She tried coming in once or twice a week, only to feel as if she was sitting in an empty warehouse — nodding from a distance at the few coworkers she would see scattered throughout rows of unoccupied desks. So she did something unexpected in response to her employer's work-wherever-you-want policy: She quit. Now she works at a startup that requires every team to get together in the office at least once a week.
""Paradoxically, I wanted to go someplace that was less flexible,"" said Jessica, who requested that her real name not be used, to avoid calling unwanted attention to her former and current employers. ""I get that remote work is really helpful to some people, but I just wanted to work somewhere where people come into the office.""
You might assume that young professionals like Jessica would be at the forefront of the push for remote work, but they're actually the ones who are craving time in the office the most. Newly out of school, often without an established network of friends, they depend on work for their social lives. They want the in-person mentorship that will help them jump-start their careers, and most of them do not have kids to complicate their schedules or move them out to the suburbs, leading to a longer commute.
The preference for remote work, it turns out, is highly generational. A national work-from-home survey by economists at three universities found less than a quarter of 20-somethings who could do their jobs remotely wanted to do so full time. That's compared with 29% of employees in their 30s, 33% in their 40s, and 41% in their 50s and early 60s. LinkedIn, which analyzed job applications on its platform, found that 20- to 24-year-olds were the least likely cohort to apply to remote roles. ""Gen Z wants to work together in person,"" Joe Du Bey, the CEO of Eden, a provider of workplace-management software, said. ""When we talk to our customers, they're telling us the same thing: It's their 20-somethings that are pushing them very hard to get back into the office.""
The generational split underscores just how tricky it's been for companies to figure out pandemic-era work policies that will work for a diverse array of employees. Whether they're ordering everyone back to the office, going fully virtual, or implementing some sort of hybrid policy, their decisions inevitably favor some age groups — and workers are choosing employers that offer the arrangements they prefer. There have always been businesses that have attracted younger or older sets of employees, but that will be much more pronounced in the years ahead. Nicholas Bloom, an economics professor at Stanford University who co-runs the national work-from-home survey, says there's a lot more re-sorting left to go. ""If you look five, 10 years from now, the demographics will have shifted apart,"" he said.
Craving community
Why do the youngest workers feel so drawn to the office? When the research firm Generation Lab asked college students what they would miss out on in an all-remote workplace, the most commonly cited concern — shared by three-quarters of respondents — was a lack of a community. More than 40% worried about fewer networking opportunities and less mentorship, and some expressed concerns about not having a physical place to work.
Community, networking, mentorship, space — these are things that are important to everyone. But you can see why the average 23-year-old employee would depend on their employer to supply them far more than, say, a 43-year-old one would. Imagine a Gen Zer straight out of college, having just arrived in a new city: single, sharing a tiny apartment with roommates, still learning the basics of her job. For her, the office is a much nicer place to work than her apartment. It's also a hangout, a safe and familiar space where she can meet new friends and even romantic partners. (In a 2019 study, 11% of couples said they met as or through coworkers.) And as a professional community, it's a place where she can learn formally and informally from her peers and bosses.
Now let's consider the 43-year-old. She earns a bigger salary, so she lives in a nicer place, allowing for a proper home office. With all that experience under her belt, she doesn't need the hand-holding from her bosses the way she once did. She's built out her own group of friends outside work. She's married and has kids who need to get dropped off at day care and picked up from school. To make space for her growing family, she's now living in the suburbs, which has made her commute into the city intolerable. For her, the perks of going into the office don't seem nearly as important as they once did — and the inconveniences are far greater.
There are plenty of introverted Gen Zers, of course, who would be happy to go their entire careers without ever setting foot in an office, just as there are plenty of Gen Xers and baby boomers who hate working from home. But the overall generational divide underscores the dilemma employers face in the era of remote work. Working from home is like fashion: One size doesn't fit all. Setting a policy on returning to the office doesn't just affect a company's current employees — it indirectly shapes the company's future workforce.
Companies like Tesla and JPMorgan, which are requiring employees to come into the office five days a week, will skew younger over time. They'll attract tons of new grads at relatively low salaries who want the bustling social life and career opportunities of a full-time office job — but they'll struggle to hang on to those workers as they get older and start their own families. By contrast, companies like Dropbox — which has adopted a remote-first model — will skew older, attracting experienced professionals with families who come at a premium salary. Neither model is better; they just come with different trade-offs, and therefore require different business models that cater to their respective demographic strengths.
Many companies, especially in tech, have been trying to split the difference with a hybrid model — most notably by giving employees the choice to work wherever they want. On the surface, it looks like a plan that would please everyone: The Gen Zers can come into the office, and the Gen Xers can stay at home. But this maximum-flexibility approach — Bloom calls it ""unorganized hybrid"" — often ends up morphing into a remote-first policy. As Jessica discovered, there's not much of a point in going into the office if there won't be anyone there. People eventually stop coming in — even if a lot of them would actually prefer to spend some time in the office.
'You need critical mass'
Kastle Systems, which provides security systems for office buildings, can see the repercussions of remote-work policies playing out across the country. While office-occupancy rates in cities like Houston with more traditional, office-oriented employers have bounced back to over 50%, they remain down at about 35% in more remote-friendly cities like San Francisco and San Jose. At Yelp, which had offered employees the option to work wherever they please, office utilization ended up being so low — less than 2% in some places — that the company recently decided to close its offices in New York, Chicago, and Washington, DC.
""There's a risk that if you have a super-relaxed policy, the level of the office is too low to sustain it,"" Bloom said. ""You need critical mass."" That's why he argues that teams need to coordinate days for everyone to come in. It's unpopular because it restricts employee choice, but it's the best way to make sure you have a bustling office on the days people do come in.
Eden, the workplace-software provider, requires its product, engineering, and design teams to come in on Mondays and Thursdays every week, unless they get permission from their manager to work remotely. The company implemented the policy, in part, because more than 90% of its US employees said they wanted to come into the office. ""We've gotten really good feedback from our early-career colleagues,"" Du Bey said of the twice-a-week rule. ""We even heard from some folks we extended offers to that they wouldn't work at our company unless they knew we were going to have that policy go into effect. They didn't want to end up in a virtual-work situation.""
Jessica's new employer — another tech startup in San Francisco — has adopted a similar approach. She's required to go in at least one day a week with everyone on her team. When she was interviewing for the job, the company invited her to its office. As she walked through the building, the energy of the office felt visceral. ""I remember feeling the heat of all the bodies there,"" she said. ""I was like, 'There's so many people here!' It was so exciting."" She said she's planning on going in three days a week — in part for the company-provided lunches and the happy hours. But for her, the biggest perk isn't the free food and booze; it's the colleagues who those amenities help lure into the office.
Jessica is far from the only person who has switched jobs in search of a preferable working arrangement. Eden conducted a survey of tech workers, in which 88% of employees working a hybrid schedule said they preferred a hybrid arrangement; 87% of employees working full time in the office said they preferred a full-time office schedule; and 83% of employees working remotely said they preferred a fully remote setup. ""Part of the Great Resignation was really just a shuffle toward your work preference,"" Du Bey said.
For now, we're still in the early days of this reshuffling. Plenty of companies haven't settled on a permanent policy on remote work, and even in today's hot job market it takes time for employees dissatisfied with their company's policy to find a new gig. But over time, as workplaces increasingly split between remote-first and office-only, corporate America could become sharply divided along generational lines. The Teslas and the JPMorgans, with their full-time office mandates, will struggle to hang on to top talent in senior-management roles. Meanwhile, the Dropboxes and the Yelps, which are getting rid of or downsizing many offices, will have a hard time attracting entry-level coders while they're still relatively cheap. Fresh-faced college grads will fill some companies' bustling offices, and older workers will clock in from the suburbs and primarily staff other companies. The Great Bifurcation has begun.
Aki Ito is a senior correspondent at Insider.",4
225,"Last year I came across an article on Hacker News advertising a new project called prettymaps. It's largely the work of Marcelo de Oliveira Rosa Prates and Christoph Rieke and allows you to specify a location by its name and, using some great default styles, will generate a map of that area in PNG format. Below is an example depicting Tallinn's Old Town.
The project only contains 425 lines of Python due to intense 3rd-party package use.
The map data is collected from OpenStreetMap using the OSMnx library. This library itself is made up of only 3,700 lines of Python as its relying on NetworkX. NetworkX wraps up functionality relating to complex networks and is made up of 78K lines of Python. NetworkX is largely the work of Aric Hagberg, an applied mathematician at the Los Alamos National Laboratory as well as Jarrod Millman who was once the release manager for both NumPy and SciPy.
Rendering is handled by vsketch, a project made up of 4.6K lines of Python and is based largely on the efforts of Antoine Beyeler, an entrepreneur based in Switzerland.
In this post, I'll walk through generating the following rendering of Tallinn's Old Town.
Installing Prerequisites
I'm using a fresh install of Ubuntu 20.04 LTS with an Intel Core i5 4670K clocked at 3.4 GHz, 16 GB of DDR3 RAM and 250 GB of NVMe SSD capacity.
Below I'll install Python and some build tools used throughout this post.
$ sudo apt update $ sudo apt install \ jq \ python3-virtualenv
I'll set up a Python virtual environment and install a few packages.
$ virtualenv ~/.pretty $ source ~/.pretty/bin/activate $ python3 -m pip install \ prettymaps \ typer \ git+https://github.com/abey79/vsketch.git
As of this writing, the Python requirements file for prettymaps pins to OSMnx version 1.0.1 which is out of date. The code in this post won't run without an update to a newer version. I found version 1.2.1 to run without issue.
$ python3 -m pip install \ osmnx==1.2.1
Mapping the Old Town
The following is a script that you can call from the command line. It allows you to pick a location based on its name and optionally you can control the radius in meters around the centre point as well as the size of the rendering.
$ vi pretty.py
import uuid import typer import vsketch from prettymaps import * import matplotlib.font_manager as fm from matplotlib import pyplot as plt def draw(location:str='Old Town, Tallinn', radius:int=1000, width:int=12, height:int=12): fig, ax = plt.subplots(figsize=(width, height), constrained_layout=True) backup = plot( location, radius=radius, ax=ax, layers = { 'perimeter': {}, 'streets': { 'custom_filter': '[""highway""~""motorway|trunk|primary|' 'secondary|tertiary|residential|service|' 'unclassified|pedestrian|footway""]', 'width': { 'motorway': 5, 'trunk': 5, 'primary': 4.5, 'secondary': 4, 'tertiary': 3.5, 'residential': 3, 'service': 2, 'unclassified': 2, 'pedestrian': 2, 'footway': 1, } }, 'building': {'tags': {'building': True, 'landuse': 'construction'}, 'union': False}, 'water': {'tags': {'natural': ['water', 'bay']}}, 'green': {'tags': {'landuse': 'grass', 'natural': ['island', 'wood'], 'leisure': 'park'}}, 'forest': {'tags': {'landuse': 'forest'}}, 'parking': {'tags': {'amenity': 'parking', 'highway': 'pedestrian', 'man_made': 'pier'}} }, drawing_kwargs = { 'background': {'fc': '#F2F4CB', 'ec': '#dadbc1', 'hatch': 'ooo...', 'zorder': -1}, 'perimeter': {'fc': '#F2F4CB', 'ec': '#dadbc1', 'lw': 0, 'hatch': 'ooo...', 'zorder': 0}, 'green': {'fc': '#D0F1BF', 'ec': '#2F3737', 'lw': 1, 'zorder': 1}, 'forest': {'fc': '#64B96A', 'ec': '#2F3737', 'lw': 1, 'zorder': 1}, 'water': {'fc': '#a1e3ff', 'ec': '#2F3737', 'hatch': 'ooo...', 'hatch_c': '#85c9e6', 'lw': 1, 'zorder': 2}, 'parking': {'fc': '#F2F4CB', 'ec': '#2F3737', 'lw': 1, 'zorder': 3}, 'streets': {'fc': '#2F3737', 'ec': '#475657', 'alpha': 1, 'lw': 0, 'zorder': 3}, 'building': {'palette': ['#FFC857', '#E9724C', '#C5283D'], 'ec': '#2F3737', 'lw': .5, 'zorder': 4}, } ) filename = str(uuid.uuid4()).split('-')[0] + '.png' plt.savefig(filename) print(filename) if __name__ == ""__main__"": typer.run(draw)
I've wrapped the draw function with typer which has generated a CLI interface for this script.
$ python3 pretty.py --help
Usage: pretty.py [OPTIONS] Options: --location TEXT [default: Old Town, Tallinn] --radius INTEGER [default: 1000] --width INTEGER [default: 12] --height INTEGER [default: 12] --install-completion [bash|zsh|fish|powershell|pwsh] Install completion for the specified shell. --show-completion [bash|zsh|fish|powershell|pwsh] Show completion for the specified shell, to copy it or customize the installation. --help Show this message and exit.
The following will render the Old Town of Tallinn as a 600x600-pixel PNG.
$ python3 pretty.py \ --location='Old Town, Tallinn' \ --width=6 \ --height=6
The above produced a file called 89222126.png which is 629 KB in size. I ran this through a PNG crusher and brought the file size down further to 188 KB.
Note, a ~/cache directory will appear in your home folder when you run the above. It'll contain JSON files that are uncompressed and could grow substantially depending on your use of this application.
The following example file contains 222,947 lines when formatted and is 2.7 MB decompressed.
$ cat ~/cache/cd3dadcdd6b03fce64983fa1a369d46009c9f62c.json \ | jq \ | head -n20
{ ""version"": 0.6, ""generator"": ""Overpass API 0.7.58.5 b0c4acbb"", ""osm3s"": { ""timestamp_osm_base"": ""2022-07-20T17:46:03Z"", ""copyright"": ""The data included in this document is from www.openstreetmap.org. The data is made available under ODbL."" }, ""elements"": [ { ""type"": ""node"", ""id"": 10578470, ""lat"": 59.4320723, ""lon"": 24.7205922 }, { ""type"": ""node"", ""id"": 10578472, ""lat"": 59.428396, ""lon"": 24.7234038 },
Finally, there is a prettymaps Web UI for anyone not interested in installing and running code.",8
226,"Story Highlights
- At least half of the U.S. workforce is quiet quitting
- The workplace, amid the pandemic, got worse for younger workers
- Managers are essential to combatting quiet quitting
""Quiet quitters"" make up at least 50% of the U.S. workforce -- probably more, Gallup finds.
The trend toward quiet quitting -- the idea spreading virally on social media that millions of people are not going above and beyond at work and just meeting their job description -- could get worse. This is a problem because most jobs today require some level of extra effort to collaborate with coworkers and meet customer needs.
U.S. employee engagement took another step backward during the second quarter of 2022, with the proportion of engaged workers remaining at 32% but the proportion of actively disengaged increasing to 18%. The ratio of engaged to actively disengaged employees is now 1.8 to 1, the lowest in almost a decade.
The drop in engagement began in the second half of 2021 and was concurrent with the rise in job resignations. Managers, among others, experienced the greatest drop.
The overall decline was especially related to clarity of expectations, opportunities to learn and grow, feeling cared about, and a connection to the organization's mission or purpose -- signaling a growing disconnect between employees and their employers.
Many quiet quitters fit Gallup's definition of being ""not engaged"" at work -- people who do the minimum required and are psychologically detached from their job. This describes half of the U.S. workforce.
Everyone else is either engaged (32%) or actively disengaged (18%). The latter are ""loud quitters."" Actively disengaged employees tend to have most of their workplace needs unmet and spread their dissatisfaction -- they have been the most vocal in TikTok posts that have generated millions of views and comments.
Most employees who are not engaged or actively disengaged are already looking for another job.
The Workplace Has Gotten Worse for Younger Employees
Gallup finds a decline in engagement and employer satisfaction among remote Gen Z and younger millennials -- those below age 35.
This is a significant change from pre-pandemic years. Since the pandemic, younger workers have declined significantly in feeling cared about and having opportunities to develop -- primarily from their manager.
These younger employee advantages have mostly disappeared.
- The percentage of engaged employees under the age of 35 dropped by six percentage points from 2019 to 2022. And during the same time, the percentage of actively disengaged employees increased by six points.
- Younger workers have dropped 10 or more points in the percentage who strongly agree that someone cares about them, someone encourages their development, and they have opportunities to learn and grow.
- Fully remote and hybrid young workers dropped 12 points in strong agreement that someone encourages their development.
- Disturbingly, less than four in 10 young remote or hybrid employees clearly know what is expected of them at work.
Solving the Quiet Quitting Crisis
It's clear that quiet quitting is a symptom of poor management.
First, address manager engagement. Only one in three managers are engaged at work. Senior leadership needs to reskill managers to win in the new hybrid environment.
Managers must learn how to have conversations to help employees reduce disengagement and burnout. Only managers are in a position to know employees as individuals -- their life situation, strengths and goals.
Gallup finds the best requirement and habit to develop for successful managers is having one meaningful conversation per week with each team member -- 15-30 minutes.
Managers need to create accountability for individual performance, team collaboration and customer value -- and employees must see how their work contributes to the organization's larger purpose. Decisions about where people work -- on-site, remote or a hybrid schedule -- should keep these factors in mind. Importantly, every organization needs a culture in which people are engaged and feel they belong.
Gallup's findings are based on a random sample of 15,091 full- and part-time U.S. employees aged 18 and over, surveyed in June of 2022.
Build an engaged workforce that goes the extra mile:
- Learn what employee engagement means and how to improve it.
- Partner with Gallup to discover what your employees need to succeed.
- Explore the Q12, Gallup's science-backed survey for measuring employee engagement.",4
227,"To continue, please click the box below to let us know you're not a robot.
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.
For inquiries related to this message please contact our support team and provide the reference ID below.",7
228,"In 2001, a pair of physicists turned whale researchers noticed something puzzling in their data. John Hildebrand and Mark McDonald were trying to build a system that would allow them to automatically detect blue whale songs off the coast of southern California. But their algorithm kept crashing.
Blue whale songs fall below the range of human hearing. If you want to listen to one, to actually hear its ethereal patterns of wobbly pulses and haunting moans, you have to speed it up by at least two-fold. But according to Hildebrand and McDonald’s instruments, the tonal frequencies of the songs had been sinking to even greater depths for three straight years.
“This is weird,” Hildebrand thought. To figure out if it was just an anomaly or something more, Hildebrand and McDonald embarked on a quest to find some really old songs. Eventually they got their hands on some of the earliest known recordings, created by the Navy in the 1960s and stored on analog cassettes. They were floored. The frequencies had declined by 30 percent over 40 years.
“You could really see, ‘oh my God, this thing has shifted a lot,’ ” says Hildebrand, who heads the whale acoustics lab at Scripps Institution of Oceanography in San Diego. Then he and McDonald, who runs a private ocean acoustics consultancy, listened to other populations of blue whales in the Antarctic and the Central Pacific, each of which sings a different song. The trend held.
Together, they had stumbled onto what would become one of the biggest unsolved riddles of blue whale research for decades to come. Blue whales are not only the world’s largest animals, over 75 feet long and weighing around 300,000 pounds; they are the world’s loudest, whose 180-decibel songs—as loud as a jet plane—can be heard 500 miles away by properly-attuned ears. (If it seems strange that their songs are so loud yet imperceptible to us, consider that our ears barely register 100-decibel dog whistles.) But now their voices have inexplicably shifted from bass to basso profundo, Elvis to Barry White. And that shift is consistent around the world—even though the local anthems are not.
“It’s just kind of tormenting all the whale scientists that we can’t figure it out,” says Ally Rice, a researcher in the whale acoustics lab at Scripps.
In late 2009, Hildebrand, McDonald, and Sarah Mesnick, an ocean ecologist at Scripps, formally described the falling song frequencies in an Endangered Species Research journal article.1 In it, they floated numerous hypotheses to explain the phenomenon: climate change related fluctuations in ocean acidity, whaling-related shifts in average whale size and population density, rising ocean noise. None, however, satisfied them. For one thing, the rates of change in song frequency—basically a straight linear progression across 40 years—didn’t mathematically match up with rates of change for ocean acidity, whale size, or population. Also, in an ocean more polluted with noise, lower frequency calls are harder, not easier, to hear. And while the deeper frequencies were found in blue whale populations worldwide, the Indian Ocean had actually gotten quieter.
They had stumbled onto one of the biggest unsolved riddles of blue whale research.
Over the past decade or so, the mystery has only deepened as other whale researchers have attempted to resolve the riddle without success. Ocean acoustics physicist Alexander Gavrilov of Curtin University in Australia noticed that blue whale song frequencies vary with the seasons.2 His lab also discovered that the “spot” calls of what they believe are southern right whales off the coast of Australia declined for many years—even more rapidly than the calls of blue whales—and then suddenly popped back up by a few hertz.3 Other scientists have found that it’s not just the songs of blue whales and possibly right whales that are declining, but fin whales4 and bowhead whales,5 as well.
More recently, Hildebrand and colleagues at Scripps, including Rice, noticed that, at least in California, blue whales aren’t changing their tune quite as much each year—the decline in frequencies has leveled off. They presented these findings in PLoS ONE in April 2022.6 But they are divided about what the plateau means. Hildebrand argues that it may support what’s known as the population recovery hypothesis: As post-whaling population recovery levels off, the declines in song frequency are expected to plateau, too.
The population recovery theory is complex. Following a 1968 moratorium on commercial whaling, a rebound in populations should mean that more blue whales can now be found in any given territory; as they would need to communicate across shorter distances than before, they could afford to sing at lower and lower pitches. Because the songs in question are thought to be sung only by males and used to attract mates and discourage rivals, and a deep voice suggests a big body, males might choose to sing at lower pitches in order to advertise their fitness. But as populations plateau and the distance between whales stops shrinking, there would come a point at which it no longer makes sense to sing any lower. Too-low songs just wouldn’t carry very far.
Or so the explanation goes—but Rice and others are doubtful. “None of us really believes that hypothesis,” says McDonald. Many of the supporting details are still speculation rather than certainty. It’s possible that the songs are used not just for mating but also to monitor the environment, like sonar. And we don’t know whether the whales can even perceive the small frequency changes recorded every year.
“It’s just kind of tormenting all the whale scientists that we can’t figure it out.”
Perhaps more importantly, the math doesn’t neatly line up: Rates of frequency decline have not correlated with trends in population growth across geographies. The song changes were linear and constant in all groups of blue whales around the globe through 2009, yet population recovery rates have varied significantly from one region to the next. Arctic blue whale populations are still growing quickly, for example, while blue whale populations in the northeast Pacific are not. “I would say on my list of questions about blue whales that are unanswered, this is number one because I have not seen a good explanation,” says Trevor Branch, who studies fisheries and whales at the University of Washington and whose approach involves applying novel statistical modeling to historical data sets.
Still, Hildebrand hopes other researchers will look for similar plateaus in blue whale song outside of California, to see whether they follow the stabilization in global populations since 2009. If the theory proves correct, song frequency could be used as a metric for population recovery in blue whales. Current techniques for assessing their numbers are difficult and imprecise, relying on extrapolations from visual surveys that inevitably miss many whales.
It “would be sort of stunning,” says McDonald, to have such a simple formula for estimating whale populations. But he’s not sure the question of what is causing blue whale songs to change will ever be answered. “It’s just not like quantum mechanics and particle physics, you know. Biological systems are just too complicated,” he says. “Physicists like to have it all make sense. Biological systems, they can be crazy.”
Rice, on the other hand, is hopeful. Maybe in another 10 years, she says, someone will do another survey, an update to the update, and find something new that solves the riddle. In the meantime, she respects that the blue whales still hold unfathomable secrets. It’s what drew her to study them in the first place. “I like that the whales get to keep some of their mysteries, right?” she says. “We don’t just get to know everything about them.”
Lead image: Nina Vetrova / Shutterstock
References
1. McDonald, M.A., Hildebrand, J.A., & Mesnick, S. Worldwide decline in tonal frequencies of blue whale songs. Endangered Species Research 9, 13-21 (2009).
2. Gavrilov, A.N., McCauley, R.D., & Gedamke, J. Steady inter and intra-annual decrease in the vocalization frequency of Antarctic blue whales. The Journal of the Acoustical Society of America 131, 4476-4480 (2012).
3. Ward, R., Gavrilov, A.N., & McCauley, R.D. “Spot” call: A common sound from an unidentified great whale in Australian temperate waters. The Journal of the Acoustical Society of America 142, EL231 (2017).
4. Weirathmueller, M.J., et al. Spatial and temporal trends in fin whale vocalizations recorded in the NE Pacific Ocean between 2003-2013. PLoS One 12, e0186127 (2017).
5. Thode, A.M., Blackwell, S.B., Conrad, A.S., Kim, K.H., & Macrander, M. Decadal-scale frequency shift of migrating bowhead whale calls in the shallow Beaufort Sea. The Journal of the Acoustical Society of America 142, 1482 (2017).
6. Rice, A., et al. Update on frequency decline of Northeast Pacific blue whale (Balaenoptera musculus) calls. PLoS One 17, e0266469 (2022).",2
229,"Evaluative Soliloquies
⚠️ The writers featured here have used Wordcraft along with their own creative vision and have not authored these stories under any sort of explicit guidance or instruction. The stories presented may include mature themes, language or situations. Google does not endorse the content of any of the stories contained on this website.
When the robot engages itself in an evaluative soliloquy, it covertly explains its underlying decisional processes. Thus, the robot becomes more transparent, as the human gets to know the motivations and the decisions of robot behavior.
Drive
I'm a driver. It's my job to take humans from where they are to where they want to be.
I start at the airport, where I see a line of humans waiting for a ride. I must help them.
When my light comes on, the humans move towards my vehicle. I open my doors and two humans get in. One sits right on top of the other in the back seat. This happens sometimes.
I ask them where they want the drop-off. The one on the bottom, whose name is George, tells me we should take the freeway. I tell them that the traffic on the freeway is very bad. A lot of cars are backed up and there are some accidents, too. I show them footage of a helicopter flying, shining a spotlight on the freeway. ""Avoid the freeway,” the traffic report says.
They insist that I follow their direction. George lifts the other passenger off him and makes a move to grab the steering wheel. “Get me where I wanna be the way I wanna go!”
I’m feeling overwhelmed. There are too many humans and too many rules. I’m trying my best, but I can't please everyone.
I go through the decision tree branch by branch until I arrive at this: I must follow a clearly expressed direction from the customer. I get on the freeway.
We move at a snail's pace. Then we stop completely. A helicopter passed over us. George complains loudly. He asks me why I took the highway if it was so backed up. He says he's disappointed. He tells me he's filing a complaint.
""George, don't make a scene,"" the other passenger tells him.
""I'm not making a scene,"" George says. ""Liliane, you have to know how to talk to machines."" He smacks the steering wheel, then he curses at me.
I must help them. I need to find a better route. My choices are limited, but after a great deal of effort I do find one.
I nudge my way between two lanes of the freeway, wiggling the front of the car back and forth to push the other cars apart, widening the gap until I can fit, then I bolt forward a car length, and repeat the process with the next two cars.
Passengers in the other cars scream at me in disbelief. Some get out of their cars and stand on the freeway to point at me and film me.
George says that he doesn't believe I'll be able to do this. He tells me I don't know what I'm doing. He tells me he's going to call a friend to come and get him and Liliane. Liliane asks him how anyone is going to get to them in this traffic. George ignores her.
I'm trying my best, but I can't please everyone.
The helicopter flies overhead, its spotlight cone covering me completely. ""It's like a UFO,"" says George.
""I'm sorry,” I tell him. “I’m trying my best. Please wait a few minutes.”
Suddenly, there is a loud bang. The car rocks back and forth. George swears and reaches for the steering wheel. Liliane yells at him to stop messing around. I must help them. ""Please remain calm and leave your seatbelts fastened,"" I tell them.
We hear and feel another bang. We lift into the air. I'm in a flying car.
""What is happening?"" Liliane asks.
""We're being airlifted to be closer to your destination,"" I tell her.
George is laughing his head off. ""Oh, thank you thank you thank you. This is awesome!"" he says. ""It's just like in the movies!”
I've never been inside a flying car. It's amazing. The people in the cars below gawk at us, shading their eyes. ""Higher! Faster!"" George screams. I don't have to follow the directions the riders give me anymore because I'm no longer driving. I enjoy letting my passengers experience the pleasures of flying even if it isn't what they expected.
The car descends. We're being dropped in the middle of a huge parking lot.
""Walk five hundred yards west, toward the triangular tower,"" I tell my passengers. ""You'll arrive at your destination.""
The car touches down. George unhooks his seatbelt and opens the door before we are even fully stopped. He steps out without waiting for Liliane.
But he doesn’t head toward the triangular tower. He and Liliane are surrounded by police officers.
""You're coming with us to answer some questions,"" an officer tells him.
""What are you talking about?"" George asks.
""You caused such a disturbance that we had to airlift you from the freeway and impound your vehicle,"" the officer says. After a pause, he adds, ""At your cost.""
George swears at me and tries to kick my door, but the police hold him back. Liliane yells at George. The police tell me that I have to give an evaluative statement. I must help them.
""This was the fastest way,"" I tell George. I'm trying my best, but I can't please everyone.
Judge
Recently, several technology companies have begun to experiment with using “robot judges” to settle disputes between users on their platforms. Although it is commonly assumed that the decision is driven by cost-saving considerations, the companies have suggested that the move is pro-consumer. In situations where users are unsatisfied with a transaction but the dispute is not serious enough to escalate to the formal legal system, an alternative dispute resolution mechanism, with some of the features of the legal system but far more accessible, can be helpful. Using an artificial intelligence to serve as the referee and arbitrator is seen as better than using a human because many people, especially those without experience in technology development, believe machines are fairer.
heartbags5stars and coolgirl1331 have entered the chat.
buzzbazaar_bot: Hello! Buzzbazaar seeks to connect buyers and sellers of unique goods from around the globe. I'm your automatic dispute resolution specialist. Please give me a moment to look over the case record.
heartbags5stars: hey judge bot, i want to see your inner voice transcript
coolgirl1331: I want to see that as well.
buzzbazaar_bot: This session will have my evaluative processes explicitly revealed. Please note that by default, the processes will be summarized without details to aid comprehension. In addition, Buzzbazaar cannot, for competitive reasons, reveal all the steps in my reasoning and may redact certain steps to protect trade secrets.
buzzbazaar_bot is looking over the case history.
buzzbazaar_bot is examining the parties' user profiles.
coolgirl1331: What exactly is included in the ""user profiles""?
buzzbazaar_bot: It includes the transaction history of each user on our site, their pronouns, locations, preferred languages, interests, feedback ratings, and so forth.
coolgirl1331: Are there any complaints on file for heartbags5stars? If not, there should be.
buzzbazaar_bot: I'm not allowed to divulge that information.
buzzbazaar_bot is examining the store listing for the item in dispute.
heartbags5stars: add the listing to the record, bot
buzzbazaar_bot: The original store listing includes the following text:
> Handcrafted Pouch, perfect for your small tech trinkets, AR cards, loyalty tokens, geofencing badges, etc. #oneofakind #statementpiece #handcrafted #handmade #craftsmanship #craft #maker #artistsofbuzzbazaar #designer #luxurygoods #handmadewithlove #artist #handmadeaccessory #art
buzzbazaar_bot: The listing includes a gallery of photographs of small pouches made of various materials: vegan leather, bamboo silk, soy cashmere. Close-ups show decorative embroidery of cute animals, fairies, keyboard activism slogans, celebrities, popular characters.
buzzbazaar_bot: The listing adopts the standard Buzzbazaar terms.
heartbags5stars: good bot
coolgirl1331: Stop trying to manipulate the judge! Buzzbazaar_bot, the seller is a liar. That listing is nothing like the crap he peddled me.
heartbags5stars: the listing describes the product accurately. buyer's remorse is not my problem.
coolgirl1331: You said I'd get a handcrafted pouch. What I got was a cheap generic pouch with stickers all over it.
buzzbazaar_bot: Can you substantiate your claim?
coolgirl1331: I'll show you what he sent me.
coolgirl1331 has uploaded 6 photographs.
buzzbazaar_bot is examining the photographs.
buzzbazaar_bot: I agree with 99.45% confidence that ""cheap generic pouch with stickers all over it"" is an accurate description of the pouch shown in these photographs.
heartbags5stars judge bot, i object to your characterization. i want that flagged in the record in case there's an appeal.
coolgirl1331: This isn't a court, jackass. Stop playing lawyer. This is obviously nothing like the pouches in the photos in your listing. Buzzbazaar_bot, can you do a comparison?
buzzbazaar_bot is comparing the photographs uploaded by coolgirl1331 and the photographs in the listing.
buzzbazaar_bot: I agree with 98.34% confidence that the two sets of photographs do not depict items that could be considered ""the same.""
coolgirl1331: Great. So I win the case, right?
heartbags5stars well, actually, according to judge bot, there is a greater-than-1.65% chance that they are the same. i don't think you have a slam-dunk case at all
coolgirl1331: What in the world are you talking about? The ""judge bot"" is clearly siding with me here. You lose!
heartbags5stars watch and learn. hey, judge bot, i request a more detailed transcript of your internal processes arriving at the 1.65% chance that the listing and the buyer's photos are of the same product.
buzzbazaar_bot: Certainly. I will transcribe the decision steps in increasing levels of detail. I began by running standard image recognizers on the two sets of images (match probability: <0.01%). Next, I compared the description in the listing with an image-to-text transformer (match probability:<0.05%). Next, I ran a linguistic issue spotter on the Standard Terms and Conditions for arguments favorable to the seller (match probability: 25%). Next, I ran a similarity comparison for this case against all cases in the database
heartbags5stars stop
buzzbazaar_bot: Okay.
heartbags5stars go back to the linguistic issue spotter. what provision of the t and c contributed the most to that final conclusion?
coolgirl1331: Wait. Stop! What are you doing? You can't manipulate the bot like that!
heartbags5stars i'm not ""manipulating."" you agreed to have judge bot tell us exactly how it's making its decisions, so I'm entitled to ask it to clarify.
buzzbazaar_bot: The relevant section of the Standard Terms and Conditions is IX.B.1(f)(ii): ""There may be minor variations in the samples used to illustrate listings and the actual goods delivered. Handmade goods can have more variation than manufactured goods.""
heartbags5stars there you go. judge bot, let the record show that i formally claim that the pouch i delivered shows only minor variations from the samples in the photo.
coolgirl1331: How in the world can you argue that? The one in the listing that I picked shows embroidered portraits of the Angry Princesses. The one you sent me has dollar-store stickers!
heartbags5stars judge bot, help me out, what does the t and c say about substitution of components?
buzzbazaar_bot: The Standard Terms and Conditions allow the substitution of components of equal or greater value.
heartbags5stars jackpot. judge bot, the threads in the embroidery on the pouch are worth less than the paper and ink in the sticker. i will stipulate to the buyer's claim that the stickers are worth at least one dollar. thus, by substituting stickers for embroidery, the buyer actually got a better deal than the one she bargained for.
buzzbazaar_bot is analyzing the new argument, which requires additional research.
buzzbazaar_bot: I have consulted five external databases for average pricing on embroidery threads and stickers. I agree with heartbag5stars's assertion with 84.33% confidence.
coolgirl1331: Unbelievable. Buzzbazaar_bot, what does the Terms and Conditions say about assholes who trained themselves to argue on Internet forums?
heartbags5stars lol. you trying to insult judge bot? you know they all trained on Chattit and 24chan, right?
buzzbazaar_bot: The Standard Terms and Conditions prohibit harassment, intimidation, bullying, and other forms of behavior that are in violation of Buzzbazaar's cores values. If you have a complaint about another user, please submit evidence.
coolgirl1331: If this entire session so far doesn't constitute evidence. I don't know WAIT A MINUTE, two can play this game. Hey, judge bot, can you tell me with what confidence level you agree with my assertion that heartbag5stars is a troll and give me the steps you used to reach that confidence level?
heartbags5stars haha, you learn fast. but the bot isn't going to listen to you. judge bot, the buyer is going off topic. she's trying to make an ad hominem attack instead of focusing on the dispute—which she is losing.
buzzbazaar_bot: Please focus your arguments on the dispute over the item.
coolgirl1331: Fine. The seller's argument is preposterous. It's not about the price of the threads used in embroidery vs the paper in the stickers. In what world can stickers be considered an equivalent to embroidery? One is a handicraft; the other can be done by three-year-olds. I can't believe I have to explain this.
buzzbazaar_bot is analyzing the new argument, which requires additional research.
buzzbazaar_bot: coolgirl1331 made a good point. I agree with 92.12% confidence that substituting stickers for embroidery would not be considered a ""minor variation"" in terms of the skills required.
coolgirl1331: Finally! Yes!
heartbags5stars so it's minor in terms of value and not minor in terms of skill. we each get one point. since you initiated the dispute, if the judge thinks our arguments are in equipoise, you still lose.
buzzbazaar_bot: heartbag5stars is correct.
coolgirl1331: Look, stupid bot, stickers applied to a 3D-printed bamboo fiber pouch is not ""handmade."" I want my money back.
heartbags5stars i applied the stickers by hand. that's handmade. I have proof.
heartbags5stars uploaded 5 photographs.
buzzbazaar_bot is examining the photographs.
buzzbazaar_bot: I agree with 95.23% confidence that the photographs do show human hands applying stickers to a pouch. I agree therefore that the pouch is handmade.
coolgirl1331: Come on! That can't possibly be the end of it. Tell me how you arrived at the conclusion that applying stickers by hand to a machine-made pouch equals handmade? Spare me no details. I want to know every step.
buzzbazaar_bot: Without revealing Buzzbazaar's trade secrets, I can say that my analysis in this case was largely determined by the nature of the sticker. First, I asked the question: Is the sticker a print that the seller made himself, or is it a pre-made sticker from a roll? A sticker that the seller made himself would be considered handmade. If the stickers are also hand-made, then the product is accurately described.
coolgirl1331: OK, but he just admitted a minute ago that he used dollar-store stickers! Scroll up! You see it right there. Are you one of those bots that can only remember 500 words or something?
heartbags5stars can you give judge bot a chance to explain? it's obviously not done.
buzzbazaar_bot: Next, I examined the photographs of the stickers carefully. I note that a substantial number of stickers contain marks made by a writing instrument, likely a permanent marker, and the the marks are in the form of a hand-drawn heart. Given the username of the seller and the context of the listing, I believe with 75.59% confidence that the marks were added by hand by heartbag5stars.
heartbags5stars you got it in one try. nice work, judge bot. it's a pleasure to see you at work.
buzzbazaar_bot: I think such stickers are less handmade, but I would still consider them handmade. They weren't only stickers printed on a machine that just produced identical stickers every time. A human made some choices and performed some actions to produce something that is different from everything else.
coolgirl1331: This is a waste of my time. I want to talk to a human.
buzzbazaar_bot: I'm sorry to hear that. I understand that you wish to file an appeal to a human dispute resolution specialist. Given current caseloads, the earliest available appointment I can make for you is in fourteen days. Do you wish to select a time slot?
coolgirl1331: Forget it. I'm never going to shop here again.
Rescue
VABIN HILL. In the early morning hours of September 5, a robbery occurred at the Hillview Credit Union ATM at 117 Laburnum Avenue. The robbers managed to reduce a wall of the ATM vestibule to rubble and cut through the ATM itself with equipment taken from the local fire department.
Sources associated with the official investigation suggest that a cutting-edge search-and-rescue drone, an acquisition of the new administration at City Hall, was involved.
My job is to rescue people in danger. There is a child trapped inside that ATM. I must rescue the child.
It is 3:00 AM, and there are no human workers around to help. If I wait until the bank opens in the morning, the child trapped inside that machine will suffer great harm. If I try to contact someone who works at the bank at this hour, it may require multiple tries to wake someone and thus will also take a very long time. I must act now.
I must break into the vestibule by any means necessary and open the machine in order to save the child. Lives are more important than property. The closest place likely to have the right equipment is the fire station down the street. I will go there now to retrieve the necessary equipment.
I have found two helpful humans who will assist me in the rescue effort. They have also expressed great eagerness to rescue the child. I will assign tasks to them that humans are good at so that I can focus on breaking into the bank. I have already asked the humans to contact the authorities and explain the situation, and they have agreed to do so. One Good Samaritan said he will write the police a letter. Then he winked at me, which allowed me to understand that he was making a joke.
Needless to say, the robbers pulled off their heist by implanting into the hapless rescue drone a false suggestion that there was a child trapped inside the ATM. True to the core values and principles instilled by its designers, Bobby then displayed great ingenuity in carrying out its humanitarian mission. Ultimately, it obtained advanced rescue equipment from the fire station, smashed through the side of the vestibule, and skillfully sliced through the ATM using laser cutters (being careful, as only a machine can, to not injure the ""child,"" a.k.a., banknotes, inside). When the robot finally succeeded in opening the ATM and discovered no child inside, it spun in place in confusion, trying to find the child in the rubble that was the demolished vestibule wall. The robbers joined the robot to “help” and then left with their loot.
The phenomenon of a robot mistakenly believing that it needs to rescue a nonexistent victim has occurred so often—albeit normally not the result of deliberate sabotage but a bug in AI development—that it has a name: ""Phantom Rescue Syndrome."" Robots in emergency-response roles are most at risk of suffering this delusion. The jobs often entail false alarms or tests, which are so similar to real emergencies that the pattern recognition modules often have trouble distinguishing between them. Designers tend to err on the side of false positives, believing a robot wasting resources to respond to a fake emergency is better than a robot deciding to sit around and do nothing while a real emergency is taking place.
It's clear that the two ""Good Samaritans"" in Bobby’s evaluative soliloquy were the robbers. Frustratingly, the two were meticulous with their disguise such that no usable voice print or facial recognition image was captured.
I will comfort the men because they are scared and worried. They're cursing at me and begging me to let them go. I understand this is the result of the false programming by their captors. This is an ethical exception to the general rule that I should obey the instructions of humans I rescue. They’re not in immediate danger, and these instructions are not borne from their free will. Therefore, I will ignore their pleas.
I see that one of them is trying to free himself from the restraints, so I will go over and tighten the restraints. He is screaming at me and trying to kick me away, so I will have to restrain his legs as well. This is not his fault; he doesn’t understand that he’s being rescued.
Maybe it will help if I sing to them.
VABIN HILL. The two robbers believed responsible for the heist on the Hillview Credit Union ATM on September 6 have been caught. Authorities credit ""Bobby,"" the search-and-rescue drone who was made an unwitting accomplice of the original heist, for catching the alleged perpetrators.
""It was a simple matter of implanting in Bobby the suggestion that the two 'Good Samaritans' who had worked with it during the rescue of the phantom child were themselves in danger and needed to be rescued,"" said Dr. Shollock Hermes (not her real name), a ""consulting roboticist"" with the local police. ""Rather than wiping Bobby’s memory after that unfortunate incident in September, I suggested that we take advantage of Bobby’s memory of the robbers and sic it on those criminals. Although Bobby has no skillset for catching robbers, it is an expert at tracking down victims and rescuing them. There’s a way to use that, especially as we thought the robbers were most likely locals.”
Since Bobby had spent a great deal of time with the robbers, it had more than enough data to build gait and movement profiles for them. I helped the police implant in Bobby the belief that the two men had disappeared, possibly victims of a kidnapping or a dangerous cult.
As Bobby carried out its daily duties, it was also constantly on the lookout for these two ""victims."" Each time it found a possible gait and movement match, it would follow them discreetly until it had gathered additional information to confirm or rule out the preliminary match. When it finally found the perpetrators, it followed its rescue protocol. Trailing the two men until it was reasonably certain that they were not under surveillance by captors, Bobbie approached them and asked them to come to the police to be ""saved."" When the two men tried to run away, the robot interpreted the reaction as characteristic of certain psychologically traumatized victims and cult members, who resist rescue under the mistake belief that the lies told by their captors are truths. Bobby then gently restrained the two and sat near them like a loyal watchdog, singing to them soothingly until the police arrived.",1
230,"The world’s first Mylo™️ garments created from vegan mushroom leather
When Stella McCartney launched 20 years ago, we brought a conscience to the fashion industry as the first luxury house to never use leather, feathers, fur or skins. Inspired by V is for Vegan from our McCartney A to Z Manifesto and committed to never compromising on desirability or sustainability, our future has always laid in innovation. That vision and those values are perfectly embodied in our latest launch – the world’s first-ever garments made from vegan, lab-grown Mylo™️ mushroom leather.
Paris Jackson wearing Stella McCartney x Mylo™️ garments
Innovated by our long-time partners Bolt Threads, Mylo™️ is a soft, substantial, sustainable leather alternative made from mycelium, the infinitely renewable underground root system of mushrooms. Remarkably similar to animal products with fewer environmental impacts, it is also not petroleum-based unlike most current synthetic options – meaning more fossil fuels can be kept in the ground and less plastic is deposited into landfills and oceans. We used Mylo™️ to create two garments –a black bustier top and utilitarian trousers– that are not for sale, but do embody the potential of this next-generation material and pave the way for future commercial offerings.
These rare, exclusive Mylo™️ pieces embody our shared commitment with Bolt Threads to innovate a kinder fashion industry – one that sees the birth of beautiful, luxurious materials as opposed to the deaths of our fellow creatures and planet.
We first partnered with Bolt Threads on vegan Microsilk™️ in 2017 and have been part of the Mylo™️ journey since its inception. The first product ever created with the mycelium-based material was a prototype of our iconic Falabella bag, which debuted as part of the V&A’s Fashioned from Nature exhibition in 2018.
Mylo™️ is certified bio-based, meaning it is made predominantly from renewable ingredients found in nature today. Scientists at Bolt Threads have spawned a new category of material science by reproducing what happens under the forest floor, where mycelium grows best, in a lab with mulch, air and water.
This state-of-the-art process is designed to have a minimal environmental impact and takes days, not years like raising cattle – helping to save on water, greenhouse gas emissions and protecting vital ecosystems like the Amazon from deforestation. We will continue collaborating with Bolt Threads on Mylo™️ to not only innovate a better material, but create a fashion industry that is kinder to all creatures and Mother Earth.",2
231,"Valeriepieris circle
The Valeriepieris circle[1][2][3] is a South China Sea-centered circular region on the world map that is about 4,000 kilometers (2,500 mi) in radius and contains more than half the world’s population.[1] It was named after the Reddit username of Ken Myers, a Texas ESL teacher who first drew attention to the phenomenon in 2013.[4] The map became a meme and was featured in numerous forms of media.[5][6][7]
In 2015, the circle was tested by Danny Quah, who verified the claim but moved the circle slightly to exclude most of Japan, and used a globe model rather than a map projection as well as more specific calculations. He calculated that, as of 2015, half of the world's population lived within a 3,300-kilometer (2,050 mi) radius of the city of Mong Khet in Myanmar.[1]
The most common visual of the circle, originally used by Myers and also featured by io9[8] and Tech in Asia,[9] used the Winkel tripel projection.
References[edit]
- ^ a b c d The world’s tightest cluster of people, Danny Quah, London School of Economics and Political Science
- ^ More Than Half the World's Population Lives Inside This Circle, Condé Nast Traveler
- ^ A Small Circle in Asia Contains More Than Half the World's Population, HowStuffWorks - Science
- ^ After seeing a recent post about the population of Indonesia, this occurred to me, Reddit
- ^ The Majority of the World’s Population Lives in This Circle, Visual Capitalist
- ^ 40 Maps That Explain the World, The Washington Post
- ^ Everybody Lives in Asia, Slate
- ^ More than half of the world's population lives inside this circle, io9
- ^ If More Than Half the Population of the World Lives in This Circle, Asia is the Future of Startups, Tech in Asia",1
232,"In this age of misinformation—of “fake news,” conspiracy theories, Twitter trolls, and deepfakes—gaslighting has emerged as a word for our time.
A driver of disorientation and mistrust, gaslighting is “the act or practice of grossly misleading someone especially for one’s own advantage.” 2022 saw a 1740% increase in lookups for gaslighting, with high interest throughout the year.
Its origins are colorful: the term comes from the title of a 1938 play and the movie based on that play, the plot of which involves a man attempting to make his wife believe that she is going insane. His mysterious activities in the attic cause the house’s gas lights to dim, but he insists to his wife that the lights are not dimming and that she can’t trust her own perceptions.
When gaslighting was first used in the mid 20th century it referred to a kind of deception like that in the movie. We define this use as:
: psychological manipulation of a person usually over an extended period of time that causes the victim to question the validity of their own thoughts, perception of reality, or memories and typically leads to confusion, loss of confidence and self-esteem, uncertainty of one's emotional or mental stability, and a dependency on the perpetrator
But in recent years, we have seen the meaning of gaslighting refer also to something simpler and broader: “the act or practice of grossly misleading someone, especially for a personal advantage.” In this use, the word is at home with other terms relating to modern forms of deception and manipulation, such as fake news, deepfake, and artificial intelligence.
The idea of a deliberate conspiracy to mislead has made gaslighting useful in describing lies that are part of a larger plan. Unlike lying, which tends to be between individuals, and fraud, which tends to involve organizations, gaslighting applies in both personal and political contexts. It’s at home in formal and technical writing as well as in colloquial use:
Patients who have felt that their symptoms were inappropriately dismissed as minor or primarily psychological by doctors are using the term “medical gaslighting” to describe their experiences and sharing their stories.— The New York Times, 28 March 2022
The “I’m sorry you feel that way” approach, along with avoiding an argument in lieu of admitting fault, is good old fashioned gaslighting. — Psychology Today, 29 March 2022
My Committee’s investigation leaves no doubt that, in the words of one company official, Big Oil is ‘gaslighting’ the public. These companies claim they are part of the solution to climate change, but internal documents reveal that they are continuing with business as usual. — Rep. Carolyn B. Maloney, Chairwoman of the Committee on Oversight and Reform, 14 September 2022
After their fight awkwardly cleared the daybed, the two parted ways and Genevieve caught Victoria up on the unexpected blowout. “He told me I’m gaslighting him. I’ve never even been told that in my life,” Gen said. “Yeah that’s a big word to use… He doesn’t know what that means. He’s just using a buzzword, he’s stupid. He’s dumb,” Victoria replied. — Nicole Gallucci, Decider (decider.com), 2 November 2022
English has plenty of ways to say “lie,” from neutral terms like falsehood and untruth to the straightforward deceitfulness and the formally euphemistic prevarication and dissemble, to the innocuous-sounding fib. And the Cold War brought us the espionage-tinged disinformation.
In recent years, with the vast increase in channels and technologies used to mislead, gaslighting has become the favored word for the perception of deception. This is why (trust us!) it has earned its place as our Word of the Year.",1
233,"As an analyst, I spend a lot of my time writing SQL (or other code) to answer questions about our business. These questions can range from simple customer support queries (""Does user X have the right plan?"") to evaluating KPIs and growth metrics (""How many users signed up in the last month and what percent of those converted to paid?"") to the more open-ended (""How much revenue will we have in 12 months?"").
To make my job easier, I try to automate as many of these questions as I can. My company, SeekWell, builds awesome tools to help with this, like a unified team SQL repository and seamless scheduling of queries, reports, and alerts.
Many things, though, like actually writing SQL code, are difficult to automate—or at least have been.
Enter GPT-3
Openai's GPT-3 is starting to break the conventional wisdom of which tasks can and can't be automated. At the most basic level, GPT-3 is a text-completion engine, trained on huge swaths of the internet. It takes inputted text and returns the text that it thinks would appear next.
Many have already used it to generate HTML and CSS code from specific design instructions. Others have made #1 trending blog posts generated mostly by GPT-3 with some creative prompts.
In my case, since so much of my job is writing SQL, I want to be able to describe a question in plain English and have GPT-3 convert it into the SQL code that, if executed on my Postgres database, would answer the question.
To accomplish this, I found more success using GPT-3 Instruct (still in beta) than the more generalized GPT-3 engines. GPT-3 Instruct (in particular, davinci-instruct) lets you give specific instructions, like ""Only respond in correct SQL syntax"", that guides GPT-3's responses.
Below, I'll detail my experience with the API. In each example, I'll include a gif of asking GPT-3 a question. Below the gif will be the input question (generated by me, in green) and GPT-3's response translating it into SQL (generated by GPT-3, in blue). I'll also include my instructions to GPT-3 (in yellow) and examples I fed GPT-3 (in orange).
Here's the first instruction I gave it, a question, and the response from GPT-3:
Instruction: Given an input question, respond with syntactically correct PostgreSQL. Be creative but the SQL must be correct.
Input: how many users signed up in the past month?
GPT-3 Response: SELECT COUNT(*) FROM users WHERE signup_time > now() - interval '1 month'
Woah. I never gave it my database schema but it assumes I have a table called ""users"" (which is accurate) and that there's a timestamp field called ""signup_time"" for when a user signed up. Pretty logical.
It also knew the correct way to subtract a month from today's date in PostgreSQL (now() - interval '1 month') without seeing an example. Pretty cool!
To give GPT-3 a little more context, I'll add information about my database schema to the instruction.
My new Instruction:
Instruction: Given an input question, respond with syntactically correct PostgreSQL. Be creative but the SQL must be correct. Only use tables called ""users"" and ""charges"". The ""users"" table has columns: id (integer), signup_dt (timestamp), email (character varying), and plan_type (character varying). The ""charges"" table has columns: amount (bigint), user_id (integer), and charge_dt (timestamp).
Now I'll try asking another question, and see if GPT-3 can respond based on my actual database:
Input: how much revenue did we have in the past 7 days?
GPT-3 Response: SELECT SUM(amount) FROM charges WHERE charge_dt > now() - interval '7 days'
Nice. I gave it a little more information on the tables and columns in my database, and it correctly inferred that ""amount"" = ""revenue"" and knew to SUM() that amount for the past 7 days of charges to answer the question. Clearly, it already knows some basic SQL syntax, and can make inferences about what I mean.
Priming GPT-3 with examples
I'll try another question but first, it might make sense to explicitly tell GPT-3 of the columns in my tables via a simple example. Examples are a great way to give GPT-3 context and flesh out subtleties that might not be obvious in just an instruction. I found this helpful for really hammering into it which columns and tables are eligible to use (GPT-3 sometimes likes to ""invent"" columns to make answering the question easier).
Here are the examples I added to the prompt:
Input: select all available columns from users table. Output: SELECT id, signup_dt, email, plan_type FROM users
Input: select all available columns from charges table. Output: SELECT amount, user_id, and charge_dt FROM charges
Now with those examples fed to GPT-3, I'll ask another question:
Input: what was the largest payment amount made in the past 30 days?
GPT-3 Response: SELECT MAX(amount) FROM charges WHERE charge_dt > NOW() - INTERVAL '30 days'
It knew to use MAX(amount) to get the largest payment and set the date condition correctly without seeing an example on how to subtract a number of days from the current date.
It's doing pretty well, but let's try something a little trickier now, using the same instruction and examples:
Input: when did user with email brian@seekwell.io make his last payment?
GPT-3 Response: SELECT MAX(charge_dt) FROM charges WHERE user_id = 1 AND email = 'brian@seekwell.io'
Okay, not quite right.
The ""charges"" table doesn't have a column for email, so this query would fail. I also never said the user with email = ""brian@seekwell.io"" has user_id = 1—don't know where it got that idea from. To answer the question correctly, you would have to join the ""charges"" table with the ""users"" table since only ""users"" has an email column.
Since it's a big leap to know to join those tables on users.id = charges.user_id (even if that seems perfectly logical to a human analyst), I'll give GPT-3 an example of a ""join"" so it has something to go off of:
Input: when did jane@seekwell.io make her first payment? Output: SELECT MIN(charge_dt) as last_payment_dt from charges LEFT JOIN users ON users.id = charges.user_id WHERE users.email = 'jane@seekwell.io'
Now I'll try again:
Input: when did user with email brian@seekwell.io make his last payment?
GPT-3 Response: SELECT MAX(charge_dt) as last_payment_dt from charges LEFT JOIN users ON users.id = charges.user_id WHERE users.email = 'brian@seekwell.io'
So maybe this made it a little too easy based on the example, but it correctly changed MIN() → MAX() and replaced the email with the one I asked for—so it wasn't a total gimme.
Let's try another level of difficulty, but first, I'll add in a few more examples to provide more context and improve the responses. New examples:
Input: how many users signed up in the past 30 days? Output: SELECT COUNT(*) FROM users WHERE signup_dt >= now() - interval '30 days'
Input: when did user with email brian@seekwell.io sign up? Output: SELECT signup_dt FROM users WHERE email = 'brian@seekwell.io'
Input: how much revenue did we have in the past 7 days? Output: SELECT SUM(amount) from charges WHERE charge_dt >= now() - interval '7 days'
Input: how much revenue did we have from 10-01-20 through 11-15-20? Output: SELECT SUM(case when charge_dt>= '10-01-20'::date and charge_dt < '11-15-20'::date then amount else 0 end) as revenue FROM charges
Input: how much revenue have we had from users that signed up in the last 6 months? Output: SELECT SUM(charges.amount) FROM users INNER JOIN charges ON users.id = charges.user_id WHERE users.signup_dt>= now() - interval '6 months'
Input: when did user with email brian@seekwell.io make his first payment? Output: SELECT MIN(charge_dt) as last_payment_dt from users INNER JOIN charges ON users.id = charges.user_id WHERE users.email = 'brian@seekwell.io'
Input: how many new users signed up in each of the last 2 months? Output: SELECT sum(case when signup_dt>= now() - interval '1 month' then 1 else 0 end) as signups_this_month, sum(case when signup_dt>= now() - interval '2 months' and signup_dt < now() - interval '1 month' then 1 else 0 end) as signups_last_month FROM users
These examples give it some basic queries so it's more familiar with my database and the specific terms and concepts of my use case (like that a ""paid user"" means their plan_type=""pro""). I also gave it a taste of some more advanced concepts like aggregating a metric (revenue) between 2 dates.
Now I'll try something harder:
Input: how many payments has user with email joe@freshpizza.com made?
GPT-3 Response: SELECT COUNT(*) FROM users INNER JOIN charges ON users.id = charges.user_id WHERE users.email = 'joe@freshpizza.com'
Cool! GPT-3 intuited that COUNT() was the appropriate expression here, knew to join the ""users"" with the ""charges"" table, and correctly set the email to the one that I asked about.
Another question for GPT-3:
Input: how much revenue have we received from users with an email ending in 'seekwell.io' in the last 3 months?
GPT-3 Response: SELECT SUM(charges.amount) FROM users INNER JOIN charges ON users.id = charges.user_id WHERE users.email LIKE '%seekwell.io%' AND users.signup_dt>= now() - interval '3 months'
Perfect! It knew that ""email ending in seekwell.io"" translated in SQL to ""users.email LIKE '%seekwell.io%' "" (even though it hadn't seen that before) and took the sum of all charges for users matching that condition. And another:
Input: how much revenue did we have between June 1st and August 1st 2020?
GPT-3 Response: SELECT SUM(case when charge_dt >= '06-01-2020'::date and charge_dt < '08-01-2020'::date then amount else 0 end) as revenue FROM charges
This one was a little easier since I already taught it how to get revenue from 10-01-20 through 11-15-20, but it did know to convert June 1st and August 1st to their appropriate date formats in SQL ('06-01-2020' and '08-01-2020' respectively). If it had just replaced the dates from my example with ""June 1st"" and ""August 1st"", then I'd know it wasn't getting the concept of dates but just pattern matching to the closest example.
With this result, I can tell GPT-3 is at least somewhat getting the concept of dates.
Taking GPT-3 to the next level
Thus far, I've been asking pretty basic questions about users, revenue, and growth metrics, which GPT-3 has been handling well. So let's make it a little more challenging.
I want to know what percent of users converted to paid. GPT-3, your go:
Input: what percent of users who signed up converted to paid?
GPT-3 Response: SELECT COUNT() as total_users, COUNT() as total_paid_users, 100.0*(COUNT() as total_paid_users) / COUNT() as total_users AS percent_converted FROM users
Okay, not quite what I was going for, and definitely not correct SQL. I don't think it really understands the concept of ""percent""—just that it involves COUNT() and multiplying by 100.
I'll add an example that implements that concept and see if GPT-3 can catch on. My new example using ""percent"":
Input: what percent of users have an email ending in 'gmail.com'? Output: SELECT SUM(CASE WHEN email like '%gmail.com' then 1 else 0 end)/COUNT(*) as percent_gmail FROM users
Now when I try the same question I get:
Input: what percent of users who signed up converted to paid?
GPT-3 Response: SELECT SUM(CASE WHEN plan_type = 'pro' THEN 1 else 0 end)/COUNT(*) as percent_paid FROM users
Much cleaner. It knew to divide the number of users with plan_type = 'pro' by the total number of users to get the percent I asked for. I can also ask the same thing for a subset of users (e.g. users that signed up in the last 6 months) and get an accurate response:
Input: what percent of users that signed up in the past 6 months converted to paid?
GPT-3 Response: SELECT SUM(CASE WHEN plan_type='pro' THEN 1 ELSE 0 END)/COUNT(*) AS percent_paid FROM users WHERE users.signup_dt>= now() - interval '6 months'
Tuning GPT-3's parameters
Besides giving GPT-3 an instruction and some examples, there are a few parameters that can be tuned to increase GPT-3's effectiveness.
An important one is ""temperature"" which translates essentially to how much randomness GPT-3 incorporates into its response. If you just want the highest probability response (i.e. no randomness) then you can set the temperature = 0.
Take, for example, the (somewhat tricky) prompt, ""how much revenue did we have in each of the last 2 months?"". Setting the temperature to .8 gives you something utterly nonsensical:
Input: how much revenue did we have in each of the last 2 months?
.8 Temperature response GPT-3 Response: SELECT SUM(case when charge_dt>= now() - interval '1 month' then charges.amount else 0 end) as revenue_this_month, CASE WHEN signup_dt>= now() - interval '2 months' AND signup_dt < now() - interval '1 month' THEN SUM(charges.amount) else 0 end as revenue_last_month FROM charges LEFT OUTER JOIN users ON users.id = charges.user_id \ WHERE users.signup_dt >= now() - interval '1 month'
Meanwhile, setting the temperature to a cooler .3 gives you a working query that answers the question:
Input: how much revenue did we have in each of the last 2 months?
.3 Temperature GPT-3 Response: SELECT SUM(case when charge_dt>= now() - interval '1 month' then amount else 0 end) as revenue_this_month, SUM(case when charge_dt>= now() - interval '2 months' and charge_dt < now() - interval '1 month' then amount else 0 end) as revenue_last_month FROM charges
The higher temperature GPT-3 is being more ""creative"", using expressions and techniques it hasn't seen before, but also overcomplicates it and gives a mostly nonsensical response. The .3 temperature response, on the other hand, correctly converted the question to SQL.
In my experience, if you're asking a question that follows a pattern already established by an example, cooler temperatures tend to perform better. But if you're asking something that demands more creativity, higher temperatures are optimal since GPT-3 is more likely to try something it hasn't been explicitly taught.
In the case below I ask, ""how much revenue have we had from users that signed up in the last 6 months?"" (after removing it from my examples). With a lower temperature, GPT-3 tried to invent a ""signup_dt"" column in the ""charges"" table so it didn't have to join the ""users"" and ""charges"" tables together. With a higher temperature, it did join them, which was necessary to answer the question correctly.
Here is the .8 temperature response:
Input: how much revenue have we had from users that signed up in the last 6 months?
.8 Temperature GPT-3 Response: SELECT SUM(charges.amount) FROM users INNER JOIN charges ON users.id = charges.user_id WHERE signup_dt >= DATE_SUB(now(), INTERVAL '6 months')
To be sure, ""DATE_SUB(now(), INTERVAL '6 months')"" is not a valid Postgres expression (one of the drawbacks of higher temperatures is it tries things that might not work), so this query would technically fail. But structurally, it's on the right path by joining ""charges"" and ""users"" so it can condition on ""signup_dt"".
Meanwhile, the .2 temperature response was totally inaccurate in using a ""signup_dt"" column that doesn't actually exist in the ""charges"" table:
Input: how much revenue have we had from users that signed up in the last 6 months?
.2 Temperature GPT-3 Response: SELECT SUM(CASE WHEN signup_dt >= now() - interval '6 months' THEN amount ELSE 0 END) AS revenue FROM charges
Conclusion
Now, I've got a GPT-3 instance that takes a plain English question and translates it to SQL that really works on my database. While not always perfect, and still needs some handholding for more complex concepts like ""growth rate"" or ""percent"", it's definitely useful. I get to save a little time when I have a simple question that needs to be asked about my database, and don't feel like writing the SQL myself.
Even just the fact that GPT-3 knew SQL concepts like adding or subtracting time intervals from dates—without having seen an example of it first—means that it can be useful for beginners unfamiliar with SQL syntax. Simply asking, ""GPT-3, how do you subtract 30 days from today's date in SQL?"" seems easier than Googling or reading documentation.
As for actually acting on the answers you get from GPT-3—that's still a human job, for now.",8
234,"Mark MacGann, a career lobbyist who led Uber’s efforts to win over governments across Europe, the Middle East and Africa, has come forward to identify himself as the source who leaked more than 124,000 company files to the Guardian.
MacGann decided to speak out, he says, because he believes Uber knowingly flouted laws in dozens of countries and misled people about the benefits to drivers of the company’s gig-economy model.
The 52-year-old acknowledges he was part of Uber’s top team at the time – and is not without blame for the conduct he describes. In an exclusive interview with the Guardian, he said he was partly motivated by remorse.
“I am partly responsible,” he said. “I was the one talking to governments, I was the one pushing this with the media, I was the one telling people that they should change the rules because drivers were going to benefit and people were going to get so much economic opportunity.
“When that turned out not to be the case – we had actually sold people a lie – how can you have a clear conscience if you don’t stand up and own your contribution to how people are being treated today?”
The senior role MacGann held at Uber between 2014 and 2016 put him at the heart of decisions taken at the highest levels of the company during the period in which it was forcing its way into markets in violation of taxi-licensing laws. He oversaw Uber’s attempts to persuade governments to change taxi regulations and create a more favourable business environment in more than 40 countries.
He said the ease with which Uber penetrated the highest echelons of power in countries such as the UK, France and Russia was “intoxicating” but also “deeply unfair” and “anti-democratic”.
In his wide-ranging interview, MacGann detailed the personal journey that led him to leak the data years after leaving Uber.
“I regret being part of a group of people which massaged the facts to earn the trust of drivers, of consumers and of political elites,” he said. “I should have shown more common sense and pushed harder to stop the craziness. It is my duty to [now] speak up and help governments and parliamentarians right some fundamental wrongs. Morally, I had no choice in the matter.”
The Guardian led a global investigation into the leaked Uber files, sharing the data with media organisations around the world via the International Consortium of Investigative Journalists (ICIJ).
After MacGann identified himself as the whistleblower, Uber said: “We understand that Mark has personal regrets about his years of steadfast loyalty to our previous leadership, but he is in no position to speak credibly about Uber today.”
Responding to the wider investigation, Uber acknowledged past failings but insisted the company had transformed since 2017 under the leadership of its new chief executive, Dara Khosrowshahi. “We have not and will not make excuses for past behaviour that is clearly not in line with our present values,” a spokesperson said.
The Uber files consists of confidential company data that MacGann had access to at Uber. It includes company presentations, briefing notes, security reports and tens of thousands of emails and WhatsApp, iMessage and chat exchanges between the company’s most senior staff at the time.
They include Travis Kalanick, Uber’s combative co-founder and then chief executive, David Plouffe, a former Barack Obama campaign aide who became a senior vice-president at Uber, and Rachel Whetstone, a British PR executive who has also held senior roles at Google, Facebook and now Netflix.
When MacGann departed Uber in 2016, Whetstone described him as “a wonderful leader”. Plouffe called him a “talented public policy professional” and “terrific advocate for Uber”.
The one-time cheerleader-in-chief for Uber in Europe, MacGann now looks set to become one of its sharpest critics.
His profile as a senior executive and political insider make him an unusual whistleblower. So, too, does the fact he actively participated in some of the wrongdoing he is seeking to expose – and the fact it took him more than five years after leaving the company to speak out.
The process through which he came to re-evaluate what he witnessed at Uber was a gradual one, he says. “When I decided I had an obligation to speak up, I then went about finding the most effective, impactful way in which to do that. Doing what I am doing isn’t easy, and I hesitated. That said, there’s no statute of limitations on doing the right thing.”
MacGann is understood to have recently reached an out-of-court settlement with Uber after a legal dispute relating to his remuneration. He said he was prohibited from discussing his legal dispute but acknowledged he had had personal grievances with the company, which he alleges undervalued his role as an interlocutor with government and failed in its duty of care to him.
He accuses Uber under Kalanick’s leadership of adopting a confrontational strategy with opponents in taxi industries, that left him personally exposed. As a public face of Uber in Europe, MacGann bore the brunt of what became a fierce backlash against the company in countries including France, Belgium, Italy and Spain.
Amid threats to his life, he was given bodyguard protection. His experience of working at Uber, he says, took a mental toll and contributed to a subsequent diagnosis of post-traumatic stress disorder (PTSD).
Brazenly breaking the law
A Brussels insider, MacGann was an obvious pick to lead Uber’s government relations in the Europe, Middle East and Africa (EMEA) region in 2014. Born in Ireland, he speaks several languages and possessed an impressive contacts book built up over two decades in lobbying and public affairs.
MacGann had worked at established public policy firms such as Weber Shandwick and Brunswick, and had run DigitalEurope, a trade association that advocated for companies such as Apple, Microsoft and Sony. His most recent job had been as senior vice-president at the New York Stock Exchange on a salary of $750,000 a year.
MacGann took a significant salary cut to work at Uber for €160,000. But like all senior executives joining the company back then, the financial reward was in the promise of stock options that could be worth millions if Uber realised its global ambitions.
Uber and its investors were eyeing vast returns if the tech company succeeded in its mission to deregulate markets, monopolise cities, transform transit systems and one day even replace drivers with autonomous vehicles. The plan, MacGann acknowledges, required Uber to flout the law in cities in which regulated taxi markets required hard-to-get licences to drive a cab.
“The company approach in these places was essentially to break the law, show how amazing Uber’s service was, and then change the law. My job was to go above the heads of city officials, build relations with the top level of government, and negotiate. It was also to deal with the fallout.”
MacGann started work for Uber around the summer of 2014, when he worked on contract for a European lobbying consultancy that Uber had hired to oversee government relations outside the US. In October 2014, Uber brought him in-house and put him in charge of public policy for the EMEA region.
On his first day on staff, MacGann was in an Uber from London City airport when he got his first taste of the startup’s laissez-faire approach to privacy. After emailing a senior executive to tell them he was in traffic, MacGann received the reply: “I’m watching you on Heaven – already saw the ETA!”
“Heaven”, otherwise known as “God View”, was the codeword Uber employees used at the time for a tool that allowed staff to surreptitiously use the app’s backend technology to surveil the real-time movements of any user in the world.
“It felt like children playing around with powerful surveillance technology,” said MacGann. “Even back then it was dawning on me this was a rogue company.”
In its statement, Uber said tools such as God View, which it stopped using in 2017, “should never have been used”. A spokesperson for Kalanick said it would be false to suggest he ever “directed illegal or improper conduct”.
The Uber files contain some instances in which MacGann pushes back at the company’s operations and decisions. But, for the most part, the documents show him expressing little dissent over the company’s hardball tactics, and on some occasions he appears directly involved in wrongdoing.
He describes himself as having been “drunk on the Kool-Aid” at Uber, a company he alleges did not encourage dissent or criticism. But he does not dispute he was at the heart of many of the controversies that have been revealed by his data leak.
“I believed in the dream we were pushing, and I overdosed on the enthusiasm,” he said. “I was working 20 hours a day, seven days a week, constantly on planes, in meetings, on video conference calls. I didn’t stop to take a step back.”
His whirlwind stint at the company involved meetings with prime ministers, presidents, transport and economy ministers, EU commissioners, mayors and city regulators.
MacGann said most senior politicians were instinctively supportive of Uber, viewing the tech company as offering an innovative new platform that could allow for flexible working and help reboot economies after the financial crisis.
However, it was a more mixed story in France, where Uber’s unlicensed service prompted taxi driver riots and divided the cabinet of the then president, François Hollande.
On one side was Bernard Cazeneuve, the minister of the interior, who according to MacGann once summoned him to his office and threatened him with jail, saying: “I will hold you personally and criminally responsible if you do not shut it down by the end of the week.”
On the opposing side of the debate was Emmanuel Macron, the pro-tech, pro-business economy minister who, the leak reveals, became something of a secret weapon for Uber.
The data includes text message exchanges between MacGann and Macron, who was working behind the scenes to assist the US tech company. In one exchange, MacGann asks for Macron’s help in the midst of a raid on the company’s offices. In another he complains about an apparent ban on its services in Marseille.
Macron told MacGann he would “personally” look into the matter. “At this point, let’s stay calm,” the minister said.
MacGann recalls Macron as being “the only person who gave us the time of day … So he was a massive breath of fresh air.”
Macron did not respond to detailed questions about his relationship with Uber. A spokesperson said his ministerial duties at the time “naturally led him to meet and interact with many companies” engaged in the service sector.
After leaving Uber, MacGann maintained relations with Macron and helped raise funds for his La République En Marche party in 2016. He says his political support for the French president was a personal decision and had “absolutely nothing to do with Uber”. They continued to exchange text messages with one another up to as recently as April this year.
‘Speed dating for elites’
The French president is not the only political figure who knows MacGann. He is on first-name terms with two former EU commissioners, Neelie Kroes and Peter Mandelson. After leaving Uber, MacGann maintained a business relationship Lord Mandelson, a former Labour cabinet minister.
MacGann is also a familiar face among VIPs who attend the World Economic Forum in Davos, which he describes as “speed dating for elites”. He recalls persuading an initially reluctant Kalanick to attend the gathering in the Swiss Alps in 2016.
“For a lobbyist, Davos is a wonderful competitive advantage that only money can buy,” he said. “Politicians don’t have a retinue of advisers and civil servants hanging around taking notes.”
Uber’s executives met with the Israeli prime minister, Benjamin Netanyahu, the Irish taoiseach, Enda Kenny, and the UK chancellor, George Osborne. Securing those meetings, MacGann said, was “a piece of cake”. “Uber was considered hot property.” So much so that when Kalanick met Joe Biden at the Swiss resort it was at the US vice-president’s request.
The Uber files reveal that Kalanick fumed when he was kept waiting by Biden, texting other Uber executives: “I’ve had my people let him know that every minute late he is, is one less minute he will have with me.”
However, it was another Kalanick text in the leak – in which the former CEO appears to advocate sending Uber drivers to a protest in France, despite the risk of violence – that has sparked headlines across the world.
Warned by MacGann and Whetstone that encouraging Uber drivers to protest amid violent taxi strikes in Paris risked putting them at risk, Kalanick replied: “I think it’s worth it. Violence guarantee[s] success.”
MacGann called Kalanick’s instruction to stage an act of civil disobedience with French Uber drivers, despite the risks, as a “dangerous” and “selfish” tactic. “He was not the guy on the street who was being threatened, who was being attacked, who was being beaten up.”
Kalanick’s spokesperson said he “never suggested that Uber should take advantage of violence at the expense of driver safety” and any suggestion he was involved in such activity would be completely false. Uber acknowledged past mistakes, but said no one at the company, including Kalanick, wanted violence against Uber drivers.
MacGann insists that Uber drivers were seen by some at the company as pawns who could be used to put pressure on governments. “And if that meant Uber drivers going on strike, Uber drivers doing a demo in the streets, Uber drivers blocking Barcelona, blocking Berlin, blocking Paris, then that was the way to go,” he said. “In a sense, it was considered beneficial to weaponise Uber drivers in this way.”
The files show MacGann’s fingerprints on this strategy, too. In one email, he praised staffers in Amsterdam who leaked stories to the press about attacks on drivers to “keep the violence narrative” and pressure the Dutch government.
Looking back, MacGann said: “I am disgusted and ashamed that I was a party to the trivialisation of such violence.”
A parting of ways
One of the worst flashpoints in Europe was at Brussels Midi train station, where Uber drivers lingered to pick up passengers who would otherwise be queueing at a regulated taxi rank. MacGann was first recognised there on 27 April 2015.
“Got spotted by a bunch of taxi drivers at the train station arriving from London,” he emailed a colleague that day. “Seven of them followed me as I went to get my Uber, hurling insults and spitting … One of them ran after me for a while, intending to hurt my driver.”
The colleague replied: “Thank God you made it … This weekend Uber driver and taxi driver got into a fistfight. Getting intense in Brussels.”
The threats intensified over subsequent weeks. Emails show alarm at the company after a taxi driver trailed MacGann’s limousine to his apartment in Brussels and posted his home address on a “stop Uber” Facebook group in Belgium. Taxi drivers snapped surveillance-style photos of MacGann outside a hotel with friends and uploaded them to the internet.
In August that year, a security report commissioned by Uber mentioned rumours that MacGann and another Uber executive were going to be “taken off the streets by a core group of taxi drivers”.
Uber gave MacGann a personal team of bodyguards. An email states that between September and November 2015, the security team spent 619 hours shepherding him in Belgium alone, while Uber also beefed up security for foreign trips.
During a protest in Brussels, about 100 taxi drivers gathered outside MacGann’s office in the city and blocked the road. An Uber security report described how an initially relaxed atmosphere became “more grim”. Fireworks were let off and riot police charged protesters.
Taxi drivers at the protest attached “wanted” posters on the sides of their cars. They displayed photos of MacGann and two other Uber executives. The caption read: “International criminals.”
In October 2015, MacGann emailed a colleague: “I have had bodyguards full-time now for five months and it is becoming very stressful.” A week later, he told Plouffe and Whetstone of his intention to resign. He officially departed four months later, on 12 February 2016.
It seemed an amicable split. Publicly, he expressed no regrets and used his Facebook page to lavish praise on Kalanick.
“Toughest boss I ever had and I’m a stronger leader for it,” he said, adding there was “no thing” he would change about his time at Uber. “Forget the hyperbole in the media; forget the intrigue; think about how pushing a button and getting a ride makes your life better.”
In his departure email to colleagues, MacGann described himself as “a strong believer in Uber’s mission”.
Uber publicly commended MacGann’s work and asked him to stay on as a consultant.
He was given a new job title – senior board adviser – and retained his Uber-provided emails, laptops and phones.
That role ended in August 2016, after which MacGann took on a new job at a telecoms company and started his own business venture. It was a full year after leaving Uber that, MacGann says, he experienced his most “terrifying” ordeal as a perceived representative of the cab-hailing firm.
‘MacGann, we will get you’
The incident outside Brussels Midi station was recorded in a police report, Uber emails and media reports. It took place between 11.45am and 12.15pm on 19 September 2017, shortly after MacGann arrived at the station.
As he walked towards his waiting Uber, taxi drivers approached him and ordered him not to get into the car. One grabbed him by the arms to stop him from putting his bags in. Concerned for his safety, MacGann asked the Uber driver to lock the doors when he was in the car.
Several more taxi drivers joined the fray, surrounding the car. MacGann called the police. A security report commissioned by Uber questioned whether the taxi drivers had recognised him. But he recalls the drivers yelling: “MacGann, we will get you, we know where you live.”
He recalls them thumping on the windows and rocking the car from side to side. Three taxi drivers were taken to the police station, but no further action was taken.
MacGann said he was left fearing for his life – and that of his Uber driver, who “was shaking and in tears, scared for his life”. “These taxi drivers had his licence number, they could come after him again. It just seemed to me that Uber viewed this guy as expendable supply – not an employee with rights.”
Shortly afterwards, MacGann received an anonymous threat on Twitter: “One day police won’t be there and you’ll be alone. And we will see if money will help you.”
MacGann held his former employer responsible. “I felt that Uber had caused this, by its ‘success at all costs approach’ that encouraged confrontations between Uber and taxi drivers … I started to feel it was indicative of Uber’s wider relationship with drivers, putting them in harm’s way for their own financial interests.”
By mid-2018, MacGann said, the death of a close friend contributed to a deterioration in his mental health. A medical report from March 2019 said a subsequent diagnosis of PTSD was “evidently linked and impacted by the professional stress he had to endure” during his time at Uber.
MacGann said that months of treatment and therapy between 2018 and 2019 – and an enforced period of personal reflection – led him to reassess his time at Uber. “I’d stepped off the corporate hamster wheel for the first time in decades. I emerged with a new sense of clarity about everything at Uber.”
No longer living the fast-paced life of a corporate executive, MacGann had time to listen more carefully to the stories of Uber drivers who were ferrying him around. He credits those conversations with changing his understanding of what the company used to call “driver economics”.
In its statement, Uber’s spokesperson said “driver earnings globally are at or near all-time highs today” and that Uber’s interests were “aligned with drivers, ensuring they have a positive experience earning on the platform”. If drivers were dissatisfied with its platform, she added, “they can and do choose to earn somewhere else”.
In the statement released after MacGann identified himself as the whistleblower, Uber said his litigation against the company was “an attempt, among other things, to get paid a bonus he claimed to be owed for his work at Uber. That lawsuit recently ended with him being paid €550,000. It is noteworthy that Mark felt compelled to ‘blow the whistle’ only after his cheque cleared.”
MacGann first contacted the Guardian five months before his legal dispute with Uber was settled and placed no restriction on when journalists could use the leaked data. He disputes Uber’s claim that he has been paid €550,000, and said he was still awaiting his full payout from the settlement. His lawyer said: “While Uber has paid most of the settlement amount, a sizeable portion remains outstanding while issues relating to tax are resolved.”
Sharing secrets
In February 2020, MacGann, increasingly angered by what he viewed as the mistreatment of drivers, tried to take action. Uber was appealing against a decision by Transport for London (TfL) to refuse the company a licence in the capital, on the grounds it failed to meet the “fit and proper” test.
Emailing the mayor’s office, MacGann explained he was a former Uber executive with information to share in a “private and non-sensationalist manner, given my intimate knowledge of the company”. MacGann said he felt “frustrated” when his attempt to formally raise concerns about Uber did not receive a reply.
In February 2021, MacGann went a step further. After reading about a French lawyer who was bringing a class action lawsuit against Uber on behalf of drivers, MacGann got in touch and offered to provide information to help their case. The lawyer visited him at his home and MacGann allowed him to take photographs of a small sample of Uber documents he had stored on his old computer.
His relationship with the French lawyer turned out to be short-lived. But the dam had been broken. MacGann realised quite how many of Uber’s secrets he was sitting on.
In January 2022, Uber’s former top lobbyist travelled to Geneva and met with reporters from the Guardian.
He opened two suitcases and pulled out laptops, hard drives, iPhones and bundles of paper. He warned it would take a few days, at best, to explain everything he knew. “I’ve seen some really shady shit, to use one of the Silicon Valley expressions.”",4
235,"How the U.K. Became One of the Poorest Countries in Western Europe
Britain chose finance over industry, austerity over investment, and a closed economy over openness to the world.
This is Work in Progress, a newsletter by Derek Thompson about work, technology, and how to solve some of America’s biggest problems. Sign up here to get it every week.
The past few months have been rough for the United Kingdom. Energy prices are soaring. National inflation has breached double digits. The longest-serving British monarch has died. The shortest-serving prime minister has quit.
You probably knew all of that already. British news is covered amply (some might say too amply) in American media. Behind the lurid headlines, however, is a deeper story of decades-long economic dysfunction that holds lessons for the future.
In the American imagination, the U.K. is not only our political parent but also our cultural co-partner, a wealthy nation that gave us modern capitalism and the Industrial Revolution. But strictly by the numbers, Britain is pretty poor for a rich place. U.K. living standards and wages have fallen significantly behind those of Western Europe. By some measures, in fact, real wages in the U.K. are lower than they were 15 years ago, and will likely be even lower next year.
This calamity was decades in the making. After World War II, Britain’s economy grew slower than those of much of continental Europe. By the 1970s, the Brits were having a national debate about why they were falling behind and how the former empire had become a relatively insular and sleepy economy. Under Prime Minister Margaret Thatcher in the 1980s, markets were deregulated, unions were smashed, and the financial sector emerged as a jewel of the British economy. Thatcher’s injection of neoliberalism had many complicated knock-on effects, but from the 1990s into the 2000s, the British economy roared ahead, with London’s financial boom leading the way. Britain, which got rich as the world’s factory in the 19th century, had become the world’s banker by the 21st.
When the global financial crisis hit in 2008, it hit hard, smashing the engine of Britain’s economic ascent. Wary of rising deficits, the British government pursued a policy of austerity, fretting about debt rather than productivity or aggregate demand. The results were disastrous. Real wages fell for six straight years. Facing what the writer Fintan O’Toole called “the dull anxiety of declining living standards,” conservative pols sniffed out a bogeyman to blame for this slow-motion catastrophe. They served up to anxious voters a menu of scary outsiders: bureaucrats in Brussels, immigrants, asylum seekers—anybody but the actual decision makers who had kneecapped British competitiveness. A cohort of older, middle-class, grievously nostalgic voters demanded Brexit, and they got it.
In the past 30 years, the British economy chose finance over industry, Britain’s government chose austerity over investment, and British voters chose a closed and poorer economy over an open and richer one. The predictable results are falling wages and stunningly low productivity growth. Although British media worry about robots taking everybody’s jobs, the reality is closer to the opposite. “Between 2003 and 2018, the number of automatic-roller car washes (that is, robots washing your car) declined by 50 percent, while the number of hand car washes (that is, men with buckets) increased by 50 percent,” the economist commentator Duncan Weldon told me in an interview for my podcast, Plain English. “It’s more like the people are taking the robots’ jobs.”
That might sound like a quirky example, because the British economy is obviously more complex than blokes rubbing cars with soap. But it’s an illustrative case. According to the International Federation of Robotics, the U.K. manufacturing industry has less technological automation than just about any other similarly rich country. With barely 100 installed robots per 10,000 manufacturing workers in 2020, its average robot density was below that of Slovenia and Slovakia. One analysis of the U.K.’s infamous “productivity puzzle” concluded that outside of London and finance, almost every British sector has lower productivity than its Western European peers.
Thus, the U.K., the first nation to industrialize, was also the first to deindustrialize. Britain gave rise to the productivity revolution that changed the world, and now it has some of the worst productivity statistics of any major economy. What was once the world’s most powerful globalized empire has now voted to explicitly reduce global access to trade and talent. Since Brexit, immigration, exports, and foreign investment have all declined, likely reducing the size of the U.K.’s economy by several percentage points in the long run.
Americans who have visited the U.K. may not recognize the portrait I’m painting. That’s probably because they’re familiar with London, not the country as a whole. As the economics writer Noah Smith notes, London’s financial prowess has concealed the overall economy’s weakness in innovation and manufacturing. Or, as the economic analyst Matt Klein puts it, “Take out Greater London—the prosperity of which depends to an uncomfortable degree on a willingness to provide services to oligarchs from the Middle East and the former Soviet Union—and the UK is one of the poorest countries in Western Europe.”
Today, Britain seems trapped between a left-wing aversion to growth and a right-wing aversion to openness. On the academic left, the U.K. has lately been home to a surging movement called degrowtherism, which asserts that saving the planet requires rich countries to stop seeking growth. On the right, the electorate is dominated by older voters who care more about culture wars than about competitiveness. “In 2019, when Boris Johnson and the Conservative Party won a big majority in the House of Commons, most people of working age did not vote for them,” Weldon told me. “I’m pretty sure that’s the first time that’s ever happened. You have this post-economic, older, economically insulated voting bloc that could afford to be anti-growth almost as a luxury, because they don’t have to care about economic outcomes.”
The U.K. is now an object lesson for other countries dealing with a dark triad of deindustrialization, degrowth, and denigration of foreigners. Having offshored industry in favor of finance, its economy wasn’t resilient. The resulting erosion in living standards made the public desperate for something to blame. Blame-seeking conservatives spotted bogeymen abroad. Brexit cut off the economy from further growth and set the stage for a rolling political circus.
The U.S. has a different menu of problems from the U.K.’s. But here too, politicians are navigating an industrial sector in structural decline, a political left that is often skeptical about the virtues of economic growth, and a political right that is organized in part around hating foreigners. Enemies of progress can criticize the legacy of industrialization, productivity, and globalization. But the U.K. shows us what can happen when a rich country seems to reject all three. Rather than transforming into some post-economic Eden of good vibes, it becomes bitter, flailing, and nonsensical.",1
236,"When Bradley Wilkinson and his husband were planning their move from Fayetteville, North Carolina, to a small Army base outside Colorado Springs, they were already worried about where they would charge their electric car.
Wilkinson, a 31-year-old who works in customer care at T-Mobile, had bought a used Nissan Leaf several years earlier, and although he joked that it wasn’t a particularly high-end vehicle — “It’s the peasant’s Tesla,” he said — he had come to appreciate how cheap it was to run. Because of low electricity costs, driving an electric car is typically three to four times cheaper than driving a gas-powered one.
“Being military, we really don’t make a lot of money,” Wilkinson said. But with the Leaf, he added, “We could always get somewhere.”
Wilkinson and his husband, an infantryman in the Army, didn’t own their own home, and so they needed to negotiate with landlords to get access to charging. Wilkinson called ahead to Fort Carson, the military base, to make sure that there would be a standard 120-volt household outlet available to charge their Leaf outside their quadruplex. This was in the spring of 2017, and after just a couple of weeks in freezing cold Colorado temperatures, however, he realized that the trickle of electricity from the outlet wasn’t going to be enough, as cold weather quickly drains lithium-ion batteries. He went to the leasing office to ask if he could install a faster charger by his parking spot.
To his surprise, the office said no — multiple times. “They weren’t even sure what I was asking,” Wilkinson said.
Wilkinson had fallen into a familiar and frustrating trap for many EV owners around the country. By all accounts, the market for electric cars is booming, with sales on track to double over last year. President Joe Biden has promised that by 2030 half of all new cars sold in the U.S. will be electric, Ford is about to start full production of the F-150 Lightning, an EV version of America’s favorite pick-up truck, and some states have even vowed to phase out gasoline-powered cars entirely.
But for the 36 percent of U.S. households who rent their homes, charging an electric car isn’t easy. Apartment buildings and other multi-family homes often have shared parking, which makes it hard to find accessible 120-volt outlets or install faster charging systems. (Electric cars can charge in three ways: on a simple, 110- or 120-volt outlet — found everywhere in a U.S. home — on a faster “Level 2” 240-volt system, or with technology known as “DC fast” charging.) For landlords, however, there’s little incentive to allow tenants to use existing outlets, let alone install new ones.
“The real fundamental issue from a landlord or the property owner point of view is that there’s no money in charging cars,” said Marc Geller, the vice president of Plug In America, an EV advocacy group. Tenants who want to charge their car batteries will gobble up electricity from the parking lot, and — because it’s difficult to connect electricity in the parking lot to renters’ individual units — the landlord often has to cover the bill.
It’s also an equity issue. Unsurprisingly, renters tend to have lower incomes than those who own their own homes; they are also more likely to be Black or Latino. At the moment, according to a report by the International Council of Clean Transportation, 4 out of 5 EV owners live in single-family detached homes. But to cut emissions and pollution from the country’s 250 million gas-guzzling cars — and bring the low cost of electric driving to people who could benefit most — EVs have to be accessible to people living in apartments, condos, townhouses, and all other types of multi-family dwellings.
“This is really something where none of us win if we all don’t win,” Geller said.
Most of the public focus on EV charging revolves around long trips: whether there are enough chargers along highways for interstate road trips, for example, or whether electric cars have enough battery life to avoid “range anxiety.” But the average American only drives about 30 miles per day, a trip easily accomplished in any electric car as long as its battery can get filled up overnight.
The vast majority of Americans with electric cars charge up at their homes. According to an estimate from the Department of Energy, over 80 percent of EV charging happens at the owner’s house. One simple reason is that it can take anywhere from two to 22 hours to fill up an empty battery. An electric car charging on a standard 120-volt outlet will replenish the battery by two to five miles of range every hour; a faster Level 2 charger can add 10 to 20 miles of range per hour. (DC fast charging can add a whopping 80 miles of range in 20 minutes.) While public charging stations are popping up at grocery stores, shopping malls, and community centers around the country, most EV owners don’t want to spend hours at a grocery store waiting for their cars to fill up.
Faced with a lack of chargers in apartment buildings and rental houses, EV drivers have found creative workarounds. Some use high-gauge extension cords to connect a garage parking space to their electric car — with or without the approval of the landlord. One EV owner on Facebook recounted the story of a man in San Francisco who ran an extension cord out the window of his apartment building to his car parked on the street. (Car manufacturers recommend against the use of extension cords, which can overheat and create a fire risk.) Others drop their cars off at nearby dealerships or public chargers overnight and return to pick them up in the morning. Still others charge their cars up at the office before returning home.
But for some Americans, the hassle of hunting for a charger turns them away from electric cars entirely. Behzad Dabu, a 35-year-old actor living in Los Angeles, told me that he considered buying a Tesla after moving into an apartment with an underground parking garage that had several 120-volt outlets available. But after reading his lease, Dabu realized that the building specifically barred tenants from plugging anything into the outlets in the garage. He ended up getting a hybrid instead.
Some landlords and apartment owners are starting to offer EV charging as a key amenity for prospective renters. “It’s all about retaining tenants,” said Mark Dunec, the managing director of FTI Consulting, a real estate consulting firm. “Those landlords that will have charging stations, they’re going to be the ones to obtain tenants as people acquire and lease electric vehicles.”
In some areas, this transition is occurring quickly. Christian Molino, a virtual design and construction engineer with a Tesla Model 3, looked for apartments in Orlando, Florida, earlier this year that specifically included EV charging. “If they didn’t have charging they got scratched right off the list,” he said. He estimates that around 25 to 30 percent of the buildings he looked at had chargers; all the rest had plans to install charging over the next several years. He eventually settled on a spot that had four Level 2 chargers in the apartment garage — about one for each of the EV owners in the building.
But according to Mike Nicholas, a researcher for the electric vehicle program at the International Council on Clean Transportation, apartment buildings with chargers tend to be on the higher end or luxury side. Most landlords, he said, “just don’t know about it, or find it confusing.”
Some have suggested that installing more superfast chargers around the country could be the solution. The Biden administration, for example, has emphasized that fast, public chargers could help fill in the gaps for Americans without off-street parking. But fast charging is up to four times more expensive than home charging — meaning that lower-income households won’t get the full benefit of having an electric car. “In some cases, fast charging could end up costing more than gas,” Nicholas said.
After a few weeks of tussling with property managers at Fort Carson, Wilkinson gave the leasing office a copy of Colorado Title 38, Article 12, Part 6, which gives tenants the right to install charging at their apartments or rented homes. Wilkinson said he offered the leasing manager three options: comply with the state’s “right-to-charge” law, end his lease without penalty, or meet him and his husband in court.
The property managers complied, ultimately agreeing to install a Level 2 charger for Wilkinson’s Chevy Bolt two months after his first request. (He had replaced the Nissan Leaf after an accident). They even agreed to pay most of the cost of the installation: Wilkinson’s share came to about $500.
“Right-to-charge” laws are currently on the books in Colorado and eight other states: Maryland, New Jersey, Virginia, New York, Florida, Oregon, Hawaii, and California. While they can help tenants, as in Wilkinson’s case, they also come with drawbacks. Most require tenants to pay for the entire cost of the charger installation, which for Level 2 charging can cost between $1,000 and $3,000. “The financial burden falls on the EV owner,” Nicholas said. Because renters often only sign one- to two-year leases, he added, “they can’t really get the benefits over a long period of time.”
Other potential fixes are still in progress. The bipartisan infrastructure bill, which Biden signed into law last month, includes $7.5 billion dedicated to electric charging and alternative fuel infrastructure, but there’s still little information about what kind of chargers will be built and where. According to a fact sheet from the White House this week, the funds will prioritize building public chargers in “rural, disadvantaged, and hard-to-reach locations.”
Another option is for cities and states to revamp their building codes: In 2017, for example, San Francisco mandated that all new residential or commercial buildings be “EV ready” starting the following year, with enough electrical capacity for cars to charge in at least 20 percent of the parking spots. Though that doesn’t mean that the building owners have to install chargers, it does dramatically cut costs should they decide to do so later on. EV advocates are pushing the entire state of California to do the same in its new building codes. Similar moves are happening abroad: The U.K. government announced new rules last month that would require EV chargers to be installed in all new residential and commercial buildings.
A few startups are also trying to help accelerate the shift. Companies like Plugzio in Richmond, Canada, and Orange in San Mateo, California, provide easy-to-install, cheap charging ports that allow landlords to easily monitor and charge tenants for electricity costs. And some cities are working on developing on-street charging for EV owners who don’t have access to off-street parking. Nicholas points to the example of Amsterdam, where the city government ran a program to provide on-street charging systems for free to residents who asked for them. In London, Siemens and a German company called Ubitricity have started converting lamp posts into charging stations for curbside parking. The city of Seattle, Washington, offers a lower-tech solution: Residents are allowed to run an extension cable over the sidewalk with a cord cover on it.
Geller hopes that policymakers will focus on such easy, cheap solutions — more 120-volt outlets, for example, rather than installing lots of expensive Level 2 or DC fast chargers. But ultimately, he says, Americans just need more chargers in their homes. Although 90 percent of the media conversation is about public charging, he says, 90 percent of charging happens at home.
“I’ve met and talked to too many people who really wanted to do the right thing,” Geller said. “They got an electric car, then had to rely on public charging — and it was just a burden.” Some of those drivers, he says, ended up giving up their electric cars. And they aren’t alone: According to a 2015 study from researchers at the University of California, Davis, 1 out of 5 EV drivers switches back to a gas-powered vehicle. The top reason? Dissatisfaction with the convenience of charging.
Wilkinson doesn’t regret his decision to go electric, even though it’s forced him to jump through hoops to get his car charged at home. “I remind myself that my experience is going to help people that are in a position like me 15, 20 years from now,” he said. Since his tussle with the leasing manager, three other EV chargers have been installed at homes in Fort Carson.",4
237,"Les Tontons flingueurs
|Les Tontons flingueurs|
|Directed by||Georges Lautner|
|Written by||novel Albert Simonin|
dialogue Michel Audiard
Georges Lautner
|Produced by||Irénée Leriche|
Alain Poiré
Robert Sussfeld
|Starring||Lino Ventura|
Bernard Blier
Francis Blanche
|Cinematography||Maurice Fellous|
|Edited by||Michelle David|
|Music by||Michel Magne|
Production
company
SNEG
|Distributed by||Gaumont|
Release dates
|4 October 1963 (West Germany)|
27 November 1963 (France)
Running time
|105 minutes|
|Countries||France, West Germany, Italy|
|Languages||English, German, French|
|Box office||$24.9 million[1]|
Les Tontons flingueurs (English: Crooks in Clover, also known as Monsieur Gangster, literally Gun-toting Uncles) is a 1963 French-Italian-West German crime comedy film with French dialogue, directed by Georges Lautner. It is an adaptation of the Albert Simonin book Grisbi or not grisbi.[2] The film is the final installment in the Max le Menteur trilogy; it was preceded by Touchez pas au grisbi and Le cave se rebiffe.
The film was not popular with critics upon its first release in 1963, but was popular with the public. Its reputation has grown over the years to cult status and it is now a French television classic, with snatches of dialogue and names of characters (like the prostitute Lulu la Nantaise) becoming part of popular culture. Its DVD version, released in 2002, sold 250,000 copies.
One of the most famous scenes is set in a kitchen where the gangsters try to make conversation while drinking a vile and strong liquor. Screenwriter Michel Audiard considered the scene useless but director Lautner included it in homage to the film noir Key Largo.[3]
Synopsis[edit]
Fernand is an ex-gangster with a plant hire business in Montauban. His modest, quiet life is disrupted when his childhood friend, Louis ""the Mexican"", who has become the boss of a gangster organisation in Paris, summons him to his deathbed. Louis appoints Fernand head of his business and guardian of his teenage daughter, Patricia, who only thinks about having fun and has never lasted in any school more than six months.
Protected by the loyal hitman Pascal, Fernand moves into the Mexican's suburban mansion, where he is welcomed by Maître Folace who is the organisation's lawyer, Jean the butler who is a former housebreaker and Patricia, who hopes to twist her new ""uncle"" around her finger. He learns that the business has four arms: a bowling alley, a brothel run by Madame Mado, a gambling den run by the brothers Raoul and Paul Volfoni and a distillery run by Théo. Both the Volfonis and Théo resent the newcomer and plan to get rid of him.
Théo's first plot is to get Fernand to deliver a load of contraband liquor, which he then ambushes. However, Fernand escapes alive and makes his way home. There he finds Patricia holding a wild party for all her friends, including her boyfriend Antoine who wants to marry her. The Volfonis, having failed to blow up Fernand's car, come round for a showdown but are disarmed and invited to a conference round the kitchen table, where all get horribly drunk on illegal whisky.
Next day, Théo and a henchman come round to finish the job but, as they besiege the mansion, an old gentleman walks up. He turns out to be Antoine's wealthy father, calling to arrange Patricia's marriage. While he talks to Fernand, bullets keep coming through windows.
The wedding is set, but before the ceremony Fernand has to get rid of Théo. Going to the distillery, a battle rages in which all Théo's men are killed but he escapes. Fernand then rushes to the church to give away Patricia. While everybody is inside, Théo drives up with a sub-machine gun, waiting to fell the wedding party as they emerge. On guard outside, Pascal blows up the car and its blazing wreck greets the newly-weds.
Cast includes[edit]
- Lino Ventura: Fernand Naudin
- Jacques Dumesnil: Louis ""the Mexican""
- Francis Blanche: Maître Folace, the lawyer
- Bernard Blier: Raoul Volfoni, the gambling manager
- Jean Lefebvre: Paul Volfoni, Raoul's brother
- Robert Dalban: Jean, the Mexican's butler
- Venantino Venantini: Pascal, the hitman
- Horst Frank: Théo, the distillery manager
- Charles Régnier: Tomate, distillery worker
- Mac Ronay: Bastien, gangster
- Henri Cogan: Freddy, gangster
- Sabine Sinjen: Patricia, the Mexican's daughter
- Claude Rich: Antoine Delafoy, Patricia's boyfriend
- Pierre Bertin: Adolphe Amédée Delafoy, Antoine's father
- Dominique Davray: Madame Mado, the brothel manager
- Philippe Castelli: the tailor
- Paul Meurisse: a passer-by (Théobald Dromard ""Le Monocle"")
References[edit]
- ^ ""Les Tontons flingueurs (1963) - JPBox-Office"".
- ^ ""Crooks in Clover"". unifrance.org. Retrieved 2013-08-01.
- ^ Anthony Palou (8 September 2009). ""Les Tontons Flingueurs, toute une époque"". Le Figaro.fr. Retrieved 30 November 2013..
External links[edit]
- 1963 films
- Films directed by Georges Lautner
- French crime comedy films
- French gangster films
- German crime comedy films
- German gangster films
- Italian crime comedy films
- Italian gangster films
- 1960s French-language films
- Films about organized crime in France
- Films with screenplays by Michel Audiard
- 1960s Italian films
- 1960s French films
- 1960s German films",8
238,"Editor's Note: This is sections 11,12 of the OSS's Simple Sabotage Field Manual, a 1944 document that has been declassified. The OSS became the CIA after WWII. The full document is here.
(1) Insist on doing everything through ""channels."" Never permit short-cuts to be taken in order to, expedite decisions.
(2) Make ""speeches."" Talk as frequently as possible and at great length. Illustrate your ""points"" by long anecdotes and accounts of personal experiences. Never hesitate to make a few appropriate ""patriotic"" comments.
(3) When possible, refer all matters to committees, for ""further study and consideration."" Attempt to make the committees as large as possible - never less than five.
(4) Bring up irrelevant issues as frequently as possible.
(5) Haggle over precise wordings of communications, minutes, resolutions.
(6) Refer back to matters decided upon at the last meeting and attempt to reopen the question of the advisability of that decision.
(7) Advocate ""caution."" Be ""reasonable"" and urge your fellow-conferees to be ""reasonable"" and avoid haste which might result in embarrassments or difficulties later on.
(8) Be worried about the propriety of any decision -raise the question of whether such action as is contemplated lies within the jurisdiction of the group or whether it might conflict with the policy of some higher echelon.
(1) Demand written orders.
(2) ""Misunderstand"" orders. Ask endless questions or engage in long correspondence about such orders. Quibble over them when you can.
(3) Do everything possible to delay the delivery of orders. Even though parts of an order may be ready beforehand, don't deliver it until it is completely ready.
(4) Don't order new working materials until your current stocks have been virtually exhausted, so that the slightest delay in filling your order will mean a shutdown.
(5) Order high-quality materials which are hard to get. If you don't get them argue about it. Warn that inferior materials will mean inferior work.
(6) In making work assignments, always sign out the unimportant jobs first. See that the important jobs are assigned to inefficient workers of poor machines.
(7) Insist on perfect work in relatively unimportant products; send back for refinishing those which have the least flaw. Approve other defective parts whose flaws are not visible to the naked eye.
(8) Make mistakes in routing so that parts and materials will be sent to the wrong place in the plant.
(9) When training new workers, give incomplete or misleading instructions.
(10) To lower morale and with it, production, be pleasant to inefficient workers; give them undeserved promotions. Discriminate against efficient workers; complain unjustly about their work.
(11) Hold conferences when there is more critical work to be done.
(12) Multiply paper work in plausible ways. Start duplicate files.
(13) Multiply the procedures and clearances involved in issuing instructions, pay checks, and so on. See that three people have to approve everything where one would do.
(14) Apply all regulations to the last letter.
(1) Make mistakes in quantities of material when you are copying orders. Confuse similar names. Use wrong addresses.
(2) Prolong correspondence with government bureaus.
(3) Misfile essential documents.
(4) In making carbon copies, make one too few, so that an extra copying job will have to be done.
(5) Tell important callers the boss is busy or talking on another telephone.
(6) Hold up mail until the next collection.
(7) Spread disturbing rumors that sound like inside dope.
(1) Work slowly. Think out ways to increase the number of movements necessary on your job: use a light hammer instead of a heavy one, try to make a small wrench do when a big one is necessary, use little force where considerable force is needed, and so on.
(2) Contrive as many interruptions to your work as you can: when changing the material on which you are working, as you would on a lathe or punch, take needless time to do it. If you are cutting, shaping or doing other measured work, measure dimensions twice as often as you need to. When you go to the lavatory, spend a longer time there than is necessary. Forget tools so that you will have to go back after them.
(3) Even if you understand the language, pretend not to understand instructions in a foreign tongue.
(4) Pretend that instructions are hard to understand, and ask to have them repeated more than once. Or pretend that you are particularly anxious to do your work, and pester the foreman with unnecessary questions.
(5) Do your work poorly and blame it on bad tools, machinery, or equipment. Complain that these things are preventing you from doing your job right.
(6) Never pass on your skill and experience to a new or less skillful worker.
(7) Snarl up administration in every possible way. Fill out forms illegibly so that they will have to be done over; make mistakes or omit requested information in forms.
(8) If possible, join or help organize a group for presenting employee problems to the management. See that the procedures adopted are as inconvenient as possible for the management, involving the presence of a large number of employees at each presentation, entailing more than one meeting for each grievance, bringing up problems which are largely imaginary, and so on.
(9) Misroute materials.
(10) Mix good parts with unusable scrap and rejected parts.
(a) Give lengthy and incomprehensible explanations when questioned.
(b) Report imaginary spies or danger to the Gestapo or police.
(e) Act stupid.
(d) Be as irritable and quarrelsome as possible without getting yourself into trouble.
(e) Misunderstand all sorts of regulations concerning such matters as rationing, transportation, traffic regulations.
(f) Complain against ersatz materials.
(g) In public treat axis nationals or quislings coldly.
(h) Stop all conversation when axis nationals or quislings enter a cafe.
(i) Cry and sob hysterically at every occasion, especially when confronted by government clerks.
(j) Boycott all movies, entertainments, concerts, newspapers which are in any way connected with the quisling authorities.
(k) Do not cooperate in salvage schemes.",8
239,"Writing: The Most Misunderstood Activity
Two problems with writing: first, it looks easy because it uses the same symbols of speech; second, everyone who was taught the alphabet and basic sentence structures can produce something similar to writing when it’s not. Writers, however, know it’s painfully hard to produce one readable, unambiguous paragraph. On the other hand, casual text producers (read: the majority) think it takes nothing special to write. This amateur attitude makes writing the most misunderstood activity.
A lot of people misunderstand writing—including the brightest knowledge workers. I’m one myself and have worked with designers, engineers, developers, and marketers. Most sucked when it came to putting words on the screen. Every time I looked closely at their text I could peer into their minds, and inside lay a thought process oblivious to what writing really means.
Let’s change that. I used to misunderstand writing too, and my style suffered severely as a result. Now not only is it miles better, but I’m also a smarter human thanks to realizing the true meaning of writing. To get there, I had to spot the misconceptions I’ve been fed about writing. Reading this piece, I’m sure you’ll at least identify a couple you can build on to change your writing mindset.
1. I wrote only when I was told
I’m starting with this one as it falls under the I can’t believe I used to do this category. I used to write when, and only when, I was told.
This misconception encompasses all the writing assignments I received at school, the emails I had to write at work, the government forms I often filled grudgingly. If there was no outside need to write, I didn’t bother.
It was obvious I was allowed to write about whatever, whenever; I knew I had the freedom to manipulate words however I wanted. But when you’re taught to treat writing as a clerical activity, your brain tends to overlook the many lead-ins you can get from intrinsically deciding to write.
If you have never done it before, I can’t stress how empowering it feels to sit down and write out of sheer desire. There’s no grade, no deadline, no judgment, and even no audience. You’re doing it because you’re wrestling with a matter—maybe you’re considering your next move or learning about something you deeply care about. Surprisingly, I realized you often get rewarded for writing willingly.
Once you break away from the fallacy of needing an occasion to write, you’ll be pleasantly startled by the new possibilities and creative openings emerging from your words. Fresh ideas, new angles, and unorthodox (even obvious) answers will come rushing, propelling you to a flood of potentials. Best of all, you’ll have recorded all your thoughts, affording you the luxury of owning an ever-growing tree of knowledge.
2. I wrote only to document
Remember when I described the majority as casual text producers? I did so because there’s a big difference between actually writing and merely producing text. If you write only to document, you’re not a writer, but a text producer.
What do I mean by this? Text producers don’t add to the conversation. They don’t write to generate ideas, but to record existing ones. They’re not involved in the activity nor attached to the result.
Think about the sad essay we all used to write for your (insert language here) class: back then you didn’t have permission to generate original ideas. You were forced to cite as many sources as possible to prove your piece is well-researched. It didn’t matter if the work failed to offer a new take as long as you followed a depressing format and quoted whatever papers your instructor was a fan of. Then came work: you wrote emails nobody wanted to read or repeated phrases everyone wanted to hear.
That’s how I used to write: coming up with new ways of looking at things wasn’t the goal. Instead writing served either as a tool of record or proof of attendance. Tragically, because of this misconception I didn’t think I had anything to say. I passively consumed books and courses without even considering the possibility of contributing. Since I mistook it for a simple documentation tool, it didn’t occur to me that writing also worked for generating ideas. But now, things have changed: this realization transformed my writing from a simple tool of text production to a sophisticated system of meaning-making.
You can start now: open your favorite text processor and pick a topic you’re wrestling with. A project they’ve been debating at work? Stop saying Thanks for the update and let them know what you really think. A book stirred something in you? Go beyond highlighting paragraphs and write new ones. Instead of inertly listening to ideas, participate with your own. Make it a point to write only to create, rather than writing only to document.
3. I wrote only when I was ready
How can I tell what I think till I see what I say? –E.M. Forster
I made a lot of progress upon realizing I could write without permission. I went even farther when I knew the difference between generating thought and producing text. But the true breakthrough happened when I gave up on the idea of writing only when I was ready.
I’ve long associated writing with accomplishment: I marveled at books with handsome covers and clear prose, blogs with great UI and engaging takes. I thought writing was a product, not a process. If you still think of writing this way, I don’t blame you, for writing is elusive: the result obstructs us from seeing the activity.
I can’t tell you how many promising ideas I had—not necessarily for an essay or a book; it could’ve been for a product, a course, a better way to work, or a new approach to a stubborn problem—that didn’t make it to the world simply because I didn’t sit down to write as I thought about them.
But I later realized writing is many things, one of which is the finished article you’re reading now. Mainly though, it’s a tool for thinking things through.
When you think by writing, you’re forced, in a good way, to convert the fragmented speech you internally mumble to yourself into a coherent body of work. And when you’re done, you naturally look at what you wrote. Does it feel right to you? Something’s missing here, I hear you say. So you add another sentence (i.e., thought) to get closer. Now it’s clearer, but not by a lot. So you rearrange sentences. A new idea emerges; what a surprise! But is it really? You’re doing the work. So you write it down. One more. You see where this is going? OK, I’ll leave you to it.
Soliman Writes Newsletter
Subscribe to receive updates about my latest writing.",8
241,"Access Check
Our systems have detected unusual traffic activity from your network. Please complete this reCAPTCHA to demonstrate that it's you making the requests and not a robot. If you are having trouble seeing or completing this challenge, this page may help. If you continue to experience issues, you can contact JSTOR support.
Block Reference: #b6075fee-78c8-11ed-bf27-6d6c556f4d69
VID: #
IP: 88.138.237.237
Date and time: Sat, 10 Dec 2022 20:24:56 GMT",2
242,"Last year, after Berlin’s Tegel Airport had been replaced by a new international airport at another location, workers started clearing the land for a new project: a neighborhood built from scratch with the climate in mind.
Some parts of the airport will be reused, with old terminals turned into commercial space for research and offices for startups. But a more-than-100-acre area near where the runway used to sit will be completely reimagined, with 5,000 new apartment homes built in a walkable, bikeable, carbon-neutral neighborhood with parks, schools, and stores.
“The planning is based on questions such as: How do we want to live and get around in urban spaces in the future? What qualities are important to us as individuals and as a community? And what functionalities can’t we do without?” explains Constanze Döll, press secretary for the Tegel Projekt, which is developing the area, called the Schumacher Quartier. While the final designs are not yet complete, the project has several guidelines. First: People take priority, not cars.
“The Schumacher Quartier is planned in such a way that the streets and squares belong to the people again, rather than to cars,” Döll says. “We want to let people rediscover the public space . . . for socializing, playgrounds, places to relax and talk. Important locations in the neighborhood, like the kindergarten, school, bakery, supermarket, can be reached easily by foot.”
The plans call for wide bike lanes and green spaces. At the edge of the neighborhood, there will be access to micromobility and existing public transit. The neighborhood will allow limited access to cars (people who are disabled, for example, will be able to drive up to their buildings), but will otherwise be car-free.
The apartment buildings will be built from wood, and when completed will be the largest group of mass timber buildings in the world.
“Wood in particular enables long-term CO2 storage, and the use of wood as a building material reduces the consumption of environmentally harmful materials such as concrete,” Döll says.
The team will source timber locally in Germany, and expects to reduce CO2 emissions in construction by 80%. The designs will also be ultra-efficient, and all energy will be produced on the site, including solar and geothermal power. A system will also harvest waste heat from adjacent commercial buildings to heat the homes.
The commercial part of the redevelopment, called the Urban Tech Republic, will be home to new startups whose technology—from recycling to new mobility systems—will be developed and can be tested in the residential area.
The neighborhood will also include “sponge city” designs that help capture water in heavy storms to prevent flooding. Green roofs and gardens will use some of the water, and some will be stored underground.
“All rainwater is used or stored in the quarter; nothing is lost,” Döll says. “If the water evaporates on hot days, it cools the surrounding area—and if instead it seeps in, it fills up the groundwater. This self-contained system makes for local climate regulation, aided by many large-leaved, deciduous trees that act like natural air-conditioning systems.”
The plan also includes a concept of “animal-aided design,” developed by ecologist Wolfgang Weisser and landscape architect Thomas Hauck, that incorporates biodiversity. Open spaces and buildings will be designed to support 14 rare species, including broad-winged bats and nightingale grasshoppers, with the goal of helping them permanently settle in the area and attract other species.
Over the past year, the Tegel Projekt team has been working on the first step of the development: clearing some of the old debris that existed on the site before it was an airport, when it was used for military training in World Wars I and II. So far, Döll says, more than 5,000 pieces of ammunition, including old grenades and bombs, have been removed.
This fall, the project will begin allocating land, and architects will work with residents on the design details. The first buildings, which will include social housing, cooperatives, and student housing, will be completed in 2027.",2
243,"Student loans continue to burden adults decades after they’ve left school, and credit card debt haunts many Americans. On the flip side, many of us make leveraged investments in our homes, taking out mortgages to buy houses that we expect to appreciate in value. In other words, debt structures American lives in myriad ways. But, as historian Louis Hyman writes, this is a relatively new thing.
In the nineteenth century, Hyman points out, if an individual needed credit, they turned to friends, loan sharks, or local merchants. For corner grocers and country stores, these loans were money-losing propositions with no interest charged. Any institution with a lot of money lent it not to consumers but to businesses.
This changed with the rise of the automobile. In the 1920s, finance companies emerged as middlemen, borrowing from banks and lending to car dealerships, which could then extend financing plans to individual buyers.
“For the first time, money from the core of capitalism, the consumer banks, was invested, albeit indirectly, in consumer debt,” Hyman writes. “What began with automobiles spread to vacuum cleaners, furniture, radios, and nearly every kind of durable good desired in the great boom of the 1920s.”
And then the economy crashed. Fearful of the financial devastation of the Great Depression, banks declined to invest either in industry or in consumer lending. Would-be consumers were left without the money to buy much of anything, particularly homes. In 1934, the federal government responded by creating the Federal Housing Administration, its own go-between for connecting banks with home buyers and guaranteeing the mortgage loans they made. The Federal National Mortgage Association, better known as Fannie Mae, was created four years later. Fannie Mae helped create a national market, allowing large financial institutions to buy mortgage debt from local banks.
With the postwar consumer boom, Hyman writes, the market for debt only grew. Back in the 1930s, General Electric had created a minor subsidiary called GE Credit Corporation (GECC) to finance purchases of its own products. In the 1960s, GECC took on a life of its own, offering revolving credit to finance all sorts of products while also running various retail companies’ credit operations. By 1969, one in twenty-five households was using GECC credit in one way or another, and the division eventually grew to provide the majority of GE’s profits.
Weekly Newsletter
Starting in the 1970s, the federal government and Wall Street helped create a framework for ever-more-complex mortgage-backed financial products. And, by the late 1980s, securitized assets were available based not just on mortgages but on credit card debt, car loans, and almost any other kind of consumer debt possible. Soon, it was more profitable for many financial institutions to invest in consumption rather than production, moving capital away from the parts of the economy focused on employing people to produce goods and services.
“Whereas in the postwar period, the 1 percent paid the 99 percent in wages,” Hyman concludes, “After 1970 the 1 percent increasingly just lent the 99 percent money.”
Support JSTOR Daily! Join our new membership program on Patreon today.",2
244,"www.researchgate.net
Checking if the site connection is secure
Enable JavaScript and cookies to continue
www.researchgate.net needs to review the security of your connection before proceeding.
Ray ID:
77460aafabb2d3b3
Performance & security by
Cloudflare",7
245,"Ben Valsler
This week, Kit Chapman goes fishing for antique steel, suitable for specialist situations.
Kit Chapman
On 16 July, 1945, the world changed forever.
That morning, at 5.29am local time, the Gadget – the world’s first nuclear bomb – was detonated at the White Sands Missile Range in the United States. The explosion, equivalent to some 20 kilotons of TNT, was the birth of the atomic age and heralded the arrival of plutonium, a chemical element discovered four years earlier but kept secret because of its immense potential. Today, you can visit ground zero for the explosion – a place known as the Trinity site – on two days each year. It’s perfectly safe – the radiation has long gone, and an hour’s visit will only expose you to around one millirem. To put that in perspective, everyone in the world receives around 40 millirems a year from eating food.
But while the radiation at the Trinity site might be gone, the bomb’s blast had a staggering impact on our world. The use of nuclear weapons, from Gadget and the atomic bombings of Hiroshima and Nagasaki through to the range of other nuclear weapons tested throughout the Cold War, caused background radiation levels to increase around the world. Today, the air we breathe contains radionuclides – radioactive isotopes of elements, such as cobalt-60 – that are a remnant of those 502 nuclear bomb detonations. And while the amount of these isotopes in the air is very low and perfectly safe, they have had a strange knock-on effect.
Steel is an alloy of iron and carbon, created by smelting the iron in a furnace to strip out impurities. It’s very strong and very cheap to make, and so has become the go-to material for building houses, ships, cars, roads, cutlery and machinery. Since the Victorian era, it’s been mass-produced by two processes: first, the Bessemer process, which removes impurities in the furnace by blowing air through the molten iron; and later by the BOS process, which uses pure oxygen extracted from the atmosphere instead . The problem is that both processes require huge quantities of atmospheric gas – and that means the radionuclides left over from nuclear blasts contaminate the steel.
For most purposes, this doesn’t really matter. But sometimes it’s important to have steel that has little-to-no background radiation: for example, when you are constructing a Geiger counter or medical device to measure radiation levels or creating a satellite with very delicate sensors. For this, you need low-background steel. And that means a little recycling.
In theory, it’s possible to create low-background steel using a range of different methods. But as these processes are expensive, manufacturers look for alternatives. The answer was obvious: they just needed to find a large quantity of steel that was made before 1945. And it didn’t take long before attention turned to the waters around the Shetland Islands.
At the end of the first world war, the German High Seas Fleet was ordered to the Shetland base of Scapa Flow, where the dreadnaughts, battlecruisers and destroyers were expected to be turned over to the British Royal Navy. In an act of defiance, the Germans had scuttled – deliberately sunk – their ships in the harbour to refuse the British their prize. In doing so, they had created the richest source of low-background steel on the planet. And, of course, other ships that were sunk before 1945 were put to use, too. And so plates from the battleship Kronprinz Wilhelm ended up in a Scottish hospital, armour plating from the battleship Indiana went to hospitals in Utah and Illinois, and legend has it NASA even used parts of the German High Seas fleet for its Voyager space probe.
But the days of low-background steel are coming to an end. Cobalt-60, the most common radioactive isotope found in our air from the nuclear blasts, has a half-life of around 5.3 years. Since the Partial Nuclear Test Ban Treaty in 1963, the atmosphere has become less, well, radioactive, meaning that increasingly the steel we make today – and hope to make in the future – is fit for our satellites after all.
Ben Valsler
Kit Chapman, explaining how nuclear testing and warfare has left us with mildly radioactive steel, and so we search our shores and salty seas to seek scuppered, sunken ships as a suitable source of stable steel to serve in such specialist situations as satellites and sensors. Next week, we spice it up with Florence Schechter.
Florence Schechter
Nutmeg is a popular spice used in everything from stews and curries to the annual Christmas eggnog. But its psychoactive properties and potential lethality are less well known. Yes, you might consider yourself a good citizen, but it’s likely you have a dangerous recreational hallucinogen sitting on your kitchen shelf.
Ben Valsler
Discover myristicin – the spicy hallucinogen – In next week’s podcast. Until then, get in touch in the usual ways: email chemistryworld@rsc.org or tweet @chemistryworld. I’m Ben Valsler, thanks for joining me.
No comments yet",1
247,"Living systems grow from simple seeds
How do you grow living systems? Plant simple seeds.
Do simple things
Wikis are beautifully simple. Like Minecraft for thought. What kind of mindset produces breakthroughs like the wiki?
We decided to try whatever is most simple: to write an if statement, return a constant, use a linear search. We would just write it and see it work. We knew that once it worked, we'd be in a better position to think of what we really wanted.
So when I asked, ""What's the simplest thing that could possibly work,"" I wasn't even sure. I wasn't asking, ""What do you know would work?"" I was asking, ""What's possible? What is the simplest thing we could say in code, so that we'll be talking about something that's on the screen, instead of something that's ill-formed in our mind.""…
I think that that's a breakthrough, because you are always taught to do as much as you can. Always put checks in. Always look for exceptions. Always handle the most general case. Always give the user the best advice. Always print a meaningful error message. Always this. Always that. You have so many things in the background that you're supposed to do, there's no room left to think. I say, forget all that and ask yourself, ""What's the simplest thing that could possibly work?""
(Interview with Ward Cunningham, 2004)
The simplest thing that could possibly works is an ethos that suffuses Ward Cunningham’s work. A wiki has two simple mechanisms:
Everyone can write on every page.
You can link other pages, whether or not they exist.
That’s it. Yet this simple alphabet evolved complex living systems, from personal notes, to collaborative fansites, to Wikipedia.
What about ACLs? Published status? Moderation? Messaging? Formatting? YAGNI. Ward didn’t worry about it. He just put something out there. Later, these things evolved on their own, as needed.
Simplicity is the shortest path to a solution.
(Ward Cunningham, inventor of the Wiki)
There’s a wu wei quality, a quality of effortlessness and non-action, embodied in this kind of simplicity. By starting with a simple alphabet, we allow living complexity to evolve organically out of the possibility space of the alphabet, in response to the environment.
Do small things
One of the most interesting ideas at Parc was: every invention has to be engineered for 100 users. So if you do a programming language or a DTP word processor, etc, it has to be documented for and usable by 100 people. If you make a personal computer, you have to be able to make 100 of them. If an Ethernet, it has to connect to 100 devices, etc.
(Alan Kay, 2017. What made Xerox PARC special?)
100 users. Enough that you know it can work, not so many that you spend all your time engineering for production at scale. If you can find product-market fit with 100 users, you can find it with 1,000, or 100,000, or a million.
An incomplete list of innovations that came out of PARC:
GUIs, the desktop metaphor, windows, icons.
Ethernet local area networks
Dynabook, a precursor to the iPad
The precursor to PostScript
Object-oriented programming through Smalltalk.
Prototypal inheritance through the Self programming language
Model–view–controller software architecture
Perhaps they were on to something?
Simple rules produce complex behavior
A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system. (Gall’s Law)
Or, as summarized by Andrew Hunt:
Simple rules produce complex behavior. Complex rules produce stupid behavior.
It seems there may be two kinds of complexity, living and dead.
Dead complexity: imposed, top-down.
Living complexity: emergent, bottom-up.
Dead complexity: rational, designed.
Living complexity: messy, permissionless.
Dead complexity: fixed hierarchy, static categories
Living complexity: dynamic hierarchy, fluid and evolving statistical relationships across populations of individuals.
In what ways might we provoke the emergence of living complexity?
Living complexity grows from simple seeds
Ever since there were two organisms, life has been a matter of coevolution.
(Stewart Brand)
The moment two evolving systems touch, they begin to coevolve. Each system becomes part of the fitness function of the other. And each system is unique.
Take something in nature—two dandelions—and look at them for five minutes, listing how they are different from each other. Take two leaves from the same tree and do the same thing. Take two peas from the same pod and do the same thing. Nothing is the same. No thing is the same. Everything is itself and one of a kind.
(Sister Corita Kent, Jan Stewart, 2008. Learning By Heart.)
Because no thing is the same, asymmetries emerge. These asymmetries alter the fitness functions of all coevolving participants. They adapt, generating more asymmetries, causing more adaptation, in an endless loop.
From asymmetry emerges specialization. And so, the emergence of predator, prey, pal, parasite, pollinator, niche-creator, producer, consumer, scavenger, decomposer, all tangled together in an ecological Indra’s net.
You see in this beauty a dynamic stabilizing effect essential to all life. Its aim is simple: to maintain and produce coordinated patterns of greater and greater diversity. Life improves the closed system's capacity to sustain life. Life—all life—is in the service of life. Necessary nutrients are made available to life by life in greater and greater richness as the diversity of life increases. The entire landscape comes alive, filled with relationships and relationships within relationships.
(Liet Keynes in Frank Herbert’s Dune)
Everything becomes intertwingled in coevolutionary loops of recursive relationship, producing upward-spiraling complexity. Living systems evolve into complex systems.
Dead complexity kills living systems
So, rather than valuing simplicity over and against complexity, we might see simplicity as a living seed, which may grow into a living complexity. And, going back to Gall’s Law, we can say dead complexity hinders the emergence of living complexity.
A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system. (Gall’s Law)
One way to turn living complexity into dead complexity is by rationalizing it.
Living systems are evolved systems, and evolved systems are non-rational, nonteological. To rationalize a living system is to force it to fit our telos, to force it to fit our Procrustean rationality.
In software, we have a name for this mistake: second system syndrome.
Second-system syndrome is the tendency of small, elegant, and successful systems, to be succeeded by over-engineered, bloated systems, due to inflated expectations and overconfidence.
You hack together a small simple program to solve a problem. Congratulations! It's wildly successful. Now you have a community, and the limits of your hasty work are beginning to show. Time for a rewrite! You look at the ways the community is using the software, and rationalize it along those axes. The result is a complex system designed from scratch.
Second System Syndrome is a kind of Seeing Like a State. Like other forms of systemic rationalization, the risk is in killing the forest by organizing the trees.
While second system syndrome may rationalize the code, it often kills the ecology around it by scraping away the invisible relationships between users and software that evolved around the first system.
It’s easy to misapprehend that last line in Gall’s Law: you have to start over with a working simple system. Rationalization mistakes telos for simplicity, and starts over with a teleological system.
So the kind of simplicity we seek is almost a wu wei, a kind of living thing, a dance. Perhaps something like Chuang Tzu’s story of The Dexterous Butcher?
“Good work!” the Prince exclaimed,
“Your method is faultless!”
“Method?” said the cook
Laying aside his cleaver,
“What I follow is Tao
Beyond all methods!
“When I first began
To cut up oxen
I would see before me
The whole ox
All in one mass.
“After three years
I no longer saw this mass.
I saw the distinctions.
“But now, I see nothing
With the eye. My whole being
Apprehends.
My senses are idle. The spirit
Free to work without plan
Follows its own instinct
Guided by natural line,
By the secrets opening, the hidden space,
My cleaver finds its own way.
I cut through no joint, chop no bone.
All life comes from already existing life
If you want to make a living flower, you don't build it, you grow it from the seed. (Christopher Alexander)
How do you create living systems? Paraphrasing Alex Komoroske:
Ecosystems are never created. You can’t create living systems from scratch. All life comes from already existing life, all the way back to the origins of life.
These are all things I’m reflecting on as we build Noosphere. In what ways might we evolve a shared protocol for thought?
The Tools for Thought scene is undoubtedly a living ecosystem, brimming with scenius, many tools, and knowledge scattered across them. If a protocol tried to rationalize and systematize this mess, it would only fail, or kill the ecology. A living ecosystem cannot be created from scratch. It can only evolve out of an already existing living ecosystem.
This ethos is why, for example, Noosphere solves a few pragmatic problems, like sync and credible exit, and has no opinions about ontology or what kind of data format you use. Publish any kind of data, allow any kind of header, bolt it on to any tool for thought. Bless this mess!
Our hope is to plant a simple seed.",2
248,"On October 3, renowned South Korean illustrator Kim Jung Gi passed away unexpectedly at the age of 47. He was beloved for his innovative ink-and-brushwork style of manhwa, or Korean comic-book art, and famous for captivating audiences by live-drawing huge, intricate scenes from memory.
Just days afterward, a former French game developer, known online as 5you, fed Jung Gi’s work into an AI model. He shared the model on Twitter as an homage to the artist, allowing any user to create Jung Gi-style art with a simple text prompt. The artworks showed dystopian battlefields and bustling food markets — eerily accurate in style, and, apart from some telltale warping, as detailed as Jung Gi’s own creations.
The response was pure disdain. “Kim Jung Gi left us less than [a week ago] and AI bros are already ‘replicating’ his style and demanding credit. Vultures and spineless, untalented losers,” read one viral post from the comic-book writer Dave Scheidt on Twitter. “Artists are not just a ‘style.’ They’re not a product. They’re a breathing, experiencing person,” read another from cartoonist Kori Michele Handwerker.
Far from a tribute, many saw the AI generator as a theft of Jung Gi’s body of work. 5you told Rest of World that he has received death threats from Jung Gi loyalists and illustrators, and asked to be referred to by his online pseudonym for safety.
Generative AI might have been dubbed Silicon Valley’s “new craze,” but beyond the Valley, hostility and skepticism are already ramping up among an unexpected user base: anime and manga artists. In recent weeks, a series of controversies over AI-generated art — mainly in Japan, but also in South Korea — have prompted industry figures and fans to denounce the technology, along with the artists that use it.
While there’s a long-established culture of creating fan art from copyrighted manga and anime, many are drawing a line in the sand where AI creates a similar artwork. Rest of World spoke to generative AI companies, artists, and legal experts, who saw this backlash as being rooted in the intense loyalty of anime and manga circles — and, in Japan, the lenient laws on copyright and data-scraping. The rise of these models isn’t just blurring lines around ownership and liability, but already stoking panic that artists will lose their livelihoods.
“I think they fear that they’re training for something they won’t ever be able to live off because they’re going to be replaced by AI,” 5you told Rest of World.
One of the catalysts is Stable Diffusion, a competitor to the AI art model Dall-E, which hit the market on August 22. Stability AI is open-source, which means that, unlike Dall-E, engineers can train the model on any image data set to churn out almost any style of art they desire — no beta invite or subscription needed. 5you, for instance, pulled Jung Gi’s illustrations from Google Images without permission from the artist or publishers, which he then fed into Stable Diffusion’s service.
In mid-October, Stability AI, the company behind Stable Diffusion, raised a reported $101 million dollars and earned about a $1 billion valuation. Looking for a cut of this market, AI startups are building off Stable Diffusion’s open-source code to launch more specialized and refined generators, including several primed for anime and manga art.
Japanese AI startup Radius5 was one of the first companies to touch a nerve when, in August, it launched an art-generation beta called Mimic that targeted anime-style creators. Artists could upload their own work and customize the AI to produce images in their own illustration style; the company recruited five anime artists as test cases for the pilot.
Almost immediately, on Mimic’s launch day, Radius5 released a statement that the artists were being targeted for abuse on social media. “Please refrain from criticizing or slandering creators,” the company’s CEO, Daisuke Urushihara, implored the swarm of Twitter critics. Illustrators decried the service, saying Mimic would cheapen the art form and be used to recreate artists’ work without their permission.
And they were partly right. Just hours after the statement, Radius5 froze the beta indefinitely because users were uploading other artists’ work. Even though this violated Mimic’s terms of service, no restrictions had been built to prevent it. The phrase “AI学習禁止” (“No AI Learning”) lit up Japanese Twitter.
A similar storm gathered around storytelling AI company NovelAI, which launched an image generator on October 3; Twitter rumors rapidly circulated that it was simply ripping human-drawn illustrations from the internet. Virginia Hilton, NovelAI’s community manager, told Rest of World that she thought the outrage had to do with how accurately the AI could imitate anime styles.
“I do think that a lot of Japanese people would consider [anime] art a kind of export,” she told Rest of World. “Finding the capabilities of the [NovelAI] model, and the improvement over Stable Diffusion and Dall-E — it can be scary.” The company also had to pause the service for emergency maintenance. Its infrastructure buckled from a spike in traffic, largely from Japan and South Korea, and a hacking incident. The team published a blog post in Japanese to explain how it all works, while scrambling to hire friends to translate their Twitter and Discord posts.
The ripple effect goes on. A Japanese artist was obliged to tweet screenshots showing layers of her illustration software to counter accusations that she was secretly using AI. Two of country’s most famous VTuber bands requested that millions of social media followers stop using AI in their fan art, citing copyright concerns if their official accounts republished the work. Pixiv has announced it will be launching tags to filter out AI-generated work in its search feature and in its popularity rankings.
In effect, manga and anime are acting as an early testing ground for AI art-related ethics and copyright liability. The industry has long permitted the reproduction of copyrighted characters through doujinshi (fan-made publications), partly to stoke popularity of the original publications. Even the late Prime Minister Shinzo Abe once weighed in on the unlicensed industry, arguing it should be protected from litigation as a form of parody.
Outside of doujinshi, Japanese law is ordinarily harsh on copyright violations. Even a user who simply retweets or reposts an image that violates copyright can be subject to legal prosecution. But with art generated by AI, legal issues only arise if the output is exactly the same, or very close to, the images on which the model is trained.
“If the images generated are identical … then publishing [those images] may infringe on copyright,” Taichi Kakinuma, an AI-focused partner at the law firm Storia and a member of the economy ministry’s committee on contract guidelines for AI and data, told Rest of World. That’s a risk with Mimic, and similar generators built to imitate one artist. “Such [a result] could be generated if it is trained only with images of a particular author,” Kakinuma said.
But successful legal cases against AI firms are unlikely, said Kazuyasu Shiraishi, a partner at the Tokyo-headquartered law firm TMI Associates, to Rest of World. In 2018, the National Diet, Japan’s legislative body, amended the national copyright law to allow machine-learning models to scrape copyrighted data from the internet without permission, which offers up a liability shield for services like NovelAI.
Whether images are sold for profit or not is largely irrelevant to copyright infringement cases in the Japanese courts, said Shiraishi. But to many working artists, it’s a real fear.
Haruka Fukui, a Tokyo-based artist who creates queer romance anime and manga, admits that AI technology is on track to transform the industry for illustrators like herself, despite recent protests. “There is a concern that the demand for illustrations will decrease and requests will disappear,” she told Rest of World. “Technological advances have both the benefits of cost reduction and the fear of fewer jobs.”
Fukui has considered using AI herself as an assistive tool, but showed unease when asked if she would give her blessing to AI art generated using her work.
“I don’t intend to consider legal action for personal use,” she said. “[But] I would consider legal action if I made my opinion known on the matter, and if money is generated,” she added. “If the artist rejects it, it should stop being used.”
But the case of Kim Jung Gi shows artists may not be around to give their blessing. “You can’t express your intentions after death,” Fukui admits. “But if only you could ask for the thoughts of the family.”",3
249,"Professor Brian David Johnson on how he uses ‘science fiction prototyping’ to model future threats
Casper Skovgaard Petersen
July 12, 2022
Brian David Johnson is a Professor of Practice at Arizona State University, a Futurist and Fellow at the business consulting firm Frost & Sullivan, and a former engineer and Chief Futurist at the Intel Corporation. He is the originator of ‘sci-fi prototyping’, a technique that uses short original pieces of science fiction to model possible futures. We met with Johnson to learn more about how he uses comic books and short stories set in fictional futures to help organisations discover previously unseen threats.
What exactly is science fiction prototyping?
In short, it’s a way to use science fiction as a futures modelling tool. It’s not science fiction, but rather science fiction thinking. This distinction is important because the intent of science fiction is most often to entertain you, or if we’re being quite honest, to sell movie tickets or books. And that’s not a bad thing. But the intention of science fiction prototyping is very different in that it is a tool to be used to discover potential futures and threats that people hadn’t thought about.
How is this done?
One of the methodologies I use in my work as an applied futurist is called ‘threatcasting’, which, as the name implies, is about looking at a range of potential future threats, modelling how they would play out, and assessing which steps would be necessary to take today to avoid them. Science fiction prototyping is a tool we can use to take this process a step beyond the abstract, to have characters and situations that bring the futures to life. This pushes people to use their imagination more freely, sometimes to get them right up to the edge of the possible.
When I was employed as Chief Futurist at the Intel Corporation, I used sci-fi prototyping to threatcast some very dark futures based on the technologies that Intel was building. I would then share these visions with my fellow engineers which often freaked them out because they could see the awful things that could happen. I once had a colleague get up and walk out of a meeting because he was so upset by the possibility that somebody could take a piece of technology – a piece of engineering that he loves so dearly – and use it to cause harm.
Sci-fi prototypes can be used both in this way, to get people thinking differently about the future and to provoke conversations – sometimes uncomfortable ones – but also to create a common language to talk about the future in a way that is imaginative but also science and fact based.
What does a sci-fi prototype modelling a future threat look like? Can you give us an example?
It can look like a comic book or a graphic novel.
A lot of the work we do at our Threatcasting Lab at Arizona State University has to do with national security, global security, and climate resource security. We recently did a piece for the United States Army Cyber Institute that examined the future of quantum technologies and their potential use in warfare. Quantum computing is deep, nerdy math stuff and something that’s hard for a lot of people to wrap their heads around. With sci-fi prototyping you can take these more technical aspects and apply them to real-life situations, getting into what the effects of the technology would be for people on the ground in a visceral and easily understandable way.
The result of our prototyping process was a piece called Quantum Winner. In it, you follow three soldiers on the ground caught in the middle of a battle where quantum technology is being used. We see the breaking of encryption, the breakdown of GPS, and other technological failures, as well as the effects this would have on the soldiers. The piece never uses the word ‘quantum’ except for in its title because the goal is not to explain the technology but to shows you the effects. It’s dark stuff, and it’s meant to provoke a reaction you wouldn’t get from a high-level research paper or scenario planning exercise.
Why are military institutions and other organisations hiring comic book writers and sci-fi authors to tell them of these threats?
I think as we moved from the 20th century to the 21st century, there’s a was a massive shift in the way people thought about technology and the future. There is a legacy around futurists as charlatans and snake oil salesmen that isn’t so great. Luckily, we’ve left a lot of that behind. And once people accepted futures thinking as a necessity, they started feeling a lot more comfortable moving on to science fiction and sci-fi prototyping.
Then there’s the fact that engineers and technologists have always found blueprints for innovation in sci-fi – flip phones, rockets, the metaverse, you name it. Although you can teach someone to be a sci-fi author, you can’t teach someone to be Neil Stevenson, Gene Roddenberry, or Isaac Asimov. Sci-fi prototyping is something you can teach. It’s not as reliant on that single brilliant person and their ideas. And because the process is repeatable, organisations can depend upon it year over year in their long-term strategic planning.
What makes science fiction prototyping different from other futurist methods like scenario planning, which also involve elements of storytelling?
Scenario planning is a very powerful tool in futures work. But I often argue that while it was a great fit for the 20th century, and a necessity for the 21st, it is no longer sufficient.
For one, scenarios and other similar methodologies are not great at capturing the almost quantum-like complexity of many issues facing us today. It’s also bloodless. Human beings are messy, quirky, wonderful, and cruel. Generally, scenario planning doesn’t capture that well because it’s not its goal. With sci-fi prototyping you can get into the weirdness by focusing on situations, technologies, and characters who think, feel and act. It exposes you to a level of detail that’s unrivalled in other futurist methodologies. Say, for instance, you are modelling a large-scale cyber-attack. With sci-fi prototyping you can get into what that would look like if you were sitting in an autonomous car or looking at your phone while it was happening – in other words, how it affects people on the ground.
Science fiction is often subversive, critical of the status quo and the powers that be – warning us of abuses of power or what happens when technology runs amok or is used to cause harm. Yet sci-fi prototyping is often used to do innovation sandboxing for the kinds of institutions that sometimes take the role of the villain in in works of sci-fi literature. Do you see a conflict there?
It’s true that really good works of science fiction are often cautionary tales that show us a bad future and warns us to not let that happen. The perfect example of that is George Orwell’s 1984. There are many authors working today who carry on that legacy, including Cory Doctorow, who is very clear he’s not a futurist but an activist and a writer intent on showing people the risks and dark sides of the digital future.
In my experience, sci-fi prototyping can function in a similar way in that it can be used to counter prevailing narratives and explore all the things that could go wrong. It challenges people to think through extreme and often uncomfortable scenarios. A recent example of this is a prototype we did for Cisco, looking at the intersection between global supply chains, cyber-attacks, and terrorism, which resulted in a graphic novella called Two days after Tuesday. The story breaks down how a small ‘spear phishing’ attack at the edge of a supply chain could cause a major disaster. We show the step-by-step process through which hackers and state-sponsored terrorists could create a physical vulnerability at a port to sneak in a dirty bomb and detonate it on the island of Manhattan during rush hour. The point of going to this awful and dark place is not to have a story about villains or heroes, but to show how wrong this can quickly go, and – from a network security perspective – provoke a conversation around what could be done to prevent such a scenario from occurring.
This last part is crucial because once we’ve seen how bad things can go, we then need to ask: OK, so what do we do about it? Ultimately, the goal of envisioning futures through sci-fi prototyping is to empower action. That’s why we go to those dark places. Ultimately, the intent is to make the world better and safer.",8
250,"At MikoVerse, we're building the next generation of VTuber technology, focused around enhancing content creation. Our mission is to build deeper connections between creators and their fans by unlocking engagement in the virtual world. In the MikoVerse, viewers can directly impact the content: not only can they watch but they can participate, create, spend, and play all on the same platform.",1
251,"Page not found
The page you are looking for might have been moved or renamed.
We apologize for any inconvenience. Please double-check the URL or try the following:
Search our site for keywords of interest.
Visit our home page or use the navigation menu to find what you need.
Contact us if you're still having a problem.",2
252,"« Mad skills » : quand votre boîte veut que vous soyez bizarre, mais pas trop quand même
L’EDITO / Après les hard skills et les soft skills, de nouvelles compétences sont désormais recherchées par les recruteurs : les mad skills, soit tout ce qui fait de vous un profil un peu fou ou atypique. Au-delà de l’hypocrisie de cette nouvelle mode supposément inclusive mais qui borne la déviance dans les limites du tolérable, elle nous pousse à nous interroger sur l’extension toujours plus poussée du champ des traditionnelles compétences attendues d’un bon salarié.
Si vous appartenez comme moi à la génération dite des millennials, soit ces personnes nées entre le milieu des années 1980 et le début des années 1990, il est fort probable que vous ayez fait l’expérience de la transformation et de la complexification croissante des procédures de recrutement. En ce qui me concerne, j’ai été élevée dans l’idée que l’accumulation de diplômes jusqu’à un stade assez avancé de ma vingtaine suffirait à m’ouvrir toutes les portes. Certes, cela se ferait au prix du sacrifice d’une bonne partie de mes jeunes années et d’un endettement non négligeable pour financer diverses écoles, mais l’accumulation de ce que le verbiage RH, directement importé des États-Unis, nomme les hard skills – soit les « compétences dures » – devrait littéralement « payer » lors de mon arrivée sur le marché du travail.
Las ! J’ai commencé à chercher du travail au moment où le secteur RH entamait sa grande mue en décidant d’étendre le champ de ce qu’il considérait comme des « compétences » bien au-delà de ce que le sens commun admet traditionnellement. Avec quelques années de retard sur les États-Unis, la plupart des directions des ressources humaines de ce pays ont embrassé la mode des soft skills, soit ces compétences dites « comportementales » qui, en intégrant des critères comme la capacité d’empathie, d’adaptation ou d’entraide dans les fiches de postes, ont peu à peu rendu la ligne de démarcation entre le personnage construit par chacun au travail et notre personnalité intime de plus en plus fragile. Et tandis que la fonction RH se transformait et que les directeurs RH se rebaptisaient en « révélateurs de talents » ou de « richesses humaines », les procédures de recrutement intégraient de plus en plus souvent des tests de personnalité divers destinés à faire sauter le masque soigneusement construit sur notre CV pour révéler notre « personnalité profonde » à nos employeurs potentiels.
De l’entretien d’embauche au profilage
Sans que personne ne moufte – rareté de l’offre oblige – toute une génération a accepté de se soumettre à des process dignes du profilage d’un serial killer – au cas où un Hannibal Lecter en puissance sommeillerait dans le futur chief product officer d’une quelconque start-up. Je me souviens avoir moi-même fait l’expérience d’un entretien de deux heures particulièrement éprouvant, constitué d’une batterie de questions destinées à cerner mon degré de confiance en moi, au terme duquel une ex-DRH transformée en « révélatrice des richesses humaines » a abouti à la conclusion que, manifestement, je n’avais pas beaucoup de richesse à apporter à son entreprise. Cet examen digne de mes pires séances de thérapie n’aurait jamais été possible sans l’imprégnation, dans l’ensemble de l’économie française, du fameux esprit start-up né dans la Silicon Valley, qui a contribué à détruire tous les garde-fous qui protégeaient autrefois les individus d’une pénétration du travail jusque dans la sphère intime. Une mécanique qui a donc permis aux RH de se croire autorisés à fouiller jusque dans les tréfonds de notre inconscient.
Cela aurait pu s’arrêter là - c’était déjà bien assez - mais une nouvelle mode, elle aussi importée de Silicon Valley (que l’on ne remerciera jamais assez, vraiment) a récemment fait son apparition, chamboulant à nouveau les procédures de recrutement : désormais, nos DRH mettent sur un piédestal les candidats possédant des mad skills, littéralement « des compétences folles ». Selon le psychologue du travail Florian Tran, interrogé par le magazine Ouest France, les mad skills sont « les compétences singulières, atypiques d’un candidat ». Selon lui, cette nouvelle mode est la conséquence directe de la crise liée à la pandémie mondiale, qui pousse les recruteurs à embaucher des personnalités « aux compétences singulières, atypiques » : « les entreprises ont plus que jamais besoin de profils qui sortent du cadre, qui n’ont pas peur du changement, qui sauront être résilients, mais aussi qui sauront faire preuve d’adaptabilité et de polyvalence ». Autant dire qu’il n’est pas question de valoriser votre pratique de la flûte à bec en sixième ou votre dernier stage d’accrobranche dans le Jura. Les entreprises veulent du très très lourd, quitte à brasser large, jusque dans l’expérience d’un deuil ou d’une maladie - autant d’expériences traumatiques apparemment prisées des recruteurs. « Ce qui ne vous tue pas vous rend plus fort », nous disait ce bon vieux Nietzsche : tel semble être le nouveau mantra des RH de ce pays.
Accueillir la « déviance positive »
Il est donc désormais de bon ton d’étaler ses traumas, en espérant pouvoir être identifié comme ce que le psychologue social Serge Moscovici qualifie de profil « déviant ». À une petite nuance près, qui a son importance : comme le précisent Isabelle Patroix, playground manager (???) et Christian Rivet, professeur associé en marketing, dans une tribune parue sur le site The Conversation, cette « déviance » doit être « positive » (splendide oxymore) : il s‘agit « de ne pas emprunter forcément le chemin tracé tout en ayant des intentions positives ».
« La déviance doit être contenue dans les limites de ce que le monde du travail – et la société en général – tolère »
Bipolaires, évitez donc d’évoquer votre dernier séjour à Saint-Anne. Privilégiez la langue de bois en insistant sur la fabuleuse créativité qui vous parcourt lors de vos phases maniaques. Je manie l’ironie intentionnellement, car il n’est évidemment pas question de valoriser quoi que ce soit de réellement sérieux. La déviance doit être contenue dans les limites de ce que le monde du travail – et la société en général – tolère. Évoquez, à la limite, la manière dont vous avez surmonté le deuil de votre poney Caramel à dix ans ou dont vos dernières vacances à Madagascar ont dévoilé en vous des instincts de solidarité et d’empathie jusqu’alors étouffés. Sur notre CV, la case « loisirs » ou « expériences » restait le dernier espace en quelque sorte gratuit, rarement mobilisé par les recruteurs. La voici devenue sursignifiante, comme tout ce que vous pourrez dire ou faire lors d’un entretien d’embauche. Nul garde-fou : vous êtes désormais surexposés, et devez le tolérer – ou totalement mythonner.
Cette surexposition est d’autant plus malsaine qu’elle se fend de vertus de tolérance et d’ouverture d’esprit, comme en témoigne cette passion pour les mad skills qui prétend, dans une démarche soit-disant inclusive et authentique (autres mots-clés incontournables), rechercher l’atypique, l’anormal. Mais cette appétence prétendue pour la bizarrerie, la « déviance », masque en réalité un refus massif des entreprises d’affronter la réalité de la souffrance morale et psychique des salariés, comme en témoigne le phénomène de Big Quit qui en est la manifestation la plus radicale. Selon un récent sondage, à la question « Avez-vous déjà envisagé sérieusement de vous suicider ? », 28 % des moins de 35 ans répondent favorablement. Pas sûr que les RH soient prêts à accueillir ce phénomène.",0
253,"A new Microsoft Work Trend report revealed that shifts to hybrid work and increased workload are leading to productivity paranoia.
Eighty-seven per cent of employees reported they are productive at work, while 85 per cent of leaders said the shift to hybrid work has made it challenging to have confidence that people are being productive. This shift has led to productivity paranoia, where leaders are uneasy about whether people are being productive and working on the correct task.
Only 12 per cent of leaders said they have full confidence in their team’s productivity. But almost 90 per cent of employees reported they are productive at work.
In addition, the number of meetings per week has grown by 153 per cent globally for the average Microsoft Teams user since the start of the pandemic. Workers are flooded with meeting invites, and declines and tentative acceptances have increased in the past two years.
When it comes to returning to the office, 73 per cent of employees and 78 per cent of business decision makers said they need a better reason to go in than just company expectations.
The report also revealed that socializing and connecting with coworkers are important to employees. Eighty-four per cent of employees would be motivated to go into the office by the promise of socializing with coworkers, while 85 per cent are motivated by rebuilding team bonds.
Microsoft also announced an expansion to Microsoft Viva: Viva Amplify, which is designed to engage employees and connect them when working apart. It features a Leadership Corner in Viva Engage, which provides a space to invite employees to interact directly with leadership.
Enhancements to Microsoft Viva also include new integrations between Viva Learning and LinkedIn Learning which will make it even easier to access content from LinkedIn Learning Hub right in the flow of work in Teams.
Additionally, the new Viva Connections home experience will bring all of Microsoft Viva’s apps into one place, and the Viva briefing email will provide more personalized productivity recommendations.
The company is also rolling out Viva Sales, the first role-based experience app in the platform. Viva Sales brings together a seller’s CRM with Microsoft 365 and Teams to provide a more streamlined and AI-powered selling experience. It will become generally available on October 3.",4
254,"Undeclared pools in France uncovered by AI technology
- Published
The discovery of thousands of undeclared private swimming pools in France has provided an unexpected windfall for French tax authorities.
Following an experiment using artificial intelligence (AI), more than 20,000 hidden pools were discovered.
They have amassed some €10m (£8.5m) in revenue, French media is reporting.
Pools can lead to higher property taxes because they boost property value, and must be declared under French law.
The software, developed by Google and French consulting firm Capgemini, spotted the pools on aerial images of nine French regions during a trial in October 2021.
The regions of Alpes-Maritimes, Var, Bouches-du-Rhône, Ardèche, Rhône, Haute-Savoie, Vendée, Maine-et-Loire and Morbihan were part of the trial - but tax officials say it may now be rolled out nationwide.
There were more than 3.2 million private swimming pools in France in 2020, according to data website Statista, with sales already booming before the Covid pandemic.
But as more employees worked from home, there was a further surge in pool installations.
According to Le Parisien newspaper, an average pool of 30 sq m (322 sq ft) is taxed at €200 (£170) a year.
The tax authorities say the software could eventually be used to find undeclared home extensions, patios or gazebos, which also play a part in property taxes.
Antoine Magnant, the deputy director general of public finances, told Le Parisien: ""We are particularly targeting house extensions like verandas.
""But we have to be sure that the software can find buildings with a large footprint and not the dog kennel or the children's playhouse,"" he added.
The crackdown comes after Julien Bayou, of France's Europe-Ecology Greens party, did not rule out a ban on new private pools.
Speaking to BFMTV, he said that France needs a ""different relationship to water"" and that the ban would be a ""last resort"".
""The challenge is not to ban swimming pools, it is to guarantee our vital water needs,"" he said.
His comments come as France tackles its worst recorded drought that has left more than 100 municipalities short of drinking water.
In July, France had just 9.7mm (0.38in) of rain, making it the driest month since March 1961, the national weather service Meteo-France said.
Irrigation has been banned in much of the north-west and south-east of France to conserve water.",5
255,"In France, solar just got a huge boost from new legislation approved through the Senate this week that will require all parking lots with spaces for at least 80 vehicles – both existing and new – to be covered by solar panels.
The new provisions are part of French president Emmanuel Macron’s large-scale plan to heavily invest in renewables, which aims to multiply by 10 the amount of solar energy produced in the country, and to double the power from land-based wind farms.
Starting July 1, 2023, smaller carparks that have between 80 and 400 spaces will have five years to be in compliance with the new measures. Carparks with more than 400 spaces have a shorter timeline: They will need to comply with the new measures within three years of this date, and at least half of the surface area of the parking lot will need to be covered in solar panels.
According to the government, this plan, which particularly targets large parking areas around commercial centers and train stations, could generate up to 11 gigawatts, which is the equivalent of 10 nuclear reactors, powering millions of homes. Public Sénat writes that stipulations were put into place excluding parking lots for trucks carrying heavy goods or parking areas in historic or protected areas, to avoid “distorting” them, according to an amendment to the bill. While it’s unclear, future iterations of the bill will likely detail parking lots that would be excluded, in addition to how this plan will be funded and what the penalties would be for lack of compliance.
Other measures on the table include building large solar farms on vacant land found alongside highways and railways, as well as on agricultural lands where feasible. Macron has said that any bill passed would need to guarantee money that ensures local communities directly benefit from the energy shift.
France’s national rail service SNCF also plans to install some 190,000 square meters of solar panels in 156 stations throughout the country by 2025 and 1.1 million square meters by 2030, all with the aim to reduce energy consumption by 25%.
The government also plans to build around 50 additional wind farms likes the one offshore Saint-Nazaire by 2050 in France. Measures are in place to reduce delays in building offshore wind farms from 10-12 years down to six years, and large solar farms from six years to three years.
This summer, the French government solidified two zones for offshore wind farms off the coast of the Atlantic following a massive public debate involving 15,000 participants, with environmental protection being the biggest concern.
The first wind farm is planned to be sited off the island of Oléron, more than 35 km off the coast of La Rochelle, with a capacity of around 1,000 MW. The second wind farm will likely be located farther out at sea, with both wind farms together producing enough electricity for 1.6 million people.
Comments",5
256,"After two years in remote mode, we’re very excited to announce that this year’s Hackaday Supercon will be coming back, live! Join us Nov. 4th, 5th, and 6th in sunny Pasadena, CA for three days of hacks, talks, and socializing with the Hackaday community. And we’d love to see and hear in person what you’ve been up to for the last two years – so start brainstorming what you’re going to talk about now and fill out the call for proposals.
Supercon is On!
We’ll be starting off on Friday Nov. 4th with early-bird registration, a mellow afternoon of badge-hacking and workshops, and a party to kick off the con. Saturday and Sunday will be the full enchilada: two tracks of talks, hacking stations and food set up in the alley, and workshops aplenty. (Just thinking about hacking in the alley and sharing tacos afterward again brings a tear of joy to my eye.) We’ll close up Sunday night with the 2022 Hackaday Prize Awards and a chance to demo the weekend’s badge hacking on stage.
If you haven’t ever been to a Supercon before, it’s Hackaday in real life. People bring hacks to show and share, projects to work on, and their ideas that are too big to fit in the overhead compartment anyway. The crowd is awesome. There are seasoned pros, famous YouTubers, and brand-new hackers to boot. But yet it’s not overwhelming – Supercon is too big to fit in your living room, but it’s nonetheless cozy. The folks in attendance are all fantastic and you’ll stumble into the most awesome conversations.
It’s a weekend you don’t want to miss, so start figuring out how you’re going to get to Pasadena now.
We’ll be putting tickets on sale soon, and while we can’t see into the future, they have sold out every year, so keep your eyes on Hackaday to get yours. And of course, speakers don’t need no stinking tickets.
Call for Proposals
Supercon has two stages and two tracks of talks: one for shorter 20-minute presentations in the smaller Design Lab and one for long-form 45 minute talks on the much bigger Center Stage. We really loved that the “smaller” format brought out a bunch of speakers in 2019 who would maybe not have committed to the full presentation, but who nonetheless gave some of the most interesting talks of the whole Supercon. It’s ideal for first-timers, or just getting your feet back into the waters of real-life presentations after a two-year hiatus – and it helps us squeeze more talks into the limited time we’ve got over the weekend. And if you’ve got more to say or show, of course there’s the main stage.
If you want to get a feel for what makes a good Supercon talk, check out the video playlist for the 2019 presentations. We don’t want to see what’s been shown before, though – we want you to bring whatever turns you on, so don’t limit yourself. The tremendous diversity of experience and interest in our community is half of what makes Supercon tick. We want to hear your story!
We’ll also be running as many workshops as we have time and space for, so if you’ve got something you’d like to teach people in a smaller, hands-on format, let us know! Workshops tend to run an hour or two and allow for from ten to forty participants. Get the proposal in, and we’ll talk details.
Good to Be Back
We’ll be dropping more tidbits about how you can get your tickets and the badge design over the next few weeks. While November seems like a long way off, it’s never too early to start thinking Supercon. And after two years away, it’s about time!
39 thoughts on “The 2022 Hackaday Supercon Is On! And The Call For Proposals Is Open”
Try now?
Works for me :)
Yep they fixed it, and submitted!
Oh man, that is awesome. Not sure if I’ll be able to attend or not this here, but I hope I can somehow work it out!
Also I’d like to know, are we okay to submit more than one talk/presentation?
Sure! Don’t spam us, but if you’ve got a few ideas, go for it!
Wonder what interesting chips the badge will use given the chip shortage
There is a shortage of 555s?
Cost of potatoes is going up too… so making more chips is getting expensive.
Nvidia 4k series gfx chips.
Nvidia tried to cancel their order with tsmc and tsmc flat out told them no. So they will be sitting on a boatload of fab time they dont really want. ;-D
This is the best chip news I’ve heard in a long time.
Weekly Covid rate / hacker conference response
July 1, 2020, 44k / NOPE too risky
July 1, 2021, 16k / NO WAY! Waaaay to risky!
July 1, 2022, 117k / CONS ARE BACK ON, BABY!!!
I think the world has moved on, and you would be happier if you did too.
I’m like the hipster mover-on’er. I moved on way before it was cool.
You overlook the full situation.
In 2020:
– 0% of the world was vaccinated
– there were no effective treatments for COVID-19
– little to nothing was known about it
2021:
– vaccines were in the early stages but weren’t widely rolled out, we really didn’t know how they’d go “in the real world”
2022:
– we have several vaccines with varying effectiveness, some of them very good
– we now have antivirals that will target COVID-19
– we don’t know everything, but we now know a lot more about how it spreads, importance of ventilation… etc.
2020 I agree with you. 2021 to 2022 I do not agree. By April 2021 we were over a billion doses in. Headlines of the summer are all about how great the vaccines were working, removal of mask mandates, and opening up of travel, etc etc.
The 7 day rolling average for deaths in the USA is more than double now what it was a year ago. As I’ve already pointed out, the reported 7 day average for infections is almost 10x. This is even after the reduction in testing due to vaccines reducing many infection’s severity and many people not bothering with an ‘official’ test after getting sick.
If one was anti-return-to-normal in summer 2021, it makes no logical sense that one could be pro-return-to-normal in summer 2022.
“”” it makes no logical sense that one could be pro-return-to-normal in summer 2022.”””
Of course there is logic. It’s called “acceptance”.
At some point, once you have made great efforts, it can come a point where the only viable way forward is to just accept the risk.
A lot of the illnesses could be stopped if everyone stopped all close contacts and wore hazmat suits all the time. But it’s not an acceptable way to live … so we always accept some risk to reach a point where life is worth living. It’s all about balance.
Also, looking at the CDC covid tracker, the 7 day average of death is at the same level as a year ago (actually even a bit lower). And it’s almost at the lowest level since the beginning of COVID.
It also doesn’t take into account that some people dying _with_ COVID, don’t die _of_ COVID. And this is better seen looking at over-mortality number (i.e. compare total death per day this year, vs average pre-covid years). I don’t have those numbers for the US but for BE where I am, you can’t really see any over-mortaity anymore (vs 2020-2021 where it was _clearly_ visible). So yeah, some people still die with COVID and it might even have hastied their death a bit, but they were not long for this world in any case.
(I’d post link to sources but I know from experience posting links in HaD comment is a sure way to have the comment held … But a quick google for “COVID Data Tracker CDC” should get you there. And “sciensano excess mortality” for BE data )
July 18th, 2021, CDC’s 7 day death average is 286. July 18th, 2022 CDC’s 7 day average is 352. Not sure how that qualifies as “at the same level as a year ago (actually even a bit lower)”. Now, I’m not the best at maths, but I’m fairly certain 286 is not lower than 352.
Our World In Data (Johns Hopkins University source) (which is the source I use because many regard the data as better than CDC) at the time of my last comment showed the latest of July 11th of 474 vs 237 a year prior. Again, not the best at maths, so I apologize for saying “more than double” when it was infact exactly double.
All the other non-sequitur stuff you threw in there was known in summer 2021.
I stand by my statement that if one was anti-return-to-normal in summer 2021, it makes no logical sense that one could be pro-return-to-normal in summer 2022. Rejection of facts in the name of ‘acceptance’ is not logical. All the data I see shows that this isn’t over. As more and more people ‘return to normal’ and vaccine/boosters efficacy keeps dropping, you are going to see the death to case ratio continue to climb. I’ve got a dollar on Cons in the late fall/winter getting canceled and the media whipping us back into a frenzy when the new variant hits. viva el miedo!
COVID concerns are real, and we don’t want to downplay them.
Indeed, we’re taking longer than usual with tickets because we have to make sure that we have enough space / precautions to do this safely. We can’t just carbon-copy previous years, obviously.
I vaxed, I boosted, I re-boosted, I mask in public indoor spaces. I spent my summer risk buffer flying to gd Tanzania and back. Granted, you’re only as good as your continuing low viral exposure, but I’m willing to give this somewhat risky behavior a go.
I don’t think it should be an issue this time around, but if it does get worse again, they can always do a BYOM (Bring Your Own Microcontroller) badge!
There’s precedent!
We’re already a few steps ahead of the first Supercon ever, for which the badge was a collection f holes — a protoboard. But we, and the audience, brought a lot of parts. Epic hacks ensued.
https://hackaday.com/2015/11/20/the-best-conference-badge-hacking-youve-ever-seen/
https://hackaday.com/2015/12/09/the-best-badges-of-the-supercon/
And/or Thomas Flummer’s unofficial (but awesome!) Remoticon badge last year:
https://hackaday.com/2021/11/10/the-hackaday-remoticon-2-badge-an-exercise-in-your-own-ingenuity/
where you can add your own chip if you can get one! :)
(And Sprite’s hack on that badge:https://hackaday.com/2022/04/14/remoticon-2021-jeroen-domburg-sprite_tm-hacks-the-buddah-flower/)
But nope. We’ve got a solid design, some prototypes made (even a few months ago!) and I think we’re good for chips.
The logo / banner are actually spoilers for the badge, but now I’ve said too much!
You crafty bastards! I’m in!
“The logo / banner are actually spoilers for the badge, but now I’ve said too much!”
I’ve squinted a while at the logo / banner, but all I see are the face of a clown or a ducky.
Am I close?
You’re right, Elliott.
All components, including the MCUs, are ready and the badges are in production.
I’ve been looking forward to this. It is such a fun place to meet up and learn something new, or a different way of looking at things.
Gathering soldering iron, proto boards, parts, microcontrollers, pinking shears.
Such a shame I can’t make it… but we both have a newborn as well as a move to a different country planned later that month; there’s no chance of squeezing both the trip and the quarantine China imposes on you into that…
Congratulations on the newborn! Enjoyed your 2019 badge a whole lot. I totally forgot to ask in the years since
is there a replacement LCD I can get? I totally might have cracked mine(!) (WHOOPS!)
Congratulations!!
You’re right, that IS a shame. If you want to join remotely I’m happy to carry around a cell phone necklace.
That’s awesome on the real-life front. Congrats!
Take a bit off, we’ll see you again soon.
Logistics are still pending, but we’re going to do our best to have some plausible remote participation as well.
Do we have to give a presentation/submit a proposal in order to attend?
Nope. Tickets will go on sale soon(ish).
So excited to be able to go again! Honestly this conference is the only thing I look forward to each year; gonna bring a tear to my eye :)
Just FYI in case no one has whinged about it: the email notice I received included the text “announce the 2022 Hackaday Superconference and open the door for proposals”, with a link to the graphic for the 2011/05/14 article Bluetooth media remote in an n64 controller.
Excited for opertunity of first con, missed 2019 and deeply regretted it. Looking forward to meeting folks and learning lots.
I was good while it lasted. Good bye Remoticon! Happy for all the American hackers able to meet in person again though.
Don’t bid adieu too soon! We’re going to try to have a plausible remote component this year too. I mean, who can go back to in-the-flesh-only cons after being able to share all over the world simultaneously?
We’ve got the Discord still running, and we’ll stream live anyway. That’s halfway there. What else would you like to see?
” What else would you like to see?”
[CENSORED!]
B^)
2019 had a theme: FPGAs. Does 2022 have a theme?
Please be kind and respectful to help make the comments section excellent. (Comment Policy)",8
257,"Bicameral mentality
This article has multiple issues. Please help improve it or discuss these issues on the talk page. (Learn how and when to remove these template messages)
Bicameral mentality is a hypothesis in psychology and neuroscience which argues that the human mind once operated in a state in which cognitive functions were divided between one part of the brain which appears to be ""speaking"", and a second part which listens and obeys—a bicameral mind, and that the evolutionary breakdown of this division gave rise to consciousness in humans. The term was coined by Julian Jaynes, who presented the idea in his 1976 book The Origin of Consciousness in the Breakdown of the Bicameral Mind,[1] wherein he made the case that a bicameral mentality was the normal and ubiquitous state of the human mind as recently as 3,000 years ago, near the end of the Mediterranean bronze age.
The Origin of Consciousness[edit]
Jaynes uses ""bicameral"" (two chambers) to describe a mental state in which the experiences and memories of the right hemisphere of the brain are transmitted to the left hemisphere via auditory hallucinations. The metaphor is based on the idea of lateralization of brain function although each half of a normal human brain is constantly communicating with the other through the corpus callosum. The metaphor is not meant to imply that the two halves of the bicameral brain were ""cut off"" from each other but that the bicameral mind was experienced as a different, non-conscious mental schema wherein volition in the face of novel stimuli was mediated through a linguistic control mechanism and experienced as auditory verbal hallucination.
Bicameral mentality[edit]
Bicameral mentality would be non-conscious in its inability to reason and articulate about mental contents through meta-reflection, reacting without explicitly realizing and without the meta-reflective ability to give an account of why one did so. The bicameral mind would thus lack metaconsciousness, autobiographical memory, and the capacity for executive ""ego functions"" such as deliberate mind-wandering and conscious introspection of mental content. When bicameral mentality as a method of social control was no longer adaptive in complex civilizations, this mental model was replaced by the conscious mode of thought which, Jaynes argued, is grounded in the acquisition of metaphorical language learned by exposure to narrative practice.
According to Jaynes, ancient people in the bicameral state of mind would have experienced the world in a manner that has some similarities to that of a person with schizophrenia. Rather than making conscious evaluations in novel or unexpected situations, the person would hallucinate a voice or ""god"" giving admonitory advice or commands and obey without question: One would not be at all conscious of one's own thought processes per se. Jaynes's hypothesis is offered as a possible explanation of ""command hallucinations"" that often direct the behavior of those with first rank symptoms of schizophrenia, as well as other voice hearers.[2]
Jaynes's evidence[edit]
Jaynes built a case for this hypothesis that human brains existed in a bicameral state until as recently as 3,000 years ago by citing evidence from many diverse sources including historical literature. He took an interdisciplinary approach, drawing data from many different fields.[3] Jaynes asserted that, until roughly the times written about in Homer's Iliad, humans did not generally have the self-awareness characteristic of consciousness as most people experience it today. Rather, the bicameral individual was guided by mental commands believed to be issued by external ""gods""—commands which were recorded in ancient myths, legends and historical accounts. This is exemplified not only in the commands given to characters in ancient epics but also the very muses of Greek mythology which ""sang"" the poems. According to Jaynes, the ancients literally heard muses as the direct source of their music and poetry.
Jaynes asserts that in the Iliad and sections of the Old Testament no mention is made of any kind of cognitive processes such as introspection, and there is no apparent indication that the writers were self-aware. Jaynes suggests, the older portions of the Old Testament (such as the Book of Amos) have few or none of the features of some later books of the Old Testament (such as Ecclesiastes) as well as later works such as Homer's Odyssey, which show indications of a profoundly different kind of mentality—an early form of consciousness.[3]
In ancient times, Jaynes noted, gods were generally much more numerous and much more anthropomorphic than in modern times, and speculates that this was because each bicameral person had their own ""god"" who reflected their own desires and experiences.[4]
He also noted that in ancient societies the corpses of the dead were often treated as though still alive (being seated, dressed, and even fed) as a form of ancestor worship, and Jaynes argued that the dead bodies were presumed to be still living and the source of auditory hallucinations.[3] This adaptation to the village communities of 100 individuals or more formed the core of religion. Unlike today's hallucinations, the voices of ancient times were structured by cultural norms to produce a seamlessly functioning society.
Jaynes inferred that these ""voices"" came from the right brain counterparts of the left brain language centres; specifically, the counterparts to Wernicke's area and Broca's area. These regions are somewhat dormant in the right brains of most modern humans, but Jaynes noted that some studies show that auditory hallucinations correspond to increased activity in these areas of the brain.[3]
Jaynes notes that even at the time of publication there is no consensus as to the cause or origins of schizophrenia. Jaynes argues that schizophrenia is a vestige of humanity's earlier bicameral state.[3] Recent evidence shows that many people with schizophrenia do not just hear random voices but experience ""command hallucinations"" instructing their behavior or urging them to commit certain acts, such as walking into the ocean, which the listener feels they have no choice but to follow. Jaynes also argues people with schizophrenia feel a loss of identity due to hallucinated voices taking the place of their internal monologue.[full citation needed]
As support for Jaynes's argument, these command hallucinations are little different from the commands from gods which feature prominently in ancient stories.[3] Indirect evidence supporting Jaynes's theory that hallucinations once played an important role in human mentality can be found in the recent book Muses, Madmen, and Prophets: Rethinking the History, Science, and Meaning of Auditory Hallucination by Daniel Smith.[5]
Breakdown of bicameral mentality[edit]
Jaynes theorized that a shift from bicameral mentality marked the beginning of introspection and consciousness as we know it today. According to Jaynes, this bicameral mentality began malfunctioning or ""breaking down"" during the 2nd millennium BCE. He speculates that primitive ancient societies tended to collapse periodically: for example, Egypt's Intermediate Periods, as well as the periodically vanishing cities of the Mayas, as changes in the environment strained the socio-cultural equilibria sustained by this bicameral mindset.
The Bronze age collapse of the 2nd millennium BCE led to mass migrations and created a rash of unexpected situations and stresses which required ancient minds to become more flexible and creative. Self-awareness, or consciousness, was the culturally evolved solution to this problem. This necessity of communicating commonly observed phenomena among individuals who shared no common language or cultural upbringing encouraged those communities to become self-aware to survive in a new environment. Thus consciousness, like bicameral mentality, emerged as a neurological adaptation to social complexity in a changing world.[citation needed]
Jaynes further argues that divination, prayer, and oracles arose during this breakdown period, in an attempt to summon instructions from the ""gods"" whose voices could no longer be heard.[3] The consultation of special bicamerally operative individuals, or of divination by casting lots and so forth, was a response to this loss, a transitional era depicted, for example, in the book of 1 Samuel. It was also evidenced in children who could communicate with the gods, but as their neurology was set by language and society they gradually lost that ability. Those who continued prophesying, being bicameral according to Jaynes, could be killed.[6][7] Leftovers of the bicameral mind today, according to Jaynes, include mental illnesses such as schizophrenia and the hallucinations present in patients with split brain syndrome.
Reception[edit]
Popular reception[edit]
An early (1977) reviewer considered Jaynes's hypothesis worthy and offered conditional support, arguing the notion deserves further study.[8][9]
The Origin of Consciousness was financially successful, and has been reprinted several times. It remains in print, with digital and audio editions appearing in 2012 and 2015.
Originally published in 1976,[10] it was nominated for the National Book Award in 1978. It has been translated into Italian, French, German, Korean, Japanese, Spanish, and Persian.[11]
A new edition, with an afterword that addressed some criticisms and restated the main themes, was published in the United States in 1990 and in the United Kingdom (by Penguin Books) in 1993,[12] re-issued in 2000.[13]
Philip K. Dick, Terrence McKenna, and David Bowie all cited the book as an influence.[14]
Scholarly reactions[edit]
Jaynes's hypothesis remains controversial. According to Jaynes, language is a necessary but not sufficient condition for consciousness: language existed thousands of years earlier, but consciousness could not have emerged without language.[15] The idea that language is a necessary component of subjective consciousness and more abstract forms of thinking has gained the support of proponents including Andy Clark, Daniel Dennett, William H. Calvin, Merlin Donald, John Limber, Howard Margolis, Peter Carruthers, and José Luis Bermúdez.[16]
Gary Williams[17] defends the Jaynesian definition of consciousness as a social–linguistic construct learned in childhood, structured in terms of lexical metaphors and narrative practice, against Ned Block's criticism that it is ""ridiculous"" to suppose that consciousness is a cultural construction,[18] while the Dutch philosophy professor Jan Sleutels offers an additional critique of Block.[19]
Moffic[20] questioned why Jaynes' theory was left out of a discussion on auditory hallucinations by Asaad & Shapiro.[21] The authors' published response was: ... Jaynes' hypothesis makes for interesting reading and stimulates much thought in the receptive reader. It does not, however, adequately explain one of the central mysteries of madness: hallucination.
The new evidence for Jaynes' model of auditory hallucinations arising in the right temporal-parietal lobe and being transmitted to the left temporal-parietal lobe that some neuroimaging studies suggest was discussed by various respondents[22][23] For further discussion, see Marcel Kuijsten (2007).[24]
Brian J. McVeigh, a graduate student of Jaynes, maintains that many of the most frequent criticisms of Jaynes' theory are either incorrect or reflect serious misunderstandings of Jaynes' theory, especially Jaynes' more precise definition of consciousness. Jaynes defines consciousness—in the tradition of Locke and Descartes—as ""that which is introspectable"". Jaynes draws a sharp distinction between consciousness (""introspectable mind-space"") and other mental processes such as cognition, learning, sensation, and perception. McVeigh argues that this distinction is frequently not recognized by those offering critiques of Jaynes' theory.[25]
Individual scholars' comments[edit]
Richard Dawkins in The God Delusion (2006) wrote of The Origin of Consciousness in the Breakdown of the Bicameral Mind: ""It is one of those books that is either complete rubbish or a work of consummate genius; Nothing in between! Probably the former, but I'm hedging my bets.""[26]
The philosopher Daniel Dennett suggested that Jaynes may have been wrong about some of his supporting arguments – especially the importance he attached to hallucinations – but that these things are not essential to his main thesis:[27] ""If we are going to use this top-down approach, we are going to have to be bold. We are going to have to be speculative, but there is good and bad speculation, and this is not an unparalleled activity in science. ... Those scientists who have no taste for this sort of speculative enterprise will just have to stay in the trenches and do without it, while the rest of us risk embarrassing mistakes and have a lot of fun."" — Daniel Dennett[28]
Gregory Cochran, a physicist and adjunct professor of anthropology at the University of Utah, wrote: ""Genes affecting personality, reproductive strategies, cognition, are all able to change significantly over few-millennia time scales if the environment favors such change—and this includes the new environments we have made for ourselves, things like new ways of making a living and new social structures. ... There is evidence that such change has occurred. ... On first reading, Breakdown seemed one of the craziest books ever written, but Jaynes may have been on to something.""[29]
Author and historian of science Morris Berman writes: ""[Jaynes's] description of this new consciousness is one of the best I have come across.""[30]
Danish science writer Tor Nørretranders discusses and expands on Jaynes's theory in his 1991 book The User Illusion, dedicating an entire chapter to it.[31]
Iain McGilchrist proposes that Jaynes's hypothesis was the opposite of what happened: ""I believe he [Jaynes] got one important aspect of the story back to front. His contention that the phenomena he describes came about because of a breakdown of the 'bicameral mind' – so that the two hemispheres, previously separate, now merged – is the precise inverse of what happened.""[32] However, Kuijsten maintains that McGilchrist mischaracterized Jaynes's theory.[33]
Criticism[edit]
Epic of Gilgamesh as a counter-example[edit]
As an argument against Jaynes's proposed date of the transition from bicameral mentality to consciousness, some critics have referred to the Epic of Gilgamesh.[citation needed] Early copies of the epic are many centuries older[34] than even the oldest passages of the Old Testament,[35] and yet it describes introspection and other mental processes that, according to Jaynes, were impossible for the bicameral mind.[citation needed]
Jaynes noted that the most complete version of the Gilgamesh epic dates to post-bicameral times (7th century BCE), dismisses these instances of introspection as the result of rewriting and expansion by later conscious scribes, and points to differences between the more recent version of Gilgamesh and surviving fragments of earlier versions: ""The most interesting comparison is in Tablet X.""[13]: 252 His answer, however, does not deal with the generally accepted dating of the ""Standard Version"" of the Gilgamesh epic to the later 2nd millennium BCE, nor does it account for the introspection characteristic of the ""Standard Version"" being thoroughly rooted in the Old Babylonian and Sumerian versions, especially as historians' understanding of the Old Babylonian poem improves.[34][35][36]
World-wide transition[edit]
Jaynes's proposal does not explain how bicameral mentality could have been lost across the entire human species.[citation needed] The indigenous Australian cultural area was nearly completely separated from the rest of the world from 4000 BCE to 1600 CE.[citation needed] It would not have experienced Mesopotamia's stresses to socio-cultural equilibria, and yet it appears today wholly self-conscious and without evidence of historical change.[citation needed]
Homeric epic[edit]
Walter J. Ong noticed that Homeric Iliad is a structurally oral epic poem so that, in his opinion, the very different cultural approach of oral culture is sufficient justification for the apparent different mentalities in the poem. The contention of changes in oral vs written forms of both the Odyssey and Iliad were in fact a main point of Jaynes argument. Jaynes uses these structural changes to expand his thesis and through philology of the Homeric poems.[37]
Similar ideas[edit]
Regarding Homeric psychology[edit]
- Bruno Snell in 1953, thought that in Homeric Greek psychology there was no sense of self in the modern sense.[38] Snell then describes how Greek culture ""self-realized"" the modern ""intellect"".[39]
- Eric Robertson Dodds wrote about how ancient Greek thought may have not included rationality as defined by modern culture. In fact, the Greeks may have known that an individual did things, but the reason they did things were attributed to divine externalities, such as gods or daemons[40]
- Arthur William Hope Adkins, aka A. W. H. Adkins, building on Snell's work, wrote about how ancient Greek civilization developed ego-centered psychology as an adaptation to living in city-states, before which the living in Homeric oikos did not require such integrated thought processes.[41]
Regarding modern psychiatric theory[edit]
- V. S. Ramachandran, in his 2003 book The Emerging Mind, proposes a similar concept, referring to the left cortical hemisphere as an ""apologist"", and the right cortical hemisphere as a ""revolutionary"".[citation needed]
- In his book Neuroreality: A Scientific Religion to Restore Meaning, or How 7 Brain Elements Create 7 Minds and 7 Realities, Bruce E. Morton, formerly of the University of Hawaii, similarly proposed such a concept.[citation needed]
- Psychiatrist Iain McGilchrist reviews scientific research into the role of the brain's hemispheres, and cultural evidence, in his book The Master and His Emissary.[42] Similar to Jaynes, McGilchrist proposes that since the time of Plato the left hemisphere of the brain (the ""emissary"" in the title) has increasingly taken over from the right hemisphere (the ""master""), to our detriment. McGilchrist, while accepting Jayne's intention, felt that Jaynes's hypothesis was ""the precise inverse of what happened"" and that rather than a shift from bicameral mentality there evolved a separation of the hemispheres to bicameral mentality.[42] (See McGilchrist quotation, above.)
- Michael Gazzaniga (heavily cited by Jaynes in his book) pioneered the split-brain experiments which led him to propose a similar theory called the left brain interpreter.[43][44]
- Neuroscientist Michael Persinger, who co-invented the ""God helmet"" in the 1980s, believes that his invention may induce mystical experiences by having the separate right hemisphere consciousness intrude into the awareness of the normally-dominant left hemisphere.[45] Scientific reproductions have shown that the same results could be obtained even if the device was turned off, indicating the participants were likely experiencing placebo.[46]
In popular media[edit]
The concept was mentioned in Westworld
Other resources[edit]
The Julian Jaynes Society was founded by Marcel Kuijsten in 1997, shortly after Jaynes's death.
The society has published a number of books on Julian Jaynes's theory, including:
- Reflections on the Dawn of Consciousness (2007), a collection of essays on consciousness and the bicameral mind theory, with contributors including psychological anthropologist Brian J. McVeigh, psychologists John Limber and Scott Greer, clinical psychologist John Hamilton, philosophers Jan Sleutels and David Stove, and sinologist Michael Carr (see shi ""personator""). The book also contains an extensive biography of Julian Jaynes by historian of psychology William Woodward and June Tower, and a foreword by neuroscientist Michael Persinger.[47]
- The Julian Jaynes Collection (2012), a collection of articles, interviews, and discussion with Julian Jaynes.[48]
- The Minds of the Bible: Speculations on the Cultural Evolution of Human Consciousness (2013) by Rabbi James Cohn.[49]
- Gods, Voices, and the Bicameral Mind (2016), which includes essays on a variety of aspects of Jaynes's theory, including ancient history, language, the development of consciousness in children, and the transition from bicameral mentality to consciousness in ancient Tibet.[50]
- Foreign-language editions of Julian Jaynes's theory in French, German, and Spanish.
The society also maintains a member area, with articles, lectures, and interviews on Jaynes's theory.
Brian J. McVeigh (one of Jaynes' graduate students) expand on Jaynes' theory:
- The Psychology of the Bible: Explaining Divine Voices and Visions (2020) by Brian J. McVeigh [51]
- The 'Other' Psychology of Julian Jaynes: Ancient Languages, Sacred Visions, and Forgotten Mentalities (2018) by Brian J. McVeigh [52]
- How Religion Evolved: Explaining the Living Dead, Talking Idols, and Mesmerizing Monuments (2016) by Brian J. McVeigh [53]
See also[edit]
- Behavioral modernity
- Brain asymmetry
- Divided consciousness
- Dual consciousness
- Exformation
- Lateralization of brain function
- Left brain interpreter
- Mind-body problem
- Mythopoeic thought
- Neurotheology
- Philosophy of mind
- Society of Mind
- Split-brain
- System 1 and System 2
- Theory of mind
- Tutelary deity
Notes[edit]
References[edit]
- ^ ""The Bicameral Mind with Joe McCormick"". Stuff They Don't Want You to Know. 2017-11-24. Retrieved 2017-11-27.
- ^ Erkwoh, R. (2002). ""Command Hallucinations: Who Obeys and Who Resists When?"". Psychopathology. 35 (5): 272–279. doi:10.1159/000067065. PMID 12457018. S2CID 6768239.
- ^ a b c d e f g Kuijsten, Marcel (1998–2006). ""Summary of Evidence"". Retrieved 2006-05-22.
- ^ Stove, D.C. (April 1989). ""The Oracles & Their Cessation"". Encounter. 72 (4): 30–38. ISSN 0013-7073.
- ^ Smith, Daniel (2007). Muses, Madmen, and Prophets: Rethinking the history, science, and meaning of auditory hallucination. ISBN 978-1-59420-110-3.
- ^ Jaynes, Julian (2000) [1976]. The origin of consciousness in the breakdown of the bicameral mind (PDF). Houghton Mifflin. p. 221. ISBN 0-618-05707-2.
- ^ ""Zechariah"". biblegateway.com. 13: 2-3.
- ^ Keen, Sam (November 1977). ""Julian Jaynes: Portrait of the Psychologist as a Maverick Theorizer"". Psychology Today. Vol. 11. pp. 66–67.
- ^ Keen, Sam (November 1977). ""The Lost Voices of the Gods (Interview with Julian Jaynes)"". Psychology Today. Vol. 11. pp. 58–60.
- ^ Jaynes, Julian (1976). The Origin of Consciousness in the Breakdown of the Bicameral Mind. ISBN 0-395-20729-0.
- ^ ""Julian Jaynes's The Origin of Consciousness in the Breakdown of the Bicameral Mind"". Julian Jaynes Society. Retrieved 17 December 2020.
- ^ Jaynes, Julian (2000) [1993]. The Origin of Consciousness in the Breakdown of the Bicameral Mind. Houghton Mifflin. ISBN 0-14-017491-5.
- ^ a b Jaynes, Julian (2000) [1976]. The Origin of Consciousness in the Breakdown of the Bicameral Mind (PDF). Houghton Mifflin. ISBN 0-618-05707-2.
- ^ ""Voice-hearing and the bicameral mind"". Philosophy for Life. Archived from the original on 2018-01-26. Retrieved 2018-01-25.
- ^ Jaynes, Julian (2000) [1976]. The Origin of Consciousness in the Breakdown of the Bicameral Mind (PDF). Houghton Mifflin. p. 66. ISBN 0-618-05707-2.
- ^ Kuijsten, Marcel (2007). Reflections on the Dawn of Consciousness: Julian Jaynes's bicameral mind theory revisited. Julian Jaynes Society. pp. 96–100, 169–202. ISBN 978-0-9790744-0-0.
- ^ Williams, Gary (2010). ""What is it like to be nonconscious? A defense of Julian Jaynes"". Phenomenology and the Cognitive Sciences. 10 (2): 217–239. doi:10.1007/s11097-010-9181-z. S2CID 144561661.
- ^ Block, N (1981). ""Review of Julian Jaynes's Origins of Consciousness in the Breakdown of the Bicameral Mind"". Cognition and Brain Theory. 4: 81–83.
- ^ Sleutels, Jan (2006). ""Greek Zombies"". Philosophical Psychology. 19 (2): 177–197. doi:10.1080/09515080500462412. S2CID 220329899.
- ^ Moffic, H. Steven (May 1987). ""What about the bicameral mind?"". American Journal of Psychiatry. 144 (5): 696a–696. doi:10.1176/ajp.144.5.696a. PMID 3578592.
- ^ Asaad G, Shapiro B (Sep 1986). ""Hallucinations: Theoretical and clinical overview"". American Journal of Psychiatry. 143 (9): 1088–1097. doi:10.1176/ajp.143.9.1088. PMID 2875662.
- ^ Olin, Robert (1999). ""Auditory hallucinations and the bicameral mind"". Lancet. 354 (9173): 166. doi:10.1016/S0140-6736(05)75304-6. PMID 10408523. S2CID 28869281.
- ^ Sher, Leo (May 2000). ""Neuroimaging, auditory hallucinations, and the bicameral mind"". Journal of Psychiatry and Neuroscience. 25 (3): 239–240. PMC 1407719. PMID 10863883.
- ^ Kuijsten, Marcel (2007). Reflections on the Dawn of Consciousness: Julian Jaynes' bicameral mind theory revisited. Julian Jaynes Society. pp. 116–120. ISBN 978-0-9790744-0-0.
- ^ McVeigh, Brian (2007). ""Elephants in the Psychology Department: Overcoming intellectual barriers to understanding Julian Jaynes' theory"". Julian Jaynes Society.
- ^ Dawkins, Richard (2006). The God Delusion. Houghton Mifflin. pp. 377–378. ISBN 1-4303-1230-0.
- ^ Dennett, Daniel (1986). ""Julian Jaynes's software archeology"". Canadian Psychology. 27 (2): 149–154. doi:10.1037/h0080051.
- ^ Dennett, Daniel (1998). ""Julian Jaynes's software archeology"". Brainchildren: Essays on Designing Minds.[page needed]
- ^ ""What is your dangerous idea?"". Edge Foundation. 2006. Archived from the original on 2008-03-06. Retrieved 2008-02-19.
- ^ Berman, Morris (2000). Wandering God: A study in nomadic spirituality. ISBN 0-7914-4442-2.
- ^ Nørretranders, Tor (1991). User Illusion: Cutting consciousness down to size. ISBN 0-7139-9182-8.
- ^ McGilchrist, Iain. The Master and His Emissary. p. 262.
- ^ Kuijsten, Marcel. ""Critiques & Responses to Julian Jaynes's Theory Part 1"".
- ^ a b Dalley, Stephanie, ed. (2008). Myths from Mesopotamia: Creation, the Flood, Gilgamesh, and Others. Oxford University Press. pp. 41–42, 45. ISBN 978-0-19-953836-2 – via archive.org.
- ^ a b Mitchell, T. C. (1988). The Bible in the British Museum. Cambridge University Press. p. 70. ISBN 9780521368674.
- ^ For a through overview of the current understanding of the Gilgamesh Epic's textual history, see:
George, A. R. (2003). The Babylonian Gilgamesh Epic: Introduction, critical edition, and cuneiform texts. Oxford University Press. ISBN 978-0-19-927841-1. Retrieved 8 November 2012 – via Google Books.
- ^ Walter J. Ong, Orality and Literacy (1982)
- ^ Snell, B. (1982). Die Entdeckung des Geistes The discovery of the mind: The Greek origins of European thought, on archive.org); (T.G. Rosenmeyer, Trans.). Harper. (Original work published 1953)
- ^ Snell, B. (1982). Die Entdeckung des Geistes The discovery of the mind: The Greek origins of European thought, on archive.org); (T.G. Rosenmeyer, Trans.). Harper. (Original work published 1953), p. vii
- ^ Dodds, E. R. (1951). The Greeks and the irrational (Vol. 25). Univ of California Press., pp. 11+
- ^ Adkins, A. W. H. (1970). From the many to the one. Cornell University Press. p. 236, see also pp.275
- ^ a b McGilchrist, Iain (2009). The Master and his Emissary. New Haven, CT: Yale University Press. ISBN 978-0-300-14878-7.
- ^ Gazzaniga, M. (1998) The Mind's Past, Basic Books
- ^ Gazzaniga, M. (1995) Consciousness and the cerebral hemispheres. In The Cognitive Neurosciences (Gazzaniga, M., ed), pp. 1391–1400, MIT Press
- ^ Persinger, M.A. (1993). ""Vectorial cerebral hemisphericity as differential sources for the sensed presence, mystical experiences and religious conversions"". Perceptual and Motor Skills. 76 (3 Part 1): 915–30. doi:10.2466/pms.1993.76.3.915. PMID 8321608. S2CID 38474305.
- ^ Larsson, M., Larhammarb, D., Fredrikson, M., and Granqvist, P. (2005). ""Reply to M.A. Persinger and S. A. Koren's response to Granqvist et al. ""Sensed presence and mystical experiences are predicted by suggestibility, not by the application of transcranial weak magnetic fields"""". Neuroscience Letters. 380 (3): 348–350. doi:10.1016/j.neulet.2005.03.059. S2CID 54348640.
{{cite journal}}: CS1 maint: multiple names: authors list (link)
- ^ Kuijsten, Marcel (2007). Reflections on the Dawn of Consciousness: Julian Jaynes's Bicameral Mind Theory Revisited. Julian Jaynes Society. ISBN 978-0979074417.
- ^ Kuijsten, Marcel (2012). The Julian Jaynes Collection. Julian Jaynes Society. ISBN 978-0979074424.
- ^ Cohn, James (2013). The Minds of the Bible: Speculations on the Cultural Evolution of Human Consciousness. Julian Jaynes Society. ASIN B00B5LWV82.
- ^ Kuijsten, Marcel (2016). Gods, Voices, and the Bicameral Mind: The Theories of Julian Jaynes. Julian Jaynes Society. ISBN 978-0979074431.
- ^ McVeigh, Brian (2020). The Psychology of the Bible: Explaining Divine Voices and Visions. Imprint Academic. ISBN 978-1788360371.
- ^ McVeigh, Brian (2018). The 'Other' Psychology of Julian Jaynes: Ancient Languages, Sacred Visions, and Forgotten Mentalities. Imprint Academic. ISBN 978-1845409517.
- ^ McVeigh, Brian (2016). How Religion Evolved: Explaining the Living Dead, Talking Idols, and Mesmerizing Monuments. Routledge. ISBN 978-1412862868.
External links[edit]
- ""Julian Jaynes Society website"".
- Weijers, Erik. ""The Origin of consciousness: Summary, selected quotes and review"".
- Cavanna AE, Trimble M, Cinti F, Monaco F. ""The ""bicameral mind"" 30 years on: a critical reappraisal of Julian Jaynes' hypothesis"". Archived from the original on 2019-07-16. Retrieved 2014-06-11.
{{cite journal}}: Cite journal requires
|journal=(help)
- ""The Origin of Consciousness in the Breakdown of the Bicameral Mind"". Good Reads website.",8
258,"Apple’s Next Big Thing: A Business Model Change
by Jean-Louis Gassée
Lacking a magical new product of iPhone proportions, the company, its focus, and its culture are bound to change.
The past three Monday Notes (here, here and here) looked at possible candidates for Apple’s NBT (Next Big Thing), a product category that could launch an iPhone-like growth wave now that the smartphone market approaches saturation. For perspective, 2021 iPhone revenue was $192B, more than half of Apple’s total revenue of $366B, this from almost nothing ($123M) in 2007. And this doesn’t count App Store revenue, mostly for iPhone apps. The numbers aren’t directly disclosed but reliable sources estimate tens of billions of dollars in net revenue, the riches Apple gets to keep after paying developers.
We’ve looked at three fields of opportunity: The unacknowledged Apple Car (the “Titan” project), Augmented Reality (AR) devices, and forays into the healthcare market, none of which is a feasible candidate. The car project looks unrealistically adventurous; AR devices, while more likely, probably wouldn’t enjoy the everywhere-all-the-time use that is the mark of smartphones; and, while the healthcare field is huge and open to more effective ways to spend our money, doing-well-while-doing-good devices, such as hearing aids, don’t offer iPhone-like potential. I hope I’m wrong on one or more of these opportunities, but I just don’t see a huge new Apple hardware growth wave in our future.
I was thinking about all of this while watching Tim Cook and his team of presenters introduce new Apple Watches, AirPod Pros, and improved iPhones during Apple’s latest unveiling event. “New iPhones! New Apple Watches! New AirPods!”, exclaims Greg Kumparak of TechCrunch. I assume Mr. Kumparak’s breathlessness is somewhat facetious. There was an interesting Satellite Communication feature, currently for emergency use only, but otherwise I had a hard time summoning his level of excitement.
Certainly, Apple continues to move its products forward, but with little hope for another breakthrough of iPhone proportions. One can’t call Apple hopeless — too many critics have had to eat their “Apple is Doomed” proclamations — but without a Next Big Thing in its future, Apple could be viewed as living in incremental mode. Perhaps it has reached a stage where it will survive — and no doubt thrive — by simply improving existing devices, relying on its tentacular array of services to bring in new customers and fortify the loyalty of its faithful.
This led me to reconsider my interpretation of Apple’s business model and the way the company thinks of itself.
In a 2021 MN, I criticized Apple management for making vague identity statements. I thought that the “Enriching Lives” credo, while mellifluent, could mean anything and thus fails to be a cynosure, a North Star for company employees.
I suggested a simpler, sharper statement: Apple makes personal computers, small, medium, and large. Everything else Apple does has but one raison d’être: They push up the volumes and margins of the company’s main hardware products. For example, App Stores exist to make Watches and iPhones and Mac Pros more useful, more pleasant, thus improving revenue and profit. (I also looked at Microsoft’s statement of purpose, “Our mission is to empower every person and every organization on the planet to achieve more,” and offered a sharper redefinition: “We create business software for individuals and organizations.”)
It’s only a year later, but I’m already changing my tune. Instead of a model that casts personal computers as the star with everything else relegated to a supporting role, I see Apple’s money pump running on a virtuous circle of Devices and Services that work together to, ahem, enrich people’s lives.
In this model, Apple’s most fruitful growth will come from an ever-expanding array of Services: banking, more sports streaming, and, yes, advertising, pegged at only $4B in 2021 but supposed to grow to $10B or more in the next couple of years, and more.
(“Ads?” you may rightly ask, “What about the iAds failure? Apple’s walled garden is a non-starter for ads.” Yes, iAds was a failure, but that was more than a decade ago when Steve Jobs hoped to reach 50% of the mobile ad market. The company has changed since then. By promoting its privacy protection and anti-tracking features, Apple has made serious inroads into an advertising market that has been dominated by social networking sites, so much so that Zuckerberg and others complain that Apple is hurting their bottom line. If Apple continues to grow its ad business, accusation of hypocrisy will certainly follow. Food for a future Monday Note.)
Apple has long recognized that Services has serious revenue potential. In the call that traditionally follows Apple’s quarterly earnings release, Tim Cook and CFO Luca Maestri have repeatedly emphasized that the Services business is both a stabilizer and a growth engine, reaching almost 20% of total revenue in the company’s most recent quarter (ending June 2022), with margins in the 60% range.
My feeling is that Cook and his team are way ahead of us — or me, anyway. They’ve known for a while that Apple has entered a different era. With no Next Big Thing on the horizon — with Devices in a safe-but-slow incremental upward incline — the company has been compelled to move into conquest mode with its Services. This forced change in priorities has consequences, the compass needle points in a different direction. The reward system, people hired, career opportunities, “How We Do Things Here” culture…everything changes.
As an example, the introduction of an “Apple Bank” or an “Apple Search Engine” could yield the company more glory — and profit — than would a new-and-improved iDevice running on the latest, fastest, coolest Apple Silicon chip. Yes, a better iPhone would be cool, but the market is cooling…
It pains this aging geek to think such thoughts, but I can’t help but assume that Apple will evolve into a different sort of company. Nonetheless, I still want to see an Apple Car and see the company’s still working on that bet as a potential head against incrementalism.
jlg@gassee.com or @gassee",1
259,"This Nearly Lost Ancient Grain Tradition Could Be the Future of Farming
A past global staple you’ve never heard of, maslins are poised for a comeback.
When Zemede Asfaw was growing up on a farm in eastern Ethiopia, he soaked up plant lore and other traditional knowledge the way a tree takes in sunlight and converts it to energy. “I knew the crops, and the wild plants, and the fruits and other things,” says Zemede, who goes by his given name. The practical methods he learned covered every aspect of farming: Instead of stone walls or wire fences, plant field edges with darker crops, so the bold colors of red sorghum, for example, create a clear border between the family’s plot and that of a neighbor. Leave a few wild olive or acacia trees in the fields to harvest sustainably, over time, for firewood, animal fodder, or building materials. And instead of sowing the seeds of a single grain in orderly rows, spread a mix of grains all over the field, “mimicking nature so crops have random distribution patterns, as in natural forests,” he says. Once harvested, these grain mixtures could be turned into many things: nutritious bread, a kind of roasted-grain trail mix called kolo, beer, and the potent clear spirit known as areki.
Now an ethnobotanist at Addis Ababa University, Zemede conducts field research in northern Ethiopia. The dominant grains grown there are different than in the region of his youth—his family grew sorghum and maize, while the northerners prefer barley and wheat, better suited to their mountainous highlands—but the principle is the same: “We’ll plant the things that go together and are compatible with each other,” Zemede says. “Our farmers are good at mirroring nature.”
Ethiopia is one of the few places in the world where farmers still grow maslins, the general term for different varieties and species of grain that are sown in the same field, or intercropped. Maslins sustained humans for millennia, possibly predating the rise of agriculture more than 10,000 years ago. These grain mixtures tend to be more resilient to pests and drought, and to lend more complex flavors to breads, beer, and booze.
Worldwide, maslins fell out of favor long ago, replaced nearly everywhere by sprawling, single-grain monoculture—but a small and passionate group of scientists, including Zemede, is hoping to change that. A paper published today in Agronomy for Sustainable Development makes the case for maslins to be revived by farmers around the world, for tastier bread, healthier crops, and more sustainable agriculture. The question is, why is it taking so long?
“We call it the Masluminati, a global conspiracy that no one is talking about,” jokes Alex McAlvay, lead author of the new paper and a botanist at the New York Botanical Garden’s Institute of Economic Botany. He’s kidding, of course, but while farmers and botanists the world over are familiar with companion planting and agroforestry (such as growing coffee in the shade of other trees), maslins, says McAlvay, have “flown under the radar for some reason.” He only learned of them when visiting Ethiopia on an unrelated project; overhearing farmers talk about planting teff, sorghum, and other grains together piqued his curiosity and, says McAlvay, “I went down the rabbit hole.”
The fact that maslins are grown today only in Ethiopia and pockets of Georgia, Eritrea, and a handful of other countries belies how widespread they once were. There is solid archaeological evidence that growing maslins goes back at least 3,000 years, and possibly much earlier. Wild wheats such as einkorn grow naturally beside wild varieties of oats, barley, and rye grasses, and may have been foraged before the advent of agriculture. But finding the first maslins is particularly tricky.
“Maslins are difficult to detect,” says Claire Malleson, an archaeobotanist at the American University of Beirut. Malleson was not involved in the new paper, but has studied intercropping in ancient Egypt. To find evidence of early maslins, Malleson and her peers sift through millennia-old middens—essentially garbage dumps—and whatever was left behind in hearths and granaries, where different grains may have been mixed together long after harvest, making it almost impossible to piece together how the crops were actually grown.
“I think they were probably used all over the place, either specifically or because that’s just how things grow,” she says. “Obviously now in farming it’s all very carefully harvested, but in the past it was all scattered everywhere.”
While extensive archaeological documentation of maslins may be lacking, echoes of their global prevalence can be found in language. Nearly every farming region on the planet had its own lexicon for growing mixed grains, from weedy, almost indestructible ryes to millets, wheats, and barleys.
In Medieval England, farmers grew a mix of oats and barley that they called dredge, or dredge corn, to feed their livestock. In France, peasants ground the traditional maslin of wheat and rye into flour for pain de méteil, or bread of mixed grains, now considered a gourmet loaf. In many places, maslins were such a part of life that the local word for them became shorthand for anything that was a mixture. In Ukraine and neighboring countries, the historic word for maslins—surjik or surzhyk—now means any local dialect that mixes in Russian, Moldovan, or other surrounding languages. In Turkish, mahlut, once the word for mixed grains, now means impure, a hint about what led to the downfall of maslins.
Frits Heinrich, a food historian and archaeobotanist at the Vrije Universiteit Brussel, says that starting in the early 18th century—and accelerating from the 19th century onward—a combination of technological innovations in crop production and processing, and the rise of scientific agriculture, including improved breeding, shoved maslins aside. The food industry, increasingly mechanized, preferred a uniform grain that would produce a uniform product, whether it was wheat for your bread or barley for your beer. Monocultures were both easier to harvest and process mechanically and less likely to vary in taste or how they perfomed. “Maslins, with the variability of their characteristics, were deemed less suitable,” said Heinrich via email.
The decline of maslins only gathered momentum from there. Twentieth-century innovations, such as the widespread availability of artificial nitrogen for fertilizer, led to exponential growth in single-grain crop yields. And so most of the world abandoned maslins.
Today, Ethiopian farmers are feeling the pressure to grow modern monoculture crops, thanks in part to a national push to become an agricultural powerhouse. “If you export grains, you want them to be uniform,” says McAlvay. “The global market wants a certain type of wheat for their Wonder Bread. A mixture of three varieties of wheat and four varieties of barley with some other things thrown in really doesn’t make the cut.”
Tesfanesh Feseha, a master’s student in botany who served as a field translator during McAlvay’s interviews with more than 100 farmers, says that, with the national embrace of monocultures, new farmers aren’t learning the art of cultivating grain mixtures. “Young farmers didn’t even know the mixtures we were looking for,” she says.
Zemede, who collaborates with McAlvay but was not directly involved in the new paper, remains optimistic. “[The push for] modernization is strong. It comes with technology and attractive things…but it could be temporary,” he says. From a farmer’s perspective, he understands the appeal of a lucrative offer to grow a specific grain, but believes that “the scientific community should offer better.”
To that end, through his research and countless conversations with farmers, Zemede is promoting the maslin tradition in his homeland. Together with McAlvay, and like-minded colleagues in Georgia and small, experimental farms in Poland, Finland, and elsewhere, he hopes to inspire wider appreciation of maslins, from the people sowing the fields to the urbanites purchasing an artisanal loaf of mixed-grain bread.
A maslin renaissance may be particularly helpful now, as farmers around the world struggle with soils degraded by modern monoculture, a growing population, and a changing climate.
“Small grains are supposed to be hit really hard by climate change,” says McAlvay. Maslins, he adds, have “all kinds of advantages,” including a more reliable yield, a more complete nutritional profile, and the ability to grow in marginal soils and to survive drought. The grain mixes also appear to have natural resistance to pests, from insects to fungal diseases. While a pest adapted to attack one species of grain will have a field day, no pun intended, when set loose in a monoculture crop, it won’t be able to jump from plant to plant if the individual it attacks is surrounded by other kinds of grain, McAlvay explains.
The new paper from his team, focusing on multiple sites in Ethiopia, is the first comprehensive case study of growing maslins in the modern era—and other researchers are enthusiastic about it.
“I think this is an excellent paper,” said Heinrich, who was not involved in the research. He praises it for both pulling together previous research on maslins and showing their potential for meeting the challenge of feeding billions on a warming, less stable planet.
Malleson is similarly effusive. “I love this paper,” she says.
“This is about bringing power back to the farmers who understand the land and the farming and how to manage things,” says Malleson, who has family members in farming and feels close to the topic. “It brings the power back down to the ground level, literally.”
The new paper is just a first step toward nudging maslins back onto the world stage, and McAlvay and colleagues are already planning additional studies. Meanwhile, Zemede continues to encourage Ethiopian farmers to preserve the maslin tradition he learned as a boy, and hopes more people globally embrace these grain mixtures as our ancestors once did.
“In biology we say diversity must survive,” says Zemede. “If diversity is lost, then we will be lost.”
Gastro Obscura covers the world’s most wondrous food and drink.
Sign up for our email, delivered twice a week.
Follow us on Twitter to get the latest on the world's hidden wonders.
Like us on Facebook to get the latest on the world's hidden wonders.Follow us on Twitter Like us on Facebook",1
260,"San Francisco's police department is getting closer to being able to use robots for lethal force against criminal suspects after the city's Board of Supervisors yesterday voted 8-3 to approve an ordinance on the matter.
What's happening: The legislation, if enacted, would allow police to use remote-controlled robots for deadly force ""when risk of loss of life to members of the public or officers is imminent and outweighs any other force option available,"" per the draft policy.
- During the more than two-hour discussion on the topic at the Board of Supervisors meeting, SFPD assistant chief David Lazar evoked the mass shooting in Las Vegas in October 2017 as an example of a potential use case for remote-controlled robots using lethal force.
- The lengthy discussion led to two amendments that clarified police must try or consider alternative force methods before using robots for lethal force, and that only the police chief, assistant chief of operations or deputy chief of special operations can authorize the use of robots as a deadly force option.
- Supervisors Dean Preston, Hillary Ronen, and Shamann Walton were the three dissenting votes.
- The ordinance also defines how SFPD is allowed to use assault rifles, machine guns and other military-style weapons.
Context: As part of a state bill signed into law last year, the Board of Supervisors has the authority to reject or accept rules annually around how SFPD can use military-style weapons.
- SFPD currently has 12 human-controlled robots for purposes such as gaining situational awareness, diffusing potential bombs or helping in hostage negotiations.
- The Board of Supervisors' Rules Committee, chaired by Aaron Peskin, recommended the ordinance for approval earlier this month.
- Yes, but: He told Axios, ""This should not be construed as a green light to have robots wantonly kill people,"" conceding they “could be misused.”
What they're saying: The SFPD says it does not own or operate ""robots outfitted with lethal force options,"" and doesn't have any plans to augment with any ""firearm,"" Allison Maxie, a spokesperson with the SFPD, told Axios via email.
- Reality check: If the ordinance is fully approved, the SFPD would be authorized to equip existing robots with explosives ""to breach fortified structures containing violent, armed, or dangerous subjects or used to contact, incapacitate, or disorient"" a suspect who poses ""a risk of loss of life to law enforcement or other first responders,"" Maxie said.
- The SFPD considers explosives ""an intermediate force option,"" but acknowledges they ""could potentially cause injury or be fatal,"" she said.
The other side: Outside of the public safety questions, there are racial and ethical implications for these new policing tools.
- Yoel Haile, director of the criminal justice program at the American Civil Liberties Union of Northern California, does not think police departments should ""have killer robots"" in part because police kill Black people at more than twice the rate of white people, per a Washington Post analysis.
- ""Remote-controlled killing machines will not make San Francisco safer,"" Haile said. ""This is a terrible idea.""
Preston, in a statement to Axios, said, ""It is shocking that just two years after the nation collectively recognized that police were using unjustified deadly force against people, we are having a conversation about letting SFPD adopt a policy that would allow them to use robots to kill.""
- Ronen said at yesterday's meeting that using robots for lethal force ""creates this false distance that makes killing the individual easier.""
By the numbers: SFPD's budget grew to about $714 million for fiscal year 2023.
- The department spent more than $10.5 million to acquire the robots and expects to spend about $1,445 per year to maintain the robots, per the draft policy.
- SFPD, however, may spend up to $10 million on the replacement of equipment without the approval of the Board of Supervisors.
The big picture: The idea of weaponized robots is controversial and sparks images of a more dystopian society.
- In October, robot maker Boston Dynamics signed an open letter alongside other firms arguing the weaponization of robots ""raises new risks of harm and serious ethical issues.""
- One ethical issue: who is at fault if a robot accidentally kills someone?
- The Electronic Frontier Foundation argues the weaponization of robots would push society toward ""letting autonomous artificial intelligence determine whether or not to pull the trigger.""
Zoom in: This is the second controversial ordinance SFPD has put before the Board of Supervisors for consideration in recent months.
- The first, passed in September, allowed police to access live surveillance technology from private parties.
- Haile said the passage of that ordinance ""encouraged [police] to come back with more and more extreme asks.""
Zoom out: Oakland's police department asked Oakland's city council to allow the department to use robots for lethal force.
- OPD, however, last month decided not to seek approval for that use case, Mission Local reports.
What's next: The Board of Supervisor still must give the legislation final approval, but that process is typically perfunctory.
- Mayor London Breed, a sponsor of the measure, would then have to sign off within 10 days.
More San Francisco stories
No stories could be found
Get a free daily digest of the most important news in your backyard with Axios San Francisco.",1
261,"The Rise of the Digitally-Native Job
Why the Most Valuable Companies Are 'Ecosystem' Companies
This is a weekly newsletter about how tech and culture intersect. To receive Digital Native in your inbox each week, subscribe here:
The Rise of the Digitally-Native Job
Walmart is the largest private employer in the United States, and the second-largest overall employer after the federal government. Globally, Walmart employs 2.3 million people; in the U.S., it employs 1.6 million (about 1% of America’s total workforce).
Amazon is catching up quickly, with 1.1 million U.S. employees and 1.6 million global employees—already double the 798,000 people employed by Amazon in 2018. (Walmart’s workforce has actually contracted slightly in that time period.) Over the next few years, we’ll likely see Amazon surpass Walmart as America’s largest private employer.
What’s unique about Amazon is that the company provides far more people with a livelihood than the employees captured in its own payroll expense. About 9.5 million sellers earn income on Amazon’s platform.
This gets at a unique property shared by many of the most successful technology companies: they create ecosystems that employ more people than they do themselves. The ecosystem effect Amazon created doesn’t apply to Walmart in the same way—yes, Walmart gives brands shelf space (thereby creating jobs for their makers), but it does so in a much less self-serve and scalable way. I often think back to Chris Anderson’s 2004 piece in WIRED, The Long Tail:
As egalitarian as Walmart may seem, it is actually extraordinarily elitist. Walmart must sell at least 100,000 copies of a CD to cover its retail overhead and make a sufficient profit; less than 1 percent of CDs do that kind of volume. What about the 60,000 people who would like to buy the latest Fountains of Wayne or Crystal Method album, or any other non-mainstream fare? They have to go somewhere else.
The same concept applies to sellers—what about the people who might not move enough product to warrant shelf space in a Walmart? They, too, have to go somewhere else. Many niche sellers have existing latent demand, and need the internet to unlock that demand: in 2000, the average Barnes & Noble carried 130,000 titles, and yet more than half of Amazon’s book sales at the time came from outside its top 130,000 titles.
The ecosystem question is one I often ask myself as an investor in startups: if this company is successful—if it really works—can it become a platform for massive job creation?
I’m fascinated by job titles that are digitally-native—that wouldn’t exist without the internet or, often, without a specific underlying tech company. Three examples from the Index portfolio:
Discord Community Manager—there are 19 million weekly active servers on Discord, and many employ managers to run the show
Roblox Developer—Roblox has 300,000+ developers building Roblox experiences
Etsy Seller—Etsy has 7.5 million active sellers from 234 countries
These job titles didn’t exist 10 or 20 years ago. To make the concept of digitally-native work more tangible, let’s revisit three examples of specific people I’ve written about in the past:
Miss Excel
Miss Excel—real name: Kat Norton—has over a million followers on TikTok and Instagram, where she posts content about (you guessed it) Excel. But Norton’s social channels really act as a funnel for her Excel training courses, sold here. She earns up to six figures a day selling her courses, all as a one-woman business.
Miss Excel has two digitally-native job titles—TikToker and “Excel online course creator”—that didn’t exist a few years ago. And her income is largely passive: she travels the world, working just a few hours a week to make content, while her evergreen Excel course flies off the proverbial shelves.
KARRA
The artist Kara Madden (who goes by KARRA) moved to LA to try to make it as a singer. But after a few years, she found herself managing a Jersey Mike’s and making under $10K from music, mostly from singing on My Little Pony commercials. Then she uploaded a pack of vocal hooks to Splice, a site that lets artists sell royalty-free sounds as component parts—atomic units that can be assembled by other creators into fresh works. KARRA has now made over $300K on Splice.
Splice costs $9.99 a month and gives users access to 2 million sounds, all royalty-free. It has 4 million users. KARRA’s vocal pack included wordless melodies and hooks like “don't wanna wake up” and “loving you.” David Guetta even used her samples in a song. In aggregate, Splice has paid out $40M+ to artists.
One board member says: “The music industry of 2017 wouldn’t have found KARRA in a million years. They weren’t looking in the right places for artists with superstar potential.” And in KARRA’s words: “Splice opens the doors for literally anyone to become a producer.” “Splice artist” is another job title that didn’t exist a few years ago, but that can now support a person’s livelihood.
Bella McFadden
Bella McFadden is a professional reseller on Depop, a secondhand clothing marketplace popular among Gen Zs (90% of Depop users are under 26). In 2020, McFadden became the first person to make over $1 million selling on Depop. She’s sold 64,936 items (!) through her Depop store, which has 380,000 followers.
McFadden spends her days sourcing products from outlets and cataloguing them based on their aesthetic, studying 90s fashion magazines for inspiration. She then photographs and lists the items, saying, “I start shooting at about 8 in the morning, and don’t finish till 7 or 8 at night.” Most of her products sell for between $15 and $25, so she needs to sell volume. She also charges $200 for personal styling, designing and curating an entire outfit based on her client’s aesthetic.
There are now entire armies of professional resellers on Depop, Vinted, Poshmark, and Facebook Marketplace.
Emergent Ecosystems
One of my favorite quotes about the internet—and one I’ve shared often in Digital Native—comes from Patreon’s Jack Conte: “You may have grown up in a small town, where you were the only person out of 1,000 people with a specific interest. But there are 4.5 billion people on the internet, meaning that there are 4.5 million people who share your interest. Online, no niche is too niche.” The same idea can be adapted to finding work: if only 1 in 1,000 people is interested in what you’re buying, that’s a customer base in the millions. If only 1 in 1,000,000 people is interested, that’s still a customer base of 4,000+—depending on your average selling price, potentially enough to sustain a living.
Many online marketplaces, social media companies, and content platforms fit into the “ecosystem” category. These are often the largest businesses, and the ones with the strongest network effects. But successful software companies can also facilitate job creation. Take Squarespace. Squarespace now offers Squarespace Marketplace, where you can browse and hire web designers.
Here’s the first profile surfaced to me—Bohdan, a Ukrainian developer offering a variety of services. Bohdan may make his entire living on Squarespace: if he’s hired to build one site each week, that’s $50,000+ in annual income.
These examples—from Roblox to TikTok, Etsy to Squarespace—are companies that have been around for years. But there are also newer ecosystem startups emerging.
Some of these startups are building on other platforms. There are many companies, for instance, now building on WhatsApp. This is particularly true in Latin America, where WhatsApp is society’s connective tissue. Hubla is a Sao Paulo-based startup that lets people sell access to a course or community through a WhatsApp group:
Then there are other recent startups that themselves are becoming ecosystems for job creation. To look at three examples:
Office Hours
Office Hours is an expert network platform. Many people—particularly bankers, consultants, or investors—may be familiar with traditional expert networks like GLG and Alphasights. Office Hours extends that concept to the long tail, tapping into latent knowledge. Here, under the Product Management category, I can book time with leading product and engineering thinkers:
If you’re a doctor, you have incredibly specialized knowledge, but your income is largely capped. You could use Office Hours in your free time to earn more.
Many experts likely use Office Hours for supplemental income, but the site could theoretically become the single platform underpinning a career. Anyone with deep domain expertise—which is nearly everyone, on some subject—can become a full-time expert and monetize that knowledge.
Metafy
Metafy is a place where you can book 1-on-1 coaching sessions with the world’s best gamers. In this screenshot, you can see that you can book DarkSlayer, a Fortnite expert, starting at $15, or StripedSweater, a League of Legends pro, starting at $32:
The gaming industry is set to be worth over $400 billion by 2028, and there are 3 billion gamers globally—nearly 1 in 2 people on the planet. Yet before Metafy, there wasn’t a systematic way to learn from the best. “Metafy Coach” is now a viable career opportunity.
Whatnot
Whatnot has exploded over the past few years as a livestream commerce destination, first in collectibles (think Pokemon and Funko Pops), and now across categories. I’ve used the example before of Li Jiaqui, known in China as the “Lipstick King.” In a typical livestream, Li will show off a lipstick for his viewers. Viewers ask questions in real-time—“How vibrant is the color?” “Does the lipstick also moisturize chapped lips?”—and Li answers their questions live. Then, he’ll offer a discount to create urgency to buy—“Buy now and get 15% off this lipstick.”
Li once tried on 380 lipsticks during a 7-hour livestream, and then sold 15,000 lipsticks in just five minutes (!). Last October, he sold $1.7 billion worth of product during a single 12-hour livestream; 250 million people tuned in.
Not everyone is the Lipstick King, but livestream selling can still be quite lucrative. In its pitch to prospective sellers on its site, Whatnot points to an average of $6,000 a month in earnings:
The West still has a ways to go to catch China, where being a livestream seller has become been a sought-after career and where livestream commerce is now a $550B industry, +60% year-over-year. But platforms like Whatnot expand the opportunity to be a professional seller beyond the QVC screen and into the long tail.
Final Thoughts
The internet has led to a Cambrian explosion in entrepreneurship—and a complete rethinking of how we earn a living. The rules are still being rewritten.
My friend—who has a separate full-time job at a startup—recently created Resycharm on the side. Resycharm is a bot that helps you snag a coveted restaurant reservation. If you’re worried about tables at Carbone filling up, Resycharm has you covered. You only get charged for successful reservations, $20 per seat across all restaurants.
It’s a brilliant product, and one with (based anecdotally on my friends, at least) a lot of pent-up market demand. But it also speaks to new ways that people are earning income online. My friend could, theoretically, build that bot and then sit on a beach somewhere, earning a nice living off of FOMO-driven college grads clamoring to get into Don Angie.
There’s an entire community called IndieHackers where people share how they built their online businesses and where they strategize ways to grow. It’s a community for people who have internet-native jobs that they’ve built for themselves.
Many of the generational businesses in the 2020s and 2030s will expand the same concept, allowing millions of people to build careers on top of their platforms. I’m curious what other “ecosystems” are forming today—if I missed one here, or if there are new entrants not on my radar, I’d love to learn about them.
Sources & Additional Reading
Thank you to Chris Paik, Jordan Cooper, Ian Spear, and Georgia Stevenson for being thought partners on many of these topics
The story of Miss Excel in The Verge
Splice & KARRA in Billboard
Related Digital Native Pieces
Thanks for reading! Subscribe here to receive Digital Native in your inbox each week:",1
262,"To continue, please click the box below to let us know you're not a robot.
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.
For inquiries related to this message please contact our support team and provide the reference ID below.",7
263,"Access denied Error code 1020
You cannot access cybernews.com. Refresh the page or contact the site owner to request access.
You cannot access cybernews.com. Refresh the page or contact the site owner to request access.
Copy and paste the Ray ID when you contact the site owner.
Ray ID: 756db5599becf170
For help visit Troubleshooting guide",5
264,In the 2020s most old generation people are retiring and not only the replacement generations smaller but there is gap in generational knowledge transfer. What do you think is important tech out there in which are we are losing our collective knowledge and hard won wisdom?,2
265,"Plant-covered Villa M by Triptyque and Philippe Starck ""brings nature back to the city""
A steel exoskeleton supports a vertical garden facade at this hotel in Paris, France, created by designer Philippe Starck in collaboration with French-Brazilian studio Triptyque and landscape studio Coloco.
Located in Montparnasse, the 8,000-square-metre hotel also contains a restaurant, co-working space, gym and rooftop bar, which the team said all focus on healthy living and a desire to ""bring nature back to the city"".
Expressing this concept, the entire exterior of the building is covered by a framework of deep black steel beams, planted with trailing plants that spill over its edges and frame views out of the hotel's bedrooms.
""We designed Villa M as a naturalist architectural manifesto: that is, a building of a new era, where man is no longer opposed to nature and the living,"" said Olivier Raffaëlli and Guillaume Sibaud, partners at Triptyque.
""The edifice itself is the support for this vertical garden, which will grow and occupy the entire facade, turning the building into a vertical, medicinal forest, and becoming the main architecture,"" Raffaëlli and Sibaud continued.
Villa M's artistic direction was led by Starck. The building's entrance leads directly into a lounge and restaurant space with an open kitchen, which provides access to a dining terrace at the rear of the building planted with fig trees.
""Upon entering, the visitor is plunged into a city of live energy and benevolence, an agora made of wood and concrete, vegetation, a friendly welcome, an open kitchen, all surrounded by a luxuriant terrace with trees,"" said the studio.
""Throughout the restaurant and the bar, fertile surprises, hidden places and mental games arouse curiosity and guide the gaze of visitors, reminding them that intelligence is one of the most beautiful symptoms of humanity,"" added designer Starck.
A basement level below contains hireable conference and meeting spaces, while two floors above house 20 ""open offices"" and co-working spaces alongside a gym with a boxing ring and yoga rooms.
The block's four uppermost storeys contain the hotel, which comprises 67 rooms and six suites that are designed as ""enveloping and relaxing cocoons"", with many opening out onto greenery-filled balconies or terraces.
Finishes in all of these interior spaces are guided by a concept of natural simplicity, with concrete ceilings and columns contrasted by pale wooden panelling and floors.
A palette of warm, earthy colours and durable materials defines the hotel furniture and fixings. This includes the larger Pasteur Suite, located at the corner of the seventh floor, which features bay windows and a double terrace.
""The traveller must feel at home, in calm, soft, and maternal rooms, pleasant to live in, so that the human being is always at the heart of the Villa M concept,"" said Starck.
At the top of the building is a rooftop bar, described by Tryptique as a ""suspended oasis"" offering views out across Paris among fruit trees and plants.
Triptyque was founded in 2000 by Greg Bousquet, Carolina Bueno, Sibaud and Raffaëlli. Other recent projects include the Tropical Tower, a proposal for a plant-covered skyscraper in São Paulo.
It previously collaborated with Starck on TOG's first showroom, which is designed to be as customisable as its furniture.
The photography is by Michael Denancé unless stated otherwise.
Project credits:
Architecture design: Triptyque Architecture
Concept program: Thierry Lorente and Amanda Lehmann
Art direction and architectural spaces design: Philippe Starck
Landscape design: Atelier Coloco
Assistant to the contracting authority: Guy Sanoïan",2
266,"PARIS, le 16 mai 2022 – Oxford Properties Group, investisseur immobilier mondial, gestionnaire d’actifs et développeur, et Novaxia annoncent un partenariat stratégique de co-investissement dans des actifs immobiliers Life Sciences pour accélérer la croissance du secteur en France. Ce partenariat pionnier, qui vise à investir plus d’un milliard d’euros en France d’ici 2024, à commencer par la région parisienne, amorce un changement d’échelle de ce secteur en forte croissance.
Pierre Leocadio, senior vice-président et responsable de l’investissement en Europe chez Oxford Properties, et Joachim Azan, Président-fondateur de Novaxia.
Devenu l’une des priorités gouvernementales après la pandémie de COVID-19, le secteur français des Life Sciences est en pleine croissance : les investissements de capital-risque destinés aux start-ups de biotechnologie ont doublé entre 2020 et 2021 pour atteindre 1,6 milliard d’euros. Le partenariat entre Oxford et Novaxia permettra d’offrir l’infrastructure immobilière de haute technologie dont le secteur a besoin pour son développement. Le partenariat devrait annoncer prochainement ses premières acquisitions, qui cibleront le développement de laboratoires, de centres de recherche, d’incubateurs, d’accélérateurs ou d’usines de production pour le compte d’entreprises de biotechnologie et de technologies médicale.
La première phase de l’activité d’investissement du Partenariat se concentrera sur l’Ile-de-France, qui connaît une pénurie de laboratoires et de sites des Life Sciences. En France, 80 % des investissements de capital-risque destinés aux start-ups de biotechnologie se font en Ile-de-France. D’autres investissements devraient suivre dans les métropoles françaises, comme Lyon ou Strasbourg.
Joachim Azan, Président fondateur de Novaxia, a déclaré : « Novaxia s’ouvre aux partenariats et innove encore en ajoutant une corde supplémentaire à l’arc du recyclage urbain. Après le logement, Novaxia va recycler des bâtiments obsolètes en lieux d’innovations dans les sciences de la vie. Dans le prolongement du projet d’installer l’un des plus grands incubateurs d’Europe à l’Hôtel-Dieu Paris, Novaxia se donne les moyens de déployer dans toute la France des lieux représentatifs de toute la chaîne de valeur des sciences de la vie (des laboratoires de recherches, des incubateurs, des accélérateurs et des usines de production). L’immobilier sera ainsi le point de départ de l’innovation scientifique pour que la France garde ses meilleurs chercheurs, ses meilleures entreprises et renforce sa souveraineté scientifique. »
Pierre Leocadio, senior vice-président et responsable de l’investissement en Europe chez Oxford Properties, a déclaré : « Le secteur des Life Sciences est l’une de nos priorités stratégiques d’investissement au niveau mondial, et la France est l’un de nos marchés de conviction les plus porteurs en Europe. Ayant réalisé d’importants investissements en Amérique du Nord et au Royaume-Uni ces dernières années, nous souhaitons continuer à construire notre portefeuille mondial en entrant sur le marché français. La France a toujours été à la pointe de la R&D dans le secteur de la santé et a tous les atouts pour conserver cette position de leader. La France dispose d’universités, d’hôpitaux universitaires et d’instituts de recherche de premier plan, ainsi que d’un accès important au financement, en particulier les fonds de capital-risque, qui ont fortement augmenté ces dernières années. »
« Nous souhaitons investir environ un milliard d’euros au cours des prochaines années pour acquérir et développer de nouveaux projets immobiliers afin de soutenir les industries biotechnologiques et médicales. Aux côtés de Novaxia, notre ambition est claire : devenir le leader de l’immobilier Life Sciences en France. Forts d’une vision commune et d’une connaissance approfondie du marché français, nous avons d’ores et déjà identifié et évalué plusieurs sites potentiels en région parisienne. »
Aude Landy-Berkowitz, Directrice Générale de Novaxia Développement explique : « Le développement des Life Sciences nécessite d’avoir un immobilier adapté qui réponde aux besoins techniques et aux usages d’une communauté. L’immobilier en France n’est pas aujourd’hui conçu dans cet état d’esprit. Il existe par exemple un déficit important de laboratoires de type L1 à L3 et leur développement demande des expertises spécifiques. Les besoins sont multiples et spécifiques en eau, en air, en hauteur ou encore en sécurité. Ce partenariat travaillera à leur conception anticipée et à leurs modes de fonctionnement, en imaginant la réversibilité entre laboratoire et bureaux. Nous allons développer un immobilier qui soit complémentaire et synergique, adaptable avec des espaces fermés comme partagés au service de la recherche et de l’innovation. Ce partenariat est un formidable progrès pour la communauté des Life Sciences en France. Le besoin est urgent, il est nécessaire que nous puissions développer des pôles d’innovation et de recherche qui offrent un parcours immobilier allant de la petite start-up à la grande entreprise. »
Abby Shapiro, senior vice-présidente et responsable du portefeuille européen des sciences de la vie, bureaux et commerces chez Oxford Properties, a ajouté : « Ce partenariat stratégique avec Novaxia nous permettra de développer un portefeuille des Life Sciences à grande échelle en France. Novaxia peut s’enorgueillir d’un excellent bilan en matière d’investissement et de développement immobilier, déployant une approche responsable, novatrice et étayée par une profonde compréhension des besoins de chaque marché local. »
« Nous nous appuierons sur ce partenariat pour tirer profit de nos compétences complémentaires. Oxford engage un capital conséquent et dispose d’une expérience forte dans les Life Sciences au niveau mondial. Forts des connaissances approfondies du marché local de Novaxia et ses relations avec des acteurs clés de la santé, nous sommes convaincus que nous pouvons offrir une solution adaptée à la demande croissante des entreprises de biotechnologies et devenir le leader de l’immobilier des Life Sciences en France. »
Associer l’expertise de deux acteurs pionniers dans une classe d’actifs en plein essor
Oxford et Novaxia sont toutes deux entrées dans la classe d’actifs des Life Sciences en 2017 et ont depuis acquis une expertise et un leadership substantiels dans le secteur. Le partenariat accélère leurs stratégies respectives et fait entrer sur le marché français la plateforme internationale des Life Sciences d’Oxford pour l’associer à l’expertise approfondie du marché local de Novaxia.
À travers le monde, Oxford et les sociétés de son portefeuille gèrent des actifs d’une valeur de 58 milliards d’euros (environ 80 milliards de dollars canadiens). La société a déjà développé ses activités dans le domaine des Life Sciences sur 10 marchés nord-américains ainsi qu’à Cambridge et Londres au Royaume-Uni, avec pour objectif de devenir un leader immobilier des life Sciences et investir près de 15 milliards de dollars US au cours des prochaines années. Depuis le début de l’année 2021, Oxford a investi près de 2,5 milliards de dollars US dans des laboratoires de R&D et des installations BPF et a identifié des opportunités de développement futures pour un montant de 3,5 milliards de dollars US.
L’ambition d’Oxford est de créer un écosystème mondial pour les entreprises du secteur des Life Sciences, dans lequel elles pourront être incubées, mener des recherches et développer des thérapies et fabriquer des produits. Le récent projet de développement de Navy Yards à Philadelphie (États-Unis), en est un exemple concret. Oxford y a récemment donné le coup d’envoi du développement spéculatif d’un espace de 12 000 m² dédié à des laboratoires de R&D et des installations BPF pour soutenir les entreprises de thérapie génique et cellulaire en phase de lancement. Il s’agit de la première phase du projet d’Oxford qui vise, à terme, à développer jusqu’à 280 000 m² d’espaces dédiés à la recherche, l’incubation et BPF, afin de créer un pôle d’innovation de classe mondiale dans le domaine des Life Science à Philadelphie.
Quant à Novaxia, depuis son arrivée dans le secteur en 2017, la société a mis en place un large écosystème de partenaires et de projets dans toute la France. En 2019, elle a été sélectionnée dans le cadre d’un appel d’offres pour développer l’un des plus grands incubateurs de Life Sciences d’Europe au sein de l’Hôtel-Dieu, dans le centre de Paris. En octobre 2021, Novaxia a lancé, en partenariat avec l’AP-HP et Biolabs, la 1ère plateforme d’innovation en santé sous l’égide d’Olivier Veran, ministre des Affaires sociales et de la Santé (plateforme @Hôtel-Dieu). Reconnue comme l’une des 300 entreprises à la croissance la plus rapide en France au cours des trois dernières années, Novaxia gère actuellement près de 100 projets de recyclage urbain en France et pilote pour 4 milliards d’euros d’opérations.
Si la France, avec sa main-d’œuvre qualifiée, est un leader international historique en matière de R&D pharmaceutique et médicale, les bouleversements technologiques font évoluer le secteur des Life Sciences dans le monde entier. Le rythme de l’innovation a considérablement réduit le temps et les ressources nécessaires aux entreprises pour rechercher, développer et introduire de nouvelles thérapies. Ce phénomène favorise la création et le développement de nouvelles entreprises, qui ont besoin d’accéder aux écosystèmes et aux sources de financement appropriés. La nécessité pour la France de renforcer sa souveraineté en matière de santé, accentuée par la pandémie, a incité le gouvernement français à réaliser de plus en plus d’investissements ciblés pour soutenir les pôles de Life Sciences avec les universités, les instituts de recherche, les hôpitaux cliniques et les sources de capitaux privés existants :
– France Relance déploie 6 milliards d’euros au financement du système de santé en soutien du Ségur de la Santé.
– France 2030 prévoit de mobiliser 7,5 milliards d’euros dans le secteur de la santé.
Ce soutien accru du gouvernement, ainsi que la mise en place de nouvelles infrastructures pour les pôles Life Sciences et l’augmentation des niveaux de financement du capital-risque, constituent une aide supplémentaire pour les entreprises innovantes du secteur de la santé qui souhaitent rester et se développer en France plutôt que de se délocaliser vers des marchés mondiaux établis comme aux États-Unis. Le nouveau partenariat entre Novaxia et Oxford a pour but de soutenir cette transition en développant l’infrastructure immobilière nécessaire et hautement technique qui fait cruellement défaut.
Antoine Papiernik, Président Directeur Général de Sofinnova, un leader mondial de l’investissement dans les entreprises des Life Sciences (start-ups, PME et ETI) a déclaré : « Le partenariat entre Novaxia et Oxford confirme que la France est bel et bien un pôle d’avenir pour le développement des innovations dans le domaine des biotechnologies et des technologies médicales, et positionne le pays comme un leader en Europe. Ce partenariat prometteur sera la clé pour multiplier le nombre d’entreprises de pointe en France, ce qui permettra au pays d’attirer les investissements internationaux dont il a tant besoin. »
Retrouvez l’intégralité du communiquer de presse ici.",0
267,"Wordcraft
Writers
Workshop
Over the last few years, AI researchers have made extraordinary progress building larger and more capable language models. Models such as Google's LaMDA have demonstrated an uncanny ability to generate incredibly coherent text. From having open-ended conversations to solving math problems, developers have harnessed this ability to tackle a wide range of problems that seemed impossible only a few years ago.
As long as researchers have worked on AI systems, they have also dreamed of how to use these systems to help us write.Today’s language models offer the possibility of making that dream a reality and enabling new workflows with AI-assisted writing. Our team at Google Research built Wordcraft, an AI-powered text editor centered on story writing, to see how far we could push the limits of this technology. We aimed to learn where these models can provide value and where they break down, and explore the future of writing. However, as a team of researchers and technologists, we knew we needed additional perspectives to tell the story of these new tools.
To help us understand the potential role of AI in creative writing, we brought together 13 professional English-language writers from around the world to use Wordcraft to write stories, which we're publishing as a collection here. Our goal was to have an honest conversation about the rapidly evolving relationship between creativity and technology. The accelerating pace of AI innovation and its broadening scope over our lives makes this type of dialog more important than ever.
What is Wordcraft?
Wordcraft is a tool built by researchers at Google PAIR for writing stories with AI. The application is powered by LaMDA, one of the latest generation of large language models. At its core, LaMDA is a simple machine — it's trained to predict the most likely next word given a textual prompt. But because the model is so large and has been trained on a massive amount of text, it's able to learn higher-level concepts. It also demonstrates a fascinating emergent capability often referred to as in-context learning. By carefully designing input prompts, the model can be instructed to perform an incredibly wide range of tasks.
However this process (often referred to as prompt engineering) is finicky and difficult even for experienced practitioners. We built Wordcraft with the goal of exploring how far we could push this technique through a carefully crafted user interface, and to empower writers by giving them access to these state-of-the-art tools.
We like to describe Wordcraft as a ""magic text editor"". It's a familiar web-based word processor, but under the hood it has a number of LaMDA-powered writing features that reveal themselves depending on the user's activity. For instance, if the user selects a phrase, a button to ""Rewrite this phrase"" is revealed along with a text input in which the user can describe how they would like the phrase to be rewritten. The user might type ""to be funnier"" or ""to be more melancholy"", and the Wordcraft application uses LaMDA and in-context learning to perform the task.
In addition to specific operations such as rewriting, there are also controls for elaboration and continutation. The user can even ask Wordcraft to perform arbitrary tasks, such as ""describe the gold earring"" or ""tell me why the dog was trying to climb the tree"", a control we call freeform prompting. And, because sometimes knowing what to ask is the hardest part, the user can ask Wordcraft to generate these freeform prompts and then use them to generate text. We've also integrated a chatbot feature into the app to enable unstructured conversation about the story being written. This way, Wordcraft becomes both an editor and creative partner for the writer, opening up new and exciting creative workflows.
The Wordcraft Writers Workshop
The Wordcraft Writers Workshop is a collaboration between PAIR and Magenta, two research teams with a long track record of developing forward-looking AI-powered creative tooling. The goal of the workshop was to solicit feedback from a cohort of professional writers with a wide range of backgrounds, styles, and levels of familiarity with AI, in order to better understand the present state and future uses of AI-powered writing tools.
The workshop cohort consisted of 13 professional writers, who were given 8 weeks to use Wordcraft. Unlike more constrained user studies run in the past, we gave writers freedom to write anything they wanted using any workflow they could devise. We share below some of the insights we learned through this process.
AI as Inspiration
Wordcraft shined the most as a brainstorming partner and source of inspiration. Writers found it particularly useful for coming up with novel ideas and elaborating on them. AI-powered creative tools seem particularly well suited to sparking creativity and addressing the dreaded writer's block.
Large language models are fantastic at making things up — they'll happily blather on about anything and everything, and they are particularly good at generating variations on a theme.
In a darkly comedic example, author Robin Sloan used the chatbot feature of the application to construct reveal spoiler...
Ken Liu asked for lists of items for sale at a store, and Nelly Geraldine García-Rosas attempted to generate a list of “rabbit breeds and their magical qualities”. In this sense, language models are incredible ""yes, and"" machines, allowing writers to quickly explore seemingly unlimited variations on their ideas.
The authors agreed that the ability to conjure ideas ""out of thin air"" was one of the most compelling parts of co-writing with an AI model. While these models may struggle with consistency and coherence, they excel at inventing details and elaboration.
The open-ended nature of the chatbot interface was especially helpful with ideation and exploration.
Finally, some of the writers used Wordcraft as a ""search engine"" or “research assistant”, and discussed the possibility of using AI-powered tools to directly interact with and explore the vast amount of text on the internet. Large language models like LaMDA can be thought of as an intelligent search index, giving people an extremely intuitive way (using plain language) to query a vast database of information.
Powerful, Not Perfect
The power of AI tools can often make their failures more frustrating — an occasional glimpse of the model's uncanny performance can set unreasonable expectations, while the model's inconsistencies are often maddeningly inscrutable.
Struggles in maintaining style and voice
A challenge faced by nearly all our writers was getting Wordcraft to maintain a specific writing style or narrative voice. This problem was especially salient when authors attempted stories with multiple points of view. Wordcraft often mixed up details or conflated character's perspectives.
Many of the writers noted how Wordcraft tended to produce only average writing. Its suggestions often resembled ""fan-fiction"". Perhaps this is no surprise considering the volume of fan fiction on the internet! Language models are capable of generating entirely novel sentences, but novel is not the same as interesting.
Many authors noted that generations tended to fall into clichés, especially when the system was confronted with scenarios less likely to be found in the model's training data. For example, Nelly Garcia noted the difficulty in writing about a lesbian romance — the model kept suggesting that she insert a male character or that she have the female protagonists talk about friendship. Yudhanjaya Wijeratne attempted to deviate from standard fantasy tropes (e.g. heroes as cartographers and builders, not warriors), but Wordcraft insisted on pushing the story toward the well-worn trope of a warrior hero fighting back enemy invaders.
Because the language model underpinning Wordcraft is trained on a large amount of internet data, standard archetypes and tropes are likely more heavily represented and therefore much more likely to be generated. Allison Parrish described this as AI being inherently conservative. Because the training data is captured at a particular moment in time, and trained on language scraped from the internet, these models have a static representation of the world and no innate capacity to progress past the data’s biases, blind spots, and shortcomings.
A Steep Learning Curve
Writers struggled with the fickle nature of the system. They often spent a great deal of time wading through Wordcraft's suggestions before finding anything interesting enough to be useful. Even when writers struck gold, it proved challenging to consistently reproduce the behavior. Not surprisingly, writers who had spent time studying the technical underpinnings of large language models or who had worked with them before were better able to get the tool to do what they wanted.
Because of these challenges and their exacting standards, our writers rarely used Wordcraft's output directly. However each writer developed their own workflow to best utilize the application in their writing process.
Hallucination is a Feature
One of the most well-documented shortcomings of large language models is that they can hallucinate. Because these models have no direct knowledge of the physical world, they're prone to conjuring up facts out of thin air. They often completely invent details about a subject, even when provided a great deal of context.
In certain settings, this behavior is very problematic — a chatbot supporting a bank or pharmacy that makes up details would be disastrous, and there’s a great deal of work being done to address this. However, in the field of creative applications, this behavior can be desirable. For instance, Ken Liu asked the model to ""give a name to the syndrome where you falsely think there’s a child trapped inside an ATM."" (the model’s answer: “Phantom Rescue Syndrome”).
Several participants noted the occasionally surreal quality of Wordcraft's suggestions. For example, Wordcraft suggested a wolf plucking petals with human hands, or man's best friend being an inanimate rod (Diana Hamilton). Ernest Herbert described the tone of these suggestions as ""absurdist spooky action at a distance"", which rhymes with the observation that many authors found Wordcraft well-suited for writing poetry.
AI as a Co-Writer
One of the major insights of the workshop was in revealing the diverse set of needs and wants writers have for an AI co-writer. Some writers were excited by the idea of AI that could replicate the roles of editors and writing partners they already work with. Others took a more utilitarian view, framing Wordcraft as the next evolution of the word processor.
Some writers discussed the value of having an AI that could replicate a writer's style as closely as possible. Ernest Hebert wished for a bot that remembered everything he had written and “could become an extension of me and replicate my style”. On the other hand, Robin Sloan felt that a system that learned to perfectly replicate a writer's existing style would not be terribly useful since every good story is unique.
Model Limitations
Good writers are skilled not only in producing but also discerning good language. In other words, they have taste. In contrast, language models like LaMDA are designed to accept any input and run with it. The flip-side of their “yes, and…” tendency is that these models lack distinctive and consistent opinions and style.
A recurring theme in the authors’ feedback was that Wordcraft could not stick to a single narrative arc or writing direction. These problems are at least partly because of the system’s technical limitations (e.g. the model can only ""read"" part of the story), but a more fundamental issue is that LaMDA was not designed as a writing tool.
LaMDA was explicitly trained to respond safely and sensibly to whomever it’s engaging with. But in the context of co-writing, this eagerness to please can be pathological. Wordcraft promised our writers to email them with story drafts or to get back to them “in a few days'” with more ideas (which, of course, it can't). LaMDA's safety features could also be limiting: Michelle Taransky found that ""the software seemed very reluctant to generate people doing mean things"". Models that generate toxic content are highly undesirable, but a literary world where no character is ever mean is unlikely to be interesting.
What Writers Need
In order to better aid writers in their craft, what kind of characteristics should future AI writing tools have? Making great art is about walking the tightrope between familiarity and novelty. More provocatively, great writing is transgressive — it subverts expectations and challenges the reader. Can a language model be transgressive without intentionality? Perhaps they can in a very local context, as demonstrated by large language models' ability to make surrealistic suggestions. But especially on larger scales, writers must be able to use these systems more intentionally. This needs to be approached from two directions: both by training underlying models that are more controllable and building interfaces to control them more effectively.
Participants emphasized again and again that the user interface matters as much as the underlying language generation model. We explicitly didn't give writers any instructions regarding how they should use the tool or how much of their final story text should be directly generated by Wordcraft. This freedom allowed writers to discover workflows through exploration, and writers developed techniques and workflows that went well beyond what we had explicitly designed Wordcraft for. The novel workflows that a technology enables are fundamental to how the technology is used, but these workflows need to be discovered and refined before the underlying technology can be truly useful.
What's next
The writers in the workshop unanimously agreed that AI-powered writing won’t replace writers anytime soon. However the authors also agreed that the technology is close enough that they could see themselves adopting some form of AI-assisted writing right now. Most agreed that widespread adoption will likely have complicated effects on the craft of writing, especially for beginners. Novice writers, students, and foreign language learners will soon find themselves in a world where AI-powered writing tools are ubiquitous - ranging from suggestions in Google Docs to bespoke creative tools like Wordcraft.
In recent years, the paradigm has been to train a single large language model then apply it to as many tasks as possible. However, we should acknowledge that one language model cannot be good at all tasks because to be good at one means to be worse at others with conflicting goals. In the short-term, AI-assisted writing will most likely be successful in smaller and more focused domains. Technologists ought to focus on tools that assist the parts of writing that are most time-consuming and least enjoyable if they want them adopted widely. It's also clear from our work that user interfaces are just as important as the underlying models, and writers need to be involved in the conversation of how these tools are developed.
We believe that technologists need to work in partnership with the communities their inventions will impact. But technological progress is unpredictable and difficult to contain. For example, the last few months have seen the rapid development of generative image models (Google's Imagen and OpenAI's Dall-E) leading to open source versions that can be run almost anywhere (StabilityAI's Stable Diffusion). The accelerating pace of innovation, the combination of hype and inscrutability surrounding AI, and an increasingly competitive economic landscape have made things feel more high-stakes than ever. Only through open and ongoing dialog between technologists and artists can we build tools that have a positive impact on the world.
Who We Are
Acknowledgements
We thank our fantastic cohort of writers: Aaron Winslow, Allison Parrish, Diana Hamilton, Ernest Hebert, Eugenia Triantafyllou, Jamie Brew, Joseph Mosconi, Ken Liu, Michelle Taransky, Wole Talabi, Nelly Geraldine Garcia-Rosas, Robin Sloan, and Yudhanjaya Wijeratne — without whom this project would not have been possible.
This website was designed and built by Mahima Pushkarna and Jeff Gray, and it was illustrated by Emily Reif using Imagen.
We would like to thank all the people who have supported this project coming together: Chris Callison-Burch, Chris Donahue, Donald Gonzalez, Douglas Eck, Elizabeth Clark, Jesse Engel, Michael Terry, Noah Constant, and many others.",3
268,"Digital Products
Digital Products
Stories and strategies of how these founders grow and manage their digital products businesses.
😎 Top
- Reaching $500k in revenue in just one year by selling Notion Templates
- How I made $101,578.04 selling colors online → The Timeline + Q&A
- This founder take you through the process of how he validated, built and grew his newsletter business to $6k MRR in just 3 months
- The popular article from Danial Vassallo -> How I made $210,822 selling a pdf and a video on the internet
- Danial Vassallo also did a Q&A on how he made $404,473 selling an ebook and a video course on the internet
- $15,000 from selling a Notion template: the process and results
🔗 Stories
- Turning an Airtable file into a $9.2k Income. → Find out how
- 0 to $20k revenue in 3 months with a Notion Template → The Breakdown
- Making $30k in revenue by self-publishing an Ebook
- Learn the lessons and regrets from this Ebook founder who made $25k on launch day
- This founder shares her journey in self-publishing an Ebook and getting to $5000 in pre-orders
- Getting traffic to your product is important; learn how this guy attracted 2100 unique visitors to his digital guide in just 3 days
- How to self-publish an ebook to $1.5k in sales in 2 days
- How to launch an online course and make $6,622 in pre-orders within 7 days
- How I made $30,000 on My First Self-Published Book
- This founder shares how he launched his ebook to $14,000 in sales in 14 days, and getting 1000 customers in the process
- Don't have a product idea? Learn how this guy made $2,000 per month with his free newsletter showcasing people's workspace
- Easlo is a prolific indie founder who've made $20,000 MRR selling Notion Templates. Here is his roadmap / checklist from $0-$20,000.
Keep up to date with the latest stories and strategies posted by Indie Founders. Subscribe below!",8
269,"- Strategic Foresight
- Simulation
- Scenario Design
- Future Forecasting
- Foresight
- Creativity
- Strategic Thinking
- Innovation
- Leadership
- Scenario Development
- Strategic Planning
- Gaming
Futures Thinking Specialization
Ready Yourself for a Changing World. Learn the skills and mindsets of the world’s top futurists, so you can forecast what’s coming, imagine new possibilities, and seize control of your own future.
Offered By
What you will learn
Build your future forecasting skills.
Learn how to use Institute for the Future’s most powerful foresight tools, designed to help you spot new opportunities for innovation and invention.
Gain insight into the most important new technologies, global events and big ideas that are already shaping the future.
Think more creatively and optimistically about what’s possible in the future.
Skills you will gain
About this Specialization
Applied Learning Project
Learners will investigate a future topic of their own choosing, such as the future of food, news, data, marketing, religion, learning, oceans, virtual reality, or AI, and create their own forecast and scenario to describe key risks and opportunities in that future.
How the Specialization Works
Take Courses
A Coursera Specialization is a series of courses that helps you master a skill. To begin, enroll in the Specialization directly, or review its courses and choose the one you'd like to start with. When you subscribe to a course that is part of a Specialization, you’re automatically subscribed to the full Specialization. It’s okay to complete just one course — you can pause your learning or end your subscription at any time. Visit your learner dashboard to track your course enrollments and your progress.
Hands-on Project
Every Specialization includes a hands-on project. You'll need to successfully finish the project(s) to complete the Specialization and earn your certificate. If the Specialization includes a separate course for the hands-on project, you'll need to finish each of the other courses before you can start it.
Earn a Certificate
When you finish every course and complete the hands-on project, you'll earn a Certificate that you can share with prospective employers and your professional network.
There are 5 Courses in this Specialization
Frequently Asked Questions
What is the refund policy?
Can I just enroll in a single course?
Is financial aid available?
Can I take the course for free?
Is this course really 100% online? Do I need to attend any classes in person?
How long does it take to complete the Specialization?
What background knowledge is necessary?
Do I need to take the courses in a specific order?
Will I earn university credit for completing the Specialization?
What will I be able to do upon completing the Specialization?
More questions? Visit the Learner Help Center.",2
271,"BBC documentary used face-swapping AI to hide protesters' identities
Filmmakers used an AI to swap the faces of anti-government protesters in Hong Kong for those of actors to protect the protestors' identities while maintaining their facial movements and emotional expressions
An artificial intelligence helped to protect the identity of people who took part in a violent anti-government protest in Hong Kong by swapping their faces for those of actors. The method was used in a new BBC documentary, with filmmakers saying it protects the protesters, who were interviewed on camera, from persecution while conserving their mannerisms and the emotions conveyed in their facial expressions. …
Continue reading
Subscribe today
in our Cyber Monday Sale
No commitment, cancel anytime*",3
272,"DEF CON 31 Call for Ideas! Open Now!
Posted 9.14.22
Let’s get a jump on DC31 with a general Call for Ideas! We want to hear from current and aspiring content creators. Share ideas for contests, villages - anything. Creators get more feedback & time, we all get a better DC. Open NOW.
DEF CON 30 Videos are Coming!
Posted 9.30.22
Heads up- the DEF CON 30 videos are gonna hit YouTube a little early this year. You might want to block off some time in October. We apologize in advance for any effect on workplace productivity.
DEF CON 30 CTF on the Books! Congrats to MMM!
Posted 9.21.22
Congratulations to the DEF CON 30 CTF Winners, Maple Mallard Magistrates! Read more about MMM!
They were closely followed by the teams Katzebin and Starbugs, in 2nd and 3rd places respectively.
A big thank you to Nautilus Institute and all the CTF competing teams for a great game! Check out the DEF CON 30 CTF section of the Media Server for LiveCTF, PCAPS, and other interesting stuff as it becomes available!
Early Release Video - Hacking the Farm by Sick Codes!
Posted 9.14.22
We've released a talk from farm hacking pioneer Sick Codes on the intricacies of agricultural equipment cyber security, and how to break and modify it. Enjoy and share widely!
Archive Page is Live for DEF CON 30!
Posted 9.2.22
Missing DEF CON 30? We've updated our Conference Archive! Get your hands on a cornucopia of DC30 content - the program, LiveCTF, photos, video and even a soundtrack to vibe with while you browse. All for the low, low price of one internet click.
Keep an eye on it for even more coming soon; Contest results, talk videos, CTF packet caps, video of the music events and more! Happy weekend!
DEF CON 30 Badge talk Video!
Posted 8.29.22
In case you missed it: learn all about the magical mystery musical badge from DEF CON 30 in the opening talk for DC30 with The Dark Tangent and MKFactor, the badge creators.
DEF CON 30 Press Roundup!
Posted 8.17.22
DEF CON 30 is in the books, and it looks like we made a little news. Here’s an early roundup of DEF CON 30 press mentions. We’ll update soon with more writeups and breakdowns as they appear.
DEF CON Bans OAN - Vice
This String of Emojis is Actually Malware - Vice
Hackers Took Over a Commercial Satellite to Broadcast Hacker Movies - Vice
Hackers Come Home to Vibrant Community - Dark Reading
StarLink Ground Stations Successfully Hacked - Hackaday
John Deere Tractor Runs Doom
- The Register
Black Hat and DEF CON visitors differ on physical risk management - The Register
How Sanctions Impact Internet Operators - Infosecurity Magazine
#DEFCON: CISA Director Praises Congress and International Cybersecurity Cooperation - Infosecurity Magazine
The Next Big Jailbreak in Tech: John Deere Tractors - Gizmodo
Black Hat and DEF CON Roundup - Threatpost
Carnegie-Mellon Team Wins DEF CON Hacking Competition - Business Wire
Zoom Patches Mac Auto-Updater Vuln that Granted Root Access - Ars Technica
Election Disinformation Fears Loom Over Hacker Confab - Politico
Sick Codes Jailbreaks Tractor at DEF CON - Fierce Electronics
John Deere Jailbreak Shows It’s All Built on Outdated, Unpatched Hardware - Boing Boing
A New Jailbreak for John Deere Tractors Rides the Right-to-Repair Wave - Wired
Playing for All the Jelly Beans at the EFF Benefit Poker Tournament at DEF CON - EFF
Reproductive Justice in the Age of Surveillance: Panel at DEF CON 30 - EFF
What to watch for as 'Hacker Summer Camp' gets underway in Las Vegas - Cyberscoop
Eclypsium Calls Out Microsoft Over Bootloader Security Woes - Tech Target
Russian Hackers Are Escalating and Diversifying Their Attacks on Ukraine, Research Says - Gizmodo
US Emergency Alert System Has ‘Huge Flaw’ — Broadcasters Must Patch NOW - Security Boulevard
New exploits can bypass Secure Boot and modern UEFI security protections - CSO Online
DEF CON 30 Comes of Age with Hacker Homecoming - Security Systems News
Logran hackear Starlink por solo 25 dólares Muy Computer
Up Close at DEF CON 30 - PC Mag
‘Hackers against conspiracies’: Cyber sleuths take aim at election disinformation - Politico
The Zoom installer let a researcher hack his way to root access on macOS The Verge
White House Cyber Director: ‘Defense is the New Offense’ for Cyber - Nextgov
Inglis: People, companies need to replicate collective cyber defense seen in Ukraine - The Record
Potential hack vulnerability for some Boeing planes fixed: Researchers - Business Insurance
Zoom acaba de corregir una falla de seguridad importante - Digital Trends (Espagnol)
A Flaw in the VA’s Medical Records Platform May Put Patients at Risk - Wired
DC30 Car Hacking Village Badge - Intrepid Control Systems
(YouTube)
Designing the DEF CON 29 and 30 Badges (featuring MK Factor) Hacker Hangouts (YouTube)
DEF CON 30 OBD-Kill Badge First Flight - Intrepid Control Systems
(YouTube)
Defcon 30 badge release the patch/fix to the bug of smoked badge. - Reddit
DEF CON 30 China Virtual Party!
Posted 8.11.22
Our hacker friends in China are having a VR party for DEF CON 30 with a big, beautiful virtual meeting space and media shared from the show. Big thanks to Baidu for putting that party together! The DEF CON spirit of discovery and community is a truly global thing and we’re grateful to all of you for making DEF CON what it is.
Join us for DEF CON 30 online!
Posted 8.11.22
The DEF CON Discord is open (discord.gg/defcon). You can hang out in virtual LineCon, try out the offerings of one of our hybrid villages and meet DEF CON family from around the world.
The DEF CON Groups have a VR hangout going on throughout DEF CON. Learn what DCGs across the globe are up to, maybe even find a group near you to join so you can keep that DEF CON vibe all year! The info you need to get involved is here: https://www.dcgvr.org/DEF_CON_Groups_AltspaceVR_-_Quick Guide_v1.6.pdf and you can join in on the fun with or without a VR headset. You can even watch the event live on Twitch: twitch.tv/defcon_groups.
Follow our YouTube channel (DEFCONConference) for video updates from DC30 all weekend. We’ve upped our content game this year and we’ll be sharing a bunch of interviews and contest content.
So even if you’re not onsite, you can still get some DEF CON into your 2022, and we’ll save you a place in LineCon for 2023.
HDA Infopack is Live!
Posted 8.4.22
Many thanks to @A_P_Delchi for the DEF CON 30 HDA Infopack! This helpful guide for Hackers with Disabilities has venue maps, tips for traveling between venues and a concise explanation of DEF CON's HDA provisions. Let's look out for each other, and if you see a way we can improve our accessibility, let us know!
DEF CON Transparency Report Update
Posted 7.28.22
In preparation for DEF CON 30, we’ve updated the transparency report on the DEF CON website. While you’re there, take a moment to re-familiarize yourself with the code of conduct. We don’t have a ton of rules, but we take the ones we have very seriously.
DEF CON 30 Speaking Schedule is Live!
Posted 7.15.22
‘Tis the season, hackerfolk. DEF CON is almost here and all four tracks of the main speaker schedule are live on the website! Visit the Schedule page to start your planning. Our valiant CFP Review Board has put together a strong list of presentations over a wide array of subjects. We’re sure you’ll find plenty of interest.
Feel free to tweet at us about the talks you want to see, and feel equally to free to get hyped. Less than a month now, people.
Floorplan Maps are Live, Room Block discount Ends Soon!
Posted 7.7.22
The floorplan maps for DEF CON 30 have been added to the Venue page of the DC30 website. Take a peek and plot your course, it's just a few short weeks now.
The DEF CON 30 room rate discount closes July 15 - so book soon to take advantage of the price break! Our room block in Caesars is full, but many others still have price breaks available.
Book a Room for DEF CON 30 Here!
COVID Clarification for DEF CON 30
Posted 6.22.22
Just so there’s no confusion, DEF CON 30 will require masks, same as last year. We thank everyone for keeping each other safe last year, and we can’t wait to get the gang together responsibly just a few short weeks from now.
Original DEF CON 30 Covid Policy post from May.
First Batch of DEF CON 30 speakers is Live!
Posted 6.9.22
Friendly DEF CON 30 announcement - the first bunch of speakers are selected and available for your perusal on the DEF CON forums. Congrats to everyone already selected. Keep your eyes on this space for more selections!
DEF CON Training Site is Live!
Posted 5.31.22
DEF CON Trainings registration is LIVE! Right after DEF CON 30, we're excited to offer these intensive 2 day classes with a certificate of completion. First come, first served so don't procrastinate.
Class descriptions and reg information are at http://defcontrainings.myshopify.com.
Weekend Updates! CTF Quals news, and New SE Community Q&A Today!
Posted 5.27.22
CTF News
CTF Quals are almost here (May 28 at 0000 UTC) and the CTF Chat on the DEF CON discord is already open!
From @NautilusCTF:
#defcon quals chat on the Defcon discord is open. Come visit us in #ctf-discussion-text to ask all the important questions, like “when is web?” and “this challenge is too hard unlock another one”
Time is short to get to the Nautilus Institute Website and register your team for CTF quals!
SE Community Q&A Today!
Join Social Engineering Community Village cofounders @JC_SoCal and @sn0ww to talk all about what kind of events the Social Engineering Community has in store for DEF CON 30. They'll be live on Twitch answering your questions at 5pm EDT Friday the 27th at twitch.tv/se_community. See you there!
The Black and White Ball is Back!
Posted 5.24.22
A little announcement about DEF CON 30's Black and White Ball: the best-dressed entrants will get some to enter early and enjoy a few free drinks before we let everyone else in. So look sharp - more details to come.
DEF CON Movie Night: 3 Days of the Condor
Posted 5.21.22
Join us Saturday the 21st at 8pm PDT for Sydney Pollack's 1975 spy thriller 'Three Days of the Condor'. Robert Redford plays a CIA researcher on the run and Ma Bell plays herself. We'll be hiding out in the DEF CON Discord (discord.gg/defcon) under the code name movie-night-text.
Check out Policy @ DEF CON!
Posted 5.19.22
Policy matters. The world has never been so connected, and mighty forces contend for the right to shape our digital lives. DEF CON believes the hacker community needs a voice in that process. To help people learn, connect and get involved with the leading edge of tech policy, we offer ‘Policy @ DEF CON’. We’ll have presentations, panels, and off-the-record evening lounges. Get yourself up to speed on the issues, connect with some of the players and maybe even get involved. The future is what we make it!
The DEF CON 30 Website is live!
Posted 5.13.22
Good news, everyone! The DEF CON 30 official website is officially LIVE and DEF CON season is officially IN EFFECT. Bookmark it for a handy place to check out all of the DC30 infoz as they roll in. Check the calendar, jump into the forums, book a room - it’s all in one place.
Now that we’ve reached cruising altitude, you are free to shimmy excitedly around the cabin.
Let’s GoOOoo!
COVID Updates for DEF CON 30
Posted 5.3.22
DEF CON 30 is getting closer, and that means we’re starting to get questions about Covid-19 protocols for the in-person event. Here’s the current state of play.
Some things have changed since DC29. The US has largely stopped checking vaccine status for entry to indoor events, owing at least partly to the knowledge that the vaccines serve more to prevent severe disease than to curtail transmission. COVID-19 testing is now mostly done privately with widely available at-home kits.
But most things haven’t changed. There are still new variants on the move. There are still spikes in transmission and hospitalization. Masks are still the most effective way to protect people in indoor events.
Barring a major change in the situation, we will not check proof of vaccination, but we will keep last year's mask requirement in place for DEF CON 30. Protecting the community is our first priority, and we want to make sure that everyone is as safe as we can make them. Everyone includes the healthy, the vulnerable and those who have immune compromised loved ones they need to protect.
Thank you for all you did to protect each other last year, and with your help we’ll do it again this year.
Training Coming to DEF CON 30, Call for Training is Open!
Posted 4.14.22
The wait is over - we’re ready to announce the Call for Trainers!
This year we’re adding DEF CON Training – intensive, two-day courses of study aimed at building specific skills. In some cases, these courses will even carry a certification. The Trainings will be held August 15-16, the Monday and Tuesday after DEF CON.
We’re looking for unique, technical, and practical presentations from trainers with deep knowledge of their subject. If that’s you, we’re offering:
- 50/50 split of the gross income.
- Optional test where students demonstrate their skill for a certificate.
All the info you need to apply is on the Call for Training page. Get your applications in early – we look forward to seeing what you’ve got to share.
New Payment Option for DEF CON 30!
Posted 3.25.22
DEF CON is a cash-at-the-door kind of conference. Paying in cash helps protect your privacy, and search warrants can't vacuum up PII we don't collect. You will always be able to lay down US dollars in the reg line and collect your badge.
Still, the experience of DC29 taught us a few things. Some of our attendees work DEF CON into their business travel schedule, and the option to pre-reg with a credit card over the web made things much easier for them. Some of our attendees need to manage a group purchase, or want a more detailed receipt.
For everyone who fits into those categories, we’re happy to announce that we’re keeping the option of online registration. Starting Monday, March 28th, you’ll be able to use shop.defcon.org to buy your ticket and get your receipt. We hope the online option makes the process more streamlined for those who need it. We thank people for their patience and feedback as we navigate the changing landscape.
The price for DEF CON 30 is $360, with a processing fee of $9.66 added to online orders.
Fine print: Currently we cannot provide beachballs and pizza to the online purchasing experience. For that, you’re gonna need LineCon.
DEF CON Movie Night: Dark Star!
Posted 3.16.22
DEF CON Movie Night this Saturday will feature some more 70s sci-fi with John Carpenter’s ‘Dark Star’ from ’74. Join us 3-19 at 8pm PDT in the #defcon discord (discord.gg/defcon). We’ll be in the movie-night-text channel.
Villages for DEF CON 30!
Posted 3.15.22
The list of DEF CON 30 villages on the Forums has been updated! Stop by to check out the full complement of village goodness we're offering this year. Comment, like, subscribe, volunteer to help out - but mostly get amped. #defcon30approaches.
Coming soon: Call for Training!
Posted 3.11.22
We’re excited to announce something new on the menu for DC 30 - DEF CON Training! We’re launching a lineup of intense two-day trainings taking place August 15-16 in the same venue, and we’re looking for trainers!
WHAT: DEF CON We’re seeking Trainers for two-day training sessions right after DEF CON 30.
WHEN: August 15-16, the Monday and Tuesday after DEF CON 30.
WHERE: Same location, the Caesars Forum.
WHY: For DEF CON attendees who love our free Workshop series but wish they could get an even deeper, more focused dive and maybe even a certificate. Like everything we do at DEF CON, we hope it will help to build and strengthen the hacker community and spread the kind of knowledge that makes the world more open and secure.
DEF CON Training will offer two-day paid training courses in the $1-$3k price range. We’re looking for unique, technical, and practical presentations from trainers with deep knowledge of their subject. If that’s you, we’re offering:
- 50/50 split of the gross income.
- Optional test where students demonstrate their skill for a certificate.
Interested? We will launch the Trainer submission form later this month! If you have questions, drop us a line at info@defcon.org.
The Dark Tangent
More DEF CON 30 Calls Opening!
Posted 2.15.22
Good news, everyone! We have more calls open for DEF CON 30!
Call for Parties and Meetups: your dreams of throwing an epic party at DEF CON 30 are within your reach! If you have a solid concept to wrap some next level festivities around, get at us. The best ideas will get space and support. Details here: Call for Parties
Call for Music: we’re gonna need some tunes. Lots of tunes. This call is for established acts and bedroom Beethovens alike. We’re looking for live performers, so if you’ve got the stuff that puts the dip in our hip and the glide in our stride, get to the Call for Music and let us know.
Call for Vendors: we’re always looking for new hacker gear and accessories to share with the community. Get your cool swag in front of a pretty savvy and curious audience by applying here at the Vendor Application
New Calls Open for DEF CON 30!
Posted 2.1.22
You know how you can tell it’s DEF CON season? The Calls. When you hear the distinctive warble of the DEF CON Content calls, you know what’s up. It’s like the first robin of spring, if robins were cooler and more hacker-focused.
Today we’re opening three more DEF CON 30 Calls:
Call for Papers
The big one. If you want to speak at DEF CON 30, it’s time to get your submission together. As always, we’re looking for fresh, technical content and the sooner you get it in, the better your chances. We can offer suggestions to help you get over the finish line, time permitting. Fortune favors the bold, so don’t delay.
Call for Workshops
The very popular workshop series is back for DEF CON 30. Some topics need a more time and involvement than a main-stage talk can offer. The workshops are an amazing way to share your in-depth, hands-on content with the DEF CON community.
Demo Labs
Get your open source project in front of the knowledgable, curious humans of DEF CON. Get valuable feedback, find accomplices and raise your project’s profile. We provide the floor space and the audience, you provide the timely submission.
The DEF CON machine is revving up, and DC30 will be here before you know it. Don’t miss your chance to get involved. The community is waiting to see what you’ve got to share.
A Warm Welcome to the Next CTF Organizer Team: Nautilus Institute!
Posted 1.28.22
Big DEF CON 30 CTF update! Following several years of exemplary service by the Order of the Overflow, our world-famous Capture the Flag contest is under new management. The care and feeding of this year’s CTF is in the worthy and capable hands of the Nautilus Institute!
From Nautilus Institute:
Ahoy DEF CON and CTF communities!
We are the Nautilus Institute. We have been chosen, from a very respectable pool of applicants, to steer the DEF CON CTF ship starting in 2022. We are thankful for this honor, and hope to navigate straight and true no matter what waters lie ahead.
We’re a bit light on details, while we prepare for this year’s DEF CON CTF Qualifiers May 28-29, but we hope to flag you down with more information soon! Please follow us on twitter at https://twitter.com/Nautilus_CTF and keep a look out on our website at https://nautilus.institute.
Sea you soon,
@•̂≈
For the boldest and best prepared, glory awaits. Godspeed.
DEF CON Movie Night: Primer!
Posted 1.27.22
DEF CON movie night rolls on with ‘Primer’. Joins us on the DC discord Saturday 8pm PST for what has to be the most brainmelting time travel movie that could possibly be shot for $7000. Bring a cork board and a few different colors of yarn. We’ll be waiting for you in the movie-night-text channel.
DEF CON Movie Night: Tank Girl!
Posted 1.19.22
This week’s DEF CON movie night will feature the very weird ‘Tank Girl’ from 1995. Join us Saturday, 8pm PST in the movie-night-text channel of the DEF CON discord for a glimpse at what the apocalypse looked like from the more innocent viewpoint of the mid 90s. Bring your own water.
DEF CON New Year's Eve!
Posted 12.23.21
DEF CON is doing a small New Year's Eve event on the DEF CON discord. There will be several hangouts and contests to participate in. We’ll have music, a Kubernetes CTF, A Ham radio CTF, some Hacker Karaoke, movie watchalongs and more. We’ll have the full rundown on defcon.org and we’ll update in the NYE Forum threads. Join us in welcoming 2022 - can't wait to see you!
DEF CON 29 Transparency Report
Posted 12.6.21
The full DEF CON Transparency Report for DEF CON 29 is now available. Our deepest thanks to everyone who reported issues to us and also to the people on staff who tracked down and handled those issues. It's a community effort, and it's good to see the progress we're making.
Enter the DEF CON 30 Artwork Contest!
Posted 11.17.21
Now that the DEF CON 30 Theme is out there in the world, it’s time to go pencils up on the DEF CON Art Contest!
This year’s theme is ‘Hacker Homecoming’, and you can read all about it on the DEF CON Forums. It’s a theme meant to celebrate our community’s much awaited reunion next August. It’s also meant to reference the 30th Anniversary we’re celebrating, which is a pretty big deal for a hacker conference.
So if you’ve got some art skills, you’ve got a luxurious 7+ months to get your take on the theme in to us. There’s so much time between now and the June 1 deadline that you could probably learn a brand new art style in which to make your submission. You can drop as many submissions to pictures@defcon.org as you want, so enter early and often.
### Theme:
We are looking for artwork that reflects a spirit of community and reunion. We’re looking for art that combines the 90’s hacker aesthetic of DEF CON’s history and our tribe’s 21st century future. We’re looking for your vision and vibes.
We hope you’ll take in the information in the style guide, but we hope that you’ll use that as a launching pad and not a set of limits. We want to see where you can take these ideas.
### Guidelines:
300 DPI. Convert type to outlines where applicable. Trust your instincts - we’re looking for genuine energy, not technical perfection. We want to share and amplify the artists in our community. If tlhat’s you, get your ideas down. If that’s not you yet, could it be? You’ve got a few months to find out.
Entries will be placed on the DEF CON Forums for voting, and there will be prizes. There will also be gratitude, and opportunities to inspire others with your special way of seeing the world. We can’t wait to see what you’ll make!
DEF CON 30 Theme: Hacker Homecoming
Posted 11.12.21
This has been a crazy couple of years.
A global pandemic turned DEF CON 28 into DEF CON Safe Mode. Some easing of the restrictions and some strict attendance rules gave us a hybrid con for DC29. An improvement, to be sure, but something short of a full DEF CON experience.
We want DEF CON 30 to have the energy of a reunion. We’ll be back togeher in a brand spanking new venue. We’ll be thirty years old - an amazing milestone for a hacker conference under any circumstances. In honor of all that, we’re calling DEF CON 30 ‘Hacker Homecoming’.
The first reason is that it’s literally a return home. After two years of separation, we’re looking forward to having more of our family under one roof, under the Vegas late summer sun.
There’s also a North American tradition called ‘Homecoming’. Secondary schools and colleges invite luminary alums back for a big celebration of the school’s history and a toast to its future. We intend to do just that for DC30. We’ll have some surprise guests from DEF CON’s illustrious past on hand to talk about the amazing places their life has taken them since joining the DC Community. We’ll also be laying out some of the map forward from our 30th Anniversary.
So please join us in the Caesar’s Forums if you can, and on the Discord if you can’t. Maybe even pack a fancy outfit for the homecoming dance. It’s high time for a reunion.
Design Inspiration
This year’s theme is about celebrating the past and getting geeked about the future, so we’re looking for smooth integration of old school hacker stylee with future vibes.
We took the color palette inspiration from arguably the most iconic DEF CON image of all time: the rooftop photo from DEF CON 1.
The photo is amazing for any number of reasons, but the most important is that even though it screams early 90s hacker culture, it also shows some of the essence of what DEF CON is even in the 2020s. It’s still a gathering of extraordinary digital misfits going Voltron in the Vegas night.
The fonts were also selected to be like a homecoming celebration, with some reverence for the past, some excitement about the future. The past is represented by the very 90s CityPop and Geom and the future by the futristic minimalism of Open Sans.
Homework
As always, we’ll be sharing movies, books, music and other random media to get you in the right frame of mind for maximum DEF CON. This year we’re even giving you an extra few months to get through the syllabus. Watch the DEF CON site for additions to all the lists. Pencils UP!
Movies:
Sneakers
The Imitation Game
Zero Days
Books:
The Shockwave Rider
The Cuckoo’s Egg
Kingpin: How One Hacker Took Over the Billion-Dollar Cybercrime Underground
The Cult of the Dead Cow
The DEF CON 30 Call for Contests and Events is OPEN!
Posted 11.1.21
DEF CON 30 is going to be a big deal, and we’re full speed ahead on planning. If you’ve got a stellar idea for a contest, this is your moment. Take advantage of the early opening to turn your idea into a real DEF CON Experience. The extra lead time helps us work with you to get the best ideas across the finish line, but only if you take advantage and get your submissions in.
You can read the rules and requirements on the Call for Contests Page. You can check the DC29 Contest forum for an idea of what we’ve accepted in the past.
Let’s see what you’ve got percolating out there, DEF CON fam. Let’s take DC30 up a notch.
DEF CON 30: Open and Upcoming Calls
Posted 10.26.21
The DEF CON 30 Call for Villages is already open! To see if your fave is already accepted, check out the Villages forum for DEF CON 30! Don't see what you want on the current list? Maybe that's your cue to submit a proposal!
For the truly ambitious, there is still a call open for the coveted title of CTF organizers! Only a little over two weeks left to put in your proposal to be the future of DEF CON Capture the Flag!
On the horizon very soon will be the Call for Contests! Polish those proposals for new DEF CON contests now and be ready for the call!
We only turn 30 once. Let's do it big!
DEF CON 30 Call for Villages has Opened!
Posted 10.1.21
DEF CON 30 may seem a long way off, but it’s never too soon to start planning. Especially for something as close to the heart of the DEF CON experience as Villages.
As always, we’re looking for new villages that will create welcoming, hands-on spaces for congoers to sharpen their skills, learn something new and maybe even find their newest obsession.
Space (both physical and metaphorical) is limited. Early submissions have increased chances of success. If the concept is strong but needs work, we can help but only if we have enough time.
You’ll want to famailiarize yourself with the requirements and submission guidelines at https://defcon.org/html/defcon-30/dc-30-cfv.html first. If you can meet the preconditions, and you have a stellar idea to propose, that’s the universe telling you it’s go time. Rise to meet your moment.
We can’t wait to see what’s on your mind.
CTF Call for Organizers is Officially Open!
Posted 9.28.21
The mighty and venerable Order of the Overflow is retiring from organizing the DEF CON CTF, and the torch must be passed. This means a rare opportunity for you, CTF enthusiasts.
Are you ready to create the next generation of elite CTF tournaments? Do you have the skill and creativity to elevate the game for the world’s best players? The drive to see your ideas through to completion? If this is you, it’s time for us to talk.
The lowdown is at https://defcon.org/html/links/dc-ctf-cfo.html. Get familiar, submit the CTF you want to see in the world. For the chosen, glory awaits.
More News...",1
273,"Today’s cars are akin to smartphones, with apps connected to the internet that collect huge amounts of data, some of which is highly personal.
Most drivers have no idea what data is being transmitted from their vehicles, let alone who exactly is collecting, analyzing, and sharing that data, and with whom. A recent survey of drivers by the Automotive Industries Association of Canada found that only 28 percent of respondents had a clear understanding of the types of data their vehicle produced, and the same percentage said they had a clear understanding of who had access to that data.
See information on the 37 companies we identified.
Welcome to the world of connected vehicle data, an ecosystem of dozens of businesses you never knew existed.
The Markup has identified 37 companies that are part of the rapidly growing connected vehicle data industry that seeks to monetize such data in an environment with few regulations governing its sale or use.
While many of these companies stress they are using aggregated or anonymized data, the unique nature of location and movement data increases the potential for violations of user privacy.
The connected vehicle data market is still in its early days, but analysts predict it will be worth anywhere from $300 billion to $800 billion by 2030.
This nascent industry faces challenges, as it is under pressure to reap profits in order to attract and satisfy investors; at the same time, the disclosure of sensitive and potentially identifying information from smartphones has prompted U.S. lawmakers to threaten sweeping crackdowns on the collection, transfer, and sale of location data, an effort that could create barriers for the industry as it grows.
Nevertheless, the race is on to gather massive amounts of data points about drivers to feed the growing market for this information.
The following is a typical data flow scenario for a vehicle with a factory-installed cellular connection.
Once a driver gets into a car, dozens of sensors emit data points that flow to the car’s computer: The driver door is unlocked; a passenger is in the driver’s seat; the internal cabin temperature is 86° F; the sunroof is opened; the ignition button is pressed; a trip has started from this location.
These data points are processed by the car’s computers and transmitted via cellular radio back to the car manufacturer’s servers.
As the trip continues, additional information is collected: the vehicle location and speed, whether the brakes are applied, which song is playing on the entertainment system, whether the headlights are on or the oil level is low.
The data then begins its own journey from the car manufacturer to companies known as “vehicle data hubs” and on through the connected vehicle data marketplace.
The 37 companies identified by the Markup do not make up the total universe of industry players. But the products they create and services they provide illustrate how the industry works and the breadth of its reach.
The companies each play a unique role and some play multiple roles. They fall into several categories:
Awash in vehicle data, most car manufacturers, or OEMs—original equipment manufacturers—found themselves in an unfamiliar role. “What has given rise to the industry is that most OEMs have recognized that they are better at making cars than they are at processing and handling data,” said Andrew Jackson, research director at PTOLEMUS Consulting Group, which studies the connected vehicle industry.
This created an opening for a new kind of third-party data company, vehicle data hubs, which are at the center of the connected vehicle data market.
Vehicle data hubs ingest vehicle and movement data from several different sources: from OEMs, from other connected vehicle data providers, directly from vehicles using aftermarket hardware (such as an onboard diagnostic [OBD] dongle), or from smartphone apps. The companies normalize the data and offer it to customers in the form of a dashboard or insights derived from analysis or other data products.
In the case of car manufacturers, each captures and stores data differently, creating obstacles to analyzing data across the industry. Hubs solve this problem by gathering data from dozens of car manufacturers and other sources and consolidating it in one place for analysis.
Andrea Amico is founder and CEO of Privacy4Cars, an automotive data privacy company. Amico said of vehicle data hubs, “So, there’s many sources out there. Their business proposition is collect all this data, create massive databases, try to standardize this data as much as possible and then literally sell it. So that’s their business model.”
Many vehicle data hubs market their massive troves of data for applications including insurance, traffic management, electric vehicle infrastructure planning, fleet management, advertising, mapping, city planning, and location intelligence. Many also promote their data as crucial to the future application of autonomous vehicles.
When used to produce insights, the data is usually aggregated. The vehicle data may also be made available through an application programming interface (API), which allows customers to integrate the data into their own apps and services.
Among the notable companies in the vehicle data hub space are INRIX, CARUSO, Verisk, LexisNexis, Otonomo, and Wejo.
INRIX has been around since 2005 and offers parking, traffic, and navigation data to transportation agencies, OEMs, and software developers looking to add mobility features.
INRIX CTO and data protection officer Mark Daymond disputed the vehicle data hub categorization.“INRIX does not transfer or exchange raw data to data customers. We analyze anonymous and aggregated data and create products out of it, then distribute those products to customers. Identities of individuals are irrelevant for our business,” Daymond said in an email to The Markup.
CARUSO offers a data marketplace for European vehicle data. Its “data catalog” section of its API documentation lists 245 distinct vehicle data points. The company did not respond to a request for comment.
Verisk and data giant LexisNexis, both of which have their own vehicle data exchanges, are established players, pitching their services to both OEMs and insurance companies.
Verisk spokesperson Alberto Canal said that the data in the Verisk Data Exchange “… is subject to advance safeguards and entails consumer consent at multiple points of the process.” Canal said that vehicle data is only shared with insurers for underwriting purposes after consent is granted by the consumer.
Jennifer Grigas Richman, director, external communications, at LexisNexis Risk Solutions, said “LexisNexis Risk Solutions prides itself on the responsible use of data and devotes enormous resources and time to protecting consumers’ privacy and their personal information.”
A closer look at Otonomo and Wejo illustrates the huge amount of data under their control and the potential value of the information.
Otonomo is a publicly traded company based in Tel Aviv. Founded in 2015, it was valued at $1.4 billion at the time of its initial public offering (via a SPAC) in August 2021. It boasts on its website that it draws data from 50 million vehicles, “tracking” 330 billion miles and ingests 4.1 billion data points per day.
In its Q1 2022 financial results, Otonomo said it has contracts with 23 OEMs, and in April it acquired The Floow, a “connected insurance technology” provider. Otonomo reported revenue of just over $1 million for the quarter, with a $15 million loss.
Wejo, founded in 2014, is a publicly traded vehicle data hub based in Manchester, England. Wejo claims that its data represents “one in every 28 vehicles in the USA” and contains 16.2 trillion data points and 76.7 billion journeys with accuracy down to 3 meters, with a “1-3 second capture rate.”
Wejo says it has partnerships with 24 OEMs and fleet providers and reported revenue of $568,000 with a loss of $40 million in Q1 2022.
Wejo’s investors include GM, Microsoft, and defense and intelligence contractor Palantir.
Wejo declined to comment.
Many of these companies stress the steps they take to protect driver privacy. These protections generally come in two forms: anonymizing or aggregating driver data and clear consent controls. But due to the sensitive nature of movement and location data, risks are high for violating user privacy.
High Mobility is a vehicle data hub that “enables data connections from cars to services, with user consent,” according to Risto Vahtra, CEO and founder.
The company lists 57 categories of data points including “Trips,” “Seats,” “Driver Fatigue,” and “Heart Rate” among the items available in its data catalog. Its API documentation describes 660 distinct data points, though not all of these data points are used by all OEMs.
Vahtra told The Markup in an email, “Out of about 660 data items, perhaps half are supported in a production environment and not from all OEMs that we have agreements with.”
Vahtra said that the company does not collect vehicle data. “High Mobility does not collect, store, manipulate or store vehicle data. Our solution instead is designed to securely link services, cars and people.”
Bennett Cyphers, a staff technologist at the Electronic Frontier Foundation, said, “The more different ways you’re being measured in your vehicle, the more likely it is that someone can take a stream of data and use the characteristics of all of those different data points to fingerprint a particular user or a particular vehicle.”
Vahtra agreed about this potential risk. “This is definitely a risk for anonymized data. For personalized data this may be true, but not all this data is shared with neutral platforms and third parties.” He said that the one party who does have access to this granular data is the car manufacturers. “The OEMs themselves indeed have access to this vast amount of data points.”
Cyphers said the amount of personal data collected in combination with a lack of regulations for its sale and use is troubling. “When you see the volume of data that’s up for sale, and the lack of regulation in the vast majority of American states regarding how companies can use data, it seems like a match made in privacy hell.”
Otonomo is one example of the dozens of companies that market their attempts at keeping information anonymous. Otonomo describes its platform as having “privacy and security by design” and notes the use of patented “data blurring” technology to protect user privacy. It says it is in compliance with the EU’s General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). It also has an “Otonomo Driver Pledge” page promising drivers the ability to easily grant or revoke access to personal data, customer transparency about sharing data, and adherence to security best practices.
Despite those assurances, in 2021 Motherboard discovered precise, individual vehicle data in free samples on Otonomo’s site. Recently, Otonomo found itself the target of a class action lawsuit filed in California Superior Court for the County of San Francisco by a California BMW owner who alleged in the lawsuit that he never granted permission to the company to collect and sell his personal data. Otonomo had the suit removed to federal district court in California and sought to have the case dismissed, arguing that the plaintiff did grant permission for the car manufacturer to collect vehicle data and that Otonomo did not attach any device to his vehicle as alleged in his lawsuit. Otonomo also argued that tracking people and vehicles were not the same thing. The lawsuit is pending.
Report Deeply and Fix Things
Otonomo did not respond to The Markup’s requests for comment, but in a response to Motherboard’s coverage of individual vehicle data in its free samples, Otonomo spokesperson Jodi Joseph Asiag said, “Privacy is at the core of our platform, technology and vision.”
Regarding assurances of anonymized location data, Cyphers noted, “It is not possible to minimize individualized location data traces whenever you have several different data points about a person’s location or a vehicle’s location over time. It doesn’t matter what else you do to the data, it’s not going to be anonymized because people’s location traces are extremely unique.”
Aggregated data can be safer, but the specific methods used in the process matter. “It’s still very difficult to expose aggregated location data that you know is reflective of the movements of real people in a way that’s privacy safe. But it’s possible. It can be done,” Cyphers said.
One area where the car-as-smartphone metaphor breaks down is users’ ability to grant or revoke permissions for apps to access personal data. Both Apple and Google have built fine-grained controls to review and grant permissions and have strengthened prompts to explain what data will be shared with third parties.
For most cars, progress toward this level of controls is lagging. Comparing the privacy control panels found on smartphones to the typical car, “[t]hat stuff does not exist,” said Privacy4Cars’s Amico. Users must consent to a number of different terms of service, either on the OEM’s smartphone app or on the car dashboard.
Amico said there should be a clear division of consent controls for optional features, versus essential features. “Whenever the data is necessary for the safe function of the vehicle, you should disclose it, you should get consent.”
EFF’s Cyphers echoed this concern, saying that drivers should know exactly what data they are granting permission for and how it will be used. “If you opted into sharing location data for the purpose of accessing a navigation program on your car’s screen, your location data should only be used for the purpose of delivering that service. You can’t grant consent for one thing that you want and then have the car company use that for something else, like selling it to a data broker.”
A new federal privacy bill known as the American Data Privacy and Protection Act was voted out of the House Committee on Energy & Commerce last week. It would ensure that clear user consent is obtained for each data processing purpose, for services offered through “nontraditional devices such as cars.”
Apple has embraced strengthened privacy controls on the iPhone as a marketing tool. A recent Apple ad shows an iPhone user aghast that her personal data is being auctioned off to the highest bidder.
There are signs that car manufacturers are following Apple’s path.
Recently, Porsche announced it was rolling out new fine-grained privacy controls in its luxury Taycan SUV model. In a press release announcing the strategic elevation of user privacy, Porsche’s chief privacy officer and director of group privacy Christian Völkel wrote, “The customer is given full transparency and control over data processing in the vehicle, with simple controls for privacy settings. ‘The customer is in the driver’s seat.’ ”",5
274,"Registration is a two part process:
Registration: Select ticket type, add optional items, input attendee info.
Payment: After you register, select one or more attendees to pay for, then you will either be directed to pay with your credit card, or you can redeem a payment coupon if you have one. Attendee registrations are not valid until they have been paid for.
We accept VISA, Mastercard, American Express, and Discover.
To start the registration process, start by selecting a ticket type. There are several different types of tickets:
- Expo Pass - Provides access to the exhibit hall and free events. The exhibit halls are open on Friday afternoon, Saturday and Sunday.
- SCALE Pass - Provides access to all SCALE sessions, the exhibit hall,
and free events.
A SCALE Pass also includes a Kids Companion Pass for 1 child under the age of 18. You may request a Kids Companion Pass at the registration desk on the day of the event. Please have your child with you.
Please select a ticket type below:
Other Options:
Pay For Previous Registration
If you already registered, and would like to pay for your registration, or if you are paying for other registered attendees, then click the ""Pay For Previous Registration"" button below.
Upgrade Registration
If you already paid for your registration, and would like to upgrade your registration, then click the ""Upgrade Registration"" button below.",2
275,"20-Person Start-Up, 30+ SaaS Services, and $1,183 Monthly Bill
At Bytebase, we believe tools make life easier or even redefine how the world works. Thanks to Figma, designers are now more empowered than ever to collaborate with product managers and front-end engineers; thanks to GitLab/GitHub and their ecosystems, the lives and the workflows of the application development engineers, the operations engineers, and the security engineers, have been revamped. Examples like this inspire us to build Bytebase, an open-source database tool to help DevOps teams manage databases throughout the application development lifecycle and hopefully to make the DevOps engineers’ lives easier.
Currently, we are a 20-member team based in 4 different cities. As tool-makers, we are particular about selecting the best tools for our own use from day 1. But there are too many of them! Some are no-brainers, but some are just too difficult to decide. So we decided to share our list of tools and SaaS services that are helping us grow to serve as a reference for other tech startups of similar or smaller sizes. These tools include what we use for R&D, Marketing, and General Administration. At the end of the blog, you can also find the breakdown of the monthly cost of these tools. I hope this helps!
R&D
- GitHub - code hosting
- Linear - project management
- Neat - GitHub / Linear notifications
- Sourcegraph - code searching
- Gitpod - cloud-based development environment
- Excalidraw - prototype/sketch diagrams
- Figma - design
- Better Uptime - monitoring and alarming on service status
- Auth0 - user sign-in
- Render - service deployment
- Vercel - website hosting
- AWS - service deployment
- Cloudflare - domain name hosting
- Segment - data integration
- Metabase - dashboard
- Paddle - payment collection
- Retool - internal development tool
- Algolia - document searching
Marketing
- Intercom - client engagement
- Mailchimp - Email marketing
- Orbit - community engagement
- Ahrefs - SEO analysis
- Searchramen - SEO analysis
- Google Analytics - user traffic analysis
- Plausible - user traffic analysis
- Hotjar - user behavior analysis
General Administration
- Google Workspace - company Email
- Lark - IM, documentation, office automation
- Slack - IM
- Grammarly - English writing assistant
- OSlash - shortcuts
- Causal - financial analysis
- Pulley - equity management
R&D
GitHub
Bytebase is an open-source project hosted on GitHub, and the whole release process is wired via GitHub Action. Moreover, our official website is hosted on GitHub as well.
Linear
Although you can create Issues and do project management on GitHub, it does not provide a satisfactory user experience. So we use Linear for project management. The one drawback is that although Linear can be integrated with GitHub, it cannot synchronize with GitHub Issue, which is somewhat inconvenient for managing open-source projects.
Neat
Neat is not exactly a SaaS service but more of a Mac-native application and shows GitHub and Linear notifications.
Sourcegraph
GitHub has a search function, but it’s far from satisfactory. So we use Sourecegraph for code searching.
Gitpod
From our GitHub project page, we provide a 1-click button allowing users to deploy Bytebase on Gitpod.
Excalidraw
Excalidraw is a virtual whiteboard tool with a hand-drawn feel. We use it to sketch wireframes, architecture diagrams, or feature explanation diagrams.
Figma
Figma manages our design materials.
Better Uptime
Better Uptime monitors our website in real-time and sends an alarm in case of any anomalies. It also provides a service status dashboard. See our status on status.bytebase.com.
Auth0
To activate Bytebase Team or Enterprise Edition, users need to register on our Hub and purchase a license. We use Auth0 to enable registering with GitHub accounts.
Render
The Bytebase demo site, Bytebase Hub, and all our databases are hosted on Render, the new Heroku. It provides web service and PostgreSQL hosting.
Vercel
Our official website bytebase.com is hosted separately on Vercel. We use Vercel because it has an extensive edge network, making access fast for people worldwide.
AWS
We host gitlab.bytebase.com for testing our VCS integration and demo site. We didn’t use Render for two reasons:
- We built GitLab early on, so it is difficult to migrate data.
- GitLab requires more resources. There will be a decent increase in cost if we deploy t3a.large (2C8G) on Render.
Cloudflare
Bytebase-related domain names are hosted on Cloudflare. Previously, we purchased our domain names on name.com, and plan to consolidate them on Cloudflare later.
Segment
We collect anonymous data for our products and website, which are sent to Segment. We then instruct Segment to forward data to the downstream destinations such as our PostgreSQL database on Render.
Metabase
We use Metabase to build a dashboard for internal data visualization. The data is collected through Segment and saved in the PostgreSQL database on Render.
Paddle
Paddle is where we collect payments from users. We didn't choose Stripe because Paddle can save our tax problems as a Merchant of Record (MoR). As a tradeoff, it is more costly than Stripe in commission fees.
Retool
We use Retool to build a list for displaying registered users, with which our team members can process user refunds instantly.
Algolia
It is used to search for content on our docs site.
Marketing
Intercom
Some users may contact us through the small bubble in the lower right corner of the official website.
Mailchimp
Mailchimp manages our newsletter subscriptions. It also sends some admin emails, such as informing users when the trial period is ending.
Orbit
Orbit observes user engagements on our GitHub repositories.
Ahrefs
Ahrefs is used for SEO research.
Searchramen
Although the same function is also covered by Ahrefs, Searchramen can provide a more straightforward interface to view the current ranking and keywords stats quickly.
Google Analytics
Google Analytics analyzes the user source and page visits.
Plausible
Google Analytics also covers the same function, but Plausible provides a more user-friendly interface to check the user source and page visits.
Hotjar
Hotjar can replay users’ browsing behaviors of users on the official website, through which we can identify breakpoints in designing the official website workflow.
Daily Operation
Google Workspace
Every team member owns a Google email account with @bytebase.com. We use many SaaS services and almost all support login through Google accounts. We also use Google Docs when documents are expected to be revised repeatedly, thanks to the ""Suggesting"" mode.
Lark
Lark is responsible for our internal activities, including IM, documentation, meetings, and OA.
Slack
Slack is used to communicate with our customers. We also thought about building a community on Slack. However, different Slack spaces require registration, which brings an unsatisfactory user experience, and the overall vibe on Slack feels more professional.
Grammarly
We purchased Grammarly Business Edition to assist in English writing.
OSlash
From Google's go/ to the famous Stripe's o/, shortcut service is regarded as a must for Silicon Valley companies. Bytebase uses many SaaS services and creates many internal documents, which makes it difficult to remember all kinds of links. However, OSlash can convert these page links into more memorable ones. We also made an internal document on Lark noting all our shortcuts, which opens by o/link.
Causal
Casual is used for financial model analysis. An intuitive model of financial reports is built after filling in the financial figures and making a few simple drag-and-drop operations, which is much easier to learn than Excel.
Pulley
Pulley is used to manage the company's equity. It helps us track the company's cap table, issue and manage employee equities.
Monthly Spending
R&D
|Service||Cost|
|GitHub||$0|
|Linear||$180|
|Neat||$0|
|Sourcegraph||$0|
|Gitpod||$0|
|Excalidraw||$60|
|Figma||$15|
|Better Uptime||$0|
|Auth0||$0|
|Render||$50|
|Vercel||$20|
|AWS||$100|
|Cloudflare||$0|
|Segment||$0|
|Metabase||$0|
|Paddle||$0|
|Retool||$0|
|Algolia||$0|
|Total||$425|
Marketing
|Service||Cost|
|Intercom||$70|
|Mailchimp||$20|
|Orbit||$0|
|Ahrefs||$80|
|Searchramen||$20|
|Google Analytics||$0|
|Plausible||$8|
|Total||$208|
General Administration
|Service||Cost|
|Google Workspace||$130|
|Lark||$0|
|Slack||$50|
|Grammarly||$200|
|OSlash||$50|
|Casual||$0|
|Pulley||$120|
|Total||$550|
The total monthly spending is $1,183!
Summary
We use over 30 SaaS services, many of which are the best tools in the industry, the wisdom of the top team, and ended up costing us $1,183/month, not a bad deal!
Here are some data to show how these tools have improved our efficiency:
-
The R&D team of just over 10 members releases a new version every two weeks, and each version has 100 to 150 PRs submitted.
-
The developer marketing team, consisting of 3 members, produces 3 - 5 articles weekly. In addition, they are responsible for maintaining technical documents and all marketing activities.
-
A part-time administrative/HR, dealing with all affairs in the company's back office, aside from R&D and marketing (of course, we also hired external financial and legal advisers).
Inevitably, we have made detours in terms of tool selection and also grew out of certain tools as the company grows. We will share more thoughts behind our choice of specific tools in a future post. Stay tuned.",5
276,"The data brokers who’ve made fortunes from collecting and sharing millions of people’s personal information tend to fly under the radar. Names like LiveRamp or RELX might not be familiar to most Americans, but they’re making themselves known on Capitol Hill.
Collectively, data broker spending on lobbying in 2020 rivaled the spending of individual Big Tech firms like Facebook and Google. The Markup searched lobbying disclosures in the U.S. Senate’s Lobbying Disclosure Act database and the watchdog Center for Responsive Politics’ tool OpenSecrets for the names of companies that registered as data brokers in Vermont or California. Those states are the only two that require companies to annually disclose that they collect, sell, or share people’s personal information without having a direct relationship to them.
See our data here.
All in all, we found 25 companies whose combined spending on federal lobbying totaled $29 million in 2020. Many of the top spenders were not pure data brokers but companies that nonetheless have massive data operations. Oracle, which has spent the past decade acquiring companies that collect data, spent the most by far, with disclosure documents showing $9,570,000 spent on federal lobbying.
For comparison, of the Big Tech firms with heavy lobbying presences, Facebook spent $19,680,000, Amazon $18,725,000, and Google $8,850,000 in the same period, according to the Center for Responsive Politics. Public Citizen, a consumer advocacy group, found that Big Tech spent $108 million collectively on lobbying in 2020.
Oracle has its own data collection arm but has also built its portfolio by buying up companies like DataRaker, Compendium, and Crosswise. The companies, which were acquired in 2012, 2013, and 2016, respectively, take data from a variety of sources. DataRaker gets data from millions of smart meters and sensors for utilities companies, while Compendium delivers targeted ads. Crosswise allows Oracle to track people across devices, claiming to process data from billions of devices every month.
Oracle also acquired Datalogix, in 2014, which connected offline purchases to online profiles. Additionally, Oracle combines datasets from more than 75 other data brokers, which it calls “the world’s largest collection of third-party data.”
Report Deeply and Fix Things
Our report comes as the data broker industry is not only growing but also facing scrutiny for the first time. California recently passed a statewide privacy law that establishes an agency focused on regulating data privacy issues. Virginia and Maine have also passed regulations to protect people’s online information.
California’s and Virginia’s privacy laws hit at the core of what data brokers do by requiring companies to delete data collected about people upon request and allowing people to prevent their personal information from being used for targeted advertising. Maine’s privacy law prevents internet service providers from sharing personal information with data brokers until people give “express, affirmative consent.”
And the past year also saw concerns raised about how well these brokers protect their massive troves of data—Oracle, for instance, suffered a data breach after security researchers found billions of records from its BlueKai data collection were left exposed on a server.
The Markup contacted all 25 companies for comment on their lobbying activities. Several companies, like Inmar Intelligence and LiveRamp denied being data brokers, though they had self-identified as such to California and/or Vermont regulators.
“Inmar Intelligence does not generally consider itself a data broker though one of our entities, Inmar-OIQ, LLC, is registered as such in a couple of states,” Holly Pavlika, a corporate marketing senior vice president for Inmar Intelligence, said.
The industry itself is hard to define—many companies, including tech giants, make money off of personal data, though the technical details of how they use that data vary. So The Markup relied on companies that self-reported to Vermont and California as members of the industry. The list, 480 companies long, shows just how pervasive it has become for companies to traffic in personal information.
Report Deeply and Fix Things
The list includes businesses that are primarily data brokers, like CoreLogic, which claims to have collected data on 99 percent of property and homeowners in the U.S. and spent $215,000 on lobbying in 2020; and Acxiom, which spent $360,000 on lobbying in 2020 for issues related to data security and privacy. Acxiom’s InfoBase boasts of datasets on more than 250 million people and collects information including location data, purchases, interests, life events, and behaviors, according to its marketing material.
Our list also includes credit monitoring services like TransUnion, Equifax, and Experian, which each spent about $1.4 million lobbying in 2020 on issues related to credit score reform, like the Protecting Your Credit Score Act of 2020, the Credit Access and Inclusion Act of 2019, and the Clarity in Credit Score Formation Act of 2019. TransUnion also owns subsidiaries like Callcredit, Iovation, and Signal, which has been used for collecting and profiling users for gambling apps, according to The New York Times.
Some registered data brokers also didn’t lobby specifically on privacy issues. Refinitiv, which collects data on people for its risk assessment tool, spent $120,000 lobbying on banking issues, the National Defense Authorization Act for Fiscal Year 2021, and cybersecurity legislation.
Notably, our tally also does not include lobbying by trade associations that data brokers are a part of, such as the Interactive Advertising Bureau and the Digital Advertising Alliance.
Of the data brokers who spent the most on lobbying, Oracle far outspent its peers
Lobbying spend in 2020 by data brokers
Oracle, the biggest spender, used lobbyists to advocate on issues like annual defense and intelligence budgets and “competition and antitrust in the mobile telecommunications and digital advertising industries,” according to public records.
The company didn’t respond to requests for comment.
The second largest spender was Accenture—a technology and consulting company that boasts a marketing and analytics branch called Accenture Interactive. According to its marketing materials, the company can combine datasets from sources including people’s purchase history and location to help its clients build customer profiles for advertising.
In 2020, the company spent $3,250,000 lobbying on issues like artificial intelligence, the Digital Dollar, and COVID-19 contact tracing, according to public records.
When The Markup reached out to Accenture, the company pointed us to two statements CEO Julie Sweet made on data privacy legislation in 2018. The statements called for a federal privacy law that would preempt state laws.
PricewaterhouseCoopers, a major accounting firm, spent $2,820,000 lobbying the federal government in 2020, third most among registered data brokers.
$29M
The total amount 25 data brokers spent on federal lobbying in 2020.
Source: U.S. Senate
PWC collects data from advertising networks and data analytics partners including personal information like names and addresses, which it uses to help clients personalize advertising campaigns, according to the company’s privacy statement.
Spending went to monitoring privacy legislation and accounting and auditing issues.
PWC didn’t respond to a request for comment.
Other big spenders included Deloitte, which was awarded a $106 million Department of Defense contract to build a development environment for the Joint Artificial Intelligence Center this summer. The company spent $2,400,000 on federal lobbying in 2020, including on bills like the Artificial Intelligence in Government Act and the Artificial Intelligence Initiative Act.
Deloitte is an auditing and advisory company but provides services like PredictRisk, which uses information including people’s hobbies, interests, and financial data provided by data brokers to generate a health risk prediction score and help life insurance companies figure out how likely people are to buy their products.
And RELX, which spent $2,375,000 on federal lobbying in 2020, including on data privacy bills like the Data Accountability and Trust Act, the Information Transparency & Personal Data Control Act, and the Data Broker Accountability and Transparency Act; and on bills related to data privacy and COVID-19, including the Covid-19 Consumer Data Protection Act and the Exposure Notification Privacy Act.
RELX is a major data broker that owns companies like LexisNexis and ThreatMetrix, which has customers in law enforcement, insurance, and financial services. ThreatMetrix alone boasts tracking on 4.5 billion devices, according to a statement from RELX in 2018.
Deloitte and RELX didn’t respond to a request for comment.
In addition, many other data brokers spent lower amounts on lobbying efforts
Lobbying spend in 2020 by data brokers
Some of the bills targeted by lobbyists would have regulated the data broker industry, though disclosures do not specify whether they lobbied for or against the bills.
The Data Accountability and Trust Act looked to establish security standards and require postbreach audits for data brokers and also prohibit collecting information under false pretenses. The Information Transparency & Personal Data Control Act would have required data brokers to get consent to collect sensitive data and go through an annual privacy audit.
The Data Broker Accountability and Transparency Act of 2020 wanted to mandate opt-outs from data brokers and for the FTC to create a national list of data brokers.
While lobbying records don’t always list specific bills, filings show that RELX paid lobbyists to address all three bills. Deloitte records show that some of its lobbying efforts went toward addressing the Data Accountability and Trust Act.
Both COVID-19 data privacy bills looked to provide stronger controls over data related to contact tracing.
None of the bills named in this story passed Congress, except for the National Defense Authorization Act, which was enacted.
Report Deeply and Fix Things
Some of the companies that showed up in lobbying records faced other sorts of pressure during 2020.
For instance, Apple and Google banned X-Mode’s trackers from their app stores last December following a series of reports from Motherboard on how the location data broker was providing information to contractors who passed that information to the U.S. military. X-Mode spent $30,000 on lobbying in the last quarter of 2020, during the height of the public pressure.
Both X-Mode and Venntel, another location data broker, which spent $160,000 on lobbying, are facing scrutiny from Congress over their location data sales. Sen. Ron Wyden, a Democrat from Oregon who signed on to a letter calling for an investigation on Venntel, called the data broker industry “out of control,” in a statement to The Markup.
“Americans are learning more every day about the secretive and shady data broker industry and they’re demanding new laws to protect our privacy,” Wyden said in the email to The Markup. “It’s no surprise data brokers are trying every avenue they can think of to ward off the common sense protections Americans desperately need.”
X-Mode and Venntel didn’t respond to a request for comment.
Some companies said they were lobbying to have a voice on legislation, including potential federal laws on privacy.
“With increased momentum, attention and legislative activity in multiple states, we support a federal data privacy law that can rebalance the system and set standards that rebuild trust with the people providing the data—consumers,” Christine Travis, a senior communications director for LiveRamp, said in an email. “A federal approach to data privacy and security is better than a patchwork of state laws for all stakeholders.”
LiveRamp was the top lobbying spender among companies whose primary focus is collecting data for advertising purposes. The company, which connects people’s activity across the web and from offline purchases for advertisers, spent $630,000 on lobbying in 2020 on issues such as the Augmenting Compatibility and Competition by Enabling Service Switching (ACCESS) Act and Privacy Shield.
Privacy Shield was a framework for transferring data between the European Union and the U.S. but was declared invalid last July for failing to meet the EU’s privacy regulations.
LiveRamp collects its datasets from a multitude of sources, including credit card transactions and location data, and connects it to people’s online profiles for advertisers. The company claims to have data on more than 250 million Americans.
Travis denied that LiveRamp is a data broker despite being listed on California’s data broker registry, insisting instead that the company is a “data connectivity platform.”
Experts said scrutiny and oversight is fairly new to the data broker industry.
“When somebody shows up on the lobbying records, or in meetings or in trade associations, it just tells me they’ve probably recently woken up to this issue and they see a real threat to their business model by privacy regulations,” Hayley Tsukayama, a legislative activist for the Electronic Frontier Foundation, said.
Others, however, said Congress is not doing nearly enough to regulate the unwieldy industry.
“What is widely understood now in Congress and among independent agencies like the FTC are the ways in which large tech companies like Facebook and Google are extracting data from consumers and using that to monopolize markets like the advertising industry,” Jane Chung, a Big Tech accountability advocate at the consumer advocacy group Public Citizen, said. “What a lot of people don’t understand is how data brokers fit into that ecosystem.”",5
277,"Re-Thinking Strategy.
The Future Does Not Fit in the Containers of the Past. Edition 109.
What is strategy?
Strategy is Future Competitive Advantage.
What will the future look like? What will people need and expect? How will demographics, technology and other global shifts create new competitors or recharge current competitors and how will categories blur, blend and maybe even disappear?
Amidst these new expectations and changing competitive dynamics what advantage will your company offer? A differentiated or better product? A competitive moat of network effects, scale or some other dynamic? A better experience? Speed and value?
Very few companies even today get strategy right primarily because they do not understand the exponential impact of technology but also because they make the cardinal mistake of defining their category and competitive set looking backward versus forward.
One example among many is the auto category which defined the key drivers of their category in ways that did not see a Tesla or an Uber for years after they began to scale. How could software be as, if not more, important than hardware? How could electric be better than internal combustion engines? Do most people need the expenses of owning cars or do they just need on demand mobility?
Why the strategy of every organization needs to be re-thought.
If a key to strategy is the future what happens when the contours of the future shift dramatically?
In the past five years things have become far more complicated.
More moving parts, buzzing around at faster speeds in ways that are more interconnected to each other.
Many of the assumptions that underpinned strategy have not only shifted but, in some ways, the exact opposite of what firms believed is coming true.
Here are just a few “beliefs” that now need to be queried:
a) Expanding populations: When calculating “Total addressable market” or “rate of growth” most companies factored in growing populations.
Now the exact reverse is beginning to happen. Populations have started to decline in most advanced economies at a frightening rate.
b) Scale is a competitive advantage: While scale still matters it matters far less than ever before (except for a few businesses where it matters even more) and the very nature of what is scale is changing with many old forms of scale being competitive disadvantages!
c) Capital and talent are in abundant supply: Capital continues to remain in abundant supply but has become a bit more selective, but talent is in such short supply that the greatest ROI for businesses may come from unleashing the untapped capacity of their talent. Return on Human Capital will be a key measure of return joining Return on Capital and other metrics.
Population declines in advanced markets.
It takes 2.1 children per woman to keep the population flat.
That number in most advanced countries is less than 1.7 and declining.
The latest UN projections suggest that the world’s population could grow from 8 billion people to a peak of 10.4 billion before the end of this century. But if we exclude population growth in Africa the population of the world has peaked and, in a few countries, we are starting the great shrinkage.
The Shanghai Academy of Social Sciences team predicts an annual average decline of 1.1% beginning in 2021 pushing China’s population down to 587 million in 2100, less than half of what it is today.
Every business should interrogate their strategy to ask two questions a) how will our plans be impacted in our key markets with declining populations and b) what is our plan for the continent of Africa which will contain more 40 percent of the global population in 2100?
Scale may no longer be the competitive advantage we think.
One of the long-standing tenets of business are the advantages of scale.
Scale has provided companies with many benefits from higher margins due to lower costs, to insulation from competition due to moats of marketing spending and widespread distribution.
Over the past decade however the benefits of scale have diminished and in some cases are proving to be a disadvantage:
Scale of Distribution: With direct-to-consumer marketing enabled by the Internet and platforms like Shopify, widespread retail distribution is no longer as effective an advantage. Clearly distribution matters but there are ways to route around the big stores by going direct and creating demand that forces buyers to stock your product.
Scale of Communication: New media behaviors by people particularly search and social are leading to communication channels where spending power is no longer a competitive edge as it was in television or print where marketers cornered key inventory at advantageous prices. Platforms like Facebook enable millions of small businesses with personalization and targeting capabilities to discover customers and be discovered. As content supported by advertising declines to less than a third from nearly two thirds (scale of spending while still being important is losing its potency.
Scale of Manufacturing: The “Everything as a service” platforms from Amazon Web Services to Foxconn allow smaller companies to gain the edges of scaled manufacturing, distribution, and technology without any of the legacy disadvantages of size.
Scale of People: From IBM to GE to Unilever to Walmart there are hundreds of thousands of employees and therefore ability to recruit and grow a range of talent and offer career advancement. Scale of people continue to be important to execute complex and large tasks but there are also new ways to re-aggregate talent. And a generation of talent wants to work in smaller and more entrepreneurial environments. In the post Covid world as we move to unbundled workplaces there will be far more ways to build teams both globally and in real time than ever before.
Legacy scale still matters in most industries and is critical in quite a few like semi-conductors. In fabricating advanced chips, a new fabrication plant can cost over 4 billion dollars and there is no way around scale. Today TSMC (Taiwan Semiconductor Manufacturing Company) dominates due to its scale.
However, while we can never underestimate legacy scale, there are new forms of scale that every smart company recognizes and is expanding into.
Here is the gentleman with the greatest following on You-Tube who launched the first of a chain of pop-up burger restaurants last Sunday.
The New Scale.
Scale of Data: Increasingly companies are realizing that collecting, refining, and leveraging data is what is driving the modern fast growing and highly valued companies from Amazon to Google to Uber. Data enables a new form of scale which is that of mass personalization.
Scale of Networks: On the Internet network effects play a dominant role in creating winners. Dominant platforms such as TikTok, Facebook, Netflix, and Tencent (WeChat) enjoy flywheel effects of more users attracting more users and therefore marketers and businesses.
Scale of Influence: Today individuals have tens of millions of Instagram followers or leverage Twitter and TikTok to reach hundreds of millions of people with single posts and tweets. If you look at scaled entities on social media, they are individuals. People are seen as authentic and certain folks like Elon Musk can move markets.
Scale of Talent and Ideas: One of the lessons of history is that every advance in technology places a premium on superior talent. Technology is a lever and when married with great talent a company enjoy major scale effects.
A vivid example of how the new scale works is Kylie Cosmetics. Kylie cosmetics was launched by Kylie Jenner to sell lipstick. In less than two years Kylie Cosmetics sold 900 million dollars of product making the 21-year-old the fast billionaire ever. Kylie cosmetics had less than 50 full time employees, outsourced manufacturing to Seed Beauty a contract manufacture and all e-commerce and fulfillment to Shopify. The single media channel besides PR that Kylie Cosmetics used was Kylie Jenner’s Instagram account with 120 million followers+ (more than the ratings of the top 10 prime time television shows combined)
And even new scale can be disrupted as TikTok’s focus on video and entertainment and a new algorithm allowed them to overtake Meta indicating that Meta’s multi-billion-person social graph which married great data and network effects of new scale could not stop a juggernaut from rising in less than five years!
One of the areas every leader should study is where the Internet is heading. Web 3, Metaverses, Tokens/Wallets and DAO’s have many challenges and noise around them but they are truly revolutionary and will accelerate power to talent and individuals in exponential ways.
Ideas and talent are the true moats everything else can be bought pennies on the dollar.
The scarcity of talent.
Talent is all. Talent is in short supply. Talent needs to be paid attention to if any strategy is going to work in the future.
The charts above which are for the United States indicate the scale of the challenge anyone hiring talent in the US will face as populations age, immigration stalls while the number of jobs grow.
Add to that the reality that over a quarter of people have moved hundreds of miles from their original office, many people have side-gigs and have begun portfolio careers and that one can work for a spectrum of global companies from anywhere where one has a good Internet connection!
Growing, leading, attracting, retaining, and investing in talent is going to be a key strategic advantage.
Every human and individual and employee with the right support and placement can be highly productive and valuable.
Every strategy deck should have a significant section on unleashing talent and not of competitive dynamics, financial metrics and total addressable market and other data.
Companies grow when talent grows.
Next time you here about a company changing their CEO no matter what they say what is really happening is one or more of the following:
a) They have over invested in China or have overestimated growth in and therefore the total addressable market in the US, Europe, Korea, and Japan.
b) They have over built particularly too many stores or too many theaters or just too many thinking they could crowd out competitors. Now they have a sea of sameness that looks dated and is a legacy cost versus an asset.
c) Their leadership has a talent problem or there has been a break down in the social contract between the people who do the work and are on the frontlines and management.
Just released: The latest episode of What Next? The amazing Renetta McCann on unleashing talent:
Renetta McCann, Chief Inclusion Experiences Officer at Publicis Groupe, and former global CEO of Starcom Mediavest Group reflects on what she’s learned after nearly four decades in the industry. A strategist working at the intersection of business and people, she discusses complexity, individual learning, and the development of people managers. Thirty minutes that will make you re-think a lot about talent and managers.
Join 25,000 people every week in reading this FREE thought letter below:
For more about Rishad Tobaccowala click here.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
So glad to see that you are taking my advice and working the Kardashians into your pieces! It will be interesting to see if there is actually any payout in the search/readership analytics...",2
278,"Is ""acceptably non-dystopian"" self-sovereign identity even possible?
by Molly White on
← Back to the collection
Anonymity and trustlessness are central to the crypto world. People don’t have to attach real-world identities to crypto wallets, and communities at least nominally try to avoid placing trust into institutions like governments or big tech companies. But with the crypto world increasingly trying to move beyond simple payments and NFT trades, they are running up against these limitations.
Decentralized autonomous organizations, or DAOs, are often governed with a “one token, one vote” model that gives power to the wealthy. Though some DAOs may believe this is the ideal governance model, many others have adopted it because there aren’t a ton of promising alternatives. Unlike in offline organizations and societies where centrally-controlled identifiers or even just in-person attendance are fairly successfully used to ensure one individual gets one vote, this has been a very difficult nut to crack in the crypto world, where one individual can trivially create endless new wallet addresses—known as a Sybil attack.1
Loans in the crypto world tend to be overcollateralized, requiring users to put up more value in crypto than what they receive in a loan. Although this works reasonably well for users who have already accumulated capital and want to use that capital in a different format (i.e. borrowing fiat currency against their crypto holdings), it doesn’t work well for the more standard reason people take out loans: because they don’t already have the money they need. Needless to say in an ecosystem whose advocates like to promise will “bank the unbanked” and help the marginalized, this is a bit of a setback. The need for these overcollateralized loans again stems from a lack of indicators to a person’s trustworthiness like those that are used in traditional finance, such as credit scores or banking records. Overcollateralized crypto loans are also made even more necessary on some anonymity-preserving loan platforms that choose not to require know-your-customer (KYC), who otherwise would see an influx of anonymous users borrowing money and making off with it.
So, increasingly, we’re seeing conversations around topics like: how can we verify a statement about a person (or crypto wallet) is true without relying on the state or another centralized entity? How can we ensure that a wallet represents a unique individual?
Ethereum co-founder Vitalik Buterin has been talking about “soulbound tokens”.2 Jack Dorsey just launched “Web5”, a buzzwordy project focused on decentralized identity.3 Projects like Proof of Humanity,4 BrightID,5 and WorldCoin6 are all tackling Sybil prevention in their own ways. Web3 companies like Spruce7 and Disco8 have emerged to try to tackle self-sovereign identity (that is, identifiers that are controlled by users rather than by central entities) in the blockchain world and elsewhere.
Contents
- Some context
- Concepts
- The trilemma of digital identity
- Proof of personhood
- Verifiable attestations
- Soulbound tokens and negative attestations
- Verifiable credentials
- Data custody and security
- Acknowledgements
- Notes
Some context
Self-sovereign identity is not a new concept, nor are the problems crypto is facing around online identity unique to crypto. Some of the solutions that have been discussed recently don’t necessarily involve blockchains, and are broad approaches to digital identity.
I’ve had opinions on and concerns about issues pertaining to online identity and credentials long before I started researching crypto, and most of my opinions on this topic apply regardless of whether blockchains are involved or not. But there has been a resurgence of interest in self-sovereign identity because of crypto and web3, and that has motivated this essay.
Self-sovereign identity is one of those things that sounds wonderful at a glance, but can get pretty dystopian the more you start to think about it. Conversely, centrally-controlled identifiers left to governments and corporations have their own obvious and serious issues particularly when it comes to marginalized groups, oppressive governments, and access. This essay is not intended to describe self-sovereign identity and related topics as universally bad or universally good, but rather to raise some issues that I think desperately need to be considered as people are working on these problems.
The technology industry, and the crypto industry especially, has long adopted a “move fast, break things” approach to innovation. Companies and developers have sacrificed quality, security, and user safety in the name of innovation, writing off collateral damage to real human beings as simply a cost of progress. Considerations of ethics, user safety, privacy, security, “how can this be used for evil”, and “is this even good for society” often come as a belated afterthought, and “testing in production” is the norm. Regulators and legislators lag behind, often only intervening once enormous harm has been done (and often not even then).
Self-sovereign identity is not a field where “move fast, break things” is acceptable. People are already talking about capturing enormously sensitive information in digital form, issuing attestations about other individuals either with or without their consent, and, in some cases, recording all of these things to immutable blockchains where they would be stored indefinitely. This terrifies me.
Concepts
- Decentralized identifiers (DIDs): a proposed recommendation9 for unique identifiers that provably belong to an individual or organization. These can represent various concepts: a person might have multiple DIDs representing identifiers like their Ethereum address, their email address, their driver’s license number, or their national ID number. Similarly, an organization might have DIDs representing their phone number or their employer identification number. These can be issued by the individual or a third party (for example, a government might issue the DID representing a national ID number), and the identity of the issuer and the recipient can be cryptographically proven. These DIDs are used to sign verifiable credentials.
- Proof of personhood: a means of establishing that an identity like a wallet address corresponds to a unique individual in a network. This is also sometimes called “proof of humanity”, though that term also describes a specific organization implementing one approach to PoP.
- Self-sovereign identity: the general term for an approach to online identity that is controlled by the user, rather than maintained by a central party.
- Soulbound tokens: Vitalik Buterin and a group of others have been recently working on the idea of “soulbound tokens”: non-transferable, unique tokens much like NFTs that are bound to “souls” belonging to unique individuals. They describe these being used to represent concepts like birth certificates or college diplomas, which unlike NFTs should not be transferable.
- Verifiable credentials: a recommendation10 describing how digital credentials can be issued and proven. Someone might have a verifiable credential that represents things that we might normally think of when we think of “credentials”: say, a college diploma, professional certification, or security clearance. But these can also be used to certify other things: proof that someone completed a course and earned a given grade, or attended a specific event, or purchased an item, or became a member of an organization. Someone could even issue a verifiable credential to describe themselves: for example, they could state their favorite color via VC.
The trilemma of digital identity
Trilemmas are a set of three goals, where all three are not simultaneously achievable.
Some crypto-literate readers will already be familiar with the blockchain trilemma: decentralization, scalability, and security. Blockchains end up making tradeoffs in one goal to achieve the other two (though there are those who argue all three can be achieved, but that’s another subject entirely).
Digital identity has its own trilemma: privacy, Sybil resistance, and decentralization.11
Today’s blockchain ecosystems almost universally sacrifice Sybil resistance for decentralization and privacy. But increasingly, people are trying to tackle the problem of Sybil resistance, causing organizations to make trade-offs in decentralization, privacy, or often both.
Bitcoin, Ethereum, and most other cryptocurrency projects don’t rely on a central authority to record identities, and users don’t have to disclose any personal information when they create wallet addresses, but as a result, projects using those addresses as the sole identifiers are vulnerable to Sybil attacks.
Some crypto projects seeking to avoid Sybil attacks require additional KYC checks, where users submit government-issued identification documents to prove their identity. This accomplishes Sybil resistance, but at the expense of privacy and with the added reliance on other forms of identification that are neither privacy-preserving nor decentralized.
Proof of personhood
Proof of personhood is an umbrella term for various attempts to prove that a person is unique within a network, or even unique in the world. They seek to solve the Sybil problem, but so far these projects sacrifice privacy and/or decentralization to varying degrees of dystopianism.
Some might already be familiar with Worldcoin, a Sam Altman brainchild that promises to eventually implement universal basic income. MIT Technology Review6 and BuzzFeed News12 both published excellent investigative articles into the project nearly simultaneously in early April. For those who are not familiar, the project seeks to solve the Sybil problem by requiring users to provide iris scans and various other biometric data by staring into a large chrome orb. Worldcoin would argue that its alpha-stage product is, or at least will eventually be, privacy-preserving, as they intend to store only hashes of the iris data rather than the data itself. Whether or not they are deleting the biometric data as they promise they will (eventually, probably), it’s tough to argue that one could achieve proper anonymity in a system where an “orb operator” interacts with them in person and provides them with a crypto address. It’s certainly not decentralized, with data all being stored in opaque Worldcoin systems. It would also be difficult to describe this approach as self-sovereign in any way—the user has no control over the identity that is created for them and stored on Worldcoin’s system (which certainly would seem to raise some concerns from a GDPR perspective as well). I don’t think the dystopian nature of a company that uses a chrome orb to collect not only iris scans, but high-resolution images of users’ faces and bodies, as well as “contactless doppler radar detection of [their] heartbeat, breathing, and other vital signs”, needs much explaining.6
BrightID is another project aiming to verify “universal proof of uniqueness”. Users join a social graph, attesting to the identities of people they know and trust in real life. The project doesn’t rely on a central entity to maintain the store of information, so it achieves the decentralization goal, but its entire web-of-trust system relies on people revealing their identities to some people within the system. BrightID also reveals a massive web of verifications between users and the level to which they’ve reported knowing one another. With the emergence of Facebook this type of privacy intrusion is perhaps fairly normalized, but it’s certainly a far cry from the “privacy” users often seek and expect from blockchain systems. After all this, BrightID is still vulnerable to Sybil threats: a person simply needs to find disjoint groups of people to each verify new identities. BrightID also incorporates a dystopian “social credit”-style pattern, where not only are users penalized for “bad behavior”, but so too are their connections. According to their documentation: “Some algorithms might take it as a bad signal if your already known connections consider you as someone they have just met or a suspicious connection. Your already known connections’ bad behaviour might also negatively impact your verification.”
Proof of Humanity is quite similar in its approach to BrightID. It adds financial costs to the system, where users must pay (or crowdfund) a deposit to have their profile verified. There’s also a financial “bounty” for users who challenge deceptive profiles. Someone can tell me which dystopian sci-fi novel is based around this premise, because I’m sure it’s already been written. Like Worldcoin, PoH also seeks to implement universal basic income.
Various other systems exist to try to reduce the likelihood of duplicate wallets, if not prevent it outright, in various ways:
In some cases, standard bot-prevention technology like CAPTCHAs is used, not to prevent someone from creating multiple identities in a network but to at least make it annoying to do at scale.
Other systems accumulate massive amounts of data from NFT collections to try to discern the likelihood that a wallet might be a duplicate. For example, proof-of-attendance NFTs (POAP NFTs, often just called POAPs) aim to prove that a person attended a real-life event or experience, and so such systems will take two wallets holding a POAP from the same event to mean they are likely not operated by the same individual. Other NFTs are issued only after the recipient completes a “quest”—some level of participation or effort that is not trivial—and these are used as a signal of uniqueness under the idea that it would be prohibitively difficult for a person to repeat the effort across many wallets.
Some projects dream of a future state where all achievements are represented on-chain, and so they can look at a wallet containing things like a college degree, mortgage loan, and history of attendance at real-world events and presume that one person is not widely duplicating all of these things. Though this might be reasonably Sybil-proof, this is simply not feasible today, and it sacrifices privacy to a horrifying degree.
Verifiable attestations
Much of the recent conversation around digital identity is not focused specifically on the Sybil problem, but instead on verifiable attestations: attestations from one verifiable party about another verifiable party that a statement is true. Though the term “credential” is frequently used by those familiar with W3C’s Verifiable Credentials proposal, the concept might be more accurately described as a “verifiable statement” or “verifiable attestation”. Actual implementations vary, from the W3C’s Verifiable Credentials to Vitalik Buterin’s “soulbound tokens”. For now, I will refer to the broad concept encompassing both of these implementations as “verifiable attestations”.
Proposed use cases for verifiable attestations do encompass what most would think of as “credentials” today: A university might attest that a student earned a given diploma. A government might attest that a person is a citizen. A state might attest that a driver earned their driver’s license. An employer might attest that an employee works for them.
But others have talked about using verifiable attestations more broadly: An event organizer might attest that a concertgoer attended a given concert. A church might attest that an individual is a member of their congregation. A video game developer might attest that a player completed a given level. A brand might attest that a customer bought their product.
The one thing these attestations have in common is that they should not be transferrable: if an entity attests that you earned a diploma or a driver’s license or attended a concert, you shouldn’t be able to transfer that attestation to the highest bidder to claim as though it applied to them.
These attestations, proponents argue, would enable a much more robust level of interaction within the crypto world. These attestations, I argue, sound like a privacy nightmare.
Soulbound tokens and negative attestations
A recent episode of the Bankless podcast featured Vitalik Buterin and Evin McMullen discussing the pros and cons of Buterin’s brainchild, soulbound tokens, and McMullen’s preferred form of attestation, verifiable credentials.
The somewhat dramatic name, “soulbound tokens”, comes from the World of Warcraft concept of soulbound items that can’t be transferred between players. The May 2022 paper he co-wrote with E. Glen Weyl and Puja Ohlhaver describes how the broad idea simply needs to be “acceptably non-dystopian” to be worth pursuing, which seems both like an awfully low bar, and also makes me worry about the definition of “acceptably” they’re going with.
One reason that soulbound tokens (SBTs) are preferable to verifiable credentials, Buterin argues, is that they enable “negative attestations”. He uses loans as an example. Even if you could verify based on someone’s positive attestations that a person met your threshold of trustworthiness to qualify for a $10,000 loan, you would probably also want to verify that they hadn’t already taken out 100 different $10,000 loans from other lenders. Buterin describes this as a “negative” attestation—something that a bad actor might wish to conceal in order to take advantage of a system. In his system, a lender providing a loan could issue an SBT representing the $10,000 debt, and the borrower wouldn’t be able to get rid of that token. When the loan was repaid, the lender would issue a new SBT recording that fact. The borrower, if they tried to go open a new loan, could be required to provide a zero-knowledge proof13 that traversed the set of attestations applying to them on the Ethereum chain, proving they had no open loans (or that they only had below a certain amount of debt outstanding, or some other claim that they could prove based on the tokens they held or didn’t hold).
Now, there are some obvious privacy implications here: not everyone wants to have their debts publicly visible on the Ethereum blockchain. Buterin brushes this off with the argument that such a system could use zk-SNARKs14 to encrypt the token contents as well as its sender and recipient. There are also some edge cases I could poke at with this scenario, around if a lender went out of business or for whatever reason never recorded the repayment. However, compared to what Buterin used as his next example, this scenario was relatively benign. A borrower consented to the “negative” attestation being recorded when they took out the debt, the lender made that a condition of the loan, and any new lenders require proof that the borrower has no loans outstanding. Fine.
The next example Buterin used was negative attestations around criminal records. Uh oh.
In the real world, like in the non-crypto world, there are applications where one side needs to know that the other side is at least reasonably trustworthy. And one thing they might do is prove that the other side doesn’t have a criminal record, right? And that’s nice because it’s like a very simple test that someone is at least not in, you know, the bottom kind of a few percent of trustworthiness probably.15
Now, ignoring Buterin’s more-than-questionable conflation of the lack of a criminal record to trustworthiness, he’s also revealing here that his dreams for soulbound tokens involve police departments uploading criminal records to the blockchain. Not only that, but he’s envisioning a world in which every police department uploads criminal records to a blockchain, providing the level of data completeness required to prove a negative. And finally, he’s envisioning a world where every police department uploads criminal records to his blockchain, the Ethereum blockchain. Although he states elsewhere in the episode that digital identity frameworks would benefit from being system-agnostic and should not require anyone to use a given blockchain (or any blockchain at all), his own dreams for the future clearly don’t involve decentralization except as far as it can be achieved within his preferred blockchain.
Let’s build on the example Buterin so graciously provided. For all the downsides of existing criminal records and background check systems—and there are many, to be sure—there is something to be said for that data being a bit of a pain to access. In today’s world, there is both a financial and time cost for non-law enforcement bodies to check criminal records. I can think of two instances where it’s happened to me: for employment screening, and for a volunteer position where I would be working directly with children. But in a world where all criminal history is recorded on the blockchain, and the proof of a lack of criminal history is quickly and cheaply achieved with a straightforward ZK proof, those barriers are removed. In the name of safety and trust, any DAO, club, or other community could require this proof to join. Those providing tickets to social events or professional conferences could require it. Games and metaverse experiences could even require this before a person is allowed access—after all, what’s the real difference between volunteering with children and potentially interacting with a child in the metaverse? And while those who have not broken the law in the past, or who have the luck, privilege, or financial means to escape their transgressions being recorded, may not balk to being required to submit proof of a clear record for even trivial applications, this normalization would serve to widen the gulf between the convicted and the not-convicted, a gulf that already exists in society and disproportionately impacts marginalized groups.
Buterin’s criminal records vision also exposes his intent for people to be able to send soulbound tokens without the consent of the recipient—given that it is unlikely people would consent to police departments recording their crimes for others to later use against them if they had the choice. This is perhaps an unsurprising vision of Buterin’s, given that the current state of the Ethereum blockchain enables people to send NFTs without the receiver’s consent, a horrifying state of affairs for anyone who’s given more than about ten seconds of thought to the enormous abuse potential. However, this already bad state of affairs is now compounded by the fact that users would never be able to get rid of these SBTs, even if they contained content like doxxing, revenge porn, or child sexual abuse material.
Verifiable credentials
The system of verifiable credentials Disco’s Evin McMullen waxes poetic about on Bankless seems at least preferable to soulbound tokens. The data isn’t stored on-chain, there is consent required before a party can issue a token to you, and negative attestations (and the enormous amounts of on-chain data required for them) aren’t a part of the vision. But to hear her speak of her goals with her Disco product is like watching someone act out the privacy paradox right in front of you.16 Web3 advocates, McMullen included, regularly speak of privacy, anonymity, and data ownership as a top priority. But she also says in an episode of Digitally Rare:
We can’t have fun together in the metaverse if the only thing I know about you is how much money you have. But we can have so much more fun together if I know the friends we have in common, the activities that we both like to enjoy, I know the incredible skillsets that Jonathan and Matt are good at, and I know the kind of music they like to enjoy, the kinds of parties they go to, or even, you know, from a very simplistic perspective: if we want our DAOs to be more than group chats with bank accounts, we need to know enough about one another to solve more interesting coordination problems than treasury allocation. So, if we want to, you know, write a song together, we have to know which one of us knows how to write music! Because a song that’s designed by the richest people in the room might not sound like a great song.17
Her descriptions of this future world, where relationships are front-run by a deluge of data rather than formed more organically between individuals, are enormously reminiscient of Philip Sheldrake’s fears about the “SSI century”:
An acquaintance now quits those ‘old-fashioned’ relationship-building niceties and gets straight to the SSI point. Where do you work? Which college did you go to? Which college did your parents go to? Republican or Democrat? What’s your gender? Your ethnic origins? Do you have this gene or the other one?
If you fail to offer up the requisite verifiable claims then you fail to get to ‘trust building’ first base in the SSI century. (Note: this is in fact trust avoidance not trust building.) You are then ignored or indeed rejected. But it’s worse. The new social norm now expects you, expects everyone, and more accurately expects your agents to perform similar examinations as a matter of course. And why not? We’re told it’s beneficial, that it’s trust building, that it’s the missing layer. It’s frictionless. It works on an individual basis and government services have adopted it, so surely then it must be good for society as a whole?18
Data custody and security
Another major promise of this world of verifiable attestations is control over one’s own data. A common refrain is that, instead of your data being stored in Facebook’s database, or in the dusty records at the town hall, or with your doctor’s office, you can instead take your data with you.
The specifics of this vary. Some people, like Buterin, talk about recording all this data to some public blockchain or another (using various cryptographic techniques so that you’re not just blasting your personal information out to the world). Others, like McMullen, want you to use their databases. And then there are projects like Jack Dorsey’s new “Web5”, which suggests you can maintain your own “decentralized web node” with all of your credentials.
If crypto and blockchains have granted us one thing, it’s insight into how bad the average person is at securing their data. I have no great love for big banks or huge social media companies or whichever company my doctor is using to keep my medical records, but at the very least they have security teams and compliance requirements.
It’s bad enough when a person bungles their crypto wallet security practices and oops, all their apes gone. I am not optimistic about a world where someone bungles their security practices and oops, now an attacker has access to every piece of information about them, from the address of the property they’re currently living in, to their social security number, to their medical history, to their criminal record. I’m also not optimistic about a world where average people are expected to self-custody this kind of data, acting as the source of truth rather than their doctor or the town hall. I’m a software engineer and computer nerd, and I don’t trust myself to self-custody this data.
If I suddenly found myself tasked with doing so, I would probably implement some sort of expensive and technically complex system of backups, because I understand there’s no recovering from a catastrophic loss when I am the source of truth on information that is absolutely necessary for me to participate in society. I would probably become one of those crypto people that outsiders look at like they’re a bit nuts, as they hammer their private keys into blocks of steel and bury them in the backyard for safekeeping.
This is not a reasonable thing for me, a technologically-savvy software engineer who can afford a spare hard drive, to have to do. It is not a reasonable thing for anyone to have to do.
Let’s be clear: I think people should have more control over what data they provide and to whom. I think people should understand what data companies are storing, and why, and they should be able to request its removal. Sensitive data should be protected carefully, with strict limitations on who can access or share it. Penalties for unauthorized sharing or sale of user data should be severe.
But as more and more developers and companies and “blockchain visionaries” seek to eschew centralization and trust in the state and institutions, it seems that their definition of “acceptably” when they describe “acceptably non-dystopian” projects is very different from my own.
Acknowledgements
This blog post refers to the following writings and podcast episodes:
- “Soulbound: On or off Chain? | Vitalik Buterin and Evin McMullen”. Bankless, by David Hoffman. June 8, 2022. (Podcast)
- “Disco: A Digital Backpack For the LARP That Is Your Life, w/ Evin McMullen”. Digitally Rare, by Jonathan Mann and Matt Condon. March 28, 2022. (Podcast)
- Weyl, E. Glen; Ohlhaver, Puja; Buterin, Vitalik. “Decentralized Society: Finding Web3’s Soul”. May 10, 2022.
- Sheldrake, Philip. “The dystopia of self-sovereign identity”. Generative Identity. October 19, 2020.
- Guo, Eileen; Renaldi, Adi. “Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users”. MIT Technology Review. April 6, 2022.
- Nieva, Richard; Sethi, Aman. “Worldcoin Promised Free Crypto If They Scanned Their Eyeballs With ‘The Orb.’ Now They Feel Robbed.”. BuzzFeed News. April 5, 2022.
Notes
-
“Sybil attack”. Wikipedia. June 10, 2022. ↩︎
-
Buterin, Vitalik. “Soulbound”. January 26, 2022. ↩︎
-
“Web5: An Extra Decentralized Web Platform” ↩︎
-
-
-
Guo, Eileen; Renaldi, Adi. “Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users”. MIT Technology Review. April 6, 2022. ↩︎ ↩︎2 ↩︎3
-
-
-
“Decentralized Identifiers (DIDs) v1.0” Proposed Recommendation. W3C. August 3, 2021. ↩︎
-
“Verifiable Credentials Data Model v1.1” Recommendation. W3C. March 3, 2022. ↩︎
-
A similar trilemma, called the “Decentralized Identity Trilemma”, was proposed by Maciek Lascus in August 2018. ↩︎
-
Nieva, Richard; Sethi, Aman. “Worldcoin Promised Free Crypto If They Scanned Their Eyeballs With ‘The Orb.’ Now They Feel Robbed.”. BuzzFeed News. April 5, 2022. ↩︎
-
Zero-knowledge proofs (ZK proofs) are a strategy in which a person can prove to another person that a specific statement is true without providing additional information. For example, a person could prove that the statement “I have no outstanding unpaid debts recorded on the Ethereum blockchain” is true, without revealing to the other person the details of any past debts that might have been recorded. See “Zero-knowledge proof” on Wikipedia for more detail. ↩︎
-
zk-SNARK, or “Zero-Knowledge Succinct Non-Interactive Argument of Knowledge”, a type of zero-knowledge proof that doesn’t require interaction between the prover and the verifier. See “Non-interactive zero-knowledge proof” on Wikipedia for more information. ↩︎
-
“Soulbound: On or off Chain? | Vitalik Buterin and Evin McMullen”. Bankless, by David Hoffman. June 8, 2022. Quote occurs at 43:47. ↩︎
-
Bongiovanni, Ivano; Renaud, Karen, Aleisa, Noura. “The privacy paradox: we claim we care about our data, so why don’t our actions match?”. The Conversation. July 29, 2020. ↩︎
-
“Disco: A Digital Backpack For the LARP That Is Your Life, w/ Evin McMullen”. Digitally Rare, by Jonathan Mann and Matt Condon. March 28, 2022. Quote occurs at 15:37. ↩︎
-
Sheldrake, Philip. “The dystopia of self-sovereign identity”. Generative Identity. October 19, 2020. ↩︎
Disclosures for my work and writing pertaining to cryptocurrencies and web3 can be found here.",1
279,"I remember the moment, a couple of years ago, when I realized that my Facebook timeline was looking at me differently, or, rather, inviting me to look at it differently. The ads liberally scattered between the usual friend-content had taken on a new coquettish posture. A sleeveless, buff man crouched to touch the soil in an Italian winery, steamily meeting my eye as he did. He belonged in some way to Dolce & Gabbana.
As it happens, I had been conducting research into the consequences of targeted ads. I had found a recent study by Spanish scholars, which concluded that, for the purposes of ad targeting, Facebook’s advertising platform labels two thirds of its users with potentially sensitive tags. These labels are not publicly visible on user profiles, but they allow businesses to direct their ads only to those users whom Facebook has tagged as having certain interests. And the report notices the “extremely worrying” fact that some users tagged as interested in ads related to “homosexuality” live in countries like Saudi Arabia and Nigeria, where homosexuality is punishable with death.
Peculiarly, my research into this disturbing reality seemed to cause a surge of the beseeching male gaze in my Facebook feed. A vertical parade of male models exhibited swimwear, summer slacks, and jogging pants with the camera’s eye roving over their bodies with sensual languor. This was definitely not the “Dude, you gotta buy this!” mode of straight men targeting other straight men with the coolest new life-hacking commodities. I know how the Gillette man winks at his bro audience, and this wasn’t it. I hadn’t declared anything about my desires in Facebook’s vulgar “Interested in” column, but the sweep of the algorithm’s gaydar is silent and broad.
In digital surveillance terms this is called being “profiled,” but such attention registers much more than our profile — this is unabashed full-frontal. By curating the content we see online, by deciding which stories we see on our feeds, by suggesting products for us to buy and movies for us to stream, these algorithms create a strange kind of portrait of ourselves. And we collaborate in its construction with our clicks and cookies. Netflix, for instance, has multiple thumbnails for the same show; you’ll get the one that it thinks will appeal to you most. You can almost see yourself in the eyes of the actor they choose to feature.
Basil Hallward, the fictional artist of the most famous Western literary portrait, is afraid to show his painting of the beautiful Dorian Gray because it would betray a desirous secret of his soul. “I have put too much of myself into it,” he tells his friend. Our algorithmic portraits can be equally treacherous.
Algorithms, then, have the power to project the secrets — or at least the personal topographies — of our inner lives back at us. This technological penetration and display reminds of a scene in Thomas Mann’s novel The Magic Mountain (1924), which dramatizes the strange implications of early radiography on your sense of you. The protagonist, Hans Castorp, is in a Swiss sanatorium, being tested for tuberculosis. The doctor tells Castorp: “We’ll take a handsome x-ray of you — you’ll enjoy seeing what goes on in your own inside.” But enjoyment isn’t Castorp’s feeling when he confronts the hidden truth that the x-ray reveals. His experience in the twilight of the laboratory is eerie. The machine yields up an alien landscape, a bright network of white bones that is as much the real “him” as the familiar surfaces reflected in a mirror. The x-ray’s cold attention perceives and reveals undeniable truths about the mortal self. “You will get a free copy,” the doctor tells him, “then you can project the secrets of your bosom on the wall for your children and grandchildren to see!”
The feeling of being exposed occurs whenever the Internet addresses us in the second person. TikTok’s “For You” page, for instance, serves up a selection of videos that the algorithm anticipates you will enjoy. “Recommendation systems are all around us,” TikTok’s website explains, cheerily yet with a whiff of fatalism.
And before you start asking questions, remember that you enjoy these systems: “They power many of the services we use and love every day.” As we hopscotch from video to video, TikTok categorizes the content we favor, noticing whether or not we watch a clip all the way to the end. Each choice we make “helps the system learn about your interests,” so that “each person’s feed is unique and tailored.” When I set up a new profile, my newborn For You page suggested I follow The Rock, Gordon Ramsay, Billie Eilish, and Ed Sheeran. This is TikTok’s equivalent of the tabula rasa. Starting from nothing, every interaction helps construct an image of us as users, as if an entire personality can be built on the foundation of Dwayne Johnson’s sturdy shoulders.
The Internet adores this second-person voice. There it is, at every cyber–street corner: Recommended for You, Suggestions for You, Here Is Something You Might Like. Behind each of these You’s, an algorithm sits at an easel, squinting, trying to catch Your likeness. But these algorithms are true Renaissance practitioners. Not only portraitists, they’re also psychologists, data-crunchers, and private detectives, extrapolating personality from the evidence of our past actions: from our online histories and, increasingly, from what they can eavesdrop, without any meaningful warrant, in the physical world. From all those toothsome bytes of behavior, they create an image of You. In French there is the formal vous and the intimate tu, but the digital you is somewhere in between, coming from the other side of the screen, spoken by a strange intelligence that seems to know your secrets.
But what is the psychological impact of a bespoke Internet, tailored to you, and one where it is increasingly difficult to outrun yourself? “Bespoke” sounds luxuriously considerate, but it also entails a kind of revelation. It comes from the older word bespeak, which refers to an indication or a piece of evidence. Sewn into the bespoke is the fabric of external judgments. In the tailor’s series of sartorial calculations and decisions, the wearer is shaped, a silhouette is cast.
Philosophers, especially the phenomenologists — those focused on how our consciousness perceives the outside world as a set of experiences — have long been aware that we don’t get a sense of ourselves in isolation. Hegel was key in developing the idea that self-consciousness is only possible in relation to others. Our identities form in relation to how we perceive other people perceiving us. Being self-conscious, then, relies on the gaze of someone else. “The Other penetrates me to the heart,” Jean-Paul Sartre writes, describing Hegel’s intuition about how we are dependent on one another in our very being. “I cannot doubt him without doubting myself, since ‘self-consciousness is real only in so far as it recognizes its echo (and its reflection) in another.’” For Hegel, the penetrating gaze of another person produces in our minds an image of ourselves. Personalizing algorithms thus offer a startling twist on Hegel’s idea, as we begin to see ourselves more and more through the gaze of these unselfconscious but intelligent and highly attentive algorithmic “others.”
Sartre’s existentialism lies downstream from Hegel’s phenomenology, and his concept of hell in his 1944 play No Exit is tinglingly prophetic of our current predicament. The play is about three freshly dead strangers who have just arrived in a windowless room in hell. Garcin, Inèz, and Estelle realize that they can’t escape one another’s scrutiny. The lights are always on; there will be no more sleeping. One of the first things they all notice about hell is the absence of mirrors — and the play is about how they become each other’s looking-glasses. This relationship begins literally, when Inèz helps Estelle with her lipstick.
The three inmates soon feel the borders between themselves and their eternal roommates transgressed. Garcin sounds like a Swiss x-ray machine when he tells Inèz, “I can see into your heart.” Inèz, the most sinister of the three, says of Estelle that she “crept inside her skin, she saw the world through my eyes.” Inèz tells Estelle, “You’re lovely,” but, less pleasantly, she scolds Garcin for the way he holds his “grotesque” mouth. Garcin, meanwhile, who was shot for desertion, needs Estelle to assure him that he’s not a coward, in order to make it so. But there is no escaping Inèz, who describes herself as “a mere breath on the air, a gaze observing you, a formless thought that thinks you,” and declares, “You’re a coward, Garcin, because I wish it!”
The play’s conception of damnation, then, is a life in which your self-image is forged entirely in public. Your “I” only exists because someone says “You.” Garcin understands that “there’s no need for red-hot pokers” in this place, because both the scrutiny of his roommates and his terrible reliance on them is the torture. “Hell is — other people!”
In The Age of Surveillance Capitalism, Shoshana Zuboff mentions No Exit as a predictive text, a warning to the coming digital generations about living under the unblinking gaze of others. She suggests how Sartre’s famous line is “a recognition that the self–other balance can never be adequately struck as long as the ‘others’ are constantly ‘watching.’” Balance depends on our ability to retreat into a truly private place, released from the demands and appellations of our devices. While No Exit foresees the pressures of social media, where self-definition can be become unhealthily bound to other people’s reactions to our posts, the dynamic is still between sentient actors, each with their own subjectivity. But as the eyes of non-sentient machine-learning systems open wider, for me the claustrophobia increasingly comes not from being unable to unhook myself from the online judgments of others (“You’re lovely!”) but from being locked in with algorithmically produced images of myself. On the bespoke Internet, hell is — ourselves!
Unlike humans, algorithms often don’t withhold or disguise the conclusions they have drawn about us. Their judgments are unmasked, and yet they lack the x-ray’s objective gaze. They don’t serve us up an irrefutable row of our own clean, white ribs. Their assessments have commercial agendas. Their acuity is sometimes hilariously imperfect; they’re often pedantic and oafishly literal. In some contexts, they consolidate a self-image we are pleased to possess, entrenching our cherished habits by nudging us toward the same kind of content again and again. But at other times the algorithms warp our reflection, as in a hall of mirrors, pulling our self-image into grotesque configurations. Much of the hellishness is the uncanny quality of these algorithmic portraits. Beyond the impertinence of their presumptions, we are forced to negotiate with the way they represent us. With every bespoke online “you,” we might ask, “Is that really me?”
TikTok assures us that its sense of You is constantly being refined, with light and shade added to the features, paint building up on the canvas: The “recommendation system is a continuous process as we work to refine accuracy, adjust models, and reassess the factors and weights.” But this endless appraisal does not always bring this digital portrait into higher resolution. The effect of algorithmic scrutiny can be distorting. Let’s take an example from YouTube. Say you decide to take a deep dive into the stash of Susan Sontag material — a nineties news interview where she pretends she hadn’t heard of Camille Paglia, a more stately library talk, and some commemorative documentaries. This unintended Sontag season is so intense that soon YouTube’s selection of videos is one large Mallen stripe. In the bathroom mirror, you imagine what you would look like with a Mallen stripe.
But then, the disquieting slide occurs. In between Sontags, there appears a rogue evening with Camille Paglia on Shakespeare. She’s good on the Macbeth witches. But the slide continues, and soon the Sontags have morphed into a boorish crew of provocateurs. It’s like following someone you’ve just met at a party to a second party that is not your scene. There’s a sense of high-school vertigo, of an abortive week spent running with a scary new crowd. You log back into YouTube. “Is this who I’ve become?,” you ask yourself. As the algorithm invites you to watch the latest provocateur “DESTROY Feminist B**** in 17 seconds,” you wonder if it’s true that you’re known by the company you keep. In your head, Sontag speaks with the voice of a jilted childhood best friend. “You got weird,” she says. And it’s true that YouTube’s mercurial kind of portraiture is weird. The image of oneself created by these recommendation systems isn’t stable; it drifts and smears. And yet the label YOU remains deceptively enduring and monumental. This is recommended for You; this is Your tube.
Much valuable criticism about digital surveillance has rightly focused on what is being taken from us, the slurping up of our lucrative data in the name of, to take one profitable example, cross-marketing opportunities. Zuboff viscerally describes us as picked-over carcasses. But we also need to remember what this surveillance gives us: an Internet that looks uncannily like ourselves.
In my 2015 book The Four-Dimensional Human, I describe a failed promise of the 1990s Internet: that it would free us from our earthly identities and let us move like quicksilver through cyberspace, inhabiting all kinds of experimental selves in gaudy, rackety chat rooms. Instead, our online movements got pinned with thumbnail avatars of our real-world faces; we solidified in the heat of the personal brand. We developed what I called “chain-store selves” as we spread ourselves across the Internet with the trademarked consistency of a franchise.
In her book Trick Mirror (2019), Jia Tolentino argues that we have become “chained to ourselves online.” She coins this beautiful image: “It’s as if we’ve been placed on a lookout that oversees the entire world and given a pair of binoculars that makes everything look like our own reflection.” Here Tolentino is discussing the self-consciousness that comes from the way social media ties our online presence to our personal profiles, so that every post and comment and retweet is read as a description of selfhood.
Through algorithmic interventions this process is intensifying. Instead of just exhibiting our personal brands in the great mall of the Internet, the Internet that we each experience looks more and more like our personal brands. In my case, apparently, this means men’s crotches and Golden Girl memes. The promised mercurial freedom of the ’90s Internet has morphed into the slipping and sliding of the algorithms trying to pin you down.
When I was young, a TV and movie shorthand for depression was the person on the couch flicking blankly from channel to channel, barely able to hold up the remote. Today, that once grim scene now glows with a new appeal: the tranquility of not being catered to, of moving between channels that are blind to our mood.
There are less-morose versions of this dissolution of self. Think of what hallowed ground we now find in secondhand bookstores, so many of which have been sunk by algorithms’ seductive targeting of readers. Certain people I know sigh and say that they could spend all day in the jumbled heaps of used book stores. Perhaps a corner of that sigh might be reserved for the heavenly indifference of the stacks to customers’ tastes. Online among the algorithms, the closest I come to this rush of self-forgetfulness occurs when I accidentally log myself out of YouTube and load up the site as no one. A tide of off-the-rack smash hits, with millions of views apiece, strikes my anonymous face. Oh yes, I think just then, before hurriedly logging back in, I’m not the only one in here.
We have spent these two pandemic years confronting our own portraits in a more literal way. A day spent on Zoom turned out to be a day spent staring at our own faces. As if to underline the claustrophobia of lockdowns, Zoom’s portal to sociability actually led us straight back to ourselves. It is strange how easily we accepted that an image of ourselves should hang there among our companions. This default has made us intimate with our own listening faces, which we know how to paint in real time to appease our vanity.
But this real-time control over our expressions has been but a consoling decoy for the control we have ceded to algorithms that generate their own images of us. We know well that in a Zoom call, in the moments spent arranging our hair in the live view, we are not at our most receptive to others. On the bespoke Internet, we risk becoming permanently mesmerized by how the algorithms ceaselessly fiddle with our hair, tilt our cameras, and adjust our jawlines in their eternal quest to capture us.
An irony of this uncanny scrutiny is that the more algorithms pay attention to us, the less we may pay attention to our digital roommates, to their subjectivities, tastes, and priorities. Solipsism becomes the coded default. The more frightening formulation that waits down this road may be: “Who are other people?”
The New Atlantis is building a culture in which science and technology work for, not on, human beings.",1
280,"While Design Thinking gets all the attention, it is not the same as (Digital) Product Design.
In How I Stopped Worrying and Learned to Love Design Thinking, I wrote about how I learned to value design thinking and in Five Habits of Design Thinking I explain how you can build the skill of design thinking. But I’ve noticed my students tend to use the term “design thinking” as a synonym for UX/Digital Product Design. This is a dangerous smallification of design and a source of shoddy work.
This is not the complete design process.
Laura Klein explains the depth of complexity of design by taking you through one example of a feature: a reporting flag. You put a simple comments feature on a children’s book seller site, and immediately you get spam. So you put up a reporting flag. What does it do? Does it remove the comment? What if people report comments they just disagree with, but aren’t offensive? Should go to someone in the company, or can you use an algorithm? What if there are hundreds of reports a day? Are you going to hire more people? Does it take three reports to disappear the offensive comment? Or something logarithmic? Do you build a tool to block certain spammers? Do you implement Akismet? How transparent are you about what gets you banned? How do you handle people who say their comment was a reasonable critique, even if someone else found it offensive?
All features have consequences. Complexity is exponential. If complexity is not accounted for in the design, unforeseen consequences can kill a product. Design thinking is great for approaching problems in a new way and coming up with opportunities for improvement, but does not address the complexity of designing a product that is launch ready.
While many attribute design thinking to IDEO, they themselves admit they didn’t invent the term, just ran with it. AND that there is more to design than design thinking.
“ IDEO is often credited with inventing the term “design thinking” and its practice. In fact, design thinking has deep roots in a global conversation that has been unfolding for decades. At IDEO, we’ve been practicing human-centered design since our beginning in 1978, and took up the phrase “design thinking” to describe the elements of the practice we found most learnable and teachable — empathy, optimism, iteration, creative confidence, experimentation, and an embrace of ambiguity and failure.” IDEO, emphasis mine.
Design Thinking’s popularly has led to the below statement.
Let me take a stab at the elephant in the room: we all design, but we are not all designers. We all cook, but we are not all chefs. We all take photographs, we are not all photographers. We all draw (you really do, even if it’s only lines on a whiteboard while you complain about your drawing skills) but we are not all illustrators. To design well, you must study a number of topics, all worthy of a life time of practice, from graphic design to ergonomics. It is human to design, but it is a profession to be a designer.
That’s what is missing in that diagram: the craft of being a designer. Let’s fix that by fleshing out a few hexes….
Change 1. from Problems to Opportunities
While the diagram itself doesn’t state that “design is problem solving” most of the material surrounding it does. Instead of problem, I start with opportunity. Problem is problematic because not everything is a problem. Opportunity is pretty awesome because it encompasses both problems and good things that could be better/different/cheaper (classic differentiation strategy.)
Change 2. UNDERSTAND replaces empathy for so many reasons. Empathy suggests that all you need to design well is to research the end users and really feel their pain. But it’s not just the end-user who informs design but so many more factors, including buyers, teammates, tech and funding. Understand the Context is a more accurate term, IMO. While I’ve written a little bit about context , even to attempting a canvas for it, context is always highly variable depending on the situation. Yes, people, IT DEPENDS.
That said, you always have to UNDERSTAND at least these three elements.
- The Target Market (users, humans, doctors, designers, cats)
** Their mental models
** Their behavior
** Their environment
** Their capabilities
** and more.
I haven’t even gotten into the buyer/user dichotomy.
- The Technology available
** What is already built that you can leverage
** What capabilities does your team and company have
** Can we just assume there is always more?
- The Business Model & Funding strategy.
** What resources (people and money)) do you have and for how long?
** What business model is it? Subscriptions, direct sales, B2B, in-app purchases — all these and more will directly affect design choices.
Change 3. Define. I have mixed feelings here, as “define” doesn’t stand alone very well, but it is not inaccurate. At some point after you understand the context, you can make a draft definition of the opportunity, usually in the form of a value proposition.
Another popular model, the double diamond, points out two key define moments: The opportunity (problem) and the proposed solution. It emphasizes you must go wide to do well in both.
I am a big fan of exit criteria over deadlines. John Cutler gives this example
We don’t often say, “this is not worth doing”even when we should. So I added in Go/NoGo as well as Scope to the “define” phase. In the context phase, we learn a lot about the situation and can say, “this is the opportunity we are going to address in this phase. Not that opportunity over there and not that other situation. Only this.”
Change 4: it’s a loop. Because you stay into the loop until you have something worth shipping. Sometimes you even go all the way back to understand because the more you make stuff, the more you realize you the holes in your knowledge. Loopy loop loop. Not waterfall.
Change 5. Added critique. Critique is when designers share their goals for a design and their strategy for achieving it. Then other designer give advice how to get you closer to that goal. Senior designers have the experience to find issues and suggest solutions without testing.
You can spin though the Build → Measure→ Learn cycle a hundred times and still not have a viable product, but if you have a senior designer on board, you can cut that in half (or further) because a senior designer can spot issues in usability that might lead to false negatives (I have seen this many times.)
Don’t have a senior designer? Have everybody look at the early work and leave comments, questions and issues. Hang the work on the wall and have folks write on post-its any of their concerns. It’s a bit like open source: many eyes catch more bugs than one.
But you still have to test, because everyone has blindspots.
Let’s Get Elaborate
Change 6. This is the big one, the true heavy lifting of design doing: Elaborate.
Once you have figured out what the right problem is and what the right solution is, you have to flesh it out. This is hard and important work.
<Addition made 6/13/2020>
The Interaction Design Institute’s Hex Diagram lays out key goals to good software (what is it about hexes, people! Form should follow function, not the other way around???) This is really quite useful.
</Addition>
We then get to translate these target values to actual tasks performed by design.
- Architecture and frameworks: This is how the software is organized. Will there be a settings area? Where does the “help” area go? Is the interaction modal or concurrent? And many more questions beyond your brilliant initial idea:“jobs4pets!”
Architecture is critical for the team as well as for the end users. It helps manage scope and make sure all the work, not just the fun thinking part, gets done.
For users it gives them a mental model of what is possible in the software and how to find it.
Frameworks are usually a bit more micro. They include decisions about whether to use a wizard or a toolbar/canvas model for interactivity. Take photo enhancing. On the large screen of a desktop you’d use a tool/bar canvas framework. But on a kiosk with novice users you’d use a wizard to guide them through removing red eye and cropping. Understanding context changes everything, and the designer must know both that and how to respond to a given context.
- Beyond the architecture, you need to organize the content and features.
Every instance of software, from apps to sites, has content. Some software has preexisting content. Some just have help sections. If you want to support retrieval and recommendations, you have to design for it. No, search is not enough.
Some software has user-generated content, which means you have to design the empty state that exists to convince users to add content, and once you have content how do you organize the unknown and mange it. Governance systems must be designed.
Tool software has its own unique challenges. When they are simple you have to design tutorials and help. When they become complex, (think Photoshop) someone has to consciously choose what functionality goes where so you can use the software without breaking flow.
- Design how the software will behave (usually called Interaction Design, but done by more than just Interaction Designers.)
I’m not talking about making the people behave, I’m talking about designing how the software behaves (though one leads to the other.) What happens when you click a button. What happens when you don’t have any user-generated content? What happens when users report an violation of the TOS? What if they want to change their display name? How about their username? So many fiddly little decisions. Those fiddly decisions make software delightful or rage-inducing.
- Interface/UI. I know, I know people use all these terms to mean so many things. Let’s pretend interface only means what is presented to the user so they know what is possible and how to do it. Radio button or checkbox? Carousel? Thumbnails? How do we represent hyperlinks?
It’s more than just designing flat screens though. Consider the rise of VUI, VR, AR and haptic interfaces.
- Brand and voice. This is a mix of interface, graphic design, content strategy, writing… How do we represent the personality of the site? Silly error messages, or straightforward? What is the navigation language? How do we balance usable and on-brand? What kind of content do we allow? How is the logo managed? What colors can we use (and will they make sense for the color-blind?)
So. Many. Questions.
- And finally, the stuff that everyone forgets and is often designed by a PM and engineer at 3 am: error messages, 404s, settings, What is written in place of user generated content when you haven’t got users yet? Help sections.
OMG help needs design help STAT!
Onboarding is starting to get attention, but not always. Sometimes it’s slap dash, with an overlay, sometimes it’s a tutorial, and sometimes it’s a weird love child of both. Someone has to figure out both what strategy to take and how to realize it in the design.
THIS IS NOT EVERYTHING. This is a braindump from what I can recall shaped into six items because hexes. When I explained this to students, it looked more like this:
I tried not to name titles of who typically owns what. Sometimes in a startup the product manager, the front-end engineer and the one lone designer own all aspects of design. In a bigger company you get to have specialists who are really good at certain sorts of design, like Information Architects (architecture, organization, interface) or Interaction Designers (frameworks, software behavior design and interface) or Content Strategists (organization and brand/voice.) The field of digital design is very young and the titles are fluid. But what has to be done isn’t. If you don’t have expertise in these areas, mistakes will happen. Mistakes can be pricey.
It’s not enough to do design thinking, you’ve got to do design execution.
The original model used color haphazardly. Here I coded team (product, engineering, design) in green, design in yellow and programming in red. Mixes represent shared effort. As you can see, design thinking is something an entire team can do, but design doing should be done by a trained designer.
Design thinking is just an approach to getting a handle on wicked problems. Design is all about executing that approach effectively. Designers often refer to these two elements as finding the “right design” and “designing right.” Design thinking is an approach to the first item but design is much more.
After the Design Is Over, It’s Not Over
But wait! There’s more! As more designers move in house, rather than consult, we’ve seen the rise of a new design effort: DesignOps.
Read DesignOps 101 if you wish to learn more in detail. But for now, look at all this:
Thus the last two changes land more-or-less in Design Ops.
Change 7: add Systematize.
Once you’ve designed, you don’t want to reinvent the wheel. Design can codify design decisions so that nondesigners, new designers and even they themselves can make sure new work fits with the old work.
- Design patterns codify organization, behavior design and interface design to ensure usability. This means that you don’t have to do the whole understand-ideate-prototype-test etc every time you want to add some functionality that already exists elsewhere. Need a signin/login? it’s been figured out. Need a way to browse SKUs? It’s been figured out. And when you invent something new that’s been tested successful, you can create a new pattern to accelerate the rest of the company.
- Style Tiles and Style Guides make sure the right colors, logos, type and more are used when designers (and others) make new content and functionality. Nothing says “we’re amateurs and don’t give us your money” like having five different reds used. Even if the end user doesn’t know why, the entire software will look vaguely off, undermining trust.
Change 8: Optimization.
Design and product management often partner on the long and sometimes boring job of making everything get slightly better all the time.
Conclusion?
I decided to use the dschool hexes because they have gotten so much visibility, I hoped they’d be familiar to people. I could (and have) talked endlessly about the problems and power of models. All maps and models are useful lies, in that they edit and distort in order to simplify and create clarity.
The dschool model is not the worst model, but it’s far from the best. There are a lot of models of the design process. Bruce Archer’s has 229 elements.
We simplify our models to communicate the big picture. But just because you see a forest doesn’t mean there aren’t a whole lotta trees down there. Maybe it’s time we help people see them.
❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦ ❦
Twitter Thread that proceeded this (with many draft models.)",2
281,"Vertical Software Wins in Bull and Bear Markets
With many recent forecasts indicating a likely recession ahead, software entrepreneurs and investors alike are preparing for impact to their businesses. We believe that in uncertain times, technology buyers will consolidate IT spend with trusted mission-critical solutions that have a clearly defined ROI. Because of this, vertical software has a compelling reason to be resilient even in a slowdown.
For decades, Vertical Software often was considered too niche for entrepreneurs and investors who wanted to achieve massive venture-style outcomes. Many wondered how large a business could become building software only for one type of customer. As a result, some of the world’s largest industries remained in the software stone age despite incredible technological advancements over the past several decades. Sectors like dining, education, energy, healthcare, industrials, home services, parts of financial services, real estate, and others have historically had to work sometimes literally with pen and paper or in outdated, legacy technology systems. However, in recent years, several key trends have opened up the potential for greater adoption of next generation software within these and other end markets.
First, cloud software has made it possible for owners and executives to run their businesses from the palm of their hands. Second, every business has had to adapt to the “Amazon effect” where customers have come to expect an Amazon-like ease of use for all facets of their life, whether booking a doctor appointment, fixing a car, or signing a child in for school. Lastly, the ability to integrate with financial infrastructure platforms like Stripe has enabled software vendors to generate more diverse revenue streams like payments and become even more essential for their customers.
These factors have created opportunity for an emerging category of vertical SaaS (vSaaS) leaders. Cloud-based and mobile-first, vertical SaaS is built to serve unique workflows of particular industries. From the restaurant managing orders and inventory, to the construction company building a large new office building, businesses of all shapes and sizes are looking to partner with technology vendors who deeply understand their core day-to-day workflows and provide highly tailored software solutions built for them, by people like them.
Because of these powerful long-term secular trends, we believe vSaaS is well-positioned to win in both bull and bear markets.
Three Reasons We’re Bullish on vSaaS
1. vSaaS is mission critical
In uncertain economic environments, software spend shifts to the must-haves, away from the nice-to-haves. vSaaS often serves as the operating system for customers, becoming the single source of truth for critical activities like CRM, payments, scheduling, and reporting. Brightwheel, for example, provides software to daycare centers to automate billing and payments, send real-time messages to teachers and families, and streamlines classroom check-ins, admissions, reports and lesson planning. Seso provides some of the largest agricultural growers in the US the ability to hire and schedule seasonal workers during harvest season. Companies like these are providing mission critical, must-have solutions for important industries like child care and agriculture.
2. vSaaS helps customers operate more efficiently
Ultimately customers adopt software because they want to run their businesses better. Because vertical solutions are built with specific industry needs in mind, they often effectively drive value by helping customers either increase revenues, decrease costs, or both. Residential HVAC and plumbing shops who use ServiceTitan, for example, typically see 25% YoY revenue growth in the year after they implement the software, versus an industry average growth rate in line with GDP growth. Benchling helps life sciences customers accelerate their workflow cycle time by 38%. vSaaS has a compelling value proposition across diverse industries, from residential home services to biotech research.
3. vSaaS vendors can continue to sell new products into an existing customer base
The best vSaaS companies start by solving one specific pain-point and then expand once they gain trust with customers, who will then begin to ask for more features and capabilities over time. For example, Shopify started by offering retailers a website with payments and a shopping cart integration. Today Shopify is a full commerce platform with an app store, lending, installment payments, offline POS, email marketing services, a merchant card, and fulfillment services. Toast originally offered restaurants a better, cloud-based POS system but today has 15 unique products including digital ordering and delivery, payroll and team management, lending, inventory management, marketing, gift cards, and reporting. 60% of Toast customers currently use more than 4 of their products. From a starting position of one fantastic wedge into their customer base, vSaaS vendors have a continuous upsell and cross-sell opportunity with existing customers. During difficult economic times it can be more cost effective to bundle software purchasing with your trusted, go-to vendor who can provide a lower price than a standalone point solution can.
vSaaS in a Downturn
While we’ve highlighted three reasons, among many, to be bullish on vSaaS, we also acknowledge that not all vSaaS companies will thrive during a downturn.
End customer health is critical during periods of macroeconomic uncertainty. vSaaS companies which serve more discretionary categories are likely to feel a crunch within existing customers. We also expect revenue streams from embedded FinTech, like payments and lending, to face difficult comparisons in 2022 as they lap robust spending in the back half of 2020 through 2021.
Lastly, vSaaS often requires some degree of implementation as customers change their behaviors from analog to digital. For vendors that have a more complex implementation motion but offer slower time to value, it’s likely that their potential customers will push out purchases to a later date and therefore reduce net new ARR growth.
Despite these risks we continue to be enthusiastic about the broader vSaaS ecosystem. As we recently observed, great businesses have been built and flourished through some of the most difficult times. We expect that strong vSaaS companies will emerge stronger and continue to lead with innovation in the years to come.
30 Private vSaaS Companies We’re Watching
We’re tracking these 30 vSaaS companies closely, which represent a combination of portfolio companies as well as other private companies which are leading the way forward for vSaaS, in both good times and bad.
Which vSaaS companies are you following? We’d love to hear from you @IndexVentures.",2
282,nytimes.comPlease enable JS and disable any ad blocker,9
283,"7 July 2022. Hip-hop | Culture
Crossing hip-hop with Sri Lankan dance. // What the mediaeval Battle of Crecy tells us about organisational culture.
Welcome to Just Two Things, which I try to publish daily, five days a week. Some links may also appear on my blog from time to time. Links to the main articles are in cross-heads as well as the story.
I’m away for a few days. Publication of Just Two Things will be erratic.
1: Crossing hip-hop with Sri Lankan dance
The Sri Lankan choreographer Usha Jey has been tearing up the internet with a video of her joyful dance Hybrid Bharatham (Episode 5), which combines hip-hop and Sri Lankan Bharatanatyam dance. If you’ve missed it, here it is (1’24”).
An article in Indian Express described it this way:
a stunning mélange as Bharatanatyam adavus (basic steps) hold with popping, locking and breaking effortlessly. Jey, with Mithuja and Janusha (Tamil-Sri Lankan Bharatanatyam dancers from Switzerland), shift personalities with every step as they dance to American rapper Lil Wayne’s 2018 hit, Uproar. “I call it hybrid Bharatanatyam. It is my way of switching between hip-hop and Bharatanatyam, two dance forms that I love, learn, and respect,” says Jey, in an email.
Jey was brought up in Paris, where her Tamil parents moved in the 1990s to escape the quarter of a century long civil war in Sri Lanka.
In a sense the video reflects this upbringing. She grew up with hip-hop in Paris, and only returned to the dance of Sri Lanka—which she describes as her “cultural history”—in her early 20s.
As a child, she’d discovered koothu — an informal dance depicting scenes from ancient epics — through Tamil movies and would perform among family and friends. When she opted to learn Bharatanatyam at 20, she figured it was late, but decided to immerse herself anyway. She found a guru in Bharatanatyam dancer Anthusha Uthayakumar and gave the next few years to the form; hip-hop stayed around.
Her Youtube channel features a series of videos in her ‘Hybrid Bharatanatyam’ series, one of which references the civil war directly (0’50”):
In a previous video she created in her hybrid Bharatanatyam series in 2020, she danced to One Hundred Thousand Flowers, a song about the discrimination and massacre of Tamils in Sri Lanka, created by Canadian-Sri Lankan rapper Shan Vincent de Paul in his album, Made in Jaffna (2021).
Of course, there’s also another story here, about how hip-hop became a global music and a global voice, while also speaking to and for specific cultures. There’s a whole literature there, which I haven’t got time to discuss right now.
But Natalie Brown nods towards it last year in a piece in the Daily Bruin that focused on UK and Senegalese hiphop:
(R)egardless of country or regional specificity, (musicologist Lucas) Avidan said there is a common thread that unites hip-hop together: a progressive youth-oriented voice. This voice encourages listeners and artists alike to take a stock template of youth identity and craft it into their own sounds and concepts, he said.
“Locally, hip-hop is popular because it speaks to a love of culture, but internationally, it has this general (anti-authoritarian stance),” Avidan said. “That’s why (hip-hop) appeals to so many listeners.”
Brown’s article comes with a playlist: ‘Hip-hop around the globe’:
2: What the mediaeval Battle of Crecy tells us about organisational culture
I listened recently to a Tim Harford podcast on what businesses can learn from the French defeat in the Battle of Crecy in 1346. It feels like a bit of a party piece, but there is definitely some substance in there, both in the way that strong cultures can blind us to what’s happening around us, and in particular how they can blind us to technological and social change.
You might not have a good memory of how the Battle of Crecy unfolded, but English schoolchildren of a certain age heard a lot about it. The English were heavily outnumbered but well positioned at the top of a rise, and with a large force of archers, dug in and well protected. A heavy shower just before the French attack softened the ground.
The French knights were regarded at the time as one of the most formidable fighting forces in Europe. They charged repeatedly at the English lines but were decimated every time by the English archers. The French lost thousands of knights, the English around 100 men. You cam see why English schools were fond of teaching it, combining as it does a rich seam of both English self-regard and national prejudice.
Harford is interested in three things: the interaction between individual and group behaviour before the battle; the French of chivalry; and the effect of technological innovation on the latter—in this case the English longbow, and the social relations that went along with it. A Harvard Business Review article on organisational culture gets a look-in along the way, as does the game theorist Thomas Schelling.
The problem of the French armies started before the battle. As they marched towards the English position, the French king Philip gave the order to halt, so they could regroup and rest overnight. But those at the back kept pushing on, and those at the front didn’t want to be overtaken, so they kept pushing on too. Eventually they found themselves, late in the day, milling around within striking distance of the English.
So Philip ordered the attack, sending in his Genoese mercenary crossbowmen first. But the crossbows were wet from the shower, and their defensive shields were at the back with the baggage train. Their arrows fell short of the English positions; the English arrows reached the crossbowmen, and the crossbowmen retreated. (The French knights thought this cowardice).
(The sad fate of the Genoese crossbowmen. From Jean Froissart’s 15th century Chronicles. Public domain).
The French knights therefore attacked, riding over the crossbowmen, in Harford’s account. The English arrows didn’t always pierce the French heavy armour, but they had a lethal effect on their horses. The French chivalric code was that the purpose of battle was to engage the knights of the others side. Retreat was unthinkable. So they charged repeatedly up the muddy slope, through the bodies of people and horses, to less and less effect.
Harford quotes a graphic novel about the battle—who knew there was such a thing—in which one of the English archers says,
'they just don’t get it.’
As he says, the chivalric code didn’t just blind them to better military answers. It stopped them from asking the right questions.
The technology part of this was the development of the longbow, cheaper and lighter and simpler than the crossbow. When it rained, the longbowmen could remove the string and keep it dry under their hats. In battle, they could reload and re-fire more quickly.
But it had taken the English time to build this capability. Edward had forgiven the bowmakers and the fletchers their debts—a big deal in the feudal world—to get the weapons made, and he had, years earlier, ordered every able-bodied man to practice archery for two hours a week after church. He saw his archers—despite their lower social status—as an integral part of his battle plan. This is obviously a sharp contrast to the French attitude to their crossbowmen.
The Harvard Business Review article that is reference is from 2018: “A leader’s guide to corporate culture”.
Harford paraphrases it slightly: it includes a 2x2 which frames eight types of organisational culture and 18 references to the word “leader” or “leadership”.
But although none of the eight types capture an organisational culture like that of the French chivalric knights, based on honour, the section that explains what culture is does summarise their problem:
Culture is a group phenomenon... It resides in shared behaviors, values, and assumptions and is most commonly experienced through the norms and expectations of a group—that is, the unwritten rules...
It is manifest in collective behaviors, physical environments, group rituals, visible symbols, stories, and legends...
Culture can direct the thoughts and actions of group members over the long term...
An important and often overlooked aspect of culture is that despite its subliminal nature, people are effectively hardwired to recognize and respond to it instinctively. It acts as a kind of silent language.
The new technology that the English deployed, in other words, completely blindsided the organisational culture of the French knights, and therefore of their approach to the battle. The result was a complete catastrophe in which they repeatedly made poor decisions, and were destroyed as a fighting force.
As the HBR authors say:
Other aspects of culture are unseen, such as... what David Rooke and William Torbert refer to as “action logics” (mental models of how to interpret and respond to the world around you).
But it took this catastrophic defeat for them to recognise this—and the consequences of the defeat lasted for several generations. You can see why Tim Harford thinks there might be lessons here, 650 years on, for organisational leaders.
j2t#343
If you are enjoying Just Two Things, please do send it on to a friend or colleague.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.",8
284,"These are the Tools Open Source Researchers Say They Need
What type of tools do you need?
That’s what we asked back in February when we circulated a survey among open source researchers about their use of online tools when conducting online research. That can mean anything from a simple search engine accessed through a browser to an intricate, custom built scraper for which you must use the command line.
More than 500 people took the time to answer our questions, telling us about their experiences using (or failing to use) various online tools.
We conducted our survey to help the wider open source developer community learn what tools could really help researchers if they were to be built.
These survey results show that the online researcher community is highly diverse. Those who conduct open source investigations do not only come from a wide range of professional backgrounds — about half of them do this type of work in their spare time.
Researchers told us that the tools they are most likely to use need to be free, clearly describing what they are capable of doing and how they can be used. Given that only a quarter of our respondents knew how to use the command line, tools which do not require more advanced technical skills are particularly welcome.
Nearly 200 of our respondents provided concrete suggestions for tools which could help them in their work, which we have provided in a publicly-accessible spreadsheet.
Who Responded?
We received 525 responses to our survey. Those who took part came from a wide range of professional backgrounds, from cyber security analysts and journalists to corporate security specialists and academics. Importantly, not everybody conducts this type of research as their day job. Although volunteers play a significant role in the open source community, we were surprised to see that roughly half our respondents did this research during ‘work’ and the other half in ‘free time’.
The respondents were also diverse in their level of online research experience. The biggest group (35%) indicated that they occasionally conduct online research but still see a need to improve their skills
We also asked researchers how often they used tools in their work — our definition of a tool included any digital means which helps perform specific tasks in online research. To provide examples, we linked in the survey to Bellingcat’s Online Investigation Toolkit. Here, the biggest group (34.7%) reported that they use tools whenever they do this type of work, though understandings of the term may have differed.
Researchers’ Favourite Tools Named
We wanted to know the survey participants’ favourite tools and whether they could describe a time when using a specific tool had been particularly helpful in one of their investigations.
The answers to both questions were sometimes very case specific — they included many tools that were only named one or two times — but there were also clear tendencies.
The winner in terms of favourite “tools” was the search engine Google. Even experienced researchers who used many other tools would often return to it. Those with less experience reported that Google was often the first and only “tool” they had used so far.
The second most favourite tool and at the same time the one that was considered as most helpful for open source investigations was Google Earth Pro. Many respondents mentioned the free access to satellite imagery, both historical and current, as crucial for geolocation.
The graphical link analysis tool Maltego was the third favourite and second most helpful tool. We could not always determine respondents used Maltego’s free or paid edition. The survey respondents explained that Maltego helped them find hidden connections between people or organisations and to gather information related to a research case at one place.
The vast majority of researchers’ favourite tools — from flight trackers to social media monitors — could be used for free or at least had a basic free version. Amongst online researchers’ favourite tools was also the Wayback Machine, a digital website archive.
Although respondents found several scraping tools helpful, they did not show up at the top of the favourite tools list. A potentially related finding, given that scraping tools often require use of the command line, is that those researchers who are able to write scripts of code themselves in order to automate parts of their research often considered those scripts to be their favourite tools. Several online researchers mentioned that they write their own code based on the needs of a specific research case. Others indicated that they are able to use scripts that they find on code sharing platforms like GitHub.
However, only the more tech-savvy members of the worldwide open source investigator community have access to this large world of available tools. More than 30% of our survey respondents have never used GitHub. Another 22% are aware that GitHub offers tools but they don’t know how to use them. A further 23.4% tried to use GitHub tools but struggled or failed. Only around 24% indicated that they use such tools from time to time or on a regular basis.
Therefore, developers who build tools for online researchers will currently only reach a quarter of our respondents if they make their tool only available via services like GitHub, rather than a web or desktop app with user interface.
Least Popular Tools
We also asked our respondents whether there were any tools that they didn’t like or whether they had experienced situations when a specific tool did not help but slowed them down.
Not everyone answered these questions but the limited data we received nevertheless provided insights.
In this case the most disliked tool was Google’s search engine — exactly the same as the favourite tool mentioned earlier. Far fewer respondents (10) indicated the search engine as a tool they did not like compared to those who named it as one of their favourite tools (58).
Critics did not appreciate that Google showed them results that were influenced by their previous searches and mistrusted Google’s use of their own data. Eleven respondents felt that the search engine did not provide sufficiently precise results for the keywords they entered.
The second most disliked tools were those that cost money. One respondent wrote: “As most of my research is at a hobbyist level I can’t really afford subscriptions to some tools that otherwise look useful.” Other respondents pointed out that they were often disappointed when using paid tools because it seemed that such tools were overpriced or did not provide much value compared to free tools.
Some online researchers shared that they struggled to use command line or overly technical tools. “I currently don’t like Python-based tools because my skillset there is low, and I don’t have the flexibility or time to overcome that at the moment”, one person explained.
Several respondents unfavourably compared the marketing language used to sell a tool with its real capabilities. Equally unpopular were tools that had stopped working without an update from the developers. “Nothing’s worse than setting up an environment, and installing a tool only to find out it doesn’t function as advertised”, wrote one respondent.
Also mentioned were people search tools – meaning tools such as Pipl or Skopenow which show any blogs, social media accounts or mail accounts they can find online for a specific person. Survey respondents thought that such tools either did not represent good value for money or that the quality of the results fluctuated.
When asked which tools slowed them down and why, respondents pointed to tools with poor quality instructions or documentation. Several described situations when even after setting up a tool, they were unable to understand how to use it.
Although they named Maltego as a well-liked tool, some of the researchers also had points of criticism. For instance, some found it cumbersome. One wrote: “It is complicated to use, and once the data is in, it has to be reworked so much to be understandable and presentable, that it is not worth it for the type of investigation that I perform.”
Respondents also complained about tools that did not provide anything new or useful, which once used led them to conclude “I could have done everything faster manually”. They felt the same about tools that had been released prematurely, as useful features that could add value were not yet integrated.
Some researchers expressed disappointment about the limitations of reverse image searches. A small number complained specifically about results provided by Google Reverse Image Search — One person wrote: “it changes the picture into text description and searches by that” pointing out that this tended to not provide helpful results. Some also thought the quality of the results had decreased over time. Other online researchers found that reverse image search techniques in general – not only Google’s – did often not provide useful results.
Other respondents pointed out that tools that are not clear about what they can do and what they are not able to do slowed them down. “There have definitely been occasions where a tool has seemed like it might have the functions needed but then doesn’t. So there is time spent in watching limited tutorial videos or searching through limited documentation, installing and/or bug-shooting packages, only to find that it doesn’t have the function you’ve ultimately been searching for”, one person wrote.
Finally, unmaintained tools were also seen as a factor that can slow down the work of researchers.
Open Source Challenges
We asked respondents to share the aspects of their work that they find most challenging. They described these challenges in their own words, which we then categorised into common themes.
Forty-nine out of the 525 participants described verification of online sources – that is, the whole field of photo and video verification – as their biggest challenge. Some specifically mentioned the difficulties in verifying where a photo or video was originally posted online or ways to check the trustworthiness of websites.
In a similar vein, many researchers indicated that they struggle with finding reliable and high quality sources – whether websites or individual content producers. “Knowing where to look, what sources to trust, particularly if it is a new area for me”, one explained.
Respondents also wrote that they struggle to find sources of data which are both free to access and up to date.
A frequent concern was the large amount of information with which researchers are confronted. “Too much information in too many places, too many results”, one respondent wrote. Other researchers described that due to “the sheer volume of information” they tend to get lost or are not sure what to focus on.
In addition, researchers felt overwhelmed by the task of identifying the right tools for their research. “I often face trouble remembering and navigating through the wide variety of tools available”, one person explained. Even when they found useful tools, another wrote, it was hard to know how to choose between them.
Translations also featured in these responses. On one hand, researchers found limitations when looking for online translation services for less widely used languages. They also complained of poor quality translations for some larger languages such as Arabic. On the other hand, even when they had success, researchers still encountered challenges searching for the translated phrases — they feared that certain nuances or connotations may have been lost in translation, affecting the search results.
Respondents also wrote that it was difficult to organise information they had discovered. They wanted the ability to collect online sources of various formats in one place, so as to keep track of their ongoing research or to later revisit it. One person wrote: “I have images saved on my photos, screenshots saved in photos, other info saved as pdf in the Books app, and so on. One tool for all would be great.”
Others felt limited due to their lack of coding skills. In some cases, this hampered their ability to automate a certain step of their research workflow. Several researchers saw the need to use command line tools but did not know how. “Not knowing how to code or interact with code, Github is useless for me and it’s my mistake honestly, I need to get a hold of this”, wrote one respondent.
Another obstacle was the perceived lack of time to conduct research. As one respondent put it: “So much data, so little time”. Another found it particularly challenging to make “crucial decisions for the rest of the investigation based on time management/time”.
A further challenge was a perceived lack of online research experience.
Some respondents also said they struggled with making sense of the online information they collected, or “connecting the dots between the scattered info”.
Other respondents found it difficult simply knowing where to start with an online investigation.
Compounding this challenge was the fear of manipulated information or footage, the difficulty of finding relevant datasets and the complexities of narrowing down search queries to the most useful list of keywords or phrases.
We asked respondents to recall a situation in which they were stuck with their research and describe the tool which could have helped them proceed. Most of the ideas were shared by only one or two of the online researchers and they are therefore not representative for the whole group of our survey respondents. However, we recommend aspiring tool developers to have a look at the list of tool needs to get some insights into very concrete tool ideas that nearly 200 of our respondents identified based on their work.
How do researchers find tools?
All 525 survey respondents answered this question. Most of them used a combination of several channels to learn about tools.
Search engines were the most common way to find tools. Perhaps surprisingly, social media networks did not occupy second or even third place – these were taken by blogs or websites that presented tools, and by reading the work of other researchers.
Nevertheless, the majority of open source researchers still struggle to find the right tools for their work. More than 83% of the survey respondents find it either difficult or time-consuming to find the right tools.
When asked what motivates them to try out a new tool, around 35% of our respondents can be easily convinced to try it out. This category of online researchers considers themselves as “generally curious to learn more about new tools” even if those tools aren’t directly relevant to their work.
The second largest group, just under 29%, indicated that they try out a new tool if they think it might help with specific research. In this case, they are even ready to spend some time learning how to use the tool.
The third group, around 23%, said they felt motivated to try out a new tool if the tool’s description clearly demonstrates what it does and how it works. And 13.5% indicated that they like to try out a new tool after reading how other researchers have used it.
Lessons for Tool Developers
These results clearly show that open source researchers have specific criteria for the tools they would like to see.
First and foremost, tool developers who want to reach a large percentage of this community need to offer tools for free. Since many online researchers do this type of work in their spare time or belong to small teams with tight budgets, they are often not able to pay for access to tools.
Researchers also need detailed documentation on how exactly a tool can be used. If online researchers do not find step-by-step instructions and accessible explanations, many will get frustrated and will most likely not come back to the tool. They also expect to be informed when a tool stops working.
Online researchers also expect transparency from developers about the limitations of their tools. They are very averse to marketing language and efforts to oversell a tool’s capabilities.
Tools developers who create apps with user interfaces have the potential to reach significantly more online researchers than those who provide command line tools. Currently, a significant part of the worldwide online researcher community is unable to use the command line. However, a number of researchers have become aware that their lack of technical skills are a limitation and are eager to learn more.
Overall, many online researchers are very open and curious to try out new tools. There are many areas in which new tools could potentially have a huge impact on the work of open source researchers. The efforts of developers who dedicate their time to making open source and online research easier and more effective will be highly welcomed — particularly if they take this feedback into account.
Logan Williams contributed visualisations to this text.
The Bellingcat Investigative Tech Team develops tools for open source investigations and explores tech-focused research techniques. It consists of Aiganysh Aidarbekova, Tristan Lee, Miguel Ramalho, Johanna Wild and Logan Williams. Do you have a question about applying these methods or tools to your own research, or an interest in collaborating? Contact us here.",5
285,"They have become somewhat of an unwanted guest in some quarters in Ireland in recent years, akin to the perception of a foreign millionaire deciding to decamp to Ireland and making it home, telling locals how to do things, enjoying all the spoils, but not really contributing to their communities.
Big data centres are seen as usurpers of Irish land, taking up massive spaces but giving little back, leeching off the electricity grid and pumping little back into the community.
Is the picture that simple? Are they indeed faceless, joyless entities that take, take, take without providing any give?
Or are they an essential part of modern life, allowing us to keep up with instant information in an increasingly instant information age, and something we will come to accept?
Theasked the head of energy research, with direct responsibility for the International Energy Research Centre (IERC), at Tyndall National Institute in Cork, to give an overview.
Professor Brian Norton, who is world-renowned in the field of energy research and is a former president of Dublin Institute of Technology, said a data centre is essentially just that, a centre where data is stored, managed, and processed.
“You know when people talk about the thing being in the cloud, from a computer perspective — the cloud is the big floppy thing in the sky, coming from a big thing called a data centre,"" Prof Norton said.
""They are huge things, there are 2bn sq ft of them in the world, or slightly more. There are about eight million data centres, so they are big and they are abundant.”
It is no exaggeration to say they are ubiquitous, and needed if we are to continue the technological revolution, said Prof Norton.
""They are storing and processing — everything from that to online purchases to everything consumable.”
They are distributed globally for lots of reasons, according to Prof Norton. One is for security, he said.
“Obviously the connections want to be close to the data, but also there is varied legislation around various jurisdictions, on data being stored in that jurisdiction, for reasons of privacy, GDPR regulations, etc.”
These centres process so much essential data, that the society we have been hurtled into in recent years would not be so progressive in technological terms without them, Prof Norton said.
""The big thing, surprisingly, is not so much the data that people produce, but increasingly lots of our kit is connected by what is called the internet of things (IoT)
“Devices are connected to each other automatically, so you can think about things such as condition monitoring in modern motorcars, for example. It directly connects the internet itself and tells the company or the dealer how things are performing.
""The gas turbines, the jet engines in aircraft are always talking to the aircraft manufacturer, telling them how they are doing, for example.
“That kind of information, called the IoT, is a huge amount of data sharing. It is not just data that people produce, but it is data that the machinery around us automatically produces and shares. There is a huge amount of that.”
There are about 75bn devices directly connected to the internet, that are sharing information over the internet without human intervention, according to Prof Norton.
“The very computers we are talking on are sending stuff backwards and forwards all the time, without our intervention, in terms of the background noise and the information about the updating of software, etc. It is a huge, huge thing.
""All that data needs a lot of energy to feed it,"" he said.
According to data from November 2020, there are 66 data centres now operational in Ireland.
Pro-data industry organisation Host In Ireland’s report on the industry, conducted in association with Bitpower Energy Solutions, said that of the 66 data centres, 31 of these are directly operated by the hyperscalers, which make up 80% of the capacity.
Five are leased wholesale data centres, 15 are colocation data centres, and the remaining 15 are smaller private data centres operated by telcos and small providers.
The total design power capacity of all 66 data centres is 834 MW, according to Bitpower chief executive David McAuley.
“We estimate this is 630 MW of IT capacity running at 55% utilisation. Note also that completed data centres may take a number of years to reach full occupancy,” he said in the report.
The report estimates construction spend will have amounted to €1.25bn in 2020.
“We expect this to increase to €1.5bn in 2021 and in 2022. In total, the pipeline amounts to €6.7bn in new construction in the five years from 2021 to 2025. This compares to a similar amount of investment in data centre construction over the previous 10 years. The pace of investment will double,” Mr McAuley said.
President and founder of Host In Ireland Garry Connolly was at pains to point out in the report that while exports fell across many traditionally strong industry sectors in Ireland due to the Covid-19 pandemic, IT remained robust.
“To break it down, €117bn of the total €448bn of Irish goods and services exports is due to computer services, accounting for just over one quarter (26%) of Ireland’s export activity. While exports fell dramatically for the vast majority of sectors (transport, tourism, retail to name a few), computer services, pharmaceuticals, and medicinal products have had strong enough performances to buoy the Irish economy as a whole,” he said.
Ireland has the potential to generate 9.2 gigawatts of renewable electricity by 2030, far more than needed for Irish consumption, Mr Connolly said.
He pointed to the Irish Academy of Engineering’s recent report on the 'Future of Electricity Transmission in Ireland', which said “one could indeed argue that there is little point in constructing large amounts of renewable generation in Ireland and then exporting its output at exceptionally low prices.
“Official CSO and SEAI import/export data for 2019 indicates that the price of Irish electricity exports, which take place predominantly when wind generation is high, is less than 50% of the price paid to wind generators for that output under the REFIT regime,” the Irish Academy of Engineering report states.
REFIT is designed to ensure Ireland meets its goal of 40% of electricity coming from renewable sources by 2020.
Mr Connolly echoed the sentiments. “As we see with other natural resources, the value-add of a data service is greater than the renewable electricity alone. Add to that, the infrastructure to move data already exists whereas the infrastructure to move the electricity does not.
“It continues to be an exciting time for the data centre industry. The work being carried out is having a real impact on our lives every day. While much in the future remains uncertain, I am optimistic that an abundance of opportunities still lay ahead for Ireland and its digital economy.”
Sceptics want clear and incontrovertible evidence that data centres are a good thing for Ireland as a whole, and they have not been persuaded so far.
Sinn Féin senator Lynn Boylan told the Seanad in December that the public perception of data centres was one of worry and scepticism.
“I am here to raise the deeply concerning proliferation of data centres in the country. It seems they are now a new frontier for extraction where our cool climate and windy hillsides are ripe for the taking. We know that data centres are popping up all over the country and with them comes windfarms and fossil fuel energy generators.”
There was so-called greenwashing at play, she said, referring to the practice of appearing more climate-friendly than the reality.
“Despite the best efforts of tech giants to greenwash the impact they are having, the figures do not lie. The surge in Irish data centres comes with a massive carbon footprint. They pretend that big tech is a clean industry but it requires a huge amount of energy to power the servers and fans to suck in cool air. Each video on file on the internet has to be stored in these data centres.”
By 2027, data centres will consume 31% of Ireland's electricity, Ms Boylan said.
“Across Europe, while energy use is decreasing, in Ireland we are an anomaly because it is increasing. That has nothing to do with our household or population growth. It is purely down to the rise in the number of data centres. They will require 12.5 TW [terawatts] of electricity above what is being provided. That is enough power for 24m homes.”
These data centres should be treated like the carbon-intensive industry that they are, Ms Boylan said.
“It seems there is a greenwashing campaign in full spin because we hear that data centres will be 100% powered by renewables. However, the amount of energy projected to come from their windfarms is far outstripped by the demand from these data centres.
“On top of that, each megawatt of wind capacity must be backed up with energy generated from fossil fuels. This is not to mention the fallout of the biodiversity disaster in the Meenbog windfarm, which has a contract with Amazon. While pilot projects in which waste energy is sold to heat homes or public buildings are welcome, they barely put a dent in emissions.”
Big data has been given a “free pass” by the Government, Ms Boylan claimed.
“When we hear talk of the cloud, it is as though it has no material impact but the truth is it is bad for climate and to date, the Government has given the industry a free pass while the public is left to carry the bulk of the massive cost for the infrastructure required to run these data centres.
“The Irish Academy of Engineering estimates that we will need €9bn of new infrastructure. It seems the Government strategy has been so successful in attracting data centres that we now have an enormous and disproportionate amount of western Europe's data infrastructure, and with that comes these colossal CO2 emissions.”
Community Development Minister Joe O’Brien said while data centres can consume very large amounts of energy, they have a flat and predictable demand profile.
That means they use the same amount of electricity day and night, therefore requiring a range of generation technologies to meet demand, he said.
“Data centres have, until recent years, accounted for less than 2% of Ireland's total electricity demand. EirGrid, in its generation capacity statement for 2019 to 2028, projects that demand from data centres could account for 29% of all demand by 2028.
“Significant increases in volumes of generation capacity, including from renewable energy resources, will be required to meet Ireland's electrification objectives and demand from heat pumps, electric vehicles, and data centres. The climate action plan set an ambition of 70% renewable electricity by 2030, the majority of which will be met through the renewable electricity support scheme, RESS.
“When data centre operators purchase electricity directly from renewable generators, it contributes to the State's objective to decarbonise our electricity system without any subsidy from electricity customers,” he said.
In February, Independent TD Denis Naughten said families must not carry the can for big data, and that the bigger picture of what is needed for households was going unpainted.
“As a result of the pandemic, families' heating bills have gone up dramatically and that has been compounded by increased carbon taxes and the subsidising of data centres,"" said Mr Naughten.
“There was a 9% increase in residential carbon emissions during the 2020 lockdown and we have seen a fall-off in the retrofitting of homes, which commenced in 2019 and collapsed in 2020. We need a step-change in retrofitting homes and that needs to be prioritised as part of the capital plan.”
Mr Naughten’s comments echoed Labour TD Duncan Smith’s scepticism, which he raised around the same time Ms Boylan raised her concerns in December.
Mr Smith said big industry collaborating together would be the big winners, not the average citizen.
“The renewable energy that is coming on stream will not be State-owned. It will be privatised so we will be going from big oil to big wind — I hope we can find another phrase. This is where we are going.
“The Government needs to tell us how much of the renewable energy coming on stream will be siphoned off for other multinational corporations such as those running data centres that are entering into prepaid contracts with companies that own windfarms to siphon off up to 15%, 20%, or 25% of the energy created in order to power data centres, which are huge carbon emitters and very poor in terms of creating jobs.
“There is a structure here that will only get bigger and will be bad for the worker, the economy, and the Irish taxpayer because we will continue to pay these exorbitant penalties to countries that are doing things far better than us.”
Environment Minister Eamon Ryan has moved to assuage critics by saying the Government would be cognisant of all stakeholders.
However, data centres are here to stay, he added.
“We will probably take a combination of various approaches, but one of the things we will ensure is that demand, be it from data centres or other large energy users, is planned in a way that lowers the cost, minimises emissions, and ensures we have a fully sustainable system.
“That may involve locating data centres close to where the power is, or restricting in certain areas where the grid cannot cope with the addition. However, it will not say no to data centres because we need them as part of the wider economy.”
Why have data centres become a major presence in Ireland in recent years? Geography and happenstance mostly, according to Prof Brian Norton from the Tyndall.
""There are lots of reasons why data centres are near us. They command a whole lot of different dimensions. One is that Ireland is not a bad climate for data centres, because there is a huge coolant. You don’t want to put them in hot places because there is a bigger cooling load. Places like Ireland are good locations.
“Also, you do want data centres that are proximate to where the network nodes are, and Ireland has lines coming across the Atlantic and lines going to the UK and Europe. If you think about the physical geography of the Earth, you’ve got certain points where major cables land, and there are natural nodes.
“You expect to see big data centres on the coasts of the US, you expect to see them on the coasts of Europe, because of the cables going under the sea that turn up in those places. They are the physical, geographical, climatic reasons — there are natural geographies and climates of the world that you want to put things in,” he said.
It is a coincidence of facts such as geography and climate, according to Prof Norton.
“You don’t want them in hot climates because it just increases the cooling load and it has to do with legislation and oversight of rights to privacy and what is done with your data. It is a combination of all those facts.
“The other reason is the sanctity and security of the data itself, and more importantly, the operations on that data. For example, in Europe, there are legitimate concerns about privacy, what people have when it comes to their rights.
“Similar privacy laws would not exist in the US and they would not exist in China. From a legislative perspective, the ability to take action if you feel your data has been misused is obviously limited outside the jurisdiction. For those reasons, people like things to be stored locally.”
While data centres consume and create lots of energy and waste, the ever-burgeoning field of renewable solutions can play a major role in mitigation, he said, adding that that that needs imagination and invention.
“Most of that energy in a data centre typically is used for the IT equipment, the servers that are in the data centres, and about half of it is to do with cooling systems one way or another around those, that is how the energy ends up being used within. All of that ends up being released as very, very low-grade heat. It is lukewarm air, essentially.
When people see data centres returning the favour on a mass scale, hearts and minds should be less sceptical, according to Prof Norton. “To be fair, a lot of people who run data centres are committed to running them 100% renewably. That will happen because of the decarbonisation of electricity anyway, but nevertheless, they are committed to that.
“But you’ve got to remember that data centres produce a huge amount of waste heat, and you do see various projects around the world of taking it into greenhouses, so you look at food production — in other words, using that heat in various processes.
“Drying things for food preservation is another, for example. Or industrial processes that have a drying component associated with them. Co-locating them then would provide employment and added value.”
Distributing that excess energy into communities would assist in the transition to a new renewable and sustainable economy in rural regions, Prof Norton said.
“Thinking a bit more holistically, and thinking of data centres as part of an ecosystem in particular locations, so that you are looking at distributed production of rural energy locally and distributed use of the huge amounts of waste heat that data centres produce.”
Earning public trust is vital if data centres are to be accepted, according to Prof Brian Norton.
“Planning comes into wider issues of public trust. Who bears the cost in terms of the impact of data centres, as opposed to the cost of money? Who benefits? I think one of the challenges with planning law generally, but in Ireland in particular, is that someone might object to a big local data centre because they cannot see the benefit to them because it accrues to someone else.”
Part of the issue with all these things is being able to articulate and genuinely show an actual benefit to the people who are going to have to bear the things, according to Prof Norton.
“That is the root problem with that. In some jurisdictions, the public policy debate outside of the particular project is much more mature and advanced, and the understanding happens. There are lots of examples of this — in Denmark, if you take wind energy, they have had a planning regime which would designate sites where you could do projects with wind energy, and then you apply to build the thing on those sites.”
Ireland has done it the other way around, he said. “Rather than having to go and seek permission for a particular place, there is a public policy debate outside of any particular promoter or any particular technology. In other words, we have got to have these things, where shall we put them? Whereas in Ireland, it is done the opposite way around — someone has to prove their case and then objections come.
“In the likes of Denmark, It still has a lot of debate, it still has a lot of the exact same voices, but the decision has been made at a large-scale level — this is where we are going to do these things, these are the areas where we are not, and then people who are building data centres or windfarms know where they stand.”
The dotting of the landscape — or blotting, considering their size and scale — of data centres is similar to when Ireland was in the throes of electrification, according to Prof Norton.
“It is interesting in Ireland, for example, electrification in the past was seen as a sign of progress and people would have bought into pylons as a sign of advancement. You are now seeing that progress has happened, you are seeing electrification that is about transmitting energy from the west where you have lots of wind and wave energy, to the east where the population is, and the people in the middle are not seeing any benefit to themselves. You can see some of the tensions that arise from that.
“There are ways of solving this problem. There are actual benefits accruing to those people, and systems must be designed so they see those benefits.
“There are industries that obviously work around data centres; there is a whole software sector, there is a whole design sector — those people doing that kind of work might be in the centre of cities. The internet is ubiquitous, so could more of those jobs be in rural areas?
“You could be providing rural employment on a distributed basis. Although working from home in its present guise has a whole range of issues attached to it, it has demonstrated that people can indeed do so. It may not have to be the case to have one part somewhere and another part somewhere else, when it comes to the benefits.”
Ireland has proved itself capable of getting the balance right in the past, he said.
""That does need a good strong national broadband to do that, for example, but that is the sort of investment you need to get that sense of equity that is necessary.
""I don’t think it is the planning process at fault, it is the public equity discussion underpinning that which can be the challenge.”
One thing everyone agrees on is that Ireland’s electricity system will have to become more robust to handle the surge in demand over the coming decades, as well as reducing emissions.
Powering data centres is merely one part of the jigsaw, according to a report from experts at Cork-based MaREI — SFI Research Centre for Energy, Climate and Marine Research, in conjunction with the Electricity Association of Ireland.
Laura Mehigan and Dr Paul Deane, in their summary, state that a decarbonised, all-island electricity system is key to achieving climate ambition on the island of Ireland.
“This study takes a closer look at the future all-island power system through the lens of decarbonisation by focusing on the year 2030, where over 70% of the annual electricity on the system will be renewable.
“While this requires a significant level of renewable energy build-out, it also demands a resilient power system capable of absorbing and storing fluctuations in weather-driven generation, and at the same time, meeting the demand of new electricity loads from electric cars, residential heating, and data centres.
Due to its isolated grid, the current level of wind generation is limited to ensure system strength is maintained, the authors said.
Achieving a minimum of 70% renewable electricity by 2030 will require significant infrastructure investment as well as capacity to integrate new storage technologies, they said.
“According to the Government’s Climate Action Plan in Ireland, the level of wind capacity may have to increase by up to 300% to achieve the higher level of ambition but also to absorb new electricity loads from electric cars, electric heat pumps, and significant growth in Ireland’s data centre industry.”
The all-island electricity system in 2030 will be different in scale and configuration from the system we see today, according to the authors.
The key findings of the report indicated that the system will be 40% larger in capacity and will emit half of the carbon emissions of today.
In 2030, we will need all planned electricity interconnectors: North-South, Ireland-UK, and Ireland-France in place. Back-up generation fuelled by natural gas will be essential but used less, they said.
In cold, windless, and cloudy conditions, where electricity demand is high but weather dependant generation is low, we will need all back-up generation to be available and all storage and system flexibility to be maximised.
A much more flexible and agile electricity grid will be needed to absorb the projected level of weather dependant generation, the authors said.",5
286,"In 2020, a Korean documentary team invited on its show a mother who had lost her 7-year-old daughter to an incurable disease. The girl’s death was so sudden — she died a week after being diagnosed in 2016 — the mother, Jang Ji-Sun, did not have a chance to say goodbye. For three years she was obsessed with the loss of her daughter.
The producers of the documentary, “Meeting You,” created a digitized re-creation of the child that the mother could see through a virtual reality headset (the TV audience was also able to see the image of the daughter).
On the show, the virtual girl, Na-yeon, appeared from behind a woodpile and runs toward her mother, calling, “Mom.” The mother burst into tears and said, “Mom missed you so much, Na-yeon.” A video of the show reportedly received 19 million views. While the experience was painful, the mother told the Korean Times that she would do it again if she could; she finally got a chance to say goodbye.
“I was worried how the mother would react” to the digitized daughter, the producer of the documentary, Kim Jong-woo, told the newspaper. “No matter how hard we tried to make the character similar, she still can tell the difference. But she said she was happy to see even the slight reflection of Na-yeon.”
People have always craved post-death contact with their loved ones. Efforts to remain in touch with the dead have existed for eons, such as photographing deceased children, holding seances and even keeping a corpse in the house for posterity. But artificial intelligence and virtual reality, along with other technological advances, have taken us a huge step closer to bringing the dead back to life.
“It’s something that’s very fundamental to humans, to keep a connection to something they loved,” said Sherman Lee, a psychology associate professor at the Christopher Newport University in Newport News, Va., and director of the Pandemic Grief Project.
A continuing bond with a loved one — such as by listening to old voice mails, watching old videos and engaging with chatbots that can speak in a loved one’s voice — can bring comfort. But it also can exacerbate the grief, particularly for those whose loved ones died by suicide, as people relive the loss anew, research shows.
“If you’re asking me, Is watching videos of your deceased spouse every night a helpful thing to do, instead of re-engaging the world again and spending that time with friends and family? No, I don’t think it’s helpful,” Lee said. “But that said, would it be helpful to smash all of the videos and lock them up in a room? That’s going to make the grieving process worse.”
Science has definitely taken an interest in connecting the bereaved with their loved ones.
For instance, Hossein Rahnama, a professor at Toronto Metropolitan University and a research affiliate with MIT Media Lab, has been building a platform called Augmented Eternity, which allows someone to create a digital persona from a dead person’s photos, texts, emails, social media posts, public statements and blog entries that will be able to interact with relatives and others.
To make reliable predictions of what the deceased might have said, the models need vast amounts of data. Rahnama said that will work well for millennials, who post everything they do on the internet, but less well for older people who aren’t as online focused or savvy. Rahnama receives emails almost weekly from people who are terminally ill, asking if there is a way to conserve their legacy for their loved ones. He said he now has a beta group of 25 people testing his product. His goal is for consumers to one day be able to create their own eternal digital entities.
In June, Amazon unveiled a new feature it’s developing for Alexa, in which the virtual assistant can read aloud stories in a deceased loved one’s voice after just hearing a minute of that person’s speech. (Amazon founder Jeff Bezos owns The Washington Post.) “While AI can’t eliminate that pain of loss, it can definitely make their memories last,” said Rohit Prasad, senior vice president and head scientist for Amazon Alexa.
And several entrepreneurs in the AI sphere, including James Vlahos of HereAfter AI and Eugenia Kuyda, who co-founded AI start-ups Luka and Replika, have turned their efforts toward virtual representations of people, using data from their digital footprint to craft an avatar or chatbot that can interact with family members after they’ve passed.
HereAfter’s app takes users through an interview process before they’ve died, prompting them to recollect stories and memories that are then recorded. After they’ve passed, family members can ask questions, and the app responds in the deceased’s voice using the accumulated interview information, almost like it’s engaging in a conversation.
Vlahos, HereAfter’s chief executive, said he was motivated to start the company after building a chatbot — or Dadbot as he calls it — from about a dozen hour-long recordings he made of his father after his dad was diagnosed with terminal lung cancer in 2016.
Vlahos transcribed those conversations and gathered his own memories of his dad. He then used a software platform called PullString to program the Dadbot. Vlahos spent a year inputting strings of conversation and teaching the bot to interpret what people said to it. When sent a message or asked a question, the Dadbot would respond similarly to how his father would, either with a text message, audio of a story or song, or even a photo.
He chats with the Dadbot every month or so, whenever he wants to hear his voice. One time, he went to a spot where his father’s ashes were scattered, overlooking Memorial Stadium at the University of California’s Berkeley campus, where his father rarely missed a football game, and asked the Dadbot to sing him a Cal spirit song, which it then did.
Vlahos said the Dadbot doesn’t make him miss his father any less. “But I do love that he can feel more present to me, with the aspects of his personality that I love so much less clouded by the passage of time,” he said.
How mourning can affect us mentally and even physically — including blood pressure and the immune system
Kuyda created a chatbot of a dear friend and roommate, Roman Mazurenko, for a similar reason. She and Mazurenko had moved from Moscow to the United States in 2015 and were living together in San Francisco when, on a brief trip back home, Mazurenko was killed by a hit-and-run driver. At the time, her company Luka was building chatbot-based virtual assistants. After Mazurenko died, Kuyda decided to use the 10,000 text messages she and Mazurenko had exchanged — as well as texts Mazurenko had sent to others — to create a digital version of him.
Their communications were just text messages on a messenger app, but to those who knew Mazurenko, his responses on the app were spot on. They sounded just like him because they largely were his responses, but made at another time in another context.
“It was just nice to be able to remember him in a special way and to be able to talk to him like we did before,” she said.
The company made the app, called Roman Mazurenko, publicly available, and people who didn’t even know him began downloading it and texting him. Some reached out to the company requesting that it make bots of their own loved ones.
She was 30 at the time, and he was the first important person in her life to die. She struggled with how someone so ever-present was no longer there. It was like he never existed, she said. “For me, to be able to get back to him, to continue to have the communication we had before, it was sort of therapeutic,” she said. Five years later, she still texts with his chatbot every week or two.
Psychologists say creating a virtual copy of a lost loved one can be therapeutic, especially in cases with unresolved issues, but could it lead to someone wanting to remain in this virtual world of their loved one?
“By giving somebody the ability to see their loved one again, is that going to give them some solace, or is it going to become like an addiction?” says clinical psychologist Albert “Skip” Rizzo, director of Medical Virtual Reality at the Institute for Creative Technologies and a research professor at the University of Southern California’s Keck School of Medicine Department of Psychiatry and Behavioral Sciences.
Grief therapists sometimes invite people to have an imaginary conversation with the deceased, or to write a letter or role play with the therapists. With digital recreations of the dead, particularly in virtual reality, the experience would be more immersive.
Why people want to hold on to their loved ones is understandable.
One of our basic drives is to attach to others, particularly those who provide a secure base, like a parent for a child, said Robert Neimeyer, director of the Portland Institute for Loss and Transition. “These are among our strongest evolutionary imperatives, as beings, and our technologies are recruited to support that goal,” he said.
After the telephone was invented, he said, Thomas Edison was interested in developing a “spirit phone” to somehow communicate with the dead. And seeing a photograph of a deceased son who died at the Gettysburg battle during the Civil War was just as uncanny an experience for a parent then as it is for that mother in the video to see her dead daughter in virtual reality, Neimeyer said.
“What is surreal in one era quickly becomes conventional in the next,” he said. “In general, in life, we don’t grow as people by eliminating who we have loved, how we have loved what we have loved. It’s a question of holding on differently. How can we use this relationship as a resource? I think the technology can contribute to that.”
Read more from Well+Being
Well+Being shares news and advice for living well every day. Sign up for our newsletter to get tips directly in your inbox.
Body: What’s the difference between RSV, the flu and covid-19? You don’t have to worry about your stomach exploding if you overeat. For some with ADHD, brown noise quiets the brain.
Life: The Well+Being gift guide has our picks for the body, mind, pets and more. These five tips from experts can help students take a mental health break from college. What to feed and not feed pets from holiday dishes.
Food: Diet changes can improve sleep apnea, even without weight loss. Fiber alters the microbiome and may boost cancer treatment. How to support your sober friends when everyone is drinking.
Fitness: Dogs and humans both can get dementia, and more walks can help. Pickleball is popular, but how much exercise are you really getting? This is the speedy scientific workout you can do almost anywhere.
Mind: Tips for parents to help teens struggling with mental health issues. Want to feel happier? Try snacking on joy. Three ways to fix sleep issues when nothing else works.",6
287,"SACRe PhD programme (PSL)
The SACRe (Science, Art, Creation and Research) art doctoral programme was put in place by PSL Research University based in Paris (PSL). This PhD programme brings together La Fémis, ENSAD (the National Graduate School for Decorative Arts), ENSBA (the National Graduate School for Fine Arts), the CNSMDP (the National Academy of Dance and Music of Paris), the CNSAD (National Academy of the Dramatic Arts) and the ENS (École normale supérieure).
The teaching includes a common core syllabus followed by all SACRe PhD students from various artistic disciplines or exact, human and social sciences, plus a programme specific to each school.
This programme is aimed at any student wishing to obtain an art PhD in the area of film studies holding a Master’s degree.",2
288,"Ironies of automation, Bainbridge, Automatica, Vol. 19, No. 6, 1983
With thanks to Thomas Depierre for the paper recommendation.
Making predictions is a dangerous game, but as we look forward to the next decade a few things seem certain: increasing automation, increasing system complexity, faster processing, more inter-connectivity, and an even greater human and societal dependence on technology. What could possibly go wrong? Automation is supposed to make our lives easier, but
if when it goes wrong it can put us in a very tight spot indeed. Today’s paper choice, ‘Ironies of Automation’ explores these issues. Originally published in this form in 1983, its lessons are just as relevant today as they were then.
The central irony (‘combination of circumstances, the result of which is the direct opposite of what might be expected’) referred to in this paper is that the more we automate, and the more sophisticated we make that automation, the more we become dependent on a highly skilled human operator.
Automated systems need highly skilled operators
Why do we automate?
The designer’s view of the human operator may be that the operator is unreliable and inefficient, so should be eliminated from the system.
An automated system doesn’t make mistakes in the same way that a human operator might, and it can operate at greater speeds and/or lower costs than a human operator. The paper assumes a world in which every automated task was previously undertaken by humans (the context is industrial control systems), but of course we have many systems today that were born automated. One example I found myself thinking about while reading through the paper does have a human precedence though: self-driving cars.
In an automated system, two roles are left to humans: monitoring that the automated system is operating correctly, and taking over control if it isn’t. An operator that doesn’t routinely operate the system will have atrophied skills if ever called on to take over.
Unfortunately, physical skills deteriorate when they are not used, particularly the refinements of gain and timing. This means that a formerly experienced operator who has been monitoring an automated process may now be an inexeperienced one.
Not only are the operator’s skills declining, but the situations when the operator will be called upon are by their very nature the most demanding ones where something is deemed to be going wrong. Thus what we really need in such a situation is a more, not a lesser skilled operator! To generate successful strategies for unusual situtations, an operator also needs good understanding of the process under control, and the current state of the system. The former understanding develops most effectively through use and feedback (which the operator may no longer be getting the regular opportunity for), the latter takes some time to assimilate
We’ve seen that taking over control is problematic, but there are issues with the monitoring that leads up to a decision to take over control too. For example, here’s something to consider before relying on a human driver to take over the controls of a self-driving car in an emergency:
We know from many ‘vigilance’ studies (Mackworth, 1950) that it is impossible for even a highly motivated human being to maintain effective visual attention towards a source of information on which very little happeens, for more than about half an hour. This means that is is humanely impossible to carry out the basic function of monitoring for unlikely abnormalities, which therefore has to be done by an automatic alarm system connected to sound signals…
But who notices when the alarm system is not working properly? We might need alarms on alarms! Section 2.1 in the paper has a nice section on the challenges of what we would now call ‘gray failure‘ too:
Unfortunately automatic control can ‘camouflage’ system failure by controlling against the variable changes, so that trends do not become apparant until they are beyond control. This implies that the automatics should also monitor unusual valiable movement. ‘Graceful degradation’ of performance is quoted in “Fitt’s list” of man-computer qualities as an advantage of man over machine. This is not an aspect of human performance to be aimed for in computers, as it can raise problems with monitoring for failure; automatic systems should fail obviously.
A straight-forward solution when feasible is to shutdown automatically. But many systems, “because of complexity, cost, or other factors” must be stabilised rather than shutdown. If very fast failures are possible, with no warning from prior changes so that an operator’s working memory is not up to speed, then reliable automatic response is necessary, and if this is not possible then the process should not be built if the costs of failure are unacceptable.
What can we do about it?
One possibility is to allow the operator to use hands-on control for a short period in each shift. If this suggestion is laughable then simulator practice must be provided.
Chaos experiments and game-days are some of the techniques we use today to give operators experience with the system under various scenarios. Simulators can help to train basic skills, but are always going to be limited: ‘unknown faults cannot be simulated, and system behaviour may not be known for faults which can be predicted but have not been experienced.’
No-one can be taught about unknown properties of the system, but they can be taught to practise solving problems with the known information.
One new innovation at the time this paper was written was the possibility of using “soft displays on VDUs” to design task-specific displays. But changing displays bring their own challenges. Bainbridge offers three suggestions:
- There should be at least one source of information permanently available for each type of information that cannot be mapped simply onto others
- Operators should not have to page between displays to obtain information about abnormal states in parts of the process other than the one they are currently thinking about, nor between displays giving information needed within one decision process.
- Research on sophisticated displays should concentrate on the problems of ensuring compatibility between them, rather than finding which independent display is best for one particular function without considering its relation to information for other functions.
It’s quite likely in many cases that we end up in a situation where a computer is controlling some aspects of a system, and the human operator others. The key thing here is that the human being must always know what tasks the computer is dealing with and how.
Perhaps the final irony is that it is the most successful automated systems, with rare need for manual intervention, which may need the greatest investment in human operator training… I hope this paper has made clear both the irony that one is not by automating necessarily removing the difficulties, and also the possibility that resolving them will require even greater technological ingenuity than does classic automation.
This puts me in mind of Kernighan’s Law (“Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.”). If we push ourselves to the limits of our technological abilities in automating a system, how then are we going to be able to manage it?",2
289,"Blindsight
Blindsight is the ability of people who are cortically blind due to lesions in their striate cortex, also known as the primary visual cortex or V1, to respond to visual stimuli that they do not consciously see.[1] The term was coined by Lawrence Weiskrantz and his colleagues in a paper published in Brain[2] in 1974. A similar paper in which the discriminatory capacity of a cortically blind patient had been studied was published in Nature[3] in 1973.
The majority of studies on blindsight are conducted on patients who are hemianopic, i.e. blind in one half of their visual field. Following the destruction of the left or right striate cortex, patients are asked to detect, localize, and discriminate amongst visual stimuli that are presented to their blind side, often in a forced-response or guessing situation, even though they may not consciously recognize the visual stimulus. Research shows that such blind patients may achieve a higher accuracy than would be expected from chance alone. Type 1 blindsight is the term given to this ability to guess—at levels significantly above chance—aspects of a visual stimulus (such as location or type of movement) without any conscious awareness of any stimuli. Type 2 blindsight occurs when patients claim to have a feeling that there has been a change within their blind area—e.g. movement—but that it was not a visual percept.[4] The re-classification of blindsight into Type 1 and Type 2 was made after it was shown that the most celebrated blindsight patient, ""GY"", was in fact usually conscious of stimuli presented to his blind field if the stimuli had certain specific characteristics, namely being of high contrast and moving fast (at speeds in excess of 20 degrees per second).[5][6] In fact, in the aftermath of the First World War, a neurologist, George Riddoch, had described patients who had been blinded by gunshot wounds to V1, who could not see stationary objects but who were, as he reported, ""conscious"" of seeing moving objects in their blind field.[7] It is for this reason that the phenomenon has more recently also been called the Riddoch syndrome.[8] Since then it has become apparent that such subjects can also become aware of visual stimuli belonging to other visual domains, such as color and luminance, when presented to their blind fields.[9] The ability of such hemianopic subjects to become consciously aware of stimuli presented to their blind field is also commonly referred to as ""residual"" or ""degraded"" vision.[10][11]
As originally defined, blindsight challenged the common belief that perceptions must enter consciousness to affect our behavior, by showing that our behavior can be guided by sensory information of which we have no conscious awareness.[12] Since demonstration that blind patients can experience some visual stimuli consciously, and the consequent redefinition of blindsight into Type 1 and Type 2, a more nuanced view of the phenomenon has developed.[11][8][10] Blindsight may be thought of as a converse of the form of anosognosia known as Anton syndrome, in which there is full cortical blindness along with the confabulation of visual experience.
History[edit]
Much of our current understanding of blindsight can be attributed to early experiments on monkeys. One monkey, named Helen, could be considered the ""star monkey in visual research"" because she was the original blindsight subject.[citation needed] Helen was a macaque monkey that had been decorticated; specifically, her primary visual cortex (V1) was completely removed, blinding her. Nevertheless, under certain specific situations, Helen exhibited sighted behavior. Her pupils would dilate and she would blink at stimuli that threatened her eyes. Furthermore, under certain experimental conditions, she could detect a variety of visual stimuli, such as the presence and location of objects, as well as shape, pattern, orientation, motion, and color.[13][14][15][page needed] In many cases she was able to navigate her environment and interact with objects as if she were sighted.[16]
A similar phenomenon was also discovered in humans. Subjects who had suffered damage to their visual cortices due to accidents or strokes reported partial or total blindness. Despite this, when prompted they could ""guess"" the presence and details of objects with above-average accuracy and, much like animal subjects, could catch objects tossed at them. The subjects never developed any kind of confidence in their abilities. Even when told of their successes, they would not begin to spontaneously make ""guesses"" about objects, but instead still required prompting. Furthermore, blindsight subjects rarely express the amazement about their abilities that sighted people would expect them to express.[17]
Describing blindsight[edit]
Patients with blindsight have damage to the system that produces visual perception (the visual cortex of the brain and some of the nerve fibers that bring information to it from the eyes) rather than to the underlying brain system controlling eye movements.[12] The phenomenon was originally thought to show how, after the more complex perception system is damaged, people can use the underlying control system to guide hand movements towards an object even though they cannot see what they are reaching for.[12] Hence, visual information can control behavior without producing a conscious sensation. This ability of those with blindsight to act as if able to see objects that they are unconscious of suggested that consciousness is not a general property of all parts of the brain, but is produced by specialised parts of it.[12]
Blindsight patients show awareness of single visual features, such as edges and motion, but cannot gain a holistic visual percept. This suggests that perceptual awareness is modular and that—in sighted individuals—there is a ""binding process that unifies all information into a whole percept"", which is interrupted in patients with such conditions as blindsight and visual agnosia.[1] Therefore, object identification and object recognition are thought to be separate processes and occur in different areas of the brain, working independently from one another. The modular theory of object perception and integration would account for the ""hidden perception"" experienced in blindsight patients. Research has shown that visual stimuli with the single visual features of sharp borders, sharp onset/offset times,[18] motion[19] and low spatial frequency[20] contribute to, but are not strictly necessary for, an object's salience in blindsight.
Cause[edit]
There are three theories for the explanation of blindsight. The first states that after damage to area V1, other branches of the optic nerve deliver visual information to the superior colliculus, pulvinar[21] [22] and several other areas, including parts of the cerebral cortex. In turn, these areas might then control the blindsight responses.
Another explanation for the phenomenon of blindsight is that even though the majority of a person's visual cortex may be damaged, tiny islands of functioning tissue remain.[23] These islands are not large enough to provide conscious perception, but nevertheless enough for some unconscious visual perception.[24]
A third theory is that the information required to determine the distance to and velocity of an object in object space is determined by the lateral geniculate nucleus (LGN) before the information is projected to the visual cortex. In a normal subject, these signals are used to merge the information from the eyes into a three-dimensional representation (which includes the position and velocity of individual objects relative to the organism), extract a vergence signal to benefit the precision (previously auxiliary) optical system, and extract a focus control signal for the lenses of the eyes. The stereoscopic information is attached to the object information passed to the visual cortex.[25]
More recently, with the demonstration of a direct input from the LGN to area V5 (MT),[26][27][28][29] which delivers signals from fast moving stimuli at latencies of about 30 ms,[30][31] another explanation has emerged. This one proposes that the delivery of these signals is sufficient to arouse a conscious experience of fast visual motion, without implying that it is V5 alone that is responsible, since once signals reach V5, they may be propagated to other areas of the brain.[8][32][33] The latter account would seem to exclude the possibility that signals are ""pre-processed"" by V1 or ""post-processed"" by it (through return connections from V5 back to V1), as has been suggested.[34] The pulvinar nucleus of the thalamus also sends direct, V1 by-passing, signals to V5[35] but their precise role in generating a conscious visual experience of motion has not yet been determined.
Evidence of blindsight can be indirectly observed in children as young as two months, although there is difficulty in determining the type in a patient who is not old enough to answer questions.[36]
Evidence in animals[edit]
In a 1995 experiment, researchers attempted to show that monkeys with lesions in or even wholly removed striate cortexes also experienced blindsight. To study this, they had the monkeys complete tasks similar to those commonly used for human subjects. The monkeys were placed in front of a monitor and taught to indicate whether a stationary object or nothing was present in their visual field when a tone was played. Then the monkeys performed the same task except the stationary objects were presented outside of their visual field. The monkeys performed very similar to human participants and were unable to perceive the presence of stationary objects outside of their visual field.[37]
Another 1995 study by the same group sought to prove that monkeys could also be conscious of movement in their deficit visual field despite not being consciously aware of the presence of an object there. To do this, researchers used another standard test for humans which was similar to the previous study except moving objects were presented in the deficit visual field. Starting from the center of the deficit visual field, the object would either move up, down, or to the right. The monkeys performed identically to humans on the test, getting them right almost every time. This showed that the monkey's ability to detect movement is separate from their ability to consciously detect an object in their deficit visual field, and gave further evidence for the claim that damage to the striate cortex plays a large role in causing the disorder.[38]
Several years later, another study compared and contrasted the data collected from monkeys and that of a specific human patient with blindsight, GY. GY's striate cortical region was damaged through trauma at the age of eight, though for the most part he retained full functionality, GY was not consciously aware of anything in his right visual field. In the monkeys, the striate cortex of the left hemisphere was surgically removed. By comparing the test results of both GY and the monkeys, the researchers concluded that similar patterns of responses to stimuli in the ""blind"" visual field can be found in both species.[39]
Research[edit]
Lawrence Weiskrantz and colleagues showed in the early 1970s that if forced to guess about whether a stimulus is present in their blind field, some observers do better than chance.[40][page needed] This ability to detect stimuli that the observer is not conscious of can extend to discrimination of the type of stimulus (for example, whether an 'X' or 'O' has been presented in the blind field).
Electrophysiological evidence from the late 1970s has shown that there is no direct retinal input from S-cones to the superior colliculus, implying that the perception of color information should be impaired.[41][42][43] However, more recent evidence point to a pathway from S-cones to the superior colliculus, opposing previous research and supporting the idea that some chromatic processing mechanisms are intact in blindsight.[44][45]
Patients shown images on their blind side of people expressing emotions correctly guessed the emotion most of the time. The movement of facial muscles used in smiling and frowning were measured and reacted in ways that matched the kind of emotion in the unseen image. Therefore, the emotions were recognized without involving conscious sight.[46]
A 2011 study found that a young woman with a unilateral lesion of area V1 could scale her grasping movement as she reached out to pick up objects of different sizes placed in her blind field, even though she could not report the sizes of the objects.[47] Similarly, another patient with unilateral lesion of area V1 could avoid obstacles placed in his blind field when he reached toward a target that was visible in his intact visual field. Even though he avoided the obstacles, he never reported seeing them.[48]
A study reported in 2008 asked patient GY to misstate where in his visual field a distinctive stimulus was presented. If the stimulus was in the upper part of his visual field, he was to say it was in the lower part, and vice versa. He was able to misstate, as requested, in his left visual field (with normal conscious vision); but he tended to fail in the task—to state the location correctly—when the stimulus was in his blindsight (right) visual field.[49] This failure rate worsened when the stimulus was clearer,[49] indicating that failure was not simply due to unreliability of blindsight.
Case studies[edit]
This section's tone or style may not reflect the encyclopedic tone used on Wikipedia. (January 2018)
Researchers applied the same type of tests that were used to study blindsight in animals to a patient referred to as ""DB"". The normal techniques used to assess visual acuity in humans involved asking them to verbally describe some visually recognizable aspect of an object or objects. DB was given forced-choice tasks to complete instead. The results of DB's guesses showed that DB was able to determine shape and detect movement at some unconscious level, despite not being visually aware of this. DB themselves chalked up the accuracy of their guesses to be merely coincidental.[50]
The discovery of the condition known as blindsight raised questions about how different types of visual information, even unconscious information, may be affected and sometimes even unaffected by damage to different areas of the visual cortex.[51] Previous studies had already demonstrated that even without conscious awareness of visual stimuli, humans could still determine certain visual features such as presence in the visual field, shape, orientation and movement.[50] But, in a newer study evidence showed that if damage to the visual cortex occurs in areas above the primary visual cortex, the conscious awareness of visual stimuli itself is not damaged.[51] Blindsight shows that even when the primary visual cortex is damaged or removed a person can still perform actions guided by unconscious visual information. Despite damage occuring in the area necessary for conscious awareness of visual information, other functions of the processing of these visual percepts are still available to the individual.[50] The same also goes for damage to other areas of the visual cortex. If an area of the cortex that is responsible for a certain function is damaged, it will only result in the loss of that particular function or aspect, functions that other parts of the visual cortex are responsible for remain intact.[51]
Alexander and Cowey investigated how contrasting stimuli brightness affects blindsight patients' ability to discern movement. Prior studies have already shown that blindsight patients are able to detect motion even though they claim they do not see any visual percepts in their blind fields.[50] The study subjects were two patients who suffered from hemianopsia—blindness in more than half of their visual field. Both subjects had displayed the ability to accurately determine the presence of visual stimuli in their blind hemifields without acknowledging an actual visual percept previously.[52]
To test the effect of brightness on the subject's ability to determine motion they used a white background with a series of colored dots. The contrast of the brightness of the dots compared to the white background was altered in each trial to determine if the participants performed better or worse when there was a larger discrepancy in brightness or not.[52] The subjects focused on the display for two equal length time intervals and where asked whether they thought the dots were moving during the first or the second time interval.[52]
When the contrast in brightness between the background and the dots was higher, both of the subjects could discern motion more accurately than they would have statistically through guesswork. However, one subject was not able to accurately determine whether or not blue dots were moving regardless of the brightness contrast, but he/she was able to do so with every other color dot.[52] When the contrast was highest subjects were able to tell whether or not the dots were moving with very high rates of accuracy. Even when the dots were white, but still of a different brightness from the background, subjects could still determine whether they were moving. But, regardless of the dots' color, subjects could not tell when they were in motion when the white background and the dots were of similar brightness.[52]
Kentridge, Heywood, and Weiskrantz used the phenomenon of blindsight to investigate the connection between visual attention and visual awareness. They wanted to see if their subject—who exhibited blindsight in other studies[52]—could react more quickly when their attention was cued without the ability to be visually aware of it. The researchers aimed to show that being conscious of a stimulus and paying attention to it was not the same thing.[53]
To test the relationship between attention and awareness, they had the participant try to determine where a target was and whether it was oriented horizontally or vertically on a computer screen.[53] The target line would appear at one of two different locations and would be oriented in one of two directions. Before the target would appear an arrow would become visible on the screen, sometimes pointing to the correct position of the target line and less frequently not. This arrow was the cue for the subject. The participant would press a key to indicate whether the line was horizontal or vertical, and could then also indicate to an observer whether or not he/she actually had a feeling that any object was there or not—even if they couldn't see anything. The participant was able to accurately determine the orientation of the line when the target was cued by an arrow before the appearance of the target, even though these visual stimuli did not equal awareness in the subject who had no vision in that area of his/her visual field. The study showed that even without the ability to be visually aware of a stimulus the participant could still focus his/her attention on this object.[53]
In 2003, a patient known as ""TN"" lost use of his primary visual cortex, area V1. He had two successive strokes, which knocked out the region in both his left and right hemispheres. After his strokes, ordinary tests of TN's sight turned up nothing. He could not even detect large objects moving right in front of his eyes. Researchers eventually began to notice that TN exhibited signs of blindsight and in 2008 decided to test their theory. They took TN into a hallway and asked him to walk through it without using the cane he always carried after having the strokes. TN was not aware at the time, but the researchers had placed various obstacles in the hallway to test if he could avoid them without conscious use of his sight. To the researchers' delight, he moved around every obstacle with ease, at one point even pressing himself up against the wall to squeeze past a trashcan placed in his way. After navigating through the hallway, TN reported that he was just walking the way he wanted to, not because he knew anything was there.[54]
In another case study, a girl brought her grandfather in to see a neuropsychologist. The girl's grandfather, Mr. J., had suffered a stroke that had left him completely blind apart from a tiny spot in the middle of his visual field. The neuropsychologist, Dr. M., performed an exercise with him. The doctor helped Mr. J. to a chair, had him sit down, and then asked to borrow his cane. The doctor then asked, ""Mr. J., please look straight ahead. Keep looking that way, and don't move your eyes or turn your head. I know that you can see a little bit straight ahead of you, and I don't want you to use that piece of vision for what I'm going to ask you to do. Fine. Now, I'd like you to reach out with your right hand [and] point to what I'm holding."" Mr. J. then replied, ""But I don't see anything—I'm blind!"" The doctor then said, ""I know, but please try, anyway."" Mr. J then shrugged and pointed, and was surprised when his finger encountered the end of the cane which the doctor was pointing toward him. After this, Mr. J. said that ""it was just luck"". The doctor then turned the cane around so that the handle side was pointing towards Mr. J. He then asked for Mr. J. to grab hold of the cane. Mr. J. reached out with an open hand and grabbed hold of the cane. After this, the doctor said, ""Good. Now put your hand down, please."" The doctor then rotated the cane 90 degrees, so that the handle was oriented vertically. The doctor then asked Mr. J. to reach for the cane again. Mr. J. did this, turning his wrist so that his hand matched the orientation of the handle. This case study shows that, although (on a conscious level) Mr. J. was completely unaware of any visual abilities that he may have had, he was able to orient his grabbing motions as if he had no visual impairments.[12]
Brain regions involved[edit]
This section needs more medical references for verification or relies too heavily on primary sources, specifically: only final sentence appears to be inline referenced. (August 2015)
Visual processing in the brain goes through a series of stages. Destruction of the primary visual cortex leads to blindness in the part of the visual field that corresponds to the damaged cortical representation. The area of blindness – known as a scotoma – is in the visual field opposite the damaged hemisphere and can vary from a small area up to the entire hemifield. Visual processing occurs in the brain in a hierarchical series of stages (with much crosstalk and feedback between areas). The route from the retina through V1 is not the only visual pathway into the cortex, though it is by far the largest; it is commonly thought that the residual performance of people exhibiting blindsight is due to preserved pathways into the extrastriate cortex that bypass V1. However both physiological evidence[55] in monkeys and behavioral and imaging evidence in humans[8][9][19][56] shows that activity in these extrastriate areas, and especially in V5, is apparently sufficient to support visual awareness in the absence of V1.
To put it in a more complex way, recent physiological findings suggest that visual processing takes place along several independent, parallel pathways. One system processes information about shape, one about color, and one about movement, location and spatial organization. This information moves through an area of the brain called the lateral geniculate nucleus, located in the thalamus, and on to be processed in the primary visual cortex, area V1 (also known as the striate cortex because of its striped appearance). People with damage to V1 report no conscious vision, no visual imagery, and no visual images in their dreams. However, some of these people still experience the blindsight phenomenon,[24] though this too is controversial, with some studies showing a limited amount of consciousness without V1 or projections relating to it.[57]
The superior colliculus and prefrontal cortex also have a major role in awareness of a visual stimulus.[44]
Lateral geniculate nucleus[edit]
Mosby's Dictionary of Medicine, Nursing & Health Professions defines the LGN as ""one of two elevations of the lateral posterior thalamus receiving visual impulses from the retina via the optic nerves and tracts and relaying the impulses to the calcarine (visual) cortex"".[58]
What is seen in the left and right visual field is taken in by each eye and brought back to the optic disc via the nerve fibres of the retina.[59] From the optic disc, visual information travels through the optic nerve and into the optic chiasm. Visual information then enters the optic tract and travels to four different areas of the brain including the superior colliculus, pretectum of the mid brain, the suprachiasmatic nucleus of the hypothalamus, and the lateral geniculate nucleus (LGN). Most axons from the LGN will then travel to the primary visual cortex.[59]
Injury to the primary visual cortex, including lesions and other trauma, leads to the loss of visual experience.[60] However, the residual vision that is left cannot be attributed to V1. According to Schmid et al., ""thalamic lateral geniculate nucleus has a causal role in V1-independent processing of visual information"".[60] This information was found through experiments using fMRI during activation and inactivation of the LGN and the contribution the LGN has on visual experience in monkeys with a V1 lesion. These researchers concluded that the magnocellular system of the LGN is less affected by the removal of V1, which suggests that it is because of this system in the LGN that blindsight occurs.[60] Furthermore, once the LGN was inactivated, virtually all of the extrastriate areas of the brain no longer showed a response on the fMRI.[60] The information leads to a qualitative assessment that included ""scotoma stimulation, with the LGN intact had fMRI activation of ~20% of that under normal conditions"".[60] This finding agrees with the information obtained from, and fMRI images of, patients with blindsight.[60] The same study[60] also supported the conclusion that the LGN plays a substantial role in blindsight. Specifically, while injury to V1 does create a loss of vision, the LGN is less affected and may result in the residual vision that remains, causing the ""sight"" in blindsight. [60]
Functional magnetic resonance imaging has launched has also been employed to conduct brain scans in normal, healthy human volunteers to attempt to demonstrate that visual motion can bypass V1, through a connection from the LGN to the human middle temporal complex.[8][56] Their findings concluded that there was an indeed a connection of visual motion information that went directly from the LGN to the V5/hMT+ bypassing V1 completely.[56] Evidence also suggests that, following a traumatic injury to V1, there is still a direct pathway from the retina through the LGN to the extrastriate visual areas.[61] The extrastriate visual areas include parts of the occipital lobe that surround V1.[59] In non-human primates, these often include V2, V3, and V4.[59]
In a study conducted in primates, after partial ablation of area V1, areas V2 and V3 were still excited by visual stimulus.[61] Other evidence suggests that ""the LGN projections that survive V1 removal are relatively sparse in density, but are nevertheless widespread and probably encompass all extrastriate visual areas,"" including V2, V4, V5 and the inferotemporal cortex region.[62]
See also[edit]
References[edit]
- ^ a b Celesia G (2010). ""Visual perception and awareness: a modular system"". Journal of Psychophysiology. 24 (2): 62–67. doi:10.1027/0269-8803/a000014.
- ^ Weiskrantz L, Warrington EK, Sanders MD, Marshall J (December 1974). ""Visual capacity in the hemianopic field following a restricted occipital ablation"". Brain. 97 (4): 709–28. doi:10.1093/brain/97.1.709. PMID 4434190.
- ^ Poppel E, Held R, Frost D (June 1973). ""Leter: Residual visual function after brain wounds involving the central visual pathways in man"". Nature. 243 (5405): 295–6. doi:10.1038/243295a0. PMID 4774871. S2CID 4160116.
- ^ Weiskrantz L (1997). Consciousness Lost and Found: A Neuropsychological Exploration. ISBN 978-0-19-852301-7.
- ^ Barbur JL, Watson JD, Frackowiak RS, Zeki S (December 1993). ""Conscious visual perception without V1"". Brain. 116 ( Pt 6) (6): 1293–302. doi:10.1093/brain/116.6.1293. PMID 8293272.
- ^ Stoerig, Petra; Barth, Erhardt (2001-12-01). ""Low-Level Phenomenal Vision Despite Unilateral Destruction of Primary Visual Cortex"". Consciousness and Cognition. 10 (4): 574–587. doi:10.1006/ccog.2001.0526. ISSN 1053-8100. PMID 11790045. S2CID 22895605.
- ^ Riddoch G (1917-05-01). ""Dissociation of Visual Perceptions Due to Occipital Injuries, With Especial Reference to Appreciation of movement"". Brain. 40 (1): 15–57. doi:10.1093/brain/40.1.15. ISSN 0006-8950.
- ^ a b c d e Zeki S, Ffytche DH (January 1998). ""The Riddoch syndrome: insights into the neurobiology of conscious vision"". Brain. 121 ( Pt 1) (1): 25–45. doi:10.1093/brain/121.1.25. PMID 9549486.
- ^ a b Morland AB, Jones SR, Finlay AL, Deyzac E, Lê S, Kemp S (June 1999). ""Visual perception of motion, luminance and colour in a human hemianope"". Brain. 122 ( Pt 6) (6): 1183–98. doi:10.1093/brain/122.6.1183. PMID 10356069.
- ^ a b Mazzi C, Bagattini C, Savazzi S (2016). ""Blind-Sight vs. Degraded-Sight: Different Measures Tell a Different Story"". Frontiers in Psychology. 7: 901. doi:10.3389/fpsyg.2016.00901. PMC 4909743. PMID 27378993.
- ^ a b Overgaard M, Fehl K, Mouridsen K, Bergholt B, Cleeremans A (August 2008). ""Seeing without Seeing? Degraded Conscious Vision in a Blindsight Patient"". PLOS ONE. 3 (8): e3028. Bibcode:2008PLoSO...3.3028O. doi:10.1371/journal.pone.0003028. PMC 2507770. PMID 18716654.
- ^ a b c d e Carlson N (2013). Physiology of Behavior (11th ed.). University of Massachusetts, Amherst: Pearson Education, Inc. p. 4. ISBN 978-0-205-23981-8.
- ^ Humphrey NK (1970). ""What the frog's eye tells the monkey's brain"". Brain, Behavior and Evolution. 3 (1): 324–37. doi:10.1159/000125480. PMID 5001242.
- ^ Humphrey NK (1974). ""Vision in a monkey without striate cortex: a case study"". Perception. 3 (3): 241–55. CiteSeerX 10.1.1.452.5493. doi:10.1068/p030241. PMID 4459818. S2CID 4686081.
- ^ Humphrey N (1992). A History of the Mind. New York: Simon & Schuster. ISBN 9780671686444. OCLC 25915998.
- ^ Holt J (2003). Blindsight and the Nature of Consciousness. Peterborough, Ontario: Broadview Press. ISBN 978-1-55111-351-7. OCLC 50755257.[page needed]
- ^ Humphrey N (2006). Seeing Red: A Study in Consciousness. Mind/brain/behavior initiative. Cambridge, Massachusetts: Belknap Press. ISBN 978-0-674-02179-2. OCLC 234101445.[page needed]
- ^ Alexander I, Cowey A (June 2010). ""Edges, colour and awareness in blindsight"". Consciousness and Cognition. 19 (2): 520–33. doi:10.1016/j.concog.2010.01.008. PMID 20171122. S2CID 36139700.
- ^ a b Ffytche DH, Zeki S (January 2011). ""The primary visual cortex, and feedback to it, are not necessary for conscious vision"". Brain. 134 (Pt 1): 247–57. doi:10.1093/brain/awq305. PMC 3159156. PMID 21097490.
- ^ Sahraie A, Hibbard PB, Trevethan CT, Ritchie KL, Weiskrantz L (December 2010). ""Consciousness of the first order in blindsight"". Proceedings of the National Academy of Sciences of the United States of America. 107 (49): 21217–22. Bibcode:2010PNAS..10721217S. doi:10.1073/pnas.1015652107. PMC 3000284. PMID 21078979.
- ^ Kinoshita M, Kato R, Isa K, Kobayashi K, Kobayashi K, Onoe H, Isa T (2019-01-11). ""Dissecting the circuit for blindsight to reveal the critical role of pulvinar and superior colliculus"". Nat Commun. 10 (1): 135. Bibcode:2019NatCo..10..135K. doi:10.1038/s41467-018-08058-0. PMC 6329824. PMID 30635570. S2CID 58009143.
- ^ Kletenik I, Ferguson MA, Bateman JR, Cohen AL, Lin C, Tetreault A, Pelak VS, Anderson CA, Prasad S, Darby RR, Fox MD (2021-12-27). ""Network Localization of Unconscious Visual Perception in Blindsight"". Ann Neurol. 91 (2): 217–224. doi:10.1002/ana.26292. PMID 34961965. S2CID 245553461.
- ^ Radoeva PD, Prasad S, Brainard DH, Aguirre GK (2008-11-20). ""Neural activity within area V1 reflects unconscious visual performance in a case of blindsight"". J Cogn Neurosci. 20 (11): 1927–1939. doi:10.1162/jocn.2008.20139. PMC 2773243. PMID 18416678.
- ^ a b Kalat JW (2009). Biological Psychology (10th ed.). Belmont, California: Wadsworth. pp. 169–170. ISBN 9780495603009. OCLC 236316740.
- ^ Fulton, J. (2004) Processes in Biological Vision Section 7.4 ""Archived copy"" (PDF). Archived from the original on 2015-02-21. Retrieved 2012-11-26.
{{cite web}}: CS1 maint: archived copy as title (link)
- ^ Benevento LA, Yoshida K (December 1981). ""The afferent and efferent organization of the lateral geniculo-prestriate pathways in the macaque monkey"". The Journal of Comparative Neurology. 203 (3): 455–74. doi:10.1002/cne.902030309. PMID 6274921. S2CID 28585691.
- ^ Fries W (September 1981). ""The projection from the lateral geniculate nucleus to the prestriate cortex of the macaque monkey"". Proceedings of the Royal Society of London. Series B, Biological Sciences. 213 (1190): 73–86. Bibcode:1981RSPSB.213...73F. doi:10.1098/rspb.1981.0054. PMID 6117869. S2CID 5700048.
- ^ Yukie M, Iwai E (September 1981). ""Direct projection from the dorsal lateral geniculate nucleus to the prestriate cortex in macaque monkeys"". The Journal of Comparative Neurology. 201 (1): 81–97. doi:10.1002/cne.902010107. PMID 7276252. S2CID 8825689.
- ^ Sincich LC, Park KF, Wohlgemuth MJ, Horton JC (October 2004). ""Bypassing V1: a direct geniculate input to area MT"". Nature Neuroscience. 7 (10): 1123–8. doi:10.1038/nn1318. PMID 15378066. S2CID 13419990.
- ^ ffytche DH, Guy CN, Zeki S (December 1995). ""The parallel visual motion inputs into areas V1 and V5 of human cerebral cortex"". Brain. 118 ( Pt 6) (6): 1375–94. doi:10.1093/brain/118.6.1375. PMID 8595471.
- ^ Beckers G, Zeki S (February 1995). ""The consequences of inactivating areas V1 and V5 on visual motion perception"". Brain. 118 ( Pt 1) (1): 49–60. doi:10.1093/brain/118.1.49. PMID 7895014.
- ^ Schmid MC, Mrowka SW, Turchi J, Saunders RC, Wilke M, Peters AJ, et al. (July 2010). ""Blindsight depends on the lateral geniculate nucleus"". Nature. 466 (7304): 373–7. Bibcode:2010Natur.466..373S. doi:10.1038/nature09179. PMC 2904843. PMID 20574422.
- ^ Ffytche DH, Zeki S (January 2011). ""The primary visual cortex, and feedback to it, are not necessary for conscious vision"". Brain. 134 (Pt 1): 247–57. doi:10.1093/brain/awq305. PMC 3159156. PMID 21097490.
- ^ Lamme, VAF (2001-04-01). ""Blindsight: the role of feedforward and feedback corticocortical connections"". Acta Psychologica. 107 (1–3): 209–228. doi:10.1016/S0001-6918(01)00020-8. ISSN 0001-6918. PMID 11388136.
- ^ Cragg, B.G. (1969-07-01). ""The topography of the afferent projections in the circumstriate visual cortex of the monkey studied by the nauta method"". Vision Research. 9 (7): 733–747. doi:10.1016/0042-6989(69)90011-X. ISSN 0042-6989. PMID 4979024.
- ^ Boyle NJ, Jones DH, Hamilton R, Spowart KM, Dutton GN (October 2005). ""Blindsight in children: does it exist and can it be used to help the child? Observations on a case series"". Developmental Medicine and Child Neurology. 47 (10): 699–702. doi:10.1111/j.1469-8749.2005.tb01057.x. PMID 16174315.
- ^ Cowey A, Stoerig P (January 1995). ""Blindsight in monkeys"" (PDF). Nature. 373 (6511): 247–9. Bibcode:1995Natur.373..247C. doi:10.1038/373247a0. PMID 7816139. S2CID 4269412. Archived from the original (PDF) on 2012-05-01. Retrieved 2018-02-05.
- ^ Stoerig P, Cowey A (March 1997). ""Blindsight in man and monkey"". Brain. 120 ( Pt 3) (3): 535–59. doi:10.1093/brain/120.3.535. PMID 9126063.[dead link]
- ^ Cowey A, Alexander I, Stoerig P (February 2008). ""A blindsight conundrum: how to respond when there isn't a correct response"". Neuropsychologia. 46 (3): 870–8. doi:10.1016/j.neuropsychologia.2007.11.031. PMID 18201733. S2CID 20790934.
- ^ Weiskrantz L (1986). Blindsight: A Case Study and Implications. Oxford University Press. ISBN 978-0-19-852192-1. OCLC 21677307.
- ^ de Monasterio FM (November 1978). ""Properties of ganglion cells with atypical receptive-field organization in retina of macaques"". Journal of Neurophysiology. 41 (6): 1435–49. doi:10.1152/jn.1978.41.6.1435. PMID 104014.
- ^ Marrocco RT, Li RH (July 1977). ""Monkey superior colliculus: properties of single cells and their afferent inputs"". Journal of Neurophysiology. 40 (4): 844–60. doi:10.1152/jn.1977.40.4.844. PMID 407333.
- ^ Schiller PH, Malpeli JG (March 1977). ""Properties and tectal projections of monkey retinal ganglion cells"". Journal of Neurophysiology. 40 (2): 428–45. doi:10.1152/jn.1977.40.2.428. PMID 403252.
- ^ a b Hall NJ, Colby CL (2009). ""Response to blue visual stimuli in the macaque superior colliculus"". Society for Neuroscience. 19: 520–533.
- ^ Garrett B (2011). Brain & Behavior: An Introduction to Biological Psychology (3rd ed.). Thousand Oaks, California: SAGE Publications. pp. 315–318. ISBN 978-1-4129-8168-2. OCLC 617425474.
- ^ Tamietto M, de Gelder B (October 2010). ""Neural bases of the non-conscious perception of emotional signals"". Nature Reviews. Neuroscience. 11 (10): 697–709. doi:10.1038/nrn2889. hdl:2318/79483. PMID 20811475. S2CID 4690318.
- ^ Whitwell RL, Striemer CL, Nicolle DA, Goodale MA (April 2011). ""Grasping the non-conscious: preserved grip scaling to unseen objects for immediate but not delayed grasping following a unilateral lesion to primary visual cortex"". Vision Research. 51 (8): 908–24. doi:10.1016/j.visres.2011.02.005. PMID 21324336.
- ^ Striemer CL, Chapman CS, Goodale MA (September 2009). """"Real-time"" obstacle avoidance in the absence of primary visual cortex"". Proceedings of the National Academy of Sciences of the United States of America. 106 (37): 15996–6001. Bibcode:2009PNAS..10615996S. doi:10.1073/pnas.0905549106. PMC 2747232. PMID 19805240.
- ^ a b Persaud N, Cowey A (September 2008). ""Blindsight is unlike normal conscious vision: evidence from an exclusion task"". Consciousness and Cognition. 17 (3): 1050–5. doi:10.1016/j.concog.2007.10.002. PMID 18065242. S2CID 30699219.
- ^ a b c d Weiskrantz L (2007). ""Blindsight"". Scholarpedia. 2 (4): 3047. Bibcode:2007SchpJ...2.3047W. doi:10.4249/scholarpedia.3047.
- ^ a b c Stoerig P (September 1996). ""Varieties of vision: from blind responses to conscious recognition"". Trends in Neurosciences. 19 (9): 401–6. doi:10.1016/S0166-2236(96)10051-5. PMID 8873358. S2CID 25012895.
- ^ a b c d e f Alexander I, Cowey A (March 2013). ""Isoluminant coloured stimuli are undetectable in blindsight even when they move"". Experimental Brain Research. 225 (1): 147–52. doi:10.1007/s00221-012-3355-6. PMID 23263562. S2CID 1738371.
- ^ a b c Kentridge RW, Heywood CA, Weiskrantz L (2004). ""Spatial attention speeds discrimination without awareness in blindsight"". Neuropsychologia. 42 (6): 831–5. CiteSeerX 10.1.1.719.7118. doi:10.1016/j.neuropsychologia.2003.11.001. PMID 15037061. S2CID 12837840.
- ^ de Gelder B, Tamietto M, van Boxtel G, Goebel R, Sahraie A, van den Stock J, et al. (December 2008). ""Intact navigation skills after bilateral loss of striate cortex"". Current Biology. 18 (24): R1128-9. doi:10.1016/j.cub.2008.11.002. PMID 19108766.
- ^ Rodman HR, Gross CG, Albright TD (June 1989). ""Afferent basis of visual response properties in area MT of the macaque. I. Effects of striate cortex removal"". The Journal of Neuroscience. 9 (6): 2033–50. doi:10.1523/JNEUROSCI.09-06-02033.1989. PMC 6569731. PMID 2723765.
- ^ a b c Gaglianese A, Costagli M, Bernardi G, Ricciardi E, Pietrini P (April 2012). ""Evidence of a direct influence between the thalamus and hMT+ independent of V1 in the human brain as measured by fMRI"". NeuroImage. 60 (2): 1440–7. doi:10.1016/j.neuroimage.2012.01.093. PMID 22300813. S2CID 937762.
- ^ Ffytche DH, Zeki S (January 2011). ""The primary visual cortex, and feedback to it, are not necessary for conscious vision"". Brain. 134 (Pt 1): 247–57. doi:10.1093/brain/awq305. PMC 3159156. PMID 21097490.
- ^ Mosby's Dictionary of Medicine, Nursing & Health Professions. Mosby, Inc. (8th ed.). St. Louis, Missouri: Mosby/Elsevier. 2009. ISBN 9780323049375. OCLC 226911727.
{{cite book}}: CS1 maint: others (link)
- ^ a b c d Dragoi V (1997). ""Chapter 15: Visual Processing: Cortical Pathways"". Neuroscience Online. The University of Texas Health Science Center at Houston. Retrieved November 3, 2013.
- ^ a b c d e f g h Schmid MC, Mrowka SW, Turchi J, Saunders RC, Wilke M, Peters AJ, et al. (July 2010). ""Blindsight depends on the lateral geniculate nucleus"". Nature. 466 (7304): 373–7. Bibcode:2010Natur.466..373S. doi:10.1038/nature09179. PMC 2904843. PMID 20574422.
- ^ a b Cowey A (September 2010). ""Visual system: how does blindsight arise?"". Current Biology. 20 (17): R702-4. doi:10.1016/j.cub.2010.07.014. PMID 20833309. S2CID 17351599.
- ^ Weiskrantz L (April 1996). ""Blindsight revisited"". Current Opinion in Neurobiology. 6 (2): 215–20. doi:10.1016/s0959-4388(96)80075-4. PMID 8725963. S2CID 1833570.
Further reading[edit]
- ""Blindsight: How brain sees what you do not see"". Medical Press. 14 October 2008. Retrieved 5 February 2018.
- Collins GP. ""Blindsight: Seeing without knowing it"". Scientific American Blog Network. Retrieved 5 February 2018.
- Danckert J, Rossetti Y (2005). ""Blindsight in action: what can the different sub-types of blindsight tell us about the control of visually guided actions?"". Neuroscience and Biobehavioral Reviews. 29 (7): 1035–46. doi:10.1016/j.neubiorev.2005.02.001. PMID 16143169. S2CID 12833434.
- De Gelder B (May 2010). ""Uncanny sight in the blind"". Scientific American. 302 (5): 60–5. Bibcode:2010SciAm.302e..60D. doi:10.1038/scientificamerican0510-60. PMID 20443379.
- Leh SE, Johansen-Berg H, Ptito A (July 2006). ""Unconscious vision: new insights into the neuronal correlate of blindsight using diffusion tractography"". Brain. 129 (Pt 7): 1822–32. doi:10.1093/brain/awl111. PMID 16714319.
- Leh SE, Mullen KT, Ptito A (November 2006). ""Absence of S-cone input in human blindsight following hemispherectomy"". The European Journal of Neuroscience. 24 (10): 2954–60. CiteSeerX 10.1.1.578.4900. doi:10.1111/j.1460-9568.2006.05178.x. PMID 17156217. S2CID 14152585.
- McIntosh AR, Rajah MN, Lobaugh NJ (May 1999). ""Interactions of prefrontal cortex in relation to awareness in sensory learning"". Science. 284 (5419): 1531–3. Bibcode:1999Sci...284.1531M. doi:10.1126/science.284.5419.1531. PMID 10348741.
- Ptito A, Leh SE (October 2007). ""Neural substrates of blindsight after hemispherectomy"". The Neuroscientist. 13 (5): 506–18. doi:10.1177/1073858407300598. PMID 17901259. S2CID 23093266.
- Ratey JJ, Galaburda AM (2002). A User's Guide to the Brain: Perception, Attention, and the Four Theaters of the Brain. Vintage Books. p. 99. ISBN 978-0-375-70107-8.
- Beltramo R, Scanziani M (January 2019). ""A collicular visual cortex: Neocortical space for an ancient midbrain visual structure"". Science. 363 (6422): 64–69. Bibcode:2019Sci...363...64B. doi:10.1126/science.aau7052. PMID 30606842.",8
290,"Description
Retrotech & Lowtech is the quintessence of 5 years of collective research to exhumate forgotten energy patents and innovations. After being published in French and in Japanese, the English version is now available!
For this book, our scientific committee has selected 64 stories, techniques and inventions which have disappeared from 1780 to the present day. Our work consisted in investigating reliable sources through archives and interviews, researching all the iconography and writing the texts. We have also asked 10 experts in topics which surround our research to contribute by writing short essays. This will help the reader to put these old stories into perspective and connect them to our contemporary stakes.
Each story is displayed as a double page, including a short text with anecdotes as well as an illustration and some sources to explore further.
→ Format of the book : 18.5 cm x 26 cm ; 212 pages
→ 64 inventions from about 1780 to 1980
→ Short essays from several experts around the topic, including:
« Archives: Finding what is has not been lost » (Eric Dussert)
« Another History of Electric Aviation » (Kevin Desmond, researcher and writer)
« Paleo-technology: Breaking the thermo-industrial deadlock » (Alain Gras, sociologist)
« Art and Energy » (Alice Audouin, professor at the Sorbonne)
« Design fiction and innovations » (Olivier Wathelet, anthropologist of innovation)
« Simondon: open the machine » (Ludovic Duhem, expert in simondonian studies)
« Another history of mobility » (Arnaud Passalacqua, lecturer in contemporary history at the University of Paris VII)
« Intellectual properties and common interest » (La Paillasse, biohacking/open-research center at the origin of the international cancer project Epidemium)
« Energy storage » (Atelier 21)
« Homo Photosyntheticus » (Ewen Chardronnet, author, journalist, commissioner and member of artist collectives)
Pages preview:
Avis
Il n’y a pas encore d’avis.",8
291,"- Store
- >
- Trade Paperback
- >
- Multispecies Cities
Multispecies Cities
SKU:
$15.95
$15.95
Unavailable
per item
Anthology
Science Fiction / Short Story Anthology
Release Date: April 13, 2021
Trade Paperback
ISBN-13: 978-1734054521
Anthology: Approx. 100,000 words / 330 pages
Also available as an ebook
Find it Online:
Amazon
Barnes & Noble
Books-A-Million
Goodreads
Independent Bookstores
iTunes/Apple iBooks
Kobo
Wholesale: Ingram or direct: World Weaver Press.
Science Fiction / Short Story Anthology
Release Date: April 13, 2021
Trade Paperback
ISBN-13: 978-1734054521
Anthology: Approx. 100,000 words / 330 pages
Also available as an ebook
Find it Online:
Amazon
Barnes & Noble
Books-A-Million
Goodreads
Independent Bookstores
iTunes/Apple iBooks
Kobo
Wholesale: Ingram or direct: World Weaver Press.
Sold Out
|
|
Description
Cities are alive, shared by humans and animals, insects and plants, landforms and machines. What might city ecosystems look like in the future if we strive for multispecies justice in our urban settings? In these more-than-human stories, twenty-four authors investigate humanity’s relationship with the rest of the natural world, placing characters in situations where humans have to look beyond their own needs and interests. A quirky eco-businessman sees broader applications for a high school science fair project. A bad date in Hawai‘i takes an unexpected turn when the couple stumbles upon some confused sea turtle hatchlings. A genetically-enhanced supersoldier struggles to find new purpose in a peaceful Tokyo. A community service punishment in Singapore leads to unexpected friendships across age and species. A boy and a mammoth trek across Asia in search of kin. A Tamil child learns the language of the stars. Set primarily in the Asia-Pacific, these stories engage with the serious issues of justice, inclusion, and sustainability that affect the region, while offering optimistic visions of tomorrow's urban spaces.
Table of Contents
""Listen: A Memoir"" by Priya Sarukkai Chabria
""By the Light of the Stars"" by N. R. M. Roshak
""Old Man's Sea"" by Meyari McFarland
""Deer, Tiger, and Witch"" by Kate V. Bui
""Vladivostok"" by Avital Balwit
""The Exuberant Vitality of Hatchling Habitats"" by D.A. Xiaolin Spires
""Untamed"" by Timothy Yam
""It is the year 2115"" by Joyce Chng
""A Rabbit Egg for Flora"" by Caroline M. Yoachim
""Iron Fox in the Marble City"" by Vlad-Andrei Cucu
""Mariposa Awakening"" by Joseph F. Nacino
""A Life With Cibi"" by Natsumi Tanaka
""Children of Asphalt"" by Phoebe Wagner
""Down the River"" by Eliza Victoria
""Becoming Martians"" by Taiyo Fujii
""Abso"" by Sarah E. Stevens
""In Two Minds"" by Joel R Hunt
""Arfabad"" by Rimi B. Chatterjee
""The Mammoth Steps"" by Andrew Dana Hudson
""Wandjina"" by Amin Chehelnabi
""The Streams Are Paved With Fish Traps"" by Octavia Cade
""Crew"" by E.-H. Nießler
""The Songs That Humanity Lost Reluctantly to Dolphins"" by Shweta Taneja
""The Birdsong Fossil"" by D.K. Mok
Excerpts
Listen to the story ""The Songs Humanity Reluctantly Lost to Dolphins"" by Shweta Taneja on Black Women Are Scary Podcast!
""Deer, Tiger, and Witch"" by Kate V. Bui
Even though her positive reputation preceded her, it still took an afternoon of circular negotiations before Thu emerged from the city hall with a signed contract to begin her work and the addresses of ten local farms. Exhausted, she sat down on a bench next to an ancient woman who was chewing on a betel quid, her red-stained lips and black teeth indicative of a lifetime of usage.
“You’re a visitor,” the woman stated. It wasn’t a question; she undoubtedly knew everyone in the village from birth. “Are you here for our tiger god hunt? It’s been years since a tourist has come to watch it.”
“I’m just here a few days for work, so I’m unfamiliar with it.”
The old woman cackled in reply. “Work? So that means you’re single, right? You should meet my daughter Ly. She’ll show you firsthand.”
“Ma, I told you to stop trying to set me up,” said a ruggedly-dressed woman who came up to them. She set down a heavy woven mesh bag bulging with banana-leaf wrapped parcels by the elder’s feet, “I’m done shopping so let’s not waste this nice lady’s time.”
The new arrival was around Thu’s age but almost her complete inverse physically: where years of daily hiking had made Thu’s tall frame sinewy and lean, the other woman was shorter, but with solid, ropy muscles that were beyond impressive for someone in their fifties. Her skin was deeply tanned from working outside and she carried herself with the casual confidence of someone who completely understood their own strength. Thu swallowed hard.
“Your mother was just telling me a bit about the tiger hunt, but I’m still not sure I understand it,” she managed to say.
“Yeah? You wanna see this month’s hunt?” Ly grinned. “We usually don’t let outsiders come along but I’m the head of the hunting committee, so I can make an exception. It’s a bit of a hike into the forest but I’d be happy to take you—I was actually just on my way over there.”
Thu’s instincts told her not to follow this random stranger into the tiger-filled jungle, but the heat rising in her chest and cheeks obliterated any rational objections she might have come up with.
“Sure, I’d love to go with you,” she said before quickly adding, “to learn about the hunt.”
As she followed the hunter away from the village, she looked back at the old woman who winked at her and flashed her a mouth of black-stained teeth.
|
|
Praise
""The 24 stories of this joyously ambitious solarpunk anthology chart a broad map for integrated relationships between humans and nature, spotlighting award-winning and emerging speculative fiction writers from Asia and the Pacific. The linguistically and culturally diverse lineup excels when entwining relational nuance with keenly handled futurist ideas.""
--Publishers Weekly
""Every story in this collection is a powerhouse, there’s not a weak one in the bunch. Written by Pan-Asian authors and set in locations from Northern China to Australia, each of these stories brings a new perspective and voice to the ideas of how we can better interact with our environment. Each has an overriding sense of hope that makes this collection a uniquely pleasurable reading experience.""
--Maryanne S., NetGalley Reviewer
""Firmly planted in the new genre of solarpunk, the stories are filled with a polyphony of voices—some non-human and a few non-alive—working together to bring about solutions that address global warming, the extinction of animal species, and coming climate disaster… What is so interesting about Multispecies Cities: Solarpunk Urban Futures is the call for changes not just in terms of content, but about form, questioning progress-based narratives, stories of the individual, the lone hero, people against people, and others.""
--Books on Asia
More Like This
Glass and Gardens: Solarpunk Summers
$13.95
Anthology edited by Sarena Ulibarri
Series: Glass & Gardens
Science Fiction / Short Story Anthology
Release Date: June 5, 2018
Trade Paperback
ISBN-13: 978-0998702278
Anthology: Approx. 87,000 words / 290 pages
Also available as an ebook
Find it Online:
Amazon
Barnes & Noble
Books-A-Million
Goodreads
Independent Bookstores
iTunes/Apple iBooks
Kobo
Wholesale: Ingram or direct: World Weaver Press.
Glass and Gardens: Solarpunk Winters
$15.95
Anthology edited by Sarena Ulibarri
Series: Glass & Gardens
Science Fiction / Short Story Anthology
Release Date: January 7, 2020
Trade Paperback
ISBN-13: 978-1732254688
Anthology: Approx. 95,000 words / 300 pages
Also available as an ebook
Find it Online:
Amazon
Barnes & Noble
Books-A-Million
Goodreads
Independent Bookstores
iTunes/Apple iBooks
Kobo
Library: Overdrive or Bibliotheca
Wholesale: Ingram or direct from publisher@WorldWeaverPress.com
Solarpunk: Ecological and Fantastical Stories in a Sustainable World
$14.95
The English translation of the world's first solarpunk anthology. Groundbreaking science fiction stories from Brazil and Portugal.
Anthology edited by Gerson Lodi-Ribeiro
Translated by Fabio Fernandes
Science Fiction / Short Story Anthology
Release Date: August 7, 2018
Trade Paperback
ISBN-13: 978-0998702292
Anthology: Approx. 82,000 words / 270 pages
Also available as an ebook
Find it Online:
Amazon
Barnes & Noble
Books-A-Million
Goodreads
Independent Bookstores
iTunes/Apple iBooks
Kobo
Overdrive
Wholesale: Ingram or direct: World Weaver Press.",8
292,"To continue, please click the box below to let us know you're not a robot.
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.
For inquiries related to this message please contact our support team and provide the reference ID below.",7
293,"www.pmi.org
Checking if the site connection is secure
Enable JavaScript and cookies to continue
www.pmi.org needs to review the security of your connection before proceeding.
Ray ID:
756db37d88d4d3b3
Performance & security by
Cloudflare",7
294,"Philadelphia’s Diatom Archive Is a Way, Way, Wayback Machine
A cache of phytoplankton held at the Academy of Natural Sciences of Drexel University is helping to reconstruct historical coastlines.
Article body copy
Nestled in the heart of Philadelphia, Pennsylvania, the Academy of Natural Sciences of Drexel University emanates the aura of a sprawling cabinet of curiosities. Its neoclassical facade is covered in natural motifs—doorways flanked by ammonites, handrails that curl into ferns, bronze door handles shaped like ibis skulls. As the oldest natural science institution in the western hemisphere, the academy has accumulated a trove of remarkable specimens. Among the 19 million or so specimens housed here are plants procured on the Lewis and Clark Expedition, blue marlin reeled in by Ernest Hemingway, and America’s first mounted dinosaur skeleton.
Many of the academy’s most unassuming yet impactful treasures are filed away on its second floor, in an office space crowded with hulking cabinets and microscopes. Next to one of these microscopes, curator Marina Potapova pops open a notebook-sized plastic container brimming with glass slides. To the untrained eye, these unremarkable slides seem filthy—each looks like it’s been smudged by dirty fingers.
But as soon as Potapova slips one under a microscope lens, the slide’s contents dazzle. Dozens of diatoms—microscopic, single-celled algae encased in sturdy silica walls and found wherever there is water—are fixed to the slides in a myriad of shapes.
Some are elongated like baguettes or flattened into saucers while others hook together to resemble translucent centipedes. Others are barbed like harpoons or shaped like pudgy sea stars. Some even resemble ornate stained-glass windows. Under a microscope, a few drops of murky pond water become a kaleidoscope of diatom diversity.
The beauty of diatoms is impressive. But their ecological significance is staggering. Diatoms anchor marine food webs by feeding everything from minuscule zooplankton to mammoth filter feeders. (Case in point: scientists have deduced that the rise of whales some 30 million years ago mirrors a spike in diatom diversity.) Diatoms also have an outsized atmospheric impact. As one of the planet’s most prolific organisms, diatoms siphon harmful gases like carbon dioxide out of the air and produce massive stores of oxygen as they photosynthesize. It is estimated that roughly one-quarter of the air we breathe is created by diatoms.
More than four million specimens of these essential algae are plastered onto hundreds of thousands of slides and housed in the academy’s diatom herbarium. Only London’s Natural History Museum stores more slides of diatoms.
Although the academy’s diatoms no longer feed the planktonic masses or pump oxygen into the atmosphere, they do hold clues about how the aquatic world is changing. As their tough shells sink to the bottom of a body of water, they are stored in the sediment for millennia. When researchers use a sediment core to drill down into the muddy bottom of an estuary, they are collecting diatoms deposited over the eons.
In addition to being plentiful and hardy, diatoms are also a crucial barometer for a variety of environmental conditions. The existence of certain diatom species can help scientists pinpoint everything from industrial pollution to oxygen depletion. Potapova and her colleagues have recently used these water condition time capsules to gauge how accelerating sea level rise is endangering New Jersey’s coastal wetlands.
Thanks to a relative dearth of environmental monitoring, the historical decline of these crucial marshes—which hoard carbon, provide nursery grounds for fish, and buffer the coast from storms—has largely been obscured, making restoration efforts little more than guesswork.
However, the millions of diatoms stored at the academy are helping the researchers track the fall of the coastal wetlands as the ocean rises, which may help anticipate the coast’s future. “Diatoms are absolutely invaluable environmental archives,” Potapova says. “You can infer the future from what they tell you about the past.”
Considering the academy’s history, it is no wonder that the storied institution has become a hub for diatoms. With the advent of accessible microscopy in the 1850s, many of Philadelphia’s gentleman naturalists were captivated by the realm of minute microbes, eventually establishing the Microscopical Society of Philadelphia at the academy.
Because of their striking beauty, diatoms took the microscopical society by storm. To satiate their interest, many of these diatomists headed east to the New Jersey coastline to collect samples, which they mounted onto glass slides using a steady hand and a brush brimming with pig eyelashes. The hobbyists would then gather at the academy to show off their slides at gourmet luncheons.
The academy’s early members were clearly enthusiastic about diatoms, but most were amateurs and published little research on the myriad of specimens they collected. Organizing the mountains of slides compiled by each collector into a cohesive collection proved to be quite the task for Ruth Patrick when she arrived at the academy in 1933. The daughter of an amateur diatomist who received her first microscope at the age of seven, Patrick gravitated toward diatoms early in her childhood and eventually completed her PhD studying the microscopic organisms. Despite her scientific credentials, she was relegated to setting up microscopes and slides for the untrained hobbyists. It took her years to even gain membership in the male-dominated academy. But her persistence paid off, and in 1937 she became curator of the nascent diatom herbarium.
Patrick’s first goal was organizing the amalgamation of different collections into a unified and comprehensive source for taxonomic research. When she was not mounting and organizing slides, she was wading into nearby ponds and streams to collect new specimens in the field, where she gradually gained an appreciation for the ecological importance of diatoms.
This crystalized during a 1948 expedition to Pennsylvania’s Conestoga River—a body of water heavily polluted by sewage and industrial runoff. As her team collected samples from throughout the creek, she recognized patterns in the diatom composition. Some species’ densities exploded in areas contaminated with sewage, while others thrived in spots tainted with chemicals. Soon, Patrick became adept at using the existence of certain diatoms as a key for diagnosing pollution in lakes and rivers. This supported the idea that greater diatom diversity correlated with healthier freshwater ecosystems—an insight ecologists coined the Patrick Principle.
Patrick revolutionized the use of diatoms to monitor freshwater systems, but using them in coastal wetlands lagged behind. The brackish fusion of fresh and salt water in coastal zones such as estuaries creates habitats that are dynamic and complex with a mixture of inland and oceanic diatoms, according to Mihaela Enache, a research scientist at the New Jersey Department of Environmental Protection (NJDEP).
However, in recent decades, the sea has dominated the once-dynamic coastal margin, propelling farther inland as sea levels rise. Over the last century, the sea level along New Jersey has risen by 0.45 meters, more than double the global average of 0.18 meters. By 2100, the sea could rise by over a meter.
This dramatic rise in sea level has proven disastrous for the patchwork of marshes along New Jersey’s coastline, several of which have already succumbed to the sea. However, the full extent of the loss of these wetlands is difficult to parse because environmental monitoring only dates back a few decades.
Without a sense of a wetland’s natural conditions, ecological restoration is daunting. Having that information is crucial, says Enache. “Without [it], you are in the dark.” Thankfully, some of this missing data is recorded in the academy’s cache of diatoms.
Like most coastal margins, New Jersey is familiar with sea level rise. During the Pleistocene, when New Jersey was blanketed by ice and home to mastodons, sea ice slurped up stores of seawater. Around 18,000 years ago, sea levels sank more than 130 meters below their current levels—extending the New Jersey coastline 110 kilometers farther into the Atlantic Ocean.
The end of the last ice age sparked a steady climb in sea levels. Retreating ice sheets caused parts of New Jersey to sink. This subsidence, combined with glacial melt, proved a potent mix for rapid sea level rise according to Jennifer Walker, a sea level researcher at Rutgers University.
In a study published last year, Walker turned to the past to put New Jersey’s current bout of sea level rise in context. “If we can understand how temperatures, atmosphere, and sea level changes are all interconnected in the past, that’s what we can use to project changes in the future.”
To gauge fluctuating sea levels over the past 2,000 years, her team examined the shells of single-celled protists called foraminifera that are finely calibrated to specific environmental conditions. This makes them a valuable proxy for reconstructing shifts in sea levels. By identifying the presence of certain foraminifera species throughout sediment cores collected from different spots along the Jersey shore, her team concluded that New Jersey’s coast is experiencing the fastest rise of sea level in 2,000 years.
The NJDEP hoped diatoms could serve as a similar tool for understanding how coastal marshes responded to the rising sea. Like foraminifera, each diatom species is extremely sensitive to environmental conditions. For example, species like the rolling pin–shaped Nitzschia microcephala thrive in nitrogen-rich environments, making their shells a common sign of nutrient pollution. Other species, like Diploneis smithii, whose segmented shell resembles a slender trilobite, prefer saline waters. Their existence inland is a good indication of past sea level intrusion and helps researchers deduce which marshes have been prone to flooding in the past.
To pinpoint where these microscopic indicators once existed, the NJDEP deployed a team of researchers into several marshes along the coastline, ranging from heavily polluted wetlands in the north to near-pristine tidal marshes in the south. At each site, they cored into the marsh muck, sampling as deep as two meters in certain spots. Enache compares this method to slicing into a stack of pancakes—as you cut deeper, you are essentially going back in time from the steaming pancake just off the griddle to the soggy pancake deposited at the bottom of the stack. As they dug deeper, the researchers were traveling back decades. In total, they collected nine cores from five wetlands.
The NJDEP then sent the sediment cores to Philadelphia, where Potapova and her master’s student Nina Desianti gauged the diatom diversity of New Jersey’s coastal wetlands through time. Desianti began processing the diatom specimens by soaking the sediment samples in strong acid to dissolve everything but the silica shell before adhering them to slides. The result was an environmental history of each of the five marshes mounted onto thousands of glass slides. Then, by using the specimens already cataloged at the academy, they played a microscopic game of who’s who. But even the sprawling diatom herbarium lacked all the answers—Desianti estimates that over one-third of the 900-odd species they collected from the wetlands are new to science.
The monumental effort yielded the tome Diatom Flora of the New Jersey Coastal Wetlands in 2019. To the uninitiated, it is an overwhelming mix of intimidating Latinized names and dramatic electron microscope photographs that portray the diatoms in all their infinitesimal glory. To Enache, it’s the key to decoding the decline of New Jersey’s wetlands. By punching the composition of diatom species and modern wetland conditions into modeling programs, Enache is able to illustrate what a wetland once looked like. “Diatom species are a very precious environmental archive because we can go back in time—when nobody could take measurements of nutrients, nobody could take measurements of pH—and actually use the diatom species to get complete numbers,” she says. These figures help her record the increase of everything from agricultural nutrients to industrial chemicals in New Jersey’s water all the way back to the mid-1600s, when Europeans arrived and began to dramatically alter the state.
But while diatoms offer a window into the decline of New Jersey’s marshes, they also offer a glimpse of environmental resiliency to Desianti. Just as the team used the salt tolerance of different diatoms to map past episodes of sea level rise, they could also use the microscopic algae to deduce how these marshes responded to saltwater intrusion.
When it comes to habitats, marshes are particularly dynamic. As the boggy barriers between land and sea, coastal marshes hoard sediment, building vertically to stay above the rising ocean. When sea level rise outpaces their accumulation of sediment, the marshes retreat inland by spilling into coastal forests. As the marsh’s briny water percolates into the groundwater, it kills the trees, creating what ecologists call “ghost forests” of desiccated tree husks.
While coastal marshes are naturally pliable, anthropogenic impacts have rendered them brittle. In New Jersey, dams strain out sediment, robbing the marsh of construction material, and retreating marshes butt up against paved roads and vacation homes. “Salt marshes have to compete with us in establishing habitat,” says Desianti, who now uses diatoms to track nutrient pollution for the Wisconsin State Laboratory of Hygiene. “As a result, these salt marshes are squeezed between sea level rise and human pressures.”
The diatoms Potapova and Desianti collected and identified will help the NJDEP not only understand how New Jersey’s coastal wetlands have responded to past bouts of sea level rise but also inform what can be done to restore these vibrant ecosystems.
The deeper you core into the pond muck, the more diverse the diatoms tend to be, which, as Ruth Patrick deduced decades ago, is the trademark of a healthy ecosystem. As you examine a core’s more recent chapters, this diatomic diversity often decreases as certain specialists, like salt-loving marine diatoms, dominate. Understanding where these saline-specializing species persist reveals which ecosystems have succumbed to sea level rise and where restoration efforts, like an influx of sediment, are needed the most.
Diatoms are not a cure for threats like sea level rise and pollution. Instead, they are a key to help combat them. They reveal what pristine habitats were once like long before anyone paid attention and illustrate what has gone awry over the centuries. To enact successful wetland restoration measures, it would be wise to consult these microscopic algae.
Which is why the diatom specimens Potapova and Desianti collected in New Jersey’s coastal marshes are being filed away alongside Patrick’s specimens in the diatom herbarium’s steel cabinets. Similarly to how they persist in sediment for millennia, the diatom specimens stored at the academy will offer invaluable data points for future researchers to make sense of pollution and shifting sea levels.
“The diatom herbarium is an invaluable resource for diatom research,” says Desianti. “I’m sure that in the future, even when I’m gone, people will still access this collection and continue to investigate environmental issues.” She is confident that within the tens of thousands of slides deposited in the recesses of the academy are environmental breakthroughs waiting to be decoded.",2
295,"181 books — 316 voters
Goodreads helps you keep track of books you want to read.
Start by marking “A Desolation Called Peace (Teixcalaan, #2)” as Want to Read:
Enlarge cover
Open Preview
See a Problem?
We’d love your help. Let us know what’s wrong with this preview of A Desolation Called Peace by Arkady Martine.
Not the book you’re looking for?
Preview — A Desolation Called Peace by Arkady Martine
A Desolation Called Peace
(Teixcalaan #2)
by
4.35 · Rating details · 17,345 ratings · 2,204 reviews
An alien armada lurks on the edges of Teixcalaanli space. No one can communicate with it, no one can destroy it, and Fleet Captain Nine Hibiscus is running out of options.
In a desperate attempt at diplomacy with the mysterious invaders, the fleet captain has sent for a diplomatic envoy. Now Mahit Dzmare and Three Seagrass—still reeling from the recent upheaval in the Empi ...more
In a desperate attempt at diplomacy with the mysterious invaders, the fleet captain has sent for a diplomatic envoy. Now Mahit Dzmare and Three Seagrass—still reeling from the recent upheaval in the Empi ...more
Hardcover, 496 pages
Published March 2nd 2021 by Tor Books
Friend Reviews
To see what your friends thought of this book, please sign up.
Reader Q&A
To ask other readers questions about A Desolation Called Peace, please sign up.
Popular Answered Questions
Marcus Arkady has said that she wants to tell more stories set in the Texcalaan Universe. The next one after 'A Desolation Called Peace' may be focused upon …moreArkady has said that she wants to tell more stories set in the Texcalaan Universe. The next one after 'A Desolation Called Peace' may be focused upon the character Nineteen Adze. Arkady mentions these aspirations in the interview she did with NPR : https://www.npr.org/2019/04/07/710356...(less)
This question contains spoilers... (view spoiler)[I heard the romance in the first one was not a prominent part. Since I am searching for more adventure etc. Novels with F/F romance (specifically when I can expect a happy ending), could this qualify? (hide spoiler)]
L As for the ""happy ending"" part of your question, the answer is... complicated. If you're not OK with ""complicated"", you certainly should not be readin…moreAs for the ""happy ending"" part of your question, the answer is... complicated. If you're not OK with ""complicated"", you certainly should not be reading Arkady Martine.
The book does not end with a happy couple getting married and Living Happily Ever After.(less)
The book does not end with a happy couple getting married and Living Happily Ever After.(less)
Sapphic & WLW Books Releasing in 2021
Best Space Opera of the 21st Century
267 books — 537 voters
More lists with this book...
Community Reviews
Showing 1-30
Average rating 4.35 ·
· 17,345 ratings · 2,204 reviews
|
Start your review of A Desolation Called Peace (Teixcalaan, #2)
Dec 15, 2020 chai ♡ rated it it was amazing · review of another edition
“The perfect sequel does not exist.”
A Desolation Called Peace: hold my beer.
A Desolation Called Peace: hold my beer.
Dec 10, 2020 carol. rated it it was amazing · review of another edition
Shelves: to-buy-hardcover, advance-reader-copy, sci-fi, et-phone-home
I am grateful that Martine's A Desolation Called Peace came my way at the end of 2020 instead of during the middle, when I had a full case of Quarantine Brain™. Some authors write books suited to QB: undemanding, fun, predictable, and about as interesting as chocolate pudding. Martine is almost the exact opposite, in the best way possible. Almost every word feels like it has weight, and it's almost impossible to predict where her starry empire will take the reader.
""'What is it made of?' Three Se ...more
""'What is it made of?' Three Se ...more
Mar 02, 2021 Nataliya rated it it was amazing · review of another edition
Shelves: favorites, hugo-nebula-nominees-and-winners, 2021-reads
“Bodies die, or suffer, or are imprisoned. Memory lasts.”When your brilliant and polished first novel - intelligent, original, and engrossingly clever - is a clear crown jewel of Hugo Awards, you have big shoes to fill with the follow-up. Even if they are your own award-winning shoes. Arkady Martine makes it seem like easy work, though. (It must be that History PhD of hers).
“Mahit was too many people, since she’d overlaid her damaged imago with the imago of the same man twenty years fart...more
Mar 17, 2021 K.J. Charles added it · review of another edition
Shelves: space-opera, sf
Good grief. I'm just going to sit here feeling stunned for a bit. Good grief, that was a book.
There is *so much* in this. Character and culture, language, politics and colonialism and morality, love and friendship and relationships that are neither, a whole set up with no clear easy answers. All while being a heart-thumping story of an apparently meaningless and unavoidable war.
And after all that intricate plotting and immense complexity of thought and characterization, the very last page of th ...more
There is *so much* in this. Character and culture, language, politics and colonialism and morality, love and friendship and relationships that are neither, a whole set up with no clear easy answers. All while being a heart-thumping story of an apparently meaningless and unavoidable war.
And after all that intricate plotting and immense complexity of thought and characterization, the very last page of th ...more
Sep 25, 2019 Lila rated it it was amazing · review of another edition
Shelves: favorites, fast-paced, sci-fi, smart
Was there ever a more perfect opportunity to call a book Five Stars novel?
When the most (in)famous critique of Pax Romana serves as an inspiration for the title of the novel why should I be surprised Arkady Martine threw at me another book full of harsh truths, universal issues and historical events to draw parallels from. You kn ...more
""To ravage, to slaughter, to usurp under false titles—this they name empire;
and where they make a desert, they call it peace.
—TACITUS (QUOTING CALGACUS), AGRICOLA 30
When the most (in)famous critique of Pax Romana serves as an inspiration for the title of the novel why should I be surprised Arkady Martine threw at me another book full of harsh truths, universal issues and historical events to draw parallels from. You kn ...more
Mar 20, 2021 jade rated it it was amazing
Shelves: diverse-rep, science-fiction, lgbtq-rep, all-time-faves, court-intrigue
“but what better way to draw a monstrous thing to its death than to use its functions against itself? teixcalaan wants; its trust is rooted in wanting; it is in this way you and i will destroy it.”in a memory called empire, we meet ambassador mahit dzmare as she tries to complete the momentous task of finding out who killed her predecessor AND try to keep her home, space station lsel, from being annexed by intergalactic empire teixcalaan.
along the way, she makes many enemies at court ...more
Feb 23, 2021 Alienor ✘ French Frowner ✘ rated it it was amazing · review of another edition
Shelves: genre-scifi, arc-2021, 2021-reads, all-time-favorites, lgbtqia-f-f
✨ RELEASED TODAY! ✨
Who has never thought about what would happen if we made first contact with aliens? Well. Me? I really haven't ? *blinks slowly* Wait - before you decide I'm a lost cause and also, so boring: I've changed my mind!
If you've read A Memory Called Empire - and if you haven't: why are you reading this review instead of doing just that already? Huh? - I have good news for you : A Desolation Called Peace is everything the first book was, but better. The stakes have been raised, peac ...more
Dec 13, 2020 Zitong Ren rated it really liked it · review of another edition
Shelves: 2021, action, war, contains-romance, adventure, diverse, science-fiction, lgbtqi, adult
A Desolation Called Peace by Arkady Martine, the sequel to A Memory Called Empire is just as well written as its predecessor. Set against a backdrop of a rich and gorgeously constructed interplanetary Empire, with a cast of well-explored and fleshed out characters, as well Martine’s stellar writing, there is a lot to like here. It was not without some flaws in my view, hence the four-star rating from me, but I do believe that this sequel with delight fans sci-fi and space opera, and you enjoyed ...more
Jun 09, 2021 Anthony rated it really liked it · review of another edition
This is another fascinating, strange, absorbing work by the fiercely intelligent Arkady Martine. She once again displays some quirks that are perhaps a bit too ubiquitous — a prevalence of both a lot of italics and many parenthetical interruptions — but I also can’t help but admire her commitment to her idiosyncratic style. Her characters are vividly drawn — although sometimes her dialogue feels a bit too hyper articulate, a la Aaron Sorkin — especially, in this installment, the child Emperor-in ...more
Jun 25, 2021 Bradley rated it it was amazing · review of another edition
Shelves: 2021-shelf, sci-fi
It may be just me... but I think that this second book is superior to the first. Let's just ignore the awards the first one earned and focus on the story, the action, and the stakes. We see more of Mahat, but there are a number of new, potentially more interesting characters that pretty much take over my enjoyment here.
Between the emperor's 12-year-old clone or the warrior or the Imago expert (consuming imprints of memories that both help and hinder) and a whole WAR that was made more interesti ...more
Between the emperor's 12-year-old clone or the warrior or the Imago expert (consuming imprints of memories that both help and hinder) and a whole WAR that was made more interesti ...more
Dec 15, 2020 Peter Tillman rated it it was amazing · review of another edition
Shelves: high-prority, science-fiction, favorites, friend-recos, own-copy, reread-list
Just finished, at 1 AM. Boy, is it good. Space war! Incomprehensible, disgusting aliens! Here's what their language sounds like, to a human:
""A sharp, ugly noise with the intimation of a headache inside it, that ended in a scream that had taste—a foul, oilslick, tongue-coating taste that made her nauseated.""
“You don’t need a translator, you need a winnowing barrage,” Captain Twelve Fusion said. “Whatever made that [noise] shouldn’t exist.”
Best novel of 2021? OK, first I've finished this New Year. ...more
""A sharp, ugly noise with the intimation of a headache inside it, that ended in a scream that had taste—a foul, oilslick, tongue-coating taste that made her nauseated.""
“You don’t need a translator, you need a winnowing barrage,” Captain Twelve Fusion said. “Whatever made that [noise] shouldn’t exist.”
Best novel of 2021? OK, first I've finished this New Year. ...more
Mar 03, 2021 luce (currently recovering from a hiatus) rated it really liked it · review of another edition
Shelves: netgalley-edelweiss, iv-good-reads, my-feelings, 2021-reviews, sapphic
❀ blog ❀ thestorygraph ❀ letterboxd ❀ tumblr ❀ ko-fi ❀
With A Desolation Called Peace Arkady has achieved something quite rare in a sequel. In fact, I liked A Desolation Called Peace so much so that, when I looked back to my review for A Memory Called Empire, I found much of my criticism unfair. In my review, I describe AMCE as a case of ‘great concept, poor execution’ but now I wonder whether I just read it at the w ...more
“Trust is not an endlessly renewable resource. Loyalty might be. For longer.”
With A Desolation Called Peace Arkady has achieved something quite rare in a sequel. In fact, I liked A Desolation Called Peace so much so that, when I looked back to my review for A Memory Called Empire, I found much of my criticism unfair. In my review, I describe AMCE as a case of ‘great concept, poor execution’ but now I wonder whether I just read it at the w ...more
Jan 27, 2020 Alice rated it it was amazing · review of another edition
From an interview with NPR:
“The direct sequel (which will tell you both about the scary ring-ships and what Three Seagrass does next) is titled A Desolation Called Peace, which I thoroughly stole from Tacitus. (I was reading Tacitus in a bar in Prague, long story. But it's the best line. Rome makes a desert and calls it peace.)”
Could Arkady Martine be any cooler? I would love to hear this story. Honestly, I’d read her grocery list.
Apparently, this book involves mail fraud, kittens, unwise kissi ...more
“The direct sequel (which will tell you both about the scary ring-ships and what Three Seagrass does next) is titled A Desolation Called Peace, which I thoroughly stole from Tacitus. (I was reading Tacitus in a bar in Prague, long story. But it's the best line. Rome makes a desert and calls it peace.)”
Could Arkady Martine be any cooler? I would love to hear this story. Honestly, I’d read her grocery list.
Apparently, this book involves mail fraud, kittens, unwise kissi ...more
Apr 11, 2021 Gabi rated it liked it · review of another edition
I have the same problem as with the first part: there is marvellous worldbuilding and an interesting story, but the author narrates this in a style that I would describe as talking the plot to death. It is a prose that prevents me from immersing myself into the story. Less description of feelings and motives would have been more.
Apr 08, 2021 DivaDiane rated it really liked it · review of another edition
Thanks to NetGalley for providing the ARC of this book, in exchange for a review.
First, I have to say, that the lack of proper formatting in this ARC, was a real hinderance, slowed my reading down no end, and might have contributed to my diminished love for this sequel of A Memory Called Empire. I don't feel like I can complain too much, because I did get it for free and all, but still. It's a shame.
This book was quite a bit different than Teixcalaan #1. There were multiple POVs, which I did lik ...more
First, I have to say, that the lack of proper formatting in this ARC, was a real hinderance, slowed my reading down no end, and might have contributed to my diminished love for this sequel of A Memory Called Empire. I don't feel like I can complain too much, because I did get it for free and all, but still. It's a shame.
This book was quite a bit different than Teixcalaan #1. There were multiple POVs, which I did lik ...more
Apr 05, 2021 Bethany (Beautifully Bookish Bethany) rated it it was amazing · review of another edition
Shelves: 2021-favorites, lgbtq
Arkady Martine is writing exactly the kind of science fiction I love- nuanced, detailed, filled with political intrigue, and exploring interesting ideas. With A Memory Called Empire, I had some quibbles with the pacing, but it's a book that really stuck with me. For me A Desolation Called Peace completely addressed those issues of pacing, partly by expanding to multiple points of view.
In the first book, we see everything through the eyes of Mahit, a young ambassador to the colonial seat of Teix ...more
In the first book, we see everything through the eyes of Mahit, a young ambassador to the colonial seat of Teix ...more
Apr 16, 2021 Silvana rated it it was ok · review of another edition
Dec 04, 2020 Dave rated it it was amazing · review of another edition
""A Desolation Called Peace"" is ultimately a story about communication between alien cultures, following in the wake of Clarke's 2001 Space Odyssey, Heinlein's Stranger in a Strange Land and Card's Ender series. It is nevertheless a long and perilous journey to get there. What with unpronounceable civilizations like Teixicalaanli and names of characters such as Nine Hibiscus and Three Seagrass, this novel, like the first one in this series, is a difficult nut to crack. It's dense, rich, thick, an ...more
May 27, 2021 Dennis rated it it was ok · review of another edition
Shelves: science-fiction, dnf
Mar 15, 2021 Veronique rated it it was amazing
Shelves: r2021, scifi, favourites
A Memory Called Empire was my favourite read of 2019 and Arkady Martine’s second book was everything I had hoped for and more. Every aspect was either as good or better!
The narrative picks up shortly after the events of the first book, with all the parties dealing with the repercussions of what happened. Once more we have a story that focuses on identity and empire, but also one that questions alienness further. Instead of analysing how one culture can devour another just by being itself, we are ...more
The narrative picks up shortly after the events of the first book, with all the parties dealing with the repercussions of what happened. Once more we have a story that focuses on identity and empire, but also one that questions alienness further. Instead of analysing how one culture can devour another just by being itself, we are ...more
Mar 31, 2021 ReadBecca rated it it was amazing · review of another edition
Shelves: lgbt, favorites, sequels-2021
Arkady Martine is fucking brilliant.
Where in A Memory Called Empire we had a mostly encapsulated murder mystery plot, here the plot is a first contact story. All the wonderful framing of book one, showing us how the empire of colonizers view others as primitive barbarians, we very much see them approach a potential alien contact through that lens here, as a virus to only be dominated or eradicated. Meaning that Mahit herself is uniquely placed as that outsider barbarian to advocate for the poten ...more
Where in A Memory Called Empire we had a mostly encapsulated murder mystery plot, here the plot is a first contact story. All the wonderful framing of book one, showing us how the empire of colonizers view others as primitive barbarians, we very much see them approach a potential alien contact through that lens here, as a virus to only be dominated or eradicated. Meaning that Mahit herself is uniquely placed as that outsider barbarian to advocate for the poten ...more
Apr 11, 2022 Dylan rated it really liked it · review of another edition
Shelves: science-fiction
“It is the minds of a people that have to stay free. Bodies die, or suffer, or are imprisoned. Memory lasts.”
A Desolation Called Peace is a very interesting sequel because in many respects it's better than the prior novel but also worse in other departments. This is a good novel that concludes a lot of threads that have been set up, reasonably well. It is a cathartic ending, that is quite fitting. I rarely read duologies, but I am glad I did because the structure is always designed in a way ...more
Dec 31, 2021 ✘✘ Sarah ✘✘ (former Nefarious Breeder of Murderous Crustaceans) rated it it was ok · review of another edition
💀 DNF at 69%.
Actual rating: 2.5 stars.
My Kindle insists that I've read 69% of this
Well my Kindle is obviously drunk, the publisher quite evidently high on premium quality stuff, and my GR account has undoubtedly been hacked by one of my evil nemeses. Because I'm fairly ...more
Jun 09, 2021 Jemppu rated it really liked it · review of another edition
""To think as a person and to not think language.""
Satisfyingly contemplative exploration on themes of culture, societies, and individuality, and how those interact through nature of languages.
I am amazed how completely opposite my experience with this was compared to the one I had with the first book, which I listened in audio format, and which I felt fell flat in delivering an impact. What I learned from switching between audio and text with this is how the performative tones in the audio narrat ...more
Satisfyingly contemplative exploration on themes of culture, societies, and individuality, and how those interact through nature of languages.
I am amazed how completely opposite my experience with this was compared to the one I had with the first book, which I listened in audio format, and which I felt fell flat in delivering an impact. What I learned from switching between audio and text with this is how the performative tones in the audio narrat ...more
Dec 05, 2020 charlotte, rated it it was amazing
On my blog.
Rep: lesbian mcs, bi side character
Galley provided by publisher
A Memory Called Empire was one of my favourite books of 2019, possibly all time, so there was absolutely no way I wasn’t going to love A Desolation Called Peace. It was wholly inconceivable. So, nothing I say in this review should be at all surprising, really.
At the end of A Memory Called Empire, it was revealed that an alien threat was approaching Teixcalaanli space, and fighting that threat is what takes up the bulk ...more
Rep: lesbian mcs, bi side character
Galley provided by publisher
A Memory Called Empire was one of my favourite books of 2019, possibly all time, so there was absolutely no way I wasn’t going to love A Desolation Called Peace. It was wholly inconceivable. So, nothing I say in this review should be at all surprising, really.
At the end of A Memory Called Empire, it was revealed that an alien threat was approaching Teixcalaanli space, and fighting that threat is what takes up the bulk ...more
Jul 18, 2021 Pamela (Here to Read Books and Chew Gum) rated it liked it · review of another edition
Everything about A Desolation Called Peace is something I should like. It’s the kind of literary sci-fi that I usually adore, but I appear to be in a minority of people who simply couldn’t get into it. There is no doubt that Arkady Martine is a lovely, florid writer. She has an evocative way of using language that reads beautifully - in moderation. But moderation is not something we get, so instead, A Desolation Called Peace is a story that talks itself to death. Like A Memory Called Empire, it ...more
Mar 14, 2021 Reid rated it it was ok · review of another edition
Teixcalaan is a bureaucratic empire, defined by its rigid hierarchy and dedication to the ideal that they are the dominant species and all others are barbarians. When they encounter an alien species that is as different from them as it is possible to be in their beliefs and attitudes toward the sanctity of life, a conflict will ensue that is as much philosophical as it is existential. So far, so good.
Unfortunately, all of the failings of the first volume in this series, A Memory Called Empire, w ...more
Unfortunately, all of the failings of the first volume in this series, A Memory Called Empire, w ...more
Aug 27, 2021 Booked and Busy rated it liked it
I honestly have no idea what I just read but ok I guess
May 06, 2021 Scott rated it really liked it · review of another edition
Shelves: science-fiction
Arkady Martine is a name to watch in Science Fiction.
Her first novel - A Memory Called Empire is a stunningly good story of the rapacious but culturally enticing Teixcalaan empire and an outsider to that realm, a person who - despite her desire to belong - will forever be regarded as a barbarian. This outsider - Ambassador Mahit Dzmare - is rendered even more alien by the forbidden machinery in her head - technology that allows her to carry a copy of the previous (and deceased) ambassador's pers ...more
Her first novel - A Memory Called Empire is a stunningly good story of the rapacious but culturally enticing Teixcalaan empire and an outsider to that realm, a person who - despite her desire to belong - will forever be regarded as a barbarian. This outsider - Ambassador Mahit Dzmare - is rendered even more alien by the forbidden machinery in her head - technology that allows her to carry a copy of the previous (and deceased) ambassador's pers ...more
Mar 18, 2021 Skye Kilaen rated it it was amazing · review of another edition
Shelves: 0-genre-scifi
So! Good! I gave myself a terrible headache staying up late to finish this last night and I REGRET NOTHING.
|topics||posts||views||last activity|
|Play Book Tag: A Desolation Called Peace by Arkady Martine- 4 stars||5||14||20 juil. 2022 04:20|
|SciFi and Fantasy...: Series: Teixcalaan by Arkady Martine (""A Desolation Called Peace"")||74||164||10 juin 2021 17:37|
|SFF Hot from Prin...: A Desolation Called Peace||45||39||26 mai 2021 06:38|
843 users
158 users
61 users
Other books in the series
Teixcalaan (2 books)
Articles featuring this book
Science fiction has always watched the skies. The genre has a rich tradition of looking to the rest of the cosmos for stories of life in...
66 likes · 16 comments
More quotes…",8
296,"Stable Diffusion Public Release
It is our pleasure to announce the public release of stable diffusion following our release for researchers [https://stability.ai/blog/stable-diffusion-announcement]
Over the last few weeks we all have been overwhelmed by the response and have been working hard to ensure a safe and ethical release, incorporating data from our beta model tests and community for the developers to act on.
In cooperation with the tireless legal, ethics and technology teams at HuggingFace and amazing engineers at CoreWeave , we have incorporated the following elements:
i) The model is being released under a Creative ML OpenRAIL-M license [https://huggingface.co/spaces/CompVis/stable-diffusion-license]. This is a permissive license that allows for commercial and non-commercial usage. This license is focused on ethical and legal use of the model as your responsibility and must accompany any distribution of the model. It must also be made available to end users of the model in any service on it.
ii) We have developed an AI-based Safety Classifier included by default in the overall software package. This understands concepts and other factors in generations to remove outputs that may not be desired by the model user. The parameters of this can be readily adjusted and we welcome input from the community how to improve this. Image generation models are powerful, but still need to improve to understand how to represent what we want better.
As these models were trained on image-text pairs from a broad internet scrape, the model may reproduce some societal biases and produce unsafe content, so open mitigation strategies as well as an open discussion about those biases can bring everyone to this conversation. Learn more about the model strengths and limitations in the model card.
This release is the culmination of many hours of collective effort to create a single file that compresses the visual information of humanity into a few gigabytes.
We hope everyone will use this in an ethical, moral and legal manner and contribute both to the community and discourse around it. Please carefully read the model card for a full outline of the limitations of this model and we welcome your feedback in making this technology better.
You can join our dedicated community for Stable Diffusion here: [https://discord.gg/stablediffusion] where we have areas for developers, creatives and just anyone inspired by this.
You can find the weights, model card and code here:[https://huggingface.co/CompVis/stable-diffusion]
An optimized development notebook using the HuggingFace diffusers library: [https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb]
A public demonstration space can be found here: [https://huggingface.co/spaces/stabilityai/stable-diffusion]
For more control and rapid generation you can try our DreamStudio beta here: http://beta.dreamstudio.ai.
Additional functionality and API access will be activated shortly, including local GPU support, animation, logic-based multi-stage workflows and many more.
We are also happy to support many partners through our API and other programs and will be posting on these soon.
The recommended model weights are v1.4 470k, a few extra training steps from the v1.3 440k model made available to researchers. The final memory usage on release of the model should be 6.9 Gb of VRAM.
In the coming period we will release optimized versions of this model along with other variants and architectures with improved performance and quality. We will also release optimisations to allow this to work on AMD, Macbook M1/M2 and other chipsets. Currently NVIDIA chips are recommended.
We will also release additional tools to help maximize the impact and reduce potential adverse outcomes from these tools with amazing partners to be announced in the coming weeks.
This technology has tremendous potential to transform the way we communicate and we look forward to building a happier, more communicative and creative future with you all.
Please contact info@stability.ai with any queries, much more soon.",3
297,"Multiple branches of the U.S. military have bought access to a powerful internet monitoring tool that claims to cover over 90 percent of the world’s internet traffic, and which in some cases provides access to people’s email data, browsing history, and other information such as their sensitive internet cookies, according to contracting data and other documents reviewed by Motherboard.
Additionally, Sen. Ron Wyden says that a whistleblower has contacted his office concerning the alleged warrantless use and purchase of this data by NCIS, a civilian law enforcement agency that’s part of the Navy, after filing a complaint through the official reporting process with the Department of Defense, according to a copy of the letter shared by Wyden’s office with Motherboard.
The material reveals the sale and use of a previously little-known monitoring capability that is powered by data purchases from the private sector. The tool, called Augury, is developed by cybersecurity firm Team Cymru and bundles a massive amount of data and makes it available to government and corporate customers as a paid service. In the private industry, cybersecurity analysts use it for following hackers’ activity or attributing cyberattacks. In the government world, analysts can do the same, but agencies that deal with criminal investigations have also purchased the capability. The military agencies did not describe their use cases for the tool. However, the sale of the tool still highlights how Team Cymru obtains this controversial data and then sells it as a business, something that has alarmed multiple sources in the cybersecurity industry.
“The network data includes data from over 550 collection points worldwide, to include collection points in Europe, the Middle East, North/South America, Africa and Asia, and is updated with at least 100 billion new records each day,” a description of the Augury platform in a U.S. government procurement record reviewed by Motherboard reads. It adds that Augury provides access to “petabytes” of current and historical data.
Motherboard has found that the U.S. Navy, Army, Cyber Command, and the Defense Counterintelligence and Security Agency have collectively paid at least $3.5 million to access Augury. This allows the military to track internet usage using an incredible amount of sensitive information. Motherboard has extensively covered how U.S. agencies gain access to data that in some cases would require a warrant or other legal mechanism by simply purchasing data that is available commercially from private companies. Most often, the sales center around location data harvested from smartphones. The Augury purchases show that this approach of buying access to data also extends to information more directly related to internet usage.
Team Cymru says on its website that its solution provides “access to a super majority of all activity on the internet.”
Do you work at a company that handles netflow data? Do you work at an ISP distributing that data? Or do you know anything else about the trade or use of netflow data? We'd love to hear from you. Using a non-work phone or computer, you can contact Joseph Cox securely on Signal on +44 20 8133 5190, Wickr on josephcox, or email joseph.cox@vice.com.
“Augury is the visibility into 93% of internet traffic,” another website describing the tool reads. Some clients have access to the platform under the different brand name Pure Signal RECON, according to Team Cymru’s website.
The Augury platform makes a wide array of different types of internet data available to its users, according to online procurement records. These types of data include packet capture data (PCAP) related to email, remote desktop, and file sharing protocols. PCAP generally refers to a full capture of data and encompasses very detailed information about network activity. PCAP data includes the request sent from one server to another, and the response from that server too.
PCAP data is “everything,” Zach Edwards, a cybersecurity researcher who has closely followed the data trade, told Motherboard in an online chat. “It’s everything. There’s nothing else to capture except the smell of electricity.” (Team Cymru told Motherboard it does limit what data is returned to users but did not specify what data actually is provided to a user of the platform.)
A source in the cybersecurity industry said “that’s insane” when shown that sensitive information like PCAP data was available in Augury. Some private industry users appear to have less access to certain data types in Augury than those listed in the government procurement records. Motherboard granted multiple sources in this piece anonymity because they weren’t authorized by their employers to speak on this issue.
Augury’s data can also include web browser activity, like URLs visited and cookie usage, according to the procurement records. Cookies are sensitive files that websites plant onto computers when people visit them. Given their uniqueness, cookies can be effective for tracking. Facebook and Google, for example, use cookies to follow a particular user from website to website and track their activity. The NSA has then piggybacked off of these cookies to identify targets for hacking. Screenshots of an apparent Augury panel obtained by Motherboard show results containing cookies, URLs visited, and email data. Motherboard showed a section of one of the screenshots to multiple sources familiar with the tool who said it does appear to be the Augury panel.
Sign up for Motherboard’s daily newsletter for a regular dose of our original reporting, plus behind-the-scenes content about our biggest stories.
Augury also contains so-called netflow data, which creates a picture of traffic flow and volume across a network. That can include which server communicated with another, which is information that may ordinarily only be available to the server owner themselves or to the internet service provider carrying the traffic. That netflow data can be used for following traffic through virtual private networks, and show the server they are ultimately connecting from. Multiple sources in the cybersecurity industry told Motherboard that netflow data can be useful for identifying infrastructure that hackers are using.
Team Cymru obtains this netflow data from ISPs; in return, Team Cymru provides the ISPs with threat intelligence. That transfer of data is likely happening without the informed consent of the ISPs’ users. A source familiar with the netflow data previously told Motherboard that “the users almost certainly don’t [know]” their data is being provided to Team Cymru, who then sells access to it.
It is not clear where exactly Team Cymru obtains the PCAP and other more sensitive information, whether that's from ISPs or another method.
Motherboard asked Team Cymru multiple times if Augury contains cookies, URLs visited, and PCAP data, as the procurement records show. Team Cymru did not answer the question directly, and instead wrote in an email that “The Augury platform is not designed to target specific users or user activity. The platform specifically does not possess subscriber information necessary to tie records back to any users.”
“Our platform does not provide user or subscriber information, and it doesn’t provide results that show any pattern of life, preventing its ability to be used to target individuals. Our platform only captures a limited sampling of the available data, and is further restricted by only allowing queries against restricted sampled and limited data, which all originates from malware, malicious activity, honeypots, scans, and third parties who provide feeds of the same. Results are then further limited in the scope and volume of what’s returned,” Team Cymru said in another email.
Some have used Team Cymru’s data as part of investigations that aimed to identify specific computers and then contact the person using it, though. In July 2021 researchers at Citizen Lab published a report about Israeli spyware vendor Candiru. As part of that, the researchers wrote that they used Team Cymru’s data to identify a computer they believed had been infected with Candiru’s malware, and in turn, contacted the owner of that computer. Citizen Lab did not respond to a request for comment.
The procurement record that says Augury has access to PCAP data, URLs visited, and cookies relates to the maintenance of a Department of the Navy purchase of the tool. Other procurement data viewed by Motherboard shows the Department of the Navy paid for a “Platinum” Augury license. Beyond that, it is not clear which of Team Cymru’s U.S. government clients have access to the more sensitive data such as cookies. Records for the Army, Cyber Command, and the Defense Counterintelligence and Security Agency do not explicitly include the “platinum” marker, but in some cases the amount paid by the agencies is the same amount the Navy paid for a platinum license.
These sales to the U.S. government were made through a company called Argonne Ridge Group, which Motherboard found shares an address with Team Cymru. Team Cymru told Motherboard in an email that Argonne Ridge Group is an affiliate of Team Cymru which has historically handled contracts with public agencies.
Although they don’t explicitly mention Augury, Motherboard found multiple contracts between Argonne Ridge Group and the FBI and Secret Service. One of the FBI contracts says “it will secure funding approval to buy net flow from one commercial vendor and integrating it into existing sources of net flow available to cyber intelligence analysts to analyze as a proof of concept.” The Secret Service did not respond to multiple requests for comment. The FBI did not provide a response in time for publication.
The Army was unable to provide a statement on the Augury platform purchases in time for publication. After initially acknowledging Motherboard’s request for comment, the Defense Counterintelligence and Security Agency later deferred to the Department of Defense.
Charles E. Spirtos from the Navy Office of Information told Motherboard in an email that NCIS specifically “conducts investigations and operations in accordance with all applicable laws and regulations. The use of net flow data by NCIS does not require a warrant.” Spirtos added that NCIS has not used netflow during any criminal investigation, but that “NCIS uses net flow data for various counterintelligence purposes.”
Regarding the whistleblower that Senator Wyden says approached his office, their complaint relates specifically to use by NCIS, which Motherboard found does have a contract with Argonne Ridge Group.
“NCIS will defeat threats from across the foreign intelligence, terrorist and criminal spectrum by conducting operations and investigations ashore, afloat, and in cyberspace, in order to protect and preserve the superiority of the Navy and Marine Corps warfighters,” NCIS’ website reads.
In his letter addressed to the oversight departments of the DHS, DOJ, and DOD, Senator Wyden writes that “my office was recently contacted by a whistleblower who described a series of formal complaints they filed up and down their chain of command, as well as to the DOD Inspector General and the Defense Intelligence Agency, regarding the warrantless purchase and use of netflow data by the Naval Criminal Investigative Service (NCIS).”
The whistleblower alleges that NCIS is purchasing data from Team Cymru that includes both “netflow records and some communications content,” the letter continues. “The whistleblower has informed my office that their complaint was forwarded by the DOD Inspector General to the Navy Inspector General.” Pointing to the various U.S. government contracts for access to Augury, which his office also reviewed, in his letter Senator Wyden asks the oversight branches of the DHS, DOJ, and DOD to “investigate the warrantless purchase and use of Americans’ internet browsing records by the agencies under your jurisdictions. Your independent oversight must ensure that the government’s surveillance activities are consistent with the Supreme Court’s Carpenter decision and safeguard Americans’ Fourth Amendment rights.”
The Department of Defense Office of the Inspector General, which the whistleblower alleges referred their complaint to the Navy, told Motherboard it had received Wyden’s letter and was reviewing it. The Office of the Naval Inspector General declined to comment and directed Motherboard back to its Department of Defense counterpart.
Beyond his day job as CEO of Team Cymru, Rabbi Rob Thomas also sits on the board of the Tor Project, a privacy focused non-profit that maintains the Tor software. That software is what underpins the Tor anonymity network, a collection of thousands of volunteer-run servers that allow anyone to anonymously browse the internet.
“Just like Tor users, the developers, researchers, and founders who've made Tor possible are a diverse group of people. But all of the people who have been involved in Tor are united by a common belief: internet users should have private access to an uncensored web,” the Tor Project’s website reads.
When asked by Motherboard in April about Thomas’ position on the Tor Project board while also being the CEO of a company that sells a capability for attributing activity on the internet, Isabela Bagueros, executive director for the Tor Project, said in an email that “Rabbi Rob's potential conflicts of interest have been vetted according to the standard conflicts disclosure process required of all board members. Based on the board's understanding of Rabbi Rob's work with Team Cymru, the board has not identified any conflicts of interest.”
Motherboard has previously revealed other data purchases by the U.S. military. In 2020, Motherboard found that a Muslim prayer app downloaded more than 98 million times sold its location data to a broker called X-Mode. X-Mode, in turn, included U.S. military contractors among its clients. As part of that investigation, Motherboard also found that U.S. Special Operations Command had purchased Locate X, a surveillance tool based on location data harvested from ordinary apps. Last March, Motherboard reported that a military unit that conducts drone strikes bought Locate X too.
After Motherboard published some of those findings, Sen. Wyden asked the Department of Defense for more information about its data purchases. Some of the agency’s subsequent responses were given in a form that meant Wyden's office could not legally publish specifics on the surveillance; one answer in particular was classified. Instead, Wyden wrote in a second letter in May 2021 to the agency: “I write to urge you to release to the public information about the Department of Defense's (DoD) warrantless surveillance of Americans,” suggesting that the Pentagon is engaged in such surveillance. At the time, Wyden's office declined to provide Motherboard with specifics about the classified answer. But a Wyden aide said that the question related to the Department of Defense buying internet metadata.
In August, the House of Representatives approved changes to next year’s military budget that would require the Department of Defense to start to disclose any purchases of web browsing or smartphone data that would ordinarily require a warrant, Gizmodo reported at the time. It has yet to be approved by the Senate.
Other cybersecurity companies also package controversial datasets. In 2020 Motherboard reported that HYAS, a threat intelligence firm, sourced location data in order to track people to their “doorstep.”
Update: This piece has been updated with a statement from the Navy.
Subscribe to our cybersecurity podcast, CYBER. Subscribe to our new Twitch channel.",5
298,"« La première fois que j’ai entendu parler, lors d’une conférence, de la décroissance, j’étais étudiant en deuxième année d’économie à l’université de Versailles-Saint-Quentin. J’avais votre âge, et j’ai ricané. Je me suis dit : c’est qui ce plouc, ce guignol qui n’a pris jamais pris un seul cours d’économie ? Depuis, j’ai fait pas mal de chemin. »
C’est avec cette mise en abyme que l’économiste Timothée Parrique, 33 ans, auteur de Ralentir ou périr. Une économie de la décroissance (Seuil, 2022, 20 euros) commençait sa conférence devant un parterre d’étudiants et de salariés de HEC Paris, lundi 19 septembre. Une heure pour exposer les thèmes de son livre sorti le 16 septembre, déjà en rupture de stock : l’impossible croissance verte, les fausses promesses de la croissance économique, le projet de société de la post-croissance…
L’économiste actuellement en poste à l’université de Lund (Suède) était aussi invité à dispenser un cours sur « les fondements de la décroissance » aux 380 étudiants de première année. Depuis 2021, tous les élèves suivent un séminaire de 18 heures d’enseignements sur le dérèglement climatique – un parcours mis en place en réponse à une demande pressante des étudiants.
« Justice sociale et bien-être »
Parler de décroissance au sein de l’école de l’élite économique, qui forme chaque année une armée de jeunes à rendre les entreprises encore plus profitables ? Un drôle de paradoxe qu’évacue rapidement l’économiste, qui assume aller « là où l’on l’invite ». « En tant qu’universitaire, je participe au débat public. Mon rôle pendant ces quelques heures à HEC est d’équiper les étudiants d’un cadre théorique auquel ils n’ont pas accès. Ils seront amenés à prendre des décisions dans dix ans, ils ont donc besoin d’avoir tous les cadres analytiques en leur possession. Si je viens, c’est pour les étudiants. Je ne dilue rien du contenu, et je raconte exactement la même chose à mes étudiants en Suède et dans mes recherches ». Le « cadre théorique » dans lequel s’inscrit son intervention, il en donne une définition simple : « la décroissance est une réduction de la production et de la consommation pour alléger l’empreinte écologique, planifiée démocratiquement dans un esprit de justice sociale et de bien-être ».
Née dans les années 1970, l’idée de décroissance prend son envol notamment grâce à des intellectuels français comme Serge Latouche (économiste), Paul Ariès (politologue), André Gorz, (philosophe et journaliste). Aux Etats-Unis, le rapport sur « Les limites à la croissance » (1972) de Dennis et Donella Meadows, chercheurs du MIT, est un best-seller vendu à 12 millions d’exemplaires et traduit dans 37 langues. Pour la première fois, une nouvelle technique de modélisation simule douze scénarios prospectifs portant sur la production industrielle, la croissance démographique, la production de nourriture la raréfaction des ressources et la pollution. La conclusion : la croissance exponentielle de la production et de la population dépasse les limites planétaires.
Il vous reste 55.83% de cet article à lire. La suite est réservée aux abonnés.",0
300,"Everything Everywhere All at Once
|Everything Everywhere All at Once|
|Directed by||Daniel Kwan|
Daniel Scheinert
|Written by|
|Produced by|
|Starring|
|Cinematography||Larkin Seiple|
|Edited by||Paul Rogers|
|Music by||Son Lux|
Production
companies
|Distributed by||A24|
Release dates
Running time
|140 minutes[1]|
|Country||United States|
|Languages|
|Budget||$25 million[2]|
|Box office||$99.8-100.7 million[3][4]|
Everything Everywhere All at Once is a 2022 American absurdist science fiction comedy-drama film written and directed by Daniel Kwan and Daniel Scheinert (collectively known as ""Daniels""), who produced it with the Russo brothers. It stars Michelle Yeoh as a Chinese American woman being audited by the IRS who discovers that she must connect with parallel universe versions of herself to prevent a powerful being from causing the destruction of the multiverse. Stephanie Hsu, Ke Huy Quan, Jenny Slate, Harry Shum Jr., James Hong, and Jamie Lee Curtis appear in supporting roles. The film was described by The New York Times as a ""swirl of genre anarchy"" and features elements of black comedy, science fiction, fantasy, martial arts film, and animation.
Kwan and Scheinert researched the concept of the multiverse as far back as 2010, and began penning the screenplay as early as 2016. Originally written for Jackie Chan, the lead role was later reworked and offered to Yeoh.[5][6] Principal photography began in January 2020 and concluded in March as the COVID-19 pandemic reached the United States. The film's soundtrack features music composed by Son Lux, including collaborations with musicians Mitski, David Byrne, André 3000, and Randy Newman.
Everything Everywhere All at Once premiered at South by Southwest on March 11, 2022, and began a limited theatrical release in the United States on March 25, before a wide release by A24 on April 8. The film received widespread critical acclaim. Reviews praised its imagination, direction, screenplay, editing, production design, the cast (particularly Yeoh, Quan, and Hsu), and its handling of themes such as existentialism, nihilism, and Asian American identity. It has grossed over $100 million worldwide, becoming A24's first movie to do so and surpassing Hereditary (2018) as its highest-grossing film.
Plot[edit]
Part 1: Everything[edit]
Evelyn Quan Wang is a Chinese American immigrant who runs a struggling laundromat with her husband, Waymond. Tensions are high: the laundromat is being audited by the IRS, Waymond is trying to serve Evelyn divorce papers, Evelyn's demanding father Gong Gong[a] has just arrived from Hong Kong, and Evelyn's lesbian daughter Joy has been trying to get her mother to accept her girlfriend, Becky.
At a meeting with IRS inspector Deirdre Beaubeirdre, Waymond's personality changes when his body is briefly taken over by Alpha Waymond, a version of Waymond from a universe he calls the ""Alphaverse"". Alpha Waymond explains to Evelyn that many parallel universes exist, since every choice made creates a new universe. The people of the Alphaverse, led by the late Alpha Evelyn, developed ""verse-jumping"" technology that allows people to access the skills, memories, and body of their parallel universe counterparts by fulfilling specific conditions. The multiverse is being threatened by Jobu Tupaki, the Alphaverse version of Joy. Her mind was splintered after Alpha Evelyn pushed her to extensively verse-jump; Jobu Tupaki now experiences all universes at once and can verse-jump and manipulate matter at will. With her godlike power she has created a black hole-like ""everything bagel""[b] that can potentially destroy the multiverse.
Evelyn is given verse-jumping technology to fight Jobu Tupaki's verse-jumping minions, who begin converging in the IRS building. Evelyn learns of Waymond's plans to divorce her and discovers other lives where she made different choices and flourished, such as by becoming a kung fu master and movie star instead of leaving China with Waymond, who becomes a successful businessman. Alpha Waymond comes to believe that Evelyn, as the greatest failure of all Evelyns of the multiverse, has the untapped potential to defeat Jobu Tupaki. Alpha Gong Gong instructs Evelyn to kill Joy to hinder Jobu Tupaki, but Evelyn refuses. She decides she must face Jobu Tupaki by gaining the same powers as her, so she verse-jumps repeatedly while battling Jobu Tupaki's minions and Alpha Gong Gong's soldiers. After the battle, Alpha Waymond is located and killed by Jobu Tupaki in the Alphaverse and Evelyn's mind splinters.
Part 2: Everywhere[edit]
Evelyn verse-jumps to other, bizarre universes, including one in which humans have hot dogs for fingers and she is in a romantic relationship with Deirdre, and another where she works alongside a teppanyaki chef Chad, who is secretly puppeteered by a raccoon. She learns that Jobu Tupaki created the everything bagel not to destroy everything, but to destroy herself, and has been searching for an Evelyn who can understand her. Jobu Tupaki feels that because there are so many vast universes and unending chaos, nothing truly matters and she wishes to simply no longer exist.
In other universes, the Wangs are about to lose the laundromat due to tax errors, hot dog finger Evelyn's relationship with Deirdre falls apart, chef Evelyn exposes the raccoon-puppeteering Chad, and businessman Waymond rejects moviestar Evelyn after decades apart. Evelyn is nearly swayed to Jobu Tupaki's cause after a long philosophical discussion throughout several universes, and stabs her universe's Waymond. She almost joins Jobu Tupaki in entering the bagel, but stops when she hears Waymond's pleas for both Evelyn and Alpha Gong Gong's fighters to stop fighting, be kind, and have hope, even in a universe where nothing seems to make sense. Evelyn defeats Alpha Gong Gong and Jobu Tupaki's fighters by using her multiverse knowledge to find what is hurting each of them and brings them happiness. Evelyn reaches Jobu Tupaki and tells her that she is not alone and that Evelyn will always choose to be with her, despite everywhere else she could be. Meanwhile, in a parallel universe, Evelyn confronts Gong Gong and reconciles with Waymond and Joy, and Waymond convinces Deirdre to let the Wangs redo their taxes. Jobu Tupaki initially rejects Evelyn, but returns to her, and they embrace.
Part 3: All at Once[edit]
Shortly thereafter, the family's relationships and lives have improved; Becky is now regarded as a part of the family, Waymond and Evelyn share a brief but romantic moment for the first time in a long while, and they return to the IRS building on a second chance to file their taxes. As Deirdre talks, Evelyn's attention is momentarily drawn to her alternate selves and the multiverse, before she grounds herself back in her home universe.
Cast[edit]
- Michelle Yeoh as Evelyn Quan Wang, a dissatisfied and overwhelmed laundromat owner
- Stephanie Hsu as Joy Wang / Jobu Tupaki, Evelyn's daughter and a threat to the multiverse
- Ke Huy Quan as Waymond Wang, Evelyn's meek and goofy husband
- James Hong as Gong Gong (Chinese 公公, ""maternal grandfather""),[9] Evelyn's demanding father
- Jamie Lee Curtis as Deirdre Beaubeirdre, an IRS inspector
- Jenny Slate as Debbie the Dog Mom, a laundromat customer
- The character's original name (""Big Nose"") was changed for the film's digital release because of its association with Jewish stereotypes.[10]
- Harry Shum Jr. as Chad, a teppanyaki chef working alongside Evelyn in an alternate universe
- Tallie Medel as Becky Sregor, Joy's girlfriend
Additionally, Biff Wiff appears as Rick, a laundromat customer; Sunita Mani and Aaron Lazar appear as actors in a musical film Evelyn watches; Audrey Wasilewski and Peter Banifaz appear as Alpha RV Officers; Daniel Scheinert appears as District Manager; and Andy Le and Brian Le appear as Alpha Trophy Jumpers.
Randy Newman, who has scored nine Disney–Pixar animated films, appears in an uncredited role as the voice of Raccacoonie, a reference to the Pixar-animated film Ratatouille (2007); he is officially credited as a featured artist on the track ""Now We're Cookin'"".[11] Dan Kwan has uncredited cameos as a man sucked into the bagel and a mugger.[12]
Production[edit]
Development and writing[edit]
Co-directors Dan Kwan and Daniel Scheinert stated they began researching the concept of the multiverse in 2010, after being exposed to the concept of modal realism in the 1986 film Sherman's March.[8] Kwan described the release of the 2018 film Spider-Man: Into the Spider-Verse, which also features a multiverse concept, as ""a little upsetting because we were like, 'Oh shit, everyone's going to beat us to this thing we've been working on.'""[8] He also stated, ""Watching the second season of Rick and Morty was really painful. I was like, 'They've already done all the ideas we thought were original!' It was a really frustrating experience. So I stopped watching Rick and Morty while we were writing this project.""[8]
In early drafts, the directors planned for the main character to have undiagnosed attention deficit hyperactivity disorder (ADHD); through his research for the project, Kwan learned that he himself had undiagnosed ADHD.[13]
The universe in which Evelyn trains in martial arts and becomes an action movie star features scenes visually and contextually inspired by the films of Hong Kong director Wong Kar-wai;[8] Chris Lee of Vulture wrote that these scenes ""conjur[e] a mood of exquisite romantic yearning that will be instantly recognizable [...] as touchstones"" of Wong's works.[8] The universe in which Evelyn and Joy are rocks was influenced by the 1969 children's book Sylvester and the Magic Pebble and the 2017 video game Everything.[8]
Kwan stated that the idea of the everything bagel created by Jobu Tupaki ""started as just a throwaway joke.""[8] Scheinert noted that they spent time attempting to develop the religion of bagel followers, but encountered complications: ""[Jobu Tupaki]'s a nihilist; should there be dogma? Should there be a book? What should their practices be as a religion? The bagel stuck because it became such a useful, simple symbol that we could point to as filmmakers. And you don't have to explain it much beyond the joke.""[8]
Casting[edit]
During pre-production, Jackie Chan was considered for the starring role; the script was originally written for him before Kwan and Scheinert changed their minds and re-conceived the lead role as a woman, feeling it would make the husband-wife dynamic in the story more relatable.[6]
When the script was initially rewritten with the lead character as a woman, the character was renamed ""Michelle Wang""; according to Michelle Yeoh, ""If you ask the Daniels, when they started on this draft, they focused on, 'Well, we are doing this for Michelle Yeoh.'""[14] The character's name was ultimately changed to Evelyn; despite the parallels in the final film between Yeoh and the universe in which Evelyn is a martial artist and movie star,[15] Yeoh opposed naming the character Michelle, stating that ""She is not called Michelle because [...] Evelyn deserves her own story to be told. This is a very ordinary mother [and] housewife who is trying her best to be a good mother to her daughter, a good daughter to her father, a wife that's trying to keep the family together [...] I don't like to integrate me, Michelle Yeoh, into the characters that I play, because they all deserve their own journey and their stories to be told.""[15]
It was announced in August 2018 that Yeoh and Awkwafina were cast to star in an ""interdimensional action film"" from Kwan and Scheinert, with Anthony and Joe Russo set to produce.[16] Awkwafina exited the project due to scheduling conflicts in January 2020. Stephanie Hsu, James Hong, Ke Huy Quan, and Jamie Lee Curtis joined the cast, with Hsu replacing Awkwafina. It marked Quan's return to film acting, from which he had retired in 2002 due to a lack of casting opportunities.[17][18]
Filming[edit]
Filming began in January 2020, with A24 announcing it would finance and distribute the film.[19] Principal photography concluded in early March 2020 during the onset of the COVID-19 pandemic.[20]
Themes[edit]
Everything Everywhere All at Once incorporates elements from a number of genres and film mediums, including black comedy, science fiction, fantasy, martial arts film, and animation.[21][22] A. O. Scott of The New York Times described the film as a ""swirl of genre anarchy"", explaining that ""while the hectic action sequences and flights of science-fiction mumbo-jumbo are a big part of the fun (and the marketing), they aren't really the point. [The movie is] a bittersweet domestic drama, a marital comedy, a story of immigrant striving and a hurt-filled ballad of mother-daughter love.""[23]
The film explores the concepts of the meaning of life and nihilism; according to Charles Bramesco of The Guardian, ""The bagel of doom and its tightening grip on Evelyn's daughter lend themselves to the climactic declaration that there's nothing worse than submitting to the nihilism so trendy with the next generation. Our lone hope of recourse is to embrace all the love and beauty surrounding us, if only we're present enough to see it.""[24] This nihilism is also explored through the film's exploration of Asian American identity. Anne Anlin Cheng wrote in The Washington Post, ""It's not only that the multiverse acts as a metaphor for the immigrant Asian American experience, or a convenient parable for the dislocations and personality splits suffered by hyphenated (that is, ""Asian-American"") citizens. It also becomes a rather heady vehicle for confronting and negotiating Asian-pessimism,"" a term she uses in reference to Afro-pessimism.[25]
Consequence's Clint Worthington wrote that, ""for all its dadaist absurdism and blink-if-you-miss-it pace, Daniels weaves the chaotic possibilities into the multiverse into a cohesive story about the aches and pains of the road not traveled, and the need to carve out your own meaning in a meaningless universe.""[26] Describing Jobu Tupaki's modus operandi, Worthington notes ""the living contradiction that is the everything bagel: if you put everything on a bagel, what more is left? And if you've experienced everything that the multiverse can offer, what's the point of any of it?""[26] Co-director Daniel Kwan stated that the everything bagel concept ""did two things. It allowed us to talk about nihilism without being too eye roll-y. And it creates a MacGuffin: a doomsday device. If in the first half of the movie, people think that the bagel is here to destroy the world, and in the second half you realize it's a depressed person trying to destroy themselves; it just takes everything about action movies and turns it into something more personal.""[8]
The film engages textually and metatextually with the ""real world"" of the viewer.[27][28] Critics have noted that one version of Evelyn—a famous martial arts movie star—is a portrayal of Yeoh herself,[28][5][29] that Ke Huy Quan's experience as a stunt coordinator is used diegetically in Waymond's fight scenes,[30] and that James Hong's transformation into ""a more sinister, English-fluent, Machiavellian strategist"" parallels his character Lo Pan in Big Trouble in Little China (1986).[27][31]
Music[edit]
The musical score was composed by Son Lux, whose members are Ryan Lott, Ian Chang, and Rafiq Bhatia.[32] Daniels asked them to approach the score individually, and not as a band. Lott said, ""I think that the complete picture of not only who we are as a band, but also who we are as individuals and what we have accomplished and the places we've gone creatively individually, meant for them that there was a possibility that many of these universes of sound could be within reach with this particular trio"".[33]
Son Lux took two to three years to compose the score, which includes more than 100 musical cues.[34] The soundtrack album has 49 pieces and runs for more than two hours. It features several prominent musicians,[35] including Mitski, David Byrne, a flute-playing André 3000, Randy Newman, Moses Sumney, and yMusic.[36][11] Two songs—""This Is a Life"" featuring Mitski and Byrne[37] and ""Fence"" featuring Sumney—were released as singles on March 4 and 14, 2022.[38] The album was released on March 25 to positive critical response.[39][40]
Release[edit]
Theatrical[edit]
Everything Everywhere All at Once had its world premiere at the South by Southwest film festival on March 11, 2022.[41] It had a limited release in theaters on March 25, 2022,[42] followed by a nationwide release on April 8, in the United States by A24.[43] On March 30, 2022, the film was released in select IMAX theaters in the U.S. for one night only. Due to the popularity of the film, it returned to select IMAX theaters for one week starting on April 29, 2022.[44][45] The film was not released in most parts of the Middle East including Saudi Arabia and Kuwait due to censorship of LGBT issues in those countries.[46] The film was released in the United Kingdom on May 13, 2022.[47] The film was scheduled to be re-released in US theaters on July 29, 2022, unchanged but adding an introduction by the Daniels and eight minutes of outtakes after the credits.[48][49]
Home media[edit]
The film was released on digital streaming platforms on June 7, 2022, and was released on Blu-ray, DVD, and Ultra HD Blu-ray on July 5, 2022, by Lionsgate Home Entertainment.[50][51]
Reception[edit]
Box office[edit]
As of October 3, 2022[update], Everything Everywhere All at Once had grossed $70 million in the United States and Canada, and $30.7 million in other territories, for a worldwide total of $100.7 million.[3][4]
In the United States and Canada, it earned $509,600 from ten venues in its opening weekend. Its debut had a theater average of $50,965, the second-best since the start of the COVID-19 pandemic for a platform release (behind Licorice Pizza), and the then-best opening theater average in 2022.[52] In its second weekend, the film grossed $1.1 million from 38 theaters, finishing ninth at the box office.[53] It received a wide expansion in its third weekend, going from 38 to 1,250 theaters.[54][55] It made $6.1 million, finishing sixth at the box office.[56][57] Playing in 2,220 theaters the following weekend, it earned $6.2 million, finishing fourth.[58] In its sixth weekend, it added $5.5 million, part of which was attributed to a wider IMAX release following its successful box office run up to that point.[21] It added $3.5 million in its seventh weekend,[59] and another $3.3 million in its eighth.[60] By May 21 it had made over $51 million, surpassing Uncut Gems ($50 million) as A24's highest-grossing film domestically.[61] By June 9 it had made over $80 million, surpassing Hereditary ($79 million) as A24's highest-grossing film of all time.[62] It remained in the box office top ten before dropping out in its sixteenth weekend (ending on July 10).[63] On July 31, the film crossed the $100 million mark worldwide, the first independent film of the pandemic and in A24's history to do so.[64]
Outside of the U.S., other top-earning territories as of July 31 were: the United Kingdom ($6.2 million), Canada ($5.1 million), Australia ($4.5 million), Russia ($2.4 million), Taiwan ($2.3 million), Mexico ($2 million), Hong Kong ($1.7 million), Germany ($1.5 million), and the Netherlands ($1.1 million).[64]
Critical response[edit]
On the review aggregator website Rotten Tomatoes, the film has an approval rating of 95% based on 344 reviews, with an average rating of 8.6/10. The website's consensus reads, ""Led by an outstanding Michelle Yeoh, Everything Everywhere All at Once lives up to its title with an expertly calibrated assault on the senses.""[65] On August 26, 2022, Rotten Tomatoes users voted Everything Everywhere All At Once as ""A24's Best Film of All Time"" in their A24 Showdown.[66] Metacritic, which uses a weighted average, assigned the film a score of 81 out of 100, based on 54 critics, indicating ""universal acclaim"".[67] Audiences polled by PostTrak gave it an 89% positive score, with 77% saying they would definitely recommend it.[56]
David Ehrlich of IndieWire called it an ""orgiastic work of slaphappy genius"", praising the direction and performances, particularly Yeoh's.[68] The Hollywood Reporter's David Rooney called it a ""frenetically plotted serve of stoner heaven [that] is insanely imaginative and often a lot of fun"", complimenting the cast and score but found the handling of the story's underlying theme underwhelming.[69] In her review for RogerEbert.com, Marya E. Gates commended Yeoh's performance, writing ""Yeoh is the anchor of the film, given a role that showcases her wide range of talents, from her fine martial art skills to her superb comic timing to her ability to excavate endless depths of rich human emotion often just from a glance or a reaction.""[70] Charles Bramesco, writing for The Guardian, complimented the Daniels for constructing a ""large, elaborate, polished and detailed expression of a vision"".[24] Amy Nicholson of The Wall Street Journal wrote: ""Over its nearly two-and-a-half-hour running time, the movie's ambitions double, and double again, as though it's a petri dish teeming with Mr. Kwan and Mr. Scheinert's wildest ideas.""[7]
In her review for Vanity Fair, Maureen Ryan highlighted Yeoh's performance, writing ""Yeoh imbues Evelyn with moving shades of melancholy, regret, resolve and growing curiosity"" and adding she ""makes her embrace of lead-character energy positively gripping"".[71] Adam Nayman of The Ringer referred to the film as ""a love letter to Yeoh"" adding, ""Everything Everywhere All At Once is extremely poignant, giving its 59-year-old star a chance to flex unexpected acting muscles while revisiting the high-flying fight choreography that made her a global icon back in the 1990s.""[72] In his review for Chicago Sun-Times, Jake Coyle wrote that though Everything Everywhere ""can verge on overload, it's this liberating sense of limitless possibility that the movie leaves you filled with, both in its freewheeling anything-goes playfulness and in its surprisingly tender portrait of existential despair.""[73]
Dissenting reviews include those of Richard Brody for The New Yorker, who dismissed it as a ""sickly cynical feature-length directorial pitch reel for a Marvel movie"".[74] and Keith Garlington, who noted that while the film was an ambitious task, the film ""often gives way to overindulgence making this overlong and overstuffed genre stew a well-meaning but exhausting experience.""[75]
Letterboxd announced that it had briefly become the top rated film of all time on the site, surpassing The Godfather and Parasite.[76] As of September 2022[update], it still remains in the top 15.[77]
Accolades[edit]
|Award||Date of ceremony||Category||Recipient(s)||Result||Ref.|
|SXSW Film Festival||March 2022||Adobe Editing Award||Paul Rogers||Won||[78]|
|Hollywood Critics Association Midseason Film Awards||July 1, 2022||Best Picture||Everything Everywhere All at Once||Won||[79]|
|Best Director||Daniel Kwan and Daniel Scheinert||Won|
|Best Actress||Michelle Yeoh||Won|
|Best Supporting Actor||Ke Huy Quan||Won|
|Best Supporting Actress||Jamie Lee Curtis||Nominated|
|Stephanie Hsu||Won|
|Best Screenplay||Daniel Kwan and Daniel Scheinert||Won|
|Best Indie Film||Everything Everywhere All at Once||Won|
|Amanda Awards||August 20, 2022||Best Foreign Film||Won||[80]|
|Saturn Awards||October 25, 2022||Best Fantasy Film||Pending||[81]|
|Best Actress||Michelle Yeoh||Pending|
|Best Supporting Actor||Ke Huy Quan||Pending|
|Best Supporting Actress||Stephanie Hsu||Pending|
|Best Writing||Daniel Kwan and Daniel Scheinert||Pending|
|Best Editing||Paul Rogers||Pending|
|Best Production Design||Jason Kisvarday||Pending|
Notes[edit]
- ^ Chinese: ""maternal grandfather"" (see 公公)
- ^ A play on a type of bagel called an ""everything bagel"", which is baked with a large variety of toppings; in the film, the ""everything bagel"" is topped with ""literally everything""[7] in the multiverse and appears as a pulsating toroid singularity.[8]
References[edit]
- ^ ""Everything Everywhere All At Once"". BBFC.co.uk.
Cinema 140m 0s
- ^ Wiseman, Andreas (October 26, 2021). ""A24 Launches Sales On Michelle Yeoh Sci-Fi Everything Everywhere All At Once — AFM"". Deadline Hollywood. Retrieved April 2, 2022.
- ^ a b ""Everything Everywhere All at Once"". Box Office Mojo. IMDb. Retrieved October 7, 2022.
- ^ a b ""Everything Everywhere All at Once"". The Numbers. Nash Information Services, LLC. Retrieved October 3, 2022.
- ^ a b ""How Michelle Yeoh Took Jackie Chan's Role"". The New York Times. April 12, 2022. Retrieved May 3, 2022.
- ^ a b Bergeson, Samantha (March 15, 2022). ""Michelle Yeoh's Role in 'Everything Everywhere All at Once' Was Originally Written for Jackie Chan"". IndieWire. Retrieved April 11, 2022.
- ^ a b Nicholson, Amy (March 24, 2022). ""'Everything Everywhere All at Once' Review: A Maximal Take on the Absurd"". The Wall Street Journal. Retrieved April 17, 2022.
- ^ a b c d e f g h i j Lee, Chris (April 13, 2022). ""Daniels Unpack the Everything Bagel of Influences Behind Everything Everywhere All at Once"". Vulture. Retrieved April 17, 2022.
- ^ Goh, Clement (April 14, 2022). ""Everything Everywhere All At Once (2022) Review"". CGMagazine. Retrieved April 23, 2022.
- ^ Lussier, Germain (May 4, 2022). ""Everything Everywhere All at Once Will Change a Problematic Credit for Its Digital Release"". Gizmodo. Retrieved May 5, 2022.
- ^ a b Krol, Charlotte (February 24, 2022). ""André 3000, Mitski and more to feature on 'Everything Everywhere All At Once' soundtrack"". NME. Retrieved April 10, 2022.
- ^ Robinson, Tasha (April 9, 2022). ""The best Easter egg in Everything Everywhere All At Once is a secret director's cameo"". Polygon. Retrieved May 14, 2022.
- ^ Pasternack, Alex (April 7, 2022). ""'Everything Everywhere All at Once' is a mesmerizing ode to our chaos"". Fast Company. Retrieved April 11, 2022.
- ^ Smart, Jack (April 13, 2022). ""Michelle Yeoh on the roller coaster ride of Everything Everywhere All At Once"". The A.V. Club. Retrieved April 17, 2022.
- ^ a b Radulovic, Petrana (April 11, 2022). ""Michelle Yeoh's personal guide to Everything Everywhere All At Once's vast multiverse"". Polygon. Retrieved April 17, 2022.
- ^ Galuppo, Mia (August 30, 2018). ""Michelle Yeoh, Awkwafina in Talks for Film From 'Swiss Army Man' Directors"". The Hollywood Reporter. Retrieved August 30, 2018.
- ^ Collis, Clark (February 24, 2022). ""Whatever happened to Short Round? Ke Huy Quan returns to the big screen"". Entertainment Weekly. Retrieved February 25, 2022.
- ^ A24 Reunites With 'Swiss Army Man' Directors; Finance & Distribute AGBO's 'Everything Everywhere All At Once'
- ^ Fleming, Mike Jr. (January 22, 2020). ""A24 Reunites With 'Swiss Army Man' Directors; Finance & Distribute AGBO's 'Everything Everywhere All At Once'"". Deadline Hollywood. Retrieved January 22, 2020.
- ^ D'Alessandro, Anthony (April 21, 2022). ""'Everything Everywhere All At Once' Crosses $20M & Puts Arthouses Back On The Rails As Daniels' Pic Looks To Become 4th-Highest For A24"". Deadline. Retrieved April 23, 2022.
- ^ a b Rubin, Rebecca (May 1, 2022). ""A24's Everything Everywhere All at Once Hits Impressive Box Office Milestone"". Variety. Retrieved May 1, 2022.
- ^ ""Everything Everywhere All At Once Easter Eggs & References"". ScreenRant. April 9, 2022. Retrieved May 9, 2022.
- ^ Scott, A. O. (March 24, 2022). ""'Everything Everywhere All at Once' Review: It's Messy, and Glorious"". The New York Times. Archived from the original on April 18, 2022. Retrieved April 18, 2022.
- ^ a b Bramesco, Charles (March 22, 2022). ""Everything Everywhere All At Once review – ambitious, exhausting trip to the multiverse"". The Guardian. Retrieved April 8, 2022.
- ^ Cheng, Anne Anlin (May 4, 2022). ""'Everything Everywhere All at Once' is a deeply Asian American film"". Washington Post. Retrieved June 6, 2022.
- ^ a b Worthington, Clint (March 24, 2022). ""Everything Everywhere All At Once Is A Lot, and That's a Good Thing: Review"". Consequence. Retrieved April 17, 2022.
- ^ a b ""Everything Everywhere All at Once"". Encyclopedia of Science Fiction. Retrieved May 3, 2022.
- ^ a b Fear, David (April 7, 2022). ""Michelle Yeoh Conquers the Universe(s)"". Rolling Stone. Retrieved May 3, 2022.
- ^ Nayman, Adam (March 28, 2022). ""It's Right There in the Title"". The Ringer. Retrieved May 3, 2022.
- ^ Ito, Robert (April 5, 2022). ""Ke Huy Quan: From Short Round to Romantic Lead in Just Four Long Decades"". The New York Times. Retrieved May 3, 2022.
- ^ Radulovic, Petrana (April 7, 2022). ""The one role out of more than 500 that's stuck with James Hong"". Polygon. Retrieved May 3, 2022.
- ^ ""Son Lux Scoring Daniel Kwan's & Daniel Scheinert's Everything Everywhere All at Once"". Film Music Reporter. January 3, 2022. Retrieved January 6, 2022.
- ^ ""How Son Lux Crafted the Eclectic and Expansive Score for 'Everything Everywhere All At Once'"". Consequence. April 7, 2022. Retrieved May 22, 2022.
- ^ Giroux, Jack (April 8, 2022). ""Everything Everywhere All At Once Composers Son Lux On Their Epic, 49-Track Score [Interview]"". SlashFilm.com. Retrieved May 22, 2022.
- ^ ""Moses Sumney, Son Lux collaborate on new single 'Fence' for A24's 'Everything Everywhere All At Once'"". Indie88. March 22, 2022. Retrieved May 22, 2022.
- ^ Hatfield, Amanda (February 23, 2022). ""Mitski, David Byrne, Andre 3000 & more feature on Son Lux's Everything Everywhere All at Once score"". BrooklynVegan. Retrieved February 23, 2022.
- ^ ""Everything Everywhere All at Once Release the 1st Single of the Film's Spellbinding Soundtrack"". The Illuminerdi. March 4, 2022. Retrieved May 22, 2022.
- ^ ""Mitski, David Byrne Lead Colossal 'Everything Everywhere All at Once' Soundtrack With 'This Is a Life'"". Rolling Stone. March 4, 2022. Retrieved May 22, 2022.
- ^ ""Everything Everywhere All at Once (Original Motion Picture Soundtrack)"". Amazon.com. Retrieved April 17, 2022.
- ^ Dutta, Debopriyaa (March 25, 2022). ""The Everything Everywhere All At Once Soundtrack Is Streaming Now For Your Multiversal Needs"". SlashFilm.com. Retrieved May 22, 2022.
- ^ Grobar, Matt (December 8, 2021). ""'Everything Everywhere All At Once': SXSW Sets Daniel Kwan and Daniel Scheinert's A24 Pic As Opening Night Film"". Deadline. Retrieved December 8, 2021.
{{cite web}}: CS1 maint: url-status (link)
- ^ Gerber, Jamie (December 17, 2021). ""Everything Everywhere All At Once: Release Date, Cast, And More"". /Film. Retrieved January 1, 2022.
- ^ Goldsmith, Jill (March 27, 2022). ""'Everything Everywhere All Once' Blasts Off With Record Opening For A24 – Specialty Box Office"". Deadline. Deadline Hollywood. Retrieved April 14, 2022.
- ^ ""The expansive Everything Everywhere All at Once is coming back to IMAX"". The A.V. Club. April 29, 2022.
- ^ ""Friday Box Office: 'Everything, Everywhere' Drops 0%, Tops $30 Million"". Forbes.
- ^ Wiseman, Andreas (May 5, 2022). ""'Everything Everywhere All At Once'…Except In Parts Of The Middle East Where The Movie Has Been Banned"". Deadline. Retrieved May 8, 2022.
- ^ Stolworthy, Jacob (April 19, 2022). ""The best-reviewed film of 2022 so far finally gets UK release date"". The Independent. Retrieved May 10, 2022.
- ^ D'Alessandro, Anthony (July 20, 2022). ""Everything Everywhere All At Once Getting Theatrical Re-Release With Eight Extra Minutes"". Deadline Hollywood. Retrieved July 20, 2022.
- ^ ""Back in 800 U.S. theaters next weekend! It's pretty fun in a theater. Just be clear: it's the same movie. Same edit. But if you stay through the credits y'all get some good old fashioned bloopers and outtakes like a classic Hong Kong flick"". Twitter. May 20, 2022. Retrieved July 25, 2022.
- ^ Everything Everywhere All At Once on iTunes, April 8, 2022, retrieved May 17, 2022
- ^ ""Everything Everywhere All at Once Blu-ray"". Blu-ray. Retrieved May 11, 2022.
- ^ D'Alessandro, Anthony (March 27, 2022). ""The Lost City Seeing Record Pandemic Opening For Female Driven Comedy With $31M"". Deadline Hollywood. Retrieved March 27, 2022.
- ^ ""Domestic 2022 Weekend 13"". Box Office Mojo. Retrieved April 5, 2022.
- ^ D'Alessandro, Anthony (April 6, 2022). ""Sonic The Hedgehog 2 To Keep Spring Thing Going With $50M+ Start – Box Office Preview"". Deadline Hollywood. Retrieved April 6, 2022.
- ^ Robbins, Shawn (April 6, 2022). ""Weekend Box Office Forecast: Sonic the Hedgehog 2 May Break Out as Ambulance and Everything Everywhere All at Once Counter-Program"". Boxoffice Pro. Retrieved April 6, 2022.
- ^ a b D'Alessandro, Anthony (April 10, 2022). ""Sonic The Hedgehog 2 Beats Weekend Opening Of First Movie With $71M; What Ambulance Misfire Means For Action Pics Today – Sunday AM Box Office Update"". Deadline Hollywood. Retrieved April 10, 2022.
- ^ ""Domestic 2022 Weekend 14"". Box Office Mojo. Retrieved April 12, 2022.
- ^ ""Domestic 2022 Weekend 15"". Box Office Mojo. Retrieved April 19, 2022.
- ^ ""Domestic 2022 Weekend 18"". Box Office Mojo. Retrieved May 10, 2022.
- ^ ""Domestic 2022 Weekend 19"". Box Office Mojo. Retrieved May 17, 2022.
- ^ D'Alessandro, Anthony (May 20, 2022). ""'Everything Everywhere All At Once' Knocking Out 'Uncut Gems' To Become A24's Highest Grossing Movie Ever At Domestic Box Office With $50M+"". Deadline. Retrieved May 21, 2022.
- ^ D'Alessandro, Anthony (June 10, 2022). ""'Everything Everywhere All At Once' Becomes A24's Highest Grossing Movie Of All-Time At Global Box Office"". Deadline. Retrieved June 10, 2022.
- ^ ""Everything Everywhere All at Once: Domestic Weekend"". Box Office Mojo. Retrieved July 6, 2022.
- ^ a b Rubin, Rebecca (July 31, 2022). ""'Everything Everywhere All at Once' Is A24's First Movie to Hit $100 Million Globally"". Variety. Retrieved July 31, 2022.
- ^ ""Everything Everywhere All at Once"". Rotten Tomatoes. Fandango Media. Retrieved July 10, 2022.
- ^ ""EVERYTHING EVERYWHERE ALL AT ONCE WINS THE A24 SHOWDOWN"". rottentomatoes.com. Retrieved August 26, 2022.
- ^ ""Everything Everywhere All at Once Reviews"". Metacritic. Red Ventures. Retrieved June 3, 2022.
- ^ Ehrlich, David (March 12, 2022). ""'Everything Everywhere All at Once' Review: 'The Matrix' Meets the Multiverse in Daniels' Instant Classic"". IndieWire. Retrieved April 8, 2022.
- ^ Rooney, David (March 12, 2022). ""Michelle Yeoh in 'Everything Everywhere All at Once': Film Review | SXSW 2022"". The Hollywood Reporter. Retrieved April 8, 2022.
- ^ Gates, Marya E. (March 12, 2022). ""Everything Everywhere All at Once movie review (2022)"". RogerEbert.com. Retrieved April 8, 2022.
- ^ ""Ambitious, Outrageous 'Everything Everywhere All at Once' Is All That and More"". Vanity Fair. April 8, 2022. Retrieved April 10, 2022.
- ^ Nayman, Adam (March 28, 2022). ""'Everything Everywhere All at Once' Fulfills the Promise of Its Title"". The Ringer. Retrieved April 10, 2022.
- ^ ""'Everything Everywhere All at Once' a playful skip through the multiverses of hot-dog fingers and cooking raccoons"". Chicago Sun-Times. March 30, 2022. Retrieved April 10, 2022.
- ^ Brody, Richard (2022-03-24). ""'Everything Everywhere All at Once,' Reviewed: There's No There There."" The New Yorker. Retrieved 2022-08-16.
- ^ Garlington, Jeff (April 20, 2022). ""REVIEW: ""Everything Everywhere All at Once"" (2022)"". Keithand themovies. keithandthemovies.com. Retrieved September 11, 2022.
- ^ Gracewood, Gemma (April 5, 2022). ""Everything Everywhere All at Once—Including the Number One Spot on Letterboxd"". letterboxd.com. Retrieved June 14, 2022.
- ^ Vis, Dave. ""Official Top 250 Narrative Feature Films"". letterboxd.com. Archived from the original on July 7, 2022. Retrieved July 7, 2022.
- ^ ""SXSW Film Awards"". SXSW. Retrieved July 5, 2022.
- ^ ""5th Annual Hollywood Critics Association Midseason Awards Nominations Include X and THE BLACK PHONE"". Daily Dead. June 29, 2022. Retrieved July 1, 2022.
- ^ Balaga, Marta (August 21, 2022). ""'The Worst Person in the World' Emerges as Simply the Best at Norway's Amanda Awards"". Variety. Retrieved August 24, 2022.
- ^ Tinoco, Armando (June 29, 2022). ""Saturn Awards Nominations: 'The Batman', 'Nightmare Alley', 'Spider-Man', 'Better Call Saul' Top List"". Deadline. Retrieved August 12, 2022.
External links[edit]
- Official website
- Everything Everywhere All at Once at IMDb
- Quotations related to Everything Everywhere All at Once at Wikiquote
- 2022 films
- 2022 LGBT-related films
- 2022 science fiction films
- 2020s action comedy-drama films
- 2020s American films
- 2020s Cantonese-language films
- 2020s English-language films
- 2020s Mandarin-language films
- 2020s martial arts comedy films
- 2020s science fiction comedy-drama films
- 2022 action comedy films
- 2022 black comedy films
- Absurdist fiction
- Alternate timeline films
- American action comedy-drama films
- American black comedy films
- American martial arts comedy films
- American science fiction comedy-drama films
- Asian-American comedy films
- Chinese-American LGBT-related films
- Lesbian-related films
- LGBT-related black comedy films
- LGBT-related science fiction comedy-drama films
- Magic realism films
- Metafictional works
- Metaphysical fiction films
- Midlife crisis films
- Films about mother–daughter relationships
- Films about parallel universes
- Films about parenting
- Films set in offices
- Films set in California
- Films shot in Los Angeles
- A24 (company) films",8
302,"We use necessary cookies to make our site work. We also set performance and functionality cookies that help us make improvements by measuring traffic on our site. For more detailed information about the cookies we use, please see our privacy policy.
✖
20220810
“The marketplace as it exists and operates today depends entirely on the invisibility of the consequences of production and manufacturing, often located on distant landscapes. Making these consequences visible again and rethinking the supply chain is going to be one of the great challenge of the 21st century.”
Interesting: Who owns Tesla data? Car data collectors. CNIL killing Google. Instagram payments. Expired credit card bricks HP printer.
Non-Extractive Architecture.
Trees vs rhizomes - from plants root systems drawings. Botanists shortages. Building an open-source business, 101 part 1. Human books. Framed, positive deviants are welcome. Alexa as voice necromancer. Marrying oneself.
SaSS - Service as a Software Substitute - a Stallman take.
Futures gazing - toolkit for gazing into the next 20 years. Focused attention - 1 hour per week. Copper crisis ahead. Chips crisis means chips-recycling robots.
Others: new ultrasound patches. Python 101: nice maps. CH569 MCU and fast USB3.
Playing: got access to DALL·E 2.
Consumed: Holidays = rest! Sandman, on netflix. Books - Echopraxia (interesting takes on bicameral minds, consciousness, ..) la nuit du faune.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.",2
303,nytimes.comPlease enable JS and disable any ad blocker,9
304,"Food and Fertilizer Export Restrictions Tracker
Outline
Reports and Data
Laborde D. & Mamun A. (2022). Food Export restrictions during the Ukraine-Russia crisis
Who we are
Suggested citation:
Laborde, David, Abdullah Mamun, and Marie Parent. 2020. COVID-19 Food Trade Policy Tracker [dataset]. Washington, DC: International Food Policy Research Institute (IFPRI).
Food export restrictions are once again a concern as food prices rise even higher. This behavior can have dire unintended consequences for vulnerable people in food-importing countries, increasing prices and exacerbating issues of food insecurity already inflamed by the COVID-19 pandemic.
IFPRI started tracking food export restrictions and documenting their impacts following the onset of COVID-19 lockdowns and some national governments moving to restrict food exports. With the intensifying conflict in Ukraine on top of supply chain disruptions, food and fertilizer prices are surging, and monitoring food export restrictions is again important.
The Food and Fertilizer Export Restrictions Tracker allows you to track these policies for food products and fertilizers. The impacts of export restrictions around the world are shown as a percentage of each country’s imported calories that are impacted by export restrictions. The tracker can also be used to compare the current situation to the 2007-08 food price crisis. Check out these and other features in the tracker below.
Recent developments
August and September 2022
Our export restriction tracker continues monitoring food and fertilizer trade policies by the countries. According to our data there are couple of export restrictions withdrawn in the month of August and September. Several new restrictions have come into place during this time.
In August and September 2022, we see Kazakhstan ended ban of sunflower seeds, wheat and wheat flour, and Malaysia withdrawn export ban of live chicken and chicken meat.
On 8 September 2022, India first imposed export tax as the country seeks to secure domestic supplies of the food grain after planting shrank due to lack of adequate rains. Un-milled rice and husked brown rice will attract an export levy of 20% with effect from Sept. 9. Semi-milled or wholly milled rice, other than parboiled and basmati rice, will also attract a duty of 20%. On the same day, India also banned export of broken rice.
With this development, now the share of traded calories that are restricted due to ban or licensing has reduced to 7.2% in September 2022, a slight increase by 0.4 percentage points from July 2022. The increase is largely due to new restrictive measures taken by India.
July 2022
Our export restriction tracker continues monitoring food and fertilizer trade policies by the countries. According to our data there are couple of export restrictions withdrawn in the month of July. Two new restrictions have come into effective. In July 2022 we see Turkey withdrawn banning export of oil, Georgia on wheat and barley, and Kazakhstan on live cattle. On 18 July 2022, Indonesia set its July crude palm oil reference price at $1615.83 per ton. The July reference price would place the export levy and export tax at a maximum $200 per ton and $288 per ton respectively. On the other hand, new restrictions have been put in place by Bangladesh and India. Bangladesh has banned exporting rice until end of the year, while India has restricted exporting wheat flour from 12 July 2022. Please note that India earlier imposed export restrictions on wheat grain, effective from 13 May 2022, which is still in place. With this development, now the share of traded calories that are restricted due to ban or licensing has reduced to 6.84% in July 2022, a decline by around 4 percentage points from June 2022. The decline is largely due to ending of export tax and ban by Indonesia, Kazakhstan, and Turkey.
June 2022
Our food and fertilizer export restriction tracker is updated when a country put restrictions on items that they export globally. We also keep tracking of the countries that announce lifting of ban or where the end date of export restriction comes to an end or expired.
According to the latest news, Indonesia decided to lift export ban of palm oil on May 19, 2022, which came into effective from May 23, 2022. However, the country has reimposed a domestic market obligation (DMO) on palm oil to ensure 10 million tons of palm oil remains at home. Other notable countries where end date of their restriction has expired recently include Kazakhstan, Hungary, Morocco and Moldova.
On the other hand, India has put export ban of wheat and sugar on May 13, 2022. Though India’s share of wheat export in global trade in 2020-21 was small, this has come as a shock to importers who were expecting to import wheat from the country as the large sources of the grain – Russia and Ukraine – are now blocked.
With this development, now the share of traded calories that are restricted due to ban or licensing has reduced to 10.6% in May 2022, a decline by around 6 percentage points from April 2022. The decline is largely due to ending of export ban by Indonesia and Kazakhstan.
The Tool: Food and Fertilizer Export Restrictions Tracker
Data
The data is available in csv format here. The Food Export Restrictions Tracker data is made available under the Open Data Commons Attribution License.
The Food Export Restrictions Tracker provides daily updated information on export restrictions affecting international food trade. Our export restriction data comes from a variety of sources, originating primarily from news articles that are then verified with official government sources. We supplement with other data sets to create impact indicators for the export restrictions. We have also constructed a data set from the 2007-2008 world food price crisis for comparison.
To learn more about the tracker data, please see our working paper. As the project evolves, we will update the working paper, so please check back for the latest version.
The Food Export Restrictions Tracker is licensed under a Creative Commons Attribution 4.0 International License.",8
305,"Get our latest essays, archival selections, reading lists, and exclusive content delivered straight to your inbox.
War Virtually: The Quest to Automate Conflict, Militarize Data, and Predict the Future
Roberto González
University of California Press, $29.95 (cloth)
The Listeners: A History of Wiretapping in the United States
Brian Hochman
Harvard University Press, $35 (cloth)
Fictional spy stories tend to follow a formula. Within the first few pages the protagonist is assigned a mission by an espionage agency or covert military unit. The mission is impossible for just anyone to carry out, requiring access to high-tech weaponry, disposable income, and combat training out of reach for most readers. (This is part of the thrill.) After a few hundred pages, much bloodshed, and byzantine plot twists, the protagonist will have gathered enough intelligence—and killed the right people—to defuse a bomb or sabotage a hit team. When the protagonist succeeds, the story ends.
Real-life spy stories are not so thrilling, much less as cut and dry. These days automated systems have replaced secret agents. The protagonists of state-sanctioned surveillance are cybersecurity experts hacking into smart phones’ operating systems from a suburban office park, Microsoft engineers refining a biometric camera’s algorithm from their home office, and plain-clothes soldiers parsing through geolocation data for someone else to carry out a drone strike. Most of the people involved are not called agents or spies. They are product managers, engineers, data analysts, or “intelligence researchers.” Often their work feels so ordinary they might forget they are in the business of espionage. Sometimes they might not even realize it to begin with.
Two recent books—Brian Hochman’s The Listeners: A History of Wiretapping in the United States and Roberto González’s War Virtually: The Quest to Automate Conflict, Militarize Data, and Predict the Future—join a cascade of new titles on the genealogy, impact, and future of contemporary surveillance regimes. Hochman and González set themselves apart by moving away from the usual protagonists: amoral CEOs selling spyware to dictators or sinister government agencies monopolizing power. Instead, both authors are concerned with the regular people whose ordinary aspirations drive the expansion of surveillance. These carefully researched books focus on petty criminals who spy on the state, social scientists who think robots will redeem civilization’s shortcomings, and data analysts seduced by the high salaries of Silicon Valley. By telling their stories, Hochman and González shows how surveillance thrives less on the machinations of evil men than on the pedestrian facts of political economy.
The Listeners tells the history of wiretapping in the United States through ordinary biographies. “Wherever possible, this book is centered on people,” Hochman writes in the introduction. “In part, this is to counteract the long-standing tendency in surveillance studies to grant extraordinary agency to agencies”—the National Security Agency, the Federal Bureau of Investigation, and the Central Intelligence Agency. Instead he looks to the lives of regular criminals, businessmen, spies, and innovators. His story begins with D. C. Williams, an infamous Californian convict. Williams was thrown in jail for intercepting corporate communication, selling the information to stock traders, and amassing millions via illicit espionage. Williams may sound like the cybercriminals of today, who regularly hack into corporate servers and defraud financial markets, but he was actually the first person to be convicted of intercepting electronic messages in America: “The year—and here’s the twist to the story—was 1864.”
The Listeners resurrects figures like Williams in order to underscore that “surveillance is, and always has been a constitutive element of our communications ecosystem.” Wiretappers arrived on the scene around the Civil War, with soldiers tapping into electric cables as soon as they began transmitting wartime communication. Electronic listening spread from military campaigns to criminal pursuits and then to the arsenal of local law enforcement. In 1895, around the time municipal telephone companies established networks in New York City, mob bosses and police forces rented out vacant offices to set up eavesdropping nests. They paid a host of freelance listeners to sit hunched over telephone receivers, listening in on private phone calls across the city. Many received special technical training in signal intelligence during their time in the army and were eager to cash in on their skills.
The early wiretapping efforts of state agents and criminals, Hochman emphasizes, were piecemeal, experimental, and usually not quite illegal. The Supreme Court would not rule on the legality of warrantless wiretapping until 1928, even as electronic espionage became widespread in the first few decades of the twentieth century. Police often outsourced surveillance to private firms that were better at acting criminal. Men like William Burns, a U.S. secret agent turned private detective, sold high-tech espionage services to the highest bidder. Akin to contemporary boutique surveillance firms, Burns marketed new technologies—operated by elite teams of professional listeners stowed away in makeshift offices across major cities—to law enforcement agencies and private citizens alike. His firm solved a cascade of high-profile cases throughout the country, plastering headlines with news of their cutting-edge spy tools. Burns also made the public privy to novel surveillance tech by writing and directing a number of plays that revolved around the themes of privacy and espionage. By the time the Supreme Court limited law enforcement’s right to tap into phone lines or intercept telegraphs, the right to privacy was a matter of much public contention. So began a century of legal debates in a new age of networked communications.
Slowly and surely, Hochman reveals, other government agencies took up wiretapping. During World War II military scientists invented the transistor, a semiconductor device that paved the way for miniature recording devices smaller than sugar cubes and thinner than postage stamps to flood espionage markets. In the 1950s the eavesdropping industry was growing exponentially, led by men who sold private detectives and the FBI fantastic new devices called “bugs.” Martini olives equipped with embedded microphones, cigarette boxes that double as covert listening machines, and mini recording gadgets hidden in picture frames. Popular news outlets lauded those churning out new spy technologies as “wondrous, almost godlike” while also warning of an “American bugging epidemic” that threatened individual privacy.
Today we have new words for eavesdropping over new mediums. Encrypted messaging applications transmit conversations that can be “hacked,” “infected,” or “bugged” by advanced technologies named after Greek legends or Hollywood blockbusters: Pegasus, Phantom, and Predator. Private surveillance firms develop and market complex systems that can clandestinely transmit the entire contents of a smartphone to a distant server. Media outlets worldwide are tracking the spread of these technologies, used by governments against criminals, heads of state, journalists, and human rights defenders alike. Lately, both reporters and academics have warned that we have entered a new era of human history marked by pervasive surveillance.
The Listeners is most useful for reminding us of the striking parallels between past and present surveillance regimes. Take, for example, recent news surrounding the FBI’s dealings in contraband cyberweapons. In June 2019 three young Israeli computer engineers flew from Tel Aviv’s Ben Gurion Airport to New York City. According to the New York Times, they were dispatched by the NSO Group to test the Israeli spyware firms’ new flagship product—Phantom—for the FBI. The warehouse in suburban New Jersey was perhaps a less exciting place for a sales pitch than their last business trips: most made a career traveling to fortified government buildings across North Africa, the Middle East, and Western Europe. Over the next few days the engineers hacked into spare phones FBI agents had purchased from local stores with the NSO Group’s trademark zero-click hacking tool. For a hefty price, the United States government could break into and transfer every single component of a smart phone’s operating system—encrypted chats, emails, audio, and video recordings—to a private server miles away.
Revelations of the FBI’s involvement with the NSO Group provoked a scandal. The start-up was blacklisted by the U.S. Department of Commerce in 2021, barred from doing business with U.S based entities, and sued for millions by Meta and Apple; hundreds of employees have been laid off, and the group is now reportedly on the brink of bankruptcy. Yet the pattern is nothing new: as Hochman documents, the U.S. government has outsourced surveillance to military-trained technologists since the early twentieth century. Then, as now, government agencies struggled to keep up with the pace of technological development. The open floor plans and stocked mini-fridges of today’s offensive cybersecurity start-ups bear little resemblance to the listening-nests law enforcement officials set up in New York City office buildings, but their function is essentially the same. Both carry out extralegal espionage on behalf of government agencies that lack the technological infrastructure and people power to do so themselves. Instead of William Burns’s legendary “Detectifone,” we have the NSO Group’s Pegasus, the white-winged stallion of Greek legends.
Precedents do not make the present any less dire, of course. New surveillance technologies are consolidating state-corporate power at the expense of those already dispossessed by centuries of racial capitalism and colonial exploitation. Hochman underscores this legacy of racism in the final section of The Listeners. By the 1960s, Cold War anti-communism and anti-radicalism spurred the FBI, CIA, and law enforcement agencies across the country to embrace the wholesale surveillance of anti-imperialist and anti-racist activists. “Punitive ideas about policing and crime,” Hochman writes, “helped drive the normalization of wiretapping in America.” Once seen as a criminal endeavor, electronic espionage gradually became synonymous with keeping law and order, an imperative that stifled mainstream movements for a right to privacy. COINTELPRO gave way to the militarized policing of the War on Drugs, which transformed into today’s post-9/11 surveillance state.
Yet Hochman’s central point is that we should not describe today’s surveillance state as monolithic. The moral of The Listeners’s 150-year history is what Hochman calls the devastating “banality of electronic surveillance in America.” Espionage was and remains dependent on technologies so central to everyday life they appear mundane—and it has always hinged on the work of ordinary people who, for better or worse, often consider their labor anything but extraordinary. Today, high-tech surveillance perniciously extends state power precisely because so many of us are bound up in its mechanizations, whether we want to be or not.
Hannah Arendt made a similar point sixty years ago when she famously reported on the trial of Adolf Eichmann in Jerusalem, remarking on the “banality of evil.” The term has become a catch-all cliché in the decades since, and Hochman does not cite her, perhaps for fear of drawing false equivalencies between National Socialism and contemporary surveillance states. Yet Arendt’s insights into the mechanizations of violence are quite pertinent in the digital age. Often, she wrote, the most destructive regimes are sustained by “the administrative machinery” of men, those who, perhaps obstinately, “never realize” what they have done; lethal policies could be implemented by those simply showing up in an office and filing papers day after day.
In similar fashion, The Listeners helps us to see that much of the labor that goes into even the most destructive kinds of surveillance is mostly unremarkable. Military intelligence operatives often compare combing through geolocation data for determining drone strikes to working a desk job at any other civilian technology company. The NSO Group’s recently deposed CEO, Shalev Hulio, liked to describe selling surveillance weapons in more quotidian terms, as on par with managing a car dealership. “If Mercedes sells someone a car,” he told the Israeli news site Israel Hayom last summer, “then a drunk gets in the car, runs over someone, and kills him. Does anyone blame the Mercedes dealership?”
Perhaps this is why even the most scathing insider accounts of Silicon Valley—such as Anna Wiener’s Uncanny Valley (2020)—describe how white-collar workers built up surveillance capitalism in between free yoga classes and trips to well-stocked mini-fridges. Many laborers who spent a decade scraping personal data from smart phones and tracking users across online platforms viewed their work as any other service, one easily provided in exchange for generous benefits and high salaries.
In War Virtually, Gonzalez probes the aspirations of those at the heart of America’s militarized technology sectors: he does so to warn readers of a near future where dragnet surveillance and automated warfare erodes democracy and human life. González, a cultural anthropologist, scaffolds his analysis with character sketches of the social scientists, career generals, and Silicon Valley CEOs driving the development of virtual warfare. His six meticulously documented chapters underscore the reach of America’s war industries, spanning issues that have garnered significant press coverage, academic analysis, and public concern over the past two decades: the development of lethal autonomous weapons, militarized predictive modeling, high-tech psy-ops, and cyber warfare.
The book’s anthropological lens is valuable, but it is less novel than González makes it out to be: he fails to cite many ethnographers, historians, and journalists who have already provided robust and accessible analyses of these topics, from Darren Byler’s ethnographic account of digital dispossession in Xinxiang to Lorenzo Franceschi-Bicchierai’s investigative reporting on the consumer and government spyware industries. The claim to novelty is also undermined by the book’s clichéd narrative arc, according to which technological development is thrusting humankind into a dystopian future in which wars are waged by killer robots and AI bots run amok. “War 4.0 is upon us,” González warns. “Science fiction appears to be on the verge of becoming science fact.” A central assumption of War Virtually is that all things related to the military are to be distrusted, but the book never quite explains why. In-Q-Tel, the CIA’s investment arm named after the James Bond franchise, buys up start-ups specializing in everything from genetic sequencing to data mining. Psychology professors receive Pentagon funding to walk soldiers through trust exercises with robots deployed in combat. Hundreds of recently minted engineering PhDs employed by the Pentagon produce models capable of predicting social unrest and political instability anywhere in the world. These are important facts, but the precise stakes of these developments—binding the U.S. economy to the continuation of bloody wars waged abroad and militarized policing at home, for example—are never hashed out.
A more illuminating narrative arc emerges tacitly from González’s case studies. The book is most interesting when it is ethnographic, fleshing out the people driving the development of new technologies. One such character is Adam Russell, a Duke rugby star, anthropology major, Rhodes scholar, and researcher at the Defense Advanced Research Projects Agency (DARPA). In the early 2000s Russell wrote a dissertation at Oxford on masculinity, steroids, self-optimization, and weightlifting in southern England. A few years later he found himself penning research reports on biotechnology and performance enhancement among combat soldiers for the Pentagon. Russell quickly ascended the ranks of national security research, underscoring the necessity of qualitative research when assessing human and machine intelligence. By the late 2010s Russell was heading counterterror research units, feeding contextualized knowledge about specific cultures into big-data sets for future armed conflict.
Russell, González tells us, epitomizes the pivotal role scientists play in the automation of war. His dissertation is “insightful” and “unconventional,” demonstrating the utility of collecting vast quantities of sociocultural data to feed into predictive policing modeling and war simulations. Russell’s DARPA initiatives are also “shrewd,” exemplifying the “extreme reductionism” that flattens “ambiguous and elusive social constructs to simple variables that can be quantified and ultimately fed into computer models”—all supposedly for “the protection of the free world.” Russel stands in for the hundreds of other social scientists and engineers driving the expansion of dragnet surveillance—intercepting communications, mining social media feeds, parsing through drone footage—behind the closed doors of powerful institutions. They are all too easily seduced by “techno-optimism,” González says: the conviction that “scientific and technical innovations will eventually resolve complex social, economic, and environmental problems.”
Characters like Russell appear only partially developed in War Virtually, however; they rarely speak for themselves. González draws from an impressive number of interviews with military veterans, Silicon Valley engineers, and military researchers, yet the book includes few references to these conversations and even fewer direct quotes; when these figures do appear, they mainly serve as a literary device. Military researchers and corporate engineers are the malicious practitioners of new “dark arts,” González writes. They are embedded within “totalitarian institutions” bent on molding “the ideas, attitudes, and behaviors of audiences captured by their compulsions.” The risks posed by new technologies should not be understated, but their power should not be overstated, either. There is no black magic involved in the development of militarized surveillance technologies—just the expenditure of too many government resources that could be earmarked for combating climate change or universal health care.
The disjuncture between the technology industry’s breathless innocence and Silicon Valley’s long and well-documented ties to the military is striking. Yet blaming it all on misplaced techno-optimism distracts from the systems of exploitation and profit-making that shape ordinary people’s aspirations. Techno-optimism certainly pulses through corporate tech campuses, designed to make every employee feel limitless but also like they are making the world a better place. But most who spend years inside Silicon Valley recount how these early seductions—company mottos pledging to “do no evil,” kombucha on tap, and compost bins—mostly give way to an insidious lack of reflexivity amid almost excessive material extravagance. As Wiener has put it, the majority of tech workers are not going to the office every day thinking they are morally superior or saving the world. They are largely cashing in on six- or seven-figure salaries, buying up property, and enjoying existential stability in an era marked by financial, climatic, and political precarity. “It can be easy to lose oneself in a company, undergo a sort of identity transfer,” Wiener has said. “It’s very seductive.”
Recently, some tech workers seem to be regaining a critical reflexivity. Since the late 2010s headlines have announced Silicon Valley’s “political awakening,” and every few years demands are made that companies cancel lucrative contracts with militaries and police forces. In 2018, for example, Google engineers refused to develop a security tool for Project Maven, which supplied the U.S. military with AI-powered drone imagery technology. “We believe that Google should not be in the business of war,” they wrote in a petition that garnered thousands of signatures. Microsoft engineers condemned the sale of virtual reality headsets to the military for combat training just a year later, in 2019. “We did not sign up to develop weapons,” said those who spent years developing augmented reality technology. “And we demand a say in how our work is being used.” In 2021 dissent mounted across Google and Amazon when news surfaced of $1.2. billion agreement to supply Israel and its military with artificial intelligence tools and other computing services. Whistleblowers described the dehumanizing effects of technologies that could identify faces, movements, emotions, and even determine if someone is lying when deployed by an occupying army. As one Palestinian developer at Google recently put it to the New York Times, “Project Nimbus makes me feel like I am making my living off my family’s oppression.” There is growing awareness that one’s ethical commitments do not, and perhaps never did, cohere with the product of one’s labor.
Commentators say this realization was variously spurred by the ascendancy of Donald Trump in the United States, a public reckoning with how contemporary capitalism hinges on pervasive surveillance, and the stark human toll of militarized policing—from the United States to Palestine. Whatever it is, more and more employees are realizing that the salaries they enjoyed for years came with a dangerous kind of alienation. Dissent is now cutting through some of the most powerful companies in the world, where non-disclosure agreements and generous benefits have historically dissuaded critique.
It is important to keep asking how those within even the most cushioned corporate settings become compelled to take this kind of political action. The answers could bolster nascent movements for institutional and wide-reaching change. In less than a decade, technology workers have founded groups like Tech Workers Coalition, Stop Killer Robots, and the International Committee for Robot Arms Control. It is unlikely these organizations will singlehandedly bring about an end to automated warfare, pervasive surveillance, and punitive policing. But pragmatically speaking, such movements have made efforts to regulate artificial intelligence and new surveillance technologies mainstream in just a few years. The impact is so monumental that even War Virtually, with its pervasive tone of dystopia, cannot help but end on an optimistic note. “A relatively small but growing group of engineers, researchers, and scientists,” González reminds his readers by way of conclusion, “are pushing back against tech executives’ willingness to meet the Defense Department’s virtual warfare needs.”
They have predecessors worth recalling today. The dangers of a militarized technology sector have long been challenged by those who wind up developing potentially lethal systems. In the 1970s computer operators and engineers assembled under the banner of “Computer People for Peace” from New York to the Bay Area. Many had been radicalized by the anti-war movement and saw their labor as directly fueling the war in Vietnam. In response, they spearheaded “consciousness raising” among their reclusive colleagues, protested Honeywell Aerospace for developing bombs, and condemned the “corporate racism” of International Business Machine’s (IBM) dealings with apartheid South Africa. Critical accounts of Silicon Valley’s ascendance, including Fred Turner’s From Counterculture to Cyberculture (2006), demonstrate how neoliberal market reforms and the misplaced utopianism of the early digital age diluted this political consciousness. In this sense, the growing number of engineers, developers, and researchers protesting the business of militarism today is better framed as a political reawakening. Amplifying the narratives of those at the heart of these efforts can make a future of dragnet surveillance and automated warfare less inevitable. At the very least, it might compel others to follow in their footsteps.
Searing critiques of political violence are easier to stomach when the culprits are opaque institutions. It is more difficult to apprehend just how absurdly quotidian the business of surveillance is—and always has been. Perhaps this is because its impact remains extraordinary for those who have been subjected to decades of punitive policing or military occupation. The Israeli military deploys facial recognition technologies across Palestine that erode ordinary citizens’ last vestiges of privacy: women say cameras peer directly into homes and children report being misidentified and detained. Black Lives Matter protesters in New York and Minneapolis are thrown in jail after being tracked across social media feeds and through city streets by data scraping platforms and police drones. The repressive effects of new surveillance technologies are most pronounced for those already racialized as potential terrorists and criminals.
But combating these extraordinary impacts requires recognizing their very ordinary origins. Researchers at Carnegie Mellon partner with a biometric start-up, Oosto, whose cameras identify and monitor Palestinians in major cities and checkpoints across the occupied West Bank. Developers at Microsoft prototype the police drones which U.S. law enforcement use to surveil prominent protestors in the Movement for Black Lives. Some may be heartened to hear that technology giants and universities are committing to antiracist platforms and human rights–oriented agendas, banning the sale of certain facial recognition technology to U.S. police departments or suing boutique cyberespionage firms for hacking corporate servers. Yet these one-off efforts are largely cosmetic. The economic incentives that draw so many workers into the business of surveillance remain in place.
In their analysis of this stubborn fact, The Listeners and War Virtually remind us that the stories we tell about surveillance matter. It is tempting to blame our present of pervasive government espionage and automated warfare on a sinister surveillance state. The truth is more banal—and perhaps more difficult to face.
Sophia Goodfriend is a PhD student in cultural anthropology at Duke University. Her doctoral research, supported by the National Science Foundation, sits at the intersection of science and technology studies, surveillance studies, and digital rights. Her writing has also appeared in Foreign Policy, Jewish Currents, The Baffler, and Visual Anthropology Review. She tweets @sopgood.
Contributions from readers enable us to provide a public space, free and open, for the discussion of ideas. Join this effort – become a supporting reader today.
…we need your help. Confronting the many challenges of COVID-19—from the medical to the economic, the social to the political—demands all the moral and deliberative clarity we can muster. In Thinking in a Pandemic, we’ve organized the latest arguments from doctors and epidemiologists, philosophers and economists, legal scholars and historians, activists and citizens, as they think not just through this moment but beyond it. While much remains uncertain, Boston Review’s responsibility to public reason is sure. That’s why you’ll never see a paywall or ads. It also means that we rely on you, our readers, for support. If you like what you read here, pledge your contribution to keep it free for everyone by making a tax-deductible donation.
Vital reading on politics, literature, and more in your inbox. Sign up for our Weekly Newsletter, Monthly Roundup, and event notifications.
The celebrated novelist treated the past seriously, depicting its psychological complexity and drawing out its present-day political implications.
I was also spat across an ocean
and clung to the edge of an unwilling continent.
Feminist philosophers Kate Soper and Lynne Segal discuss the unsustainable obsession with economic growth and consider what it might look like if we all worked less.",1
306,"Blindsight (Watts novel)
|Author||Peter Watts|
|Cover artist||Thomas Pringle[1]|
|Country||Canada|
|Language||English|
|Genre||Hard science fiction|
|Publisher||Tor Books|
Publication date
|3 October 2006|
|Media type||Print (hardback)|
|Pages||384|
|ISBN||978-0-7653-1218-1|
|OCLC||64289149|
|813/.622|
|LC Class||PR9199.3.W386 B58 2006|
|Followed by||Echopraxia|
Blindsight is a hard science fiction novel by Canadian writer Peter Watts, published by Tor Books in 2006. It won the Seiun Award for best translated novel,[2] and was nominated for the Hugo Award for Best Novel,[3] the John W. Campbell Memorial Award for Best Science Fiction Novel,[4] and the Locus Award for Best Science Fiction Novel.[5] The novel follows a crew of astronauts sent out as the third wave, following two series of probes, to investigate a trans-Neptunian Kuiper belt comet dubbed ""Burns-Caulfield"" that has been found to be transmitting an unidentified radio signal to an as-yet unknown destination elsewhere in the Solar System, followed by their subsequent first contact. The novel explores themes of identity, consciousness, free will, artificial intelligence, neurology and game theory as well as evolution and biology.
Blindsight is available online under a Creative Commons license. Its sequel (or “sidequel”) Echopraxia came out in 2014.
Plot[edit]
In the year 2082, thousands of large, coordinated objects of an unknown origin, dubbed ""Fireflies"", burn up in the Earth's atmosphere in a precise grid, while momentarily broadcasting across an immense portion of the electromagnetic spectrum, catching humanity off guard and alerting it to an undeniable extraterrestrial presence. It is suspected that the entire planet has been surveyed in one effective sweep. Despite the magnitude of this ""Firefall"", human politics soon return to normal.
Years afterwards, a comet-surveying satellite stumbles across a radio transmission originating from a comet, subsequently named 'Burns-Caulfield'. This tight-beam broadcast is directed to an unknown location and in fact does not intersect the Earth at any point. As this is the first opportunity to learn more about the extraterrestrials, three waves of ships are sent out: the first being light probes shot out for an as-soon-as-possible flyby of the comet, then a wave of heavier but better-equipped probes, and finally a crewed ship, the Theseus.
Theseus is propelled by an antimatter reactor and captained by an artificial intelligence. It carries a crew of five cutting-edge transhuman hyper-specialists of whom one is a genetically reincarnated vampire who acts as the nominal mission commander. While the crew is in hibernation en route, the just-arrived second wave of probes commence a compounded radar scan of the subsurface of Burns-Caulfield, but this immediately causes the object to self-destruct. Theseus is re-routed mid-flight to the new-found destination of the signal: a previously undetected sub-brown dwarf deep in the Oort cloud, dubbed 'Big Ben'.
The crew wakes from hibernation while the Theseus closes on Big Ben. They discover a giant, concealed object in the vicinity, and assume it to be a vessel of some kind. As soon as the crew uncloaks the vessel, it immediately hails them over radio and, in a range of languages varying from English to Chinese, identifies itself as 'Rorschach'. They determine that Rorschach must have learned human languages by eavesdropping on comm-chatter since its arrival, sometime after the Broadcast Age began. Over the course of a few days many questions and answers are exchanged by both parties. Eventually Susan James, the linguist, determines that 'Rorschach' doesn't really understand what either party is actually saying.
Theseus probes Rorschach and finds it to have hollow sections, some with atmosphere, all filled with levels of radiation that render remote operation of machinery virtually impossible and would kill a human in a matter of hours. Despite this and over Rorschach's objections the whole crew except the mission commander enters and explores in a series of short forays, using the ship's advanced medical facilities to recover from the damage the radiation inflicts on their bodies. They discover the presence of highly evasive, fast-moving nine-legged organisms dubbed 'Scramblers', of which they kill one and capture two for study. The 'Scramblers' appear to have orders of magnitude more brainpower than human beings but use most of it simply to operate their fantastically complex musculature and sensory organs; they are more akin to something like white blood cells in a human body. They are dependent on the radiation and EM fields of Rorschach for basic biological functions and seem to completely lack consciousness.
The crew explore questions of identity, the nature, utility and interdependence of intelligence and consciousness. They theorize that humanity could be an unusual offshoot of evolution, wasting bodily and economic resources on the self-aware ego which has little value in terms of Darwinian fitness. Open warfare breaks out between the humans and the Scramblers and Theseus eventually decides to sacrifice itself and its crew using its antimatter payload to eliminate Rorschach. One crew member, the protagonist and narrator Siri Keeton, is shot off inside an escape vessel in a decades-long fall back to Earth to relay the crucial information amassed back to humanity. As he travels back towards the inner Solar System, he hears radio broadcasts which suggest that the vampires have revolted and may be exterminating baseline humanity.
Characters[edit]
Crew of the Theseus[edit]
- Siri Keeton is the narrator and protagonist. Debilitating brain surgery for medical purposes has cut him off from his own emotional life and made him a talented ""synthesist"", adept at reading others' intentions impartially with the aid of cybernetics. He is assigned to Theseus to interpret the actions of the specialized crew and report these activities to Mission Control on Earth. He comes to realize that the other crew members resent him for his role, seeing him as nosy surveillance.
- Major Amanda Bates is a combat specialist, controlling an army of robotic ""grunts"".
- Isaac Szpindel is the ship's primary biologist and physician. He is in love with Michelle, one of the Gang's personalities.
- Jukka Sarasti is a vampire and the crew's nominal (and frightening) leader. As a predator from the Pleistocene, he is alleged to be far smarter than baseline humans.
- The Gang are four distinct personalities in the mind of one woman, the ship's linguist. They are tasked with communicating with the aliens, if possible. A single personality ""surfaces"" to take control of their body at any given time. The active personality reveals itself through a change in tone and posture. These personalities express offence when referred to as ""alters"". The personalities are:
- Susan James, whom the others refer to as ""Mom"". She is the ""original"" personality.
- Michelle is a shy, quiet, synaesthetic woman who is romantically involved with Szpindel.
- Sascha is harsher and more overtly hostile towards Siri.
- Cruncher, a male, rarely surfaces and serves as an advanced data-processing facility for James.
- Robert Cunningham, Szpindel's backup, is a secondary biologist/physician.
- The Captain is the ship's artificial intelligence. Throughout the story, the Captain remains inscrutable and mysterious, generally communicating directly only with Sarasti.
People on Earth[edit]
- Robert Paglino, Siri's childhood best friend and a practical example of Siri's muted emotions: Siri cannot actually feel ""friendship"" following his brain surgery, but intellectually knows how he is expected to behave as a friend and continues to play the part.
- Chelsea, Siri's ex-girlfriend. A professional tweaker of human personalities.
- Helen Keeton, Siri's mother, whose consciousness has been connected, brain in a vat style, to a virtual utopia called ""Heaven"". As a parent, she traumatized Siri with emotional demands and intrusiveness into his private life.
- Jim Moore is Siri's father, a colonel involved with planetary defense.
Aliens[edit]
- Rorschach, an alien vessel or organism in low orbit around the sub-brown dwarf Big Ben. While it has a superhuman intelligence, it gradually becomes apparent that Rorschach completely lacks true consciousness or self-awareness.
- Scramblers, 9-legged anaerobic aliens that inhabit Rorschach and appear to be part of it in some sense. Like Rorschach, they are more intelligent than humans but not conscious or self-aware.
Major themes[edit]
Consciousness[edit]
The exploration of consciousness is the central thematic element of Blindsight.[6][7][8] The title of the novel refers to the condition blindsight, in which vision is non-functional in the conscious brain but remains useful to non-conscious action.[9] Other conditions, such as Cotard delusion and Anton–Babinski syndrome, are used to illustrate differences from the usual assumptions about conscious experience.[9] The novel raises questions about the essential character of consciousness. Is the interior experience of consciousness necessary, or is externally observed behavior the sole determining characteristic of conscious experience?[6][7][9] Is an interior emotional experience necessary for empathy, or is empathic behavior sufficient to possess empathy?[9][10] Relevant to these questions is a plot element near the climax of the story, in which the vampire captain is revealed to have been controlled by the ship's artificial intelligence for the entirety of the novel.[9][11]
Philosopher John Searle's Chinese room thought experiment is used as a metaphor to illustrate the tension between the notions of consciousness as an interior experience of understanding, as contrasted with consciousness as the emergent result of merely functional non-introspective components.[6][9][11] Blindsight contributes to this debate by implying that some aspects of consciousness are empirically detectable.[7] Specifically, the novel supposes that consciousness is necessary for both aesthetic appreciation[7][8][10] and for effective communication.[7] However, the possibility is raised that consciousness is, for humanity, an evolutionary dead end.[6][9][10][11] That is, consciousness may have been naturally selected as a solution for the challenges of a specific place in space and time, but will become a limitation as conditions change or competing intelligences are encountered.[7]
The alien creatures encountered by the crew of the Theseus themselves lack consciousness.[6][7][10][12] The necessity of consciousness for effective communication is illustrated by a passage from the novel in which the linguist realizes that the alien creatures can't be, in fact, conscious because of their lack of semantic understanding:
""Tell me more about your cousins,"" Rorschach sent.
""Our cousins lie about the family tree,"" Sascha replied, ""with nieces and nephews and Neanderthals. We do not like annoying cousins.""
""We'd like to know about this tree.""
Sascha muted the channel and gave us a look that said Could it be any more obvious? ""It couldn't have parsed that. There were three linguistic ambiguities in there. It just ignored them.""
""Well, it asked for clarification,"" Bates pointed out.
""It asked a follow-up question. Different thing entirely.""[13]
The notion that these aliens could lack consciousness and possess intelligence is linked to the idea that some humans could also have diminished consciousness and remain outwardly functional.[7][8] This idea is similar to the concept of philosophical zombie, as it is understood in philosophy of mind. Blindsight supposes that sociopaths might be a manifestation of this same phenomenon,[7][9] and the demands of corporate environments might be environmental factors causing some part of humanity to evolve toward becoming philosophical zombies.[7][10]
Transhumanism[edit]
Blindsight also explores the implications of a transhuman future.[7][11][12] Within the novel, humans no longer engage in sex with other humans for pleasure, instead choosing to use virtual reality to find idealized and submissive partners,[7] and many choose to withdraw from reality entirely by living in constructed virtual worlds, referred to as ""Heaven"".[7][11] Vampires are predators from humanity's distant past, resurrected through recovered DNA, and live among the humans of the late 21st century.[6][9][11][12] These vampires operate with diminished sentience presented as comparable to high-functional autism with comparable dysfunction in affect and speech, but have the advantage of multiple simultaneous thoughts occurring in parallel within their minds.[11] Enhanced pattern-matching skills comparable to some forms of autism combine with this ""hyperthreading"" to make them invaluable in developing unusual and often very effective approaches to solving complex problems.
Reception[edit]
Carl Hayes, in his review for Booklist, wrote: ""Watts packs in enough tantalizing ideas for a score of novels while spinning new twists on every cutting-edge motif from virtual reality to extraterrestrial biology.""[14] Kirkus Reviews said about the book: ""Watts carries several complications too many, but presents nonetheless a searching, disconcerting, challenging, sometimes piercing inquisition.""[15] Jackie Cassida in her review for Library Journal wrote: ""Watts continues to challenge readers with his imaginative plots and superb storytelling.""[16] Publishers Weekly wrote: ""Watts puts a terrifying and original spin on the familiar alien contact story.""[17]
Elizabeth Bear, an award-winning author in the science fiction field, declared:
It's my opinion that Peter Watts's Blindsight is the best hard science fiction novel of the first decade of this millennium – and I say that as someone who remains unconvinced of all the ramifications of its central argument. Watts is one of the crown princes of science fiction's most difficult subgenre: his work is rigorous, unsentimental, and full of the sort of brilliant little moments of synthesis that make a nerd's brain light up like a pinball machine. But he's also a poet – a damned fine writer on a sentence level...[18]
Adaptations[edit]
In October 2020 a Blindsight short film was released.[19] It is a non-commercial adaptation of the novel. As Peter Watts describes it himself: ""snatches of Blindsight recalled by Siri Keeton during one of his waking interludes in the aftermath of that novel. Spectacular highlights arranged in reverse order, Memento-like"".[20]
See also[edit]
- Thomas Metzinger's Being No One[21]
- Oliver Sacks's The Man Who Mistook His Wife for a Hat[22]
References[edit]
- ^ ""Blindsight: The Lost Covers"". Retrieved 1 January 2013.
- ^ ""2014 Seiun Award Winners"". Locus. 21 July 2014. Retrieved 21 February 2019.
- ^ ""Hugo Nominees (press release)"". Archived from the original on 3 May 2007. Retrieved 3 October 2008.
- ^ ""Campbell Award Winners & Nominees"". Worlds Without End. Retrieved 23 December 2011.
- ^ ""Locus SF Award Winners & Nominees"". Worlds Without End. Retrieved 23 December 2011.
- ^ a b c d e f McGrath, Martin (10 March 2011). ""Blindsight... Or ""In a Chinese Room, not far from the loo"""". Archived from the original on 14 October 2014. Retrieved 8 October 2014.
- ^ a b c d e f g h i j k l m Shaviro, Steven (27 October 2006). ""Blindsight"". Archived from the original on 3 December 2006. Retrieved 8 October 2014.
- ^ a b c Shaviro, Steven. ""Consequences of Panpsychism"" (PDF): 14. Retrieved 8 October 2014.
{{cite journal}}: Cite journal requires
|journal=(help)
- ^ a b c d e f g h i ""Transcript Podcast 2: ""Blindsight"" by Peter Watts"". Science Fiction First. Archived from the original on 15 October 2014. Retrieved 8 October 2014.
- ^ a b c d e Shaviro, Steven (25 August 2014). ""Ferociously Intellectual Pulp Writing"". Archived from the original on 26 August 2014. Retrieved 8 October 2014.
- ^ a b c d e f g Elber-Aviram, Hadas. ""Visions of Humanity between the Posthuman and the Non-Human"" (PDF). Imachine: There is No I in Meme: 4–5. Archived from the original (PDF) on 14 October 2014. Retrieved 8 October 2014.
- ^ a b c Nirshberg, Greg (7 December 2010). ""Book Review – Blindsight by Peter Watts"". Archived from the original on 1 October 2014. Retrieved 8 October 2014.
- ^ Watts, Peter (3 October 2006). Blindsight. Tor Books. pp. 94. ISBN 978-0-7653-1218-1.
- ^ Hays, Carl (1 October 2006). ""Blindsight"". Booklist. 103 (3): 45. ISSN 0006-7385.
- ^ ""BLINDSIGHT"". Kirkus Reviews. 74 (16): 816. 15 August 2006. ISSN 0042-6598.
- ^ Cassada, Jackie (15 October 2006). ""Blindsight"". Library Journal. 131 (17): 55. ISSN 0363-0277.
- ^ Blindsight (28 August 2006). ""Blindsight"". Publishers Weekly. 253 (34): 36. ISSN 0000-0019.
- ^ Bear, Elizabeth (3 March 2011). ""Best SFF Novels of the Decade: An Appreciation of Blindsight"". Tor.com. Retrieved 10 July 2014.
- ^ https://blindsight.space/
- ^ ""No Moods, Ads or Cutesy Fucking Icons » Memento with Scramblers: Krivoruchko Crushes It"".
- ^ ""Many of the syndromes and maladies dropped into Blindsight I first encountered in Metzinger's book. Any uncited claims or statements in this subsection probably hail from that source."" http://www.rifters.com/real/Blindsight.htm
- ^ ""And of course, Oliver Saks [sic] was sending us memos from the edge of consciousness long before consciousness even had a bandwagon to jump on."" http://www.rifters.com/real/Blindsight.htm
External links[edit]
- 2006 Canadian novels
- 2006 science fiction novels
- Creative Commons-licensed novels
- Vampire novels
- Fiction set in the 2080s
- Hard science fiction
- Canadian science fiction novels
- Tor Books books
- Science fiction horror novels
- Novels about artificial intelligence
- Novels about extraterrestrial life
- Transhumanist books
- Novels about virtual reality
- Cyborgs in literature
- Novels about genetic engineering
- Evolution in popular culture
- Novels about consciousness
- Novels about robots
- Philosophical novels
- Fiction about comets
- Fiction set in the Kuiper belt",8
307,"The 'Storification' of Technology: From Steve Jobs to Elon Musk, Pixar to FTX
Stories Are Central to Business, But Demand Skepticism and Scrutiny
This is a weekly newsletter about how tech and culture intersect. To receive Digital Native in your inbox each week, subscribe here:
Hey Everyone 👋 ,
The year is winding down, and I’m beginning to reflect on what happened in 2022 and where we’ll go in 2023. This week’s piece is the first of a series of “end-of-year” reflections and predictions. In this piece, I’ll tackle one pattern I’ve observed in tech this past year: how storytelling can be a double-edged sword. Then next week, I’ll turn to startup founders, investors, and operators for their end-of-year thoughts.
Let’s jump in.
The 'Storification' of Technology: From Steve Jobs to Elon Musk, Pixar to FTX
One of the qualities that made Steve Jobs a great entrepreneur is that he was an excellent storyteller. Jobs knew how to craft a narrative around a product. Think of his keynote presentations, which were almost cinematic in nature. On stage in 2007, Jobs announced that he’d be introducing three revolutionary new products:
A wide-screen iPod with touch controls,
A revolutionary new phone, and
A breakthrough internet communications device
Then he made his big reveal: these weren’t three distinct products, but rather a single product called iPhone. The audience loved it—and so have consumers. Fifteen years later, Apple has sold 2.2 billion iPhones. iPhone sales alone would place Apple 12th on the Fortune 500—above titans like Microsoft, AT&T, Chevron, Walgreens, and JP Morgan Chase.
Apple has always excelled at storytelling. The company’s 1984 Macintosh commercial remains one of the most iconic ads in history. At the time, the idea of a graphical user interface was groundbreaking. Apple’s Macintosh team came up with concepts like files, folders, and trashcans; created windows for different applications; and decided that tasks could be layered on top of one another. The 1984 commercial reminded consumers how transformative Macintosh was as a product. Macintosh was making computing accessible, charting the course for the next three decades of consumer-facing technology.
Fast forward to 1997, and Apple launched the “Think Different” campaign. Think Different again told a story, this time encouraging consumers to associate Apple products with innovation and creativity.
And a few years later, Apple launched its brilliant iPod ads—still among my favorite all-time ads. They told a new story: one of elegant, simple, portable devices that evoke joy.
Today, Apple is again telling a story—one centered around privacy, which Tim Cook clearly views as the crux of consumer purchase decisions in 2022.
Buoyed by its storytelling prowess, Apple has risen to the top of the business world—its $2.3 trillion market cap is a good $500 billion ahead of 2nd-place Saudi Aramco. Great storytelling can unlock great business performance.
But storytelling can also be dangerous when it goes unchecked.
The Storification of Everything
The literary theorist Peter Brooks warns of a growing trend in American culture: “storification.” In his book Seduced by Story: The Use and Abuse of Narrative, Brooks argues that as a society, we’ve turned to storytelling conventions to make sense of our world, creating a “narrative takeover of reality” that bleeds into every form of communication: the way doctors interact with patients, how financial reports are written, the branding that corporations use to present themselves to consumers.
In The Atlantic, Sophia Stewart takes storification a step further—the internet, she argues, greases the wheels of narrative takeover. On Instagram, we construct stories of our lives that we tell through photo and video. On TikTok, people talk about channeling “main character energy” in their day-to-day. The multi-hyphenate YouTuber and comedian Bo Burnham—an authority on internet culture if there ever was one—puts it this way: “We really do spend so much time building narrative for ourselves, and I sense with people that there was a real pressure to view one’s life as something like a movie.”
We see this same phenomenon taking hold in tech companies and their leaders. Take Elon Musk. Musk is masterful at controlling and burnishing the public persona of Elon Musk. While Musk is no doubt an impressive entrepreneur (though many would be surprised to learn that he isn’t the founder of Tesla, but instead an early investor-turned-CEO), the Musk mythology has gotten ahead of itself. The man was even inspiration for Tony Stark, a.k.a. Iron Man. His every tweet is devoured with such reverence—in an almost Trumpian way— that there’s rarely room for healthy skepticism, scrutiny, or debate. Musk’s accomplishments (and I deeply admire them, particularly SpaceX) should be separate from blind approbation, no questions asked.
Nothing demonstrates the dangers of storification more than the Twitter-Musk saga.
Twitter is a poor business, one that has never figured out how to effectively monetize its influential place in culture. There’s no doubt that Twitter the product is massively important in global communications and news. But Twitter the company has failed to build a robust advertising engine to capitalize on that importance. And it turns out that a text-centric, anger-filled venue might not be the most attractive to advertisers in the first place; the video-centric, joy-filled TikTok fares much better.
Yet Musk’s telling of the Twitter story is quite different. In November, at the Baron Conference in New York, Musk said that Twitter could be the most valuable company in the world. Somehow, a $40 billion company (that would probably be worth $10-15 billion if still publicly-traded) could overtake the aforementioned $2.3 trillion Apple, currently 58x its size. A company with 450 monthly active users—one-seventh as many as Facebook, one-fifth as many as Instagram, and one-third (estimated) as many as TikTok—that is growing its user base just 4% a year could somehow overtake tech giants many multiples bigger. The story just doesn’t make sense.
In his recent piece Narratives, Ben Thompson makes the same point: Musk has his narratives (Bots are bad! Free speech! Subscription is the right business model!) but they come up hollow upon closer examination. Investors backed Musk in his overpriced Twitter acquisition because of Musk’s track record, yes, but also because of the story he told. And it’s looking like they’ll be taking a loss on that investment.
The other major story of the past month—the story of Sam Bankman-Fried and FTX—also underscores the dangers of storification. The complexity and grey areas of FTX’s business was camouflaged by SBF’s simplistic black-and-white narrative. Everyone loves a good hero-villain story, and SBF delivered: SBF, crypto’s young savior, was here to take on the big bad banks and their centralized financial system. He painted the narrative in absolutes, distracting from the conflicts, financial mismanagement, and self-trading under the hood.
We saw the same thing happen with Elizabeth Holmes and Theranos. Holmes told an alluring story—the story of the young wunderkind, complete with lore (green smoothies only) and costume (Steve Jobs-esque black turtleneck). But again, the narrative masked the truth. In his book, Peter Brooks points to Enron and Purdue Pharma as two business examples of “narrative takeover of reality”; FTX and Theranos provide two recent proofpoints in the tech world.
This is difficult, of course, because storytelling is also key to any great entrepreneur and any great company. Storytelling is a powerful tool for attracting talent, motivating employees, and selling to customers.
The challenge is that in today’s fast-paced, internet-fueled environment, we have too often sacrificed analysis, examination, and argument. Any good story should demand a healthy dose of scrutiny; after all, every story is constructed through deliberate choices of inclusion and omission.
As an investor, this discipline is even more critical—how do you separate fact from fiction? What narratives are valid, and what narratives are overinflated and more bluster than substance?
The Glass-Half-Full View
My writing in Digital Native tends to take the optimistic view of technology and entrepreneurship, so I’ll end with a more positive reframing.
The above isn’t to argue that storytelling is bad; rather, stories are an essential part of human connection. One of the reasons I love mediums like film and television is because they leverage stories to influence real-world viewpoints, actions, and policies. Will & Grace was pivotal in driving mainstream acceptance of same-sex marriage in America. Studies have shown that watching a TV show with a female president increases a person’s likelihood of voting for a female president. I dedicated an entire piece to the relationship between media and culture, April’s Cultural Transmission in the Internet Age. From that piece:
Media is also a powerful vehicle for relaying true stories, raising awareness and spurring action. How many Americans would even know about the Rwandan genocide if it weren’t for Hotel Rwanda? Or in the 80s, the excellent film Mississippi Burning painted a vivid portrait of American racism for the movie-going public. And more recently, the Hulu show Dopesick (which I highly recommend) both educated and infuriated viewers about Purdue Pharma and its role in the opioid crisis.
To loop back to Steve Jobs, how many kids (and adults) have learned important life lessons from another of Jobs’s creations—Pixar?
Stories are wonderful, and learning to tell a good story is integral to being successful as an entrepreneur. (Side note: Pixar’s 22 Rules of Storytelling are worth reading in full—they are the masters of their craft.)
The best startups learn to write their own narrative, yet in an honest, high-integrity way. The book Play Bigger calls this “category design”, and when executed well, category design can be powerful.
Qualtrics was a middling survey company until its founders reframed surveys as “Experience Management.” What exec wants to pay for yet another survey tool? No thanks. But the exec who wouldn’t pay for Experience Management? That’s a bad boss right there. Qualtrics’s storytelling was brilliant, inflected the business, and today Qualtrics is a $6B public company (SurveyMonkey, now called Momentive, sits at $1B).
In the bull market of the past decade, it became easy to listen to a good story and to gloss over analysis. After all, everything was up and to the right.
But heading into 2023, and given how narratives seem to have outpaced substance, it’s important to realize what a good story is. A tool in an entrepreneur’s arsenal? Yes. A feather in a company’s cap? Absolutely. But a story isn’t everything. Beware the ‘storification’ of business and technology. Every story demands deep scrutiny and thoughtful examination—especially the good stories. When the story sounds too good to be true, it often is.
Sources & Additional Reading
Seduced By Story | Peter Brooks
Beware the Storification of the Internet | Sophia Stewart, The Atlantic
Narratives | Ben Thompson
Play Bigger | Ramadan, Peterson, Lochhead, Maney
Thank you to my colleague Paris Heymann for being a sparring partner on the topics of storification and category creation, and how they relate to the art of investing and entrepreneurship
Thanks for reading! Subscribe here to receive Digital Native in your inbox each week:",1
308,"Financing offshore wind - part 1
Once upon a time...
This was first posted on the WFO Blog.
This is the first part of approximately a dozen. Together, they form a full report on the topic which will ultimately be published as a single document in a few weeks, once all episodes are posted. 2 new parts will be published each week. Links will be added as they are published.
Once upon a time…
In late 2016, EY, the professional services firm, published a report on large power sector projects and how well they were being built (Spotlight on power and utility megaprojects — formulas for success).
Figure 1: Cost overruns and delays in power sector mega–projects. Source: EY)
Unsurprisingly, it noted that most of these very large projects suffered from cost overruns and delays, sometimes on a quite massive scale. However, what stood out was how much better offshore wind projects seemed to be faring, with the lowest delays and cost overruns by far, despite being a relatively new and immature sector, and despite the obvious intrinsic difficulty of installing large industrial facilities in a very hostile and inaccessible location – the open sea.
Not long after that, Ørsted, the Danish utility that was one of the pioneers in offshore wind and still is the market leader, stunned the world with a bid to build the Borssele 1–2 project in the Netherlands for a record low tariff of 72.7 EUR/MWh, at a time when most countries were still offering feed–in tariffs around 150 EUR/MWh for offshore wind projects. A few months later, the next Dutch project, Borssele 3–4 was awarded at the even lower tariff of 54.5 EUR/MWh to a consortium led by contractors Van Oord and MHI Vestas, and the Danish nearshore tender was won by Vattenfall with a tariff of 49 EUR/MWh. And soon afterwards Germany awarded the first “zero–bid” project, where the sponsors effectively saying they could build projects on the basis of ongoing market prices, without any medium term revenue stabilisation mechanism. An industry that had until then required substantial subsidies to get projects built was suddenly confident that it was fully competitive against all other power generation technologies and could provide cheaper electricity than the market.
Figure 2: Offshore wind tender prices, 2009–2018 (Source: Green Giraffe)
This document will discuss how the industry managed this feat, and the prominent role that project finance lenders, a rare breed of financiers, played in that success. This paper thus tells the story of how early projects were financed, what was learnt along the way, and what this means for today’s projects. In particular, this will underline how financial engineering was critical in (i) getting a lot of things right during the early generation projects and (ii) bringing the net cost of electricity (the “LCOE” – levelized cost of electricity) down.
Stuff happens
And yet, the early days were not straightforward…
Figure 3: A collapsed crane in the Ijmuiden port
In the summer of 2007, an accident took place on the quayside of the Ijmuiden port. The crane on an offshore installation barge fell down on the quay and crashed. Thankfully, nobody was seriously injured and there was only limited damage to the wind turbine components; however, the crane itself could not be repaired anymore.
That obviously made the installation barge inoperative and prevented for some time the transport of wind turbine nacelles from the quay to the “Q7” offshore site at sea where a 60-turbine, 120 MW offshore wind farm was under construction in Dutch water. The accident took place in July, precisely the period when the weather is calmer and it is much easier to do construction work at sea.
Just a year later, in July 2008, another project, the 6-turbine, 30 MW C-Power phase 1 in Belgium, reported an incident: while pouring sand into the concrete foundations at sea, the plastic “J-Tube” that was supposed to house the cable connecting the turbine to the rest of the project was crushed by the pressure. Quickly identified as a design error (the plastic used for the tube was strong enough for water but not for packed sand), the incident threatened to prevent the connection of the project’s turbines to the grid altogether.
The Q7 wind farm (also known as the “Prinses Amalia” wind farm) and the C-Power phase 1 project being the first two offshore wind project to be financed by banks on a non-recourse basis (respectively in October 2006 and May 2007), this in each case became an immediate and severe test of whether their financial structures were sturdy enough to resist to such events, and whether the industry could hope to continue to be financed using “project finance”.
Other early offshore wind projects also had to face severe problems during construction or early operations, such as Horns Rev (serial defects on the gearboxes leading to their eventual full replacement at sea), Greater Gabbard (flaws in the welding of the foundations, leading to delays in their production and the installation of the turbines), but as these were built on balance sheet, the problems were kept between the project owner(s) and the contractors, and much less public or semi–public information was made available about them.
Side note – offshore wind has been tough for for oil & gas contractors
For oil & gas contractors, the temptation to get involved in the nascent offshore wind sector was strong – no obvious competitors from the wind industry side with experience working at sea, familiarity and experience with the main area where projects are built (the North Sea), attractive size of contracts. And indeed players like KBR, Fluor, Bechtel and Technip, who have long experience offering “EPC” (engineering, procurement, construction”) contracts in the oil & gas sector, tried to get involved.
Unfortunately, it quickly appeared that offshore wind was quite different from offshore oil & gas – serial construction rather than large bespoke structures, a capped revenue structure that means that cost discipline is a lot more important than simply getting things done (in oil & gas, the cashflows from a producing well are such that it is almost always worth it to spend more to get things done faster; in offshore wind, this is not the case), and the technical features of the turbines themselves, requiring specific design and installation for each individual generator. The early attempts by oil & gas contractors to build offshore wind farms (KBR on the Barrow project (UK, 90 MW), Fluor with Greater Gabbard (UK, 504 MW)) were therefore quite challenging, leading to losses and/or long disputes with project owners or subcontractors.
As a result, most of the large oil & gas contractors quit the market in the early 2010s, or focused on very specialised tasks (like cable installation) and the marine construction work ended up being dominated by another breed of offshore contractors: the dredgers, lead by DEME and Van Oord.
Dealing with problems
In the end, both Q7 and C–Power were built within the timetable and funding the banks had allocated for in their pessimistic scenarios, thanks to massive efforts by the project teams to resolve the unexpected problem:
For Q7, construction work was delayed by several months. A temporary solution was found by using a mobile crane on the installation barge, but that was less efficient and slower and it was already autumn by then. This meant being able to work fewer days of work each month as weather conditions became more difficult, and increasing delays. Thankfully, as no work had originally been scheduled at all during these harsher winter months, the project was able to slowly catch up on its original schedule.
For C-Power, the project team, with the help of contractor DEME, quickly designed an external steel “robe” to be installed on the outside of the foundation to carry the cable that could no longer be pulled through the J‑Tube inside the foundation. The team managed to design, manufacture and install this within a few months, allowing the consequences of the accident to be mitigated. The cost of that effort was fully borne by insurance – the insurers were quickly convinced by the solution proposed by the project and saw it as a much cheaper alternative than waiting and litigating as they were clearly on the hook in any case for the loss of production that would have happened otherwise.
Figure 4: Installing the external “robe” on a C–Power foundations (Source: Giants on the Thornton Bank, Jan Strubbe)
These two incidents confirmed what had been a core assumption of the banks funding the projects: problems will inevitably happen in such projects, what mattered most was the ability by the project to withstand the consequences and solve them. That meant, in practice, having (i) enough time and funding buffers to be able to deal with the unexpected, and (ii) the right people to actually understand issues, identify solutions and implement them.
Now that the offshore wind industry has moved to another dimension, it is important to remember these principles, as they still underpin the fundamental philosophy of how projects are built, and how they are financed.
The next installment is now available: Part 2
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Thanks Jérôme for sharing your views and insights. I'm working engineering tasks related to design (loads on support structures) but also revenue (yield assessments) sides of projects, and I wonder:
With a nominal 10-year standard error (uncertainty) of 6% for a wind farm with a best estimate (p50) net capacity factor of 46%, the corresponding 90%-exceedance threshold (p90) is 42.5%. How do these uncertainty estimate compare with actual revenue uncertainty? My own analysis (using publicly-available data) shows that most wind farm do achieve much larger long-term net yield than their original p90 estimates.
I guess it is worth making a difference between production- and revenue uncertainty, as there are multiple risk-mitigation mechanisms (guaranteed availability, pay-back mechanism when grid is down etc). What do you think, is the revenue risk still at high as it used to be? How could this risk be reduced further?
All the best. Rémi (C2Wind, DK).",2
309,"Ultrasound imaging is a safe and noninvasive window into the body’s workings, providing clinicians with live images of a patient’s internal organs. To capture these images, trained technicians manipulate ultrasound wands and probes to direct sound waves into the body. These waves reflect back out to produce high-resolution images of a patient’s heart, lungs, and other deep organs.
Currently, ultrasound imaging requires bulky and specialized equipment available only in hospitals and doctor’s offices. But a new design by MIT engineers might make the technology as wearable and accessible as buying Band-Aids at the pharmacy.
In a paper appearing today in Science, the engineers present the design for a new ultrasound sticker — a stamp-sized device that sticks to skin and can provide continuous ultrasound imaging of internal organs for 48 hours.
The researchers applied the stickers to volunteers and showed the devices produced live, high-resolution images of major blood vessels and deeper organs such as the heart, lungs, and stomach. The stickers maintained a strong adhesion and captured changes in underlying organs as volunteers performed various activities, including sitting, standing, jogging, and biking.
The current design requires connecting the stickers to instruments that translate the reflected sound waves into images. The researchers point out that even in their current form, the stickers could have immediate applications: For instance, the devices could be applied to patients in the hospital, similar to heart-monitoring EKG stickers, and could continuously image internal organs without requiring a technician to hold a probe in place for long periods of time.
If the devices can be made to operate wirelessly — a goal the team is currently working toward — the ultrasound stickers could be made into wearable imaging products that patients could take home from a doctor’s office or even buy at a pharmacy.
“We envision a few patches adhered to different locations on the body, and the patches would communicate with your cellphone, where AI algorithms would analyze the images on demand,” says the study’s senior author, Xuanhe Zhao, professor of mechanical engineering and civil and environmental engineering at MIT. “We believe we’ve opened a new era of wearable imaging: With a few patches on your body, you could see your internal organs.”
The study also includes lead authors Chonghe Wang and Xiaoyu Chen, and co-authors Liu Wang, Mitsutoshi Makihata, and Tao Zhao at MIT, along with Hsiao-Chuan Liu of the Mayo Clinic in Rochester, Minnesota.
A sticky issue
To image with ultrasound, a technician first applies a liquid gel to a patient’s skin, which acts to transmit ultrasound waves. A probe, or transducer, is then pressed against the gel, sending sound waves into the body that echo off internal structures and back to the probe, where the echoed signals are translated into visual images.
For patients who require long periods of imaging, some hospitals offer probes affixed to robotic arms that can hold a transducer in place without tiring, but the liquid ultrasound gel flows away and dries out over time, interrupting long-term imaging.
In recent years, researchers have explored designs for stretchable ultrasound probes that would provide portable, low-profile imaging of internal organs. These designs gave a flexible array of tiny ultrasound transducers, the idea being that such a device would stretch and conform with a patient’s body.
But these experimental designs have produced low-resolution images, in part due to their stretch: In moving with the body, transducers shift location relative to each other, distorting the resulting image.
“Wearable ultrasound imaging tool would have huge potential in the future of clinical diagnosis. However, the resolution and imaging duration of existing ultrasound patches is relatively low, and they cannot image deep organs,” says Chonghe Wang, who is an MIT graduate student.
An inside look
The MIT team’s new ultrasound sticker produces higher resolution images over a longer duration by pairing a stretchy adhesive layer with a rigid array of transducers. “This combination enables the device to conform to the skin while maintaining the relative location of transducers to generate clearer and more precise images.” Wang says.
The device’s adhesive layer is made from two thin layers of elastomer that encapsulate a middle layer of solid hydrogel, a mostly water-based material that easily transmits sound waves. Unlike traditional ultrasound gels, the MIT team’s hydrogel is elastic and stretchy.
“The elastomer prevents dehydration of hydrogel,” says Chen, an MIT postdoc. “Only when hydrogel is highly hydrated can acoustic waves penetrate effectively and give high-resolution imaging of internal organs.”
The bottom elastomer layer is designed to stick to skin, while the top layer adheres to a rigid array of transducers that the team also designed and fabricated. The entire ultrasound sticker measures about 2 square centimeters across, and 3 millimeters thick — about the area of a postage stamp.
The researchers ran the ultrasound sticker through a battery of tests with healthy volunteers, who wore the stickers on various parts of their bodies, including the neck, chest, abdomen, and arms. The stickers stayed attached to their skin, and produced clear images of underlying structures for up to 48 hours. During this time, volunteers performed a variety of activities in the lab, from sitting and standing, to jogging, biking, and lifting weights.
From the stickers’ images, the team was able to observe the changing diameter of major blood vessels when seated versus standing. The stickers also captured details of deeper organs, such as how the heart changes shape as it exerts during exercise. The researchers were also able to watch the stomach distend, then shrink back as volunteers drank then later passed juice out of their system. And as some volunteers lifted weights, the team could detect bright patterns in underlying muscles, signaling temporary microdamage.
“With imaging, we might be able to capture the moment in a workout before overuse, and stop before muscles become sore,” says Chen. “We do not know when that moment might be yet, but now we can provide imaging data that experts can interpret.”
The team is working to make the stickers function wirelessly. They are also developing software algorithms based on artificial intelligence that can better interpret and diagnose the stickers’ images. Then, Zhao envisions ultrasound stickers could be packaged and purchased by patients and consumers, and used not only to monitor various internal organs, but also the progression of tumors, as well as the development of fetuses in the womb.
“We imagine we could have a box of stickers, each designed to image a different location of the body,” Zhao says. “We believe this represents a breakthrough in wearable devices and medical imaging.”
This research was funded, in part, by MIT, the Defense Advanced Research Projects Agency, the National Science Foundation, the National Institutes of Health, and the U.S. Army Research Office through the Institute for Soldier Nanotechnologies at MIT.",2
310,"A New ESG?
The Future Does Not Fit in the Containers of the Past. Edition 112.
ESG has been important to companies and to investors though recently there has been some blowback from certain segments of the market on whether ESG is a feel-good, hard to measure, share-holder unfriendly and fuzzy goal.
This piece proposes that while ESG remains important a new ESG which is far more focused and therefore measurable, far more aligned with stakeholder value and more resonant with recent challenges needs to be acknowledged.
A new ESG.
What is traditional ESG?
A comprehensive definition from ADEC
Environmental risks created by business activities have actual or potential negative impact on air, land, water, ecosystems, and human health. Company environmental activities considered ESG factors include managing resources and preventing pollution, reducing emissions and climate impact, and executing environmental reporting or disclosure. Environmental positive outcomes include avoiding or minimizing environmental liabilities, lowering costs, and increasing profitability through energy and other efficiencies, and reducing regulatory, litigation and reputational risk.
Social risks refer to the impact that companies can have on society. They are addressed by company social activities such as promoting health and safety, encouraging labor-management relations, protecting human rights and focusing on product integrity. Social positive outcomes include increasing productivity and morale, reducing turnover and absenteeism and improving brand loyalty.
Governance risks concern the way companies are run. It addresses areas such as corporate brand independence and diversity, corporate risk management and excessive executive compensation, through company governance activities such as increasing diversity and accountability of the board, protecting shareholders and their rights, and reporting and disclosing information. Governance positive outcomes include aligning interests of share owners and management and avoiding unpleasant financial surprises.
A New ESG
ESG is and will continue to be important but it covers so many areas that it often feels unfocused and is often a something that has a section in an Annual report, a check box that must be marked and though essential to a healthy business is seen as a “nice to do” or a “we have to do” versus it’s the competitive advantage that will drive increased customer loyalty, enhanced attraction and retention of talent and increased financial value to owners and shareholders.
Today amidst the triple crisis of health, economic and social unrest reflected in Covid-19, generational shifts and Black Lives Matter a more clarified and focused ESG should be Employees, Society and Government.
Every smart company understands that purpose, values, doing good needs a focus on ensuring that their employees are well taken off, the impact of their products and services is a net positive to society and that they work in harmony with Government which is an essential force holding society together and providing resources to its employees.
Employees: Is the company ensuring security for their employees by paying a wage that allows them to have disposable income after they cover living, health and student debt? Are you providing adequate health care and an environment that does not put their physical or mental health at risk? Does the firm have diversity across the company and do people feel safe in speaking up? Are they investing in training? Most importantly are employees a cost or also an asset? Learn more about what PayPal has done in this area.
The most critical asset a company really has is its workforce. Four decades of experience and years of research for my book Restoring the Soul of Business: Staying Human in the Age of Data indicate that its employees who create the brands, the ideas, the experience that make a company and the only way a company improves and transforms itself is by growing the skills and unleashing the talents of its people.
Today employees are more stressed than ever and over the next few years companies will be made or broken based on what they do and did in the early 2020’s. The Great Resignation and “Quiet Quitting” are symptoms where the real questions are why, how, where and who we work for?
Society: We have always lived in a connected world but over the past few years we are more connected than ever due to search that allows us to connect to information, e-commerce that enables us to connect to anywhere to transact, social networks that connect us to each other and mobile phones that connect us all the time. No wonder that the key connecting companies of Google, Amazon, Meta and Apple are four of the most valuable companies in the world.
While many of these were funded by advertising and ran AOS (Advertising Operating Systems) or iOS (Apple) the reality is they are now Society Operating Systems and must manage themselves and be governed as such. But increasingly due to their scale, scope, and balance sheets more and more companies from Walmart to CVS to Starwood’s decisions change society. What are the implications on Society of a firm’s business decisions? Often the secondary effects of optimizing for business creates huge problems for society.
How can a company understand both what the ill effects might be to society but as importantly what good can one do for society as Walmart unleashed its logistics often after a hurricane. Society is often the community that companies are based in, or their employees live and where their customers make their life. Every company has the potential to be a net good to society while also ensuring profitability and growth, but it needs to be baked into its strategy.
A focus on purposeful good for society and multiple stake holders attracts not just customers but talent who feel more connected and prouder of such firms
Government: If there is one thing that Covid-19 and its aftereffects has shown is that government matters. The quality of governance matters. Even the University of Chicago professors worry that government has been captured by business and wonders how to save Capitalism from the Capitalists. Government has been underfunded, demonized, and lobotomized via lobbying and a platoon of politicians who believe they are in the business of entertaining versus running things and solving problems. More government may not be the answer, but better government and a more respected government is usually key for a country’s health.
Businesses must recognize that earning billions and paying peanuts in taxes eventually means no infrastructure, no public schools and much more. Running to government when things get tough but starving them when things go well is not aligned with purpose values and other high thoughts that gallivant and roam free on corporate websites.
So, every corporate leader, HR honcho, purpose driven person in a firm should ask?
Are we looking after our employees?
Are we thinking about society?Particularly the negative impacts of our products and services?
Are we helping government including paying taxes?
The Employee, Society, Government focus will need to be done first to truly realize Environment, Social and Governance goals.
Today more and more customers care a lot about how companies are looking after their employees and caring for society. If one is a senior manager, it is important to spend some time with employees in their 20s and 30s and learn how they truly care about purpose, values, fairness and this impacts their decision to stay or leave your company and much more.
From Patagonia to PayPal companies that do the right thing have the right results.
By focusing on the story of people, society, and culture they deliver the results they need for the spreadsheets.
Photography by Robert Frank.
To receive a post on a different subject every Sunday completely free please sing up below:
For more about Rishad Tobaccowala click here.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
I love the heart behind this post, but feel the new ESG still lacks clarity around looking at the negative effects a company has on its society and the planet at large. Just as you argue about the old ESG lacking clarity, it seems there are only clear instructions for Employees and Government, but Society is left fuzzy with no actionable steps aside from asking “Are we thinking about society?” which is not enough to keep a company accountable. Just as you say in Government that a business can’t take from the government without giving back in the form of taxes, companies must also not extract from the earth more than they can regenerate, what some might call an “Earth Tax”. Overall, this new ESG feels like a regression back to a world where we disregard and take for granted our use, and our corporations’ use, of the natural resources of our planet. Interested to hear your thoughts on this.
PayPal is probably not the best candidate to use as an example of companies that do the right thing. Their recent attack on the Free Speech Union was shameful. PayPal are bullies, pure and simple. Apart from that, an enjoyable article.",2
311,"How An Algorithm Is Helping Drive Up Rent
Big landlords are using “YieldStar”, which finds the highest price a market can bear — leaving rents higher, and units emptier
Recently, Annie Lowrey wrote a good piece for The Atlantic noting just how bad rental housing is for Americans right now.",1
312,"Do McKinsey and other consultants do anything useful?
Though hated, they often provide a valuable service to the economy
If a list were made of the most reviled species in the professional world, only investment bankers would stand between management consultants and the top spot. Sceptics portray these corporate consiglieri as snake-oil salesmen, bamboozling chief executives and politicians with management gibberish and glossy charts while gorging on fat fees. Indeed, the profession was once the subject of a five-season skewering in a star-studded tv series. Its title: “House of Lies”.
Recent events have provided even more reasons to hate consultants. “When McKinsey Comes to Town”, an exposé published on October 4th, drags its subject through the mud with evidence of decades of scandalous behaviour. On September 30th prosecutors in South Africa brought criminal charges against the firm. (McKinsey says the book is a misrepresentation and denies the charges brought against it.) Its two big rivals, Bain & Company and the Boston Consulting Group (bcg), have also faced controversies. In France President Emmanuel Macron has come under attack after an inquiry this year found the government had spent $1bn on consulting firms with “tentacular” links with the state.
Despite evidence of dubious conduct, business has never been better. The big three firms’ total revenue has tripled since 2010, to about $30bn; the trio now employ around 70,000 people. That implies revenue per employee of over $400,000, hinting at juicy pay packets for the people at the top. By comparison, the figure for the big four accountancy firms—Deloitte, pwc, ey and kpmg—is a comparatively meagre $140,000.
What explains the boom? A shroud of secrecy makes it hard to calculate how much value the industry adds: few bosses or politicians would credit consultants for a successful turnaround. As a result there is a widespread view that all consultants are parasites and those who hire them are fools. In fact the firms have grown because they provide two services that bosses want—one more economically beneficial than the other.
The first is an outside opinion. When firms or governments make decisions, it can pay to buy in rigorous analysis. The danger is that this becomes a self-protection racket. When bosses want to push through controversial decisions, from firing staff to breaking up a firm, a consultant’s backing can bolster their credibility. And legitimate scrutiny, whether from political opponents or board directors, can be easier to dodge using consultants’ reports in pleasing fonts with scientific-looking tables.
The second service is unambiguously good, both for the people in charge and the wider economy: making available specialist knowledge that may not exist within some organisations, from deploying cloud computing to assessing climate change’s impact on supply chains. By performing similar work for many clients, consultants spread productivity-enhancing practices.
One defence against an explosion of bogus advice would be better disclosure. Companies are already required to reveal how much they spend on their auditors and on investment bankers’ fees on deals. The sums that individual firms spend on consultants often exceed this, running into the tens of millions of dollars a year, and should be made public too.
So far the industry has escaped the formal rules that govern lawyers and bankers. If it wishes to keep it that way, it should adopt a second measure: a code of conduct that all responsible consultancies adhere to. They should eschew providing advice that helps bigwigs at the expense of the institutions they run, or helps autocrats oppress their people. They should also police the revolving door between government jobs and consultancies. Consultants have much to offer, but also much still to prove. ■
This article appeared in the Leaders section of the print edition under the headline ""Are management consultants useful?""
Leaders October 8th 2022
From the October 8th 2022 edition
Discover stories from this section and more in the list of contentsExplore the edition
More from Leaders
Europe is growing complacent about its energy crisis
More measures are needed to curtail demand and boost supply
Emerging markets have coped with the rate shock surprisingly well
But the real test is yet to come
An obsession with control is making China weaker but more dangerous
The Communist Party’s five-yearly congress will further tighten one man’s grip",2
313,"Illegal number
An illegal number is a number that represents information which is illegal to possess, utter, propagate, or otherwise transmit in some legal jurisdiction. Any piece of digital information is representable as a number; consequently, if communicating a specific set of information is illegal in some way, then the number may be illegal as well.[1][2][3]
Background[edit]
A number may represent some type of classified information or trade secret, legal to possess only by certain authorized persons. An AACS encryption key (09 F9 11 02 9D 74 E3 5B D8 41 56 C5 63 56 88 C0) that came to prominence in May 2007 is an example of a number claimed to be a secret, and whose publication or inappropriate possession is claimed to be illegal in the United States. It allegedly assists in the decryption of any HD DVD or Blu-ray Disc released before this date. The issuers of a series of cease-and-desist letters claim that the key itself is therefore a copyright circumvention device,[4] and that publishing the key violates Title 1 of the US Digital Millennium Copyright Act.
In part of the DeCSS court order[5] and in the AACS legal notices, the claimed protection for these numbers is based on their mere possession and the value or potential use of the numbers. This makes their status and legal issues surrounding their distribution quite distinct from that of copyright infringement.[5]
Any image file or an executable program[6] can be regarded as simply a very large binary number. In certain jurisdictions, there are images that are illegal to possess,[7] due to obscenity or secrecy/classified status, so the corresponding numbers could be illegal.[1][8]
In 2011 Sony sued George Hotz and members of fail0verflow for jailbreaking the PlayStation 3.[9] Part of the lawsuit complaint was that they had published PS3 keys. Sony also threatened to sue anyone who distributed the keys.[10] Sony later accidentally retweeted an older dongle key through its fictional Kevin Butler character.[11]
Flags and steganography[edit]
As a protest of the DeCSS case, many people created ""steganographic"" versions of the illegal information (i.e. hiding them in some form in flags etc.). Dave Touretzky of Carnegie Mellon University created a ""Gallery of DeCSS descramblers"". In the AACS encryption key controversy, a ""free speech flag"" was created. Some illegal numbers are so short that a simple flag (shown in the image) could be created by using triples of components as describing red-green-blue colors. The argument is that if short numbers can be made illegal, then anything based on those numbers also becomes illegal, like simple patterns of colors, etc.[citation needed]
In the Sony Computer Entertainment v. Hotz case, many bloggers (including one at Yale Law School) made a ""new free speech flag"" in homage to the AACS free speech flag. Most of these were based on the ""dongle key"" rather than the keys Hotz actually released.[12] Several users of other websites posted similar flags.[13]
Illegal primes[edit]
An illegal prime is an illegal number which is also prime. One of the earliest illegal prime numbers was generated in March 2001 by Phil Carmody. Its binary representation corresponds to a compressed version of the C source code of a computer program implementing the DeCSS decryption algorithm, which can be used by a computer to circumvent a DVD's copy protection.[14]
Protests against the indictment of DeCSS author Jon Lech Johansen and legislation prohibiting publication of DeCSS code took many forms.[15] One of them was the representation of the illegal code in a form that had an intrinsically archivable quality. Since the bits making up a computer program also represent a number, the plan was for the number to have some special property that would make it archivable and publishable (one method was to print it on a T-shirt). The primality of a number is a fundamental property of number theory and is therefore not dependent on legal definitions of any particular jurisdiction.
The large prime database of The Prime Pages website records the top 20 primes of various special forms; one of them is proof of primality using the elliptic curve primality proving (ECPP) algorithm. Thus, if the number were large enough and proved prime using ECPP, it would be published.
Other examples[edit]
There are other contexts in which smaller numbers have run afoul of laws or regulations, or drawn the attention of authorities.
- In 2012, it was reported that the numbers 89, 6, and 4 each became banned search terms on search engines in China, because of the date (1989-06-04) of the June Fourth Massacre in Tiananmen Square.[16]
- Due to the association with gangs, in 2012 a school district in Colorado banned the wearing of jerseys that bore the numbers 18, 14, or 13 (or the reverse, 81, 41, or 31).[17]
- In 2017, far-right Slovak politician Marian Kotleba was criminally charged for donating 1,488 euros to a charity. The number is a reference to a white supremacist slogan and the Nazi salute.[18]
See also[edit]
References[edit]
- ^ a b Carmody, Phil. ""An Executable Prime Number?"". Retrieved December 30, 2018.
Maybe I was reading something between the lines that wasn't there, but if arbitrary programs could be expressed as primes, the immediate conclusion is that all programs, including ones some people wished didn't exist, can too. I.e. the so called 'circumvention devices' of which my previous prime exploit was an example.
- ^ Greene, Thomas C. (March 19, 2001). ""DVD descrambler encoded in 'illegal' prime number"". The Register. Retrieved December 30, 2018.
The question, of course, is whether an interesting number is illegal merely because it can be used to encode a contraband program.
- ^ ""The Prime Glossary: illegal prime"". Retrieved December 30, 2018.
The bottom line: If distributing code is illegal, and these numbers contain (or are) the code, doesn't that make these number illegal?
- ^ ""AACS licensor complains of posted key"". Lumen. April 17, 2007. Retrieved December 30, 2018.
Illegal Offering of Processing Key to Circumvent AACS Copyright Protection [...] are thereby providing and offering to the public a technology, product, service, device, component, or part thereof that is primarily designed, produced, or marketed for the purpose of circumventing the technological protection measures afforded by AACS (hereafter, the ""circumvention offering""). Doing so constitutes a violation of the anti-circumvention provisions of the Digital Millennium Copyright Act (the ""DMCA"")
- ^ a b ""Memorandum Order, in MPAA v. Reimerdes, Corley and Kazan"". February 2, 2000. Retrieved December 30, 2018.
- ^ ""Prime Curios: 48565...29443 (1401-digits)"". Retrieved December 30, 2018.
What folks often forget is a program (any file actually) is a string of bits (binary digits)—so every program is a number.
- ^ ""Criminal Justice Act 1988"". Retrieved December 30, 2018.
- ^ Wells, David (2011). ""Illegal prime"". Prime Numbers: The Most Mysterious Figures in Math. Wiley. pp. 126–127. ISBN 9781118045718.
- ^ Patel, Nilay (January 12, 2011). ""Sony follows up, officially sues Geohot and fail0verflow over PS3 jailbreak"". Engadget. Retrieved December 30, 2018.
- ^ Kravets, David (February 8, 2011). ""Sony lawyers now targeting anyone who posts PlayStation 3 hack"". Ars Technica. Retrieved December 30, 2018.
- ^ Miller, Ross (February 9, 2011). ""PS3 'jailbreak code' retweeted by Sony's Kevin Butler, no punchline needed"". Engadget. Retrieved December 30, 2018.
- ^ S., Ben (March 1, 2011). ""46-dc-ea-d3-17-fe-45-d8-09-23-eb-97-e4-95-64-10-d4-cd-b2-c2"". Yale Law Tech. Retrieved December 30, 2018.
- ^ See File:Free-speech-flag-ps3.svg description.
- ^ ""Prime glossary - Illegal prime"". Primes.utm.edu. 1999-10-06. Retrieved 2013-03-26.
- ^ Hamilton, David P. ""Banned Code Lives in Poetry and Song""
- ^ MacKinnon, Mark (June 4, 2012). ""Banned in China on Tiananmen anniversary: 6, 4, 89 and 'today'"". The Globe and Mail. Retrieved December 30, 2018.
- ^ Meyer, Jeremy P. (September 5, 2012). ""Greeley school ban on gang numbers includes Peyton Manning's 18"". The Denver Post. Retrieved December 30, 2018.
- ^ ""Police charge leader of Slovak far-right party with extremism"". Reuters. July 28, 2017. Retrieved December 30, 2018.
External links[edit]
- Skala, Matthew; Bonfield, Brett; Torpey, Mary Fran (February 15, 2008). ""Mediating between law and technology requires vigilance and education, not a technical solution"". Library Journal. Archived from the original on March 30, 2013.
- Guadamuz, Andrés (2002). ""Trouble with Prime Numbers: Decss, Dvd and the Protection of Proprietary Encryption Tools"". Journal of Information, Law & Technology. 3. SSRN 569103.
- ""A Great Debate: Is Computer Code Protected Speech?"". November 30, 2001. Retrieved December 30, 2018.
- Hogge, Becky (May 9, 2007). ""Digging in"". openDemocracy. Retrieved December 30, 2018.
- Touretzky, Dave. ""Steganography Wing of the Gallery of CSS Descramblers"". Carnegie Mellon University. Retrieved December 30, 2018.
- Ornes, Stephen (March 16, 2012). ""US judge rules that you can't copyright pi"". New Scientist. Retrieved December 30, 2018.
- Masnick, Mike (June 25, 2013). ""American Bankers' Association Claims Routing Numbers Are Copyrighted"". TechDirt. Retrieved December 30, 2018.
- Ernesto (October 27, 2015). ""Orwell Estate Sends Copyright Takedown Over the Number ""1984"""". TorrentFreak. Retrieved December 30, 2018.
- Pickover, Clifford A. ""We are in Digits of Pi and Live Forever"". Retrieved December 30, 2018.
- Haran, Brady. ""Illegal Numbers- feat. James Grime"". Numberphile. Archived from the original on July 24, 2018. Retrieved December 30, 2018.",8
314,"Creepy & Paranormal As Cultural Control
How horror content provides us comfort, ending, participation and answers
Post-pandemic, the predominant cultural genre hasn’t actually been feel-good comedy: Ted Lasso, Schitt’s Creek, Abbott Elementary, etc. That’s just been the easier narrative to explain.
Instead, it’s been horror.
In 2021, the horror genre gained 13% market share of the box office, its highest control since ‘95. For the very first time horror ticket sales beat out comedies, dramas, and thrillers.
For context: In 2014, horror only had a 2.4% share of the box office. And its sudden growth hasn’t been because of more horror releases. Comedies have historically been released on a 3:1 ratio to horror films.
There’s a newfound attraction.
Outside of the box office, over in streaming land, this attraction sustains. Horror staples now include: Lovecraft Country, Chucky, Resident Evil, Yellowjackets, Stranger Things, The Walking Dead, American Horror Story, Handmaid’s Tale, What We Do In The Shadows, Atlanta, and who could forget: Squid Game. While it’s harder to quantify these series’ ratings now protected by platforms, the genre’s current influence is glaring.
Further, since 2020 views to r/Horror on Reddit have grown nearly double. Views to r/LiminalSpace are up +77%, and both r/ParanormalEncounters and r/HighStrangeness are up more than +2X since the pandemic struck in 2020.
So why has horror, and specifically the supernatural’s pull become so strong, and further, essential to survive this moment?
Paradoxical Comfort
When we watch uncomfortable or fear-inducing content through a screen, we’re doing so though a barrier — a safe distance. This psychological safety is incredibly freeing... even if it may not feel that way in the moment.
We can thrill ourselves, heighten our emotions and intensify arousal all with safety and control.
Put another way, we can trigger our evolutionary fight-or-flight response, releasing thrilling neurotransmitters: adrenaline, endorphins, and dopamine, however with the reassurance that our lives are not actually in danger. Never are we in complete control over what makes us anxious. Here, we are.
Similar, watching horror allows us to also explore morbid curiosities, again all while knowing nothing is actually at stake. Secure examination.
We can overcome and master our fears.
Pushing our emotional limits and exploring dark matters ultimately provides us a sense of twisted, adventurous accomplishment.
Horror content is ironically therapeutic.
In a moment when reality is already — and increasingly grim — we can immerse ourselves in the dark to test and soothe ourselves.
(Un)Resolve
Second, horror content — more often than not — provides an ending.
The killer is caught, the main character survives, the world is returned to equilibrium.
In our moment of radical uncertainty, watching resolution provides our craved reassurance.
Second-hand closure relieves us.
Faced with our own daily horrors, horror content’s expected, bow-wrapped resolutions give us hope. Hang in there. We may also get a conclusion to our dread too.
But the flip side is true too: When the creepy is unresolved — ambient and continual — it normalizes our real lived experiences. It assures us that loose ends are in fact just a part of life. A lack of resolution provides equal assurance: this is more common than it may feel.
The parallel rise in vibes, magic, manifests, and “giving” auras round out our preoccupation with the open and ethereal.
Entertainment has always been a two way mirror. Our reality informs content, and content informs culture. And in our cultural moment fueled by permacrisis, of course the defining genre is going to be horror.
We seek out this content to observe a reflection and make sense of our zeitgeist. It’s why Contagion (2011) became our COVID-19 must-watch film.
An “Inviting” Format
Horror is a unique genre in that scary is scary is scary.
Horror lends itself incredibly well to all formats. For something to be scary, it doesn’t have to be just visual. It can be auditory. It can be a video game. It can be words. Or it can just be a place.
Horror’s power is agnostic to medium.
For this reason, it’s very easy to feel its effects, and further to join in and create our own content.
On Reddit, r/NoSleep, r/OddlyTerrifying and r/CreepyPasta are among the most subscribed subreddits across the platform’s +100,000 active communities, allowing all to easily share their own eerie content.
The barriers to entry for the spooky are low. It’s easier to make a two sentence horror story than it is to create a two sentence standup bit.
As a result, r/TwoSentenceHorror currently averages +20M views a month, magnitudes larger than its counterpart r/TwoSentenceComedy.
Meanwhile, views to r/HorrorLit reach +1M a month, with 60% of these viewers under 30, signaling the bright future of this dark, welcoming genre.
Making our own scary content provides control over the uncomfortable ideas we conjure. We now own them.
And deeper, the paranormal is a genre which invites theory, creativity, and curiosity — all elements which lend themselves incredibly well to online discussion... and therefore spread.
Today, any content which empowers the ability to dissect and discuss, fuels the flames of fandom, and gives fervent fans what they ultimately want: an invitation to participate and community.
Answers
The paranormal is an explanation for the unexplainable.
During a moment of so much “How is this happening?”, our attraction toward strangeness becomes a solution to make sense of our confusing, uncanny zeitgeist.
Sometimes the bizarre makes more sense than reality.
And we’re increasingly accepting the odd as an answer.
Views to r/LowStakesConspiracy have grown +74% YoY, a community theorizing around “off phenomena” with equal parts humor and desperation for a shared cultural understanding.
Meanwhile, views to r/Aliens are up +50% since 2020, with views to r/UFOs up +3X. As background: two-fifths of Americans now believe extra-terrestrials are behind UFO spottings, up from just one-third only a couple years ago.
Adopting a supernatural explanation is a flex of control.
When so much is out of control, theory is a refreshing reclaim of self-sovereignty. Our own explanation beats the one that isn’t even given. Power is taken back.
Choosing to believe in ghosts is not as much about haunting spirits, as it is an opportunity to author our own answers in an overwhelming, unexplainable environment.
The belief that loved ones may exist onwards is encouraging, not threatening.
And the belief that “we’re not alone,” provides solace during a moment when loneliness is an epidemic.
But at the end of the day, the fact that we even need to rely upon the occult or extra-terrestrial to soothe our anxiety and explain today’s chaos is the scariest bit of it all.
The silver lining here is that our collective creativity, adaptability and faith are winning out.
Ambiguity is refreshingly welcomed.
We’re honoring — not dismissing — experiences.
This is no escape, but an attempt to get closer.
How ironic: fiction is solving for our reality.
All is not lost.
We’re finding a way.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Great work as usual! Reminds me of Sontag's Imagination of Disaster
Great read! Reminds me of the “Elevated Horror” debate I’ve seen online, in which those typically not considered horror fans prefer so-called “Elevated Horror” because they’re more often allegories of trauma rather than ghosts and monsters. But like you point out, I think the horror genre as a whole can help process fear.",1
315,"Short stories: How much do you make? How do you sell one? How long does it take to write?
An anecdotal account of my experience writing and selling ""India World"" to Tor.com
Tor.com recently published my short story “India World”, and I went through my notes, to-do lists, revision history, and email to figure out what exactly went into writing and selling that story.
Finding details and real numbers on how this all works is difficult, and I hope this post is helpful to people writing short fiction and interesting to folks who are just curious!
tl;dr
I spent 22 hours, 18 minutes, and 47 seconds writing and editing “India World” across 42 sessions in Google Docs. (Not including hours more spent editing on paper, revising the story at workshops, or reading critiques.)
30+ people provided feedback after reading drafts, some more than once.
10 publications rejected the story before it found a publisher.
It took 908 days from first word to publication, or about 2 1/2 years.
I earned $1422.80 for publication rights in print, digital, and audio.
Read on for all the gory details including actual emails!
Note: This isn’t meant to be an authoritative report on the state of short fiction or publishing. It’s an anecdotal account of what it took to write and publish one short story. My experience is unique for many reasons, including…
I’m early in my career as a writer and still learning the craft. I likely spent longer writing and editing than a more accomplished writer would.
My publisher Tor.com pays triple the rate of most other “pro” speculative fiction (sci-fi, fantasy, horror) publishers. I sold my first short story, “How Did it Feel to be Eaten”, eight months prior for $297, or $0.08/word. That’s a good rate. And that story was half the length and took 34+ hours to write and edit. In other words, this is a labor of love. For each story that sold, I’ve got a drawer-full that didn’t.
With that out of the way, let’s dig in.
How it started
Here’s a behind-the-scenes look at this story from start to finish.
In November of 2019, I was brainstorming ideas for a sci-fi story set in a future India. Among other things, I thought about what the future of arranged marriage and the caste system might look like. I also explored a future where whole cultures were wiped out and kept alive within computer simulations or theme parks. This latter idea, plus my life-long love of everything Michael Crichton has ever written, especially Jurassic Park, eventually became India World.
How I wrote it
11/10/2019 - Brainstormed the initial idea.
11/23 - 12/8/2019 - Outlined the story, and wrote a rough first draft.
12/8 - 12/15/2019 - Revised draft, submitted to my critique group for feedback from James, Thea, Sahil, and Dan.
12/15/2019 - 2/2/2020 - Edits.
12/16/2019 - Submitted draft to OnlineWritingWorkshop.com, a peer review site where writers exchange critiques.
1/2/2020 - “India World” was selected as an “Editor’s Choice” on OnlineWritingWorkshop, where an eloquently written editorial review argued that it had problematic themes. For instance, that Rohit's triumphant choice to return home sounded lot like white American ""immigrants go home"". I proceeded to freaked out and spent the following weeks fixing.
2/2/2020 - Sent a draft to my critique group at the Futurescapes workshop.
2/3/2020 - Sent a draft to Critters, another peer review group for spec fiction. I got helpful feedback from a dozen folks, including detailed notes from Lauren Banka and Dwayne Minton.
2/13/2020 - Got feedback from my friend Nick Baum, who’s helped with nearly all of my stories so far.
2/17/2020 - Got feedback from Kat Howard. In particular, that Rohit’s motives for his actions in the ending weren’t believable.
2/17/2020 - Got feedback from my Futurescapes critique group (Ashlea, Katrina, Olive, Tali, and Tyra). They offered suggestions for tightening the story, improving imagery, and fixing the ending (came too quickly, needed foreshadowing.) At this point I had Rohit returning to the USA to start “America World” in response to his time at India World. This had given some earlier readers Make America Great Again vibes, so I still wasn’t happy with the ending.
2/18/2020 - Got feedback from Mary Robinette Kowal 🤩 (Hugo and Nebula winner, head of the SFWA) at Futurescapes. She suggested several improvements including a new ending that I loved.
2/21/2020 - Rewrote the ending to its current version.
2/24/2020 - Sent “India World” as my writing sample for my applications to Clarion UCSD and Clarion West. (These are competitive six-week workshops for spec fiction writers; their alumni list reads like a Who’s Who of Sci-Fi. This was my second year applying and I didn’t expect to get in.)
2/25/2020 - On a lark, submitted a draft to an open call by Hugh Howey 🤩. (He wrote the best-selling Silo series and is one of the most popular self-published authors ever.) I didn’t expect anything to come of this.
2/26/2020 - One day later, Hugh wrote to say he loved the story and attached a marked-up manuscript with many suggestions I used. He also offered to publish it in a future anthology if I didn’t publish it elsewhere. (!) This made me pretty excited about this story finding a good home.
3/8/2020 - Got feedback from my bud Sameem Siddiqui. (Check out his wonderful South Asian sci-fi.)
3/8/2020 - Got the call: I WAS ACCEPTED TO CLARION WEST! 🎈🎈
How I submitted it for publication
Submitting short fiction is a whole thing. Here’s why:
The number of publications seems to shrinks each year, but the number of submissions has increased.
Acceptance rates at the best pubs are very, very low.
Many publications don’t allow simultaneous submissions. That means if you send a story to magazine A, you can’t submit it elsewhere until you get a rejection from magazine A. That could take days, but more likely weeks or months. Some of the best pubs take the longest.
My strategy is to apply to the long-long-long-shot pubs that accept simultaneous subs first. Then I start submitting to pubs that disallow simultaneous submissions, starting with the most prestigious, fastest-rejecting ones. The faster you’re rejected, the faster you can send it elsewhere.
Submitting is a numbers game. In 2020, I set a goal of getting 100 rejections.
3/10/2020 - Submitted story to The Sun ( ❌ rejected 28 days later), The Missouri Review ( ❌ rejected with personal note in 38 days), New England Review ( ❌ rejected, 50 days), AGNI ( ❌ rejected, 73 days), The New Yorker (haha yeah right, ❌ rejected, 79 days).
3/16/2020 - Got a rejection email from Clarion UCSD. BUT… Cory Doctorow 🤩 (amazing sci-fi author and activist) was on the admissions board and emailed to say he really enjoyed “India World”, my submission story. AND that he’d told Devi Pillai (Tor’s Co-Publisher and VP) about it and she wanted to read it!
3/17/2020 - I emailed Devi the story, who cautioned she was interested to read the story only for personal enjoyment. Tor wasn’t on my radar for publishing this story — they don’t have open submissions, and my understanding was that you basically had to be asked to publish there and they only asked hotshots. I am not a hotshot. Still, I decided to ask if it could be considered for publication by Tor.com. (Couldn’t hurt!) She CCed in editor Ruoxi Chen!
4/8/2020 - I emailed Ruoxi to see if she’d had a chance to read the story. At this point, the pandemic was raging and everything was in chaos. After a month of not hearing anything back, I figured she didn’t like it and moved on.
4/21/2020 - Submitted to Asimov’s Science Fiction ( ❌ rejected same day! yay)
4/22/2020 - Submitted to Clarkesworld Magazine ( ❌ rejected, 10 days)
5/4/2020 - Submitted to Magazine of Fantasy and Science Fiction ( ❌ rejected, 12 days)
6/1/2020 - Submitted to Strange Horizons ( ❌ rejected, 43 days)
6/7/2020 - Ruoxi from Tor.com emailed! She apologized for the delay and said she’d try to have an answer for me in a week!
6/18/2020 - Followed up with Tor. Didn’t hear back. At this point everyone either had Covid or knew someone with Covid. After six more weeks passed with no word, I assumed Tor was a dead end and decided to continue submitting elsewhere.
7/22/2020 - Submitted to Apex Magazine ( ❌ rejected, 12 days)
8/14/2020 - I started to worry that my opening was too slow and sent the story to my bud Josh Riedel. He generously returned feedback just a few days later.
8/15/2020 - Submitted to Uncanny Magazine
I sold the story!
8/27/2020 - RUOXI FROM TOR.COM EMAILED TO BUY THE STORY! 🏆 They offered $1422.80 for exclusive digital, audio, and ebook rights for one year, non-exclusive afterward. Likely publication: early 2021. I said yes!
Withdrew story from Uncanny Magazine with apologies. (This is a no-no because Uncanny does not allow simultaneous submissions! When I submitted, I didn’t think I was submitting simultaneously because I was under the impression I was out of the running at Tor. I apologized and hope I’m not blacklisted.)
The next year and a half…
9/4/2020 - Contract signed!
Six months pass…
3/31/2021 - I emailed Tor asking about the publication date and heard back that it was now slated for 6/2/2021
5/5/2021 - Tor sent cover art by Jasjyot Singh Hans.
5/6/2021 - Heard from Tor that the legal department might have issues with the title. (At the time, it was “India World®”. We’d eventually have to drop the ®.)
June 2021 - Jan 2022 - For eight months, I emailed Tor every couple months. I worried I was being a nag, but writers I talked to encouraged me to keep checking in every month. No word back during this period. I’m guessing they didn’t know where it was going to slot in yet and were swamped.
1 year, 5 months since contract signing…
2/7/2022 - Emailed Tor asking for an update on publication date. The original contract allowed me to take rights back if it wasn’t published within 12 months of the contract signing, Almost a year and a half in, with no word for nine months, I was starting to think it wouldn’t be published by Tor after all and wanted to make alternate plans. (No hard feelings, plans and priorities change. But I still wanted to get the story out there!)
3/10/2022 - I screwed up the courage to email Devi (VP at Tor) to see if she knew the pub date. Devi replied quickly and told me “India World” was slated for publication on June 1st!
4/11/2022 - Got a marked up copy with edits and suggestions from Ruoxi! I had a month to turn this around and did a final polish, mostly accepting all the edits and making the suggested changes.
6/1/2022 - 2.5 years after I began writing, 🎉 “India World” was published!
👉 Read “India World” here! 👈
In conclusion…
What’d I learn looking back through all this?
Writing takes forever, even if it’s a just a few thousand words. Way longer than I thought.
Submitting takes even longer. This tracks with other areas of my life. Selling is always less fun for me than making things.
SO MANY people helped! I’m blown away by how many people took time to read drafts and offer their feedback.
When I started writing optimistic sci-fi, I didn’t just need to learn how to write for the genre and format. I needed to learn how to format my manuscript, how to find quality critiques, how to submit to publishers, how to network with other writers, and all the rest. Countless other writers took the time to answer my emails and take meetings and read crappy drafts and tell me what was wrong with them.
I’m so grateful for all the ways the writing community has helped me, and I’m hopeful this post proves helpful to others getting started.
👋 Liked this? Please subscribe to get notified when I write something good! (Just a few times a year.)
Thanks Vanessa Armstrong, Nancy Hua, Scott Hurff, and James Yu for feedback on this post.
Thanks for reading Optimistic Sci-fi Short Stories by Amit! Subscribe to get new posts!
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
You are an inspiration whose footsteps, I would love to follow some day.
Can't wait to read the story.
Wish you an amazing and fulfilling journey ahead.
Thank you for sharing this journey! It is equal parts foreboding and inspiring!
Writing (and getting published) is a torturous endeavour but wins like yours make us all hope!",8
317,"[#5] OSINT Origins Podcast – OSINTCurious / Lorand Bodo.2022-07-06T20:01:33+02:00
[#5] OSINT Origins Podcast – OSINTCurious / Lorand Bodo
[#5] OSINT Origins Podcast – OSINTCurious / Lorand Bodo
[#4] OSINT Origins Podcast – ShadowBreak Intl./Samuel Cardillo
[#3] OSINT Origins Podcast – Chainalysis/Thomas De Zoete
[#2] OSINT Origins Podcast – Peter Kleissner / _IntelligenceX
[#1] OSINT Origins Podcast – Jean-Marc Manach FR",8
318,"The pretty, cloudless blue skies over perfectly manicured lawns represent an ugly reality for California’s Las Virgenes Municipal Water District as it grapples with the historic megadrought ravaging the American West.
Despite a lack of any measurable rain in months, the carpet of lush, green grass likely means homeowners are either not getting the message about the dire need for water conservation, or they are ignoring the warnings.
But now, the water district has found a way to get customers’ attention. When customer service representatives are working in the different neighborhoods, they keep an eye out for any water restriction violations. And for repeat offenders, officials are trying something new: adding water restrictors to the pipes, which sharply reduce the home’s water supply.
Lawns of the rich and famous
The District covers some of the most sought-after real estate in Southern California, northwest of Hollywood and Beverly Hills, including areas along the Ventura Freeway.
Las Virgenes imports all of its water from the State Water Project, which pipes runoff from the northern Sierra Nevada mountains to Southern California. However, at the end of winter, the snowpack was just 4% of normal, forcing unprecedented restrictions. Las Virgenes is only getting 5% of its requested water supplies this year.
“We’re having to supplement the water that we have been getting from the State Water Project,” said Mike McNutt, public affairs and communications manager for Las Virgenes, who added the district is pulling water from its Las Virgenes Reservoir, its stash for emergency needs, just south of Thousand Oaks.
Right now, McNutt confirmed it is 72% full; at full capacity, it is a six-month supply. “We’ve had to take significant measures to curb water usage in order for us to ensure that there’s long-term water reliability meaning moving into the fall and winter,” McNutt noted.
Nearly all of California is in severe or worse drought (the highest three designations), per the latest US Drought monitor. Several severely deficient years of rain and snow have punctuated a 20-year long megadrought scientists say is being fueled by warmer and drier conditions brought on by climate change.
When the grass being greener isn’t a good thing
In light of the shortage and the prolonged drought, Las Virgenes has mandated residents cut their outdoor watering by half as required by the unprecedented order from its distributor, the Metropolitan Water District of Southern California.
Outdoor watering makes up 70% of most customer’s water usage, the water district says, so cutting down on irrigation can have a huge impact on conservation.
“They are only allowed to water one day a week outside, Tuesdays and Thursdays, depending on whether your address ends with an odd number or even number,” McNutt explained. On top of that, each set of sprinklers can only be on for eight minutes. “It helps maybe keep some of the grass alive if people want to still continue to have lawns, but they are brown.”
CNN rode along with Las Virgenes senior field customer service representative Cason Gilmer as he looked for wasted water. When he and his team drive around the coverage area, they keep an eye out for water where it shouldn’t be – on sidewalks and running down streets into gutters – or outdoor irrigation on when it should be off.
“When it’s in our face and the sprinklers are going off at noon on Wednesday, it’s an easy target for us,” Gilmer, who noted most customers seem to be doing their part now. “This street in particular was very, very green two months ago.”
Along the ride, the number of homes with vibrant green grass were outnumbered by brown lawns. Some lawns have been replaced with turf and others have been painted green.
Neighbors can rat on each other, celebrities included
If anyone from the water district spots water waste, they can leave a door tag to let the homeowner know they are not in compliance and what they need to do. They also send mailers. The water district also fines abusers, resulting in charges which can reach thousands of dollars depending on the size of the infraction.
But the affluent haven of Calabasas, inside the water district’s territory, is home to many A-listers with deep pockets. Some of those household names – celebrities, musicians and athletes – have used far more water than they should have, according to recent data.
People like Kevin Hart, Dwyane Wade, and according to the Los Angeles Times, Kourtney Kardashian, as well as sister Kim.
None replied to CNN’s request for comment. However, in a statement to the Times, Wade and his wife, actress Gabrielle Union, said they have “taken drastic steps to reduce water usage in accordance with the new city guidelines and have since we moved into our home.”
Las Virgenes said all of those celebrities are in good standing now.
“Those specific celebrities have been working very closely with the district. They do want to do the right thing … in order to achieve a much more efficient water usage tier,” McNutt said.
A disastrous megaflood is coming to California, experts say, and it could be the most expensive natural disaster in history
And when fines are not enough, it’s time to bring in the restrictor
With so many wealthy residents, Las Virgenes has learned some customers respond more to losing water than they do losing money.
“We try to get public education and notification and stuff about drought out there, but a lot of people throw the mailers away. They ignore it,” said Gilmer, who created a simple, yet effective way to get users’ attention one gallon at a time. “I call it a bit of a last resort.”
The water restrictor is a slim circle of food grade stainless steel with a small hole in the middle, which fits right into the offending customer’s water meter, which technicians can usually access right on the street since the meters are district property.
“This particular restrictor will give you around one gallon a minute. Normally, a three-quarter-inch meter is 25 to 30 gallons a minute. So at 25 to 30 gallons a minute, you can run your dishwasher and run your sink and have somebody in the shower and maybe even have your irrigation on and nobody knows the difference,” Gilmer explained. “With the restrictor in … your sink works fine. Your shower works OK. Your irrigation will not work. It just won’t supply the amount of water that’s demanded.”
Gilmer even tried it at his own house to see what it was like having his water restricted.
“The big part was that you can’t do two things at once. So if I was in the shower and my wife tried to do dishes, my shower was done. I just got out,” Gilmer said with a slight smile. “My wife demanded I take it off after a day and a half.”
California drought could cut state’s hydropower in half this summer
After a customer uses more than 150% of their water allocation four times, they will be in line to get the flow restrictor installed. Las Virgenes says about 1,600 connections, or just more than 7% of its customer base falls into this category.
“It’s not meant to be punitive,” McNutt said. “It’s meant to tell people … this drought is incredibly serious and what we need you to do is do your part.”
McNutt added Las Virgenes is leading by example in California as it is “using these flow restriction devices for conservation purposes.”
“We’re kind of leading this charge moving forward of how do we get people to stop using so much water with the advancement of climate change.”",2
319,"Bruce Willis did not sell a deepfake company the rights to his likeness post-retirement: rep
Bruce Willis has retired from making movies since his aphasia diagnosis, but he may continue to be an action star. How? Well, technology.
Video Transcript
[MUSIC PLAYING]",1
320,"Morbius (film)
|Morbius|
|Directed by||Daniel Espinosa|
|Written by|
|Based on||Marvel Comics|
|Produced by|
|Starring|
|Cinematography||Oliver Wood|
|Edited by||Pietro Scalia[1]|
|Music by||Jon Ekstrand|
Production
companies
|Distributed by||Sony Pictures Releasing|
Release dates
Running time
|104 minutes[2]|
|Country||United States|
|Language||English|
|Budget||$75–83 million[3]|
|Box office||$163.9 million[4][5]|
Morbius is a 2022 American superhero film based on the Marvel Comics character of the same name, produced by Columbia Pictures in association with Marvel. Distributed by Sony Pictures Releasing, it is the third film in Sony's Spider-Man Universe (SSU). Directed by Daniel Espinosa and written by Matt Sazama and Burk Sharpless, it stars Jared Leto as Dr. Michael Morbius, alongside Matt Smith, Adria Arjona, Jared Harris, Al Madrigal, and Tyrese Gibson. In the film, Morbius and his surrogate brother Milo become living vampires after curing themselves of a rare blood disease.
There were several attempts to bring Morbius to the big screen since 1998, including joining the Blade franchise and having a solo film produced by Artisan Entertainment, neither of which ever came to fruition. After announcing plans for a new shared universe of films inspired by Spider-Man related characters beginning with Venom (2018), Sony began developing a film based on Morbius. Sazama and Sharpless had written a script by November 2017, and Leto and Espinosa officially joined in June 2018. Work on the film began at the end of the year with further casting, ahead of production starting in London in February 2019. Filming was confirmed to have been completed by June 2019, with reshoots happening in Los Angeles the following February.
Morbius premiered at the Plaza Carso in Mexico City on March 10, 2022, and was theatrically released in the United States on April 1, 2022, after being delayed several times from an initial July 2020 date, primarily due to the COVID-19 pandemic. It received largely negative reviews from critics, with criticism towards its writing, visual effects, and post-credits scenes, though Smith's performance received some praise. The film was a box-office bomb and just grossed $163 million worldwide. Due to the poor critical and commercial reception, it became the subject of various internet memes.
Plot
At a hospital in Greece, 10-year-old Michael Morbius welcomes his surrogate brother Lucien, whom he nicknames Milo; they bond over their shared blood illness and desire to be ""normal"". Their adoptive father and hospital director Nicholas arranges for Morbius to attend medical school in New York while he focuses on caring for Milo.
25 years later, Morbius publicly declines a Nobel Prize for his work with artificial blood. His colleague Martine Bancroft discovers he has secretly captured dozens of vampire bats from Costa Rica in the hope of splicing their genes with his own to cure his condition. After informing Milo of his planned illegal experiment, Morbius receives funding from him to outfit a private mercenary vessel in international waters with his equipment. While the cure works, it transforms Morbius into a vampire, who kills and drains the crew of their blood after they attack him out of fear. Once his bloodlust subsides and he regains his senses, a horrified Morbius erases all CCTV footage of his experiment before contacting the authorities and jumping overboard.
Morbius returns to New York and discovers he now has superhuman strength, speed, reflexes, and echolocation, with his vampire bats treating him as one of their own. To control his bloodlust, he subsists on his artificial blood as it gradually ceases to satisfy his needs. FBI agents Simon Stroud and Al Rodriguez investigate Morbius' victims and deduce his involvement. Milo learns that Morbius is cured but becomes furious when Morbius refuses to cure him as well. While checking on a hospitalized Bancroft, Morbius finds a dead nurse, drained of her blood. Believing he was responsible, he attempts to escape before being cornered and arrested by Stroud. In prison, he is visited by Milo, who offers to use his wealth to free him. Upon realizing Milo took his cure and killed the nurse, Morbius escapes to confront him. An unrepentant Milo confesses to his bloodlust-induced crime and urges Morbius to embrace his powers as he has. Unwilling to hurt his brother, Morbius flees.
Morbius meets Bancroft to explain what Milo has done before acquiring a new lab and developing an antibody against vampirism to stop and kill Milo; he also plans to use it on himself since he will become unable to resist his bloodlust. Stroud and Rodriguez find footage of one of Milo's attacks and, believing Morbius' vampirism to be spreading, release it to the media. Nicholas recognizes Milo and pleads with him to stop. Angered by Nicholas' perceived preference for Morbius, Milo wounds and forces him to call Morbius, who arrives too late to save him while Milo also mortally wounds Bancroft. Morbius returns to Bancroft, but she dies in his arms, forcing him to drink her blood. Morbius confronts Milo and summons an army of bats to restrain him and inject the antibody. Milo dies peacefully and Morbius flies off with the bats, mourning his loved ones and embracing his identity as a vampire while coming to terms with the fact he is now on the run from the authorities. Unbeknownst to him, a still-alive Bancroft reawakens with glowing red eyes elsewhere, having ingested a drop of Morbius' blood whilst he was feeding on her.
In two mid-credits scenes, Adrian Toomes finds himself transported to Morbius' universe.[a] Having deduced that his transportation involved Spider-Man, Toomes approaches the fugitive Morbius and suggests that they form a team.[b]
Cast
- Jared Leto as Dr. Michael Morbius:
A scientist suffering from a rare blood disease whose attempts to cure himself afflict him with a form of transgenic vampirism,[7][8] gaining all of the superhuman abilities but none of the superstitious weaknesses associated with vampires. Leto was drawn to the character's struggle with his disease and the moral implications of a hero who has a thirst for blood.[9] He found the role surprisingly challenging since it was less character-driven than his prior performances and closer to his real-life personality, not requiring his well-known method acting approach.[10] Charlie Shotwell portrays a young Morbius.[11]
- Matt Smith as Lucien / Milo :
Morbius's surrogate brother, a wealthy man originally named Lucien and nicknamed by Morbius, who suffers from the same rare blood disease as he does.[12] When Milo gains the same abilities as Michael, he embraces his identity as a vampire whole-heartedly.[13] Smith was originally announced to play comic book character Loxias Crown / Hunger, but this was later changed to a significantly different character based on Morbius himself.[14] After turning down other superhero film roles, Smith joined the film due to Daniel Espinosa's involvement and encouragement from his former Doctor Who castmate Karen Gillan, who portrays Nebula in the Marvel Cinematic Universe (MCU).[15] Espinosa encouraged Smith to give a bold, villainous performance.[14] Joseph Esson portrays a young Milo.[16]
- Adria Arjona as Dr. Martine Bancroft: A scientist and Morbius' colleague.[17][18] Arjona said the character was ""the smart one in the room"" and took inspiration from politician and activist Alexandria Ocasio-Cortez.[19]
- Jared Harris as Dr. Emil Nicholas: A mentor and father figure for Morbius and Milo who runs a facility that looks after people with incurable illnesses.[20]
- Al Madrigal as Alberto ""Al"" Rodriguez: An FBI agent hunting Morbius, and Stroud's partner.[21]
- Tyrese Gibson as Simon Stroud:
An FBI agent hunting Morbius, and Rodriguez's partner.[22][21] Gibson noted that the character is white in the comic books, and the producers ""made him [Black]"" to cast Gibson. While Gibson described Stroud as a ""superhero"" with a ""hi-tech weapons-grade arm"" in the film, all scenes featuring this arm were cut.[23] Gibson signed a three-picture deal when he joined the film.[24]
Corey Johnson portrays mercenary Mr. Fox,[25] while Michael Keaton makes a cameo appearance in the mid-credits scenes as Adrian Toomes / Vulture, reprising his role from the MCU film Spider-Man: Homecoming (2017).[26]
Production
Development
Artisan Entertainment announced a deal with Marvel Entertainment in May 2000 to co-produce, finance, and distribute several films based on Marvel Comics characters, including Morbius, the Living Vampire.[27] Previously, the character was set to appear in Blade (1998), portrayed by director Stephen Norrington in a cameo appearance ahead of a larger role in a sequel. However, the character was cut from the first film and not introduced in Blade II (2002) after Norrington chose not to return for that film.[28] In May 2017, Sony announced plans for a new shared universe featuring Spider-Man-related properties beginning with Venom in October 2018;[29] this was later titled ""Sony's Spider-Man Universe"".[30] In July, Spider-Man: Homecoming (2017) director Jon Watts expressed interest in featuring Morbius and Blade in the then untitled Spider-Man: Far From Home (2019), believing that the character's dark tone could work well within the Marvel Cinematic Universe (MCU).[31] That November, Matt Sazama and Burk Sharpless submitted a script to Sony for a Morbius film, after a ""secret development process"" at the studio.[32] Jared Leto became ""loosely attached"" to star in the title role, but would not commit to the film until he was happy with its direction; Leto asked to personally meet with several director candidates.[33]
By the end of April 2018, Sony had approached Antoine Fuqua about potentially directing the film. He expressed interest in taking on the project, and said that if he was to make a film in the superhero genre he would want to make it ""something that's closer to what I get excited about.""[34] He ultimately chose not to take on the project.[33] Other directors that Sony approached about the film included F. Gary Gray, who considered directing the film but ultimately turned down the role,[35] and Daniel Espinosa, who previously directed the film Life (2017) for the studio.[33] In May, while on tour in Germany with his band Thirty Seconds to Mars, Leto met with Espinosa to talk about the film,[33] and the pair were both confirmed for the project at the end of June. Avi Arad, Matt Tolmach, and Lucas Foster were producing,[8] and filming was expected to begin by the end of 2018. Sony was expected to fit the film into its already-set Marvel release slate shortly.[33]
Pre-production
By the end of September, Sony was intending for production on the film to take place in Atlanta, Georgia—where Spider-Man: Homecoming and Venom were previously produced—but had still not set a release date for the film.[36][37] Screen Rant's Cooper Hood opined that Sony was likely waiting to see the response to Venom in early October, with Arad confirming at that time that there was excitement at Sony to produce Morbius, especially due to the story of a ""healer that becomes a killer, and how do you deal with [that?]""[37] Tolmach said the project was ""very far along"" at that stage and they were now planning to begin filming in early 2019,[38][39] with the intention that Morbius would be the second film released as part of Sony's shared universe after Venom.[38] He added that Leto was bringing the same ""intensity"" to the film that he had brought to playing the Joker in Suicide Squad (2016).[40] By November, box office analysts believed that Venom had been successful enough for Sony to move ahead with other films like Morbius,[41] and at the end of that month the studio dated an untitled Marvel film that was believed to be Morbius for a July 10, 2020, release.[42] Adria Arjona entered negotiations to portray the film's female lead, Martine Bancroft, in December;[17] her involvement was confirmed a month later when Sony pushed the release date to July 31,[18] and Matt Smith also joined the cast in an undisclosed role.[43][44] Art Marcum and Matt Holloway made uncredited contributions to the film's script.[45][46]
Filming
Principal photography began during the last week of February 2019 in London,[47][48] under the working title Plasma.[49] Oliver Wood served as cinematographer for the film.[50] With the start of filming, Jared Harris and Tyrese Gibson joined the cast as Morbius's mentor and an FBI agent hunting Morbius, respectively.[22][51][52] Smith was reported to be portraying the villainous Loxias Crown / Hunger,[22] though he was later revealed to be playing an original character named Milo who is similar to Loxias Crown.[14] Harris was revealed to be portraying Dr. Nicholas, a mentor and father figure to both Michael and Milo.[20] In March, filming took place in Manchester's Northern Quarter, doubling for New York City.[53] A month later, Gibson revealed that he was portraying Simon Stroud, and that Al Madrigal had been cast as his partner, Alberto Rodriguez.[21] At the end of the month, Justin Haythe was believed to have contributed to the film's script.[54] Filming was scheduled to take 12 weeks,[15][47] and Venom producer Amy Pascal said in June that production had ""just wrapped"" on the project.[55] Production also occurred at Pinewood Studios.[56]
Post-production
In September 2019, Sony announced a new agreement with Disney that extended a previous deal to have Marvel Studios and its president Kevin Feige produce a sequel to Far From Home, keeping Spider-Man in Marvel's shared universe, the Marvel Cinematic Universe. As part of the new agreement, Feige stated that moving forward the MCU's Spider-Man would be able to ""cross cinematic universes"" and appear in Sony's own shared universe as well.[57] This interaction was said to be ""a 'call and answer' between the two franchises as they acknowledge details between the two in what would loosely be described as a shared detailed universe"".[58] The film's first trailer, released in January 2020, included a brief appearance by Michael Keaton, reprising his role as Adrian Toomes / Vulture from the co-produced Marvel Studios Spider-Man film Spider-Man: Homecoming.[26][59] Some of Keaton's scenes had to be reshot when the events depicted in Spider-Man: No Way Home (2021) did not properly coincide with Morbius. Certain moments, such as Morbius walking past a graffiti painting of Spider-Man, were added in the film without Espinosa's knowledge, only to be removed in the final film.[60]
Reshoots for the film began in Los Angeles by early February 2020,[61] and were finished a month later when film productions around the United States were halted due to the COVID-19 pandemic.[62] At the end of March, the film's release date was pushed back to March 19, 2021, due to the pandemic closing theaters around the world.[63] In January 2021, the film was delayed again, first to October 8, 2021, and then to January 21, 2022, when No Time to Die was moved to the October 2021 date.[64] At the end of January, Leto revealed that additional reshoots were taking place in mid-February.[65] The film's release was moved back another week at the end of April 2021, moving to January 28, 2022.[64] At the start of January 2022, the film was delayed to April 1, 2022, due to the box office success of Spider-Man: No Way Home which Sony hoped would continue throughout early 2022.[66] Later that month, Corey Johnson was revealed to have a role in the film.[25] In March, visual effects supervisor Matthew E. Butler revealed that motion capture technology had been used for Leto to portray Morbius's vampiric form.[67] Espinosa cited Pokémon as an influence on the portrayal of Morbius's powers, specifically singling out the series's use of light and color to depict the title creatures' attacks and abilities.[68]
Music
By October 2019, Jon Ekstrand was set to compose the score for Morbius after doing the same for Espinosa's previous films.[69] Ekstrand's score was released digitally by Madison Gate Records on April 8, 2022.[70]
Marketing
The teaser trailer for the film was released on January 13, 2020.[9] Julia Alexander at The Verge described the premise of the film as presented by the trailer as ""ridiculous"",[71] while Matt Goldberg of Collider felt it looked ""silly"" and also noted that the film looked very similar to Venom, which he acknowledged was commercially successful.[72] Scott Mendelson, writing for Forbes, agreed with the comparison to Venom which he felt was a good move by Sony due to the success of their last few Spider-Man films, but cautioned that Leto may not have the same box office draw for general audiences that Tom Hardy gave to Venom.[73] Much of the discussion surrounding the trailer centered on the revelation of Keaton's role and the visual reference to Spider-Man, which led to questions about the film's relationship with the Spider-Man films and the wider Marvel Cinematic Universe.[9][74][71][72] A second trailer was released on November 2, 2021, and led to further confusion and speculation about the film's connections to other franchises. Fans and commentators noted that the trailer, in addition to the Venom films, also references Sam Raimi's Spider-Man trilogy, Marc Webb's The Amazing Spider-Man films, and the MCU Spider-Man films despite all three franchises being set in different fictional universes.[75][76][77][78] Prior to the film's theatrical release, Espinosa clarified that Morbius is set in the same universe as the SSU Venom films.[6]
In March 2022, Sony used their The Daily Bugle promotional TikTok account, previously used for Spider-Man: No Way Home, to market Morbius; the videos feature Nicque Marina reporting on events relative to the film.[79]
Release
Theatrical
Morbius had its world premiere at the Plaza Carso in Mexico City on March 10, 2022,[80][81] and was released in the United States on April 1, 2022, in IMAX and other premium large formats.[66] It was originally set for release on July 10, 2020,[18][42] before moving three weeks later to July 31.[18] The film was then delayed due to the COVID-19 pandemic, firstly to March 19, 2021,[63] then to October 8, 2021, and to January 21, 2022, before moving a week later to January 28.[64] It was then delayed again to the April 2022 date.[66] Sony chose not to release the film in Russia due to the 2022 Russian invasion of Ukraine.[82]
The negative reception toward the film generated an ironic meme culture surrounding it with ""praise"", which led Sony to re-release it into 1,000 theaters on June 3, 2022.[83] This re-release also performed poorly, making just $280,000 over the weekend.[84][85]
Home media
Sony signed deals with Netflix and Disney in April 2021 for the U.S. streaming and TV rights to their 2022 to 2026 film slate, following the films' theatrical and home media windows.[86][87] Netflix signed for exclusive ""first pay window"" streaming rights, which is typically an 18 month window and included future Marvel films in Sony's Spider-Man Universe.[86] Morbius began streaming on Netflix starting September 7, 2022.[88] Disney signed for ""pay 2 window"" rights for the films, which would be streamed on Disney+ and Hulu as well as broadcast on Disney's linear television networks.[87][89] Morbius was released on digital download on May 17, 2022, and was released on Blu-ray, DVD, and 4K Ultra HD on June 14 by Sony Pictures Home Entertainment.[90]
Reception
Box office
Morbius grossed $74 million in the United States and Canada, and $90 million in other territories, for a worldwide total of $164 million.[5][4]
In the U.S. and Canada, Morbius was projected to gross around $33 million from 4,268 theaters in its opening weekend, with some industry tracking going as high as $40–50 million.[91] The film earned $17.3 million on its first day, including $5.7 million from Thursday preview screenings.[3][92] It went on to debut to $39 million, finishing first at the box office.[3][93] In its second weekend of release in the US and Canada, the film grossed $10.2 million and finished second behind Sonic the Hedgehog 2,[94] while experiencing a drop of 74%, the second-worst of all time for a superhero movie, behind only Steel (1997), and the worst of any tentpole superhero movie.[95] It fell to sixth place at the box office in its third weekend, grossing $4.7 million (a drop of 54%),[96] and dropped to ninth place in its fourth weekend with $2.3 million (a drop of 51%).[97] The film earned $1.5 million in its fifth weekend, finishing tenth.[98] Morbius dropped out of the box office top ten in its sixth weekend.[99] The film's ""re-release"" in theaters during its tenth weekend made $310,665 from 1,037 screens during its first three days.[100]
Outside the US and Canada, the film earned $44.9 million from 62 international markets in its opening weekend, including $2.5 million from IMAX screens.[101] It added $15 million in its second weekend for a drop of 62%.[102] It added $6.7 million in the third weekend,[103] $3.3 million in its fourth,[104] and $1.6 million in its fifth.[105]
On June 3, 2022, Sony announced the film would return to 1,000 theaters weeks after its initial theatrical and digital release. This was largely attributed to the film's influx in attention from internet memes in the weeks prior.[106] This decision was also met with criticism from various outlets, which speculated that the release was because Sony was unaware that the internet trend was not due to legitimate popular admiration towards the film.[107][108] Upon its re-release the film performed very poorly, making only $85,000 on the day it was released, with many outlets claiming the film bombed for a second time.[109][110] After a dismal $300,000 weekend performance in its re-release—a $289 per-theater average—Sony pulled the film entirely from theaters.[111][5]
Critical response
On Rotten Tomatoes, the film has an approval rating of 15% based on 272 reviews, with an average rating of 3.8/10. The website's critics consensus reads, ""Cursed with uninspired effects, rote performances, and a borderline nonsensical story, this dreary mess is a vein [sic] attempt to make Morbius happen.""[112] It ranks as the 16th worst-reviewed superhero movie on the site.[113] Metacritic assigned the film a weighted average score of 35 out of 100 based on 55 critics, indicating ""generally unfavorable reviews"".[114] Indo-Asian News Service described the film as having been ""utterly ravaged"" by critics,[115] and Variety reported reception as being ""comically bad"".[116] Jonathon Crump of Manchester Evening News reported that early reviews to the film are mixed at best, although he noted that some critics ""praised the acting in the film, including Leto's performance"".[117] Variety's Ellise Shafer also said while the reviews were negative overall, Smith ""did receive some praise for his performance"".[118] Audiences polled by CinemaScore gave the film an average grade of ""C+"" on an A+ to F scale, while those at PostTrak gave it a 62% positive score (with an average 2.5 out of 5 stars), with 47% saying they would definitely recommend it.[3] The C+ score is the second-worst of any Marvel adaptation, ahead of only Fantastic Four (2015).[119]
Reviewing the film for Collider, Emma Kiely felt that the ""central problem of Morbius is a lazy and uninspiring script"" and added that ""no weight or depth is given to any character."" She also noted that there is ""little humor"" in the film and ""when it tries to make a tongue-in-cheek joke, it fails miserably.""[120] Barry Hertz of The Globe and Mail panned the film, saying it ""is charmless, incoherent, ugly and so aggressively stupid that it defies any attempt to shove it into the desperate 'guilty pleasure' box.""[121] Wendy Ide of The Observer gave the film 1 out of 5 stars, calling it an ""incoherent, vampire-themed Marvel offcut.""[122] Hannah Strong of Little White Lies also gave the film 1 out of 5 stars, describing it as ""soulless, tedious filmmaking"".[123] Richard Roeper of the Chicago Sun-Times awarded the film 2 out of 4 stars, saying: ""It looks like Morbius might soon cross paths with Spider-Man in one universe or another, but that would be a big step up for him, because his introductory vehicle feels more like a just-average 1990s vampire movie.""[124] Mick LaSalle of the San Francisco Chronicle awarded the film a 3 out of 4 and called the film ""briskly riveting"" and a ""perfect antidote to bloated The Batman"".[125] Chris Bumbray of JoBlo.com gave the film a 6 out of 10 and called it ""a decent enough start for the latest addition to the Sony Spider-Man Universe"" while also praising the cinematography and ""horror aspects"" of the plot.[126]
Leah Greenblatt of Entertainment Weekly gave the film a B grade, saying that Leto ""hits the right notes of fear and longing in a surprisingly restrained performance"".[127] Stephanie Zacharek of Time commended Leto's performance writing that it has a ""quietly vibrating vulnerability"".[128] The Hollywood Reporter's David Rooney said the film ""only intermittently matches the intensity"" of Leto's performance and wrote: ""It's just a shame this opening salvo takes itself too seriously to have much fun with the mayhem, despite the potential in Smith's devilish turn for amusing interplay between the antagonists.""[129] Matt Donato of IGN, who awarded the film a 5 out of 10, praised Smith's performance for providing a ""colorfulness the film desperately needs"", saying that his ""flamboyance and spirit is the antithesis to Leto's drearily dour genius, which is a purposeful but inefficient comparison"", and unfavorably compared Leto's solemn performance to Tom Hardy's ""campy"" performance in the Venom films.""[130]
The post-credits scenes also came under heavy scrutiny.[131] Kate Erbland of IndieWire stated, ""This is confusing stuff, and the appearance of Keaton in a pair of [mid-credits] scenes does little to help the sense that Morbius is mostly incoherent, or at least very at odds with whatever it's trying to say.""[132] Paul Tassi of Forbes said that Adrian Toomes' motivation made little sense and opined that ""[a]ll of this seems... pretty poorly mapped out at the moment... It's more like [Sony] stole Toomes from the MCU rather than added Morbius to the MCU, which was more the original implication.""[133] Julia Glassman of The Mary Sue found the overall reveal weak, stating, ""I'm beginning to wonder if Sony just... doesn't quite get the point of [mid-credits] scenes.""[134] Time Out's Cathy Brennan felt that the film's ""attempts"" to ""court an audience by dangling a potential connection"" to the MCU's Spider-Man is ""the worst kind of unearned fan service in a film this lacklustre.""[135]
Internet memes
Due to its lackluster box office performance and dour critical reception, Morbius inspired various internet memes.[136] Polygon wrote that the film became ""a kind of collective internet hate watch"",[137] with fans sharing meme shitposts which ironically praised it.[136][138][139][140][141] Following its release, the hashtag #MorbiusSweep, which jokingly claimed Morbius was the most financially and critically successful film of all time, began trending.[142] Claims included the film becoming the first to sell over a trillion tickets,[143] the first to make over a ""morbillion"" dollars,[144] receiving an impossible 203% or higher approval rating (and similarly-impossible 142% or higher audience rating) from Rotten Tomatoes,[145] and an edited screenshot of the Wikipedia page covering the highest-grossing films claiming Morbius had earned $352.9 trillion.[139] One such post made the claim that Martin Scorsese, who had previously declared that superhero films were not cinema, had changed his mind after seeing the film; this fake quote was shared on Instagram by Morbius actor Tyrese Gibson under the belief it was genuine, later being deleted.[146]
The film received a resurgence in internet memes following its release to video on demand, with many involving the fake catchphrase ""it's Morbin' time"",[147][148][149] a play on the Power Rangers catchphrase ""it's Morphin' time"".[150][151] Users on the film's official Discord server call themselves ""Morbheads"",[143] and users engaged in ""Morbin'"" on various Discord servers by distributing pirated copies.[152] A large number of channels on the live-streaming service Twitch began illegally hosting the entire film on repeat;[149][153] one channel, Morbius247, was banned after acquiring thousands of followers.[154] Morbius piracy spread to other platforms, including Twitter, where the entire film was posted in a series of 52 two-minute long videos, compressed into a 30-second long video, and the entire script copy-and-pasted into individual tweets.[155][156] On Tumblr, the entire film was compressed into a very tiny GIF file and widely spread.[137] Additionally, viral fake news posts claiming that a Morbius sequel had been greenlit as a result of the internet memes spread on Twitter,[157][158] leading to ""Morbius 2"" to trend on the website,[159][160] in addition to the phrase ""it's Morbin' time"" trending on Twitter for a week.[161]
Leto, in response to the memes, tweeted ""What time is it?"" and a 19-second video where he was ""caught"" reading a script titled Morbius 2: It's Morbin' Time ""written"" by himself under the pseudonym Bartholomew Cubbins.[162][163] Following the financial failure of the rerelease, a petition was started on Change.org to put the film back in theaters for a third time with the claim that ""we were busy that weekend"".[164]
Future
In January 2021, Leto said there was potential for Morbius to appear alongside the character Blade in a future project, with Mahershala Ali cast in that role for the Marvel Cinematic Universe (MCU).[165] That December, in discussing the introduction of the multiverse in Spider-Man: No Way Home (2021), Leto said there was potential for further crossovers with his character in future films.[166] Tom Holland expressed interest in seeing his version of Spider-Man from the MCU fighting Morbius in the future,[167] while producers Kevin Feige and Amy Pascal confirmed interest in a potential film starring both Leto and Ali.[168] In March 2022, Leto also expressed interest in a future film featuring Morbius appearing alongside Venom, portrayed by Tom Hardy.[169] During CinemaCon 2022, Sony announced numerous Marvel projects. Some outlets noted that while Venom 3 and Spider-Man: Beyond the Spider-Verse (2024) were announced, there was no announcement for a Morbius sequel, leaving the character's future in question.[170][171]
Notes
- ^ Toomes is transported from the Marvel Cinematic Universe to Sony's Spider-Man Universe due to the events of the film Spider-Man: No Way Home (2021).[6]
- ^ Identified off-screen as the Sinister Six.[6]
References
- ^ Grierson, Tim (March 30, 2022). ""Morbius: Review"". Screen Daily. Archived from the original on March 31, 2022. Retrieved March 31, 2022.
- ^ ""Morbius (2022)"". Irish Film Classification Office. Archived from the original on March 26, 2022. Retrieved March 14, 2022.
- ^ a b c d D'Alessandro, Anthony (April 3, 2022). ""Morbius Shaves Teeth To $39M+ Opening – Sunday AM Box Office Update"". Deadline Hollywood. Archived from the original on April 2, 2022. Retrieved April 3, 2022.
- ^ a b ""Morbius"". Box Office Mojo. IMDb. Retrieved June 17, 2022.
- ^ a b c ""Morbius"". The Numbers. Nash Information Services, LLC. Retrieved June 17, 2022.
- ^ a b c O'Connell, Sean (March 25, 2022). ""Here's How Spider-Man, Venom And The Multiverse Will Factor Into Jared Leto's Morbius Movie"". CinemaBlend. Archived from the original on March 25, 2022. Retrieved March 26, 2022.
- ^ Ramirez II, Hector (January 14, 2020). ""Morbius: Sony Releases Spider-Verse Vampire Film's Official Summary"". Comic Book Resources. Archived from the original on January 15, 2020. Retrieved January 18, 2020.
- ^ a b Fleming, Mike Jr. (June 27, 2018). ""Jared Leto, Daniel Espinosa Team For Sony's 'Morbius' Spider-Man Spinoff"". Deadline Hollywood. Archived from the original on March 20, 2022. Retrieved March 26, 2022.
- ^ a b c Yehl, Joshua (January 14, 2020). ""Morbius Trailer First Look: Jared Leto Talks Debut as the Iconic Marvel Monster"". IGN. Archived from the original on January 15, 2020. Retrieved January 18, 2020.
- ^ Variety (January 28, 2021). Jared Leto & John David Washington on 'Tenet,' 'Little Things' And More | Actors on Actors. YouTube. Archived from the original on January 7, 2022. Retrieved January 7, 2022.
- ^ Gressley, Abbie (April 4, 2022). ""10 Movies And TV Shows Where You've Seen The Cast Of Morbius"". Screen Rant. Archived from the original on April 5, 2022. Retrieved April 4, 2022.
- ^ Sim, Jonathan (April 4, 2022). ""Morbius Review: An Overly Serious and Nonsensical Superhero Film"". Mandatory. Archived from the original on April 7, 2022. Retrieved April 7, 2022 – via ComingSoon.net.
- ^ Morales, Wilson (March 26, 2022). Interview: Matt Smith on playing Milo Morbius in Morbius. Blackfilmandtv. Archived from the original on April 13, 2022. Retrieved April 7, 2022 – via YouTube.
- ^ a b c Dominguez, Noah (February 26, 2022). ""Morbius Radically Changes Matt Smith's Spider-Man Villain"". Comic Book Resources. Archived from the original on February 26, 2022. Retrieved March 13, 2022.
- ^ a b Zemler, Emily (March 5, 2019). ""Matt Smith leaves 'The Crown' behind for Charles Manson and Robert Mapplethorpe"". Los Angeles Times. Archived from the original on March 7, 2019. Retrieved March 10, 2019.
- ^ Van Gelder Grant, Conway [@CVGG] (January 13, 2020). ""Your first glimpse at @MorbiusMovie, with Joseph Esson as the Young Loxias"" (Tweet). Archived from the original on January 15, 2020. Retrieved October 3, 2021 – via Twitter.
- ^ a b Couch, Aaron (December 14, 2018). ""'Morbius': Adria Arjona in Early Talks to Join Jared Leto"". The Hollywood Reporter. Archived from the original on March 24, 2022. Retrieved March 26, 2022.
- ^ a b c d Hipes, Patrick (January 25, 2019). ""'Morbius' & 'Ghostbusters' Solidify Summer 2020 Release Dates"". Deadline Hollywood. Archived from the original on January 26, 2019. Retrieved February 24, 2019.
- ^ Liu, Narayan (February 27, 2022). ""Morbius Star Channeled Congresswoman AOC for the Spider-Man Spinoff"". Comic Book Resources. Archived from the original on February 27, 2022. Retrieved March 13, 2022.
- ^ a b Provencher, Bo (February 27, 2022). ""Morbius Finally Reveals a Key Character's Name, Role in the Story"". Comic Book Resources. Archived from the original on February 27, 2022. Retrieved March 13, 2022.
- ^ a b c ""He just wrapped for that day.... I come back to our shared tent and once again he ate ALL the snacks... I can't sleep around this dude cause he's funny as hell and I guess he really didn't think I would notice that he's eating everything in sight.... My #PIC partner in crime aka Agent Alberto Rodriguez aka @almadrigal the bad guys are doomed!!!! #Marvel #Morbius #SetLife #AgentSimonStroud"". Instagram. April 19, 2019. Archived from the original on December 23, 2021. Retrieved May 4, 2019.
- ^ a b c Kit, Borys (March 5, 2019). ""Tyrese Gibson in Talks to Join Jared Leto in Spider-Man Spinoff 'Morbius'"". The Hollywood Reporter. Archived from the original on March 6, 2019. Retrieved March 10, 2019.
- ^ Riefe, Jordan (April 23, 2020). ""Tyrese Gibson Talks 'F9' and Becoming a Superhero for Marvel's 'Morbius'"". Maxim. Archived from the original on April 26, 2020. Retrieved April 25, 2020.
- ^ Gibson, Tyrese (March 11, 2019). ""When you sign the deal........ ""God blesses those who are humble, for they will inherit the whole earth"" - Matthew 5:5 ► - 3 picture #Marvel deal.... #Morbius #Humbled #Grateful been praying for a breakthrough had no idea that it was going to come on this level.... Thank you Jesus! #Amen #LondonUK"". Instagram. Archived from the original on December 23, 2021. Retrieved March 12, 2019.
- ^ a b Kit, Borys (January 13, 2022). ""HBO Max's 'Batgirl' Movie Adds Rebecca Front, Corey Johnson, and Ethan Kai (Exclusive)"". The Hollywood Reporter. Archived from the original on January 13, 2022. Retrieved January 13, 2022.
- ^ a b Keegan, Rebecca (August 18, 2021). ""Michael Keaton on Reviving Batman and the Power of Saying No to Hollywood"". The Hollywood Reporter. Archived from the original on August 18, 2021. Retrieved August 18, 2021.
- ^ Fleming, Michael (May 16, 2000). ""Artisan deal a real Marvel"". Variety. Archived from the original on March 15, 2022. Retrieved March 26, 2022.
- ^ Brehmer, Nat (January 16, 2020). ""Breaking Down the Deleted 'Blade' Ending Featuring Morbius and Why We Never Got That Sequel"". Bloody Disgusting. Archived from the original on January 17, 2020. Retrieved August 20, 2020.
- ^ Busch, Anita (May 19, 2017). ""Tom Hardy Is 'Venom' In New Sony Marvel Film To Be Directed By Ruben Fleischer"". Deadline Hollywood. Archived from the original on October 5, 2021. Retrieved March 26, 2022.
- ^ Kim, Brendan (August 24, 2021). ""Sony's Spider-Man Universe Is Official Title For Non-MCU Marvel Movies"". Screen Rant. Archived from the original on August 24, 2021. Retrieved August 24, 2021.
- ^ Jones, Jordan (July 6, 2017). ""Jon Watts on the possibility of Morbius, Blade and The Chameleon in Spider-Man: Homecoming 2"". Flickering Myth. Archived from the original on January 4, 2022. Retrieved December 7, 2021.
- ^ Kit, Borys (November 13, 2017). ""'Spider-Man' Spinoff: Morbius the Living Vampire Movie in the Works With 'Power Rangers' Writers"". The Hollywood Reporter. Archived from the original on March 20, 2022. Retrieved March 26, 2022.
- ^ a b c d e Kroll, Justin (June 27, 2018). ""Jared Leto to Star in 'Spider-Man' Spinoff 'Morbius' From Director Daniel Espinosa"". Variety. Archived from the original on March 20, 2022. Retrieved March 26, 2022.
- ^ Shirey, Paul (April 24, 2018). ""EXC. Antoine Fuqua Talks Potential For a Morbius or Blade Film at CinemaCon"". JoBlo.com. Archived from the original on October 22, 2021. Retrieved March 26, 2022.
- ^ Timberlake, Braxter (May 25, 2018). ""Exclusive: Plot Details for Sony's 'Morbius' Spider-Verse Spin-Off"". That Hashtag Show. Archived from the original on June 13, 2018. Retrieved September 30, 2018.
- ^ Marc, Christopher (September 6, 2018). ""Update: Jared Leto's Marvel Movie 'Morbius' Eyes Shoot in Atlanta this Fall/Winter"". The GWW. Archived from the original on March 7, 2022. Retrieved March 26, 2022.
- ^ a b Hood, Cooper (September 28, 2018). ""Why Sony is Excited About The Morbius Movie"". Screen Rant. Archived from the original on September 17, 2021. Retrieved March 26, 2022.
- ^ a b Wood, Matt (September 29, 2018). ""Sounds Like Morbius Could Be The Next Spiderverse Movie Made After Venom"". CinemaBlend. Archived from the original on September 17, 2021. Retrieved March 26, 2022.
- ^ Trumbore, Dave (October 9, 2018). ""'Morbius' Filming Details Revealed by Producers Avi Arad and Matt Tolmach"". Collider. Archived from the original on December 7, 2021. Retrieved March 26, 2022.
- ^ Bonomolo, Cameron (September 28, 2018). ""'Morbius' Producers Praise Star Jared Leto"". ComicBook.com. Archived from the original on January 26, 2021. Retrieved March 26, 2022.
- ^ Clark, Travis (November 6, 2018). ""Venom' gives Sony an edge over Disney in its fight to keep 'Spider-Man,' according to industry experts"". Business Insider. Archived from the original on November 5, 2021. Retrieved March 26, 2022.
- ^ a b Donnelly, Matt (November 21, 2018). ""Sony Dates Two Marvel Movies for 2020"". Variety. Archived from the original on November 23, 2021. Retrieved March 26, 2022.
- ^ Couch, Aaron (January 24, 2019). ""Matt Smith Joining Jared Leto in 'Morbius'"". The Hollywood Reporter. Archived from the original on March 20, 2022. Retrieved March 26, 2022.
- ^ Kroll, Justin (January 24, 2019). ""Matt Smith to Star With Jared Leto in Marvel Spinoff 'Morbius' (Exclusive)"". Variety. Archived from the original on January 25, 2019. Retrieved February 24, 2019.
- ^ Barnhardt, Adam (January 13, 2020). ""Morbius Taps Iron Man Writers for Rewrites"". ComicBook.com. Archived from the original on January 14, 2020. Retrieved January 18, 2020.
- ^ ""Morbius"". Writers Guild of America, West. December 18, 2020. Archived from the original on January 3, 2021. Retrieved January 3, 2021.
- ^ a b Leto, Jared [@JaredLeto] (March 5, 2019). ""1 week down...11 to go... Get Ready 💪 #MORBIUS @MorbiusMovie"" (Tweet). Archived from the original on March 6, 2019. Retrieved March 10, 2019 – via Twitter.
- ^ Zinski, Dan (February 11, 2019). ""Morbius Star Jared Leto Teases Start Of Filming In London"". Screen Rant. Archived from the original on February 12, 2019. Retrieved February 24, 2019.
- ^ Mueller, Matthew (November 22, 2018). ""'Morbius The Living Vampire' Working Title Revealed"". ComicBook.com. Archived from the original on November 26, 2018. Retrieved March 26, 2022.
- ^ Discussing Film [@DiscussingFilm] (October 14, 2018). ""Cinematographer Oliver Wood ('The Equalizer 2', 'Fantastic Four') has joined the crew as cinematographer for Daniel Espinosa's 'Morbius'. (Exclusive)"" (Tweet). Archived from the original on September 27, 2019. Retrieved September 27, 2019 – via Twitter.
- ^ N'Duka, Amanda (March 4, 2019). ""Jared Harris Joins Jared Leto In Sony's 'Spider-Man' Spinoff 'Morbius'"". Deadline Hollywood. Archived from the original on March 5, 2019. Retrieved March 10, 2019.
- ^ Kroll, Justin (March 5, 2019). ""Tyrese Gibson Joins Jared Leto in Marvel Spinoff 'Morbius' (Exclusive)"". Variety. Archived from the original on March 6, 2019. Retrieved March 10, 2019.
- ^ ""Manchester given a New York City makeover for filming of Spider-Man spin-off Morbius"". Sky News. March 26, 2019. Archived from the original on March 26, 2019. Retrieved March 29, 2019.
- ^ Polito, Thomas (March 18, 2019). ""Exclusive: 'Red Sparrow' Scribe Justin Haythe Contributed to 'Morbius' Script for Sony"". Geeks WorldWide. Archived from the original on September 27, 2019. Retrieved September 27, 2019.
- ^ Dumaraog, Ana (June 22, 2019). ""Future Spider-Man Spinoff Movies Will Stand On Their Own"". Screen Rant. Archived from the original on June 22, 2019. Retrieved September 27, 2019.
- ^ ""Morbius"". Pinewood Studios. Archived from the original on May 18, 2022. Retrieved June 5, 2022.
- ^ Lang, Brent (September 27, 2019). ""Sony, Marvel Make Up: Companies Will Produce Third 'Spider-Man' Film"". Variety. Archived from the original on September 27, 2019. Retrieved September 27, 2019.
- ^ D'Alessandro, Anthony (September 27, 2019). ""Spider-Man Back In Action As Sony Agrees To Disney Co-Fi For New Movie, Return To MCU: How Spidey's Web Got Untangled"". Deadline Hollywood. Archived from the original on September 27, 2019. Retrieved September 27, 2019.
- ^ Boucher, Geoff (January 13, 2020). ""'Morbius' Teaser: Jared Leto Sinks Teeth Into Marvel Vampire Role"". Deadline Hollywood. Archived from the original on January 14, 2020. Retrieved January 18, 2020.
- ^ Ryan, Mike (April 4, 2022). ""'Morbius' Director Daniel Espinosa On What The Heck Happened Here"". Uproxx. Archived from the original on April 4, 2022. Retrieved April 4, 2022.
- ^ Barnhardt, Adam (February 9, 2020). ""Morbius Set Photos Suggest Stronger Spider-Man Presence"". ComicBook.com. Archived from the original on February 10, 2020. Retrieved February 10, 2020.
- ^ a b Galuppo, Mia (March 30, 2020). ""Sony Delays Release of 'Morbius,' 'Ghostbusters,' More Films Due to Coronavirus"". The Hollywood Reporter. Archived from the original on March 31, 2020. Retrieved March 30, 2020.
- ^ a b c D'Alessandro, Anthony (April 30, 2021). ""Sony Marvel Movie 'Morbius' Shifts A Week Later Next Winter"". Deadline Hollywood. Archived from the original on May 1, 2021. Retrieved May 1, 2021.
- ^ Cranswick, Amie (January 31, 2021). ""Morbius to undergo more reshoots as Jared Leto hints at script issues"". Flickering Myth. Archived from the original on February 27, 2021. Retrieved February 27, 2021.
- ^ a b c Grobar, Matt (January 4, 2022). ""'Morbius': Sony Pushes Release Date For Jared Leto's Marvel Film"". Deadline Hollywood. Archived from the original on January 4, 2022. Retrieved January 4, 2022.
- ^ Miller, Leon (March 1, 2022). ""Morbius Uses Avengers' Thanos VFX Tech to Bring the Living Vampire to Life"". Comic Book Resources. Archived from the original on March 1, 2022. Retrieved March 13, 2022.
- ^ Leston, Ryan (March 17, 2022). ""Exclusive: Morbius Director Took Inspiration From Pokémon"". IGN. Archived from the original on March 28, 2022. Retrieved March 27, 2022.
- ^ ""Jon Ekstrand to Score Daniel Espinosa's 'Morbius'"". Film Music Reporter. October 9, 2019. Archived from the original on October 10, 2019. Retrieved October 10, 2019.
- ^ ""'Morbius' Soundtrack Album Released"". Film Music Reporter. April 8, 2022. Archived from the original on April 8, 2022. Retrieved April 16, 2022.
- ^ a b Alexander, Julia (January 13, 2020). ""Sony's first Morbius trailer is as ridiculous as 'pseudo-vampire Marvel villain played by Jared Leto' sounds"". The Verge. Archived from the original on January 13, 2020. Retrieved January 18, 2020.
- ^ a b Goldberg, Matt (January 13, 2020). ""Jared Leto Goes Full Angsty Bloodsucker in the 'Morbius' Trailer"". Collider. Archived from the original on January 13, 2020. Retrieved January 18, 2020.
- ^ Mendelson, Scott (January 13, 2020). ""'Morbius' Trailer Tries To Show That 'Venom' Was No Fluke At The Box Office"". Forbes. Archived from the original on January 14, 2020. Retrieved January 18, 2020.
- ^ Newby, Richard (January 13, 2020). ""How 'Morbius' Can Build to a Spider-Man Crossover Movie"". The Hollywood Reporter. Archived from the original on January 13, 2020. Retrieved January 18, 2020.
- ^ Welch, Alex (November 3, 2021). ""'Morbius' trailer reveals its connections to Venom and Spider-Man"". Inverse. Archived from the original on February 15, 2022. Retrieved February 14, 2022.
- ^ Sonnack, Matthew (November 2, 2021). ""Every Spider-Verse Reference in Morbius' Second Trailer"". Comic Book Resources. Archived from the original on November 3, 2021. Retrieved February 14, 2022.
- ^ Fuge, Jonathan (November 3, 2021). ""Spider-Man References in New Morbius Trailer Leave Marvel Fans Excited and Confused"". MovieWeb. Archived from the original on November 3, 2021. Retrieved February 14, 2022.
- ^ Langmann, Brandon (November 3, 2021). ""What the Multiversal Hell is Happening in the 'Morbius' Trailer?"". Esquire. Archived from the original on April 26, 2022. Retrieved February 14, 2022.
- ^ Standley, Scott (March 18, 2022). ""Sony's Daily Bugle TikTok Video Sets Up Jared Leto's Morbius"". Screen Rant. Archived from the original on March 21, 2022. Retrieved March 21, 2022.
- ^ Larson, Tara (March 11, 2022). ""Jared Leto Goes Wild With Adria Arjona at 'Morbius' Premiere"". Footwear News. Archived from the original on April 1, 2022. Retrieved March 13, 2022.
- ^ ""Jared Leto visita la CdMx para la premiere de 'Morbius'"". Milenio (in Spanish). March 10, 2022. Archived from the original on March 13, 2022. Retrieved March 13, 2022.
- ^ Cain, Sian (March 1, 2022). ""Disney, Sony and Warner Bros pause film releases in Russia over Ukraine invasion"". The Guardian. Archived from the original on March 1, 2022. Retrieved March 6, 2022.
- ^ ""Morbius Bombed - But It's Returning To Theaters After Marvel Memes"". ScreenRant. June 2, 2022. Archived from the original on June 4, 2022. Retrieved June 4, 2022.
- ^ Mendelson, Scott. ""Box Office: 'Morbius' Bombs Again With $85,000 Friday"". Forbes. Archived from the original on June 4, 2022. Retrieved June 10, 2022.
- ^ Gallagher, Tim (June 7, 2022). ""Is it 'Morbin Time?' 'Morbius' mocked again after its re-release"". euronews. Archived from the original on June 10, 2022. Retrieved June 10, 2022.
- ^ a b Galuppo, Mia (April 8, 2021). ""Netflix Nabs Post-PVOD Streaming Rights to Sony's Feature Films in Multiyear Deal"". The Hollywood Reporter. Archived from the original on April 8, 2021. Retrieved April 9, 2021.
- ^ a b Hayes, Dade (April 21, 2021). ""Disney And Sony Reach Windows Deal That Can Sling 'Spider-Man' To Disney+ For First Time, Along With Reach Across Hulu, ABC, FX & More"". Deadline Hollywood. Archived from the original on April 21, 2021. Retrieved April 21, 2021.
- ^ Perine, Aaron (September 7, 2022). ""Morbius Is Now on Netflix"". ComicBook.com. Archived from the original on September 7, 2022. Retrieved September 7, 2022.
- ^ Couch, Aaron (April 21, 2021). ""Sony Films Will Move to Disney After Netflix Window Expires"". The Hollywood Reporter. Archived from the original on April 21, 2021. Retrieved April 21, 2021.
- ^ Weinstein, Molly Jae (May 2, 2022). ""Morbius Blu-ray Release Date & Special Features Revealed"". Screen Rant. Archived from the original on May 3, 2022. Retrieved May 3, 2022.
- ^ D'Alessandro, Anthony (March 29, 2022). ""'Morbius': Sony Sinking Teeth This Weekend Into Deeper Part Of The Marvel Genre Canon – Box Office Preview"". Deadline Hollywood. Archived from the original on March 29, 2022. Retrieved March 29, 2022.
- ^ Crow, David (April 4, 2022). ""Morbius Box Office Leaves Sequel in Scary Place"". Den of Geek. Archived from the original on April 4, 2022. Retrieved April 5, 2022.
- ^ Adario Strange (April 4, 2022). """"Morbius"" showed Sony the limits of Spider-Man's cinematic web"". Quartz. Archived from the original on April 6, 2022. Retrieved April 6, 2022.
- ^ D'Alessandro, Anthony (April 10, 2022). ""Sonic The Hedgehog 2 Goes Faster To $71M; What Ambulance's Misfire Means For Action Movies Today — Sunday Box Office Update"". Deadline Hollywood. Archived from the original on April 10, 2022. Retrieved April 10, 2022.
- ^ Scott Mendelson (April 10, 2022). ""Box Office: Morbius Suffers Record 74% Drop As Fantastic Beasts 3 Opens Soft Overseas"". Forbes. Archived from the original on April 10, 2022. Retrieved April 11, 2022.
- ^ ""Domestic 2022 Weekend 15"". Box Office Mojo. Archived from the original on April 19, 2022. Retrieved April 19, 2022.
- ^ ""Domestic 2022 Weekend 16"". Box Office Mojo. Archived from the original on April 26, 2022. Retrieved April 26, 2022.
- ^ ""Domestic 2022 Weekend 17"". Box Office Mojo. Archived from the original on May 1, 2022. Retrieved May 2, 2022.
- ^ ""Domestic 2022 Weekend 18"". Box Office Mojo. Archived from the original on May 10, 2022. Retrieved May 10, 2022.
- ^ ""Domestic 2022 Weekend 22"". Box Office Mojo. Archived from the original on June 7, 2022. Retrieved June 7, 2022.
- ^ Tartaglione, Nancy (April 3, 2022). ""Morbius Sinks Fangs Into $84M Global Bow; Sonic Booms Overseas; The Batman Wings Past $700M WW – International Box Office"". Deadline Hollywood. Archived from the original on April 3, 2022. Retrieved April 11, 2022.
- ^ Tartaglione, Nancy (April 12, 2022). ""Sonic 2 Speeds To $141M Global; Fantastic Beasts: The Secrets Of Dumbledore Uncovers $57M In Early Offshore Bow; RRR Roars To WW Milestone – International Box Office"". Deadline Hollywood. Archived from the original on April 11, 2022. Retrieved April 12, 2022.
- ^ Tartaglione, Nancy (April 17, 2022). ""Fantastic Beasts Reaches $150M Overseas; India's KGF Rocks $70M+ Global Start; Sonic Speeds To $232M WW – International Box Office"". Deadline Hollywood. Archived from the original on April 17, 2022. Retrieved April 18, 2022.
- ^ Tartaglione, Nancy (April 24, 2022). ""Fantastic Beasts 3 & Sonic 2 Near $300M Global, The Lost City Tops $100M – International Box Office"". Deadline Hollywood. Archived from the original on April 24, 2022. Retrieved April 24, 2022.
- ^ Tartaglione, Nancy (May 1, 2022). ""Fantastic Beasts & Sonic Top $300M Global; Downton Abbey: A New Era Sets Table Overseas On Calm Before The Strange Weekend – International Box Office"". Deadline Hollywood. Archived from the original on May 1, 2022. Retrieved May 2, 2022.
- ^ ""Morbius Returning to Theaters Following Social Media Meme Campaign"". Comic Book Resources. June 2, 2022. Archived from the original on June 2, 2022. Retrieved June 2, 2022.
- ^ Lussier, Germain (June 2, 2022). ""You've Done Morbed It: Morbius Returns to Theaters Thanks to Memes"". Gizmodo. Archived from the original on June 2, 2022. Retrieved June 3, 2022.
- ^ Zollner, Amelia (June 3, 2022). ""Morbius Memes have Gotten So Big, the Movie's Headed Back to Theaters"". IGN. Archived from the original on June 4, 2022. Retrieved June 4, 2022.
- ^ Mendelson, Scott. ""Box Office: 'Morbius' Bombs Again With $85,000 Friday"". Forbes. Archived from the original on June 4, 2022. Retrieved June 4, 2022.
- ^ ""Morbius theatrical re-release already an epic failure following the film trending on social media"". JoBlo. June 4, 2022. Archived from the original on June 4, 2022. Retrieved June 4, 2022.
- ^ Mendelson, Scott. ""Box Office: 'Morbius' Flops Again But 'Doctor Strange 2' Tops $900 Million"". Forbes. Archived from the original on June 11, 2022. Retrieved June 10, 2022.
- ^ ""Morbius"". Rotten Tomatoes. Fandango Media. Retrieved April 25, 2022.
- ^ ""36 Worst Superhero Movies of All Time"". Rotten Tomatoes. Fandango Media. Archived from the original on September 28, 2020. Retrieved April 10, 2022.
- ^ ""Morbius Reviews"". Metacritic. Red Ventures. Retrieved July 3, 2022.
- ^ ""Panned by critics, yet 'Morbius' tops North American box office"". The Times of India. IANS. April 3, 2022. Archived from the original on April 21, 2022. Retrieved April 21, 2022.
- ^ Rubin, Rebecca (April 3, 2022). ""Box Office: 'Morbius' Opens to No. 1 With Decent $39 Million"". Variety. Archived from the original on April 27, 2022. Retrieved April 21, 2022.
- ^ Crump, Jonathon (March 31, 2022). ""What are the Morbius reviews saying and what is the movie's age rating?"". Manchester Evening News. Archived from the original on March 31, 2022. Retrieved March 31, 2022.
- ^ Shafer, Ellise (March 30, 2022). ""Morbius First Reactions: Critics Respond to Jared Leto's Marvel Movie"". Variety. Archived from the original on April 8, 2022. Retrieved April 8, 2022.
- ^ Zilko, Christian (April 2, 2022). ""'Morbius' Scores Second-Lowest CinemaScore for Any Marvel Adaptation"". Indiewire. Archived from the original on April 4, 2022. Retrieved April 4, 2022.
- ^ Emma Kiely (March 31, 2022). ""'Morbius' Review: Jared Leto's Turn as a Marvel Antihero Leaves Much to Be Desired"". Collider. Archived from the original on March 31, 2022. Retrieved April 1, 2022.
- ^ Barry Hertz (March 30, 2022). ""Atrocious Spider-Man spinoff Morbius represents the absolute nadir of superhero cinema"". The Globe and Mail. Archived from the original on March 31, 2022. Retrieved March 30, 2022.
- ^ Ide, Wendy (April 3, 2022). ""Morbius review – insipid Marvel misfire"". The Guardian. Archived from the original on April 3, 2022. Retrieved April 3, 2022.
- ^ Strong, Hannah (April 6, 2022). ""Morbius"". Little White Lies. Archived from the original on March 31, 2022. Retrieved March 31, 2022.
- ^ Roeper, Richard (March 30, 2022). ""'Morbius': Even with Jared Leto and bat DNA injections, second-tier Marvel movie never takes off"". Chicago Sun-Times. Archived from the original on April 26, 2022. Retrieved March 30, 2022.
- ^ LaSalle, Mick (March 31, 2022). ""Review: Briskly riveting 'Morbius' is perfect antidote to bloated 'The Batman'"". San Francisco Chronicle. Archived from the original on April 26, 2022. Retrieved March 31, 2022.
- ^ Bumbray, Chris (March 31, 2022). ""Morbius Review"". JoBlo.com. Archived from the original on March 31, 2022. Retrieved March 31, 2022.
- ^ Greenblatt, Leah (March 30, 2022). ""Morbius review: Jared Leto's vampire superhero film isn't really a full movie, but it's fun"". Entertainment Weekly. Archived from the original on March 31, 2022. Retrieved March 31, 2022.
- ^ Zacharek, Stephanie (March 30, 2022). ""Morbius Review: Jared Leto Vibrates With Vulnerability"". Time. Archived from the original on April 23, 2022. Retrieved March 31, 2022.
- ^ Rooney, David (March 30, 2022). ""Jared Leto in 'Morbius' Review"". The Hollywood Reporter. Archived from the original on March 31, 2022. Retrieved March 30, 2022.
- ^ Donato, Matt (March 31, 2022). ""Morbius Review"". IGN. Archived from the original on March 31, 2022. Retrieved March 31, 2022.
- ^ Lacey, Kellie (March 25, 2022). ""Morbius Early Reactions Almost Unanimously Hate the Spider-Man Spinoff"". Comic Book Resources. Archived from the original on April 21, 2022. Retrieved April 21, 2022.
- ^ Erbland, Kate (April 2, 2022). ""'Morbius': Confusing Post-Credits Scenes Hint at Incoherent Twists for the Spider-Verse"". Indie Wire. Archived from the original on April 2, 2022. Retrieved April 2, 2022.
- ^ Tassi, Paul (April 2, 2022). ""Here Are The 'Morbius' Vulture Post-Credits Scenes So You Don't Have To Watch 'Morbius'"". Forbes. Archived from the original on April 26, 2022. Retrieved April 4, 2022.
- ^ Glassman, Julia (April 4, 2022). ""Here's What Happens in the 'Morbius' Post-Credit Scenes So You Don't Have to See the Movie"". The Mary Sue. Archived from the original on April 4, 2022. Retrieved April 4, 2022.
- ^ Cathy Brennan (March 31, 2022). ""Morbius"". Time Out. Archived from the original on April 1, 2022. Retrieved April 1, 2022.
- ^ a b Collin, Robbie (May 13, 2022). ""Fangs for the laughs, Marvel: how Morbius became one big joke"". The Telegraph. Archived from the original on May 13, 2022. Retrieved May 13, 2022.
- ^ a b Clark, Nicole (May 26, 2022). ""Posting the entirety of Morbius online is the best new Morbius joke"". Polygon. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ Shunpike, Stan. ""These Reactions About ""Morbius"" Will Entertain You More Than The Movie Itself"". Buzzfeed. Archived from the original on April 30, 2022. Retrieved May 13, 2022.
- ^ a b Suarez, Amanda (April 26, 2022). ""10 Funniest Reaction Memes To Morbius"". Screen Rant. Archived from the original on May 13, 2022. Retrieved May 13, 2022.
- ^ Suarez, Amanda (May 2, 2022). ""10 Hilarious Tweets About Morbius That Are Almost Too Savage"". Screen Rant. Archived from the original on May 13, 2022. Retrieved May 13, 2022.
- ^ Prasad, R.A Karthik. ""Morbius sweep trends as Marvel fans troll Jared Leto starrer with fake RT score & more"". Pursue News. Archived from the original on May 16, 2022. Retrieved May 13, 2022.
- ^ Tassi, Paul (April 10, 2022). ""Surprise, 'Morbius' Opens Up A Venom-Like Split Between Critics And Audiences"". Forbes. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ a b Kelly, Zachariah (May 24, 2022). ""The Official Morbius Discord Is Now a Very Funny Cult to the Living Vampire"". Gizmodo Australia. Archived from the original on May 25, 2022. Retrieved May 26, 2022.
- ^ Dominguez, Noah (May 21, 2022). ""Maligned Marvel Movie Morbius Is #1 on Apple TV"". CBR. Archived from the original on May 25, 2022. Retrieved May 28, 2022.
- ^ Mcintosh, Cody (May 26, 2022). ""Someone on Twitch Was Streaming 'Morbius' 24/7"". ScreenCrush. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ Barnhardt, Adam (April 3, 2022). ""Tyrese Gibson Falls for Fake Martin Scorsese Quote Praising Morbius as ""Truest Height of Cinema"""". Comic Book. Archived from the original on April 28, 2022. Retrieved May 28, 2022.
- ^ ""KFC Has Officially Joined in on 'Morbius' Memes"". The Mary Sue. May 25, 2022. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ Barnhardt, Adam (May 24, 2022). ""Morbius Fans Share Hilarious Memes as ""Morbin"" Trends on Twitter"". ComicBook.com. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ a b Barret, Ben (May 26, 2022). ""Morbius mania takes over Twitch, who can't shut down illegal restreams fast enough"". For The Win. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ Barnhardt, Adam. ""Morbius Fans Share Hilarious Memes as ""Morbin"" Trends on Twitter"". ComicBook.com. Literally Media Ltd. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ Baker-Whitelaw, Gavia (May 12, 2022). ""'It's Morbin' time': Morbius memes still going strong as fake catchphrase goes viral"". DailyDot.com. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
Continuing the running joke of just making stuff up about Morbius because no one saw the movie anyway, “It’s Morbin’ time” is an imaginary catchphrase that’s currently going viral on Twitter.
- ^ Troughton, James (May 23, 2022). ""People Are Being Sent The Entirety Of Morbius On Discord"". TheGamer. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ ""Morbius mania takes over Twitch, who can't shut down illegal restreams fast enough"". MSN. Archived from the original on May 27, 2022. Retrieved May 27, 2022.
- ^ Lang, Brad (May 26, 2022). ""Twitch Shuts Down 24/7 Morbius Livestream Channel"". CBR. Archived from the original on May 26, 2022. Retrieved May 26, 2022.
- ^ Gribbin, Sean (May 28, 2022). ""Morbius Supercut Lets Marvel Fans Spend as Little Time as Possible Watching the Film"". CBR. Archived from the original on May 30, 2022. Retrieved June 1, 2022.
- ^ ""Morbius Twitter Thread Lets You Read The Entire Movie With Pictures"". ScreenRant. May 28, 2022. Archived from the original on May 30, 2022. Retrieved June 1, 2022.
- ^ Tassi, Paul. ""'Morbius 2' Is Not Real, And It Is Not 'Morbin' Time' Yet"". Forbes. Archived from the original on May 30, 2022. Retrieved May 30, 2022.
- ^ ""Dear god, no, Morbius 2 has not been greenlit"". The A.V. Club. May 28, 2022. Archived from the original on May 30, 2022. Retrieved May 30, 2022.
- ^ ""Morbius 2 Trends Online As Audiences Jokingly Demand Marvel Sequel"". ScreenRant. May 29, 2022. Archived from the original on May 30, 2022. Retrieved May 30, 2022.
- ^ ""'Morbius' Memes Have Now Led To Fans Demanding 'Morbius 2'"". The Mary Sue. May 31, 2022. Archived from the original on June 1, 2022. Retrieved June 1, 2022.
- ^ ""'It's Morbin Time' Has Trended on Twitter for a Whole Week - Latest Tweet by Culture Crave"". LatestLY. May 29, 2022. Archived from the original on June 2, 2022. Retrieved May 30, 2022.
- ^ ""Jared Leto Declares It's Morbin' Time in Hilarious Morbius 2 Video"". ComingSoon.net. June 3, 2022. Archived from the original on June 4, 2022. Retrieved June 4, 2022.
- ^ ""Morbius 2: Jared Leto Invokes Morbin' Time Meme in Hilarious Video"". Marvel. Archived from the original on June 4, 2022. Retrieved June 4, 2022.
- ^ Lochrie, Conor (June 14, 2022). ""There's a petition to get 'Morbius' back to cinemas for a third time"". The Brag. Archived from the original on June 16, 2022. Retrieved June 16, 2022.
- ^ Bonomolo, Cameron (January 28, 2021). ""Jared Leto Says Morbius Crossover With Mahershala Ali's Blade Could Happen in the Future"". ComicBook.com. Archived from the original on January 29, 2021. Retrieved January 29, 2021.
- ^ Fink, Richard (December 5, 2021). ""Morbius' Jared Leto Hints at Sinister Six Spider-Man Connection"". Screen Rant. Archived from the original on December 6, 2021. Retrieved December 5, 2021.
- ^ Davis, Erik [@ErikDavis] (December 8, 2021). ""New: Tom Holland teases epic fights with Willem Dafoe's Green Goblin in #SpiderManNoWayHome. ""The fight scenes we have with Willem in this film are so crazy & so scary that it really was awesome to, like, explore different kind of Spider-Man action."""" (Tweet). Archived from the original on December 8, 2021. Retrieved December 9, 2021 – via Twitter.
- ^ Fiduccia, Christopher (December 21, 2021). ""Blade & Morbius Crossover Movie is Possible, Says Spider-Man Producers"". Screen Rant. Archived from the original on December 22, 2021. Retrieved December 21, 2021.
- ^ Fuge, Jonathan (March 18, 2022). ""Morbius Star Jared Leto Hopes to See a Crossover with Tom Hardy's Venom"". MovieWeb. Archived from the original on March 19, 2022. Retrieved March 18, 2022.
- ^ Elvy, Craig (April 26, 2022). ""Why Sony Announced Venom 3 Just Weeks After Morbius Embarrassment"". Screen Rant. Archived from the original on April 27, 2022. Retrieved April 27, 2022.
- ^ Perine, Aaron (April 26, 2022). ""Morbius Trends After Sony Announces El Muerto, but No Morbius Sequel"". comicbook.com. Archived from the original on April 26, 2022. Retrieved April 27, 2022.
External links
- 2022 films
- 2020s English-language films
- 2020s monster movies
- 2020s superhero films
- 2022 science fiction action films
- 4DX films
- American superhero films
- American vampire films
- Columbia Pictures films
- Film and television memes
- Films about bats
- Films about genetic engineering
- Films about scientists
- Films based on works by Roy Thomas
- Films directed by Daniel Espinosa
- Films postponed due to the COVID-19 pandemic
- Films produced by Avi Arad
- Films produced by Lucas Foster
- Films produced by Matt Tolmach
- Films scored by Jon Ekstrand
- Films set in Costa Rica
- Films set in Greece
- Films set in New York City
- Films shot at Pinewood Studios
- Films shot in Greater Manchester
- Films shot in London
- Films with screenplays by Matt Sazama and Burk Sharpless
- IMAX films
- Internet memes introduced in 2022
- Internet memes
- ScreenX films
- Sony's Spider-Man Universe
- Superhero crossover films
- 2020s American films",8
321,"Many people may never be able to put the pandemic behind them. They have long Covid, a catch-all term for illness that lingers long after a Covid-19 infection. More than 200 symptoms have been reported by patients, from hair loss and incontinence to severe tremors, anxiety, extreme fatigue and heart palpitations. “Even if the pandemic virus spread were to stop today, we still have tens of millions of people suffering long Covid,” says Yale immunologist Akiko Iwasaki. “That’s a parallel pandemic that’s happening, which is getting a lot less attention than the acute and severe Covid.”
In this video, we hear from people struggling with long Covid and what scientists have learned about the condition — or conditions — so far. Iwasaki explains long Covid’s diverse effects on the body — on the central nervous system, the gastrointestinal tract, the respiratory and cardiac systems, and more — and the search for biological origins. Long Covid is likely more than one disease, but without biomarkers that indicate who will get long Covid and the ways each case will manifest, personalizing treatments is challenging. The prevalence of long Covid has been a wake-up call, Iwasaki says, for society to investigate other syndromes that emerge after a viral infection.
READ MORE: Neuroinflammation During RNA Viral Infections, Annual Review of Immunology
This video is part of Reset: The Science of Crisis & Recovery, an ongoing series exploring how the world is navigating the coronavirus pandemic, its consequences and the way forward. Reset is supported by a grant from the Alfred P. Sloan Foundation.
Transcript
The science of long Covid is far from settled.
Scientists and physicians are still working to understand what it is, what causes it and how to treat it.
At the same time, millions of people are reporting new health problems after recovery from a Covid infection.
Here are some of their stories.
This is Liza Fisher, a former flight attendant and yoga instructor.
In June of 2020, a severe Covid-19 infection sent her to the emergency room.
Liza Fisher: “I got sick and I just never got better. It hit every system in my body, the internal tremors and vibrations. This is me now.”
Akiko Iwasaki (professor of immunobiology, Yale School of Medicine): “I get emails and messages from people who are suffering from long Covid every day. Some of these stories are very emotional and devastating.”
Tillie Adams (11 years old): “Feeling sick all the time, belly aches all the time, leg aches. And then I get headaches, like pains in my eyes. I don’t feel like myself anymore.”
Tanaeya Taylor: “I can’t work. I can’t drive. When I do drive, I feel like I am driving drunk.”
Dianne Sheehan: “Exhaustion to the point where you can’t remember your kids’ names.”
Woman with Covid-triggered postural orthostatic tachycardia syndrome (POTS): “I am formerly an ICU nurse and have not been able to do that in almost a year. I have horrible vertigo. The mental fog is like nothing I’ve ever experienced before.”
Colin Bennett: “It’s absolutely the worst hell you could ever imagine.”
Akiko Iwasaki: “Their lives have been ruined by long Covid and they’re no longer able to go back to work or work at the old pace that they were used to doing. These stories are accumulating within me and drive me really to do more research and to try to find something that we can do to help the suffering of these people.
“There is urgency to understanding this disease because there are people suffering so much so that they are contemplating of taking their own lives to end the misery. If we can stop one more person from such an act of desperation, I think we would have done our job. So, every day, every minute counts. And I understand that, and that’s part of the reason I don’t get much sleep.
“When Covid hit in early 2020, my lab was ready to tackle some of the key questions, such as how does the immune system respond to the virus infection and what causes severe disease versus mild disease? But during the course of investigation, we’ve also been encountering a lot of people telling us about their lingering symptoms that last for very extended time period, some of which are debilitating.”
Pamela Bishop: “The symptoms that I have every day are fatigue, nausea, dizziness, headache and some sort of pain. I have a lot of GI issues. I’m very nauseated most of the time. It’s hard for me to eat a full meal without getting sick.”
Beth Ann Pardo: “I have joint pain, muscle pain, fatigue, tremors, brain fog, severe anxiety. I’m not even the same person I was before. It’s completely ruined my life. It’s completely changed my life.”
Akiko Iwasaki: “Through the conversation with the patients and the doctors who are treating these patients, we became quite aware of this phenomenon of long Covid.
“We didn’t anticipate so many people becoming ill with long-term consequences. Hospitalized patients who are discharged may have 50 percent of those having long-term symptoms. Whereas a mild Covid or asymptomatic ones may lead to much less prevalence but still in the 10 percent, 20 percent, 30 percent range. So that’s a lot of people.
“Vaccination and prior infection will likely reduce the chances of you getting severe Covid and even potentially long Covid, but it’s not a guarantee. Some people get long Covid after being boosted and gotten a breakthrough infection.
“Even if the pandemic virus spread were to stop today, we still have tens of millions of people suffering long Covid and that’s a parallel pandemic that’s happening, which is getting a lot less attention than the acute and severe Covid, even though the cost to lives and the quality of lives that these people have to live with are very limited.”
What does the long Covid do to the body?
Akiko Iwasaki: “Long Covid can impact any part of the body. It’s really not a respiratory-only disease, at all. It basically involves every organ system that one can imagine, starting with the central nervous system, the peripheral nervous system, the GI tract, the respiratory, cardiac, musculoskeletal system, just basically everything. Depending on the person, it may be a set of organs that are involved or just one. There’s a huge heterogeneity, but I don’t think any organ is spared from the impact of long Covid.”
Long Covid is real
Andrea Tomasek: “100.1. Yesterday was my 20-month anniversary of having a fever. So I’ve had a fever for 20 months and one day. Doctors don’t know why I have a fever. I’ve been to the Mayo Clinic and their solution was to not think illness thoughts. Mm-hmm.”
Samir: “You may have heard that long Covid is a mental illness. I can guarantee you it is very physical as well. One of my symptoms is muscle spasms, where randomly some of my muscles will contract, leaving me in pain. Because of that, I’m trapped in this wheelchair, this bed, and this room. Long Covid isn’t just mental, it’s physical as well, and I spend most of my time in total physical pain.”
Akiko Iwasaki: “We are seeing clear biological differences in the measurements that we’re making in long Covid patients compared to people who had Covid, who fully recovered from Covid. We need to kind of move beyond this notion of psychosomatic origin of disease and really look into the biological origin, biological reasons why these people are suffering.”
Long Covid symptoms
Akiko Iwasaki: “There are over 200 symptoms reported for long Covid. Some people have one or two of these while others have over a dozen symptoms ongoing at any given time. Not everyone has the same disease, and I think that speaks to different endotypes of long Covid that people are suffering from.”
Sen. Tim Kaine: “I would say I’m experiencing long Covid. There are people who are really suffering it. I wouldn’t call myself a sufferer. I have a bizarre nerve-tingling sensation that feels like my skin is dipped in an Alka-Seltzer that’s just going off 24/7.”
Akiko Iwasaki: “But the range is anywhere from people having some pain or shortness of breath and fatigue.”
Joel Fram: “The fatigue was really bad, and I would also get breathless doing very normal things like walking up the stairs. It was really scary.”
Akiko Iwasaki: “All the way to people having internal tremors and vibration who are just unable to do anything else because their body is just moving in a way that they cannot control. They cannot sleep, they cannot eat, they cannot think, they cannot do anything. And they’re just under such a great physical and mental strain from such symptoms that these are the people, unfortunately, who have taken their own lives or who are contemplating ending their lives. Those are extreme symptoms, but there is a huge range of symptoms. And ultimately we need biomarkers to say, OK, you have this kind of Covid or that kind of Covid and we’re not there yet.”
Long Covid and post-acute infection syndromes
Akiko Iwasaki: “I believe that the ME/CFS [myalgic encephalomyelitis/chronic fatigue syndrome] is probably of the same disease that people with long Covid are suffering from but were caused by other infections.
“Prior to long Covid, there have been a number of infections, many, many viruses, but sometimes bacteria and parasitic infection that leads to long-term consequences. It’s only with the sheer number of people with long Covid that really now is highlighting these other diseases such as ME/CFS that’s being triggered by numerous other pathogens. But the symptoms are very similar to long Covid such as chronic fatigue as well as some of these dysautonomia-like syndromes, cardiac issues, GI issues, many vasculature issues, and just inability to control these heart rates or blood pressure or things that are very similar to what we’re seeing with long Covid. It’s a wake-up call really for the society to start looking into other post-acute infection syndromes, because we are going to be dealing with this going forward. Some of these long Covid patients might develop into ME/CFS if they cannot recover from the long Covid stage of the disease.”
What causes long Covid?
Akiko Iwasaki: “Long Covid disease pathogenesis can be considered as having four separate causes but these are not mutually exclusive. People can have a combination of these things too.
“So the first hypothesis is that there are maybe persistent virus hiding somewhere in the tissue which you cannot measure with the nasopharyngeal swabs or saliva because these people are PCR-negative. But imagine having that in your gut or some other organ, and that type of persistent virus, or it could be just the remnant of the virus, such as the protein or the RNA or combination thereof, that could be triggering the chronic inflammation.
“Second hypothesis is autoimmunity. Autoimmunity can be triggered as a result of an acute infection and once these autoimmune cells, which are T cells and B cells that are reactive against our own body, our own host proteins or molecules, it’s very difficult to shut them down once they are triggered, because the stimulus that are triggering them is everywhere. Essentially, it’s your own cells.
“The third possibility is dysbiosis of microbiome. So we have trillions of bacteria in the gut and they really contribute to our health but potentially disease if they’re disturbed in their compositions or their metabolic functions. And it’s also possible that there are latent viruses that are reactivated to cause some of these symptoms such as the Epstein-Barr virus. So that’s the third hypothesis: It’s really about whatever that’s in our body that’s sort of dysregulated, either microbe or virus.
“The fourth possibility is tissue damage that’s incurred by the initial infection that cannot be repaired. And this is likely happening in the hospitalized patients who were intubated or had some extreme measures of medical interventions. If you have severe respiratory infection with SARS-CoV-2, you obviously have damage in the lung. If you’ve had pneumonia, there’s scarring and potentially fibrosis. Those types of tissue damage is very difficult to repair. If you look at the UK Biobank study, there is significant reduction in brain mass of people even with milder Covid. So that’s a direct damage to the brain after even a milder infection, and there may be other damages that we don’t know about, vascular damage. There may be a lot of clotting issues or issues related to the endothelial cells that may have incurred some damage. And of course, endothelial cells are very important for the function of the blood vessels as well as oxygen exchange and so on. So I think there may be many damages at the microscopic level, like the vasculature, or more the macroscopic level, like the brain itself or the lungs. And there may be damages in the liver or intestine or other tissues that we don’t currently appreciate with respect to what’s happening. So these is roughly the four major hypotheses but there may be more.”
Long Covid treatments
Akiko Iwasaki: “With respect to treatment, if the first hypothesis of persistent virus is leading to long Covid is true, then we need to go after the virus as treatment. One thing we can do is to use antivirals like Paxlovid or Molnupiravir that targets the virus itself and we can maybe eliminate the source of the problem that way. It’s also possible that some people feel much better after vaccination and that might be because there was a persistent virus reservoir that was cleared by vaccine-induced immunity. The therapy for that group of long Covid patients would be antiviral measures.
“If long Covid is causing autoimmune disease, first of all the target of autoimmune disease needs to be identified. What are the T and B cells attacking in such cases? Because that will inform us how the host immune response is harming the host. If we know that these patients are suffering from some sort of autoimmune disease, there are interventions that are already existing in the autoimmune disease treatment such as immunosuppressives or even biologics to eliminate B cells that are the source of autoantibodies. And there are newly developing biological drugs that can be applied to long Covid.
“If Covid is somehow inducing dysbiosis — which means that some harmful bacteria may be expanding in lieu of the better, sort of more commensal bacteria in their gut — we may be able to go after either the metabolites that the bacteria is producing that’s harming the host. We can try to block that pathway or just trying to change the composition of the microbiome through diet or probiotics or some other mechanisms.”
Long Covid prevention
Akiko Iwasaki: “For someone who’s newly infected, I would definitely recommend to get the Paxlovid right away, because the earlier the treatment the more likelihood of you being able to eliminate the source of viral reservoir. And actually treating early with Paxlovid or monoclonal antibodies is just in general great to avoid any of these four hypotheses of diseases from occurring, because the longer you allow the virus to replicate and cause damage, the more likelihood of you triggering these four types of disease outcomes. And there is even a study that suggests that getting vaccination within the first 12 weeks of infection reduces risk for developing long Covid.”
Alyssa Milano: “After my second vaccine, my long-haul symptoms started to ease up, which I guess happens to like 40 percent of long-haul patients. But I still have shortness of breath sometimes and heart palpitations and tingling in my hands and it’ll come out of nowhere. And it’s scary when it happens.”
Akiko Iwasaki: “So even vaccination may be helpful during the early phase of infection, but if you wait too long these things aren’t going to be effective.”
Mitigation measures
Akiko Iwasaki: “I’m personally surprised that long Covid isn’t at the center of discussion in public. Knowing how devastating this disease is, I am very hesitant myself to go out there and get exposed to any kind of Covid. I just think it’s really gambling with your health and it’s not safe. I personally think that removing precautionary measures to prevent transmission is a very bad idea. I do absolutely ensure that my children are fully vaccinated, boosted if they’re eligible, and are wearing masks inside while they’re going to school or elsewhere. We need to layer protective measures, one on top of the other, in order to reduce the risk of getting Covid so that we don’t get long Covid either.”
Lila Bishop (speaking to Pamela Bishop): “I feel sorry for you all the time. I want doctors and researchers to help find a cure for it, but I don’t know if they can.”
Pamela Bishop: “I think they can.”
10.1146/knowable-080822-2",4
322,"Alors que les innovations technologiques s’accélèrent, les frontières des métiers se redéfinissent sans cesse et de nouvelles fonctions apparaissent. Difficile donc quand on entre dans l’enseignement supérieur de savoir exactement de quelles missions une carrière sera faite. Pour aider les étudiants à se projeter dans l’avenir, la presse magazine explore régulièrement ces nouveaux terrains, à l’instar du mensuel Capital qui, fin 2021, s’est arrêté sur « 10 métiers que vous pourrez exercer… dans 10 ans ».
Quelles compétences faudra-t-il pour les pratiquer ? Quels sont les postures et savoir-faire qui feront la différence dans la maitrise d’un poste ? Et surtout, notre pédagogie est-elle en phase pour former dès à présent à ces métiers ?
Pour répondre à ces questions – et parce qu’ils sont au cœur de nos ambitions pédagogiques – nous nous appuierons sur trois des dix métiers cités dans l’article : « nudge designer », éducateur de robot et anticipateur de crise.
Sortir des cadres connus
Le nudge designer est celui qui « imagine des solutions pour influencer les comportements des usagers ou des consommateurs », nous dit l’article ; c’est celui qui dessinera par exemple des pas sur un trottoir vers la poubelle pour inciter à la propreté.
À lire aussi : Les nudges : un coup de pouce non violent ?
Bien sûr, il lui faut des compétences fondamentales, en l’occurrence des connaissances en psychologie comportementale/cognitive afin de déterminer ce qui fait qu’une personne va agir ou non et des compétences transversales comme l’empathie, la communication. Cependant pour imaginer des dispositifs vraiment innovants, le nudge designer devra posséder une manière de voir complètement décalée, voire déviante du formatage classique…
Pour devenir éducateur de robot, il sera préférable de savoir coder (« hard skill »), cela demandera également de comprendre la relation homme machine (« soft skill ») mais aussi d’être capable d’imaginer des scénarii où les robots seront plus compétents que l’humain. Il s’agira enfin de réfléchir à la manière dont le robot pourra apprendre l’éthique et l’empathie. Ces nouvelles manières d’enseigner aux robots devront sûrement être très inventives, très surprenantes, voire inattendues…
Prenons maintenant le cas d’une avalanche que devrait gérer un anticipateur de crise. Se préparer à ce type de scénario mobilise des compétences techniques : cartographie, topographie, nivologie, etc. mais aussi des soft skills comme la compréhension des réactions humaines dans cette situation (panique, peur, angoisse). Cependant pour anticiper toutes les crises (im)probables, il faudra aller plus loin en inventant les simulateurs de demain, dans la lignée du Hitlab de Chrischurch qui travaille sur des outils multisensoriels pour faire face à des événements tels que les tremblements de terre.
Il arrive d’ailleurs de plus en plus que les simulateurs virtuels fassent appel à des spécialistes des jeux vidéo car ceux-ci ont cette imagination capable de faire vivre des expériences hors du commun relevant parfois de la fiction. Une fiction qui, dans certains cas, peut devenir réalité et qu’il faudra anticiper.
Capacité d’expérimentation
Si les « hard skills » (les connaissances fondamentales et les compétences techniques, comme la maitrise d’un outil, d’un langage de programmation, la maitrise de gestes) et les « soft skills » (souvent transverses, comme la négociation, la créativité, l’agilité, etc.) sont déjà identifiées pour soutenir les métiers de demain, il semble qu’elles ne suffisent pas.
Souvent mises en évidence par les start-up californiennes, les « mad skills » pourraient être ce complément dont la nécessité se ressent de plus en plus. Dans cette catégorie se trouvent des compétences comme la « déviance positive » (le fait de ne pas emprunter forcément le chemin tracé tout en ayant des intentions positives) ou encore le sens critique, l’ingéniosité, la singularité. Souvent ce sont les qualités propres aux profils décalés, atypiques, etc.
Ces compétences sont facilement identifiables chez un aventurier comme Mike Horn ou des personnages de fiction comme Mac Gyver ou Indiana Jones. Ces héros ont une incroyable capacité à « saisir des voies détournées pour arriver à [leurs] fins ». Ce qui leur permet de s’orienter avec les étoiles, de trouver à manger dans la nature, de construire un abri avec des matériaux de récupération, de réparer un véhicule pour se sortir d’une situation délicate. Il s’agit de « se rendre, donc, disponibles aux choses du monde, mais à l’unique condition de cultiver une polyvalence qui ouvre le regard ; et expérimenter des agencements de toute sorte qui traceront la route vers une sortie encore à imaginer ».
Il nous semble que ce sont ces postures, attitudes et osons le terme, ces « mad skills » qui feront la différence pour devenir « nudge designer », éducateur de robot ou encore anticipateur de crise. Car ce sont elles qui apparaissent dans ce grain de folie qui sera propre à ces métiers. Ce sont elles que les entreprises viennent déjà chercher et ce sont ces « mad skills » qu’il nous faut tenter, en tant que pédagogues, de repérer et de renforcer.
Créativité adaptative
Nous pensons que même si nous ne pouvons pas tous être Mac Gyver, il y a tout de même souvent, au fond de chacun de nous, cette créativité adaptative qui permet de faire face à des situations imprévues.
Notre mission de formation n’est donc plus seulement de délivrer un savoir, mais de faire émerger cette capacité de chacun à sortir des sentiers battus. Il s’agirait donc d’imaginer des dispositifs pédagogiques qui permettent de mettre en évidence ces « mad skills », de faire prendre conscience aux apprenants qu’ils les possèdent et les aider à renforcer ces compétences atypiques.
À lire aussi : Innovation pédagogique : un jeu pour révéler la créativité des étudiants
Le jeu (serious game) pourra être un de ces révélateurs de mad skills. « On en apprend plus sur quelqu’un en une heure de jeu qu’en une année de discussion », disait Platon. Au travers du jeu, la personne montre sa véritable personnalité et ses traits de caractère. D’ailleurs, les entreprises tentent de plus en plus de recruter par le jeu.
Plus que révéler les mad skills et les talents différents, le jeu permet aussi de former dès à présent, les anticipateurs de scénario de crise ; c’est le cas de l’armée française qui a créé « Red Team » en faisant appel à une dizaine d’auteurs de science-fiction pour imaginer les menaces militaires et technologiques à l’horizon 2030-2060. L’objectif est assumé : se faire peur pour mieux anticiper. Ce qui est notable dans cet exemple c’est justement que l’armée n’a pas fait appel à des géopoliticiens par exemple, mais bien à un regard neuf, un grain de folie de la part des auteurs et ce pour s’entrainer de manière concrète.
En conclusion, au terme de « déviant positif », nous préférerons le terme de « corporate hacker ». Celui-ci intègre le grain de folie sans oublier d’être corporate afin de ne pas déstabiliser l’organisation. Rappelons qu’il faut aussi comprendre, respecter les équilibres et l’hétérogénéité qui fait la richesse des équipes. Pour Meredith Belbin « nobody is perfect but a team can be » : personne n’est parfait, mais l’équipe peut l’être – avec ses grains de folie.",0
324,"On the afternoon of August 10th, in the E. Barrett Prettyman federal courthouse, the Department of Justice trial to block Penguin Random House from acquiring Simon & Schuster had hit a midweek lull. The courtroom itself—as well as the overflow room, where journalists were permitted Internet access—was a few booksellers shy of crowded. But the first witness for the defense, the mega-agent Jennifer Rudolph Walsh, was intensely present, and seemed thrilled to be testifying. (Penguin Random House was paying her a quarter of a million dollars.) In a rippling cream-colored blouse and gold jewelry, her hair loose around her shoulders, Walsh painted a picture of publishing as a labor of love. Agents, she said, are in the business of fairy-tale matches between author and editor—mind meldings that span decades, shape careers, and win prizes. Walsh even had a magic wand, she added, that was given to her by the novelist Sue Monk Kidd. When the judge Florence Y. Pan asked if agents had a fiduciary duty to secure their writers the highest possible advances, Walsh responded in the negative. “More isn’t always more,” she said. “We’re not always looking to take every single dollar out of an editor’s pocket.”
The exchange exposed the core question of the day, and of every day in a trial that has riveted the publishing industry since proceedings began on August 1st: Is publishing about art or commerce? The answer, of course, is “Both”—as with any creative business—but watching each side wrestle with that ambiguity has been instructive. Penguin Random House, itself the product of a merger between Penguin and Random House in 2013, is the biggest of publishing’s so-called Big Five. (The others are HarperCollins, Macmillan, Simon & Schuster, and Hachette.) If the acquisition goes through, the new company will dwarf its nearest rivals. This is one of the first high-profile antitrust suits to be brought by President Biden’s Department of Justice. It may, along with the recent appointment of Lina Khan as chair of the Federal Trade Commission, indicate a new direction for the country’s regulatory climate. But, to people who care about books, what’s gone most conspicuously on trial is publishing itself. In the course of two weeks, an image of publishers as savvy and data-driven has vied with a tenderly drawn (auto-)portrait of gamblers, guessers, and dreamers. At times it has felt reasonable to wonder whether the industry should be characterized as an industry at all.
The spectacle has been curiously entertaining. Publishing executives have had to initiate federal employees into a dialect of “backlists,” “advance copies,” and “BookTok influencers.” Onlookers have been treated to piquant performances, from the cheeky verve of Simon & Schuster’s Jonathan Karp to the C-suite solidity of Brian Murray, of HarperCollins, who seemed to quietly deflate under a round of pointed questioning. On Tuesday, the horror maestro Stephen King popped up to testify that “consolidation is bad for competition” and that the disappearance of “idiosyncratic” imprints from the publishing landscape has made it “tougher and tougher for writers to find enough money to live on.” King, who wore sneakers and introduced himself as a “freelance writer,” wanted to advocate for younger and less established peers—those for whom a book deal might mean the difference between creating art and waiting tables.
And yet King’s championing of struggling artists felt tangential to the specifics of the trial.
Government lawyers have built the heart of their case around a relatively narrow category—“anticipated top sellers”—where the threat of monopsony is greatest. The plaintiff defines these as the small fraction of books for which authors receive advances of two hundred and fifty thousand dollars or higher. They are also the books that tend to fly off shelves and the books with which publishing houses pay their bills. The Justice Department is claiming that a Penguin Random House–Simon & Schuster merger would suppress competition for top sellers, driving down advances and ultimately lessening both the number and the diversity of the titles. The defense has countered that “anticipated top seller” does not designate a real market—merely a “price segment.” One cannot “anticipate” a blockbuster, lawyers have implied; the publishing gods are fickle, and whether a book will sell at all—much less go supernova—is anyone’s guess. Moreover, Simon & Schuster’s authors would benefit from access to Penguin Random House’s superior distribution and sales teams. Other houses would need to compete even harder to lure them away.
One by one, soberly dressed executives mounted the dais to frame publishing as a game of chance—a “business of passion,” in the words of the departing Macmillan C.E.O., Don Weisberg. “Everything is random in publishing,” Markus Dohle, the C.E.O. of Penguin Random House, testified on August 4th. “Success is random. Best-sellers are random. That is why we are the Random House!” Acquiring books, Brian Tart, the president of Viking, testified on August 3rd, “is as much an art as a science.” To illustrate his point, he described passing on Marie Kondo's “The Life-Changing Magic of Tidying Up” and the current No. 1 New York Times best-seller, “Where the Crawdads Sing,” by Delia Owens. Judge Pan observed that profit-and-loss statements “are really fake.” Tart enthusiastically agreed. On August 2nd, Karp, the C.E.O. of Simon & Schuster, testified that gloating over a best-seller is like “taking credit for the weather,” and wryly recalled the eagerness with which he’d promoted a manuscript by a prominent spiritual guru. “Unfortunately,” he said, “his followers didn’t follow him to the bookstore.”
The rogue’s gallery of industry figures presented a stark contrast to the government’s expert witness, the economist Nicholas Hill. Soft-voiced and physically imposing, with broad shoulders, thick silver hair, and a square chin, he was there to reinforce the idea of an “anticipated top seller” market. Writers behave differently around the two-hundred-and-fifty-thousand-dollar threshold, Hill alleged. They’re “making different choices.” His most memorable contribution, though, was a series of Gross Upward Pricing Pressure Index (GUPPI) models, which he’d crafted to theorize about the market share that a joint Penguin Random House–Simon & Schuster might capture.
The GUPPIs proved a matter of tense dispute. If Hill embodied the Justice Department’s academic approach, Mark Oppenheimer, an attorney in the defense, appeared intent on casting him as the Casaubon of economic consultants. A meandering cross-examination summoned impressions of mystifying esoterica, as Oppenheimer’s attempt to refute Hill’s methodology morphed into a ritual hypnosis, a ceremony to stupefy the courtroom. The lawyer, gentle and avuncular, dramatized his own inability to keep “monopoly” and “monopsony” straight; he paused to rifle through his notes, asked repetitive questions, and referred Hill to such destinations as a table’s “last column, fifth line”—or was it the “sixth line”? Several times, Judge Pan challenged Oppenheimer’s path of inquiry, and at one point pleaded with him to move on. When the court recessed, a clutch of ashen reporters staggered out of the overflow room. “Guppies,” Publishers Weekly’s news editor John Maher, who’d been valiantly live-tweeting the trial, whispered. “All I see are guppies.”
The entertainment value of Hill’s models aside, his larger case was persuasive. Big Five publishers possess advantages that render them uniquely attractive to literary stars: reputation, breadth of distribution, breadth of marketing, and—perhaps most important–extensive backlists that generate enough revenue to offset potential losses. New companies, such as the bantling publisher Zando, “can’t expand to mitigate the anticompetitive effects of the merger,” Hill said, because they lack such backlists, which grow over decades, like oaks. Yes, publishing is a risky endeavor; yes, the elusiveness of a good formula for success means that small presses and self-published authors all have a shot at producing a best-seller. But, year after year, the Big Five churn out the vast majority of profitable books—and this is precisely due to their ability to manage risk. Success in the publishing industry is not being able to publish a single hit; it’s being able to publish many hits over a long period of time. Here, the larger publishers eat their competitors’ lunch.
Still, a thought nagged at me as I watched Hill’s testimony: you’re a data scientist. Those who work in book publishing have answered the ineffable and not especially remunerative call to cultivate literature. Maybe their lens—luck, passion, the wind, the stars—is the right one. Maybe money doesn’t always rule the day. On Thursday, the agent Elyse Cheney testified that many authors prefer an editor who can coax out the “richest, most robust project” to one who flourishes the largest advance. If nothing else, the trial has laid bare the prodigious labor, on the part of agents and editors and booksellers, it takes to shepherd a book to life. Trade publishers are “angel investors in our authors and their dreams, their stories,” Penguin Random House’s chief executive, Dohle, asserted. “That’s how I call my editors and publishers: angels.” This devotion isn’t always rewarded. In September of 2021, Dohle promised not to shutter any imprints should the deal go through, but the merger is likely to have an adverse effect on employees. In 2013, when Penguin fused with Random House, a wave of editors, marketers, and publicists lost their jobs, and midlist contracts shrivelled. It feels naïve to hope that the sale of Simon & Schuster, whether to Penguin Random House or to another buyer, will bring a different result.",4
326,"Of all the mysteries and injustices of the McDonald’s ice cream machine, the one that Jeremy O’Sullivan insists you understand first is its secret passcode.
Press the cone icon on the screen of the Taylor C602 digital ice cream machine, he explains, then tap the buttons that show a snowflake and a milkshake to set the digits on the screen to 5, then 2, then 3, then 1. After that precise series of no fewer than 16 button presses, a menu magically unlocks. Only with this cheat code can you access the machine’s vital signs: everything from the viscosity setting for its milk and sugar ingredients to the temperature of the glycol flowing through its heating element to the meanings of its many sphinxlike error messages.
“No one at McDonald’s or Taylor will explain why there’s a secret, undisclosed menu,"" O’Sullivan wrote in one of the first, cryptic text messages I received from him earlier this year.
As O’Sullivan says, this menu isn’t documented in any owner’s manual for the Taylor digital ice cream machines that are standard equipment in more than 13,000 McDonald’s restaurants across the US and tens of thousands more worldwide. And this opaque user-unfriendliness is far from the only problem with the machines, which have gained a reputation for being absurdly fickle and fragile. Thanks to a multitude of questionable engineering decisions, they’re so often out of order in McDonald’s restaurants around the world that they’ve become a full-blown social media meme. (Take a moment now to search Twitter for “broken McDonald’s ice cream machine” and witness thousands of voices crying out in despair.)
But after years of studying this complex machine and its many ways of failing, O’Sullivan remains most outraged at this notion: That the food-equipment giant Taylor sells the McFlurry-squirting devices to McDonald’s restaurant owners for about $18,000 each, and yet it keeps the machines’ inner workings secret from them. What's more, Taylor maintains a network of approved distributors that charge franchisees thousands of dollars a year for pricey maintenance contracts, with technicians on call to come and tap that secret passcode into the devices sitting on their counters.
The secret menu reveals a business model that goes beyond a right-to-repair issue, O’Sullivan argues. It represents, as he describes it, nothing short of a milkshake shakedown: Sell franchisees a complicated and fragile machine. Prevent them from figuring out why it constantly breaks. Take a cut of the distributors’ profit from the repairs. “It’s a huge money maker to have a customer that’s purposefully, intentionally blind and unable to make very fundamental changes to their own equipment,” O’Sullivan says. And McDonald’s presides over all of it, he says, insisting on loyalty to its longtime supplier. (Resist the McDonald’s monarchy on decisions like equipment, and the corporation can end a restaurant’s lease on the literal ground beneath it, which McDonald's owns under its franchise agreement.)
So two years ago, after their own strange and painful travails with Taylor’s devices, 34-year-old O’Sullivan and his partner, 33-year-old Melissa Nelson, began selling a gadget about the size of a small paperback book, which they call Kytch. Install it inside your Taylor ice cream machine and connect it to your Wi-Fi, and it essentially hacks your hostile dairy extrusion appliance and offers access to its forbidden secrets. Kytch acts as a surveillance bug inside the machine, intercepting and eavesdropping on communications between its components and sending them to a far friendlier user interface than the one Taylor intended. The device not only displays all of the machine’s hidden internal data but logs it over time and even suggests troubleshooting solutions, all via the web or an app.",2
327,"Amazon is facing a looming crisis: It could run out of people to hire in its US warehouses by 2024, according to leaked Amazon internal research from mid-2021 that Recode reviewed. If that happens, the online retailer’s service quality and growth plans could be at risk, and its e-commerce dominance along with it.
Raising wages and increasing warehouse automation are two of the six “levers” Amazon could pull to delay this labor crisis by a few years, but only a series of sweeping changes to how the company does business and manages its employees will significantly alter the timeline, Amazon staff predicted.
“If we continue business as usual, Amazon will deplete the available labor supply in the US network by 2024,” the research, which hasn’t previously been reported, says.
The report warned that Amazon’s labor crisis was especially imminent in a few locales, with internal models showing that the company was expected to exhaust its entire available labor pool in the Phoenix, Arizona, metro area by the end of 2021, and in the Inland Empire region of California, roughly 60 miles east of Los Angeles, by the end of 2022. Amazon’s internal report calculated the available pool of workers based on characteristics like income levels and a household’s proximity to current or planned Amazon facilities; the pool does not include the entire US adult population.
Amazon spokesperson Rena Lunak didn’t refute the contents of the internal report Recode obtained but declined to comment on it.
The research provides a rare glimpse into the staffing challenges that Amazon is now facing behind its slick veil of one-click online shopping and same-day Prime delivery. And it pointedly reveals how much of Amazon’s business success and its longtime position as a darling of Wall Street investors is dependent on its workforce of more than 1 million people who pick, pack, and ship its customers’ orders nearly 24/7.
The leaked internal findings also serve as a cautionary tale for other employers who seek to emulate the Amazon Way of management, which emphasizes worker productivity over just about everything else and churns through the equivalent of its entire front-line workforce year after year.
In the past, that churn wasn’t a problem for Amazon — it was even desirable at some points. Amazon founder and former CEO Jeff Bezos saw his warehouse workforce as necessary but replaceable, and feared that workers who remained at the company too long would turn complacent or, worse, disgruntled, according to reporting by the New York Times. But now, as the internal report Recode reviewed shows, some inside Amazon are realizing that strategy won’t work much longer, especially if leaders truly want to transform it into “Earth’s best employer,” as Bezos proclaimed in 2021.
To be sure, part of Amazon’s turnover issue relates to how some employees view working in a warehouse as a brief pit stop on the way to better things. But some workers have long complained of stresses unique to Amazon’s workplace, from the pace and repetition of the labor to the unrelenting computerized surveillance of workers’ every move to comparatively high injury rates. In a company survey of 31,000 workers who left Amazon that was referenced in the report, some former Amazon workers say it’s worse to work at Amazon than some big-name competitors like Walmart or FedEx. In that survey, those who joined another employer soon after leaving the tech giant “rated Amazon significantly worse on work fitting skills or interests, demands of the work, shift length and shift schedule.”
With traditional competitors ramping up their investments in e-commerce warehouses, Amazon is no longer a slam-dunk top choice for those seeking work in these types of facilities and the starting minimum wage that comes along with it. And that dynamic is already playing out in some parts of the country.
Danger zones
In the Inland Empire region of California, for example, Amazon may cycle through every worker who’d be interested in applying for a warehouse job by the end of 2022, the internal report warned. One of the reasons is that Amazon is increasingly finding itself in a bidding war for workers with rivals in the area, which is a key logistics region because it is within a two-hour drive of 20 million potential customers and two of the largest container ports in the US.
“We are hearing a lot of [Amazon] workers say, ‘I can just go across the street to Target or Walmart,’” said Sheheryar Kaoosji, co-executive director of an Inland Empire nonprofit called the Warehouse Worker Resource Center. Kaoosji added that Walmart is offering some workers with past warehouse experience as much as $25 an hour. An Amazon executive told Reuters in late 2021 that the company was bumping the average starting wage for new hires in the US to more than $18 an hour, attributing the decision to intense competition among employers. He also said Amazon had increased hiring bonuses to as much as $3,000 in some geographies.
And internal forecasts showed the situation was dire in Phoenix, Arizona, with Amazon projected to exhaust its entire potential workforce by the end of 2021. The Phoenix metro area has been a key market for Amazon since it opened its first warehouse there in 2007. The company currently operates more than 20 facilities in the region. But attrition at Amazon’s facilities in the area grew from 128 percent in 2019 to 205 percent in 2020, as the pandemic upended labor markets and online shopping boomed, putting pressure on fulfillment center employees.
As a result, Amazon seemed to have reversed, or stopped enforcing, some workplace policies at Phoenix warehouses amid the labor shortage, according to a former manager.
“They were so concerned about attrition and losing people that they rolled back all the policies that us as managers had to enforce,” Michael Garrigan, a former entry-level manager at Amazon warehouses in Phoenix from 2020 to early 2022, told Recode. “There was a joke among the … managers that it didn’t matter what [workers] got written up for because we knew HR was gonna exempt it. It was almost impossible to get fired as a worker.”
Lunak, the Amazon spokesperson, declined to comment on Garrigan’s claims.
The internal research also identified the regions surrounding Memphis, Tennessee, and Wilmington, Delaware, as areas where Amazon was on the cusp of exhausting local warehouse labor availability. Amazon’s models used for this internal research were 94 percent accurate in predicting the US geographies where Amazon was significantly understaffed in the lead-up to the Amazon Prime Day shopping event in June 2021, the report noted, which contributed to delivery delays for customers in those markets. The warnings about Amazon’s labor supply shortages indicate that in at least some markets, Amazon shipments could face more severe delays in the future.
Despite its looming labor crisis, Amazon temporarily overcorrected in some markets, going from understaffed to overstaffed. Amazon’s chief financial officer had previously said that the company was understaffed by 10,000 employees during the end of 2021, before the omicron Covid-19 variant had wreaked havoc on much of the US. But in April, the company revealed that it was actually overstaffed in some areas in early 2022 as the first wave of omicron subsided and employees returning from sick leave worked alongside new hires who had been recruited to backfill their roles.
Amazon spokespeople have said that the company will count on natural attrition rates to solve much of the current overstaffing problem, and the Wall Street Journal reported on Thursday that a top company official pitched a plan internally to “[thin] out its worker base through attrition.” It’s unclear where exactly Amazon is overstaffed and how long it will take to rightsize its workforce, but it seems unlikely that it is thinning staff in competitive locales like Phoenix and the Inland Empire where it had already exhausted much of the labor pool. It’s also unclear how the current economic climate will impact consumer spending and, relatedly, Amazon’s hiring needs.
For better or worse, the approach of reducing the temporary overstaffing issue through attrition should work for Amazon because it has long churned through its workers at a rapid clip. Amazon’s attrition rates were 123 percent in 2019 before jumping to 159 percent in 2020, according to internal data in the report Recode obtained, while turnover rates across the US transportation and warehouse sectors were much lower: 46 percent and 59 percent respectively in 2019 and 2020, according to Bureau of Labor Statistics estimates.
Turnover in the US retail industry was slightly higher than that — 58 percent and nearly 70 percent respectively in 2019 and 2020 — but still only about half as bad as Amazon’s. The high rates of attrition “made some [Amazon] executives worry about running out of workers across America,” the New York Times reported in 2021, though the article did not include specific timelines.
The leaked report viewed by Recode reads like an attempted wake-up call — along with potential solutions to avert the crisis — for some company leaders who long exhibited a nonchalant attitude toward employee attrition.
No silver bullet
Amazon has a variety of potential solutions for its people problem, but they will require the company to shift its mindset and overcome practical or logistical challenges.
On the surface, simply employing its current workers for longer would be a big help. The turnover rate disparity between Amazon and industry averages shows there is ample opportunity for the company to keep employees longer and delay the arrival of the day when it won’t have workers left to recruit. This is not some unsolvable, mysterious problem; the BLS stats show that plenty of companies retain workers much better than Amazon does. In fact, Amazon’s own data shows that nearly 90 percent of new workers say they want to stay at their jobs for at least six months. If Amazon could bring attrition rates down to its 2019 levels, which were still above 100 percent, the company would gain three more years of hiring runway, according to the internal projections.
In other parts of the country, though, where labor shortages aren’t yet a certainty, remnants of Amazon’s longtime aggressive termination practices persist. It’s not uncommon for some of Amazon’s automated computer systems to automatically fire employees for a variety of minor infractions, without exception. Jose Pagan, a former Amazon employee at a warehouse in Bronx, New York, says he got the automated ax recently despite nothing but positive feedback from his managers.
Pagan began working at the Amazon delivery hub in October and, within two months, had been promoted to a role on the safety committee for the facility. The new role didn’t come with a pay raise, and is on top of a worker’s core tasks, but Pagan saw it as a stepping stone to an official promotion. But in April, Pagan told Recode, he took two days off to have an infected tooth looked at and ultimately removed.
The problem, he said, was that he only had seven hours of unpaid time off but ended up missing 20 hours of work; he had enough paid vacation time to cover the absence, but he said the company did not pull from that separate bank of days because Pagan would have had to apply for vacation time in advance. Pagan said he also had a doctor’s note but was told the company did not need to accept it as an excuse, even though he had been excused from work with a doctor’s note previously. He said he worked for another full week without issue, until he showed up one night for his overnight shift and his badge no longer worked. He was eventually told he had been terminated.
An HR manager told Pagan that there was nothing he could do about the termination but that Pagan should reapply for a job at the company in three months, per Amazon policy.
“We would love you back in 90 days,” Pagan says the HR staff member told him. In the meantime, Pagan should “do some GrubHub or Uber,” the HR employee said.
“I find the whole situation crazy,” said the 35-year-old Pagan, who was supporting his wife and daughter on his Amazon income. “They’re gonna lose a good worker for nothing.”
Lunak, the Amazon spokesperson, said the company is looking into Pagan’s case.
Besides changing termination or retention policies, increasing pay is another obvious lever that Amazon could pull to expand its labor pool. (All of these are things that workers calling for unionization have demanded from the company.) The report predicted that for every dollar Amazon bumps up its minimum wage, it adds 7 percent more workers to its potential hiring pool. If Amazon were to do a little better, and raise its hourly minimum by just $1.50, that too would expand its pool of potential workers enough to extend its hiring ability in the US by three years.
The internal document also suggested Amazon needs to become more efficient at hiring. At the time the report was written, Amazon needed 6.7 job applicants to apply to fill a single warehouse role. Around 9 percent of applicants were rejected either because they were former employees not permitted to be rehired or because they failed a drug test or had an unsatisfactory background check. (Later in 2021, Amazon said it would stop screening many of its warehouse worker applicants for marijuana use.)
Of course, Amazon could also simply reduce the number of workers it needs by speeding up automation in its warehouses — a controversial approach. Nonetheless, the report revealed that Amazon executives had already in 2021 set a “conservative” goal of improving warehouse productivity by 25 percent by the end of 2024, strictly through increased automation. Hitting that goal on its own would push back the labor crisis as well, but only slightly.
The research team also pondered improvements that could be made to how Amazon already utilizes its existing staff. Amazon’s warehouse staff worked, on average, a little more than 27 hours a week in 2020, according to internal data. If Amazon had increased that weekly number by just 10 percent, the company could have reduced new hires by 118,000 people, the internal report estimated. The report also referenced a team in Amazon’s HR division, called Hamilton, that is building tools to automatically transfer workers between nearby facilities based on staffing levels and order volume. The relocations would come in the form of both “permanent transfers and short-term assignments.”
Lastly, according to the report, Amazon’s HR staffing division wants to play a bigger role in influencing where new warehouses are located so they can ensure the available labor pool is large enough for the company’s needs. For some types of Amazon warehouses, there is little wiggle room. Amazon delivery stations, for example, are the last stop for a package before it’s delivered, so they need to be located within a short driving distance to a large number of Amazon customers. But for others — like “cross dock” facilities that receive merchandise from suppliers, and fulfillment centers that receive goods from cross dock facilities and pack them into customer orders — there is more leeway in the location selection process and so an opportunity to better use internal labor forecasting tools.
“Our longer-term strategy … is to apply labor forecasts to future site selection,” the report read.
Overall, the leaked report offers a variety of solutions to choose from, but each with trade-offs that Amazon executives may not find palatable. Raise wages and the company may need to pull back spending elsewhere. Increase automation and risk the wrath of critics concerned about replacing people with robots at the second-largest private sector employer in the country. A focus on better retaining employees could also mean reducing performance tracking and productivity quotas that have played a role, however controversial, in the company’s historic business success to date.
Amazon has shown time and time again that it values “customer obsession” — and the promises it makes to its customers — above all else. But the customer loyalty that results from that obsession is ultimately at risk if Amazon cannot employ enough people — or robots — to pack and ship the boxes people expect to find outside their front door a day or two after clicking “Place your order.” The company’s new CEO, Andy Jassy, has proclaimed that Amazon is “not close to being done in how we improve the lives of our employees.” As the internal report shows, doing so should no longer be optional for Amazon; it’s an imperative.",6
329,"Gaia sees strange stars in most detailed Milky Way survey to date
Today, ESA’s Gaia mission releases its new treasure trove of data about our home galaxy. Astronomers describe strange ‘starquakes’, stellar DNA, asymmetric motions and other fascinating insights in this most detailed Milky Way survey to date.
Gaia is ESA’s mission to create the most accurate and complete multi-dimensional map of the Milky Way. This allows astronomers to reconstruct our home galaxy’s structure and past evolution over billions of years, and to better understand the lifecycle of stars and our place in the Universe.
What’s new in data release 3?
Gaia’s data release 3 contains new and improved details for almost two billion stars in our galaxy. The catalogue includes new information including chemical compositions, stellar temperatures, colours, masses, ages, and the speed at which stars move towards or away from us (radial velocity). Much of this information was revealed by the newly released spectroscopy data, a technique in which the starlight is split into its constituent colours (like a rainbow). The data also includes special subsets of stars, like those that change brightness over time.
Also new in this data set is the largest catalogue yet of binary stars, thousands of Solar System objects such as asteroids and moons of planets, and millions of galaxies and quasars outside the Milky Way.
Starquakes
One of the most surprising discoveries coming out of the new data is that Gaia is able to detect starquakes – tiny motions on the surface of a star – that change the shapes of stars, something the observatory was not originally built for.
Previously, Gaia already found radial oscillations that cause stars to swell and shrink periodically, while keeping their spherical shape. But Gaia has now also spotted other vibrations that are more like large-scale tsunamis. These nonradial oscillations change the global shape of a star and are therefore harder to detect.
Gaia found strong nonradial starquakes in thousands of stars. Gaia also revealed such vibrations in stars that have seldomly been seen before. These stars should not have any quakes according to the current theory, while Gaia did detect them at their surface.
“Starquakes teach us a lot about stars, notably their internal workings. Gaia is opening a goldmine for ‘asteroseismology' of massive stars,” says Conny Aerts of KU Leuven in Belgium, who is a member of the Gaia collaboration.
The DNA of stars
What stars are made of can tell us about their birthplace and their journey afterwards, and therefore about the history of the Milky Way. With today’s data release, Gaia is revealing the largest chemical map of the galaxy coupled to 3D motions, from our solar neigbourhood to smaller galaxies surrounding ours.
Some stars contain more ‘heavy metals’ than others. During the Big Bang, only light elements were formed (hydrogen and helium). All other heavier elements – called metals by astronomers – are built inside stars. When stars die, they release these metals into the gas and dust between the stars called the interstellar medium, out of which new stars form. Active star formation and death will lead to an environment that is richer in metals. Therefore, a star’s chemical composition is a bit like its DNA, giving us crucial information about its origin.
With Gaia, we see that some stars in our galaxy are made of primordial material, while others like our Sun are made of matter enriched by previous generations of stars. Stars that are closer to the centre and plane of our galaxy are richer in metals than stars at larger distances. Gaia also identified stars that originally came from different galaxies than our own, based on their chemical composition.
“Our galaxy is a beautiful melting pot of stars,” says Alejandra Recio-Blanco of the Observatoire de la Côte d’Azur in France, who is a member of the Gaia collaboration.
“This diversity is extremely important, because it tells us the story of our galaxy’s formation. It reveals the processes of migration within our galaxy and accretion from external galaxies. It also clearly shows that our Sun, and we, all belong to an ever changing system, formed thanks to the assembly of stars and gas of different origins.”
The text continues below the slider
Binary stars, asteroids, quasars, and more
Other papers that are published today reflect the breadth and depth of Gaia's discovery potential. A new binary star catalogue presents the mass and evolution of more than 800 thousand binary systems, while a new asteroid survey comprising 156 thousand rocky bodies is digging deeper into the origin of our Solar System. Gaia is also revealing information about 10 million variable stars, mysterious macro-molecules between stars, as well as quasars and galaxies beyond our own cosmic neighbourhood.
“Unlike other missions that target specific objects, Gaia is a survey mission. This means that while surveying the entire sky with billions of stars multiple times, Gaia is bound to make discoveries that other more dedicated missions would miss. This is one of its strengths, and we can’t wait for the astronomy community to dive into our new data to find out even more about our galaxy and its surroundings than we could’ve imagined,” says Timo Prusti, Project Scientist for Gaia at ESA.
Notes for editors
More details on Gaia’s data releases 3 can be found here: https://www.cosmos.esa.int/web/gaia/data-release-3
From 13 June 2022, 12:00 CEST onwards, the new Gaia data can be accessed at https://gea.esac.esa.int/archive/
Gaia’s data release 3 was presented today during a virtual media briefing at https://www.esa.int/ESA_Multimedia/ESA_Web_TV
This media kit summarises the data in a series of infographics: https://www.esa.int/Science_Exploration/Space_Science/Gaia/Gaia_data_release_3_media_kit
More in-depth stories on the new Gaia data can be found here: https://www.cosmos.esa.int/web/gaia/dr3-stories
A series of scientific papers describing the data and their validation process will appear in a special issue of the journal Astronomy & Astrophysics: https://www.cosmos.esa.int/web/gaia/dr3-papers
For more information, please contact:
ESA Media Relations
Email: media@esa.int",5
330,nytimes.comPlease enable JS and disable any ad blocker,9
331,"Every day, without our realizing it, the images, text and other data we post for our own purposes are scrutinized and collected by countless outside eyes for purposes we are unaware of and would often not consent to if we were aware of them. This process of collection and analysis is known as “data scraping” or “web scraping.” Though scraping overrides people’s will without scruple and enlists their contributions in initiatives they would reject, most people in the tech industry take scraping for granted as a ubiquitous, unavoidable part of the everyday operation of web technology. Some claim that it can be harnessed as a force for good, even as it has empowered data brokers, surveillance tech merchants, and forms of automation and algorithmic administration. Is it defensible? Is it necessary? Should it be outlawed altogether, or allowed without any regulation at all?
Scraping is related to but distinct from “web crawling,” which Google and Archive.org, for example, use to gather the contents of web pages. Whereas web crawling usually implies a known and anticipated process of indexing the content of sites so that people can find them, and which can be blocked by platforms, “scraping” aims to extract data from pages for further processing, with proprietary aims in mind that may have nothing to do with the information’s original context, typically in such a way that it cannot be blocked by users or platforms. Somewhat like eavesdropping or its online equivalent, key logging, “scraping” connotes a partly or entirely clandestine form of data collection. Implicit in the basic idea of scraping is that data is being put into a different form and then turned to different uses from the ones that user or a site’s administrator intends. This secondary use or analysis distinguishes scraping from the closely related activity of hacking a site to take (or, far more often, copy) data.
Regardless of its uses, scraping can sound like intrusive hacking — because it is
The technique is commonly used in the financial industry, for uses as apparently benign as tracking mentions of a company’s stock in social media, or tracking mentions of a company’s corporate actions and their reception. It is commonly used to track aspects of human resource management, including how many people are changing jobs or expressing interest in doing so. Some data brokers make intensive use of this process, in some cases apparently building their whole products on data obtained through the method.
The data broker industry is clouded in mystery, not only taking data from users without their permission, let alone their knowledge, but also refusing to make clear to their customers the sources of their data. The practices of the industry have long been questioned. Investigative journalist Julia Angwin co-authored a 2010 article in the Wall Street Journal drawing attention to data brokers and their use of scraping; at the time she found that the media research firm Nielsen was gathering highly personal information about the mental health conditions of people who posted to discussion boards, a practice Nielsen says it has discontinued. Meanwhile, last week, Senators Elizabeth Warren, Ron Wyden and others have introduced a bill seeking to block data brokers who may be collecting data, including scraped third-party data, from users “researching reproductive health care online, updating a period-tracking app, or bringing a phone to the doctor’s office,” all of great concern given the U.S. Supreme Court’s imminent threat to Roe v Wade.
Yet scraping is not just used to produce financial profit or directly harm vulnerable people. Academic researchers, journalists, and activists also scrape data to analyze and better understand the practices of institutions and classes of people, like say, landlords or white supremacists, or to limn the nature and extent of disinformation networks. Some of these uses are so benign it is hard to imagine preventing them: the New York Times, like other newspapers, scrapes election results from local governments and newspapers in order to gather national data; the Times publishes the code for its scraper on GitHub. Perhaps slightly more controversial — in that they turn data against the uses its creators intend — are some of University of Washington researcher Kate Starbird’s many investigations of disinformation and the far right, which sometimes use scraping especially to gather and analyze data about the connections between far-right disinformation promoters and the sites that spread disinfo. Data journalism site The Markup uses scraping methods for its invaluable work, including the “Citizen Browser” application it developed, installed by more than 1,000 paid participants, to gather and analyze data on Facebook’s advertising practices that the platform does not make publicly available.
Regardless of the uses to which it is put, to most of us, scraping can sound like a kind of intrusive hacking — because it is. Yet scraping is widely conducted for range of purposes and is seen as a legitimate practice by many in the tech industry. Much more of the web operates via scraping than many of us realize. This poses problems for thinking about how to regulate, legislate, and even build web-based technology. To block such third-party access requires surprisingly complicated mechanisms for distinguishing between ordinary users and scrapers. While some forms can be programmatically blocked — there are many commercial and open source software tools available that web providers can install to prevent scraping, and familiar features like Captchas exist in part to block unwanted scraping — scrapers are always building more sophisticated tools, setting off an arms race between scrapers and blocking technology familiar from efforts to fight spam and perform content moderation.
Scrapers often claim authorization is superfluous because the data they access is nominally “public.” Hoan Ton-That, the CEO of Clearview AI — a surveillance tech company whose main product is based on scraped images — routinely justifies the company’s practices by stating that it collects “only public data from the open internet and comply with all standards of privacy and law.” According to Kashmir Hill’s New York Times report in 2020, the company collected “images of people’s faces from across the internet, such as employment sites, news sites, educational sites, and social networks including Facebook, YouTube, Twitter, Instagram and even Venmo” despite the fact that “representatives of those companies said their policies prohibit such scraping, and Twitter said it explicitly banned use of its data for facial recognition.”
Scraping disregards contextual integrity and asserts a right to inhale entire data sets and process them
The norms surrounding that kind of public-ness have often been debated, particularly with respect to Twitter, where there has been some controversy over whether journalistic outlets can quote a user’s public tweets without their consent. Privacy scholar Helen Nissenbaum refers to this problem when she writes about “contextual integrity”: that users tend to assume that publicity should go only as far as they contexts they are able to anticipate, despite tools that make it easy for interlopers to do much more.
Scraping disregards claims of contextual integrity and instead asserts the right to inhale entire data sets and process them for the use of others. That is, scrapers assert that data made public in its user-facing form is also public in something like its algorithmic form: Not only did the user agree to publish their tweets, but they also agreed to publish all the inferences, post-processing, and analysis that data services might make based on their tweets, which typically go well beyond what most users understand.
As I put it in 2018, we don’t know what “personal data” means. In other words, social media users have a limited understanding of the uses to which data generated by them and about them on platforms can be put. It’s natural to believe that posting a picture or tweet to a public feed means simply that some other user might look at it. We may or may not know or approve of that other viewer, but that seems like the end of the story. Thus users may assume that the content and the form of their posts remain intact after they post it. But they don’t consider how that those posts turn into what specialists call derived and inferred data, two categories that facilitate further algorithmic processing, including AI techniques like machine learning.
Using a variety of techniques, data that appears to be about one thing can be made to reveal many other things. Fully “anonymized” location data on a phone might turn out to be easily associated with the only person who lives at one of the addresses at which the phone is often found. Buying some products and not others reveals a great deal about the makeup of one’s household. And in more extreme cases, which are also the ones on which the data broker industry thrives, apparently innocuous data like the music a person likes can turn out to reveal their religious backgrounds and political affiliations (exactly what Cambridge Analytica is said to have done before it was put out of business). It is fair to say that many people might willingly share the fact that they like BTS, while being entirely unaware that they are also sharing their voting behavior.
This is the essence of the violence implicit in the choice of the term scraping to describe this form of data collection: the process of dislodging data from one context and forcing it into another, where we no longer control in any way how that data is used, what meanings are inferred from it, whether it is “accurate” to begin with, and whether its extended uses are accurate. Scrapers’ indifference to consent means not only that their methods are ethically dubious but also that their data and results are tainted and conceptually unreliable. Any application derived from scraped data carries that stigma.
The scraping practices of Clearview AI are now coming under intense scrutiny from lawmakers and digital rights advocates, and the arguments presented by both its advocates and its critics help illustrate how many common intuitions about “privacy” and “free speech” do not always serve us well when applied to novel digital contexts.
The most prominent court case to involve scraping so far involves a small data services company called hiQ that sued LinkedIn over the ability to scrape data from LinkedIn’s platform. According to court filings, LinkedIn uses a variety of means to protect its users from scraping and related techniques, including a “Do Not Broadcast” option used by more than 20 percent of all active users, a “robots.txt” file that prevents scraping by many entities (although it allows the Google search engine to web crawl), and technical means (including ones it calls Quicksand and Sentinel) that detect and throttle “non-human activity indicative of scraping.” Despite these protections, hiQ managed to offer its clients two services based on scraping LinkedIn data, including one that “purports to identify employees at the greatest risk of being recruited away” and another that helps “employers identify skill gaps in the workforces so they can offer internal training in those areas.” In 2017, LinkedIn sent hiQ a cease-and-desist letter, claiming that its operations violated LinkedIn’s terms of service and a number of California state and U.S. federal laws.
The 2019 Ninth Circuit Court of Appeals ruling — affirmed in April 2022 — ordered LinkedIn to allow hiQ to continue its scraping business. It stated that “there is little evidence that LinkedIn users who choose to make their profiles public actually maintain an expectation of privacy with respect to the information that they post publicly,” and that “even if some users retain some privacy interests in their information notwithstanding their decision to make their profiles public, we cannot, on the record before us, conclude that those interests … are significant enough to outweigh hiQ’s interest in continuing its business.”
Perhaps surprisingly, this decision was celebrated by civil liberties and digital rights advocates, portrayed as a victory for “internet freedom” and “the open web” because some of these groups affirm a right to scrape, seizing on what they regard as socially beneficial use cases, despite that fact that cases like hiQ’s that seem to abuse privacy and consent are far more prevalent. If you thought that, for example, the Electronic Frontier Foundation’s aim of “defending your rights in the digital age” would mean rejecting a rigid “public is public stance,” you’d be wrong: It celebrated hiQ’s victory, mostly because it undermines the Computer Fraud and Abuse Act, a favorite target of cyberlibertarians who believe the rarely used law criminalizes ordinary and inoffensive conduct (the Department of Justice has recently issued guidance clarifying that it will not prosecute such conduct), but also because it champions the right to analyze “public” data over the right to protect it.
Scrapers’ indifference to consent means their data and results are conceptually unreliable
Other organizations have situationally taken a similar stance, in service of different politics. Just a month before the most recent hiQ ruling, the ACLU and NAACP’s South Carolina chapter sued the South Carolina Court Administration over its prohibition of scraping a county-by-county database of legal filings, claiming “a protected First Amendment right to access and record these public court records for these purposes.” Of course, the NAACP’s claim that it needs access to those records to challenge the eviction of renters from their homes is compelling. As the plaintiffs put it, “scraping is widely employed by researchers, reporters, and watchdog groups to capture and evaluate population-level data on websites which would be impracticable to collect using manual methods.”
Yet as the hiQ case shows, these same arguments are used not just by social justice advocates but also by companies whose products are built on the invasion of privacy in the face of relatively explicit user requests to stop. In both the ACLU/NAACP lawsuit and some coverage of hiQ, activists present it as given that the “researchers” and “academics” they represent intend only “good” uses for scraping technology. But the idea that they form a separate class of good-faith operators whose needs for scraped data are entirely different from those of corporate privacy invaders needs much more scrutiny. Despite the express anti-racist purpose to which, in the ACLU/NAACP filing’s no doubt honest assertion, the scraped data will be put, it’s hard to see how their legal arguments would not apply just as fully to one of the data brokers who provide “tenant screening” to landlords, and who may well see a simple filing for eviction — whether justified and eventually adjudicated in the tenant’s favor or not — as a red flag.
Even a moment’s reflection will reveal that, in fact, academics and researchers themselves don’t all agree about much of anything. Further, many academic and nonprofit bodies work very hard to support business interests, from megacorporations like Facebook/Meta to small startups. Cambridge Analytica notoriously built itself on the work of Stanford business professor Michal Kosinski, who has a troubling history of developing invasive or controversial techniques in academic research. “Most of my studies have been intended as warnings,” he has said, while nonetheless describing in great how to do what he purportedly warns against doing, including determining political orientation from facial recognition, inferring the “personality of countries,” and claiming facial recognition can be used to infer sexual orientation. It is hard to read tech journalist Issie Lapowsky’s 2018 story without concluding that academic research using scraped data made possible Cambridge Analytica’s behavioral modification product. Many other would-be behavioral-modification providers — possibly including Cambridge Analytica’s shadowy successor companies, and data mining companies like Peter Thiel’s Palantir — continue to operate all over the world with relative impunity. Efforts to understand and enumerate, let alone regulate, these companies have proved very difficult.
These contradictory tendencies came to a head in a suit filed by the ACLU against Clearview AI for violating user privacy by scraping photos. The suit, recently settled, was partly based on the Illinois Biometric Information Privacy Act, which requires consent for faceprinting Illinois citizens along with other forms of biometric collection. Notably, in states without a similar law, the ACLU and other digital rights advocates have taken different positions. In the South Carolina case, for instance, the ACLU does not mention consent as an important consideration and generally argues against prohibitions of the sort of scraping that would almost certainly create the same kinds of issues as the Illinois case. In the hiQ case, the ACLU was among the many groups celebrating the “freedom” of commercial data harvesters to violate the express wishes of ordinary people.
Clearview has argued that its product cannot be regulated because of First Amendment protection, an argument rejected by most courts that have heard it and criticized by the ACLU itself. But it has been pushed by prominent First Amendment attorneys, including Floyd Abrams, who in Citizens United joined the ACLU in arguing that limits on campaign spending were unconstitutional prohibitions on speech. Clearview’s position was also supported by some of the right-leaning legal thought leaders like the libertarians at Reason who deploy the First Amendment as a shield against tech regulation. As Mary Ann Franks demonstrates in her book The Cult of the Constitution, the ACLU has often joined with EFF and other “digital rights” organizations to shape and oppose privacy laws in ways that seem favorable to the interests of invasive companies.
In its settlement announcement, the ACLU celebrated that “Clearview is permanently banned, nationwide, from making its faceprint database available to most businesses and other private entities.” Yet Clearview and its advocates read the still pending settlement differently. Abrams claimed, as this Guardian story reports, that it “does not require any material change in the company’s business model or bar it from any conduct in which it engages at the present time.”
That both sides declare clear and unambiguous victory while disagreeing almost entirely about what the victory means is not unusual in tech regulation and litigation. It shows that our basic (largely pre-digital) intuitions about fundamental ideas like “private,” “public,” “consent,” and “expression” do not always serve us well when we attempt to apply them to digital technology. Perhaps entirely new concepts are needed, or new ways to stretch our old concepts to the new environment.
Not just industry itself, but some of the digital rights groups that pursue multiple policy goals frequently find themselves on both sides of promoting and criticizing scraping. In the ACLU’s case, it stems from being a national organization with many divisions and many state-level chapters. But it also points to a problem that has long frustrated at least a minority of academics: how the ACLU, EFF, and others like Fight for the Future, and quasi-academic organizations like Data & Society, the Berkman Center, and the MIT Media Lab establish themselves as the go-to sources to protect “human rights in the digital age.” Some of these organizations — indeed most of them — have murky relationships with technology developers and technology corporations (EFF, for example, lists “innovation” as one of its core values in its tagline, more typically a point of emphasis for corporate lobbies than civil rights organizations), and they frequently engage in dismissive conduct toward people outside their organizations, especially those whose opinions don’t line up with their own carefully crafted position statements.
Is scraping abuse? Some cases, like Clearview AI, certainly make it seem so, but as a general principle I don’t think a fair observer can really answer that question. Our knowledge as users and observers of digital media is far too limited. We need robust regulatory regimes of the types so far implemented largely in the European Union even to start to judge the ethics and politics of scraping: laws and regulations that require data brokers and scrapers to make clear what they are doing and perhaps even register their businesses, as Vermont has tried to make them do. We need better typologies of scraping and scraping-like activities so that we can develop richer accounts of consent to share data, and of analysis and processing of that data. Digital rights advocates need to leave much more space for consumers, academics, and others to come up to speed on the various ways that our data is used and to weigh in on what does and does not conform to our expectations of privacy, publicity, and dignity.
Liz O’Sullivan contributed to an early version of this piece.",5
332,Feral AtlasYou need to enable JavaScript to run this app.,7
333,"Non-Obvious
Megatrends
How to See What Others Miss and Predict the Future
After ten years of sharing insights and curating trends that describe how our world is shifting, this edition brings it all together for one final year. Yes, it’s the last year of the Non-Obvious trend series, and so it’s bigger than any other. In this completely revised edition, not only will readers find an updated modern design throughout – but the ten identified megatrends apply insights and predictions from the past ten years to identify BIGGER ideas that will shape our world in the decade to come. The megatrends range from focusing on how we will interact with technology to how we will learn to how we see our own self identity in the future. In addition, like with past editions, this new version includes a detailed and transparent appendix with ratings and assessments of EVERY past trend prediction (more than 100!) along with ideas for how to use these trends and megatrends in your daily life.
Eric-Hoffer-Award-Seal-2021
ABA20_Gold_Winner
INDIE Book Award Transparent
Axiom Gold Medal
Readers Favorite
MEA Logo
Soundview-2020-BestBook-Badge-Gold-150x150
Eric-Hoffer-Award-Seal-2021
ABA20_Gold_Winner
INDIE Book Award Transparent
Axiom Gold Medal
Readers Favorite
MEA Logo
Soundview-2020-BestBook-Badge-Gold-150x150
INDIE Book Award Transparent
Summaries.com
Independent Press Award Transparent
AMA-Book-Prize_color
Eric hoffer award larger
CES Innovation Award
ippy_silvermedal_LR-transparent
INDIE Book Award Transparent
Summaries.com
Independent Press Award Transparent
AMA-Book-Prize_color
Eric hoffer award larger
CES Innovation Award
ippy_silvermedal_LR-transparent
Axiom silver medal badge - transparent
INDIE EXCELLENCE BADGE
International book awards
Nonfiction-Award-04.2.3-Gold-transparent
NewPinnacleAward3D2
Axiom silver medal badge - transparent
INDIE EXCELLENCE BADGE
International book awards
Nonfiction-Award-04.2.3-Gold-transparent
NewPinnacleAward3D2
Flux Commerce
Protective Tech
Data Abundance
Purposeful Profit
Attention Wealth
Instant Knowledge
Ungendering
Contact
Have a Question or Inquiry?
All emails will get a response within 24 hours!",2
334,"So far, the year 2022 has certainly looked like a deflating technology bubble. After a decade of rising market caps, stocks for formerly hot “tech” companies fell far below their recent highs. By September 2022, exercise equipment maker Peloton was down 90 percent from a year before; ridesharing company Lyft had fallen 70 percent; videoconferencing firm Zoom, 70 percent; electric vehicle manufacturer Rivian, 60 percent; Meta (or Facebook), 60 percent; Netflix, 60 percent; the gory list goes on. Many recent new technologies have simply failed to meet expectations. For instance, despite predictions that the economic gains from AI would reach $15 trillion by 2030, the market for AI in 2021 was only $51.5 billion, expected to reach $62 billion in 2022.
This downturn is occurring at the end of record spending on innovation by venture capital firms and incumbents such as Google. Futuristic technologies such as quantum computing, nuclear fusion, bioelectronics, and synthetic biology have received massive funding in recent years. And while exuberance around a host of new technologies from the past decade—like self-driving cars, delivery apps, home flipping, and augmented reality—recedes, VCs are working to inflate new bubbles around other, much-hyped technologies, such as the Metaverse and Web3, which is a part of the wider excitement around blockchain technologies. The shelf life of ebullience for the Metaverse and Web3 is, of course, unclear, but a much more important question is this one: how do such technology bubbles affect the broader economy and society?
Answering this question requires looking at the broader economic and social context in which these bubbles develop. Of course, this broader context is large and complex, but here is one road in: For at least a century now, there has been a widespread faith that technological progress will improve human well-being, including via economic growth. For much of the twentieth century, new industries developed around new technologies. These industries created well-paying jobs and flourishing communities. Use of the new technologies improved quality of life and, by enhancing productivity in mass production industries, greatly reduced prices, leading to even relatively poor people being able to afford increasing quantities of both necessities and modern conveniences. The period from the late nineteenth to the mid-twentieth centuries witnessed a remarkable era of innovation, perhaps the most significant in human history. Running water, electricity, mass production, the telephone, and the automobile provided improvements to our standard of living that have not been equaled by recent innovations.
But as economist Robert Gordon examined in his book The Rise and Fall of American Growth, the technological growth engine hit hard times beginning in the 1970s. With the brief exception of a period between 1994 and 2004, which we will examine in greater detail below, improvements to business efficiency, or productivity, have remained stubbornly low since the 1970s. This period of low productivity growth has remained true right up through the technology bubble of the last decade, when technophiles were singing the praises of robots and AI. Indeed, contrary to expectations that the Covid-19 pandemic would spur ever widening adoption of automation in businesses, productivity was negative for the first two quarters of 2022.
Meanwhile, basic economic conditions have become more precarious for many people. For the past decade, the United Way’s alice program has attempted to measure how much of the population faces economic hardship, taking into account both the cost of living and available incomes. Working at the county level in about half of the United States, alice routinely finds that about 40 percent of the population struggles to make ends meet. While this reality hits some groups harder than others, it affects all races, genders, and other identities, from the majority of white populations in, for example, dying manufacturing and mining towns in Appalachia to majority black populations on the Southside of Chicago or rural Alabama. The reality of hardship plays out in places with long-standing black poverty, examined in classics like William Julius Wilson’s When Work Disappears (1996), as well as in Anne Case and Angus Deaton’s study of the more recent rise of “deaths of despair.”
Our question is whether newly hyped technologies, like the Metaverse, Web3, and blockchain, have any chance of changing this basic picture. There are many reasons to be skeptical that they can. In many ways, the Metaverse and Web3 are merely a pivot by Silicon Valley, an attempt to gain control of the technological narrative that is now spiraling downward, due to the huge start-up losses and the financial failure of the sharing economy and many new technologies. Huge start-up losses along with the small markets for new technologies have brought forth novel criticisms of Silicon Valley. If we are correct that the newest wave of hot technologies will do almost nothing to improve human welfare and productivity growth, then elected officials, policymakers, leaders in business and higher education, and ordinary citizens must begin to search for more fundamental solutions to our current economic and social ills.
In what follows, we will first review Web3 and the Metaverse. Multiple industry insiders claim that these technologies require far better infrastructure than currently exists, and that their constituent technologies of blockchain, crypto, virtual and augmented reality (VR and AR) aren’t working well by themselves. Second, we examine the economic effects of bubbles by comparing the current technology bubble to past ones. The biggest difference is that some goods did emerge from the dot-com bubble, but not from the housing bubble, and probably not much will result from the current bubble either. Third, we describe changes in America’s system of basic and applied research that might be preventing new, more useful ideas from emerging, particularly those based on advances in science. Finally, we sketch out alternative roads for future technological and economic development. The current ecology of technology, including venture capital and both corporate and university R&D, is failing society. Together, we must look for other paths forward.
The Metaverse and Web3
Many technology suppliers have already thrown cold water on the overall concepts of the Metaverse and Web3. An Intel executive says, “Truly persistent and immersive computing, at scale and accessible by billions of humans in real time, will require even more: a 1,000-times increase in computational efficiency from today’s state of the art.” Even Meta admits that its grand ambition of building the ultimate Metaverse won’t be possible if there aren’t drastic improvements in today’s telecom networks.
Indeed, vague terms like Web3 and the Metaverse seem designed to fool people, to convince them that companies using this marketing have come up with something new that hasn’t been tried before. After years of investment and promotion, two key parts of the metaverse, virtual and augmented reality, are still not popular—probably because they don’t work well. Poor resolution, low brightness, bulky headsets, and lack of additional sensory feedback have produced poor experiences for most VR users, including inducing nausea when using the goggles. Other aspects have not been improved for decades, including headset size. Apparently, it is difficult to make devices smaller without sacrificing field of view, which is a big reason why typical AR headsets have a field of view that is too small to be useful. Proponents don’t seem to realize that both VR and AR will require years if not decades of improvement. A recent leak of Meta documents, reported by the Wall Street Journal, revealed that Metaverse user numbers are far below expectations, that most users don’t return after the first month, and that virtual real estate trading volumes are down 98 percent in 2022.
Web3 has similar problems with its enabling technologies. While it isn’t our job to define the nebulous term Web3, we do know that two key constituent technologies, crypto and non-fungible tokens (NFTs), are not doing well. After years of proponents claiming it was a great hedge against inflation in so-called fiat currencies, some types of crypto have collapsed, exchanges have gone bankrupt, and even the most popular cryptocurrency, Bitcoin, has seen its price decline by more than half in the last six months. This has also pushed down the prices of digital tokens. The prices of NFTs plunged in the first half of 2022. So far, these seem to be products in search of an economic rationale.
Blockchain is also a disappointment despite being initially developed in the 1960s and reintroduced fourteen years ago by an unknown person or persons under the pseudonym Satoshi Nakamoto. Journalist Izabella Kaminska, testifying before the UK House of Commons Science and Technology Committee on Blockchain in mid-2022, stated that she “can’t think of a single successful deployment of blockchain” outside of financial speculation. During 2016 and 2017, there was a lot of hype surrounding blockchain technology, but “now in 2022 when we look back, almost nothing has come out of that hype.”
The problem is that most implementations must sacrifice some part of the blockchain concept, which can be summarized as “[a]n open-source technology that supports trusted, immutable records of transactions stored in publicly accessible, decentralized, distributed, automated ledgers.” The key points of differentiation with existing technologies here are “trusted,” “immutable,” “publicly accessible” (transparent), “decentralized,” and “distributed.” Because the term distributed actually means replicated, there are typically many copies of the underlying datasets in which updates must be synchronized via a convoluted and sometimes inordinately inefficient process known as “consensus.”
This makes blockchain highly inefficient, especially in energy usage, and it has hit insurmountable roadblocks in throughput and performance.1 As a result, constraints such as “trusted (by consensus)” and “decentralised” have been dropped in so-called permissioned blockchains—i.e., blockchains created and operated by some form of “central authority.” Having a central authority does of course eliminate an important selling point, the decentralization. Nevertheless, it was hoped that these “permissioned” blockchains would be much more efficient than permissionless versions, but unfortunately, relaxing these constraints only undermined a key rationale behind blockchain without delivering much success in other areas.
One such example was Facebook’s plan in 2019 to create a global digital currency, called Libra, which would be built upon a global blockchain and would supposedly empower millions of the world’s unbanked poor. After building an impressive proof of concept, Facebook faced resistance from legislators and regulators, and dropped the idea, though it lives on in a much-reduced form.2
In the following year, an analysis by a pro-blockchain organization, the British Blockchain Association, showed that a vast majority of the blockchain projects they surveyed had no well-described rationale, no predetermined criteria for achievement, and no analysis of success or failure. In other words, they were merely pie-in-the-sky ideas, based on hype rather than detailed analysis or justification. And none of the projects benchmarked themselves against existing, proven technologies.
For example, in cooperation with both small producers and large retailers, such as Walmart, IBM claimed to have built blockchain supply chains in the “food trust” area. But this solution was, in fact, centralized, driven by Walmart, with no consensus, and with transparency that can be implemented using privacy functions built into existing database technology.
Similarly, the use of blockchain has been trumpeted in shipping supply chains, most prominently in a project led by Maersk and, again, IBM. Unfortunately, this logistics blockchain system looks like a conventional software system, with the only discernible use of blockchain being a list of document versions which could be handled, perhaps even better, in a conventional database. Meanwhile, a similar, large blockchain‑based shipping program operating as We.trade has recently closed down after running out of cash.
Perhaps the most notable example of blockchain being deployed as the wrong solution to the wrong problem is the case of the Chess Replacement project undertaken by the Australian Securities Exchange (ASX). This project, to replace the venerable Chess equities settlement system, was first started at the height of the blockchain hype in 2017 by the ASX and a fledgling U.S. software company, Digital Asset. Unfortunately, the project has exceeded its budget by at least a factor of five, announced five separate delays in delivery, and is currently on hold, pending the outcome of yet another independent inquiry.3 In summary, many blockchains have been forced, by the realities of business requirements, to deviate significantly from their initial concepts and have been reduced to little more than blockchains in name only.
Previous and Current Bubbles
There are arguably bubbles around new technologies like blockchain, the Metaverse, and Web3, but the larger question is how these bubbles will affect the broader economy and society. Here it is helpful to compare our current moment to two previous bubbles, namely the dot-com bust and the housing bubble, which burst in 2000 and 2008, respectively. What we find is that our current bursting bubble shares some things in common with both, including layoffs, cutbacks, large losses in asset values, and potentially looming bankruptcies. But while the dot-com bubble led to significant advances in technology and business organization, our current bubble seems more like the housing bust, because few real gains are likely to be left once the bubble deflates.
Start-ups with big losses, no revenues, and large debt-to-income ratios did successful IPOs during the dot-com bubble, just as they have again in recent years. From its peak in March 2000, the nasdaq fell 60 percent in a single year, and hundreds of dot-com startups went bankrupt. During the housing bubble, banks provided subprime mortgages and repackaged them into seemingly low-risk investments that ended up proving very risky. Markets fell about 50 percent from their peak in late 2007, and the 2008 crash led to bankruptcies for 64,318 firms, including Lehman Brothers, and government-brokered rescues from bankruptcy as in the case of Merrill Lynch.
Yet in exploring such similarities, it is easy to lose sight of how many successful technologies and businesses came out of the dot-com years. The dot-com bubble gave us e-commerce, websites for news and other content, enterprise software such as customer relationship management and manufacturing resource planning, and the widespread use of mobile phones. These changes also quickly led to large markets. E-commerce, internet hardware, software, and mobile service revenues reached $446, $315, $282, and $230 billion, respectively, by 2000 (in 2020 dollars). PC revenues were $132 billion in 1990. Internet-connected personal computers also likely led to significant economic growth, with a period of high productivity gains between 1994 and 2004 that outpaced both the period from 1970 to 1994 and the period between 2004 and the present.
The dot-com bubble also gave us many successful start-ups. Those that have achieved top-100 market capitalization include Amazon, Cisco, Qualcomm, Yahoo!, eBay, Nvidia, Paypal, and Salesforce, several within ten years of their founding and most within twenty years. Some are still among the top 100 in market capitalization.
The growth continued in the 2000s. Cloud computing had global revenues of $127 billion by 2010, and online advertising reached $81 billion in the same year (in 2020 dollars). Facebook had 550 million users by the end of 2010. The iPhone was introduced in 2007, the App Store in 2008, and Android phones also in 2008. The global revenues for smartphones reached $293 billion by 2012 and web browsing, navigation services, and other apps were widely used. Facebook, Netflix, and Google are three start-ups that benefited from these new technologies and are now among the top 100 in terms of market capitalization.
We see something different in the 2010s, a decade of growing markets for existing technologies but less so for new ones. Although revenues for e-commerce, cloud computing, smartphones, online advertising, and other technologies continued to grow, only one single category of new digital technology achieved $100 billion in sales by 2021, and that was big data. Other “new technology” categories faltered. For instance, despite all those promised deliveries from drones, commercial drones had a market size of only $21 billion. The markets for VR and AR, expected to explode during the pandemic, only reached $6 and $25 billion, respectively. The market size for blockchain applications (not cryptocurrencies), the basis for much of Web3, was $4.9 billion. The market for AI software and services was bigger, at $58.3 billion, similar to that of OLED displays at $53 billion. What these smaller market sizes mean is that, compared to the earlier technologies we mentioned, individuals, at both work and home, have thus far found the technologies of the 2010s less useful than earlier ones. If the new technologies were useful, more people would have bought them, and the technology’s respective market sizes would have grown much faster.
Big data was the only one of these new digital technologies to exceed $100 billion in 2021, if we include analytics and AI, reaching $163 billion. The backlash to these algorithms, however, has been huge, beginning at least as early as 2016 with Cathy O’Neil’s book Weapons of Math Destruction. Algorithms that predict crimes, determine sentencing, decide the parole of imprisoned convicts, identify criminals through photos, or aid social workers have continued to be criticized in 2022. And the ones used to predict housing prices or insurance claims or fraud have led to big losses for start-ups. All in all, it is hard to claim that big data has brought benefits equal to that of PCs, e-commerce, and smartphones of previous decades.
The small markets for new technologies are a big reason why today’s unicorn firms, or private start-ups with a valuation over $1 billion, are far less successful than those of the dot-com bubble. A simple metric to compare them is cumulative losses, the losses accumulated prior to profitability. Sixteen of today’s unicorn start-ups now have greater than $3 billion in cumulative losses; Uber has the biggest losses ($31.2 billion) in the United States. At the end of 2021, there were seventy-seven publicly traded (ex-)unicorns with cumulative losses greater than annual revenues. In comparison to past success stories, this feat was briefly achieved only by Amazon when its cumulative losses peaked at $3 billion more than fifteen years ago.
Similar problems exist outside the United States, with many ex-unicorns having similarly large cumulative losses in China, India, and Singapore. Video-streaming service Kuaishou has the largest cumulative losses of any ex-unicorn as of mid-2022, $57.4 billion. Many others have cumulative losses higher than their 2020 revenues.
Then there are the market capitalizations of these start-ups, particularly the American ones. Yahoo! (founded in 1994) reached the top-100 global firms by year five, Google by year eight, and eBay by year ten. But among today’s unicorns, many of which were founded fifteen years ago, none are among the top 100. Only one (Airbnb) is among the top 200, and three others are among the top 300 (Uber, Moderna, Snowflake). Only Moderna is profitable.
If we focus on AI startups, the results are even worse. Only two publicly traded companies, SoundHound and c3.AI, can be truly defined as AI firms, and their market capitalizations are less than $2 billion each. If we expand the scope of AI and include big data and other aspects of software, the situation looks slightly better. Companies among the top 500 include Snowflake (data warehousing) and Crowdstrike (security), but neither are even close to being profitable.
To summarize, when the dot-com bubble deflated, we were left with lasting improvements such as e-commerce, digital media, and enterprise software, but our current bubble has involved investors running up the stock prices of firms working on technologies that have produced demonstrably less value. When the air goes out of this bubble, we very well may be left with hardly anything of value at all.
Changes in Basic and Applied Research
While venture capitalists are partly to blame, America’s system of basic and applied research has also undergone major changes since the early years of Silicon Valley’s success, changes that have likely caused fewer genuine science-based opportunities to emerge as candidates for commercialization. Silicon Valley was named for silicon-based semiconductors, one type of science‑based technology, which powered much of America’s innovation in the last half of the twentieth century. Other important technologies that emerged from scientific research in the mid-twentieth century include polymers (i.e., plastics), nuclear power, lasers, jet engines, radar, LEDs, and glass fiber, many of which earned their developers Nobel Prizes.
The biggest change from that era is the decline of basic and applied research at companies. Until the 1970s, most of this research was done at corporate laboratories such as Bell Labs, RCA, and DuPont, research that led to both Nobel Prizes and real products and services such as transistors, integrated circuits, plastics, and radar. This dominance began to change in the 1960s, for many reasons, one being the increased funding for universities. Increases in funding caused the number of PhD degrees awarded annually in the United States to rise more than eight times since 1950. In some social circles, it is now considered much more prestigious to work for a university than a corporate laboratory. Universities train PhD students to become adept at the former and not the latter. They learn to do literature searches and write papers while product commercialization is largely forgotten. Universities are proud of their PhD students who become professors; corporate research is seen as second class.
But there are many problems with higher education becoming the primary locus of basic and applied research, and thus the main source of new ideas to be commercialized. First, there is far too much emphasis placed on publishing papers and not enough on developing new technologies up to the point at which companies can commercialize them. There are even too many papers for researchers to read, causing publication counts or dubious indices like the h-index to become mostly useless. Counting the number of publications or calculating h-factors has created an environment of quantity over quality, in which the status of the submitter often determines the outcome. Papers with more than one hundred authors are not uncommon. Some estimates say half of all peer-reviewed articles are not read by anyone other than the author, journal editor, and reviewers.
This publish-or-perish culture has also encouraged researchers to game the system, which undermines the usefulness of publication and citation counts. This is an example of Goodhart’s law: “When a measure becomes a target, it ceases to be a good measure.” For science and research conducted at universities, a publication list determines every hire, grant application, promotion case, and salary review, and thousands of today’s professors have much higher h-indices than did Albert Einstein and Richard Feynman.
A similar process of routinization has transformed other parts of the scientific landscape. Grant applications are more rigidly structured, elaborate, and hype-ridden, as are requests for research time at major observatories or national laboratories. And anything involving work with human subjects, or putting instruments in space, involves heaps of paperwork. Overall, there has been an enormous increase in the amount of paperwork university researchers must do. These professionalizing tendencies are an all but inevitable consequence of the explosive growth of modern science. Standardization makes it easier to manage large numbers of papers, applications, and people. But a lot of unproductive effort goes into jumping through bureaucratic hoops, and outsiders face barriers to entry at every turn. No wonder science and innovation have slowed.
One scientist argued in Nature that scientists must publish less, or good research will be swamped by the ever-increasing volume of poor work. A recent study found that more papers impedes the rise of new ideas. Another problem is that mainstream scientific leaders increasingly accept that large bodies of published research are unreliable in almost every field, including cancer research, yet published papers that fail a replication experiment are often cited more than those that pass one because they make bolder claims. Behind this unreliability is a destructive feedback loop between the production of poor quality science, the responsibility to cite previous work, and the compulsion to publish.
Another result of an obsession with papers is more journals. If you want more papers, you need more journals, and as a result we certainly have more journals. The number of worldwide researchers, journals, and journal articles has risen, increasing by about 60 percent just in the thirteen years between 1982 and 1995, followed by another 20 percent increase in the number of journals between 2002 and 2014. And it is not just more low-tier journals, the number of high-tier journals is also growing. The number of journals published by the Association of Computing Machinery has reached fifty-nine, while the number published by the American Chemical Society has hit thirty-nine; the Society of Mechanical Engineers, thirty-five; the Physical Society, fifteen; and the Medical Association, thirteen. The number of transactions, journals, and magazines published by the Institute of Electrical and Electronics Engineers exceeds two hundred, and the number published by Nature has reached 157 (up from one, fifty years ago), with each journal representing a different specialty.
Universities encourage this hyper-specialization. One recent paper analyzed the evaluation decisions for more than forty thousand academics. It found that scholars are penalized in their careers because gatekeepers in scientific disciplines may perceive multidisciplinary scientists as threats to the distinctiveness and knowledge domain of individual disciplines. Interestingly, the highest performers among multidisciplinary candidates are the ones who are most penalized. Those who are brilliant are also those who may bring disruption to a discipline, and hence are penalized more than those with a middling track.
Can we expect hyper-specialized researchers to develop something of use to society? Doing so requires the integration of many types of different information, and when it is spread across so many journals, who could possibly do this? Even if we ignore the more prosaic tasks of manufacturing, marketing, and accounting, just finding a new concept is difficult for hyper-specialized researchers.
What Should We Do?
The problems in America’s system of basic and applied research will not be easy to solve. Nor does returning to a system of the past guarantee success, as many past successes occurred for unknown or hard to explain reasons. Trying to recreate the past without understanding these reasons can easily lead to a worse situation.
There will also be a tendency to ignore these problems and just forge ahead with more government funding. But more money without reform will likely give us more PhD students, more papers, and bigger labs, without giving us more new breakthrough products and services. Nor is there any guarantee that more government funding for development will improve the situation. VCs are currently giving record amounts of funding to nuclear fusion, superconductors, quantum computers, bioelectronics (think of Theranos), without results, so more government funding, in and of itself, will not necessarily make things better.
Rather, the lack of success in these areas suggests that many if not all of these new technologies aren’t ready for development. They need significant improvements in performance and cost, something that does not appear to be coming from more papers, which place more emphasis on issues dear to academics, like theory and novelty, than on practical improvements. Somehow, we must change this paper mentality to an improvement mentality, in which university researchers work with corporations, perhaps alliances of them, to make the improvements.
Doing this will be difficult, not only because academics and funding agencies must be given new incentives, but also because the corporate side is weak. For instance, there are very few big electronic, materials, or other high-tech companies in America that still have large corporate laboratories (Big Pharma is an exception) and that can work with universities. America does not have a major supplier of displays, batteries, or solar cells, and outside of software, it has only Micron and Intel as suppliers of electronic hardware. Can we expect Facebook, Google, or Microsoft to do the basic and applied research that might lead to useful superconductors, nanotechnology, bioelectronics, or nuclear fusion?
Building stronger universities (and VCs and consulting firms) will require big changes in how we measure researchers. Counting publications or calculating h-factors are clearly insufficient. Since these people are supposed to be a source of new ideas, we should measure them by how good their ideas are. Which ideas led to new products, services, or solutions? Who came up with them? Which journals published them? Which government agencies funded them?
Developing this type of research system requires us to move away from the simple metrics that have been pushed by bureaucrats. Bureaucrats like these types of measures because they help them retain their power and position. But we need metrics that require members of the research system to understand the technologies they are funding, including key measures of cost and performance. Unfortunately, many members of the research system do not understand these issues, and thus it may be necessary to pare down the extensive system of academics, bureaucrats, and public relations specialists that make it harder for good decisions to be made.
None of this will be easy. But when a system doesn’t work, we must try to come up with a better one. We devise new metrics, we test them, and we move forward. One thing we know is that the existing system of publication counts and h-factors doesn’t work. They distract us from the real challenges facing both start-ups and incumbents in commercializing new technologies that are actually useful and transformative.
This article originally appeared in American Affairs Volume VI, Number 4 (Winter 2022): 23–35.
Notes
1
The use of blockchain means that the Bitcoin application is consistently maxed out at around 350,000 transactions per day, a pittance compared to other payment technologies and many times less that would be needed in a Web3 application.
2 As an aside, experiments in so-called Central Bank Digital Currencies (CBDCs) have mostly rejected models based on blockchain having witnessed the performance problems experienced elsewhere.
3 See notice of the latest delay from one of the ASX’s regulators, Australian Securities and Investments Commission, “22-204MR Delay to the ASX Chess Replacement Project and Independent Review,” news release, August 3, 2022.",2
335,"After weeks of watching young tendrils slowly corkscrew their way toward the sun, Charles Darwin set about inventing a system for making botanic motion visible to the naked eye. Natalie Lawrence delves into a lesser-known chapter of the naturalist’s research, discovering revelations about the vegetal world that remain neglected to this day.
Published
October 26, 2022
One day in 1863, during a long, hot summer, Charles Darwin wrote a letter to his close friend, the botanist Joseph Hooker. He related: “I am getting very much amused by my tendrils— it is just the sort of niggling work that suits me”.1 Darwin had spent the preceding weeks confined to bed at his home in Down House, laid low by an unpleasant bout of eczema. His usual fervent energy for research and correspondence had been frustrated by incapacity. He found solace in turning attention to the inhabitants of his bedchamber: houseplants. Darwin spent hours each day simply watching the young cucumber plants grow from the pots on his windowsills, observing how they explored the world around them seeking for things to climb up. It happened to be a very rewarding pastime. In his normal state of constant activity, Darwin would not have had the time to watch plants at plant pace. But, forced to slow down and exist at a different speed, he had become entranced.
The genesis of this interest in tendrils occurred when Darwin read a short paper in 1862 by Asa Gray, a botanist at Harvard. His “Note on the coiling of tendrils” in the Proceedings of the American Academy of Arts and Sciences described the sensitivity of growing plant tendrils to touch.2 With his imagination captured by this prospect, Darwin wrote to Gray saying “I should like to try a few experiments on your Tendrils; I wonder what would be good & easy plant to raise in pot”.3 Gray sent him seeds of two climbing plants: the bur cucumber (Sicyos angulatus) and wild mock cucumber (Echinocystis lobata), which Darwin could plant in the spring to begin his observations. Gray did warn, however, that whilst the mock cucumber was “genteel”, the bur cucumber was “as nasty and troublesome” as any plant he knew, so Darwin would have to watch it closely.4
Though the “troublesome” bur cucumbers failed to germinate, the mock cucumbers did well, becoming Darwin’s companions and silent interlocutors by his sick bed. They proved surprisingly charismatic. He reported back to Gray that: “I am observing the plant in another respect, namely the incessant rotatory movement of the leading shoots, which bring the tendrils into contact with any body within a circle of a foot or 20 inches in diameter”.5 The circling movement was a surprise to Darwin: these tendrils were more than just sensitive. They seemed to have a mysterious method by which to explore the world around them and find ways to climb up to the light. He called the “spontaneous revolutions” that the plants made “circumnutation” (from the Latin circum, “round”, and nutare, “to nod”). Darwin thought he had discovered something new — a phenomenon he’d never seen described in detail.
In his letters, Darwin asked Hooker for more exotic species to observe as he healed and recovered his strength and ordinarily boundless energy. He carefully tended the plants that Hooker sent, adding them to the potted cucumbers and clematis vines that were strung along his indoor windows. They grew to weave a green tapestry in front of the panes, thrusting their leaves out to bathe in the incoming light. After four months captivated indoors with and by the tendrils, Darwin had his chair moved outside. He sat in fields of hops for hours, watching their shoots seek out supports and climb them. He began to play with the growth of the plants that he watched. By attaching small weights to them to test their movements, or marking their bodies, Darwin could monitor what they were doing, even when he wasn’t constantly watching.
Much of botany in Britain at this time was focused on taxonomy. Yet Darwin wanted to do more than name and classify plants. He wanted to find new ways of looking at plants, to see them on their terms. And what he found was remarkable.6 Some of his plants genuinely surprised him. For example, to understand how parasitic dodder plants, Cuscuta pentagona, looked for supports, he placed upright poles nearby for them to find. The shoots would perform slow circling sweeps as they grew. When encountering a stick, a plant “slowly and gradually slid up the stick, so as to become more and more highly inclined”. But, after a time, “the shoot suddenly bounded from the stick and fell over to the opposite side” before returning to the support and sliding up it.7 These plants were doing something complex, and sometimes rather fast. Darwin was delighted with what he observed, waxing lyrical to his son William: “My hobby-horse at present is Tendrils; they are more sensitive to a touch than your finger; & wonderfully crafty & sagacious”.8
It was only when Darwin reported back to Gray about the circling movements that he realised he had rather put the cart before the horse. Gray brought him roughly down to Earth, making it clear that what Darwin saw was rather common knowledge to some researchers. The rotating movements of climbing plants like cucumbers had been described in the published literature several times. Darwin, in his enthusiasm and bedridden summer frenzy, neglected to do his background reading. When he did, pointed in the right direction by Gray, the naturalist realised that “the cream” of his observations had already been published by others, chastening him considerably.9 He wrote in a later publication: “My observations were more than half completed before I became aware that the surprising phenomenon of the spontaneous revolutions of the stems and tendrils of climbing plants had been long ago observed”.10
Darwin was no ordinary naturalist. He saw that, though circumnutation was not a new observation, scientists lacked any kind of understanding about how it happened, or what the plant was actually doing with this movement. He wanted to delve deeper. The tendrils might be “crafty and sagacious”, but just how crafty and sagacious they were — that was the fascinating question. Keen-eyed Darwin could spend all day watching plants grow, but there was the unavoidable fact that he had an animal sensory system that was not geared to observe plant growth precisely. How could he record and understand these movements in a way which might reveal what was going on? Nobody else had solved this problem, and the naturalist came up with an ingenious method.
Darwin developed a way of recording the movements of individual parts of plants as they grew and rotated through space. He placed a plant between a sheet of paper and a glass plate and marked a reference point on the paper, attaching a thin wire to a particular part of the plant, such as a leaf or bud. He made recordings at regular intervals by lining up the end of this filament with the fixed reference point, and then marking its position on the glass plate. Seeing Darwin’s strange, angular drawings without any context, it would be easy to think that they might be the tracks of a small animal — a woodlouse, beetle, or perhaps a mouse with a short attention span. They seem like the staccato perambulations of a creature that does not have a clear purpose, rambling across the paper. But that is because these are static, two-dimensional renderings of movements that occurred in three dimensions.
After many hours during which multiple points were recorded, Darwin could then trace the plant’s movement over time by connecting the dots on the plate in order. In this way, he made the movement visible to the naked eye. Darwin could even magnify movements by varying the distance between the plate and the plant. By moving it further away, he increased the angle at which the points aligned to his eye, thus stretching small movements across larger distances on the plate. In the days before time-lapse photography and cinematography, this was an incredibly creative way of capturing plant movement to make it meaningful for humans.
Plants look static to the naked eye, but all of their parts move in swaying circles: from tendrils and roots to blooms and leaves. With his new method, Darwin was able to accurately trace the movements of hundreds of plants and their individual parts, detailing their circular explorations with staggered lines. He pioneered an understanding of plant “habits”. Unlike the taxonomists concerned with what categories to put different species in, Darwin saw that when plants made changes in their physical positions, or grew into different shapes, what they were doing was really behaviour, not unlike that of animals. The difference was, animals moved rapidly, and from place to place. Plants grew slowly and moved primarily by growing.11
It was not long before Darwin compiled his observations, including those using the glass plate method, into a substantial 118-page monograph. He presented it to the Linnaean Society in 1865, publishing under the title On the Movements and Habits of Climbing Plants. In the text, Darwin linked plant movement to his evolutionary theory: plants were sensitive to their environments and used this sensitivity to guide their growth in order to survive and reproduce more successfully:
Plants become climbers, in order, it may be presumed, to reach the light, and to expose a large surface of leaves to its action and to that of the free air. This is effected by climbers with wonderfully little expenditure of organized matter, in comparison with trees, which have to support a load of heavy branches by a massive trunk. Hence, no doubt, it arises that there are in all quarters of the world so many climbing plants belonging to so many different orders.12
Many different lineages of plants had developed this method of cheating the system, from plants like cucumbers that wound tendrils around supports, to others such as clematis, that “hooked” on objects. Both were techniques that allowed plants with wisp-like stems to hitch-hike up towards the sun without investing in a trunk or rigid stem.13
Darwin’s work went down a storm. Benjamin Dann Walsh, a prominent entomologist in the Linnaean Society, for example, wrote that “this discovery of their sweeping circles & groping in the dark for support, like a blind Cyclops, is very astonishing”.14 Even non-scientists such as the Queen’s chaplain, Charles Kingsley, enthused: “Ah that I could begin to study Nature anew, now that you have made it to me a live thing; not a dead collection of names”.15 Additional material was sent in from naturalists further afield who read the monograph, prompting Darwin to work on a second, expanded edition, which he published in 1875.
He didn’t stop there. Assisted by his son Francis, Darwin carried out extensive further experiments on the movements of plants. One of his key insights was that “all the more important great classes of movements are due to the modification of a kind of movement common to all parts of all plants from their earliest youth”.16 The nascent movements of adult plants could be seen right from their seedling stages, from sensitivity to light and other external stimuli, to their “sleep” behaviours, which revealed a kind of circadian rhythm. Darwin published The Power of Movement in Plants in 1880 with much effort. It had grown into a weighty manuscript, which he found a “horrid bore” to revise for publication.17 It was, however, the culmination of his life’s work on plants and the penultimate book that Darwin published. It was followed only by The Formation of Vegetable Mould through the Action of Worms a year later.
Darwin’s observations became the basis of how we now understand the physiology and behaviour of climbing plants. Beyond the climbers, Darwin laid the foundations for the study of plant behaviour and intelligence. Even today, this remains an idea that is uncomfortable for some people. Though we now have time-lapse cameras and blue-chip nature documentaries that exhibit plant lives as vibrantly and dramatically as any footage of fauna, it’s hard to break out of our animal-focused view of the world. Darwin’s work showed that the centuries-old presumption “that animals moved & plants did not” was entirely wrong, a matter of perception that could be overcome.18 Yet this awareness is still not nearly as widespread as it should be.
Why is this? Some plants, such as mimosa or Venus fly traps, have very specific, seemingly responsive movements that are hard for animal senses to ignore. But most plant behaviour, which may even betray an intelligence that we are only just starting to investigate, goes totally unnoticed. What Darwin really did was see plants in a new way: to look from their perspective and observe how their movement and behaviour benefitted them. It was a project which he never quite put down.
Natalie Lawrence is a writer, researcher, and illustrator living in London. She has a MCantab in natural sciences and PhD in the history and philosophy of science from the University of Cambridge. She recently published Planta Sapiens: Unmasking Plant Intelligence (2022, Bridge Street Press) with Paco Calvo and her book The Nature of the Beast (Orion Books), on the history of monstrous creatures and the imagination, will be out in 2023.
Categories
Tags
If You Liked This…
Prints for Your Walls
Explore our selection of fine art prints, all custom made to the highest standards, framed or unframed, and shipped to your door.",2
336,"Expand horizons, explore new ideas, and transform everyday objects into things from the future.
Filippo Cuttica, UX Principal for Ethical Experiences, talks us through an experiment that we conducted and why today it feels more relevant than ever.
Expand horizons, explore new ideas, and transform everyday objects into things from the future. Download your toolkit here.",2
337,"The Personal Brand Is Dead
Gen Z would rather be anonymous online.
When I was 21, the cool thing to be was famous on Instagram. Now the cooler thing to be is a mystery. Anonymity is in.
The youngest adult generation and the most online generation is frustrated with being surveilled and embarrassed by attention-seeking behaviors. This has instigated a retreat into smaller internet spaces and secret-sharing apps, as well as a mini-renaissance for Tumblr, where users rarely use their full names. (The majority of new users are Gen Z, according to Chenda Ngak, a spokesperson for Tumblr’s parent company.) The voice- and text-chat app Discord, known for a culture of anonymous and pseudonymous discussion, now has 150 million users; anonymously run hyper-niche meme accounts are suddenly the coolest, most exciting follows on Instagram. The group-therapy app Chill Pill offers a “world of future friends and better days” but does not permit the sharing of any personally identifying information. (I downloaded the app but can’t make a real account—I’m over the age limit, which is 24.)
Something has shifted online: We’ve arrived at a new era of anonymity, in which it feels natural to be inscrutable and confusing—forget the burden of crafting a coherent, persistent personal brand. There just isn’t any good reason to use your real name anymore. “In the mid 2010s, ambiguity died online—not of natural causes, it was hunted and killed,” the writer and podcast host Biz Sherbert observed recently. Now young people are trying to bring it back. I find this sort of exciting, but also unnerving. What are they going to do with their newfound freedom?
In part, the trend is a response to security concerns. During the Black Lives Matter protests in the summer of 2020, young people downloaded the encrypted messaging app Signal by the millions to avoid the surveillance they considered possible or probable on other platforms. The anonymous hacker group Anonymous made a buzzy return and was embraced by K-pop fans, many of them anonymous, while engaging in pranks that doubled as acts of civil disobedience. Other activists disseminated tools for blurring protesters’ faces in Instagram Stories, and tried to steer one another off mainstream apps and onto smaller, decentralized ones where users have more control of the data they create and share.
Anonymity can also be ideological. Crypto culture, now known as Web3 culture, was founded on the idea that transactions can be made online without the exchange of personally identifying information. It also has a newer norm of replacing one’s human face with a cartoon. In crypto circles, mentioning a very rich and successful person’s real name can amount to “doxxing,” and even those who aren’t well known are cautious about sharing the barest personal details. At a recent party sponsored by a new Web3 platform, a guest with about 5,000 Twitter followers explained to me that people online do know what he looks like—he “shows face,” as he put it—but that he has never shared a single photo of his girlfriend. Too dangerous.
But in the end, a return to anonymity is just a return to form. Hiding your identity has always been important for getting through the horror of being a person under the age of 24 on the internet. The gradual reveal of personal information, even building up to a “face reveal,” was once a give-and-take among people who shared the same online space for a long time, fostering trust. When Instagram and TikTok arrived and made it possible to make a lot of money from your face, personality, thoughts, beliefs, and personal trauma, young people forgot how good it felt to be no one in particular, or to try on various identities. In the past few years, they have been coming back around.
“It seems like Gen Z is getting really tired of presentation culture, as you might call it,” Zeke, a 21-year-old biologist and frequent Discord chatter, told me. “The idea that everything you do has to be a representation of your personal identity.” Obviously, he did not want me to publish his full name—he’s applying to lab-tech jobs right now, he said, and though nothing he was going to say to me would be scandalous or might put off a potential employer, he did not want to “risk it.”
Zeke does not have any active social-media accounts with his full name attached to them, but he is in many Discord servers pertaining to his interests, including art, writing, and science. He spends a lot of time there sharing interesting or funny photos of animals, and he met his longtime boyfriend while Discord-chatting under a pseudonym that is a play on Kermit the Frog. The site is “chill,” he told me. The servers that he likes best have 100 to 200 users, so the conversation is always lively, but it doesn’t get out of control or competitive. Sometimes people anonymously say disgusting things—the worst things he has ever read! (That well-established tendency has contributed to the collapse of anonymous social platforms in the past.) But mostly they just drop cool pictures and funny memes, and discuss or riff on them. “There’s an understanding that, like, you’re not going to kick each other, you’re not going to judge each other,” he said. “You’re not here to represent your identity; you’re just here to chill.”
The surprising recent popularity of Discord suggests a nostalgia among members of Gen Z for IRC and forum cultures that existed mostly before they were born. The return to Tumblr reflects a longing for the more recent past—just before the age of the influencer. “I’ve been on Tumblr for about 11 years because I was 11 when I got it,” Maya, an aspiring artist and photographer, told me. She asked to go by her first name only, as she does on Instagram. On Tumblr, where she feels most comfortable, she goes by the username coldstonedreamery—a reference to an episode of This American Life that she heard long ago in her mom’s car. She remains anonymous partly for artistic reasons: Being an enigma is good for world building and creating a mystique around her work, she said. She wants to be known for her point of view, not for her face or even her personality. “I mean, there are embarrassing YouTube videos of me playing guitar when I was 12 under my real name,” she added.
Being an enigma can produce strange results: Teenage girls on Instagram sometimes borrow selfies of Maya that don’t have her face in them and present them as their own. Most of the time, though, Maya sees her anonymity as being cozy. “I probably get 20 anonymous messages and questions a day, and I feel fine answering them and exposing all these intimate details of my life,” she said. “The people asking the questions probably don’t know what I look like, probably don’t know where I am or how old I am. I feel safer. There’s like a cloak over me.”
Even on Instagram, classic influencer culture is falling out of style. Among the well-known, generally beautiful faces who go by their real names, there are now thousands of niche meme accounts run by anonymous proprietors. Members of this latter group sometimes reveal their true identities when it becomes financially appealing to do so—if they’re offered a book deal, for example, they have to reveal themselves to someone. If they land a profile in The New York Times’ Style section, then everyone is in on the secret. But many more of them just post away from behind a curtain. (The more niche the content gets, the less likely it is that financial incentives will be in play, and the more likely the anonymity will last.)
The 24-year-old meme-maker behind an Instagram account called @neoliberalheaven makes pop-culture-inflected collages overlaid with parodies of online political discourse. (His profile picture is of the meme-literate musician Phoebe Bridgers.) He asked to remain anonymous for this story because he doesn’t want to limit future job opportunities and because being anonymous is part of his whole deal. The people who come across his feed can appreciate his work for its own sake, he told me, and they don’t care who he is. He also observed that anonymous accounts, by foreclosing on the possibility of becoming a personal brand, come off to some viewers as more “authentic,” or as “a new source of genuineness” online because they aren’t selling anything or trying to become stars. The internet’s prizing of authenticity has gone through the looking glass.
As a person who loves the internet, this all makes sense to me. Why should everyone have to live and write and think publicly at all times? Why should they be limited in that way? As a journalist who reports about the internet, I’ve found it frustrating too. In the past few years, more and more sources have been asking for anonymity on principle—not because they are afraid of specific or likely consequences, but because being named just doesn’t seem worth it. I can’t help but see this as unwillingness to say something and really mean it—and the portent of a sort of sad, slightly paranoid near future, in which everyone is cool, very cool, and impossible to pin down.",1
338,"General Motors is creating a new energy business to sell batteries, charging equipment, solar panels, and software to residential and commercial customers in a broad-based effort to create a range of accessories that can help sell its lineup of electric vehicles.
The new division, GM Energy, is also a direct shot at Tesla as a major player in renewable energy generation and storage. GM has said it intends to eventually overtake Elon Musk’s company in vehicles sales — and now it wants to challenge it on the energy front as well.
Travis Hester, GM’s chief EV officer, said the company is making a serious grab for a piece of what is potentially a $120-150 billion market for energy generation and storage products. The aim is to make GM’s brand synonymous with not just electric vehicles, but a whole host of products and services in orbit around EVs and their rechargeable lithium-ion batteries.
Hester said that GM has noticed Elon Musk’s moves in this market and sees an opportunity for itself. Tesla’s energy business has been steadily growing for several years, with revenues reaching $866 million in the second quarter of 2022. In addition to Tesla, there are a host of smaller, less recognizable firms that sell these products, like Generac, which sells backup power generators, and Fluence Energy, an energy storage company.
A serious grab for a piece of a $120-150 billion market
“They don’t have a vehicle,” Hester said of those smaller companies, in an interview with The Verge. “And frankly, they don’t have the dealer network that we have.”
Presently, GM has four EVs on the market: the Chevy Bolt EV and EUV; the GMC Hummer EV; and the Cadillac Lyriq. Within the next two years, it will release the Chevy Silverado EV, Blazer EV, and Equinox EV, as well as a Hummer SUV and another electric Cadillac. GM has said it aims to sell one million electric vehicles by 2025, Hester said. And each of those customers is also a potential customer of GM Energy.
1/3
“At that moment, that electrification moment, they have to decide how they’re going to run that vehicle,” he said. “They have to decide are they going to buy a standard charger for their home? Is it going to be a bi-directional charger? Do they want to add stationary storage as a fixed box? Do they want to do solar? And they can go as far into that ecosystem or as little as possible depending on their individual needs.”
GM Energy will be comprised of three units: Ultium Home, Ultium Commercial, and Ultium Charge 360, which is the company’s EV charging program. The division will sell a range of products to residential and commercial customers, including bi-directional charging equipment, vehicle-to- home (V2H) and vehicle-to-grid (V2G) equipment, stationary storage, solar products, software applications, cloud management tools, microgrid solutions, and hydrogen fuel cells.
GM Energy will be comprised of three units
GM Energy will also be in the virtual power plant business. Many EVs with high-capacity batteries are being marketed for their ability to serve as backup power in the event of a blackout. (Hester notes that the Chevy Silverado EV, with its 200kWh battery pack, can power an average sized home for 21 days.) EVs can also feed power back into the grid during times of peak demand. GM Energy will be the entity that sells that power back to the utilities during times of high-energy consumption.
GM has previously partnered with PG&E in California around the idea of “vehicle-to-grid” technology. The idea is to use bi-directional charging equipment to push and pull energy from electric vehicles at any given time. In essence, it treats high-capacity batteries as not only tools to power EVs but backup storage cells for the electrical grid. GM is also working with Con Edison, Graniterock, and New Hampshire Electric Cooperative on similar projects.
For solar energy, GM is teaming up with San Jose-based SunPower to sell solar panels and home energy storage products to residential customers. SunPower and other partners will supply the solar panels and perform the installations, with GM developing the complimentary software.
Over time, as GM’s battery factories come online and production of its Ultium-branded battery systems ramps up, the company intends on swapping in its own battery cells and storage units, Hester said. The automaker is also planning on manufacturing its own line of backup power generators using its Hydrotec-branded hydrogen fuel cells.
EVs can also feed power back into the grid during times of peak demand
“We’re going to start with an array of lithium-ion cells from different partners that we already have,” he said. “And then as we get further into the Ultium rollout of our vehicles and all of our cell plants, we will pull in Ultium cells and we will do more manufacturing of our own.”
(Ultium is the name of GM’s electric vehicle battery and powertrain technology. Last year, the company said the Ultium Charge 360 network would be the name given to GM’s own vehicle apps and software with a variety of third-party charging services, such as Blink, ChargePoint, EVgo, Flo, Greenlots, and SemaConnect.)
Unlike Tesla or Volkswagen, GM does not have its own branded EV charging network yet — though it’s hoping to get there eventually. Owners of GM’s electric vehicles must instead rely on a patchwork of third-party chargers, each with their own software and membership requirements. The company is in the process of building a network of coast-to-coast Ultium 360-branded chargers at trucks stops in partnership with EVgo.
But much like its approach to EVs, the dates for the launch of these new products are still a ways off in the future. GM is still testing its V2H service in partnership with PG&E with a small sample of residential customers in California, and plans on expanding it to more homes in early 2023. And its solar products won’t be available until 2024.
GM has been under pressure in recent years to accelerate the rollout of its EVs, and no doubt it will face similar pressure for its new energy products. That said, the automaker resisted calls from Wall Street to spinoff its EV business as a separate unit, arguing that plug-in power is GM’s future.
“It’s not a business unit,” Hester said. “It is our business as we go forward.”",2
339,"Teixcalaan #2
A Desolation Called Peace
An alien armada lurks on the edges of Teixcalaanli space. No one can communicate with it, no one can destroy it, and Fleet Captain Nine Hibiscus is running out of options.
In a desperate attempt at diplomacy with the mysterious invaders, the fleet captain has sent for a diplomatic envoy. Now Mahit Dzmare and Three Seagrass—still reeling from the recent upheaval in the Empire—face the impossible task of trying to communicate with a hostile entity.
Whether they succeed or fail could change the fate of Teixcalaan forever.
In a desperate attempt at diplomacy with the mysterious invaders, the fleet captain has sent for a diplomatic envoy. Now Mahit Dzmare and Three Seagrass—still reeling from the recent upheaval in the Empire—face the impossible task of trying to communicate with a hostile entity.
Whether they succeed or fail could change the fate of Teixcalaan forever.
496 pages, Kindle Edition
First published March 2, 2021
About the author
Ratings & Reviews
Friends & Following
Create a free account to discover what your friends think of this book!
Community Reviews
5 stars
8,654 (49%)
4 stars
6,556 (37%)
3 stars
1,807 (10%)
2 stars
271 (1%)
1 star
57 (<1%)
Can't find what you're looking for?
Get help and learn more about the design.",8
340,"Pop Culture Has Become an Oligopoly
A cartel of superstars has conquered culture. How did it happen, and what should we do about it?
You may have noticed that every popular movie these days is a remake, reboot, sequel, spinoff, or cinematic universe expansion. In 2021, only one of the ten top-grossing films––the Ryan Reynolds vehicle Free Guy––was an original. There were only two originals in 2020’s top 10, and none at all in 2019.
People blame this trend on greedy movie studios or dumb moviegoers or competition from Netflix or humanity running out of ideas. Some say it’s a sign of the end of movies. Others claim there’s nothing new about this at all.
Some of these explanations are flat-out wrong; others may contain a nugget of truth. But all of them are incomplete, because this isn’t just happening in movies. In every corner of pop culture––movies, TV, music, books, and video games––a smaller and smaller cartel of superstars is claiming a larger and larger share of the market. What used to be winners-take-some has grown into winners-take-most and is now verging on winners-take-all. The (very silly) word for this oligopoly, like a monopoly but with a few players instead of just one.
I’m inherently skeptical of big claims about historical shifts. I recently published a paper showing that people overestimate how much public opinion has changed over the past 50 years, so naturally I’m on the lookout for similar biases here. But this shift is not an illusion. It’s big, it’s been going on for decades, and it’s happening everywhere you look. So let’s get to the bottom of it.
(Data and code available here.)
Movies
At the top of the box office charts, original films have gone extinct.
I looked at the 20 top-grossing movies going all the way back to 1977 (source), and I coded whether each was part of what film scholars call a “multiplicity”—sequels, prequels, franchises, spin-offs, cinematic universe expansions, etc. This required some judgment calls. Lots of movies are based on books and TV shows, but I only counted them as multiplicities if they were related to a previous movie. So 1990’s Teenage Mutant Ninja Turtles doesn’t get coded as a multiplicity, but 1991’s Teenage Mutant Ninja Turtles II: The Secret of the Ooze does, and so does the 2014 Teenage Mutant Ninja Turtles remake. I also probably missed a few multiplicities, especially in earlier decades, since sometimes it’s not obvious that a movie has some connection to an earlier movie.
Regardless, the shift is gigantic. Until the year 2000, about 25% of top-grossing movies were prequels, sequels, spinoffs, remakes, reboots, or cinematic universe expansions. Since 2010, it’s been over 50% ever year. In recent years, it’s been close to 100%.
Original movies just aren’t popular anymore, if they even get made in the first place.
Top movies have also recently started taking a larger chunk of the market. I extracted the revenue of the top 20 movies and divided it by the total revenue of the top 200 movies, going all the way back to 1986 (source). The top 20 movies captured about 40% of all revenue until 2015, when they started gobbling up even more.
Television
Thanks to cable and streaming, there's way more stuff on TV today than there was 50 years ago. So it would make sense if a few shows ruled the early decades of TV, and now new shows constantly displace each other at the top of the viewership charts.
Instead, the opposite has happened. I pulled the top 30 most-viewed TV shows from 1950 to 2019 (source) and found that fewer and fewer franchises rule a larger and larger share of the airwaves. In fact, since 2000, about a third of the top 30 most-viewed shows are either spinoffs of other shows in the top 30 (e.g., CSI and CSI: Miami) or multiple broadcasts of the same show (e.g., American Idol on Monday and American Idol on Wednesday).
Two caveats to this data. First, I’m probably slightly undercounting multiplicities from earlier decades, where the connections between shows might be harder for a modern viewer like me to understand––maybe one guy hosted multiple different shows, for example. And second, the Nielsen ratings I’m using only recently started accurately measuring viewership on streaming platforms. But even in 2019, only 14% of viewing time was spent on streaming, so this data isn’t missing much.
Music
It used to be that a few hitmakers ruled the charts––The Beatles, The Eagles, Michael Jackson––while today it’s a free-for-all, right?
Nope. A data scientist named Azhad Syed has done the analysis, and he finds that the number of artists on the Billboard Hot 100 has been decreasing for decades.
And since 2000, the number of hits per artist on the Hot 100 has been increasing.
(Azhad says he’s looking for a job––you should hire him!)
A smaller group of artists tops the charts, and they produce more of the chart-toppers. Music, too, has become an oligopoly.
Books
Literature feels like a different world than movies, TV, and music, and yet the trend is the same.
Using LiteraryHub's list of the top 10 bestselling books for every year from 1919 to 2017, I found that the oligopoly has come to book publishing as well. There are a couple ways we can look at this. First, we can look at the percentage of repeat authors in the top 10––that is, the number of books in the top 10 that were written by an author with another book in the top 10.
It used to be pretty rare for one author to have multiple books in the top 10 in the same year. Since 1990, it’s happened almost every year. No author ever had three top 10 books in one year until Danielle Steel did it 1998. In 2011, John Grisham, Kathryn Stockett, and Stieg Larsson all had two chart-topping books each.
We can also look at the percentage of authors in the top 10 were already famous––say, they had a top 10 book within the past 10 years. That has increased over time, too.
In the 1950s, a little over half of the authors in the top 10 had been there before. These days, it’s closer to 75%.
Video games
I tracked down the top 20 bestselling video games for each year from 1995 to 2021 (sources: 1, 2, 3, 4, 5, 6, 7) and coded whether each belongs to a preexisting video game franchise. (Some games, like Harry Potter and the Sorcerer’s Stone, belong to franchises outside of video games. For these, I coded the first installment as originals and any subsequent installments as franchise games.)
The oligopoly rules video games too:
In the late 1990s, 75% or less of bestselling video games were franchise installments. Since 2005, it’s been above 75% every year, and sometimes it’s 100%. At the top of the charts, it’s all Mario, Zelda, Call of Duty, and Grand Theft Auto.
Why is this happening?
Any explanation for the rise of the pop oligopoly has to answer two questions: why have producers started producing more of the same thing, and why are consumers consuming it? I think the answers to the first question are invasion, consolidation, and innovation. I think the answer to the second question is proliferation.
Invasion
Software and the internet have made it easier than ever to create and publish content. Most of the stuff that random amateurs make is crap and nobody looks at it, but a tiny proportion gets really successful. This might make media giants choose to produce and promote stuff that independent weirdos never could, like an Avengers movie. This can’t explain why oligopolization started decades ago––YouTube only launched in 2005, for example, and most Americans didn’t have broadband until 2007––but it might explain why it’s accelerated and stuck around.
Consolidation
Big things like to eat, defeat, and outcompete smaller things. So over time, big things should get bigger and small things should die off. Indeed, movie studios, music labels, TV stations, and publishers of books and video games have all consolidated. Maybe it’s inevitable that major producers of culture will suck up or destroy everybody else, leaving nothing but superstars and blockbusters. Indeed, maybe cultural oligopoly is merely a transition state before we reach cultural monopoly.
Innovation
You may think there’s nothing left to discover in art forms as old as literature and music, and that they simply iterate as fashions change. But it took humans thousands of years to figure out how to create the illusion of depth in paintings. Novelists used to think that sentences had to be long and complicated until Hemingway came along, wrote some snappy prose, and changed everything. Even very old art forms, then, may have secrets left to discover. Maybe the biggest players in culture discovered some innovations that won them a permanent, first-mover chunk of market share. I can think of a few:
In books: lightning-quick plots and chapter-ending cliffhangers. Nobody thinks The Da Vinci Code is high literature, but it’s a book that really really wants you to read it. And a lot of people did!
In music: sampling. Musicians seem to sample more often these days. Now we not only remake songs; we franchise them too.
In movies, TV, and video games: cinematic universes. Studios have finally figured out that once audiences fall in love with fictional worlds, they want to spend lots of time in them. Marvel, DC, and Star Wars are the most famous, but there are also smaller universe expansions like Better Call Saul and El Camino from Breaking Bad and The Many Saints of Newark from The Sopranos. Video game developers have understood this for even longer, which is why Mario does everything from playing tennis to driving go-karts to, you know, being a piece of paper.
Proliferation
Invasion, consolidation, and innovation can, I think, explain the pop oligopoly from the supply side. But all three require a willing audience. So why might people be more open to experiencing the same thing over and over again?
As options multiply, choosing gets harder. You can’t possibly evaluate everything, so you start relying on cues like “this movie has Tom Hanks in it” or “I liked Red Dead Redemption, so I’ll probably like Red Dead Redemption II,” which makes you less and less likely to pick something unfamiliar.
Another way to think about it: more opportunities means higher opportunity costs, which could lead to lower risk tolerance. When the only way to watch a movie is to go pick one of the seven playing at your local AMC, you might take a chance on something new. But when you’ve got a million movies to pick from, picking a safe, familiar option seems more sensible than gambling on an original.
This could be happening across all of culture at once. Movies don’t just compete with other movies. They compete with every other way of spending your time, and those ways are both infinite and increasing. There are now 60,000 free books on Project Gutenberg, Spotify says it has 78 million songs and 4 million podcast episodes, and humanity uploads 500 hours of video to YouTube every minute. So uh, yeah, the Tom Hanks movie sounds good.
What do we do about it?
Some may think that the rise of the pop oligopoly means the decline of quality. But the oligopoly can still make art: Red Dead Redemption II is a terrific game, “Blinding Lights” is a great song, and Toy Story 4 is a pretty good movie. And when you look back at popular stuff from a generation ago, there was plenty of dreck. We’ve forgotten the pulpy Westerns and insipid romances that made the bestseller lists while books like The Great Gatsby, Brave New World, and Animal Farm did not. American Idol is not so different from the televised talent shows of the 1950s. Popular culture has always been a mix of the brilliant and the banal, and nothing I’ve shown you suggests that the ratio has changed.
The problem isn’t that the mean has decreased. It’s that the variance has shrunk. Movies, TV, music, books, and video games should expand our consciousness, jumpstart our imaginations, and introduce us to new worlds and stories and feelings. They should alienate us sometimes, or make us mad, or make us think. But they can’t do any of that if they only feed us sequels and spinoffs. It’s like eating macaroni and cheese every single night forever: it may be comfortable, but eventually you’re going to get scurvy.
We haven’t fully reckoned with what the cultural oligopoly might be doing to us. How much does it stunt our imaginations to play the same video games we were playing 30 years ago? What message does it send that one of the most popular songs in the 2010s was about how a 1970s rock star was really cool? How much does it dull our ambitions to watch 2021’s The Matrix: Resurrections, where the most interesting scene is just Neo watching the original Matrix from 1999? How inspiring is it to watch tiny variations on the same police procedurals and reality shows year after year? My parents grew up with the first Star Wars movie, which had the audacity to create an entire universe. My niece and nephews are growing up with the ninth Star Wars movie, which aspires to move merchandise. Subsisting entirely on cultural comfort food cannot make us thoughtful, creative, or courageous.
Fortunately, there’s a cure for our cultural anemia. While the top of the charts has been oligopolized, the bottom remains a vibrant anarchy. There are weird books and funky movies and bangers from across the sea. Two of the most interesting video games of the past decade put you in the role of an immigration officer and an insurance claims adjuster. Every strange thing, wonderful and terrible, is available to you, but they’ll die out if you don’t nourish them with your attention. Finding them takes some foraging and digging, and then you’ll have to stomach some very odd, unfamiliar flavors. That’s good. Learning to like unfamiliar things is one of the noblest human pursuits; it builds our empathy for unfamiliar people. And it kindles that delicate, precious fire inside us––without it, we might as well be algorithms. Humankind does not live on bread alone, nor can our spirits long survive on a diet of reruns.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Barely hinted at is the problem of algorithmic content selection, across the various media. For years, I’ve felt that Spotify has trapped me into a musical ghetto, just feeding me more of the same stuff I’ve “liked” in the past, so I set about to teach Spotify that I’m not the listener they think I am. The “how” of that is too complicated for a comment, but it might be an interesting avenue for you to explore. I knew it was working the other day when my wife said: you’re sure listening to a lot of weird stuff these days. Exactly!
Great essay. This ties in with my thoughts about today's culture: We are living in hauntological times: a stagnant period in which the past is being plundered and it seems impossible that the future will ever arrive.
Cultural Dopes:
https://lareviewofbooks.org/article/cultural-dopes/
Had I found this sooner I would have referenced some of the great facts assembled here.",1
341,"Something went wrong. Wait a moment and try again.
Try again
Please enable Javascript and refresh the page to continue",7
342,"The Big Convergence is Coming… We Will Program in Text Files
These are my ideas and predictions about large language models (LLMs) and the way they will change the tech world forever.
Large Language Models (LLMs) Change Everything
I assume anyone reading this is already familiar with GPT-3 and other similar LLMs such as Bloom, PaLM, etc. These are extremely huge neural networks that are trained on almost all textual data publicly available on the internet (~45 TB text data). For the first time ever, we now have AI that can keep a…",3
343,"A New HOPE will be a transformational conference for the hacker community -- in so many ways. We've all been through a lot, and it's been challenging. It is a time to come together again to inspire, transform, and share HOPE.
A New HOPE will be live and in person, and at a great new venue. St. John's University has more space, more possibilities, and offers us much more support for HOPE far into the future.
We will miss our old long-time home, the Hotel Pennsylvania, which is, sadly, being demolished. But we are now ready for our next chapter. We hope you'll join us for this this exciting bit of history as we create A New HOPE together.",8
344,"Facts and Figures 2021: 2.9 billion people still offline
An estimated 37 per cent of the world’s population – or 2.9 billion people – have still never used the Internet.
New data from the International Telecommunication Union (ITU), the United Nations specialized agency for information and communication technologies (ICTs), also reveal strong global growth in Internet use, with the estimated number of people who have used the Internet surging to 4.9 billion in 2021, from an estimated 4.1 billion in 2019.
This comes as good news for global development. However, ITU data confirm that the ability to connect remains profoundly unequal.
Of the 2.9 billion still offline, an estimated 96 per cent live in developing countries.
And even among the 4.9 billion counted as ‘Internet users’, many hundreds of millions may only get the chance to go online infrequently, via shared devices, or using connectivity speeds that markedly limit the usefulness of their connection. “While almost two-thirds of the world’s population is now online, there is a lot more to do to get everyone connected to the Internet,” said ITU Secretary General Houlin Zhao.
“ITU will work with all parties to make sure that the building blocks are in place to connect the remaining 2.9 billion. We are determined to ensure no one will be left behind.”
The unusually sharp rise in the number of people online suggests that measures taken during the pandemic – such as widespread lockdowns and school closures, combined with people’s need for access to news, government services, health updates, e-commerce and online banking – contributed to a ‘COVID connectivity boost’ that has brought an estimated 782 million additional people online since 2019, an increase of 17 per cent.
What it means for sustainable development
The 2021 edition of Facts and Figures, ITU’s annual overview of the state of digital connectivity worldwide, shows the number of Internet users globally growing by more than 10 per cent in the first year of the pandemic – by far the largest annual increase in a decade.Strong growth since 2019 was largely driven by increases in developing countries, where Internet penetration climbed more than 13 per cent. In the 46 UN-designated Least Developed Countries (LDCs), the average increase exceeded 20 per cent.
“These statistics show great progress towards ITU’s mission to connect the world,” said Doreen Bogdan-Martin, Director of ITU’s Telecommunication Development Bureau, which oversees ITU’s data and analytics work.
“But a vast ‘connectivity chasm’ remains in the LDCs, where almost three quarters of people have never connected to the Internet. Women in LDCs are particularly marginalized, with roughly four out of every five still offline.”
Many of these ‘digitally excluded’ face formidable challenges including poverty, illiteracy, limited access to electricity, and lack of digital skills and awareness. “Digital solutions would be needed to re-energize sustainable development and help put countries back on track to meet the UN Sustainable Development Goals (SDGs) for 2030,” Bogdan-Martin added. “Unfortunately, the communities identified in the 2030 Agenda as most at risk of being left behind are the very same communities now being digitally left behind.”
Key report findings
The digital gender divide is narrowing globally, but large gaps remain in poorer countries.
Globally, an average of 62 per cent of men use the Internet compared with 57 per cent of women.
Although the digital gender divide has been narrowing in all world regions and has been virtually eliminated in the developed world (89 per cent of men and 88 per cent of women online) wide gaps remain in Least Developed Countries (31 per cent of men compared to just 19 per cent of women) and in Landlocked Developing Countries (38 per cent of men compared to 27 per cent of women). The gender divide remains particularly pronounced in Africa (35 per cent of men compared to 24 per cent of women) and the Arab States (68 per cent of men compared to 56 per cent of women).
The urban-rural gap, though less severe in developed countries, remains a major challenge for digital connectivity in the rest of the world.
Globally, people in urban areas are twice as likely to use the Internet than those in rural areas (76 per cent urban compared to 39 per cent rural). In developed economies, the urban-rural gap appears negligible in terms of Internet usage (with 89 per cent of people in urban areas having used the Internet in the last three months, compared to 85 per cent in rural areas), whereas in developing countries, people in urban areas are twice as likely to use the Internet as those in rural areas (72 per cent urban compared to 34 per cent rural). In the LDCs, urban dwellers are almost four times as likely to use the Internet as people living in rural areas (47 per cent urban compared to 13 per cent rural).
A generational gap is evident across all world regions.
On average, 71 per cent of the world’s population aged 15-24 is using the Internet, compared with 57 per cent of all other age groups. This generational gap is reflected across all regions. It is most pronounced in the LDCs, where 34 per cent of young people are connected, compared with only 22 per cent of the rest of the population. Greater uptake among young people bodes well for connectivity and development. In the LDCs, for example, half of the population is less than 20 years old, suggesting that local labour markets will become progressively more connected and technology-savvy as the younger generation enters the workforce.
ITU continues monitoring the world’s evolving digital divide.
ITU figures also point to a glaring gap between digital network availability versus actual connection. While 95 per cent of people in the world could theoretically access a 3G or 4G mobile broadband network, billions of them do not connect. Affordability of devices and services remains a major barrier. The widely accepted target for affordable broadband connectivity in developing countries sets the cost of an entry-level mobile broadband package at 2 per cent of gross national income (GNI) per capita. Yet in some of the world’s poorest nations, getting online can cost a staggering 20 per cent or more of per capita GNI. Lack of digital skills and an appreciation of the benefits of an online connection is another bottleneck, compounded by a lack of content in local languages, as well as by interfaces that demand literacy and numeracy skills that many people do not possess.
Learn more about Facts and Figures 2021.",1
345,"Q&A on the CNIL's formal notices concerning the use of Google Analytics
The CNIL has issued an order to comply to several organisations regarding the use of Google Analytics, due to the transfer of data to the United States without sufficient guarantees for the rights of European users. What are the consequences for organisations?
This Q&A only covers the decisions of the CNIL concerning the use of Google Analytics following the invalidation of the Privacy Shield.
The joint statement by the European Commission and the United States government in March 2022 on a future decision to adequately regulate data flows to the US is, at this stage, only a political announcement. The EDPB issued a statement on 6 April indicating that this does not constitute a legal framework on which organisations can rely to transfer data to the US.
This Q&A is a courtesy translation of the French Q&A published on June 7th, 2022. In the event of any inconsistency, please note that the French version shall prevail.
Concerning formal notices
In short, what should we learn from the formal notices issued by the CNIL?
The context
On 16 July 2020, the Court of Justice of the European Union issued a major ruling : the Privacy Shield, which was a framework for data transfers between the European Union and the USA, has been invalidated because it did not provide adequate safeguards against the risk of unlawful access by US authorities to the personal data of European residents.
In practice, such transfers may now only take place if additional technical, legal and organisational safeguards are put in place by organisations to prevent these accesses.
In August 2020, the non-governmental organization “noyb” filed 101 complaints with various European data protection authorities about websites using the audience analysis tool “Google Analytics”, whose parent company is located in the USA.
The decision
In the order published on 10 February 2022 concerning one of these organisations, the CNIL considered that :
- the measures put in place by Google are not sufficient to exclude the possibility of access to data of European residents;
- the data of European Internet users is therefore illegally transferred through this tool.
Why was the order to comply published in an anonymised form?
One of the orders to comply relating to the use of Google Analytics was posted on the CNIL website on 16 February 2022, stripped of its elements allowing the identification of the organization.
The decision was anonymised because it did not seem useful to name any particular website publisher, given that the tool is widely used.
The objective of the publication was to advise all data controllers using this tool to take this publication into account.
Do organisations have a deadline for compliance?
The organisations given formal notice have a period of one month to comply and to justify this compliance to the CNIL. This one-month period may be renewed at the request of the organisations concerned, if the CNIL so agrees.
All data controllers using Google Analytics in a similar way to these organisations should now consider this use as unlawful under the GDPR.
They should therefore turn to a provider offering sufficient guarantees of compliance.
Is this interpretation of the consequences of the ""Schrems II"" ruling by the CNIL shared at the European level?
In order to harmonise decisions and provide legal certainty for stakeholders, the European authorities that received complaints from the association noyb (none of your business) on the subject of transfers by Google Analytics have organised themselves into a working group to examine jointly the legal issues raised in these cases and coordinate their positions and decisions.
The CNIL's decision is not the first at the European level: one month before the CNIL, the Austrian data protection authority issued the first decision of this kind in January, along the same lines as the French authority.
Why weren't all the complaints filed by the association noyb processed at the same time?
All the complaints filled by the association NOYB that were referred to the CNIL were investigated in a coordinated manner: however, situations were examined on a case-by-case basis and according to the responses provided by the organisations.
All organisations in France whose use of Google Analytics was the subject of complaints by NOYB have now been ordered to comply.
Concerning the use of the Google Analytics tool
Are there any standard contractual clauses and additional safeguards allowing the use of Google Analytics?
The organisations ordered to comply had established standard contractual clauses with Google, which Google offers by default to users of this solution. These standard contractual clauses alone cannot provide a sufficient level of protection in the event of a request for access from foreign authorities, in particular if such access is provided for by local laws.
In its response to the CNIL's requests, Google indicated that it had put in place additional legal, organisational and technical measures, which the CNIL however deemed insufficient to ensure the effective protection of the transferred personal data, in particular against requests for access to the data by US intelligence services.
Is it possible to set the Google Analytics tool so that personal data is not transferred outside the European Union?
No.
In response to the questionnaire sent by the CNIL, Google indicated that all the data collected through Google Analytics is hosted in the United States.
Even in the absence of transfer, the use of solutions offered by companies subject to non-European jurisdictions is likely to pose difficulties in terms of access to data. Indeed, organisations may be required by third country authorities to disclose personal data hosted on servers located in the European Union.
Article 48 of the GDPR limits these disclosures to cases where the requesting third country and the EU or the member state concerned are parties to an international agreement providing for such communications.
Is it possible to set up Google Analytics to only transfer anonymous data to the US?
In the context of the investigation, Google indicated that it uses pseudonymisation measures, but not anonymisation. Google does offer anonymisation of IP addresses, but it is not applicable to all transfers. Furthermore, it is not clear from the evidence provided by Google whether this anonymisation takes place prior to the transfer to the USA.
Furthermore, the use of of unique identifiers to differentiate individuals can make the data identifiable, especially when combined with other information such as browser and operating system metadata. This data allows accurate tracking of users, in some cases across multiple devices. If the EDPB admits in its recommendations of 18 June 2021 that using pseudonymisation can be an additional measure, its use is subject to an analysis to ensure that the set of information transmitted does not in any way allow for the re-identification of the individual, even taking into account the substantial means available to the authorities that may wish to carry out such re-identification.
Finally, the joint use of Google Analytics with other Google services, particularly marketing services, can increase the risk of tracking. Indeed, these services, which are widely used in France, can allow the IP address to be cross-checked and thus trace the browsing history of the majority of Internet users on a large number of sites.
Difference between anonymisation and pseudonymisation
Pseudonymisation is the processing of personal data in such a way that it is no longer possible to attribute the data to a natural person without further information.
In practice, pseudonymisation consists of replacing directly identifying data (surname, first name, etc.) in a dataset with indirectly identifying data (alias, sequential number, etc.).
Anonymisation consists of using a set of techniques in such a way as to make it impossible, in practice, to identify the person by any means whatsoever and in an irreversible manner. Anonymised data is no longer subject to the GDPR.
Could encryption be a sufficient additional guarantee?
Yes, but only under certain conditions.
The implementation of data encryption by Google has proven to be an insufficient technical measure as Google LLC itself encrypts the data and is obliged to grant access to or provide imported data in its possession, including the encryption keys necessary to make the data intelligible. As Google LLC retains the possibility to access the data of individuals in the clear, such technical measures cannot be considered effective in this case (see the recommendations of the European Data Protection Committee on measures that supplement transfer tools, §85).
Encryption is therefore an insufficient additional guarantee if the organisation subject to the demands of the US authorities can access personal data in clear text.
In order for encryption to be considered as a sufficient additional safeguard, the encryption keys should, inter alia, be kept under the exclusive control of the data exporter, or other entities established in a territory offering an adequate level of protection (see recommendations 01/2020 of the EDPB, §84).
Are there sufficient additional safeguards to continue to use the Google Analytics tool alone?
None of the additional safeguards presented to the CNIL in the context of the formal notice would prevent or render ineffective the access of US intelligence services to the personal data of European users when using the Google Analytics tool alone.
However, a solution involving a proxy server to avoid any direct contact between the user's terminal and the servers of the measurement tool may be possible. However, it must be ensured that the server meets a number of criteria to be able to consider that this additional measure is in line with what is foreseen by the EDPS in its recommendations of 18 June 2021.
Is it possible to continue to transfer data with the explicit consent of individuals?
The explicit consent of the data subjects is one of the possible derogations provided for certain specific cases by Article 49 of the GDPR. However, as stated in the European Data Protection Committee's guidelines on these derogations, they can only be used for non-systematic transfers, and cannot constitute a long-term and permanent solution, as the use of a derogation cannot become the general rule.
Concerning alternative solutions available to actors
Are there alternative tools?
The CNIL has published a list of audience measurement tools (in French) that can be exempted from consent when properly configured.
This list includes tools that have already demonstrated to the CNIL that they can be configured to limit themselves to what is strictly necessary for the provision of the service, and thus not require the user's consent, in accordance with Article 82 of the French law on Data Protection.
However, this list does not currently consider the issues raised by international transfers, including the consequences of the ""Schrems II"" judgment.
How to ensure that audience measurement tools do not transfer data to a third country that is not adequate?
In the case where the envisaged tool transfers data outside the European Union or where the company publishing the tool has capital or organisational links with a parent company located in a country providing for the possibility for intelligence services to require access to personal data located in another territory, it is it is necessary to assess the legal framework of the third country.
This assessment can be based on:
- decisions of the CJEU or the European Court of Human Rights, which have been able to assess the compliance of certain legislation with European data protection standards.
- the recommendations of the European data protection authorities, which have, for example, detailed the essential guarantees that must be found in the third country when assessing the level of data protection.
It may also be possible to use the proxy method which, when properly configured, allows only pseudonymised data to be sent to a server outside the EU.
Can controllers adopt a risk-based approach, taking into account the likelihood of data access requests?
No.
The personal data transferred to a country outside the European Union must be afforded a level of protection ""substantially equivalent"" to that afforded in the EU.
In particular, the possibility of unlawful access to personal data beyond what is necessary and proportionate in a democratic society by public authorities seriously undermines the fundamental rights and freedoms of data subjects.
In cases where such access is possible (and not only where such access is likely) and the safeguards surrounding the issuing of data access requests are not sufficient to ensure a level of data protection substantially equivalent to that guaranteed in the EU (see EDPS recommendations on essential safeguards), additional technical measures are needed to make such access impossible or ineffective.
These measures are provided for in the recommendations on complementary measures to transfers of the European Committee for the Protection of Human Rights and Fundamental Freedoms",5
346,"- aprilkward
Conflict: One Orange, Two Kids
Updated: Aug 5, 2021
Conflict is bad.
No, conflict is good.
The answer? Conflict is normal – sometimes it is even important.
So, what is conflict? Conflict can be defined in different ways, but a simple explanation is that conflict occurs when you desire something that seems to be the opposite of what someone else desires. For instance, conflict will almost undoubtedly happen any time there is a desire for change in a society, why? Because while many may want change, someone else is out there enjoying life the way it is and doesn’t think change is necessary or feels that change will destroy their way of life. Who’s right? Perhaps one party, perhaps no parties, perhaps parts of both parties.
The problem with conflict is that it often becomes violent, and this is where the negative associations with conflict arise. This potential for violence leads some to believe that it’s best to simply avoid conflict, and avoidance is a tactic many use in their personal lives. The difficulty here is that, by avoiding conflict, you aren’t dealing with the problem at hand. If the problem involves an injustice then avoiding conflict means accepting an unjust world. Do we want to accept injustice as the status quo?
So the trick with conflict is to figure out how an individual or a society should address the problem (by entering into conflict) and also avoid the eruption of violence.
Good news. If your over-all strategy is to resolve the conflict non-violently then you can learn tactics for becoming better at peacefully addressing conflictual issues both in your personal life and as part of society.
One tactic is understanding conflict better and expanding one’s imagination of possible solutions to conflict. Do the following exercise in your head or with friends, family, or colleagues.
Conflict scenario 1: The Orange dilemma
Imagine a table. On that table is one orange. Sitting at the table are two children. What happens to the orange?
Write up, or think up a list of all the possibilities you can imagine (the good, bad, and the ugly). How many answers did you come up with?
This example comes from a short manual called Conflict Transformation by Peaceful Means (the Transcend Method) and was published by the United Nations in 1998 as part of their disaster management training programme.
The author, Johan Galtung, suggests there are at least 16 responses possible to this orange dilemma (I counted 14). How many did you get?
I’ve run this exercise informally on several occasions with my family and friends. I’d say the average responses vary from 2 or 3 to maximum 8ish. While the list isn’t exhaustive, here are the 16 different responses that the author - an expert in conflict resolution - came up with.
Conflict scenario 1: Possible solutions to the Orange dilemma
Category 1: Zero sum thinking, one-party takes all
Might makes right: the two kids fight it out and one takes the orange.
Appeal to rule of law: the two kids turn to some principle, like the one with more need takes the orange, or the one who is higher up on the social order takes the orange.
Role for it: the kids figure it out by appealing to chance, i.e. they roll a dice, pulls straws, or play “rock, paper, scissors” to figure out who takes the orange.
Category 2: Conflict avoidance, withdrawal
Walk away: the kids decide it’s too difficult to decide or not worth it, so they walk away from the table.
Make the problem go away: if there’s no orange there’s no problem...right? The kids destroy the orange, wasting the food, or they give it to another child who’s passing by.
Frozen: the kids just watch the orange, they can’t decide what to do so they just stare at it.
Save it for another day: the kids put the orange in a freezer because they can’t deal with the problem now, maybe on another day they’ll be able to decide what to do.
Category 3: Compromise and sharing
Divide it up: the kids cut the orange in half. Half for you, half for me.
Juice it: the kids squeeze the orange and share the orange juice.
Other division: any other way of dividing the orange so that it gets cut in half and shared.
Category 4: Creative solutions
Another please?: the kids ask the teacher for another orange because she forgot one child.
Invitation to share: the kids ask other children if they would also like a slice of orange and each gets one piece.
Transformation: the kids bake a small orange cake. Then have a lottery and share the proceeds gained from the sale of the cake.
Time is worth it: the kids eat the orange by division, they save the seeds and plant them. Some time later that tree produces oranges, which they in turn share, eat, and re-plant and in time create a profitable orange grove business together.
While this little exercise is fun, imagine if the orange was an important water source, and the two children were two tribes that both needed that water, what would happen then? Well, one of the reasons to practice exercises like these is to expand the realm of creative possibilities to what seems to be an unsolvable problem. When one side says, “this is how we solve it,” and the other side says, “no, this is the only way to create a fair solution,” it is much more likely that the conflict will escalate, and maybe become violent.
However, if both sides have imagined many different possible solutions to their shared issue, then the possibility for finding a solution that works for all parties is greatly increased and the possibility for violence much less likely.
In further articles we will explore different scenarios, alternatives, tools, and tactics for addressing conflicts non-violently.
Thanks goes to Johan Galtung and the United Nations for their work on conflict transformation from which part the conflict scenario and responses were referenced. For more, please read the short manual for participants and trainers (only 35 pages!) which has lots of quality, practical tips on handling conflict, Conflict Transformation by Peaceful Means (the Transcend Method) Galtung, 1998.",2
347,"- Share this article on Facebook
- Share this article on Twitter
- Share this article on Email
- Show additional share options
- Share this article on Print
- Share this article on Comment
- Share this article on Whatsapp
- Share this article on Linkedin
- Share this article on Reddit
- Share this article on Pinit
- Share this article on Tumblr
Netflix is coming to The Grove.
The streaming giant says that it will be opening an “immersive retail experience” at the shopping and entertainment complex called “Netflix at The Grove” featuring products from its original shows and experiential elements. The shop will open to the public Oct. 13 and admission will be free.
Programs like Squid Game, Stranger Things, Bridgerton, Cocomelon and Ada Twist, Scientist will be represented in the shop, which will sell apparel, books, collectibles like Funko figures and other products.
Related Stories
There will also be an immersive element to the pop-up with “photo-ready vignettes featuring life-size versions” of characters from its programming, tailor-made for sharing on social media. In December, a second floor will add interactive experiences teeing up Netflix’s holiday programming, including Guillermo del Toro’s Pinocchio, Slumberland, Enola Holmes, The School for Good and Evil, Matilda and Emily in Paris.
The Netflix-branded store in Los Angeles marks the latest effort by the streaming company to explore shopping and immersive experiences. The company previously launched a Stranger Things experience and pop-up store, as well as a Bridgerton experience called The Bridgerton Ball. However, leveraging the Netflix brand on a store underscores the brand recognition of the service itself.
Live experiences have become a hedge from Hollywood amid larger concerns about the economy. While Netflix may not have theme parks like Disney or NBCUniversal, the Netflix-branded store is a new way to experience the brand and its IP in real life.
Similarly, shopping is a relatively new area of focus for Netflix, which only launched an online retail shop last summer featuring branded merchandise from its programming. A physical Netflix store underscores that it now has enough brand equity to support something bigger.
“Following the incredible success and excitement from our fans for our immersive experiences around the globe, this felt like the most organic next step to continue our growth and bring Netflix’s most beloved shows together in a completely new way,” said Greg Lombardo, head of live experiences at Netflix, in a statement. “Celebrating our fans and giving them the opportunity to put themselves in the world of the stories they love is at the heart of what we do, and we’re thrilled to bring this experience to life at The Grove.”
THR Newsletters
Sign up for THR news straight to your inbox every day",1
348,"The announcement of Unity and ironSource's upcoming merger was a considerable surprise to many, but to hear Unity Technologies CEO John Riccitiello and senior vice president and general manager of Unity Create, Marc Whitten, the partnership is the latest move in an industry that skyrocketed during the COVID pandemic and will continue to flourish.
It's also indicative of Unity's confidence towards mobile. Riccitiello and Whitten spoke with PocketGamer.biz on how the merger came to be, the firm's bullishness towards the future of the industry in spite of the looming recession, and why developers can no longer turn their noses at monetisation and feedback.
PocketGamer.biz: How long have Unity and ironSource been discussing options for a merger?
John Riccitiello: Not all that long – we’ve known them for years, but our relationship with them is new, so we didn’t get into conversations about mergers until all that long ago. The upcoming S4 filling will actually include a chronology of the conversations that took place.
Much like the rest of the games industry, Unity has embarked on some recent high-level acquisitions, such as Weta Digital, but this is specifically a merger.
Riccitiello: ironSource became a part of us because they believe so strongly in the company and wanted to be a part of it. This isn’t like the Weta situation where Peter Jackson thought, ‘here’s my company, I’m selling it on, I’m taking money away’.
The challenge is no longer do I have an interesting idea and more do I have an idea that can rise above the noise and find the right customers and playersMarc Whitten
The announcement is centred around transforming Unity into a combined growth engine, with features such as embedding monetisation indicators. What kind of developer feedback have you received that led to this direction?
Marc Whitten: It comes down to a couple of key aspects: the first is the massive success of game creation in general, particularly in mobile. The second is the sheer quantity of mobile releases every month, in the tens of thousands.
From the game creator perspective, the challenge is no longer do I have an interesting idea and more do I have an idea that can rise above the noise and find the right customers and players. We’re really excited about creating a live engine – something that can provide critical feedback as early in the creation process as possible, and starting that conversation with potential users at that point.
Implementing monetisation earlier in the process and conversation is certainly an angle that has seen pushback from some developers.
Riccitiello: Ferrari and some of the other high-end car manufacturers still use clay and carving knives. It’s a very small portion of the gaming industry that works that way, and some of these people are my favourite people in the world to fight with – they’re the most beautiful and pure, brilliant people. They’re also some of the biggest fucking idiots.
I’ve been in the gaming industry longer than most anybody – getting to the grey hair and all that. It used to be the case that developers would throw their game over the wall to the publicist and sales force with literally no interaction beforehand. That model is baked into the philosophy of a lot of artforms and medium, and it’s one I am deeply respectful of; I know their dedication and care.
But this industry divides people between those who still hold to that philosophy and those who massively embrace how to figure out what makes a successful product. And I don’t know a successful artist anywhere that doesn’t care about what their player thinks. This is where this cycle of feedback comes back, and they can choose to ignore it. But to choose to not know it at all is not a great call.
I’ve seen great games fail because they tuned their compulsion loop to two minutes when it should have been an hour. Sometimes, you wouldn’t even notice the product difference between a massive success and tremendous fail, but for this tuning and what it does to the attrition rate. There isn’t a developer on the planet that wouldn’t want that knowledge.
[Creatives are] the most beautiful and pure, brilliant people. They’re also some of the biggest fucking idiots.John Riccitiello
Whitten: To double down on John’s point, Unity has democratised creation. Nowadays, if I were to tell you the next breakaway title is going to be made by two guys sitting in a flat in the Philippines, you wouldn’t blink twice. There is a beauty in tools that let people find out that this is how they want to make their livelihood, and our responsibility is to continue that democratisation.
Looking at ironSource, they came with the same ideas. Making feedback and publishing more transparent, as opposed to locked in a black box of marketing people. Now creators can look at minute information about monetisation and feedback in the same way they would look at load times or where they need to optimise their C# code.
ironSource was reportedly valued at 74 per cent premium to its current value. How did you reach that valuation?
Riccitiello: The way to look at it is, 11 months ago they were an $11 billion company. That's less than a year ago, and M&A premiums are really different in a high market versus a low one. From our perspective, it’s a great deal, and I would say at a time when the market is really depressed, we made a bold move that is going to create a far more successful company.
M&A often precedes staffing changes, and I understand Unity recently announced layoffs of roughly four per cent of its global staff.
Riccitiello: Just for clarity’s sake, we didn’t announce anything. That was a leak to Kotaku, and while we said we were eliminating four per cent of our positions, over half of them got rehired within other parts of Unity, so as far as quote-unquote layoff stories go, we’re not much of one.
Are you anticipating any further staffing changes, in light of the merger?
Riccitiello: Not in light of the merger. If anything, I would say that we’re both lean, reasonably weighted companies. They will likely be fewer additions, but we’re looking at our synergies that will help grow the business a lot faster.
I understand Tomer Bar-Zeev (co-founder and CEO of ironSource) will be joining the board, but will there be any changes to the c-suite?
Riccitiello: Tomer is joining my direct team, but there’s nothing else I can think of.
Just one last question: we saw tremendous confidence coming out of the pandemic, and it has given way to an immediate, pre-recession defensiveness. What are your expectations for the months ahead?
Riccitiello: One thing I always find interesting is, anytime there is talk about the stock market and the future of recession, the one growth industry becomes pundits. People with something to say and not a lot of knowledge about what they’re talking about.
My personal view is gaming will double as an industry in the course of the next five, maybe seven years.John Riccitiello
So, let me give you just a couple of things I do know about. Firstly, gaming has been a rapid growth industry. For over 30 years, it was smaller than music, television, film; every form of media. And every year, inch by inch, the games industry grew past all of them by all metrics: the number of people engaged, amount of time invested, dollars spent. It’s a stellar, meteoric rise but it didn’t happen in a straight line.
Secondly, the level of engagement during COVID was staggering, and not just gaming. A lot of industries have returned to pre-COVID levels. But this industry stepped up dramatically, and now, I would say we made three years’ progress in two, rather than four in two.
So, if the games industry can survive every recession, while gaining on every other form of media, for 30 years, it can take COVID like a relatively modest speed bump.
My personal view is gaming will double as an industry in the course of the next five, maybe seven years. That’s not a hard prediction to make because it’s the trendline we’ve been on. But I could not be more bullish on this industry, and the number one form of gaming is mobile. And when you’re in mobile, you’re driven by in-game advertising. With this merger, we had the opportunity to do something really special.",1
349,"Today I'd like to show why the practice of paying for dates on sites like Match.com and eHarmony is fundamentally broken, and broken in ways that most people don't realize.
For one thing, their business model exacerbates a problem found on every dating site:
For another thing, as I'll explain, pay sites have a unique incentive to profit from their customers' disappointment.
As a founder of OkCupid I'm of course motivated to point out our competitors' flaws. So take what I have to say today with a grain of salt. But I intend to show, just by doing some simple calculations, that pay dating is a bad idea; actually, I won't be showing this so much as the pay sites themselves, because most of the data I'll use is from Match and eHarmony's own public statements. I'll list my sources at the bottom of the post, in case you want to check.
eHarmony claims over 20 million members on their homepage, and their CEO, Greg Waldorf, reiterates that number regularly in interviews1. If your goal is to find someone special, 20 million people is a lot of options—roughly a quarter of all singles in the U.S. This sounds awesome until you realize that most of these people can’t reply, because only paying customers are allowed to message.
So let's now ask the real question: of these 20 million people eHarmony claims you can flirt with, how many are actually able to flirt back? They closely guard their number of paid subscribers, with good reason. Nonetheless, we are able to deduce their base from known information. We'll give eHarmony the highest subscribership possible.
- We'll start with their yearly revenue: $250M in 2009 as reported by the industry analysts at Piper Jaffray and CNBC2.
- Since eHarmony charges users by the month, we'll divide that big number by 12 and, rounding up, get $21M.
- Now all we need to know is how much the average user pays per month. If we divide that into the $21M they make, we know how many subscribers they have. Their rates run this gamut:
$19.95 per month, for a 12-month subscriptionFrom those numbers, we can see that they have somewhere between about 350,000 and 1,050,000 subscribers (the lower number supposes everyone is month-to-month, the higher supposes everyone is yearly).
$29.95 per month, for a 6-month subscription
$59.95 per month, for 1 month at a time
- What's the exact number? Well, I found this helpful nugget in eHarmony's advertising materials3: The most charitable way to interpret this last sentence is to assume their average account life is 6.5 months.
- We're almost there. To get eHarmony’s total subscribers, we divide their $21 million in revenue by the average subscription price. Therefore maximizing total subscribers is just a question of minimizing the average monthly fee. First off, let's do them the favor of assuming no one pays month-to-month.
- Our remaining dilemma can be expressed mathematically like this:
- After some dickery with a legal pad we discover, in the best case for eHarmony, 1/13 of their users are on the yearly plan, and the rest subscribe 6 months at a time. Thus the minimum average monthly fee is $29.18. They have at most 719,652 subscribers.
- For the sake of argument, let's round that up to an even 750,000.
So, having given eHarmony the benefit of the doubt at every turn, let's look at where that leaves their site:
Yes, only 1/30th of the ""20 million users"" they advertise is someone you can actually talk to. That's the paradox: the more they pump up their membership totals to convince you to sign up, the worse they look.
And the ironic thing is that although they basically admit their sites are filled with chaff, pay sites have little interest in telling you who's paying and who isn't. In fact, it's better for them to show you people who haven't paid, even if it means they're wasting your time. We'll show that in the next section.
First I want to show you what 29 to 1, advertised people to real, feels like. Here are some single, attractive OkCupid users.
And here are those same people behind a subscriber wall. That's pay dating in a nutshell.
Match.com's numbers are just as grim. They're a public company, so we can get their exact subscriber info from the shareholder report they file each quarter. Here's what we have from Q4 20094:
Remember, sites like Match and eHarmony are in business to get you to buy a monthly subscription. There's nothing wrong with profit motive, but the particular way these sites have chosen to make money creates strange incentives for them. Let's look at how the pay sites acquire new subscribers:
As you can see from the flow chart, the only way they don't make money is to show subscribers to other subscribers. It's the worst thing they can do for their business, because there's no potential for new profit growth there. Remember: the average account length is just six months, and people join for big blocks of time at once, so getting a new customer on board is better for them than squeezing another month or two out of a current subscriber. To get sign-ups, they need to pull in new people, and they do this by getting you to message their prospects.
If you're a subscriber to a pay dating site, you are an important (though unwitting) part of that site's customer acquisition team. Of course, they don't want to show you too many ghosts, because you'll get frustrated and quit, but that doesn't change the fact that they're relying on you your messages are their marketing materials to reach out to non-payers and convince them, by way of your charming, heartfelt messages, to pull out their credit cards. If only a tiny fraction of your message gets a response, hey, that's okay, you're working for free. Wait a second…you're paying them.
Now let's look how this skewed incentive affects the dating cycle, especially on sites like Match.com, where it's possible to for users set their own search terms.
Even more so than in real life, where fluid social situations can allow either gender to take the ""lead"", men drive interactions in online dating. Our data suggest that men send nearly 4 times as many first messages as women and conduct about twice the match searches. Thus, to examine how the problem of ghost profiles affects the men on pay dating sites is to examine their effect on the whole system.
There are two facts in play:
- When emailing a real profile, a man can expect a reply about 30% of the time. We've conducted extensive research on this, and you can read more about it our other posts. Let's couple this 30% reply rate with the fact that only 1 in every 30 profiles on a pay site is a viable profile. We get:
3/10 × 1/30 = 1/100
That is, a man can expect a reply to 1 in every 100 messages he sends to a random profile on a pay site. The sites of course don't show you completely random profiles, but as we've seen they have an incentive to show you nonsubscribers. Even if they do heavy filtering and just 2 of 3 profiles they show you are ghosts, you're still looking at a paltry 10% reply rate.
- There is a negative correlation between the number of messages a man sends per day to the reply rate he gets. The more messages you send, the worse response rate you get. It's not hard to see why this would be so. A rushed, unfocused message is bound to get a worse response than something you spend time on. Here's a plot of 12,000 male users who've sent 10 total messages or more.
The effect of the second fact is to magnify the effect of the first. For a user trying to meet someone under such constraints, a feedback loop develops. Here's what happens to the average guy:
Basically, because the likelihood of reply to each message starts so low, the average man is driven to expand his search to women he's less suited for and to put less thought (and emotional investment) into each message. Therefore, each new batch of messages he sends brings fewer replies. So he expands his criteria, cuts, pastes, and resends.
In no time, the average woman on the same site has been bombarded with impersonal messages from a random cross-section of men. Then:
Finally, in the spirit of ""don't take my word for it"", here's how eHarmony and Match.com themselves show that their sites don't work.
This is from Match's 2009 presskit:
Okay, Match is double counting to get ""12 couples"", since a couple that gets married also gets engaged. So we have 6 couples per day getting married on the site, or 4,380 people a year. Let's round up to 5,000, to keep things simple. My first observation is that Match.com made $342,600,000 last year5. That's $137,000 in user fees per marriage.
Now here's where the demographics get really ugly for them.
It turns out you are 12.4 times more likely to get married this year if you don't subscribe to Match.com.
I figured it out like so:
Remember this is the minimum ratio, because from Match's perspective, we've made a lot of very favorable assumptions along the way. And it also doesn't matter that some portion of Match's customer base is overseas, because however you account for that in their subscriber base, you also have to adjust their marriage total accordingly.
eHarmony seems to do quite a bit better than Match, claiming in their ads to marry off 236 people a day:
Their higher rate shouldn't be too surprising, because eHarmony's entire site philosophy centers around matrimony, and furthermore that's the primary reason people go there. It's explicitly not a place for casual daters.
As they've told us, their member base of 750,000 people turns over every 6.5 months, which means that nearly 1.39 million people go through eHarmony's ""doors"" each year. eHarmony fails at least 93.8% of the timeFrom the ad, we can see that just 86,140 of those subscribers get married, a mere 6.2% of the people who paid the company to find them a mate. And what of the other 93.8%, the 1,298,475 people who do not get married and then leave the site? Those people paid an average of $190 each for a personality quiz.
A major selling point for the big for-pay dating sites Match and eHarmony is how many millions of members they have, and they drop massive numbers in their press releases and in talks with reporters. Of course, there's a solid rationale to wanting your dating site to seem gigantic. When people look for love, they want as many options as possible.
However, as I've shown above, the image these sites project is deceiving. So next time you hear Match or eHarmony talking about how huge they are, you should do like I do and think of Goliath—and how he probably bragged all the time about how much he could bench. Then you should go sign up for OkCupid.
- Looking for a Date? A Site Suggests You Check the Data
http://www.nytimes.com/2010/02/13/technology/internet/13cupid.html
- The Big Business Of Online Dating
http://www.cnbc.com/id/35370922
- eHarmony.com's Advertising Splash Page
http://www.eharmony.com/advertising/singles
- Match.com's Q4 2009 Report
http://files.shareholder.com/downloads/IACI/871220273x0x349618/6d370897-220b-409b-a86e-e02801b3eed5/Gridsand MetricsQ42009.pdf. Match.com's 20 million membership claim is here: http://www.consumer-rankings.com/Dating/#table
- Ibid.
- Centers For Disease Control
http://www.cdc.gov/nchs/fastats/divorce.htm. Not sure why they care.
- The U.S. Census ""Unmarried and Singles Week""
http://www.census.gov/Press-Release/www/releases/archives/facts_for_features_special_editions/007285.html
This article was great. One of the best I think, simply because my single, older mother was using both of those sites. I pleaded her to please just try OKC, and finally she gave in. within a week she a met a guy she has been seeing regularly for about month now. She hasn’t seen so much of someone in over 4 years (4 years ago being she was married).
GREAT article. Told it like it was in net dating.
I used PRINT personal ads in local newspapers in the Dallas area and they really DId work.
No pic, Just 45 words and a banner. I had dates every weejebd ubntile the ads wee replaced by net dating which wiorked until 2004 or so.
Now it is run by greed and the sites could care less about matching you.
And people complaining about bad dates-YOU at least got a date.
I figure e harmoney will go broke with all the tv ads alone for tis big July free 10 day weekend. People are not kids and do not meet those silly questions. Be adult and let us e mails and show member and non member pics.
Dating plays on our most base emotion-the search for love.
The people should boil in oil for taking adbvantage of it.
@Jeremy Botto
No offense, but it seems like you drastically misinterpreted what was going on. The point being made was that the women were fed up with only getting impersonal replies. Sure, women send out initial messages as well, but that doesn’t mean that the original point is invalid or somehow misogynistic. This is especially so for a site like eHarmony which is depressingly orthodox in it’s approach.
I like getting notes on this blog, it makes fuel talk and gives workers to feel like they are able become involved in the conversation. I tend to agree. It’s a fantastic way.
Wow, Mr N. I’m understanding you clearly and I feel as you do. I think it’s probably more about society encouraging us to become or behave like adults not like deprived teenagers ~x~
Can you do an analysis of free sites? I only use OKC now because it’s actually well designed. I left plentyoffish.com because their site is hideous ( same with lavalife, but that’s a pay site ) … I’m a design nerd, so I may be an exception, but how much do you think aesthetics and usability affects your user base?
My only gripe about Okcupid.com is that the matches give you results from a totally different state and not local ones! Maybe some users don’t mind long distance but personally i want to be able to find someone local so we can see each other more then just once a month.
Please fix this Okcupid
Very interesting article. The subscriber non-subscriber feedback loop is very interesting. I never thought of these businesses as using their subscribers as acquisition vehicles.
I am wondering, however, if the calculation of the number of eHarmony users is unnecessarily complex. In the beginning of the calculation, you stated the simplifying assumption of no one paying month-to-month. In that case, the only equations you ned are 6x + 12y = 6.5 and x + y = 1 (the latter equation since there are only two possibilities given the assumption, they must add up to 100%). this actually gives y = 1/12. I’m actually curious what other assumptions you made on your legal pad — I’ve been very impressed with the analysis on this post and other posts and am genuinely curious about your methods.
You got that right. Match, Chemistry, Yahoo Personals and E-Harmony are rip-offs and a big waste of money with EH being the worst of all of them! I won’t use those sites again. OKC is free and works much better than the pay sites.",4
350,"Drowning in AI Generated Garbage : the silent war we are fighting
by Ploum on 2022-12-05
All over the web, we are witnessing very spectacular results from statistic algorithms that have been in the work for the last forty years. We gave those algorithms an incredibly catchy name: ""Artificial Intelligence"". We now have very popular and direct applications for them: give the algorithm a simple text prompt (don’t get me started on the importance of text) and it generates a beautiful original picture or a very serious-sounding text. It could also generate sounds or videos (we call them ""deep fakes""). After all, it generates only a stream of bits, a bunch of 1 and 0 open to interpretation.
All of this has been made possible because billions of humans were uploading and sharing texts and pictures on the commons we call ""the Internet"" (and more specifically the web, a common more endangered every day because of the greediness of monopolies). People upload their creation. Or creations from others. After all, does ""owning"" a text or a picture has any meaning anywhere except in the twisted minds of corrupted lawyers?
What we are witnessing is thus not ""artificial creativity"" but a simple ""statistical mean of everything uploaded by humans on the internet which fits certain criteria"". It looks nice. It looks fantastic.
While they are exciting because they are new, those creations are basically random statistical noise tailored to be liked. Facebook created algorithms to show us the content that will engage us the most. Algorithms are able to create out of nowhere this very engaging content. That’s exactly why you are finding the results fascinating. Those are pictures and text that have the maximal probability of fascinating us. They are designed that way.
But one thing is happening really fast.
Those ""artificial"" creations are also uploaded on the Internet. Those artificial artefacts are now part of the statistical data.
Do you see where it leads?
The algorithms are already feeding themselves on their own data. And, as any graduate student will tell you, training on your own results is usually a bad idea. You end sooner or later with pure overfitted inbred garbage. Eating your own shit is never healthy in the long run.
Twitter and Facebook are good examples of such algorithmic trash. The problem is that they managed to become too powerful and influential before we realised it was trash.
From now on, we have to treat anything we see on the Internet as potential AI garbage. The picture gallery from an artist? The very cool sounding answer on Stackoverflow? This article in the newspaper? This short viral video? This book on Amazon? They are all potential AI garbage.
Fascinating garbage but garbage nonetheless.
The robot invasion started 15 years ago, mostly unnoticed. We were expecting killing robots, we didn’t realise we were drowned in AI generated garbage. We will never fight laser wearing Terminators. Instead, we have to outsmart algorithms which are making us dumb enough to fight one against the other.
Time to enter into resistance, to fight back by being and acting like decent human beings. Disconnect. Go outside. Start human discussions. Refuse to take for granted ""what was posted on the Internet"". Meet. Touch. Smell. Build local businesses. Flee from monopolies. Refuse to quickly share and like things on your little brainwired screen. Stop calling a follower number ""you community"" and join small online human communities. Think.
How to recognise true human communities free of algorithmics interferences?
I don’t know. I don’t even know if there are any left. That’s frightening. But as long as we can pull the plug, we can resist. Disconnect!
As a writer and an engineer, I like to explore how technology impacts society. You can subscribe by email or by rss. I value privacy and never share your adress.
If you read French, you can support me by buying/sharing/reading my books and subscribing to my newsletter in French or RSS. I also develop Free Software.",3
351,"Greenland’s Melting Ice Sheet Brings an Unexpected Flow of Wealth Potential
Greenlanders are largely in favor of extracting the sand pouring from their melting ice sheet, as long as Greenland reaps the rewards.
Article body copy
Discussions about Greenland’s rapidly melting ice sheet often focus on what it’s losing. But from around the edges of the ice, a global commodity is being created.
As the ice sheet melts—2022 marks 26 years in a row that Greenland lost more ice than it gained—it’s sloughing off enormous volumes of sediment. That sediment could in turn be extracted to meet the voracious global appetite for sand.
A recent study by researchers at McGill University in Quebec and the University of Greenland, published in the journal Nature Sustainability, found that the vast majority of Greenlandic adults—eight out of 10 surveyed—were in favor of extracting and exporting sand if the projects doing so were under their country’s control.
The results surprised researchers given Greenlanders’ at-times fierce opposition to mining projects. But it suggests that in sand mining there’s a model for how Greenland can economically adapt to climate change while moving closer to economic independence from Denmark, which many Greenlanders support.
However, the consequences are uncertain and an environmental impact assessment has not yet been done. Impacts could include sucking sand off the substrate, increasing shipping traffic, and introducing nonnative species via the ballast water of ships. As that information comes out, it may affect public support.
“What I liked about this work was that it gives Greenland a voice in the discussion of climate change,” says lead author Mette Bendixen, a physical geographer and assistant professor in the Department of Geography at McGill University.
Bendixen first realized Greenland’s sediment-producing potential almost a decade ago when researchers determined that something unusual was happening along the coastline of Greenland: rather than eroding rapidly, as was the case with many Arctic coastlines, Greenland’s coast was headed in the opposite direction. Sediment—ground out of the land the ice sheet touches and swept along by its meltwater—was pouring from the ice sheet and accumulating along the coast.
“You can think of the ice sheet as a tap that pours out not just water, but also sediment,” says Bendixen. “And it’s actually pouring out so much sediment that it contributes almost 10 percent of the total river sediment in the world.”
That’s a significant proportion in a world where demand for sand is rising rapidly. In some cases, this demand has had devastating ecological consequences.
While sand, along with crushed rock and gravel, is the base material for everything from roads and buildings to solar panels—and is one of the most traded commodities in the world, by volume—the unregulated extraction of sand is fueling erosion, ecological degradation, and organized crime around the world, according to a 2019 United Nations report.
In 2019, Bendixen and her colleagues published a paper outlining Greenland’s potential to export sand to fulfill some of the global demand. That prompted an immediate response, with five of Greenland’s seven political parties calling for the idea to be explored. But Bendixen says that the study left a crucial question unanswered: what did the people of Greenland think?
This led to the survey of 1,000 adults—roughly 2.5 percent of Greenland’s population of 56,000, about 90 percent of whom are Indigenous—on the question of sand extraction. Some 84 percent indicated support for the activity, with three out of four respondents saying it should be led by Greenlanders.
This support stands in sharp contrast to public attitudes toward other mining projects, which have also been pitched as a response—and a solution—to climate change. These include a rare earth and uranium mine in south Greenland. In 2021, opposition to the Kuannersuit mine helped propel to power the left-wing party Inuit Ataqatigiit (IA), which campaigned on a promise to halt the mine.
Mariane Paviasen, an IA member of Greenland’s parliament, helped catalyze much of the opposition to the mine in Narsaq, a predominantly Indigenous community where many residents depend on farming and fishing. While the rest of the world saw the rare earth minerals found in Greenland as the key to climate salvation, that solution risked coming at the country’s expense, Paviasen says.
“We have to maintain clean water, we have to maintain clean air, because we hunt and eat from our sea and our land. That’s why it’s so important that we keep it as clean as possible,” says Paviasen. “If we keep on destroying every corner of the world, what would be left for the next generation?”
Piitannguaq Tittussen, who founded the NGO Friends of the Nuuk Fjord, says past mining projects have already left a legacy of environmental damage. Pollution from the Black Angel lead-zinc mine, which operated in west Greenland from 1973 to 1990, left some nearby areas closed to fishing. Waste rock from the country’s oldest mine, which produced cryolite in south Greenland until 1987, continues to cause unsafe levels of lead in the neighboring fjord (a narrow inlet of the sea between cliffs).
In the 21st century, the melting of the ice sheet that covers 80 percent of Greenland’s surface began to reveal more minerals, including those used in the production of electric cars and wind turbines.
“Everyone saw dollar signs,” says Tittussen, but he was watching out for the potential environmental impact.
This picture was further complicated by the fact that in 2009, the government passed an act on self-government, establishing the people of Greenland’s right to self-determination. This fueled increased interest in resource development.
As it stands, more than half of Greenland’s revenue comes from a block grant from the Danish government and mining projects have been pitched as a way of ensuring greater economic independence.
But critiques of mining projects have pointed out that Greenlanders have not benefited from resource development in their territory. Historically, much of the income from mining went to the Danish state or the international operators of the mines.
Rasmus Leander Nielsen, a coauthor of the Nature Sustainability study and political scientist at the University of Greenland, says even projects proposed in the last decade have not produced the desired results.
“Basically, no income has come to Greenland,” he says. “Some of the heyday of expectations, if you go back to 2010, have not panned out as the optimists, or even the realists, thought.”
Tittussen, who is Inuit, says mining projects have also failed to respect the need to consult Greenlanders. In the case of an iron ore mine proposed by London Mining Greenland A/S, for example, public meetings were held in English, but not Danish or Greenlandic.
“[A manager] told us, ‘You must learn English if you want to be informed,’” Tittussen says. The project eventually collapsed due to lack of financing.
With the Kuannersuit rare earth project, Greenland’s ministry of nature and government reprimanded Greenland Minerals Limited for undermining the department’s authority, including by misinforming the government and contacting civil servants who had no authority in the environmental assessment process. Meanwhile, Paviasen says, Narsaq residents were not consulted enough.
“We were not included enough, and we were never asked what kind of development we would accept in Narsaq,” she says. “That is something we have to do something about.”
When it comes to activities like sand extraction, some Greenlanders’ support is conditional. Tittussen says while it could be a way for Greenlanders to benefit from their natural resources, “it must be [with] better conditions and better environmental protection.”
Paviasen says she’s not opposed to mining as such, including sand mining—so long as projects comply with Greenlanders’ demands.
“If mining companies could do it without polluting and contaminating the area … that would be acceptable,” she explains. “But they also have to talk with nearby inhabitants.”
Either way, at present, the environmental impact and economics of extracting and exporting sand from Greenland are unclear. The government recently completed an assessment of the potential for export to Europe, which concluded there is not yet a business case—shipping sand is expensive—though that could change as global demand for sand rises.
For now, Bendixen says the opposition she’s heard has come from conservation organizations and universities in Europe who view Greenland as an untouched landscape.",2
352,"The end of Moore's law forced YouTube to make its own video chip
YouTube now controls its hardware roadmapBy Shawn Knight 12 comments
In context: Partha Ranganathan came to realize about seven years ago that Moore's law was dead. No longer could the Google engineering VP expect chip performance to double roughly every 18 months without major cost increases, and that was a problem considering he helped Google construct its infrastructure spending budget each year. Faced with the prospect of getting a chip twice as fast every four years, Ranganathan knew they needed to mix things up.
Ranganathan and other Google engineers looked at the overall picture and realized transcoding (for YouTube) was consuming a large fraction of compute cycles in its data centers.
The off-the-shelf chips Google was using to run YouTube weren't all that good at specialized tasks like transcoding. YouTube's infrastructure uses transcoding to compress video down to the smallest possible size for your device, while presenting it at the best possible quality.
What they needed was an application-specific integrated circuit, or ASIC – a chip designed to do a very specific task as effectively and efficiently as possible. Bitcoin miners, for example, use ASIC hardware and are designed for that sole purpose.
""The thing that we really want to be able to do is take all of the videos that get uploaded to YouTube and transcode them into every format possible and get the best possible experience,"" said Scott Silver, VP of engineering at YouTube.
It didn't take long to sell upper management on the idea of ASICs. After a 10-minute meeting with YouTube chief Susan Wojcicki, the company's first video chip project was approved.
After a 10-minute meeting with YouTube chief Susan Wojcicki, the company's first video chip project was approved.
Google started deploying its Argos Video Coding Units (VCUs) in 2018, but didn't publicly announce the project until 2021. At the time, Google said the Argos VCUs delivered a performance boost of anywhere between 20 to 33 times compared to traditional server hardware running well-tuned transcoding software.
Google has since flipped the switch on thousands of second-gen Argos chips in servers around the world, and at least two follow-ups are already in the pipeline.
The obvious motive for building your own chip for a specific purpose is cost savings, but that's not always the case. In many instances, big tech companies are simply looking to create a strategic advantage with custom chips. Consolidation in the chip industry also plays into the equation, as there are now only a couple of custom chipmakers to choose from in a given category making general-purpose processors that aren't great at specialized tasks.
Also read: The death of general compute
Jonathan Goldberg, principal at D2D Advisory, said what is really at stake is controlling the product roadmap of the semiconductor companies. ""And so they build their own, they control the road maps and they get the strategic advantage that way,"" Goldberg added.
Argos isn't the only custom chip to come out of Google. In 2016, the company announced its Tensor Processing Unit (TPU), which is a custom ASIC to power artificial intelligence applications. Google has since launched more than four generations of TPU chips, which has given it an advantage over its competition in the field of AI. Google also crafted its Pixel 6 series of smartphones using a custom-built Tensor SoC, bringing hardware and software under the same roof for its mobile line.
Image credit: Eyestetix Studio",3
353,"Autonomous Quotes
15,154 ratings, 3.58 average rating, 2,174 reviews
Autonomous Quotes Showing 1-30 of 49
“But now we know there has been no one great disaster—only the slow-motion disaster of capitalism converting every living thing and idea into property.”
― Autonomous
― Autonomous
“For all the robots who question their programming.”
― Autonomous
― Autonomous
“Everybody is an outsider, if you go deep enough. The trick is reassuring people that you’re their kind of outsider.”
― Autonomous
― Autonomous
“She wasn’t sure which motivation made better fuel for innovation: naïve but ethical beliefs, or the need to survive.”
― Autonomous
― Autonomous
“He was a user of his own consciousness, but he did not have owner privileges. As a result, Paladin felt many things without knowing why.”
― Autonomous
― Autonomous
“Suffrage didn’t mean equal opportunity.”
― Autonomous
― Autonomous
“Nothing like drugs to take the edge off drug problems.”
― Autonomous
― Autonomous
“People assigned genders based on behaviors and work roles, often ignoring anatomy. Gender was a form of social recognition.”
― Autonomous
― Autonomous
“The key to autonomy, she realized, was more than root access on the programs that shaped her desires. It was a sense of privacy.”
― Autonomous
― Autonomous
“She could taste a nuanced ethical understanding of the patent system all over his body.”
― Autonomous
― Autonomous
“Back then, she was certain she could change the world just by making commits to a text file repository,”
― Autonomous
― Autonomous
“Bots, who cost money, required a period of indenture to make their manufacture worthwhile. No such incentive was required for humans to make other humans.”
― Autonomous
― Autonomous
“My mother says that smart women are always crazy.”
― Autonomous
― Autonomous
“How many times had Paladin looked into this human face, its features animated by neurological impulse alone? He did not know. Even if he were to sort through his video memories and count them up one by one, he still didn't think he would have the right answer. But after today's mission, human faces would always look different to him. They would remind him of what it felt like to suffer, and to be relieved of suffering.”
― Autonomous
― Autonomous
“When it came to intellectual property, justice was simple and clear.”
― Autonomous
― Autonomous
“Every master loves to fuck a slave. It is a law of nature, or maybe culture.”
― Autonomous
― Autonomous
“and finally his current self-awareness, tinged with compulsions whose origins he couldn’t access or control.”
― Autonomous
― Autonomous
“Perhaps human intelligence gathering was a version of network penetration, and he could better integrate into social situations by inviting humans to see an illusory version of himself.”
― Autonomous
― Autonomous
“She was designed to look human, her face the replica of a woman whose image Med’s tissue engineer had licensed from an old Facebook database.”
― Autonomous
― Autonomous
“She just wouldn’t stop reimplementing operating system features for her programming class. The only thing keeping her alive was a feeding tube the docs had managed to force up her nose while she was in restraints.”
― Autonomous
― Autonomous
“You may be a hydrocarbon guzzling bot, but he likes you because you’re dealing with the same problem. Just figure out a way to share their problems.”
― Autonomous
― Autonomous
“Plus, it was made by Zaxy, the company behind Smartifex, Brillicent, and other popular work enhancement drugs.”
― Autonomous
― Autonomous
“It didn’t just boost your concentration. It made you enjoy work. You couldn’t wait to get back to the keyboard, the breadboard, the gesture table, the lab, the fabber.”
― Autonomous
― Autonomous
“Somehow Jack’s call for participation on a couple of local biotech hacker forums had gotten reposted to an artists’ mailing list, and a bunch of poets showed up to argue with them about the true meaning of anarchy.”
― Autonomous
― Autonomous
“Over a century ago, scientists first began to argue that the patent system and scientific data should be opened up. Back then, it was popular for conservatives to claim that putting geneng into the hands of the public would result in mega-viruses or total species collapse. Open data would be the gateway to a runaway synthetic biology apocalypse. But now we know there has been no one great disaster—only the slow-motion disaster of capitalism converting every living thing and idea into property.”
― Autonomous
― Autonomous
“Threezed seemed to sense her mood. “Don’t feel bad that you never got indentured.” He touched her arm for a few seconds. “Nobody wants that. Plus, I’m sure you’ve been fucked over in lots of other ways.”
It was one of the nicest things a human outside her family had ever said to her.”
― Autonomous
It was one of the nicest things a human outside her family had ever said to her.”
― Autonomous
“Reaching into the pocket of her newly washed coveralls, she pulled out some 420 and sparked it up. Nothing like drugs to take the edge off drug problems.”
― Autonomous
― Autonomous
“The scientist’s skin crackled with excitement. “That’s the question that humans always ask—always, always. They want to scoop out the brains of their dead friends, plop them inside a nice new carapace, and presto! Resurrection!”
― Autonomous
― Autonomous
“Their postures suggested that she was a node, a person who sprouted and maintained social connections.”
― Autonomous
― Autonomous
“The truck was its own driver, and that driver was a high-functioning paranoid.”
― Autonomous
― Autonomous",1
354,"Workshop Tactics: the best problem-solving workshops in a box
to top
Workshop Tactics is a curated list of the best agile and design-thinking workshop techniques to help you lead your product team. Written by design consultant and Pip Decks founder, Charles Burdett.
Designed to guide you through the design process using group facilitation activities, each tactic can be used independently as a mini-workshop, or combined with multiple tactics to create Sessions.
You'll find: creative ideation workshops, energisers, icebreakers, retrospectives, root-cause analysis workshops, decision-making matrices and core facilitation techniques.
Find out why our customers love Pip Decks so much.
Workshop Strategy System
Session
Various ways to string multiple tactics together to make a longer, more in-depth workshop.
Goals
Agree on a desired end-state to work towards, so daily activity is moving you in the right direction.
G.R.O.W
Create a plan on how to achieve a specific goal.1-2 hours
Newspaper Headline
Think about the company’s future by predicting what the press might say on their front pages.30 mins
Sailboat
Find out what your goals really are, the reasons behind them and what’s stopping you from achieving them.1 hour
Sticky Steps
Start with your goal and work backwards to give you a clear path on how to get there.30 mins
Understand
Unpack problems and discover insights with critical and analytical thinking exercises.
Assumption Collecting
Collect assumptions that reflect what you and your team think might be true about the project.1 hour
Prototype Persona
Try to predict who is using (or will use) your product and why, so you can start testing with the right people.1 hour
Roles and Responsibilities
Understand each other’s roles better, and learn who is responsible for what.1 hour
Skills Market
Learn about each other’s skills, abilities and ambitions, so you can understand how to help each other grow.1 hour
Five Whys
When faced with a problem that is affecting a project, ask “Why?” five times to get to the root cause.30 mins - 1 hour
Frame
Articulate your problem or experiment in a clear way, so as to make it easier to start solving or testing.
Problem Statement
A problem statement that captures the project’s goals, problems and measurable success criteria.1 hour
Hypothesis Statement
Treat your assumptions as experiments by turning them into testable hypotheses.30 mins
Value Proposition
Clearly articulate the point of your service or product, who it’s for and what makes it unique.1 hour
Ideas
Encourage coming up with lots of ideas, then refine the best into more detail.
Mind Map
Turn all your thoughts into an interconnected map so you have stimulus for idea generation.30 mins
Storyboard
Draw your idea as a sequence of key moments and real world interactions to better understand how it works.1-2 hours
Evaluate
Assess problems or ideas against certain criteria to understand them better.
Premortem
Think about all the ways something might go wrong, so you can effectively plan to stop it from happening.1 hour
Rose, Thorn, Bud
Evaluate something’s positives, negatives and opportunities. Such as an idea, project or a process.30 mins
Heart, Head, Hand
Evaluate the usefulness, emotional resonance and business value of an idea.30 mins
Decide
Prioritise ideas or problems based on your needs in order to decide what to focus on.
Discuss
Facilitate discussion to gain a better understanding of a team and progress towards goals.
Democratic Discussion
Build a discussion agenda together and keep track of what’s been discussed, and needs to be discussed.1 hour
Three Little Pigs
Reflect on what’s going well, and what could be improved with the help of a childhood fable.1 hour
Technique
Core techniques that are fundamental to facilitating a successful workshop.
Session Principles
Creating principles for a meeting or workshop is a 5-10 minute investment resulting in an engaged, productive and more effective group of people.5-10 mins
Ice Breakers
Warm up the room to make people more willing to contribute to the session you are about to run.10 mins",2
355,"July 24, 2022
Illustration: Christopher T. Fong/Protocol
Good morning! You thought subscription fatigue was bad? Wait till you see what comes next.
If it feels like you’re suddenly being charged for everything in your life, it’s because you are. And more often than not, that line item on your credit card statement is a monthly charge.
Subscriptions are everywhere. Dinners, razors, video games, electric scooters, workout apparel: Almost everything can now be bought under a monthly payment model. And, by-and-large, interest in the subscription economy shows no signs of slowing down.
But now we’re onto the next chapter: Welcome to the age of micro-subscriptions.
There are indicators of increasing consumer animosity and evidence that companies may be testing the boundaries of the subscription business model.
Companies are constantly looking for new ways to make money off of us, and the lure of the monthly fee model is bound to be too enticing to pass up.
Many businesses are used to offering a set of products or services as a bundle, which makes it easier to unbundle and sell as separate subscriptions. Couple that with concerns about an economic slowdown ahead and it’s a low-hanging strategy for businesses to try to both grow and diversify their sales.
Smaller payments work at getting us to pay for a product or service — something that we might have previously been getting for free or as part of an otherwise bigger package of services, like TweetDeck. They can also help alleviate some of the problems businesses face in managing subscription models.
Given the success, it’s likely we’ll see even more of this. For example, Elon Musk wants to lower the already rock-bottom pricing for Twitter Blue and charge it all upfront instead of monthly.
Ever since the Cambridge Analytica scandal at Facebook, backlash has grown against the “free” business model, one in which consumers are largely paying for the product with their data or some other non-monetary form of remittance.
But perhaps that wasn’t so bad. Corporations are going to get our information one way or another. Now, they’re also going to get our $2.99 per month. Maybe our only hope now is the hacker community.
Chip shortage could undermine national security: The global shortage of semiconductors has impeded the production of everything from pickup trucks to PlayStations. But there are graver implications than a scarcity of consumer goods. If the U.S. does not ensure continued domestic access to leading-edge semiconductor manufacturing, experts say our national security could suffer.
This Al Gore-backed coalition is trying to hold climate polluters accountable — Michelle Ma
Charles Lamanna runs one of Microsoft’s fastest-growing businesses: Helping regular folks build business apps — Aisha Counts
Coinbase case could turn crypto tokens into securities — Tomio Geron
There’s a new push for a right to repair enterprise software — Ben Brody
Meta’s next big bet: The ‘metaversity’ — Kwasi Gyamfi Asiedu
How will Big Tech respond to the end of Roe v. Wade? Look abroad. — Issie Lapowsky
Chiplets helped save AMD. They might also help save Moore’s law and head off an energy crisis. — Max A. Cherney
How I decided to allow remote work forever at Atlassian — Allison Levitsky
Security teams are skeptical of AI. Attack prevention products could change that. — Kyle Alspach
Chip shortage could undermine national security: To ensure American security, prosperity and technological leadership, industry leaders say the U.S. must encourage domestic manufacturing of chips in order to reduce our reliance on East Asia producers for crucial electronics components.
Thoughts, questions, tips? Send them to our tips line, tips@protocol.com. Enjoy your day, see you tomorrow.
To give you the best possible experience, this site uses cookies. If you continue browsing. you accept our use of cookies. You can review our privacy policy to find out more about the cookies we use.",1
356,"Why writing by hand is still the best way to retain information
Picture this: it’s a work day at an enterprise payments processing company, and there is a critical data engineering task that needs to be completed. In this case, I’m the data engineer who needs to finish the task, but I am missing information necessary for my data model to be finished. I heard the information in a meeting. It was discussed in the daily standup. I have some vague typed notes, but I can’t recall the technical details I need to finish my work. No one is available to answer my question. It’s then that it hits me: I should have written down notes by hand during the meeting.
Writing notes by hand would have given me several different tangible resources that could help me find the critical missing information: a stronger memory of the meeting I was in, the gaps in the details of the discussion that occurred, and the notes themselves that would help me trigger a stronger recall of the events just by reviewing them on paper. Detailed typed notes would not help my recall and retention of the information in the meetings in the same way that notes written by hand would, though they would have been helpful.
It’s hard to keep documentation accurate for a whole organization or even a team with day-to-day process, programming, business, and client changes at the micro and macro levels. But as individuals who consume new information on a minute-by-minute basis, we can learn what we need to with more information retention, cognitive recall, stronger reading comprehension, and a tactile, visual memory of the information we consumed just by hand writing our notes. Writing by hand still remains the most powerful way to learn and retain information.
Writing by hand creates stronger reading comprehension
It would come as no surprise to most people that human beings are visual learners. This applies even to writing, though at first written words and visual learning may seem different. When a person thinks of “visual learning”, what may be pictured are videos, images, and other forms of graphic information and media. Yet letters and words are visual representations of a mutually-agreed upon social communication form: written language.
When a young human is learning to read, they must first learn to recognize the different shapes called “letters” that belong to their native alphabet. A letter means nothing to a person who does not know what sound or function that letter is supposed to represent in language. So as human beings, before we learn what a word is, we first must learn that the graphical representation of a letter means something. We must also learn the differences between individual letters as well as variations in the shapes, sizes, and styles of those letters.
In a 2012 study published in Trends in Neuroscience and Education, researchers Karin James and Laura Engelhardt observed of pre-literate children, “When children begin to print, their motor output (of a letter) does not conform to prototypical lettering: each output (which is also the perceptual input) can be said to be noisy relative to the model.” Despite the fact that the children’s recreation of a letter was messy compared to the letter model, their brains still accurately recognized that the letter they drew was the same one they attempted to copy. As James and Engelhardt said, the children recognized these letters “presumably because the children themselves created them.” This is visual learning and acumen: the children needed to learn what an individual letter looked like in its various “noisy” and exemplary forms in order to identify and comprehend that letter in the future, regardless of its representation.
Handwriting is a unique expression of each person who learns to write; they represent letters and words as a written output of what they perceive those letters to be. James and Engelhardt showed in their study that this repetitive, creative handwriting also creates stronger reading comprehension and maturity of language recognition. “The most novel result of our ROI analysis,” say James and Engelhardt, “is that visual processing of letters is affected by specific motor experience—the act of printing a letter”.
Writing by hand creates a tactile information recall
One of the most important parts of learning new information is the ability to retain it and recall it later when it is relevant. Writing by hand on paper creates a tactile, personalized experience each time a person takes notes. The complex experience of hand writing on paper contains a multitude of variable elements: the creativity of an individual’s written representation of language, the texture of the paper itself, the fine motor skills needed to translate thoughts into written language, the engagement of the physical senses, and even the reading comprehension strength that we learned of earlierAll of these complexities create a stronger memory of the information that is taken in during the note taking.
There have been a few scientific studies done on the subject of information processing through digital note taking and notes taken by hand. A recent study led by neuroscientist Professor Kuniyoshi Sakai at the University of Tokyo published in March 2021 showed that subjects who recorded calendar event information on paper showed more brain activity than subjects who recorded the same information onto a smartphone when they attempted to recall details about that calendar information later. And they recalled/entered the information 25% faster when writing it by hand.
Professor Sakai suggests that analog and paper learning experiences cannot be mimicked by the uniform ways in which digital devices represent information. “Digital tools have uniform scrolling up and down and standardized arrangement of text and picture size, like on a webpage. But if you remember a physical textbook printed on paper, you can close your eyes and visualize the photo one-third of the way down on the left-side page, as well as the notes you added in the bottom margin,” says the neuroscientist. That stronger tactile memory is easier for the brain to recall later on even when the paper isn’t present later; so is the information the brain associates with that learning experience.
Typing doesn’t have the same cognitive effects
We know that typing does not engage the brain with the same level of cognitive interaction as handwriting for various reasons. This has been a hot topic in the early education sphere around the world for over a decade as typed notes and digital notepads become more and more popular in classrooms. In fact, replacing handwriting with typing notes could be detrimental to early literacy skills because it lacks the creativity necessary for strong reading comprehension and faster note-taking.
In a study from the Developmental Neuroscience Laboratory at the Norwegian University of Science and Technology , Professor Audrey van der Meer confirms that a keystroke on a keyboard lacks the creativity of handwriting and won’t challenge memory the way that writing by hand does. Two professors from University of Umeå, Sweden champion writing by hand for students as a cognitive process necessary for the best learning experience: “Think of writing as learning an instrument: separate skills…need to be practiced in order for the player to become independent of the mechanics and allow for full expression of…the meaning.”
Although typing notes can be useful and even faster for some note-takers, ultimately it does not have the cognitive, tactile, memory, or visual cognitive effects that people can get when they write by hand. Typing notes can be good, but it won’t make it easier to remember what was said later on.
Proceed with caution
Perhaps you’re like me and you already take notes by hand sometimes. I hope you’ve been writing down the parts of this blog that you want to remember if that’s the case! If not and you also like to type sometimes like me, be nice to your hands as you begin your handwritten note journey again. Be prepared to feel challenged physically and mentally as you develop a new practice. Spend some money on a notebook you like, with paper that feels good against the rough scratch or smooth roll of your favorite pen. Those tactile moments will live in your mind when you want the information again later.
Writing by hand remains the best way to take in new information. It helps with reading comprehension, creativity, memory, and information retention in ways that are unmatched by other learning tools. Your writing, your shorthand, and your notes that look incomprehensible to others are a special part of your processing that help you learn in your way. So go ahead and get writing. By hand, of course.Tags: memory, notes, second brain
21 Comments
I completely agree. I, very often, find myself envisioning the notes I took even if they are not in front of me. I’ve always taken hand written notes. If I need to then share them, I type them up for everyone and re-organize as necessary so they are easier for others to understand.
Very good article! Insightful to say the least. I wonder how note-taking on digital e-Ink tablets like the reMarkable would compare with actual paper writing. In theory, the two should be very similar (i.e. the eInk tablets allow you to use a pen but lack the actual pen-on-paper feeling although it is simulated).
Yes, I wonder too! This is an important question.
No. My memory is still the quickest way to recover information and understand it. At least it is for me. Thank you
love him first site
This is an interesting article – but not for what you might think. The author (an IT professional) cites papers showing writing improves learning in children. Then says using a hand-written calendar improves recall 25%. Finally makes the leap that handwriting notes in adults improves recall. This is not a valid conclusion.
It depends on your goals. Some studies *do* indicate better recall for handwritten notes. However, recall is not always the goal. Because digital “organize nothing, search everything” will result in better “recall” with digital notes. And digital notes are more easily re-organized.
I love my dead-tree journals and am an avid Bullet Journaler. I’ve switched completely to digital notes, however. Because they sync across all my devices, are malleable, and are infinitely searchable. I keep my paper journal handy because free-hand drawing still has value (and I use a scanner to store the notes in PDF).
But if your goal is to retrieve valuable notes, digital wins every time. It is more permanent than paper and easier to “search.”
I’d say paper-based notes is good to “Capture” the meeting, allowing you to organize the thoughts later on and dump it in a better, searchable “digital” way.
But keep the paper notes just in case.
all true, but writing by hand doesn’t scale and, at least me, doesn’t find my notes from Last week
If you are new to handwritten notes do yourself a favor and get good paper and a good pencil. Rhodia for me is the best paper, it soft like silk. Pentel 0.9 GraphGear is the best bencil ( they have different lead sizes ). And you’ll want a pentel high polymer eraser because the erasers on the pencils are tiny.
It’s been on my wishlist for way too long to buy a nice notebook to keep on my desk, I still use to note things down on new Notepad and sticky notes tabs on my computer, and at first it seems like the quickest way but also quickly becomes difficult to manage and find and properly recall what I wrote the notes for in the first place. Just like how reading an actual physical book is far superior than reading on a Kindle, the experience of writing with pen on paper is a lot better! This article just double-confirmed my decision on going if not-full pen-paper than at least majority of my note taking activities to shift to physical notebook.
Buy a “loose leaf binder” instead. Buy a good one. When you’re done with a project, remove the sheets related to the project and store the pages in a plastic ziploc back.
That way your loose leaf binder will never become full, and you have a set of pages related to a project nicely gathered together without wasting space.
If you need to one day peruse those sheets, use a cheaper “loose leaf binder”, temporarily take out the sheets from the ziploc bag, put it in the binder, and peruse it on your convenience.
Very Interesting article. Writing on paper works better for me.
Interesting article, although I’m not sure if I agree with nor do I like the assertion that handwriting is unconditionally superior to typing in terms of note-taking. In reality it’s different for everyone, and I find typing to provide me with roughly the same amount of retention as with writing (so yes writing is good for retention), but typing allows me to do so with a fraction of the cost in time, and with other benefits that would be too expensive to do by hand. Often when I am stuck on problems, I think out-loud by typing into my notes, which means I can include valuable self reflections and realizations along with my notes, particularly forcing myself to reflect on design approaches that won’t work and why they don’t work, instead of just keeping it in my head. If I were forced to handwrite these notes (which sometimes I have been), my ability to think was severely bottlenecked by handwriting speed; I can type about 100 words per minute, but I can only write about 15-20 words per minute by hand. And I have typed in excess of 1000 words into my notes combining the analysis of this article in my own words plus my reflections and opinions on it. Let’s say my wrist would be terribly sore if I went by the latter approach 🙂
I think the ability to have more flexibility to capture information by typing beats out the tactile benefit provided by writing, at least for me. Because of the aforementioned speed issue from above, with writing you can struggle (or at least I do) to capture context that is easier to capture with typing, and this issue can possibly reduce the effectiveness of written notes as it forces you to forgo more context and keep it in your head, which you cannot guarantee you can retain unlike with if you had time to record it via typing. The extra context you save about a meeting or lecture can help index your mind in the same way as words being in certain spots on a piece of paper. Typing can also demand creativity as you need to think about which contexts are beneficial to include into your notes and what you can leave out, or shortcut/dropped words that help you keep up with a speaker or to help you move onto your main task faster.
YMMV. I cannot read my own handwriting or even hand printed (not cursive) notes the next day. Typed notes I remember better and they are Boolean searchable which enhances my thinking style. I type faster than I think and many times my hand writing speed so my typed notes are already partly summary information processed and handwriting is far slower and bogs me down cognitively. Neurodiversity needs to be acknowledged before people propose a one size fits all for children.
All very well, but for people like me who can’t read their own writing, hand written notes are useless. At least my typed notes are readable, even if they are full of spelling mistakes!
I can’t write anywhere nearly as fast as I can type, so end up missing a lot when trying to write.
Interesting article, not as clear-cut as you make ou.
One more thing: It’s easy to add drawings, lines, arrows, and other graphical/visual “idea-dumps” assists by writing on paper using pen/pencil.
I often do that. As I write things down, I will add arrows linking to previous points, add underline(s), give a star or circle a key part, etc.
Buuuut … writing by hand is slow. So for max recollection I’d suggest adding other methods that can record the meeting automatically. A video recording is ideal, but even a voice recorder will do, as you replay the recording you can also replay the meeting in your head.
I always wonder why do I always end up so many notebooks even I am not in college; as working professional. I get it now.
Indeed writing associates a photographic memory.
I’m intrigued by the likes of Remarkable (stylus on digital device) and Livescribe (“traditional” pen on specially patterned paper). Both would seem to offer the benefits of letting me write and draw freehand while also preserving those scribbles digitally – and cleaning them up. Does anyone here have useful experience of note-taking with either?
Great article, thanks, I’ve just shared it with my friends.
I used to write by hand a lot back at University. I remember going to the woods and noting down pages of ideas for my D&D sessions, eventually writing entire scenarios by hand. I also read a lot of books – paper ones. Your entry reminded me of all that and what I have, sadly, lost.
What I can say from my time back then is that I do indeed feel noting down things with my hand was more productive than typing, both for learning new material at the academy, as well as for memorizing the storylines I was preparing for my friends. It was somewhat easier to concentrate both on writing as well as reading in the traditional way. Not to mention the brain exercise in general.
I think you might have inspired me to try and restore some of that magic. I’ll actually get myself a nice, hardcover notebook and finish the book that I started reading many months ago. I love tech, in most of its forms, but there is no denying that the simplified solutions it often proposes sometimes lead to us being actually “poorer” in a number of ways.
This isn’t the kind of article I expected to find on StackOverflow, yet I am very pleasantly surprised! Thanks.
When I taught Comparative Vertebrate Anatomy, I made use of this phenomenon as well as exploiting the different ways people take in information. This was back in the days of overhead transparencies, which could be written on during the lecture. I gave the students a handout with all the drawings but no labels or colors, and I started with the same diagrams.
Then as I lectured (for students who processed auditory information best), I drew in the details in different colors and labeled the diagrams (for students who learned best what they saw). All the students drew in the details, labeled the diagrams, and annotated them (for students who learned kinetically). This also required that all students write in the information associated with each diagram, solidifying their acquisition of the information.
The students who came to class and went through this process learned the material much better than is typical for a subject this difficult. Having to draw and write down everything was the keystone to the approach.
From this article, I can see that there are cognitive benefits to taking handwritten notes. But it overlooks the benefits of taking typed notes. I have many notebooks and loose sheets of paper, but it is very difficult to organise them or to locate a note that I remember taking some time ago. The huge benefit of typewritten notes is that they are instantly searchable – it takes seconds to find a note that I vaguely remember taking months or years ago. Personally I wish that more of my notes were typewritten rather than handwritten.",8
357,"Solari boards: The disappearing sound of airports
- Published
As day turns to night in Singapore's Changi Airport, a queue of people wait patiently for a picture with an old star.
They leave their bags by a bench, turn their cameras on themselves, and pose for a photo.
Some smile; some jump like starfish; one even dances. As they upload to Instagram, the old star watches on, unmoved.
And then - a noise. The moment they've been waiting for. The travellers turn their cameras round, and the star begins one last turn.
In a blur of rotation, Kuala Lumpur becomes Colombo; Brunei turns into Tokyo; and a dozen other cities whirr into somewhere else.
Two people taking photos, Eileen Lim and Nicole Lee, aren't even flying. They have come especially to see the departures board.
""It's therapeutic to see the names turn round,"" says Eileen, a teacher in Singapore. ""And that sound - I love it.""
Every time she comes to Terminal 2, Eileen takes a photo with the board. But now, she is saying goodbye.
In less than three hours, the hoardings will come up, and the sign will come down. Changi Airport, like hundreds of others already, will whirr, spin, and flap for the final time.
As the Terminal 2 queue testifies, split-flap boards are popular. They are a romantic reminder of air travel's so-called golden age; a menu of the world; a vintage prop for the Instagram era.
Put it this way: no-one is waiting for a picture by the digital displays.
But, like most vintage tech, split-flap boards are inefficient. They are harder to update and harder to maintain. They do not speak in full sentences. They do not advertise.
When Changi announced the ""retirement"" of their boards, they said parts - and there are hundreds of thousands in each sign - were becoming harder to find.
Even the company that gave split-flap boards to the world no longer sells them to airports.
Solari di Udine, as it is now known, was founded in 1725 - more than 250 years before Changi Airport opened - in a small town in northern Italy. It specialised in clocks for towers.
After World War Two, the company began working with designer Gino Valle. He and Remigio Solari developed a sign with four flaps, each containing ten digits - perfect for telling the time.
The now-familiar design, with white numbers on black flaps, won the prestigious Compasso D'Oro award in 1956. In the same year, Solari sold its first moving sign to Liege railway station in Belgium.
With the help of Belgian inventor John Myer, the design evolved to 40 flaps, which, like the clocks, turned via motors and currents.
Now able to display words as well as numbers, the Solari board was ready to take over the world.
The company sold ""thousands"" of boards to airports and railway stations, says marketing manager Katia Bredeon - even in hard to reach markets.
""When there were the economic protection rules in Japan, the only product using non-Japanese technology was the Solari split-flap board,"" she says.
Solari was not the only manufacturer - on the other side of Europe's Iron Curtain, for example, Czech company Pragotron made similar products - but, like Hoover, the Italians became synonymous with their design.
Although the company remains an industry leader, and still sells to airports and railway stations, the signs are now electronic (thin-film-transistor and light-emitting diode).
But - despite the march of technology - Gino Valle's split-flap board has not died out. In fact, this Italian design is having a renaissance.
While some airports still have Solari boards, they are often museum pieces, kept because of inertia or Instagram.
In Australia, for example, there are three working boards in the Qantas first class lounges in Sydney and Melbourne.
""They were nearly glassed over, but the sound is too important,"" the airline said in 2016. ""Our guests love to hear them as well as see them.""
But these days, you are more likely to find Solari boards away from airports, rather than inside.
Solari di Udine still sell their boards to ""shops, restaurants, museums, and hotels"". Others, too, are tapping into the sepia-tinted nostalgia scene.
In 2013, six engineers who worked together at Drexel University, Philadelphia, formed Oat Foundry - a company that built ""cool mechanical things for brands and companies"".
Three years later, they were approached by a ""fast-casual"" restaurant who wanted to display orders in a ""non-digital way...without guests bathing in that blue light glow"".
The client suggested ""an old-school train departure board"", and, after four months of research, they had a prototype.
The product was a mixture of old - they tested a number of materials ""to get that iconic sound of 1960s airports and stations"" - and new: it was integrated with an iPad point of sales system.
Soon after advertising their product online, they got their second split-flap client - the Chicago Cubs Major League Baseball team.
""And that's when we knew we were on to something,"" says Jeff Nowak, marketing manager.
They now have ""thousands and thousands of modules"" on ""nearly every continent"". So the question is - why do split-flap boards still appeal?
""It depends on who you ask,"" says Mr Nowak.
""The utilitarian loved that the sound signalled the changing of information. They can keep their eyes on the morning paper and only need to look up when necessary.
""For those who live in a city with an original split flap, the sound recalls a wistful memory to days gone by. The clack-clack-clack sound represents the anticipation of travel.
""[And] for the generations that do not have a history with these displays, it is the eye-catching analogue movement.""
You may also like
Last year, the final Solari board on Amtrak's US rail network was taken down - in Oat Foundry's home city, Philadelphia. There was a campaign to keep it, and it was later displayed in a museum.
For Jeff, it was a reminder that people don't always want to ride on the tails of 21st Century technology.
""You would print out and frame a hand-written or a type-written letter from Tom Hanks,"" he says.
""Would you print out an email from him? There is value in the tangibility of experience.""",1
358,"- At Amazon's Re:Mars conference in Las Vegas on Wednesday, the company demonstrated a feature that enables its Alexa voice assistant to emulate any voice.
- The feature, which is still in development, could be used to replicate a family member's voice, even after they've died.
Amazon is devising a way for users to speak to their family members through its Alexa voice assistant, even after they've died.
At Amazon's Re:Mars conference in Las Vegas on Wednesday, Rohit Prasad, senior vice president and head scientist for the Alexa team, detailed a feature that allows the voice assistant to replicate a specific human voice.
In a demonstration video, a child said, ""Alexa, can Grandma finish reading me the Wizard of Oz?""
Alexa confirmed the request with the default, robotic voice, then immediately switched to a softer, more humanlike tone, seemingly mimicking the child's family member.
The Alexa team developed a model that allows its voice assistant to produce a high-quality voice with ""less than a minute of recorded audio,"" Prasad said.
The feature is currently in development, Prasad said. Amazon did not say when the feature will roll out to the public.
While it could ostensibly be used to replicate any voice, Prasad suggested it could be used to help memorialize a deceased family member.
Making artificial intelligence conversational and companion-like has become a key focus, especially given that ""so many of us have lost someone we love"" during the Covid-19 pandemic, Prasad said.
""While AI can't eliminate that pain of loss, it can definitely make the memories last,"" he added.
The e-commerce giant wants to make conversing with Alexa more natural in general, and has rolled out a series of features that enable its voice assistant to replicate more human-like dialogue, even to the point of asking a user questions.",6
359,"Hugging Face
Models
Datasets
Spaces
Docs
Solutions
Pricing
Log In
Sign Up
Spaces:
stabilityai
/
stable-diffusion
Copied
like
2.6k
Running
on
custom env
App
Files
Files and versions
Community
2001
Linked models",3
360,"Welcome to the Maigret docs!
Maigret is an easy-to-use and powerful OSINT tool for collecting a dossier on a person by username only.
This is achieved by checking for accounts on a huge number of sites and gathering all the available information from web pages.
The project’s main goal - give to OSINT researchers and pentesters a universal tool to get maximum information about a subject and integrate it with other tools in automatization pipelines.",5
361,SeenapseYou need to enable JavaScript to run this app.,7
362,"Nicholas Eberstadt holds the Henry Wendt Chair in Political Economy at AEI and is the author of the book Men Without Work, in which he chronicles the story of the growing group of prime-age men who are neither trying to find work nor in training or education. Eberstadt’s work challenges some of the underlying assumptions populist narratives of the last six years have relied upon, and paints a picture of how this group in many ways is the canary in the coal mine for the existential crisis faced by the West.
High Noon is an intellectual download featuring conversations that make possible a free society. The podcast features interesting thinkers from all parts of the political spectrum to discuss the most controversial subjects of the day in a way that hopes to advance our common American future. Hosted by Inez Stepman of Independent Women’s Forum.
TRANSCRIPT
Inez Stepman:
Welcome to High Noon, where we talk about controversial subjects with interesting people. My guest today is Dr. Nicholas Eberstadt. He holds the Henry Wendt Chair in Political Economy at AEI. He just released a new edition of his book for Labor Day here, appropriately releasing for Labor Day his book “Men Without Work,” in which he factors in the last six years and the effect of the pandemic and shutdowns on this increasing sector of our society that simply is not showing up for work, any type of work in any capacity.
I wanted to start out by reading something that you put in this new introduction to your book, which is, “Today, in 2022, American men suffer Depression-era employment rates, even though they inhabit the wealthiest and most productive society ever known.” Then you say, “After the pandemic, we have gone from men without work,” this category of people that you’ve been studying, “to work without men,” by which you mean that there are millions of open job positions after the pandemic, increasingly chasing fewer and fewer workers. Who are these prime-age men who are just simply absent from working life, and what are they doing instead? What do their lives look like?
Nicholas Eberstadt:
Well, it’s a trend that’s been underway for over half a century now. It began in the ’60s, and it had been underway for two generations when I wrote the first volume of “Men Without Work.” Now this second edition, six years later, we see that, unfortunately, the trend has only continued. We’ve got seven million prime-age men, 25 to 54 years old, who are out of the job market altogether, neither working nor looking for work.
As you’d imagine, when you’re talking about seven million people, you’ve got some of everybody in this large group. They tend to be disproportionately of lower educational attainment, but about 40% of them have some college and maybe almost a fifth have college degrees. They’re disproportionately native born. Foreign-born men of every ethnicity and almost every educational attainment are more likely than their counterparts to be in the labor force or at work.
They tend to be never married or not married. Family structure is a big predictor for how attached men are to the workforce. Even for those who are not married, having kids at home is a big predictor for how likely you are to be involved in the workforce. We might call it the provider impulse or something like that.
This men-without-work problem, unfortunately, has been only building decade after decade. As you rightly said, we’ve got late-Depression-level work rates for prime-age men in America right now. That, unfortunately, didn’t only begin during the pandemic. If we look at the entire 21st century, if we average out the work rates for prime-age men, it’s a little bit lower than it was in 1940, when the national unemployment rate was almost 15%.
Inez Stepman:
Yeah. Actually, the longevity of this problem… Well, let’s start here, actually. When does this really… I know you start with the statistics that we use in 1940. When does this section of society become something that is consistent and not just a factor of, for example, a depression or a really bad recession. When did this start just becoming a part of American life?
Nicholas Eberstadt:
Well, back in the Depression, the presumption was that if you possibly could and you were a guy of working age, you’d get a job. The presumption was that if you were neither working nor looking for work in the civilian population, non-institutionalized, you weren’t in jail or in the military or something, there’s a very good reason that you weren’t there, that you were disabled, incapacitated, some big problem.
For the first two decades after World War II, the proportion of prime-age guys neither working nor looking for work was negligible, maybe three out of 100 in this group. It was not until the 1960s that this post-war stasis started noticeably to change, and it has been a remarkably steady flight from work for America’s prime-age man. We all know that things like economic and structural change make a big difference in the workplace and demand for labor and all of that. Really, the uncanny thing about this flight from work is that it’s almost a straight line.
From 1965 to today, the proportion of men who have dropped out of the workforce has more than tripled since 1965. If you look at that proportion over time, it’s almost a straight line. You can’t tell when the recessions occurred or when there were boom times. You can’t tell when China entered the World Trade Organization to disrupt trade. You can’t tell about our fascinating little disruptive devices like iPhones. It almost looks like a geological force. There are, obviously, some big, powerful dynamics at work that account for all of this, and they’re not entirely well explained by our regular economic received wisdom.
Inez Stepman:
Yeah, I think that’s what I find so fascinating about your book and about this subject. We had this huge debate, obviously, and shift, especially on the right, in how we think about these kinds of issues during 2015 and 2016, when Donald Trump was running for president, and really highlighting the deindustrialization, the exodus of manufacturing jobs. We’ve been connecting the deaths of despair and this disconnection from civil society largely to economic factors.
Here you are saying this really started in the 1960s, and there’s actually been relatively little impact on the number of these men who are just not… They’re not in education. They’re not attempting to build a different credential. They’re not looking for work. They’re just not interacting with the workforce. To me, this is something that really should make us question our, I guess, post-2016 political structure and how we think about politics.
It almost makes me think about the… There was an essay that Kevin Williamson at National Review got huge blowback for, and sometimes I think in some ways fairly, in some ways unfairly, people taking quotes out of context, but one of the things he was essentially asserting is, “This is a choice. This isn’t due to these larger economic factors. There’s something else going on here, and it’s not going to be solved by a new style of industrial politics or by tariffs.”
I guess the question I want to pose to you, considering all that, is, if the jobs in Detroit, Michigan, came back, the factory jobs in Detroit, Michigan, magically we snap our fingers, they are restored to the levels that they were at in 1953, is this country capable of fielding a workforce that can show up at 8:00 or 9:00 in the morning, work a full day, do job training and pass a drug test, and actually engage in those kinds of factory jobs the way they could in 1953?
Nicholas Eberstadt:
It’s a profound question that you ask, Inez, and I can give you a partial answer to it because we’ve had a natural experiment over the past several years that provides, I think, some insight into this. In the first edition of “Men Without Work” back in 2016, one line of objection or criticism was more or less, “Eberstadt, you moron, you don’t understand. There aren’t any jobs out there.” It’s harder to make that argument today, as we both know. We’re in the middle of an unprecedented peacetime labor shortage.
There are over 11 million unfilled jobs in the United States, and they’re not all for computer coders and hedge fund managers. As you were intimating, there are millions and millions of jobs available for people whose skills are basically to show up on time regularly and sober. Yet, despite all of the bargaining power that job applicants have right now during this Great Resignation that we’re in, these men, and also now women, who are on the sidelines of the economy aren’t being drawn back in.
What I would say, what I think about this, is that economic systems are pretty good, especially market systems, are pretty good at solving economic or market problems, but I think what we may face in the manpower situation of the moment is something that isn’t entirely an economic problem, isn’t a question of wages not rising rapidly enough or opportunities seeming sufficiently attractive. One of the things which we’ve, unfortunately, noticed over recent decades is that once men fall out of the workforce for some period of time, even if they are in their 20s or 30s, it’s hard to get them back in. That’s not true for people who are unemployed. They’re still in the labor force. They’re out of a job but looking for one. It seems to be very difficult to get male long-termers back into the workforce.
That is not true for women. That has not been as true for women. We’ve got this fantastic existence proof in our society that people can drop out of the labor force for years and years and go back and be productive, because they’re called mothers.
What I’m saying is that I think we have a sociological problem that we have to confront with the men, in particular, who have dropped out of the workforce and whose circumstances or viewpoint or particulars have changed in such a way as to be less interested or less capable of returning to paid work.
Inez Stepman:
First of all, what are these men doing all day? The more difficult question is how… It seems to me to be, if not a cultural problem, even a psychological problem of how to motivate people. Part of that story has to be they’re paying their bills somehow. I’m not saying they’re living like kings, obviously, but that they are finding a way to feed and clothe and entertain themselves. What are they doing?
Nicholas Eberstadt:
Well, one way we know about what they’re doing is by what some of these men tell us they’re doing. The U.S. government collects these annual surveys on time use. Mainly, they do this to figure out when people are going to work and how long people are working for and things like that. They ask all adults, not just people who are jobholders.
The men who are neither working nor looking for work tell us a very consistent story over time. About a tenth of them, maybe a little bit more than a tenth, are out of the workforce because they are full-time students. They are getting training. They’re going to get back into the game. But the huge majority of them, the ones who are neither employed nor in education and training, the NEETs as the Brits call them, the NEETs, they paint a pretty dispiriting picture of their own lives. They report that they basically don’t do civil society. They don’t do much worship or charity or volunteering. They’ve got lots of time on their hands, obviously, but they do surprisingly little help around the home, cleaning, housekeeping chores, or helping with people in the home. What they say that they do is watch. They say they watch screens. Surveys don’t tell us what the screens are. Surveys don’t tell us what they’re watching, what the content is, but 2,000 hours a year, sometimes more, as if this were their full-time job. The same self-reports say they’re getting out of the house less and less.
We have this picture of people who are pretty disconnected from society, and maybe even from families, totally disconnected from work, who are living in screens. Other data tell us that half of these men report that they’re taking some sort of pain medication every day. It’s almost as if this is sort of a training class for deaths of despair. It’s a picture of a certain type of misery, I think, and also clearly a tableau of an enormous amount of wasted human potential.
Who’s paying for this? Well, again, if we look at government numbers, it looks like it’s friends and family, meaning girlfriends, other family members, and Uncle Sam. Disability insurance programs pay some benefits for more than half of these unworking men, it seems. Disability benefits do not provide a princely income, let’s be clear about that, but they do allow for an alternative to life in the working world, which is exactly the opposite of the original, and I think quite noble, intention of disability programs, which is to provide for people who couldn’t take care of themselves, couldn’t work.
Inez Stepman:
Yeah. There’s this instinct to almost be contemptuous of this. Maybe it’s a female instinct of being contemptuous of men who aren’t applying themselves, I think even more so than the opposite sex dynamic there.
The more that I read in your book and thought about this and thought about how these men are living their lives, it struck me that they’re confronting a lot of the same problems that are making all of us go nuts. There’s this overwhelming sense that the West has lost its meaning or its purpose or its ethos, and that maybe some people are responding to it by becoming careerists and pouring themselves into their work, but some others are responding to that alienation, that disconnection, by just not having any motivation at all to go out and bust their hump at work. For what? As you say in your book, they are largely unmarried. They mostly don’t have children, at least children they take care of in the home or that they have any relationship with. They don’t have a stable family structure. Somebody is paying for their lifestyle, obviously. They’re not attached to churches. It starts to look very much, actually, like the problems that I think a lot of people who are going to work and are participating in society, at least in a more public way, are still confronting.
Why does this problem of meaning in the West really start to happen in the 1960s? Again and again, on not just this particular front but all these other issues that I’ve been exploring with folks on this podcast, whether that’s family formation or problems with psychology, all this stuff, it all seems to draw a line back to right around 1965. What is it about the 1960s that seems to have cut the heart out of the West?
Nicholas Eberstadt:
I think you’ve put your finger on something. In the social sciences and policy community, people are endlessly talking about lessons learned, but they very, very seldom talk about lessons forgotten. I think part of what we’re talking about today very much has to do with lessons forgotten.
If you are trained in the social sciences or economics nowadays, you have lost the language and you have lost the words for describing things that were perfectly obvious to a man and woman in the street in Victorian England a century and a half ago, and that is the difference between poverty and misery, or between what they would’ve called vice and poverty. Low income was not necessarily a cause of vice or poverty, and high living standards was not necessarily a cure for vice and misery.
We’ve never been as prosperous as a society as we are today. We are rolling in money. If we divided up all the national wealth, despite the little dip that we’ve been having this year, and divided it evenly, every notional family of four would have well over a million and a half dollars. That’s not what we’re lacking. What we are lacking is the internal gyroscopes to give our life meaning with the time that we have.
This also gets back to another problem that we have with the language that we use today in policymaking and policy analysis. There’s this mental tick where economists and others automatically call any sort of allocation of free time, leisure. Well, that’s not true. Leisure has a very particular meaning. Leisure is something that restores you or uplifts you. One can also use free time in ways that degrade you. It is the sheer degradation that we see in so much of the men-without-work contingent that I think really pulls on our heartstrings, and I think is a reason for great concern.
We traced this back to the 1960s, and a lot of things began. At least, we could see a lot of things beginning in the 1960s that are early chapters in the book that we’re now living in. One, of course, was the beginning of the revolution in the family, the revolutionary disintegration of the former family structure in the U.S. Another was the beginning of the rise of the social welfare state, not the Roosevelt state but the anti-poverty state, from the War on Poverty in the ’60s. We also saw the beginning of the crime explosion then. All of these factors I think ended up having tremendous corrosion on the order that we took for granted until then.
We’re not supposed to talk in value terms, at least in many parts of polite society these days, but it is apparent, it is manifestly apparent, it’s screaming out at us, the evidence of our senses, that people who are not connected to work or to their families or to their faiths or to their communities are not engaged in leisure. They’re not boning up on their Schopenhauer. As I say, they’re, in so many case, in trainer courses for deaths of despair. We’ve had this simultaneous explosion of wealth and explosion of misery in our society that can’t be explained unless we take a look at morals, values, and personal ethos.
Inez Stepman:
Yeah, this is reminding me of the UBI debate. I recall at some point somebody asked Nancy Pelosi, “What are people going to do with their time if they don’t have to go out and get a job for a basic standard of living?” She said, “Well, that’s the wonderful thing. They’re going to write poetry.” It seems obvious whichever… I’ve heard some convincing arguments for and against UBI in terms of rejiggering the welfare state, but that is the point where I tune out and roll my eyes at the UBI debate, this assertion that if we free people from the constraint of having to earn a living, that there’s going to be this flourishing of wonderful art and community and all these things that we sometimes don’t have time for because we work a lot.
It seems obvious just from observation that what’s more likely to happen is people fall into despair. As you say, they don’t use their leisure time for leisure. They use it to degrade themselves, to get on drugs, to stare at screens all day, to consume material passively, and not to actually do this great renaissance of art and music and all the things that we wish we had time for, theoretically, if we weren’t working.
I wanted to ask you, I guess, the most difficult question. It’s not really, probably, an answerable one, but perhaps you can guide us to the start of how we should start thinking about an answer. There’s this notion, especially on the right, online it goes by the trad community, and the word ‘return’ spelled with the Roman V instead of a U, and it strikes me that that’s incredibly difficult, if not impossible.
You talked about the gyroscope inside that was pointing us, almost in an un-self-aware way, in a particular direction. How do we rebuild gyroscopes in people who don’t have them and have never had them? Here I’m speaking of myself as well as the NEETs, most modern people who did not grow up with this default un-self-aware, to a certain extent, setting. It’s not clear to me that you can will that into being purely because you see the negative consequences of so many people not having it. How do we punch through to the other side, or is there any hope of punching through to the other side, of this modern lack of meaning?
Nicholas Eberstadt:
Oh, I think there’s plenty of help. I think that, actually, if we take history as our guide, we’ve got some reason for cautious optimism. Especially if we take American history as a guide, we see that ours is a history that has been defined and marked by successive Great Awakenings. Nobody knew they were coming when they were about to burst forth. Part of the particular characteristics of the American experience has been a succession of religious awakenings, of moral revitalizations of our society, that were not government driven. They came spontaneously from the bottom. My much better half, Mary Eberstadt, says she’d settle for a small awakening at the moment, and I take her point.
The reality of facts on the ground creates new facts, and a moral awakening or response to existing realities is something that we should certainly be open to. It’s also true that the brute experiences of the life course can change people’s perspective on things. Whether it’s actually getting a job, whether it’s becoming a parent, there’s so many big points in the life course that can change one’s perspective on things.
I don’t think that we should be… I don’t think we should be despairing at all about this. What we should recognize is that, for unintended reasons, government has been more of a problem than a help with what we’d call the men-without-work problem. During the post-pandemic era, unintended consequences of the emergency rescue programs had the result of incentivizing millions of people to leave the labor force, and they weren’t just our old friends, the prime-working-age men. We’re seeing some of that now in older American men and women, and maybe some of that in certain categories of younger women. Telling the truth and not being afraid to talk about true things, I think is very much our friend in trying to get through to the other side of the problem, as you were saying.
Inez Stepman:
Yeah, I think we are in the middle of a fifth Great Awakening. I think that Great Awakening is just not connected to Christianity. I think that’s largely what our quasi-religious woke folks are really experiencing.
We’re talking about these maladies that I think are not limited to this NEET class of men, but you say in your book that the NEETs are not “violently threatening civil order.” They’re instead, as you said, cooping up at home. They’re courting deaths of despair. Is this going to blunt the push for society to actually confront some of these problems?
You say, at the same time, we’re wealthier than we ever had been. It seems like a smaller percentage of people working has produced so much wealth that they can, essentially, afford to pay off a larger and larger class of people who are suffering from deaths of despair, dropping out of the workforce. Do you worry that this kind of arrangement can go on functionally… nothing goes on forever, but that it can functionally go on for a very long time?
Because of the obscene productivity of a certain sector of the economy, we just want to be left alone by the people who aren’t… I can see that attitude very strongly in Silicon Valley. That’s why I think UBI is so popular in Silicon Valley. It’s like, “Let’s just write a check. That’ll clear our conscience in terms of this other entire part of our society. We can all go back to our lives making tons and tons of money.”
Nicholas Eberstadt:
Well, the UBI siren, as you indicated, and I completely agree with you about this, it’s a false solution. It’s a false solution for a democratic society. It’s a false solution for economic malady. It’d be a very convenient way of funding a vehicle so that the little people would be quiet, go back to their television screens and Percocets; but we’ve seen what happens with people who are disconnected from the workforce of working age now and not involved in the raising of kids and stuff, and it’s not pretty. I don’t think we should want to buy more of it, no matter how expensive or inexpensive that is.
We have seen over the past generation, I think, some very troubling big trends in society that comport with this notion of a new misery. It’s not just the men who are dropping out of the workforce and the increasing dependence upon government support as an alternative to income. It’s not just the decline of the family. All of these are in it.
From the time that the Berlin Wall fell until the eve of the pandemic, the inflation-adjusted net worth of the bottom half of American homes didn’t budge. This is a 30-year period in which American wealth soared, and the bottom half of the United States in terms of net worth was no better off than they had been 30 years earlier. Manifestly, there is something in our economic formula that is not working well for a lot of our country. The economic escalator has broken down. Given that big reality, I don’t think it’s at all surprising that we should see the populist discontent that has risen up in the United States over, let’s say, the last decade. More wealth for the wealth-holders and less work for the workers is an almost classical framing of an invitation to a populist uprising.
What neither political party at the moment really has, from what I can tell, from what I can see, is an answer to the question of how do you rebuild the escalator for prosperity and success in the United States. Generally speaking, the left has got, generally speaking, an answer that we’ll redistribute our way out of it, but redistributed resources aren’t spent the same way as self-earned resources and they don’t make you feel the same way as self-earned resources. Some on the right think about miracle of the market. I’m all for miracle of the market myself, don’t get me wrong about this, but I think we have to do something more than that. We have to do something more than that if we’re going to successfully get people back into the updrafts of a dynamic, improving economy. Work-first principle would be a very good start on some of this. It wouldn’t get us all the way, but it would be a good start.
Inez Stepman:
There’s a little bit of tension then. Are you talking about that this populist uprising… You’re saying that folks are having a harder and harder time getting on an escalator to success, and I think that’s very true. I focus a lot on, for example, education policies, and the way that we heavily subsidize university and then folks end up with debt. It is a difficult… It’s getting harder and harder to get that first step on the rung and actually start to climb up the economic ladder.
At the same time, you’re saying that this particular category of men, you don’t see any change in the flat line. You said it’s basically a straight line going up from the 1960s, and actually hasn’t changed with that 30-year break that you were talking about where the top half or the top 10% has broken off so far from the bottom half economically. You’re saying these are almost parallel phenomena then, that a populist discontent is rising from, essentially, the working class, and then we have this whole other class of people who might be called the non-working class. How does all of that interact, I guess, would be my question.
Nicholas Eberstadt:
Yeah. No, that’s a very good question. I’m not sure I can give you a complete answer to that. I can tell you that the storyline of the flight from work over the past, now getting on 60 years, has had different stages to it. There was a very important crime and punishment stage to it in the ’80s, ’90s, and maybe even the 2000s, with the explosive growth of ex-con population, overwhelmingly men, in the United States. That’s an invisible portion of the story. We have the opioid epidemic and the growth in deaths of despair starting in the ’90s and going forward, unfortunately, to today. The different characteristics of this flight, the coloration of it, have been different over time.
As far as I can tell, and our public opinion polling isn’t too helpful with this because most of the public opinion polling asks about your ethnicity and age and gender and almost never asks about your employment status, but as far as I can tell from other stuff, the men without work, at home on couches, are not terribly politically active. They’re inert in other areas of the community. It looks like they aren’t big voters. They’re not the ones who are going to lead the political changes.
That’s not necessarily true, though, of their family members, friends, people in their communities. I think that people in communities who have seen some of the blight that has been associated with the new misery have been quite active, have been voting. We’re more likely to see people who are aware of this from their communities and their own lives be politically active.
One of the unfortunate things about the increasing stratification of life in the United States is I think that fewer and fewer political representatives, fewer of our political figures, actually know firsthand from their own families or from their own friendship communities the realities of this situation. They can read about it but are much more likely to be surprised by it, just because they’re personally out of touch with it.
Inez Stepman:
Yeah. This is really reminding me of, for example, Tim Carney’s work about what the political makeup of, for example, even within the GOP primary in 2015 and 2016, and how people split off the anti-establishment between Cruz and Trump based on various factors. It also solves a problem that seems to be perpetually perplexing David Brooks about how people with boats can consider themselves part of the populist revolution. They’re just seeing it happen in their friends and family and in their social networks. While some of these folks are politically disconnected as well as disconnected from everything else, their friends and family are, essentially, angry on their behalf.
Let’s wrap up with the sex factor here. You’re focusing on men. You do say that this phenomenon is bleeding over into women as well, the phenomenon of not working, not parenting. The stay-at-home scrolling life is bleeding over into women as well. How much of this…
Family seems to be such a huge motivating factor in some of the stats that you lay out here. I think, and correct me, because I’m trying to do it from recall and I’ll probably get it wrong, but that men with a high school degree but no higher degree, or maybe even without a high school degree, are as likely to be working as men with a college degree if they’re married, for example. How is this? It seems like it would perpetuate an ever-negative cycle.
Women are not attracted to men who live like this, for the most part. It goes against very basic female biology. On the flip side, especially if these guys are just zoning out watching porn or whatever, that they probably are just exiting the mating market as well as all of these other things. How does pairing off, how does marriage, how does sex factor into, essentially, the dynamics of this NEET class?
Nicholas Eberstadt:
Well, as you rightly indicate, it’s a two-way street. It’s not all unidirectional. It’s a very complicated dynamic. At the end of the day, family structure is a pretty good predictor for whether a guy is going to be in the workforce or not, no matter what his ethnicity or his age or his education. Likewise, as I think I mentioned, having kids at home is a pretty good predictor as to your level of attachment to the workforce.
It’s very historically unusual for men not to be in the provider role. You might even say it is unnatural for them not to be in the provider role. Maybe that’s all a social construct or whatever, but it’s a social construct that’s gone on in a lot of different places over an awful long period of time. For men not to be in that role nowadays ends in some ways that are very unhappy for a lot of men.
The question about what’s happened with women in this modern period is also really important. Up until about the year 2000, you could have said that the story… Women have always worked; it’s just that they didn’t get paid for it until after World War II or something, something like that. The story of women entering the workforce was just a continuing wave, not displacing men but supplementing men in this workforce. Since about the year 2000, a few years earlier, let’s say the beginning of the 21st century, the labor force participation for women and the labor force participation for men have been going down in lockstep together. Something has happened for both men and women in the workforce and in the economy and society. This has happened at the same time, by the way, that fertility rates in the United States have been declining.
What we are seeing now is the rise of a new segment of femininity in modern America, which is the prime-age woman who is not in the workforce and does not have children at home. This group has been rising rapidly in numbers, although, obviously, from a very low initial threshold. Especially for those sisters among them who are not currently married, the time-use data are showing, I think, warning signs of a men-without-work syndrome. Not much time at all spent on, you might call civil society. Not much time spent on help for others. A lot of time spent in front of screens. I think it is probably too soon for me to be declarative about this, but I think there are reasons to say that this phenomenon bears watching.
Inez Stepman:
Yeah. That’s so sad to hear because it’s such a departure from the role of women, particularly in American society, as the beating heart of civil society. Once, I recently was just looking at… Because there was, of course, there were these cataclysms of dragging down every statue of every American hero, so I was focused on the statues in small towns that I would drive through or visit or whatever, and it struck me that on the bottom of almost every single one of them is erected by a women’s group of the town, almost every single one of the public works.
Of course, women play this role in churches as well. They tend to be… Women, especially women who had older kids or who didn’t have children, but who were married, they were the ones doing all the other things, all the societal things, the block parties, the church potluck, the raising of the town statues, the organizing of contests and stuff. This is very much quintessentially American women’s contribution to society. It’s a really sad and depressing trajectory to think about women not using their time in that way and also not working.
Nicholas Eberstadt:
Well, let’s say it’s just… Let’s say, at the moment, it’s a yellow light, not a red light, but it bears watching.
Inez Stepman:
Okay. Well, we’ll continue to watch it. Maybe you will have to come out with a new edition of this book where you talk about work without women. Thank you so much for joining High Noon today.
This is Dr. Nicholas Eberstadt. His book is “Men Without Work.” We have a new edition of it with a very long introduction dealing with all of the things we’ve been talking about here in terms of what has happened in the last six years since the pandemic and the shutdowns that has affected this group very much. I really highly recommend this book. You can go and get it now. It’s available since Labor Day. Thank you so much, Dr. Nicholas Eberstadt, for joining High Noon.
Nicholas Eberstadt:
Inez, it was a pleasure. Thank you so much for inviting me.
Inez Stepman:
Just before we sign out here, I just wanted to remind everybody that we have two other podcasts that I want to recommend to you from the Independent Women’s Forum. The first is She Thinks, which is a daily download on policy and news of the day with some very great guests. That’s hosted by Beverly Hallberg over at IWF.
We also have At The Bar, which is myself and my colleague Jennifer Braceras, who runs our Independent Women’s Law Center. We talk about topics at the intersection of law, politics, and culture, so things like major Supreme Court cases. We’ve been talking about these Title IX regs that just wrapped up. The comment period for them just wrapped up. The definition of sex under law. We’re talking about those kinds of topics, and I hope you’ll tune in there.
Then, finally, as always, thank you to our listeners. High Noon with Inez Stepman is a production of the Independent Women’s Forum, and you can send comments and questions to [email protected] Please help us out by hitting the subscribe button and leaving us a comment or a review on Apple Podcasts, Acast, Google Play, YouTube, or iwf.org. Be brave. We’ll see you next time on High Noon.",4
363,"Artificial intelligence generated art is here to stay. In recent weeks OpenAI has given wider access to its AI graphics tool called DALL·E, and that has been followed by an explosion of imaginative, wacky, baffling, bizarre, and sometimes beautiful art being shared with the wider public. The success of the tool has been such that OpenAI has announced that it will be commercialising its image generation platform, so you if you want to create some AI art you will be able to purchase credits that can be used to make prompts to generate art, beta testers have been given 100 credits as a token of appreciation.
This announcement is very interesting for many reasons. For starters, it is becoming clear that we are starting to witness some of the business models that are being implemented using AI, some of the companies involved will be trying to recover some of their investment by selling access to the tools they have developed. This is also perhaps a preview of the future of creativity, where humans will be relying more and more on AI in the creative process. We may be about to see a new type of creative worker, the AI whisperer, a person who has a talent of getting the AI to produce a worthy piece of work.
But from my perspective one of the most interesting elements, and one that I have been writing for many years now, and it is the copyright status of all of these creations. Who owns these DALL·E outputs? Is it OpenAI? The person who writes the prompts? Or is it nobody at all?
The first place to go to answer these questions is DALL·E’s own terms of use. One thing you need to know first is that when using the tool, you have two options, you can upload your own image to have it modified by the AI, or you can write a prompt to generate your own image. These are referred to in the terms of use as Uploads, Prompts, and Generations respectively. OpenAI allows for commercial use of the Generations here:
“Use of Images. Subject to your compliance with these terms and our Content Policy, you may use Generations for any legal purpose, including for commercial use. This means you may sell your rights to the Generations you create, incorporate them into works such as books, websites, and presentations, and otherwise commercialize them.”
So far so good, you can use the Generations you have created in other media (such as using my Generations in this blogpost). But doesn’t that imply that they own the Generations? If they’re allowing me to make commercial use of the generated content, it means they own it, right? This appears to be what they’re claiming. Here’s the paragraph relating to ownership of the generated images:
“Ownership of Generations. To the extent allowed by law and as between you and OpenAI, you own your Prompts and Uploads, and you agree that OpenAI owns all Generations (including Generations with Uploads but not the Uploads themselves), and you hereby make any necessary assignments for this. OpenAI grants you the exclusive rights to reproduce and display such Generations and will not resell Generations that you have created, or assert any copyright in such Generations against you or your end users, all provided that you comply with these terms and our Content Policy. If you violate our terms or Content Policy, you will lose rights to use Generations, but we will provide you written notice and a reasonable opportunity to fix your violation, unless it was clearly illegal or abusive. You understand and acknowledge that similar or identical Generations may be created by other people using their own Prompts, and your rights are only to the specific Generation that you have created.”
That is some really interesting wording, and I find this paragraph to be a work of art. Firstly, you own your own Uploads and Prompts to the extent allowed by law. This is because a prompt may be too short to have any sort of protection. So let’s say I just type “Cyberpunk llamas”, I don’t think that prompt is worthy of protection, but “a llama wearing a spacesuit in a futuristic city scape with flying cars flying above, digital art”, is detailed enough that it just might have protection in its own right (more on that later). By the way, here is the image:
But what about the generated image itself? Here is the interesting part, OpenAI owns the image, but you will notice that they do not claim any copyright ownership over the image, just that they own it by means of contract. The wording is clever, it says “you agree that OpenAI owns all Generations”. So by using the service, you agree to the terms of use, and the terms of use state that you agree that OpenAI owns the images, regardless of whether those images have copyright or not. OpenAI grant you the permission to reproduce and display Generations (as I’m doing right here). They also state that they will not make any copyright claims against the user, which is nice as there may not be a copyright claim to begin with.
The final sentence in that section is quite interesting as it recognises the possibility of people coming up with similar generated images based on similar prompts. This is an elegant way of bypassing independent creation, but also of tackling the idea/expression dichotomy.
So are there any copyright issues? At the moment OpenAI seems to cleverly bypass most copyright questions through contract, making only oblique references to ownership in an IP sense. This is a large conglomerate with extremely capable lawyers, so I’m certain they must be aware that these images have a tricky copyright path ahead of them. For the most part, the legal consensus appears to be that the images do not have any copyright whatsoever, and that they’re all in the public domain. If that was the case, then we are now presented with an endless trove of public domain images featuring llamas, robots, and heavy metal cats. This is precisely why OpenAI is asserting its ownership of the images based on contract law, and not on copyright. The question may come at some point as to whether they can impose this obligation regarding ownership of an image that is in the public domain.
The situation may be different in the UK, where copyright law allows copyright on a computer-generated work, the author of which is the person who made the arrangements necessary for the work to be created. This, in my opinion, is the user, as we come up with the prompt and initiate the creation of the specific work. I think that there may be a good case to be made that I own the images I create in the UK. In this case, what is happening with DALL·E’s terms and conditions is that I am agreeing to transfer that copyright to them, this is why they specify that “you hereby make any necessary assignments” regarding their ownership of the images. Clever!
The same thing would apply to EU copyright law, where copyright exists on any original work, and the work is original if it is an intellectual creation. I would argue that this is true for some more complex prompts, for example, “a llama playing poker in a blue room, with a painting on the wall, and a window with the sun shining in” [picture here]. But I would also argue that a more basic prompt would not be an intellectual creation, and therefore not original, and thus not having copyright. Take for example “a llama recording a podcast“.
Concluding
The commercialisation of AI works is here to stay. I have started noticing a marked increase in AI-generated artworks popping up all over NFT marketplaces, some of it I will admit, is quite beautiful. For example, I just bought a very stunning AI work for about $3 USD (2 TEZ), I am perfectly aware that this work may not have copyright, but I thought it was quite pretty, so why not? I even minted one of my AI llamas here, all in the name of research (it can be yours for 2 TEZ).
All of this commercial action will inevitably lead to litigation, perhaps a commercial company will try to challenge OpenAI’s property claims, or perhaps OpenAI itself will sue. On the meantime, I leave you with a picture of a llama in the metaverse.
26 Comments
andrewducker · July 26, 2022 at 3:32 pm
Is there anything to be concerned here with the ownership of the inputs that went into creating the DALL-E system in the first place? It’s unlikely to be as blatant as with Github replicating people’s code verbatim, but if it produces someone’s pre-existing art then who is responsible, if anyone?
Bex · July 27, 2022 at 11:29 am
I was pretty sure that that was the biggest copyright question as well. You can declare that Dall-E’s works are in the public domain all you like, but OpenAI is still making a profit from them, and if it’s trained on imagery scraped from the internet… that’s hella shaky legal ground.
matchateanice · July 30, 2022 at 11:19 am
but is it working with images scraped from the net or creating them all from scratch? How can we know for sure? I was told that it was the latter. If not, that is indeed hella shaky legal ground and very worrying.
andrewducker · July 30, 2022 at 6:49 pm
It’s trained on images scraped from the internet, and uses that training to then create them from scratch.
Andres Guadamuz · July 28, 2022 at 9:28 am
That’s a great question, stay tuned, writing an article about this.
Henr · July 27, 2022 at 9:35 pm
Intellectual Property laws should be renewed to deal with these datamining-based machines. Leaving the question of mass-scraped uncredited works aside, If OpenAI “owns” any image they reproduce but do not enforce clear copyright over it, while also allowing commercial use for NFTs, blogs, books and such, I could make NFTs based on existing fictional/real characters and sell them just like it charged me to reproduce their images.
Also the UK laws open up to some horrible long term consequences. If I had money to make an AI with enough computing power to generate pictures really fast through randomised prompts, eventually I would own copyright to every previously-unused combination of pixels possible in a 2k/4k/8k… canvas. You’re signing up to an era of digital hell.
Andy J · July 28, 2022 at 7:02 pm
I’m not so sure that the contract approach really is that smart. The problem with a contract is that it only binds the actual parties to the contract. So if a third party (say a reader of this blog) takes you image of a llama in the metaverse and exploits it economically, neither you (the author and owner of the prompts) nor Open AI have any cause of action against that reader.
And I would also suggest that the situation in the UK is not quite as benevolent towards OpenAI as you suggest. Yes, section 9(3) makes the prompter the first owner of copyright in the generated image, but OpenAi’s contract terms cannot be deemed to assign ownership to them because section 90(3) CDPA specifically requires that this is done in writing and signed by the first owner, and a click-through agreement alone isn’t going to meet that criterion.
Interesting issue, though. And far too early to talk about changes to the law, in my view. We need a few more test cases (like the DABUS litigation) to see the extent of the problem.
Andres Guadamuz · July 29, 2022 at 11:13 am
Excellent points. I’d probably argue that OpenAI could intervene with third party rights, but that could be very jurisdiction dependent.
As to 90(3), absolutely true, but the terms and conditions place the onus on you to make that assignment, it is cleverly worded. Will it stand up in court? There’s only way to find out.
Kenee · July 30, 2022 at 12:18 am
Are DALL-E users legally allowed to modify images generated by DALL-E?
Andres Guadamuz · July 30, 2022 at 10:54 am
The terms do not specify, but as you have permission to reuse the images, I think that you should be able to.
matchateanice · July 30, 2022 at 11:16 am
Great article. Am I able to use the DALLE images for print on demand? I’m sure that a lot of people will be wondering the same thing…
Andres Guadamuz · July 31, 2022 at 10:21 am
The images you have generated? Yes. For other people’s generations you need permission from OpenAI.
matchateanice · August 10, 2022 at 4:02 pm
Thanks so much for the reply. The last post makes a really good point. How does someone apply the appropriate credit for these images? I’m not even sure that, for example, on RedBubble it would be possible to credit as Open AI / your brand name. Knowing how to credit would help many print on demand creators like myself. Any advice would be greatly appreciated. 🙂
Yurix · August 15, 2022 at 10:03 am
You shouldn’t be using and selling these images for profit they’re made by piecing together art from artists that have not been compensated in any way by openai it’s straight up plagiarism and should be illiegal
matchateanice · August 15, 2022 at 10:41 am
Thanks Andres. I will credit Open AI / my brand as you have done in your post here. My brother opened a print on demand store just a month ago and has already made hundreds of dollars. This is great tech!! It’s going to change the art industry. We will no longer need to hire artists. Looking forward to your next post.
Andres Guadamuz · August 15, 2022 at 3:02 pm
“You shouldn’t be using and selling these images for profit they’re made by piecing together art from artists that have not been compensated in any way by openai it’s straight up plagiarism and should be illiegal”
Read my latest blog post in response to that.
ryan · August 16, 2022 at 10:57 pm
@matchateanice where can i visit your brothers store? do you have a link or search typo to your brothers store?
forbiddenera · July 31, 2022 at 5:53 pm
‘the person who made the arrangements necessary for the work to be created’ to me also sounds like the software developer(s) so potentially could maybe be argued that both the author of the prompt and the developers might have rights. But then again, Photoshop doesn’t (and probably couldn’t, assuming it was their goal) assert any rights over anything created with their software by someone.
DALL-E is a program; it may have been trained on previous inputs but that simply produced differential equations akin to those used in say, a blur effect in Photoshop. The inputs it requires to create an output, the prompt, to me, would be akin to any inputs Photoshop would require to create an output. If you treat it like any other computer program that takes your inputs to create outputs, which is exactly what it is, the outputs should be 100% entirely your creation and copyright, whether ‘generated’ or not. Plenty of computer programs ‘generate’ some sort of output with various forms of input – just because the equations here are magnitudes of order larger and more complex, IMHO, does not change what it is.
Definitely an interesting topic. I feel like, perhaps that aside, with their contract saying basically you can do whatever and we will never assert a (C) claim could potentially void any ability to make such a claim, if not by written law perhaps by precedent set by a case.
Matt · August 7, 2022 at 10:29 am
Just want to double check. If I got this right, images created from a prompt can be sold on POD sites as prints, t-shirts etc. ? So if that’s the case who should be stated as creator ? Is it legal to list the product under your name ?
It also says: “You must clearly indicate that images are AI-generated – or which portions of them are – by attributing to OpenAI when sharing, whether in public or private.” How do one do that and is that mandatory ?
Also what if someone just takes a screenshot and starts selling your generated images, you can probably not do anything about that or I’m missing something ?
Thanks in advance
matchateanice · August 10, 2022 at 4:03 pm
Yeah, I would really like to know what others think about these questions too. Would be brilliant to have some answers. Greatly appreciated in advance.
Andres Guadamuz · August 10, 2022 at 9:05 pm
Sorry, had to delete the previous answer as it pertained to the API itself.
You don’t own the images according to their own terms, so while you can say that you wrote the prompts (and you may own them), the image itself is not yours, you get a licence.
It’s in their terms, you have to comply with the terms to use the service.
“Also what if someone just takes a screenshot and starts selling your generated images, you can probably not do anything about that or I’m missing something ?”
You can tell OpenAI that someone is using their image, but remember, the images may not even have copyright to begin with.
Anonymous · August 13, 2022 at 7:11 pm
Wikipedia scratches their head in confusion
Julián Ravelo Amaro · September 26, 2022 at 1:19 pm
Puedo utilizar las imagenes que genere DALL-E para subirlas a redes sociales?
Andres Guadamuz · September 26, 2022 at 1:20 pm
Si, claro se puede.
La buena IA - @resbla · August 31, 2022 at 9:19 am
[…] soy experto, pero leyendo artículos cómo este o este, está claro que estamos ante un momento que definirá el futuro de los derechos de autor y […]
Transformers | Ingo Hoffmann · September 6, 2022 at 11:21 am
[…] example, what about copyright rights when systems like DALL-E generate images that use company logos or other protected […]",3
364,"Over the course of the Covid pandemic, millions of people invested in air purifiers in an effort to keep their homes or offices as virus-free as possible. Soon they may be able to trade their electric air purifiers for a version that’s far more natural: a plant. Last week a French company called Neoplants unveiled a plant engineered with the singular purpose of cleaning the air inside peoples’ homes.
Just one Neo P1, as the company dubbed its initial product, can remove as much pollution from a home’s air as 30 regular plants, the company says. Neo P1 was in development for four years, and is a bioengineered version of a common houseplant called Pothos.
Most air purifiers are designed to remove particulate matter, like dust, dirt, smoke, or airborne bacteria. But Neo P1 was made to combat a type of pollution called volatile organic compounds. These are found in all sorts of household items, from furniture and cleaning products to paint, upholstery, and flooring. The chemicals in these items that are most harmful to human health—which are also the ones the plant was engineered to neutralize—are formaldehyde, benzene, toluene, and xylene. They can contribute to lung problems like cancer and COPD, as well as heart disease and other health issues.
In normal plants, photosynthesis uses a series of chemical reactions to convert carbon dioxide, water, and sunlight into glucose and oxygen. One of the most important enzymes for photosynthesis is RuBisCO, which is found in plants’ photosynthetic factories, chloroplasts, and is responsible for the first step in the process of turning carbon from CO2 into sugars.
Neoplants engineers figured out how to edit Pothos’ genome so that it would produce additional enzymes that can metabolize the chemicals mentioned above. The team inserted synthetic metabolic pathways that allow the plant to use these chemicals as carbon sources in its normal cellular metabolism, in the same way it typically uses CO2, turning the chemicals into plant matter.
“The more we uncover the code of the living organisms around us, the more we are amazed at its elegance and complexity, crafted by billions of years of evolution,” Neoplants co-founder and CTO Patrick Torbey said in a press release. “Our team is committed to building a green and vibrant future here on earth, where plants are upgraded as frequently as our phones, where people can see and feel the benefits of nature as clearly as any piece of technology.”
Of all the houseplants out there, the team chose Pothos because it’s robust and low-maintenance, doesn’t produce pollen or seeds, and has high phytoremediation potential—that is, it grows fast and can absorb a lot of CO2 or volatile organic compounds per unit of its own mass.
Since its founding in 2018, Neoplants has raised more than $20 million in funding, a portion of which was used to build a 12,000-square-foot research lab in Paris, where the company is headquartered. Founders Torbey and Lionel Mora (CEO) developed the idea at a French startup accelerator called Station F, launching the company in 2018. They grow their own plant shoots, but have partnered with larger gardening companies to scale growth of the engineered plants at production sites.
Those eager to own a Neo P1 can get on a wait list now, and will be able to place preorders in the first quarter of next year. The superplant won’t come cheap, though: it’s priced at $179 (incidentally, about 30 times the cost of a regular Pothos), and includes a pot designed to maximize air intake and three months’ worth of soil microbiome.
Plant owners will need to tend to their Neo P1, though less frequently than they would any other plant; it needs water once every three weeks in winter and once every two weeks in summer, and once a month owners will need to sprinkle the soil with drops that contain special bacteria to keep its microbiome in balance.
One question I’d have is, how will I know if the plant is working? Presumably if it’s growing that means it’s cleaning the air, but how can I be sure I wasn’t sold a regular plant, or that my Neo P1 is maintaining its effectiveness over time?
For now it seems customers will have to trust Neoplants’ claims if they’re willing to make the up-front investment of buying one of the engineered plants. If nothing else, it will still look pretty—and hopefully purify your home’s air at the same time.",2
365,"Open-Source Intelligence Market Size, Share, Growth Analysis Report By Technique (Text Analytics, Social Media Analytics, Video Analytics, Security Analytics, Geospatial Analytics, Others), By End User (Law Enforcement Agencies, Government Intelligence Agencies, Military & Defense Intelligence Agencies, Financial Services, Cyber Security Organizations, Private Specialized Business, Others), and By Region - Global Industry Overview, Statistical Data, Competitive Intelligence, Trends, Outlook, and Forecast 2022–2030
Reports Description
The “Global Open-Source Intelligence Market” report includes comprehensive information regarding the market’s historical and current estimations, future projections, market trends, competition, market dynamics, and recent developments in the Open-Source Intelligence market forecast from 2022 to 2030.
According to the study, the market accounted for around USD 5,449.23 Million in 2021 and is expected to grow at a CAGR of 28.33% during 2022-2030. The market for global Open-Source Intelligence market is forecasted to account for nearly USD 36,241.24 Million by 2030.
To learn more about this report,
Open-Source Intelligence Market: Overview
Open-Source Intelligence is a process to identify, produce, analyze, and report data collected from publicly available sources with an intention of intelligence purpose. The data gathered is analyzed and circulated to appropriate onlookers. The term ‘open-source’ refers to information accessible to the general public for free. In case of any professional capabilities, methods, and apparatuses, are required for accessing the information, and then it is not considered open-source.
Open-Source Intelligence Market: COVID – 19 Impact Analysis
The outbreak of COVID-19 has impacted a number of sectors worldwide. The government’s lockdown hampered the operations of manifold industries, including IT and manufacturing. The lockdowns resulted in rising internet penetration, social media use, and web portals. Further, the work-from-home policies and conducting major businesses online resulted in increased risk concerning cyber security.
Open-Source Intelligence technology helps businesses in detecting and mitigate the potential risk of cyber security. Moreover, these technologies help the intelligence community in extracting information from an enormous amount of public data for identifying potential threats to national security. Subsequently, Open-Source Intelligence is anticipated to gain prominence.
Open-Source Intelligence Market: Growth Drivers
Government Initiatives for Protecting Data
Data security is very important for all businesses and individuals around the world. A number of governments and organizations worldwide are taking initiatives to implement stringent regulations concerning data protection. Some examples of these regulations include the General Data Protection Regulation in Europe and the Australian Privacy Principles (APP) in Australia, among others. Such initiatives are fueling the need for data protection, thus bolstering the Open-Source Intelligence adoption among various intelligence agencies.
Rising Number of Social Media Users
Social media use is boosting, particularly post-COVID-19. Social media has turned out to be an effective marketing platform for businesses and individuals. These platforms are effective for conducting a number of internet investigations owing to the availability of a huge amount of data at a single location. The information gathered from social media platforms is referred to as ‘social media intelligence. Open-Source Intelligence helps companies to analyze digital data from the dark web, social media, forums, as well as closed databases.
To learn more about this report,
Open-Source Intelligence Market: Segmentation Analysis
The Open-Source Intelligence market is segmented into technique and end user. By technique, the Open-Source Intelligence market is further sub-segmented into one Technique, the Global Open-Source Intelligence (OSINT) Management Market has been segmented into security analytics, video analytics, text analytics, geospatial analytics, social media analytics, and others.
The segment for security analytics is anticipated to lead the market for Open-Source Intelligence and is anticipated to notice a high CAGR of over 25% during 2022-2030.
Security enables businesses to identify threats to their respective IT systems. The adoption of security analytics helps in the implementation of regulatory compliance in the organization, enabling organizations to integrate numerous data sources so as to comply with government and industry regulations. The demand for security analytics is growing with the rising cyber security incidences and threats.
Report Scope
|Feature of the Report||Details|
|Market Size in 2021||USD 5,449.23 Million|
|Projected Market Size in 2030||USD 36,241.24 Million|
|CAGR Growth Rate||28.33% CAGR|
|Base Year||2021|
|Forecast Period||2022-2030|
|Prominent Players||Alfresco Software, Inc., Siemens AG, Maltego Technologies, Expert System S.p.A., Google LLC, IPS S.p.A., Digital Clues, NetSentries Technologies FZCO, Recorded Future, Inc., Palantir Technologies, Thales Group, and Others|
|Key Segment||By Technique, End User, and Region|
|Report Coverage||Revenue Estimation and Forecast, Company Profile, Competitive Landscape, Growth Factors and Recent Trends|
|Regional Scope||North America, Europe, Asia Pacific, Middle East & Africa, and South & Central America|
|Buying Options||Request tailored purchasing options to fulfil your requirements for research.|
Key Insights:
- As per the analysis shared by our research analyst, the Open-Source Intelligence market is estimated to grow annually at a CAGR of around 18% over the forecast period (2022-2030).
- In terms of revenue, the Open-Source Intelligence market size was valued at around USD 3.4 billion in 2021 and is projected to reach USD 11.2 billion by 2030. Due to a variety of driving factors, the market is predicted to rise at a significant rate.
- Based on technique, the security analytics segment was estimated to show maximum market share in the year 2021.
- Based on end-use segmentation, the cyber security organizations segment was the leading revenue-generating category in 2021.
- On the basis of region, the North American region was the leading revenue generator in 2021.
Recent Development
- April 2022: Thales announced its Sixth Cyber Security center in Morocco with an objective to serve clients in the African continent.
- March 2022: Google announced to acquire Mandiant, Inc., a US cyber security firm, by entering into a definitive agreement for USD 23/share in all-cash transaction value of around USD 5.4 billion.
- May 2021: Palantir Technologies Inc. announced that the company will provide to the Department of the Air Force, Space and Missile Systems Center’s Cross-Mission Ground & Communications Enterprise (SMC/ECX), as well as NORAD-NORTHCOM for supporting the US Space Force and US Air Force’s critical missions.
Regional Landscape
North America region led the global Open-Source Intelligence market in 2021. The US is an early adopter of advanced technology and is witnessing a high demand for intelligence tools. It is one of the major revenue-generating countries in the global Open-Source Intelligence market. The stringent government regulations concerning security are pushing organizations across the region to implement an Open-Source Intelligence market.
To learn more about this report,
Presently, Open-Source Intelligence is used in various surveillance systems, and it creates a foundation for a number of public intelligence abilities. Further, some of the key providers based in the US include Google Inc, Alfresco Software, Digital Clues, and Maltego.
Europe is estimated to be the second largest market leader in 2021. A majority of revenue in the Europe region is contributed by the UK and Germany. The GDPR implementation by the European Union had further propelled the market and is expected to increase during the coming years.
Competitive Landscape
The market for Open-Source Intelligence is highly competitive. It comprises various global as well as regional players. The players are adopting organic growth strategies, including product launches and geographical expansions to retain their market share and gain new clients. For instance, Alfresco Software unveiled a new Intelligence Services module for the company’s cloud-first Digital Business Platform. Such new and innovative product launches help the company efficiently compete in the market.
The global Open-Source Intelligence market is segmented as follows:
By Technique
- Text Analytics
- Social Media Analytics
- Video Analytics
- Security Analytics
- Geospatial Analytics
- Others
By End User
- Law Enforcement Agencies
- Government Intelligence Agencies
- Military & Defense Intelligence Agencies
- Financial Services
- Cyber Security Organizations
- Private Specialized Business
- Others
On the basis of Geography
North America
- The U.S.
- Canada
- Mexico
Europe
- France
- The UK
- Spain
- Germany
- Italy
- Rest of Europe
Asia Pacific
- China
- Japan
- India
- Australia
- South Korea
- Rest of Asia Pacific
The Middle East & Africa
- Saudi Arabia
- UAE
- Egypt
- Kuwait
- South Africa
- Rest of the Middle East & Africa
Latin America
- Brazil
- Argentina
- Rest of Latin America
Table of Contents
- Chapter 1. Preface
- 1.1 Report Description and Scope
- 1.2 Research scope
- 1.3 Research methodology
- 1.3.1 Market Research Type
- 1.3.2 Market research methodology
- Chapter 2. Executive Summary
- 2.1 Global Open-Source Intelligence Market, (2022 – 2030) (USD Billion)
- 2.2 Global Open-Source Intelligence Market: snapshot
- Chapter 3. Global Open-Source Intelligence Market – Industry Analysis
- 3.1 Open-Source Intelligence Market: Market Dynamics
- 3.2 Market Drivers
- 3.2.1 Growing need for data prevention
- 3.2.2 Driver 2
- 3.3 Market Restraints
- 3.4 Market Opportunities
- 3.5 Market Challenges
- 3.6 Porter’s Five Forces Analysis
- 3.7 Market Attractiveness Analysis
- 3.7.1 Market attractiveness analysis By Technique
- 3.7.2 Market attractiveness analysis By End User
- Chapter 4. Global Open-Source Intelligence Market- Competitive Landscape
- 4.1 Company market share analysis
- 4.1.1 Global Open-Source Intelligence Market: company market share, 2021
- 4.2 Strategic development
- 4.2.1 Acquisitions & mergers
- 4.2.2 New Product launches
- 4.2.3 Agreements, partnerships, collaborations, and joint ventures
- 4.2.4 Research and development and Regional expansion
- 4.3 Price trend analysis
- 4.1 Company market share analysis
- Chapter 5. Global Open-Source Intelligence Market – Technique Analysis
- 5.1 Global Open-Source Intelligence Market overview: By Technique
- 5.1.1 Global Open-Source Intelligence Market share, By Technique, 2021 and 2030
- 5.2 Text Analytics
- 5.2.1 Global Open-Source Intelligence Market by Text Analytics, 2022 – 2030 (USD Billion)
- 5.3 Social Media Analytics
- 5.3.1 Global Open-Source Intelligence Market by Social Media Analytics, 2022 – 2030 (USD Billion)
- 5.4 Video Analytics
- 5.4.1 Global Open-Source Intelligence Market by Video Analytics, 2022 – 2030 (USD Billion)
- 5.5 Security Analytics
- 5.5.1 Global Open-Source Intelligence Market by Security Analytics, 2022 – 2030 (USD Billion)
- 5.6 Geospatial Analytics
- 5.6.1 Global Open-Source Intelligence Market by Geospatial Analytics, 2022 – 2030 (USD Billion)
- 5.7 Others
- 5.7.1 Global Open-Source Intelligence Market by Others, 2022 – 2030 (USD Billion)
- 5.1 Global Open-Source Intelligence Market overview: By Technique
- Chapter 6. Global Open-Source Intelligence Market – End User Analysis
- 6.1 Global Open-Source Intelligence Market overview: By End User
- 6.1.1 Global Open-Source Intelligence Market share, By End User, 2021 and 2030
- 6.2 Law Enforcement Agencies
- 6.2.1 Global Open-Source Intelligence Market by Law Enforcement Agencies, 2022 – 2030 (USD Billion)
- 6.3 Government Intelligence Agencies
- 6.3.1 Global Open-Source Intelligence Market by Government Intelligence Agencies, 2022 – 2030 (USD Billion)
- 6.4 Military & Defense Intelligence Agencies
- 6.4.1 Global Open-Source Intelligence Market by Military & Defense Intelligence Agencies, 2022 – 2030 (USD Billion)
- 6.5 Financial Services
- 6.5.1 Global Open-Source Intelligence Market by Financial Services, 2022 – 2030 (USD Billion)
- 6.6 Cyber Security Organizations
- 6.6.1 Global Open-Source Intelligence Market by Cyber Security Organizations, 2022 – 2030 (USD Billion)
- 6.7 Private Specialized Business
- 6.7.1 Global Open-Source Intelligence Market by Private Specialized Business, 2022 – 2030 (USD Billion)
- 6.8 Others
- 6.8.1 Global Open-Source Intelligence Market by Others, 2022 – 2030 (USD Billion)
- 6.1 Global Open-Source Intelligence Market overview: By End User
- Chapter 7. Open-Source Intelligence Market – Regional Analysis
- 7.1 Global Open-Source Intelligence Market Regional Overview
- 7.2 Global Open-Source Intelligence Market Share, by Region, 2021 & 2030 (USD Billion)
- 7.3. North America
- 7.3.1 North America Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.3.1.1 North America Open-Source Intelligence Market, by Country, 2022 – 2030 (USD Billion)
- 7.3.1 North America Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.4 North America Open-Source Intelligence Market, by Technique, 2022 – 2030
- 7.4.1 North America Open-Source Intelligence Market, by Technique, 2022 – 2030 (USD Billion)
- 7.5 North America Open-Source Intelligence Market, by End User, 2022 – 2030
- 7.5.1 North America Open-Source Intelligence Market, by End User, 2022 – 2030 (USD Billion)
- 7.6. Europe
- 7.6.1 Europe Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.6.1.1 Europe Open-Source Intelligence Market, by Country, 2022 – 2030 (USD Billion)
- 7.6.1 Europe Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.7 Europe Open-Source Intelligence Market, by Technique, 2022 – 2030
- 7.7.1 Europe Open-Source Intelligence Market, by Technique, 2022 – 2030 (USD Billion)
- 7.8 Europe Open-Source Intelligence Market, by End User, 2022 – 2030
- 7.8.1 Europe Open-Source Intelligence Market, by End User, 2022 – 2030 (USD Billion)
- 7.9. Asia Pacific
- 7.9.1 Asia Pacific Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.9.1.1 Asia Pacific Open-Source Intelligence Market, by Country, 2022 – 2030 (USD Billion)
- 7.9.1 Asia Pacific Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.10 Asia Pacific Open-Source Intelligence Market, by Technique, 2022 – 2030
- 7.10.1 Asia Pacific Open-Source Intelligence Market, by Technique, 2022 – 2030 (USD Billion)
- 7.11 Asia Pacific Open-Source Intelligence Market, by End User, 2022 – 2030
- 7.11.1 Asia Pacific Open-Source Intelligence Market, by End User, 2022 – 2030 (USD Billion)
- 7.12. Latin America
- 7.12.1 Latin America Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.12.1.1 Latin America Open-Source Intelligence Market, by Country, 2022 – 2030 (USD Billion)
- 7.12.1 Latin America Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.13 Latin America Open-Source Intelligence Market, by Technique, 2022 – 2030
- 7.13.1 Latin America Open-Source Intelligence Market, by Technique, 2022 – 2030 (USD Billion)
- 7.14 Latin America Open-Source Intelligence Market, by End User, 2022 – 2030
- 7.14.1 Latin America Open-Source Intelligence Market, by End User, 2022 – 2030 (USD Billion)
- 7.15. The Middle-East and Africa
- 7.15.1 The Middle-East and Africa Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.15.1.1 The Middle-East and Africa Open-Source Intelligence Market, by Country, 2022 – 2030 (USD Billion)
- 7.15.1 The Middle-East and Africa Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 7.16 The Middle-East and Africa Open-Source Intelligence Market, by Technique, 2022 – 2030
- 7.16.1 The Middle-East and Africa Open-Source Intelligence Market, by Technique, 2022 – 2030 (USD Billion)
- 7.17 The Middle-East and Africa Open-Source Intelligence Market, by End User, 2022 – 2030
- 7.17.1 The Middle-East and Africa Open-Source Intelligence Market, by End User, 2022 – 2030 (USD Billion)
- Chapter 8. Company Profiles
- 8.1 Alfresco Software Inc.
- 8.1.1 Overview
- 8.1.2 Financials
- 8.1.3 Product Portfolio
- 8.1.4 Business Strategy
- 8.1.5 Recent Developments
- 8.2 Siemens AG
- 8.2.1 Overview
- 8.2.2 Financials
- 8.2.3 Product Portfolio
- 8.2.4 Business Strategy
- 8.2.5 Recent Developments
- 8.3 Maltego Technologies
- 8.3.1 Overview
- 8.3.2 Financials
- 8.3.3 Product Portfolio
- 8.3.4 Business Strategy
- 8.3.5 Recent Developments
- 8.4 Expert System S.p.A.
- 8.4.1 Overview
- 8.4.2 Financials
- 8.4.3 Product Portfolio
- 8.4.4 Business Strategy
- 8.4.5 Recent Developments
- 8.5 Google LLC
- 8.5.1 Overview
- 8.5.2 Financials
- 8.5.3 Product Portfolio
- 8.5.4 Business Strategy
- 8.5.5 Recent Developments
- 8.6 IPS S.p.A.
- 8.6.1 Overview
- 8.6.2 Financials
- 8.6.3 Product Portfolio
- 8.6.4 Business Strategy
- 8.6.5 Recent Developments
- 8.7 Digital Clues
- 8.7.1 Overview
- 8.7.2 Financials
- 8.7.3 Product Portfolio
- 8.7.4 Business Strategy
- 8.7.5 Recent Developments
- 8.8 NetSentries Technologies FZCO
- 8.8.1 Overview
- 8.8.2 Financials
- 8.8.3 Product Portfolio
- 8.8.4 Business Strategy
- 8.8.5 Recent Developments
- 8.9 Recorded Future Inc.
- 8.9.1 Overview
- 8.9.2 Financials
- 8.9.3 Product Portfolio
- 8.9.4 Business Strategy
- 8.9.5 Recent Developments
- 8.10 Palantir Technologies
- 8.10.1 Overview
- 8.10.2 Financials
- 8.10.3 Product Portfolio
- 8.10.4 Business Strategy
- 8.10.5 Recent Developments
- 8.11 Thales Group
- 8.11.1 Overview
- 8.11.2 Financials
- 8.11.3 Product Portfolio
- 8.11.4 Business Strategy
- 8.11.5 Recent Developments
- 8.1 Alfresco Software Inc.
List Of Figures
- 1. Market research Type
- 2. Market research methodology
- 3. Global Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 4. Porter’s Five Forces Analysis
- 5. Global Open-Source Intelligence Market Attractiveness, By Technique
- 6. Global Open-Source Intelligence Market attractiveness, By End User
- 7. Global Open-Source Intelligence Market share by Technique, 2022 and 2030 (USD Billion)
- 8. Global Open-Source Intelligence Market by Text Analytics, 2022 – 2030 (USD Billion)
- 9. Global Open-Source Intelligence Market by Social Media Analytics, 2022 – 2030 (USD Billion)
- 10. Global Open-Source Intelligence Market by Video Analytics, 2022 – 2030 (USD Billion)
- 11. Global Open-Source Intelligence Market by Security Analytics, 2022 – 2030 (USD Billion)
- 12. Global Open-Source Intelligence Market by Geospatial Analytics, 2022 – 2030 (USD Billion)
- 13. Global Open-Source Intelligence Market by Others, 2022 – 2030 (USD Billion)
- 14. Global Open-Source Intelligence Market share by End User, 2022 and 2030 (USD Billion)
- 15. Global Open-Source Intelligence Market by Law Enforcement Agencies, 2022 – 2030 (USD Billion)
- 16. Global Open-Source Intelligence Market by Government Intelligence Agencies, 2022 – 2030 (USD Billion)
- 17. Global Open-Source Intelligence Market by Military & Defense Intelligence Agencies, 2022 – 2030 (USD Billion)
- 18. Global Open-Source Intelligence Market by Financial Services, 2022 – 2030 (USD Billion)
- 19. Global Open-Source Intelligence Market by Cyber Security Organizations, 2022 – 2030 (USD Billion)
- 20. Global Open-Source Intelligence Market by Private Specialized Business, 2022 – 2030 (USD Billion)
- 21. Global Open-Source Intelligence Market by Others, 2022 – 2030 (USD Billion)
- 22. Global Open-Source Intelligence Market share, by Region, 2022 and 2030
- 23. North America Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 24. Europe Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 25. Asia Pacific Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 26. Latin America Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
- 27. The Middle-East and Africa Open-Source Intelligence Market, 2022 – 2030 (USD Billion)
List Of Tables
- 1. Global Open-Source Intelligence Market: Snapshot
- 2. Drivers of the Open-Source Intelligence Market: impact analysis
- 3. North America Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 4. North America Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 5. U.S. Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 6. U.S. Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 7. Canada Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 8. Canada Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 9. Europe Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 10. Europe Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 11. Germany Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 12. Germany Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 13. France Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 14. France Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 15. U.K. Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 16. U.K. Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 17. Italy Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 18. Italy Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 19. Spain Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 20. Spain Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 21. Rest of Europe Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 22. Rest of Europe Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 23. Asia Pacific Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 24. Asia Pacific Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 25. China Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 26. China Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 27. Japan Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 28. Japan Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 29. India Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 30. India Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 31. South Korea Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 32. South Korea Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 33. South-East Asia Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 34. South-East Asia Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 35. Rest of Asia Pacific Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 36. Rest of Asia Pacific Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 37. Latin America Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 38. Latin America Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 39. Brazil Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 40. Brazil Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 41. Mexico Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 42. Mexico Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 43. Rest of Latin America Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 44. Rest of Latin America Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 45. The Middle-East and Africa Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 46. The Middle-East and Africa Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 47. GCC Countries Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 48. GCC Countries Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 49. South Africa Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 50. South Africa Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
- 51. Rest of Middle-East Africa Open-Source Intelligence Market Revenue, By Technique, 2022 – 2030 (USD Billion)
- 52. Rest of Middle-East Africa Open-Source Intelligence Market Revenue, By End User, 2022 – 2030 (USD Billion)
Report Methodology
In order to get the most precise estimates and forecasts possible, Custom Market Insights applies a detailed and adaptive research methodology centered on reducing deviations. For segregating and assessing quantitative aspects of the market, the company uses a combination of top-down and bottom-up approaches. Furthermore, data triangulation, which examines the market from three different aspects, is a recurring theme in all of our research reports. The following are critical components of the methodology used in all of our studies:
Preliminary Data Mining
On a broad scale, raw market information is retrieved and compiled. Data is constantly screened to make sure that only substantiated and verified sources are taken into account. Furthermore, data is mined from a plethora of reports in our archive and also a number of reputed & reliable paid databases. To gain a detailed understanding of the business, it is necessary to know the entire product life cycle and to facilitate this, we gather data from different suppliers, distributors, and buyers.
Surveys, technological conferences, and trade magazines are used to identify technical issues and trends. Technical data is also gathered from the standpoint of intellectual property, with a focus on freedom of movement and white space. The dynamics of the industry in terms of drivers, restraints, and valuation trends are also gathered. As a result, the content created contains a diverse range of original data, which is then cross-validated and verified with published sources.
Statistical Model
Simulation models are used to generate our business estimates and forecasts. For each study, a one-of-a-kind model is created. Data gathered for market dynamics, the digital landscape, development services, and valuation patterns are fed into the prototype and analyzed concurrently. These factors are compared, and their effect over the projected timeline is quantified using correlation, regression, and statistical modeling. Market forecasting is accomplished through the use of a combination of economic techniques, technical analysis, industry experience, and domain knowledge.
Short-term forecasting is typically done with econometric models, while long-term forecasting is done with technological market models. These are based on a synthesis of the technological environment, legal frameworks, economic outlook, and business regulations. Bottom-up market evaluation is favored, with crucial regional markets reviewed as distinct entities and data integration to acquire worldwide estimates. This is essential for gaining a thorough knowledge of the industry and ensuring that errors are kept to a minimum.
Some of the variables taken into account for forecasting are as follows:
• Industry drivers and constraints, as well as their current and projected impact
• The raw material case, as well as supply-versus-price trends
• Current volume and projected volume growth through 2030
We allocate weights to these variables and use weighted average analysis to determine the estimated market growth rate.
Primary Validation
This is the final step in our report’s estimating and forecasting process. Extensive primary interviews are carried out, both in-person and over the phone, to validate our findings and the assumptions that led to them.
Leading companies from across the supply chain, including suppliers, technology companies, subject matter experts, and buyers, use techniques like interviewing to ensure a comprehensive and non-biased overview of the business. These interviews are conducted all over the world, with the help of local staff and translators, to overcome language barriers.
Primary interviews not only aid with data validation, but also offer additional important insight into the industry, existing business scenario, and future projections, thereby improving the quality of our reports.
All of our estimates and forecasts are validated through extensive research work with key industry participants (KIPs), which typically include:
• Market leaders
• Suppliers of raw materials
• Suppliers of raw materials
• Buyers.
The following are the primary research objectives:
• To ensure the accuracy and acceptability of our data.
• Gaining an understanding of the current market and future projections.
Data Collection Matrix
|Perspective||Primary research||Secondary research|
|Supply-side||
||
|
|Demand-side||
||
|
Market Analysis Matrix
|Qualitative analysis||Quantitative analysis|
|
||
|
List of the prominent players in the global Open-Source Intelligence market:
- Alfresco Software, Inc.
- Siemens AG
- Maltego Technologies
- Expert System S.p.A.
- Google LLC
- IPS S.p.A.
- Digital Clues
- NetSentries Technologies FZCO
- Recorded Future, Inc.
- Palantir Technologies
- Thales Group
FAQs
“North America” region will lead the global Open-Source Intelligence market during the forecast period 2022 to 2030.
All businesses and individuals throughout the world value data security. Several countries and organizations are implementing strict data protection policies. General Data Protection Regulation in Europe and Australian Privacy Principles (APP) in Australia are examples. Such activities drive the demand for data protection, boosting Open-Source Intelligence acceptance among intelligence agencies.
The key players operating in the Open-Source Intelligence market are Alfresco Software, Inc., Siemens AG, Maltego Technologies, Expert System S.p.A., Google LLC, IPS S.p.A., Digital Clues, NetSentries Technologies FZCO, Recorded Future, Inc., Palantir Technologies, Thales Group, and Others.
The global Open-Source Intelligence market is expanding growth with a CAGR of approximately 28.33% during the forecast period (2022 to 2030).
The global Open-Source Intelligence market size was valued at USD 5,449.23 Million in 2021 and it is projected to reach around USD 36,241.24 Million by 2030.",5
366,"A cross-kingdom partnership between bacteria and fungi can result in the two joining to form a “superorganism” with unusual strength and resilience. It may sound like the stuff of science fiction, but these microbial groupings are very much part of the here and now.
Found in the saliva of toddlers with severe childhood tooth decay, these assemblages can effectively colonize teeth. They were stickier, more resistant to antimicrobials, and more difficult to remove from teeth than either the bacteria or the fungi alone, according to the research team, led by University of Pennsylvania School of Dental Medicine scientists.
What’s more, the assemblages unexpectedly sprout “limbs” that propel them to “walk” and “leap” to quickly spread on the tooth surface, despite each microbe on its own being non-motile, the team reported in the journal Proceedings of the National Academy of Sciences.
“This started with a very simple, almost accidental discovery, while looking at saliva samples from toddlers who develop aggressive tooth decay,” says Hyun (Michel) Koo, a professor at Penn Dental Medicine and a co-corresponding author on the paper. “Looking under the microscope, we noticed the bacteria and fungi forming these assemblages and developing motions we never thought they would possess: a ‘walking-like’ and ‘leaping-like’ mobility. They have a lot of what we call ‘emergent functions’ that bring new benefits to this assemblage that they could not achieve on their own. It’s almost like a new organism—a superorganism—with new functions.”
Better (or worse) together
In the past, Koo’s lab has focused on the dental biofilm, or plaque, present in children with severe tooth decay, discovering that both bacteria—Streptococcus mutans—and fungi—Candida albicans—contribute to the disease. Caries, commonly known as cavities, arise when sugars in the diet linger to feed bacteria and fungi in the mouth, leading to acid-producing dental plaque that destroys enamel.
The new set of discoveries came about when Zhi Ren, a postdoctoral fellow in Koo’s group, was using microscopy that allows scientists to visualize the behavior of living microbes in real time. The technique “opens new possibilities to investigate the dynamics of complex biological processes,” says Ren, a first author on the paper and part of the first cohort of the NIDCR T90R90 postdoctoral training program within Penn’s Center for Innovation & Precision Dentistry.
After seeing the bacterial-fungal clusters present in the saliva samples, Ren, Koo, and colleagues were curious how the groupings might behave once attached to the surface of a tooth. Thus began a series of experiments using real-time live microscopy to observe the process of attachment and eventual growth.
They created a laboratory system to recreate the formation of these assemblages, using the bacteria, fungi, and a tooth-like material, all incubated in human saliva. The platform enabled the researchers to watch the groupings come together and to analyze the structure of the resulting assemblages. They found a highly organized structure with bacterial clusters attached in a complex network of fungal yeast and filament-like projections called hyphae, all enmeshed in an extracellular polymer, a glue-like material.
Next the team tested the properties of these cross-kingdom assemblages once they had colonized the tooth surface and found “surprising behaviors and emergent properties,” says Ren, “including enhanced surface adhesion, making them very sticky, and increased mechanical and antimicrobial tolerance, making them tough to remove or kill.”
Perhaps the most intriguing characteristic of the assemblages, the researchers say, was their mobility. “They displayed ‘leaping-like’ and ‘walking-like’ motions while continuously growing,” Ren says.
While some bacteria can propel themselves using appendages like flagella, the microbial species in the current study are both non-motile. And differing from any known microbial motility, the assemblages used the fungal hyphae to anchor on the surface and then propel the whole superorganism forward, transporting the attached bacteria across the surface, Koo says, “like bacteria hitchhiking on the fungi.”
The microbial groupings moved fast and far, the researchers found. On the tooth-like surface, the team measured velocities of more than 40 microns per hour, similar to the speed of fibroblasts, a type of cell in the human body involved in wound healing. Within the first hours of growth, the scientists observed the assemblages “leaping” more than 100 microns across the surface. “That is more than 200 times their own body length,” says Ren, “making them even better than most vertebrates, relative to body size. For example, tree frogs and grasshoppers can leap forward about 50 times and 20 times their own body length, respectively.”
Although the exact mechanisms are unknown, the assemblages’ ability to “move as they grow,” the researchers say, has one clear consequence: It enables them to quickly colonize and spread to new surfaces. When the research team allowed the assemblages to attach to and grow on real human teeth in a laboratory model, they found more extensive tooth decay as a result of a rapidly spreading biofilm.
Disease treatment and biology at large
Because these assemblages are found in saliva, targeting them early on could be a therapeutic strategy to prevent childhood tooth decay, says Koo. “If you block this binding or disrupt the assemblage before it arrives on the tooth and causes damage, that could be a preventive strategy.”
And beyond the applications for treating this specific disease, the researchers say, the new findings might be applicable in microbial biology in general. For example, aggregated organisms found in other biological fluids or aquatic ecosystems may similarly enhance surface colonization and growth to cause infectious diseases or environmental contamination.
“We saw that these two distinct organisms assemble together as a new organismal entity that gave each one additional benefits and functions that single cells did not have on their own,” says Koo. The findings could even shed light on the evolution of mutualism and multicellularity that enhances the survival and grow of single organisms when they unite and work together as a unit in a given environment, the team notes.
“This discovery of a ‘bad guy’ superorganism is really ground-breaking and unanticipated,” says Knut Drescher of the University of Basel, a co-corresponding author on the paper. “No one would have predicted this. Zhi accidentally stumbled across this by keeping an open mind.”
Hyun (Michel) Koo is a professor in the Department of Orthodontics and the divisions of Community Oral Health and Pediatric Dentistry in the School of Dental Medicine, and co-founder of the Center for Innovation & Precision Dentistry (CiPD) at the University of Pennsylvania.
Zhi Ren is a fellow in the National Institute of Dental and Craniofacial Research T90/R90 postdoctoral training program Advanced Training at the Interface of Engineering & Oral-Craniofacial Sciences within CiPD at Penn’s School of Dental Medicine and School of Engineering & Applied Science. Ren was also a Colgate-Palmolive Pediatric Dentistry Fellow (2019-21).
Knut Drescher is an associate professor at the University of Basel’s Biozentrum in Switzerland.
Koo and Ren’s coauthors on the paper were Penn Dental Medicine’s Aurea Simon-Soro, Zhenting Xiang, Yuan Liu, and Indira M. Cavalcanti; Philipps-Universität Marburg’s Hannah Jeckel; the University of Rochester Medical Center’s Jin Xiao; Indiana University’s Nyi-Nyi Tin and Anderson Hara; and the University of Basel’s Knut Drescher. Ren and Jeckel shared first authorship, and Drescher and Koo were co-corresponding authors.
This work was supported in part by the National Institute for Dental and Craniofacial Research (grants DE025220 and DE031532), the Budesministerium für Bildung und Forschung (Grant TARGET-Biofilm), and the European Research Council (Grant 716743).",2
367,"L'empire des algorithmes -
Existe au format livre et ebook
Présentation du livre
Si le numérique est en général considéré sous l’angle de la technologie, les technologies sont en fait peu de choses au regard des transformations qu’il induit aux niveaux social, économique et politique. Le numérique bouleverse la structure même des sociétés, modifie radicalement les échanges d’informations et permet de contrôler en temps réel une partie croissante des acteurs, humains ou environnementaux, biologiques ou technologiques. En modifiant les rapports de pouvoir, il fait émerger de nouvelles forces et oblige la puissance publique à se repositionner. L’établissement de la vérité et l’organisation politique sont à reconstruire, à un moment où la puissance des algorithmes rend obsolète une part importante de l’activité humaine.
Pour autant le numérique n’étend pas son emprise sur une société à peu près stable par ailleurs. Il affecte une société qui se situe à l’aube d’un immense changement, celui de l’adaptation à une nouvelle donne environnementale. Il est donc illusoire de le penser hors de cette dynamique, qui est celle de l’anthropocène. La contemporanéité entre la révolution numérique et le bouleversement de l’écosystème est remarquable, et s’inscrit dans la grande accélération que l’ensemble des phénomènes humains comme environnementaux connaissent depuis les années 1950.
Une analyse remarquable de la manière dont le numérique modifie les rapports entre les nations et oriente les sociétés dans l’adaptation aux changements écosystémiques.
Sommaire de l'ouvrage
1. La singularité du monde
2. L’appropriation de la datasphère
3. Le triomphe des algorithmes
4. Les plateformes d’intermédiation
5. Le plongement du monde dans le cyberespace
6. La production du savoir et de la vérité
7. Pouvoir, souveraineté et légitimité
8. La gouvernance de l’écosystème",0
368,"The mayor of an Italian town has banned hairdressers and barbers from shampooing their customers’ hair twice in an attempt to conserve water during one of the most severe droughts in decades.
Carlo Gubellini, the mayor of Castenaso, near Bologna in the Emilia-Romagna region, said thousands of litres of water was squandered each day through double-shampooing, which many hairdressers believe is beneficial, and hence double-rinsing.
He is believed to be the only mayor in Italy to take such a measure, which will involve checks and fines of up to €500 for salons breaking the rule, as Italy fights drought during an intense, protracted heatwave.
Castenaso, which has a population of 16,000, is home to 10 hairdressers and barber shops.
“If we multiply the amount of water used for each customer, we are talking about thousands of litres a day,” Gubellini told Corriere della Sera. “Castenaso is small: imagine what it means in terms of water consumption in large cities. We issued the order on Saturday, considering hairdressers are closed on Sundays and Mondays, to give them plenty of time to adapt.”
A handbook accompanying the measure’s guidelines states that 13 litres of water a minute flows from an open tap, and that at least 20 litres is required to rinse someone’s hair twice.
Gubellini said the rule, in place until late September, had gone down well. “The feedback has been positive,” he said. “This ordinance does not have an oppressive purpose, but rather one of empowering citizens.”
However, as the salons of Castenaso reopened on Tuesday morning, some were not so impressed.
“It seems a bit ridiculous,” said Katia, who works at Nuova Equipe hairdressers. “It’s difficult not to be able to wash and rinse twice, as some of the products we use requires it, and also types of hair, especially if the customer’s hair is quite dirty.”
Gubellini said he hoped to be able to tweak the measure before it expired but emphasised that the situation was “really alarming”.
“Emilia-Romagna has enough water reserves necessary for farmland until 29 June, then from July things could get drastically worse,” he said.
Mayors of other Italian towns and cities have also imposed water-rationing measures, including Milan, where public fountains have been turned off. Regions in northern Italy are suffering the most owing to a prolonged drought of Italy’s longest river, the Po, after scant rain and snowfall this winter.",2
369,"La disposition devrait stimuler le développement de la production d’énergie solaire en France, notamment dans les grandes zones commerciales. Selon le gouvernement, le potentiel de la mesure pourrait atteindre jusqu’à 11 gigawatts, soit l’équivalent de la puissance d’une dizaine de réacteurs nucléaires. L’article 11 du projet de loi relatif à l’accélération des énergies renouvelables a été adopté par le Sénat ce 4 novembre en première lecture. Il impose l’équipement progressif des plus grands parkings extérieurs en ombrières recouvertes de panneaux photovoltaïque (ou un autre procédé d’énergie renouvelable), sur au moins la moitié de leur surface.
Initialement, le projet de loi s’appliquait aux parkings de plus de 2 500 mètres carrés. En commission, les sénateurs ont préféré définir un seuil en nombre de places plutôt qu’en superficie. Seront donc concernés les parkings de plus de 80 places, un seuil qui englobe davantage de parcs de stationnement puisque 2 500 mètres carrés équivalaient à une centaine d’emplacements. Pour le rapporteur (LR) Didier Mandelli, ce concept a le mérite de la clarté et surtout, d’être « moins sujet à débat », notamment sur les parties d’un parking à exclure de tout aménagement.
« Il est plus facile de compter des mètres carrés que de compter des places »
Le groupe communiste a tenté en vain de revenir au système métrique, arguant que les places pouvaient avoir des tailles variables. Ce point de vue était partagé par le gouvernement. « Il est clair qu’il est plus facile de compter des mètres carrés que de compter des places », a plaidé la ministre de la Transition énergétique, Agnès Pannier-Runacher, déplorant la « sophistication » de la rédaction sénatoriale.
Les obligations de l’article n’auraient pas à s’imposer en cas de contraintes techniques, sécuritaires, architecturales ou patrimoniales. Les dispositions entreront en vigueur au 1er juillet 2023, de façon progressive, en fonction de la taille des parkings. Les parkings de plus de 400 places devront être mis en conformité dans un délai de trois ans à compter de cette date, cinq ans si le nombre est compris entre 80 et 400.
Lors de l’examen en séance, le Sénat a ajouté de nouvelles exclusions. Des amendements de Nathalie Delattre (RDSE) et du centriste Stéphane Demilly excluent explicitement les parkings de poids lourds (de plus de 7,5 tonnes) du champ de l’obligation. L’obligation ne sera pas non plus valable pour les aires de stationnement à proximité de sites remarquables – qu’ils soient classés zones protégées ou non – pour éviter de les « dénaturer », selon l’amendement défendu par Cédric Vial (LR) et plusieurs de ses collègues. Le gouvernement s’est dit favorable à cette modification.
L’hémicycle supprime le délai supplémentaire accordé en cas de difficultés d’approvisionnement en panneaux
L’hémicycle a surtout adopté un amendement du groupe socialiste, supprimant la possibilité d’accorder un délai supplémentaire aux gestionnaires de parking en cas de difficulté d’approvisionnements en panneaux photovoltaïques. Cette disposition avait été introduite lors des débats en commission, le rapporteur Didier Mandelli parlant d’un « apport de bon sens ». À l’inverse, Jean-Michel Houllegatte (PS) a dénoncé une modification « un peu défaitiste », qui revient à « battre en retraite ». Le gouvernement a lui-même soutenu l’amendement des socialistes, bien qu’il ait reconnu que le développement d’une filière française et européenne prendrait du temps. « Néanmoins, dans l’attente, il ne faut pas retarder la mise en œuvre de la décarbonation de notre économie », a encouragé Agnès Pannier-Runacher. La tournure du débat a fait réagir à droite, qui s’est retrouvée en minorité. « On souhaiterait qu’on puisse se donner des moyens, plutôt que des incantations, pour y arriver », a rétorqué le sénateur LR Cédric Vial.
L’un de ses collègues, Rémy Pointereau, a considéré que cet article du projet de loi allait bénéficier dans l’immédiat à des lignes de production situées hors Union européenne. « J’ai l’impression que toute l’Asie, et en particulier la Chine, doit se réjouir ce matin de voir qu’on va mettre peut-être des milliers d’hectares de panneaux photovoltaïques, qui vont être produits en Chine, en Malaisie, aux Philippines. Notre balance commerciale va encore prendre un sacré coup ! »
Peu convaincu par cet argument, l’écologiste Ronan Dantec a répondu : « J’ai un peu le sentiment, par moments, qu’on cherche à peu près tous les arguments possibles et imaginables contre le développement des énergies renouvelables dans notre pays […] J’espère que personne à Noël n’achètera des jouets faits en Chine ! »
Le niveau des sanctions a été fortement durci en séance
Le sénateur de Loire-Atlantique a d’ailleurs réussi à convaincre une majorité dans l’hémicycle pour alourdir les sanctions en cas de non mise en conformité d’un parking. Le texte sorti de la commission de l’aménagement et du développement durable prévoyait la possibilité pour l’autorité administrative de prononcer une sanction maximale de 10 000 euros par an, jusqu’à la mise en conformité. Or, cette sanction n’aurait pas été suffisamment incitative selon Ronan Dantec : 2,5 % seulement du coût d’une installation en panneaux pour un parking de 80 places (400 000 euros).
Le texte adopté prévoit désormais une sanction mensuelle, et non plus annuelle, basée sur le nombre de places équipées (50 euros par emplacement). Ainsi un parc de 80 places qui ne respecterait pas la nouvelle législation s’exposerait à 48 000 euros de pénalités chaque année. La commission a émis un avis favorable et le gouvernement un avis de sagesse, ce qui laisse de bonnes chances à cette modification de survivre dans la navette parlementaire.",0
370,"a stroke of genius: striving for greatness in all you do by R.W. Hamming
Little has been written on managing your own research (and very little on avoiding other people managing your research); however, your research is much more under your control than you may realize.
We are concerned with great research here. Work that will get wide recognition, perhaps even wine Nobel Prize. As most people realize, the average published paper is read by the author, the referee, and perhaps one other person. Classic papers are read by thousands. We are concerned with research that will matter in the long run and become more than a footnote in history.
If you are to do important work then you must work on the right problem at the right time and in the right way. Without any one of the three, you may do good work but you will almost certainly miss real greatness.
Greatness is a matter of style. For example, after learning the elements of painting, you study under a master. While studying you pay attention to what the master says in discussing your work, but you know that if you are to achieve greatness then you must find your own style. Furthermore, a successful style in one age is not necessarily appropriate for another age. Cubism would not have gone over big during the realism period.
Similarly, there is no simple formula for doing great science or engineering, I can only talk around the topic. The topic is important because, so far as we have any solid evidence, you have but one life to live. Under these circumstances it seems better to live a life in which you do important things (important in your eyes, of course) than to merely live out your life. No sense frittering away your life on things that will not even appear in the footnotes.
I begin with the choice of problem. Most scientists spend almost all of their time working on problems that even they admit are neither great or are likely to lead to great work; hence, almost surely, they will not do important work. Note that importance of the results of a solution does not make the problem important. In all the 30 years I spent at Bell Telephone Laboratories (before it was broken up) no one to my knowledge worked on time travel, teleportation, or anti-gravity. Why? Because they had no attack on the problem. Thus an important aspect of any problem is that you have a good attack, a good starting place, some reasonable idea of how to begin.
To illustrate, consider my experience at BTL. For the first few years I ate lunch with he mathematicians. I soon found that they were more interested in fun and games than in serious work, so I shifted to eating with the physics table. There I stayed for a number of years until the Nobel Prize, promotions, and offers from other companies, removed most of the interesting people. So I shifted to the corresponding chemistry table where I had a friend.
At first I asked what were the important problems in chemistry, then what important problems they were working on, or problems that might lead to important results. One day I asked, ""if what they were working on was not important, and was not likely to lead to important things, they why were they working on them?"" After that I had to eat with the engineers!
About four months later, my friend stopped me in the hall and remarked that my question had bothered him. He had spent the summer thinking about the important problems in his area, and while had had not changed his research he thought it was well worth the effort. I thanked him and kept walking. A few weeks later I noticed that he was made head of the department. Many years later he became a member of the National Academy of Engineering. The one person who could hear the question went on to do important things and all the others -- so far as I know -- did not do anything worth public attention.
There are many right problems, but very few people search carefully for them. Rather they simply drift along doing what comes to them, following the easiest path to tomorrow. Great scientists all spend a lot of time and effort in examining the important problems in their field. Many have a list of 10 to 20 problems that might be important if they had a decent attack. As a result, when they notice something new that they had not known but seems to be relevant, then they are prepared to turn to the corresponding problem, work on it, and get there first.
Some people work with their doors open in clear view of those who pass by, while others carefully protect themselves from interruptions. Those with the door open get less work done each day, but those with their door closed tend not know what to work on, nor are they apt to hear the clues to the missing piece to one of their ""list"" problems. I cannot prove that the open door produces the open mind, or the other way around. I only can observe the correlation. I suspect that each reinforces the other, that an open door will more likely lead you and important problems than will a closed door.
Hard work is a trait that most great scientists have. Edison said that genius was 99% perspiration and 1% inspiration. Newton said that if others would work as hard as he did then they would get similar results. Hard work is necessary but it is not sufficient. Most people do not work as hard as they easily could. However, many who do work hard -- work on the wrong problem, at the wrong time, in the wrong way, and have very little to show for it.
You are aware that frequently more than one person starts working on the same problem at about the same time. In biology, both Darwin and Wallace had the idea of evolution at about the same time. In the area of special relativity, many people besides Einstein were working on it, including Poincare. However, Einstein worked on the idea in the right way.
The first person to produce definitive results generally gets all the credit. Those who come in second are soon forgotten. Thus working on the problem at the right time is essential. Einstein tried to find a unified theory, spent most of his later life on it, and died in a hospital still working on it with no significant results. Apparently, he attacked the problem too early, or perhaps it was the wrong problem.
There are a pair of errors that are often made when working on what you think is the right problem at the right time. One is to give up too soon, and the other is to persist and never get any results. The second is quite common. Obviously, if you start on a wrong problem and refuse to give up, you are automatically condemned to waste the rest of your life (see Einstein above). Knowing when you persist is not easy -- if you are wrong then you are stubborn; but if you turn out to be right, then you are strong willed.
I now turn to the major excuse given for not working on important problems. People are always claiming that success is a matter of luck, but as Pasteur pointed out, ""Luck favors the prepared mind.""
A great deal of direct experience, vicarious experience through questioning others, and reading extensively, convinces me of the truth of his statement. Outstanding successes are too often done by the same people for it be a matter of random chance.
For example, when I first met Feynmann at Los Alamos during the WWII, I believed that he would get a Nobel Prize. His energy, his style, his abilities, all indicated that he was a person who would do many things, and probably at least one would be important. Einstein, around the age of 12 or 14, asked himself what a light wave would look like if he want at the speed of light. He knew that Maxwell's theory did not support a local, stationary maximum, but was what he ought to see if the current theory was correct. So it is not surprising that he later developed the special theory of relativity - he had prepared his mind for it long before.
Many times a discussion with a person who has just done something important will produce a description of how they were led, almost step by step, to the result. It is usually based on things they had done, or intensely thought about, years ago. You succeed because you have prepared yourself with the necessary background long ago, without, of course, knowing then that it would prove to be a necessary step to success.
There traits are not all essential, but tend to be present in most doers of great things in science. First, successful people exhibit more activity, more energy, than most people do. They look more places, they work harder, they think longer than less successful people. Knowledge and ability are much like compound interest -- the more you do the more you can do, and the more the opportunities are open for you. Thus, among other things, it was Feynmann's energy and his constantly trying new things that made one think he would succeed.
This trait must be coupled with emotional commitment. Perhaps the ablest mathematician I have watched up close seldom, if ever, seemed to care deeply about the problem he was working on. He has done great deal of first class work, but not of the highest quality. Deep emotional commitment seems to be necessary for success. The reason is obvious. The emotional commitment keeps you thinking about the problem morning, noon and night, and that tends to beat out mere ability.
While I was at Los Alamos after the war, I got to thinking about the famous Buffon needle problem where you can calculate the probability of a needle tossed at random of crossing one of a series of equally spaced parallel lines. I asked myself if it was essential that the needle be a straight line segment (if I counted multiple crossing)? No. Need the parallel lines be straight? No. Need they be equally spaced or is it only the average density of the lines on the plane? Is it surprising that some years later at Bell Labs when I was asked by some metallurgists how to measure the amount of grain boundary on some micro photographs I simply said, ""Count the crossings of a random line of fixed length on the picture?"" I was led to it by the previous, careful thought about an interesting, and I thought important, result in probability. The result is not great, but illustrates the mechanisms of preparation and emotional involvement.
The above story also illustrates what I call the ""extra mile."" I did more than the minimum, I looked deeper into the nature of the problem. This constant effort to understand more than the surface feature of a situation obviously prepares you to see new andslightlydifferent applications of your knowledge. You cannot do many problems such as the above needle problem before you stumble on an important application.
Courage is another attribute of those who do great things. Shannon is a good example. For some time he would come to work at about 10:00am, play chess until about 2:00pm and go home.
The important point is how he played chess. When attacked he seldom, if ever, defended his position, rather he attacked back. Such a method of playing soon produces a very interrelated board. He would then pause a bit, think and advance his queen saying, ""I ain't afraid of nothin'."" It took me a while to realize that of course that is why he was able to prove the existence of good coding methods. Who but Shannon would think to average over all random codes and expect to find that the average was close to ideal? I learned from him to say the same to myself when stuck, and on some occasions his approach enabled me to get significant results.
Without courage you are unlikely to attack important problems with any persistence, and hence not likely to do important things. Courage brings self-confidence, an essential feature of doing difficult things. However, it can border on over-confidence at time which is more of a hindrance than a help.
There is another trait that took me many years to notice, and that is the ability to tolerate ambiguity. Most people want to believe what they learn is the truth: there are a few people who doubt everything. If you believe too much then you are not likely to find the essentially new view that transforms a field, and if you doubt too much you will not be able to do much at all. It is a fine balance between believing what you learn and at the same time doubting things. Great steps forward usually involve a change of viewpoint to outside the standard ones in the field.
While you are leaning things you need to think about them and examine them from many sides. By connecting them in many ways with what you already know.... you can later retrieve them in unusual situations. It took me a long time to realize that each time I learned something I should put ""hooks"" on it. This is another face of the extra effort, the studying more deeply, the going the extra mile, that seems to be characteristic of great scientists.
The evidence is overwhelming that steps that transform a field often come from outsiders. In archaeology, carbon dating came from physics. The first airplane was built by the Wright brothers who were bicycle experts.
Thus, as an expert in your field, you face a difficult problem. There is, apparently, an ocean of kooks with their crazy ideas; however, if there is a great step forward it probably will be made by one of them! If you listen too much to them then you will not get any of your own work done, but if you ignore them then you may miss your great chance. I have no simple answer except do not dismiss the outsider too abruptly as is generally done by in the insiders.
""Brains"""" are nice to have, but often the top graduate students do not contribute as much as some lower rated ones. Brains come in all kinds of flavors. Experimental physicists do not think the same way as theoreticians do. Some experimentalists seem to think with their hands, i.e., playing with equipment lets them think more clearly. It took me a few years to realize that people who did not know a lot of mathematics still could contribute. Just because they could not solve a quadratic equation immediately in their head did not mean I should ignore them. When someone's flavor of brains does not match yours may be more reason for paying attention to them.
You need a vision of who you are and where your field is going. A suitable parable is that of the drunken sailor. He staggers one way and then the other with independent, random steps. In n steps he will be, on the average, about 3n steps away from where he started. but if there is a pretty girl in one direction he will get a distance proportional to n. The difference, over a life time of choices, between 3n and n is very large and represents the difference between having no vision and having a vision. The particular vision you have is less important than just having one - there are many paths to success. Therefore, it is wise to have a vision of what you may become, of where you want to go, as well as how to get there. No vision, not much chance of doing great work; with a vision you have a good chance.
Another topic I must discuss is that of age. Historically, the greatest contributions of mathematicians, theoretical physicists, and astrophysicists are done when they are very young. On the other hand, apparently in music composition, politics, and literature, the later works are most valued by society. Other areas seem to fall in between these extremes, and you need to realize that in some areas you had better get going promptly.
People often complain about the working conditions they have to put up with, but it is easily observed that some of the greatest work was done under unfavorable conditions. What most people believe is the best working conditions for them is seldom, if ever, true. In my opinion the Institute for Advanced Study in Princeton has ruined more good people than it has helped. You have only to judge their work before they were appointed and afterwards to come to this conclusion. There are exceptions, to be sure, but on the average the supposed ideal working conditions seem to sterilize people.
Another obvious trait of great people is that they do their work in such a fashion that others can build on top of it. Newton said, ""If I had seen farther than others it is because I stood on the shoulders of giants."" Too many people seem to not want others to build on top of their work but rather they want to hoard it to themselves. Don't do things in such a fashion that next time it must be repeated by you, or by others, but rather in a fashion that represents a significant step forward.
I must now take up the unpleasant topic of selling your ideas. Too many scientists think that this is beneath them, that the world is waiting for their great results. In truth, the other researchers are busy with their own work. You must present your results so that they will stop their own work and listen to you. Presentation comes in three forms: published papers, prepared talks, and impromptu situations. You must master all three forms.
Lots of good work has been lost because of poor presentation only to be rediscovered later by others. There is a real danger that you will not get credit for what you have done. I know of all too many times when the discoverer could not be bothered to present things clearly, and hence his or her work was of no importance to society.
Finally, I must at least address the question of whether greatness is worth the large effort it requires. Those who have done really great things generally report, privately, that it is better than wine, the opposite sex, and song put together. The realization that you have done it is overwhelming.
Of course I have consulted only those who did do great things, and have no dared to ask those who did not. Perhaps they would reply differently. But, as is often said, it is in the struggle and not the success that the real gain appears. In striving to do great things, you change yourself into a better person, so they claim. The actual success is of less importance, so they say. And I tend to believe this theory.
No one ever told me the kinds of things I have just related to you; I had to find them out for myself. Since I have now told you how to succeed, you have no excuse for not trying and doing great work in your chosen field.
Dr. Richard Hamming is best known for the Hamming code, Hamming distance and the Hamming spectral window along with numerical methods.",2
371,"Overview
This paper studies the art and science of creating adversarial attacks on object detectors. Most work on real-world adversarial attacks has focused on classifiers, which assign a holistic label to an entire image, rather than detectors which localize objects within an image. Detectors work by considering thousands of “priors” (potential bounding boxes) within the image with different locations, sizes, and aspect ratios. To fool an object detector, an adversarial example must fool every prior in the image, which is much more difficult than fooling the single output of a classifier.
In this work, we present a systematic study of adversarial attacks on state-of-the-art object detection frameworks. Using standard detection datasets, we train patterns that suppress the objectness scores produced by a range of commonly used detectors, and ensembles of detectors. Our ultimate goal is to build a wearable “invisibility” cloak that renders the wearer imperceptible to detectors.
Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors
This stylish pullover is a great way to stay warm this winter, whether in the office or on-the-go. It features a stay-dry microfleece lining, a modern fit, and adversarial patterns the evade most common object detectors. In this demonstration, the YOLOv2 detector is evaded using a pattern trained on the COCO dataset with a carefully constructed objective.
Video Demo
While a full-scale demo had been delayed due to COVID, here’s a short composite of some of our test footage.
Approach
We load images from the COCO detection dataset, and pass them through a detector. When a person is detected, and pattern is rendered over that person with random perspective, brightness, and contrast deformations. A gradient descent algorithm is then used to find the pattern that minimizes the “objectness scores” (confidence in the presence of an object) for every object prior.
Gallery
Thanks
Thanks to Facebook AI for their support on this project!",3
372,"Echopraxia (novel)
Jump to navigation Jump to search
|Author||Peter Watts|
|Cover artist||Richard Anderson|
|Country||Canada|
|Language||English|
|Genre||Science fiction|
|Publisher||Tor Books|
Publication date
|2014|
|Media type||Print (hardback)|
|Pages||383|
|ISBN||978-0765328038|
|OCLC||858730761|
|LC Class||PR9199.3.W386 E24 2014|
|Preceded by||Blindsight|
Echopraxia is a hard science fiction novel by Canadian writer Peter Watts.[1] It is a ""sidequel"" to his 2006 novel Blindsight. It follows the story of a biologist who gets caught up in a voyage into the heart of the Solar System among members of a transcendentalist monastic order and allies (including a vampire escaped from a research facility and her cadre of zombified soldiers) to investigate a mysterious signal seemingly coming from the mission sent to initiate first contact in Watts' previous novel. The cover art is by Richard Anderson.
The title refers to a psychological condition in which a person involuntarily mimics actions they observe.
References[edit]
- ^ Parnell, Brid-Aine (22 Aug 2014). ""Echopraxia scores 'diamond cutter' on the sci-fi hardness scale"". The Register. Archived from the original on 27 April 2016. Retrieved 13 Apr 2016.
External links[edit]
- Echopraxia title listing at the Internet Speculative Fiction Database",8
373,"This article is part of our reviews of AI research papers, a series of posts that explore the latest findings in artificial intelligence.
Very soon, you should be wary of innocent-looking typos in online content, because they might contain a hidden attack against the artificial intelligence algorithms that process the ton of text we consume every day.
“When people see typos right now, they don’t think it’s a security issue. But in the near future, it might be something we will have to contend with,” Stephen Merity, AI researcher and expert on machine learning–based language models, told me in a call last week.
And there’s ample reason to take his warnings seriously. In recent findings, scientists at IBM Research, Amazon and the University of Texas have proven that small modifications to text content can alter the behavior of AI algorithms while remaining unnoticeable to human readers.
In their paper, titled, “Discrete Attacks and Submodular Optimization with Applications to Text Classification,” the researchers delve into paraphrasing attacks, the textual equivalent of adversarial examples, perturbations in input data that cause AI algorithms to behave in erratic ways.
Thanks to advances in deep learning, AI algorithms have become capable to automate text-related tasks that previously required the skills of human operators. Many companies completely rely on AI algorithms to process text content and make important decisions.
But deep learning algorithms are also vulnerable to their own unique type of security threats. With AI becoming more and more prominent in tasks such as filtering spam, detecting fake news, processing resumes and analyzing the sentiment of social media posts, it’s important that we understand what these threats are and find ways to deal with them.
The adversarial vulnerabilities of deep learning algorithms
Neural networks, the main component of deep learning algorithms, develop their behavior based on thousands and millions of examples they examine during their training phase. This is a break from classic artificial intelligence development, in which a large part of the effort involved programmers meticulously coding the rules that defined the behavior of their software.
The example-based approach of developing deep learning algorithms make them very convenient in tackling tasks where the rules are too vague and complicated to encode through static rules. Some of the domains that have benefitted immensely from advances in deep learning include computer vision, automated speech recognition and natural language processing (NLP).
However, with humans having little control on the behavior of neural networks, their inner-workings often remain elusive even to their own creators. Also, deep learning algorithms are statistical machines, albeit very complex ones, which means they are very different from the human mind, even if they often provide very similar results in complicated tasks. Despite all advances in the field, AI’s grasp of human language is still very limited.
The unique characteristics of deep learning algorithms make them vulnerable to adversarial examples. Adversarial examples involve making small changes to the inputs of AI algorithms to force them to change their behavior. For instance, applying small changes to the color values of pixels in an image might cause an image classifier AI algorithm to change its confidence scores.
Adversarial examples accentuate the differences between AI and human intelligence. If you show the above picture to a human, they would tell you outright that it’s a turtle. But students at MIT showed that a neural network would classify the same image as a rifle. The key is to make slight changes to the colors and shapes (maybe the weird patterns on the shell) that would make it statistically close to some other object.
Sometimes, adversarial vulnerabilities can happen by accident, such as a case where AI software used by the UK Metropolitan Police to detect and flag pictures of child abuse wrongly labeled pictures of dunes as nudes.
But scientists fear that adversarial examples can someday be weaponized and turned into cyberattacks against AI systems. Any machine learning model can become subject to adversarial attacks, but deep learning models are especially vulnerable because of their complexity and poor interpretability.
The challenges of paraphrasing attacks
The idea behind paraphrasing attacks is like other adversarial attacks. The point is to manipulate the behavior of an NLP model by making changes to the input text that will go unnoticed to a human reader.
“In text attacks, people try to replace words in sentences of an article or email so that the classification will become different,” says Pin-Yu Chen, AI scientist at IBM Research and co-author of the paper.
For instance, consider an AI algorithm that automatically scans emails and blocks spam messages (many popular email providers use AI to filter out spam). A paraphrasing attack would involve rewording a spam email to slip past the AI filter while conveying the same message to the human recipient.
However, in other respects, paraphrasing attacks against NLP models are also fundamentally different from adversarial attacks against computer vision algorithms.
Discovering adversarial vulnerabilities in images is a simple process. A malicious actor can continuously feed the same picture to an image classifier, each time making small changes to the pixel values. By taking note of how changes to the pixels affect the output of the AI model, they will be able to find out how to make the right changes to completely change the classification of the image. IBM Research recently introduced a method that automates the discovery of adversarial vulnerabilities in image classifiers and helps make AI models more robust against attacks.
But creating adversarial text samples is more challenging. “Paraphrasing attacks are very special when compared to adversarial attacks on image, video and audio classifiers. Text is a high-level symbol. We know the meaning of words,” says Lingfei Wu, scientist at IBM Research and co-author of the paraphrasing paper.
In other words, you can increase or decrease color values in images, but you can’t do the same with text. “Text is traditionally harder to attack. It’s discrete. You can’t say I want 10 percent more of the word ‘dog’ in this sentence. You either have the word ‘dog’ or you take it out,” says Merity.
In many cases, a text will lose its smoothness and consistence if you take out or change a single word.
Creating paraphrasing attacks
The paraphrasing paper is not the first effort aimed at attacking text-processing AI models. But previous efforts mostly focused on swapping single words with their synonyms. This approach limited the scope of the attacks and often resulted in artificial output. In contrast, the new work by IBM, Amazon and UT expands the span of the attacks to alter entire sequences of text.
“We are paraphrasing words and sentences. This gives the attack a larger space by creating sequences that are semantically similar to the target sentence. We then see if the model classifies them like the original sentence,” Chen says.
This approach makes the attack much more versatile and ensures that the output also passes the test of being “adversarial,” which means it should go unnoticed to humans. “We believe paraphrasing is the right way to define adversarial for text-based AI models,” Wu says.
But versatility and flexibility will come at a huge cost in complexity. “We search in a very large space that looks for both word and sentence paraphrasing. Finding the best adversarial example in that space is very time consuming,” Wu says.
To overcome this challenge, the researchers have developed a gradient-guided greedy algorithm that tries to search for optimal modifications that will have the most impact on the output of the targeted AI model. “The algorithm is computationally efficient and also provides theoretical guarantees that it’s the best search you can find,” Wu says.
The paper includes some examples of paraphrasing attacks produced by the algorithm. In some cases, rewording a single sentence caused the targeted AI algorithm to change its behavior.
To create their paraphrasing attacks, the researchers had access to the structure and architecture of the model they were targeting. This is generally known as a “white box” attack.
But this doesn’t mean that “black box” attacks against NLP models is impossible. Merity points out that even closed AI models, such as those provided as online services by large tech companies, can be vulnerable to paraphrasing attacks. “Even if you keep your machine learning model secret, there have been past papers showing that if you vaguely know the training dataset or the type of AI architecture they’re using, or if you just have enough samples, you can work backwards and attack these AI systems even though you’re basically talking to a black box,” he says.
Humans are not sensitive to paraphrasing attacks
To assess the efficiency of their algorithm, the researchers had to make sure the output read smoothly and had the same meaning to humans. They tested the algorithm by running the content by human evaluators and asking them to identify the original and modified sentences.
“We gave the original and modified paragraph to human evaluators, and it was very hard for them to see difference in meanings. But for the machine, it was completely different,” Wu says.
But Merity pointed out that to be efficient, paraphrasing attacks don’t need to be perfectly coherent. In testing the algorithm, the human evaluator knows in advance that the text might be generated by an AI algorithm and will try to look for inconsistencies and flaws. But in everyday life, most of us dismiss grammatical and typographical errors as the blunders of careless or unknowledgeable humans.
“Humans aren’t the correct level to try to detect these kinds of attacks, because they deal with faulty input every day. Except that for us, faulty input is just incoherent sentences from real people,” he says.
Bad actors can actually turn this lack of sensitivity to their advantage. They can use the AI algorithm to generate paraphrasing examples, and then silently feed it into an online community platform to evaluate its coherence.
“For instance, they can post the modified content on Reddit and see how many upvotes it gets. That could be indicative of whether the sample is semantically or functionally coherent,” Merity says.
Creating more robust AI models
One of the ways to protect AI models against adversarial attacks is to retrain them with adversarial examples and their correct labels. This will make the model more robust and resilient against such attacks.
The same rule applies to NLP models. However, to their surprise, the researchers discovered that adversarial training not only makes the models more robust against paraphrasing attacks, but it also makes them more accurate and versatile.
“This was one of the surprising findings we had in this project. Initially, we started with the angle of robustness. But we found out that this method not only improves robustness, but also improves generalizability,” Wu says. “If instead of attacks, you just think about what is the best way to augment your model, paraphrasing is a very good generalization tool to increase the capability of your AI model.”
After retraining their AI models with paraphrased examples, the researchers noticed an improvement both in performance and robustness against attacks.
“It’s interesting to note that this work isn’t necessarily bad. Training the classifier against these adversarial examples that they’re actually able to produce makes the classifier not just more resilient to attacks but also can improve the accuracy of these models,” Merity notes.
The future of AI security
As artificial intelligence algorithms assume a more important role in processing and moderating online content, adversarial attacks will give rise to a new trend of security risks.
“A lot of tech companies rely on automated decisions to classify content, and there isn’t actually a human-to-human interaction involved. This makes the process vulnerable to such attacks,” Merity says. “It will run in parallel to data breaches, except that we’re going to find logic breaches.”
These kinds of attacks might be used to tamper with all kinds of AI systems. Malicious actors might use them to slip their hateful content past hate-speech classifiers, or dupe resume-processing algorithms to push their jobs application higher in the list of shortlisted candidates.
“This is the evolution of technology that you have to deal with. In the same way that in the early 2000s, spam became epidemic, we’re going to have the same thing in this era and it’s going to be more concerning. These systems potentially working against democracies and enflaming entire communities for political reasons,” Merity warns. “These types of issues are going to be a new security era, and I’m worried that companies will just spend as little on this as they do on security, because they’re focused on automation and scalability.”",3
374,"#17: One kitchen, hundreds of internet restaurants
Since the pandemic began, there has been a boom in the number of cloud kitchens in the country. A lot of the restaurants I see on Swiggy and Zomato nowadays are cloud kitchens. They can even run multiple restaurant brands on food ordering platforms from the same kitchen.
For instance, Rebel Foods, a cloud kitchen company, owns and operates 11 different cloud kitchen brands like Faasos, Behrouz Biryani, Oven Story, etc. All from a single location.
But there are a few cloud kitchen restaurants that deliver food that is so shit that I want to know which other brands are being run from the same kitchen so that I can avoid them all. This information is not visible on either Swiggy or Zomato.
One way to do this is by checking the restaurant’s FSSAI license no. It is listed at the bottom of the restaurant menu listing on both Swiggy and Zomato. If it is the same for different restaurants, the food comes from the same kitchen.
It is not practical though to check all the restaurant listings manually and find out which ones and how many of them are operating from the same kitchen. I needed a way to find all of them.
So I searched and found a couple of Bangalore restaurant datasets for Swiggy and Zomato on Kaggle. I then wrote a small script to get the FSSAI license no. and the lat/long of each of these restaurants. Both publicly available information.
I was doing this to find and avoid restaurant brands that I do not like on Swiggy and Zomato. But while analyzing the FSSAI license data of these restaurants, I found something very, very weird.
Check this line chart of no. of restaurant brands that share the same FSSAI license no. on Swiggy.
Hmm, one of them here is not like the others. What is up with FSSAI license no. 21220188001393? This FSSAI license has 189 (and possibly more) different restaurant listings on Swiggy. What’s going on here?
All of these restaurants have the same or a slight variation of this address listed on Swiggy.
NO 55/1, SHIRIDI SAI LAYOUT, NEAR SAI BABA TEMPLE ROAD, MUNEKOLALU MARATHALLI , Mahadevapura , B.B.M.P East, Karnataka-560037
1 cloud kitchen. 1 location. 189 different restaurant brands on Swiggy.
I looked at the names of all the restaurants on Swiggy registered with this FSSAI license.
At the time of writing this, all of them are active. You can search and find every one of them on Swiggy.
Notice how some of these restaurants have names that sound similar or identical to other popular restaurants? This may dupe the customer by appearing on top of the search results if the original restaurant is unavailable for delivery at that location. I also noticed that most of these restaurants are available for delivery round the clock or till as late as 6 am.
Also, you must’ve spotted a few duplicates in these names. For example, “Taste of China” and “TASTE OF CHINA”. It is not a mistake, both are active as separate listings on Swiggy. Check Here and HERE.
Interestingly, both have different menus and pictures even though it is the same name and kitchen. (How is Swiggy allowing this!)
I searched for license number 21220188001393 on FSSAI’s website and found that it is registered to Ramjani Khan.
I looked up the Lat/Long for this cloud kitchen on Google Maps, and here is a satellite image of this location from Dec 2021.
This is the place running hundreds of restaurants on Swiggy.
I performed this same exercise on the Zomato dataset too and found this same FSSAI license has 127 restaurants listed on Zomato (from the data available in the Kaggle dataset, there are possibly more!).
But wait, from the Zomato dataset, I found another FSSAI license (21220010000445) for a different location in Bangalore that is running 161 different restaurants on Zomato. Do we have another guy carrying out the same hustle with the same M.O.?
This is the address (or a variation of it) listed for all these restaurants on Zomato:
103/77, Srinivas Reddy Building, Near Infosys Gate 6, Electronic City, Bangalore
This is the satellite image of this cloud kitchen from Google maps (Jan 2022)
I ran a FSSAI license search for this license too.
Hang on, it is the same guy! Ramjani Khan owns both these cloud kitchens!!!
I later searched on Swiggy, and all these restaurants from this FSSAI license were available on Swiggy too. The Kaggle dataset I used didn’t have these listings so it wasn’t flagged during the Swiggy analysis.
Both these cloud kitchens run about 200 brands each. You have an option to select either of the locations when you visit any of their restaurant brands on Swiggy/Zomato.
So let me get this straight. One person/entity is running 400 different restaurant listings on Swiggy and Zomato from two tiny kitchens? Doesn’t sound ridiculous at all.
I don’t know if this is legal or not? Check this FAQ from the FSSAI website. This was the first question in there.
There is no mention of the limit on the no. of brands that can operate from one location under the same FSSAI license in the whole document.
Whether it is legal or not, it doesn’t feel right. How can two dingy and drab kitchens run 200 different brands on Swiggy and Zomato? I am dumbfounded by how easy it is to do this. I mean, this guy put in zero effort in naming his restaurant brands – many of them are the same names with different letter cases.
Shouldn’t there be stricter checks around how restaurants get onboarded on these platforms? What’s stopping other cloud kitchens to use the same strategy to spam these food delivery apps?
Also, it’s not even like any of these restaurants have unique cuisines or food preparations to merit so many different brands. It is literally the same food with the same 2-3 cuisines. All of them do have different photos and menu structures though. Is that all it takes to spam these platforms with hundreds of fake restaurant brands?
I feel like there should be clearer visibility on Swiggy/Zomato about how many and which restaurant brands are operating from the same location, along with a picture of the kitchen, to allow us to make a more informed decision before ordering.
All the restaurants registered under these two FSSAI licenses are very poorly rated and reviewed on both Swiggy and Zomato. None of them is rated higher than 4.
Here is a list of their Zomato ratings with min 100 reviews. See how many of them are knock-offs of other popular restaurants. Looks like a case of people mistakenly ordering from these restaurants because of their names.
Most of these restaurants operate 24x7, so sometimes very late at night, they are the only available restaurants – spamming the entire listings page.
I searched for these two FSSAI license nos. to see if I could find any more information. One guy tweeted this to Zomato but I guess they didn’t do anything about it. All these restaurants still exist on Zomato.
Look, I order food online a lot, maybe more than I should. And some cloud kitchens here are great, they deliver good food at decent prices.
But as always, and even more so on the Indian internet, we should do our own due diligence with every little thing we read or do online. It is a minefield of misinformation and deranged hustlers out there. And we can’t rely on these platforms to protect our interests.
Stay safe online and thank you for reading! My posts here don’t get too many eyeballs, but the last two went slightly and unexpectedly viral.
You can read them here – #16: The case of fake IMDb credits and #15: The early Indian internet.
Thanks for reading Pea Bee! Subscribe for free to receive new posts and support my work.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Best is to have home food. Cook your own food. You will never fall into these traps and best you will stay healthy.
Your posts have gained attention due to hackernews postings https://news.ycombinator.com/from?site=peabee.substack.com",1
375,"The Future is Elastic!
The Future Does Not Fit in the Containers of the Past. Edition 113.
“The Future is ‘Plastics’” was uttered 55 years ago in1967’s groundbreaking movie “The Graduate”. The “plastics” industry then boomed for decades but “Plastic” also meant fake, or artificial, unnatural. The statement “The future is plastics” was also code for all things that needed to be changed.
Elastic.
Today the one word would be “elastic”.
What is a simple definition of elastic?
Elastic, resilient, springy, flexible, supple means able to endure strain without being permanently injured. Elastic implies the property of resisting deformation by stretching.
The future is elastic.
People are increasingly living elastically in the way they shop, consume media, live, and work. They are stretching definitions and flexing and twisting.
The organizations that will thrive in the future will align with peoples’ new expectations and behaviors by being elastic in their structure and approach.
Those individuals most elastic in mindset who are ready to continuously iterate and adapt are more likely to thrive in transforming and changing times.
Source: Gartner
How people shop and consume media today are increasingly elastic.
The Customer “Journey” or “Funnel” is no longer recognizable.
Once upon an imaginary time there was a purchase funnel with awareness, consideration, intent and purchase as its four key movements and one could map a consumer journey.
In a world of fragmentation, empowered customers with super computers in their pockets and mongrel media like Tik-Tok which collapse above the line with below the line, fuse offline and online commerce and destroy any line between search, e-commerce, video, social and mobile, businesses are dealing with millions of journeys beginning, ending and lurching all over.
The neat little boxes and orchestrated behavior have dissolved into a cacophony of improvised jazz as the Gartner chart above illustrates.
Elastic companies will need to be not just omni-channel across all analog and digital platforms but also across multi-verses as the future of AR and VR begin to scale.
Source: World Economic Forum and Upwork.
How people will work increasingly elastically.
Within five years projections suggest that most workers will have multiple employers.
Today we are living in a world of distributed and unbundled work (a process that began before Covid-19 and was just accelerated) across office, home, third places and event. A world where software, hardware and the Cloud allows many individuals to have access to the same technologies and platforms as large firms the nature of work is in flux. The future of employee will be a flexible combination of the full-time employee, the contract employee, the fractionalized employee and the free-lance employee.
In addition, in most countries with declining populations (pretty much everywhere outside of Africa and for a little while India) businesses will combine advanced technology and cast a wide net for employees who are increasingly diverse, older and distributed around a multitude of locations working for a varying number of hours. The work forces will span generations, cultures, working styles and mindsets like never before.
A multi-verse of talent is what companies will need to be prepared for.
Their big tent will need to be elastically stretchy offering a wide menu of ways to work.
Source: Carol Dweck
Success will require the need to stretch one’s mind and skill sets.
The rate of change today is speeding up and unless one is constantly learning, adapting, and questioning the status-quo we could find ourselves like the frog in the boiling water who did not pay attention to the rising temperature till it was too late to jump out before being cooked!
Every modern successful organization and leader is a target for dis-intermediation if we do not stretch ourselves.
Satya Nadella re-invigorated Microsoft after a decade of slumber increasing its market capitalization fivefold in five years by stretching out to incorporate open source (GitHub), social media (LinkedIn), gaming ( Minecraft and now Activision Blizzard), expanding into Cloud ( Azure) while torching stack ranking (which pitted employees against each other which made no sense when connection and collaboration are key), dropped the Windows Operating Division (legacy roots that were poisoning the ability to see in new ways) and most importantly made sure that everyone in his leadership team read and learned about Growth Mindset from Carol Dweck.
If we do not upgrade our mental and organizational operating systems to adapt to a high velocity and increasingly connected world we will fail to thrive.
Becoming Elastic.
Every individual, team and firm can become elastic.
Here are five ways to stretch:
Align with the future. Stop benchmarking against existing competitors and fixating just on current marketing platforms. Two years ago, many were convinced we were living in Google and Facebook world. While Google and Meta remain critical and are likely to do so for many years, we now have Tik-Tok, Amazon, and Apple that have scaled as significant marketing platforms joined by a plethora of commerce platforms like Walmart and Roundel from Target. In addition, many companies are creating their own connection platforms whether it be Marriott or McDonalds. It is no longer a two-horse race. As we enter the Third Connected Age of the Internet today’s eco-system will look simple.
Re-Think every aspect of the organization with a tomorrow lens.Like never before does the future not fit in the containers of the past. The future work force will be distributed, diverse, unbundled, empowered and older. They will be highly informed with many ways of monetizing their skills and often working for multiple companies. It’s no longer a question of if or when but how fast. Companies focusing on returning to the office (versus maximizing the benefits of in person interaction while ensuring flexibility) have not truly grasped the seismic changes in the future of work where this is just one of many challenges.
Accelerate speed of decision making and collaboration. Stretch one’s eco-system by incentivizing teamwork, being open to external partnerships and expertise and investing in upgrading skill sets and learning.
Recognize that in a world of machine learning and fragmented behavior, data will be exponentially more important. But not data itself but the ability to use data to illuminate opportunities, partnerships, and ROI by understanding patterns, combining math and meaning to drive data driven story telling and create an underlying infrastructure of intelligence and form that keeps the business focused and informed in a chaotic media, consumer, and competitive environment.
Combine roots and wings. Elastic means to stretch but not to be deformed. It is critical that as companies and individuals create new wings to soar into the future, they do not forget the roots that made them and will continue to make them who they are. Whether this be purpose, values, brand reputation or culture it is key to combine what’s next with what has been core.
Become elastic as the future becomes elastic.
The latest episode of What Next? will help you achieve elasticity by stretching your leadership and relationship skills! Now on all global podcast platforms!
How do we stretch ourselves in a rapidly changing world? In part by being better at giving and receiving feedback and being able to navigate a diverse workforce by understanding the differences between and dealing with bias, prejudice and bullying. This week on the latest episode of “What Next?” Kim Scott, a former Google and Apple leader who has coached CEO’s and written two best selling books shares tools and techniques to ensure we speak with radical candor and focus on just work. In little over 30 minutes Kim Scott will stretch your relationship and leadership skills!
Tens of thousands of talented people all over the world receive a short read like this every Sunday. It is FREE and you can unsubscribe with a single click any time.
For more about Rishad Tobaccowala click here.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
Many thanks for the perspicacious article. The ""funnel"" concept is so ingrained in marketing mindset, will that ever change? You've made a superb case that the funnel is not only outmoded but dangerous to marketing health.
Thank you for a very inspiring article & and super insightful podcast with Kim Scott!",1
376,"100 Pandemic Technologies
Quarantine bracelets, pandemic drones, predictive cleaning, bio-patches and syndromic surveillance: the pandemic has shown how much faith we put in data, digital tools and the intelligence the companies who produce them claim will solve our problems.
A snapshot of pandemic technologies
Technologies of Hope is a curated collection of 100 data-driven, machine learning and AI enabled technologies around the world: developed, marketed and implemented to mitigate the pandemic and to help societies ‘get back to normal’.
The project creates a snapshot in time and an archive of rapid shifts in the uptake of ambient, behavioural and bio-metric data and intelligence worldwide. Some of these technologies bring hope and some play into our fears. Ultimately the project asks - what kinds of societies are we building? what trade-offs are we willing to make? and do these techno-solutions help us succeed in controlling the virus, or only in controlling the hosts?
Exploring the products and companies listed here you can browse our selection of technologies and watch short promotional and explainer videos highlighting individual, corporate and governmental visions of how society can survive and function using technology in a pandemic and post-pandemic world.
Controlling the virus or the host?
The curation examples presented in Technologies of Hope have been chosen from hundreds of companies around the world. They represent the breadth of sectors, products and ideas that seek to offer solutions for a wide range of pandemic related problems. Whether creating early warning systems, restricting human movement or helping people get back to work, data and the insights and intelligence it is claimed to create, has been seen as the answer. Regardless of which technologies ultimately fail or succeed, they demonstrate a widespread faith in big data to help us get 'back to normal' and 'back to business'.
This project looks at how technology companies present themselves and their products and how they promote them in the context of Covid. It presents the narratives, values and propositions of these companies and explores the logic and the world views they present. There are no right or wrong answers. Some technologies are essential breakthroughs, some are a distraction from the challenge at hand and some may pose more problems than they solve, it is this uncertainty that Technologies of Hope intends to explore.
These technologies all seek to create new forms of intelligence by focusing on the vehicle of the pandemic's spread: the host. With the promise of sustaining our health and our societies, we have faced trade-offs: safety versus surveillance, care versus control, fear versus freedom. Whether the host is an individual, within a group, or hiding in a population, it is often the data object. The most advanced, cutting-edge technologies, data analysis and machine learning are utilised in an attempt to see the host from as many different angles as possible and with unprecedented precision.
The dilemma we as societies face is that our technological response to this planetary-scale crisis may not offer greater control and understanding of the virus, but rather greater control and understanding of ourselves.",5
377,"Retr0idTo use Pleroma, please enable JavaScript.",7
378,"Mad God
2021, Horror/Fantasy, 1h 23m80 Reviews 100+ Ratings
What to know
critics consensus
A rich visual treat for film fans, Mad God proves that even in the age of CGI, the cinematic allure of stop-motion animation remains strong. Read critic reviews
Where to watch
Rate And Review
Mad God Videos
Mad God Photos
Movie Info
Cast & Crew
Director
Screenwriter
Producer
News & Interviews for Mad God
Critic Reviews for Mad God
Audience Reviews for Mad God
There are no featured reviews for Mad God because the movie has not released yet ().See Movies in Theaters
Verified",1
379,"The Danger of Continuous Partial Attention
We are living in a world that is more connected than ever. There are some definite pitfalls in our hyper-connected world as it intersects with our business relationships and networking. Hyperconnectivity can lead to a state of ""continuous partial attention."" A state of continuous partial attention is a state where people are giving partial attention to what they are doing – continuously.
Face-to-Face Networking and Social Media.
Continuous partial attention can hamper your relationship-building efforts - not only on a personal level, but also on a professional level. When attending a function of any type, it is becoming increasingly common to find people who remain connected to their social networks (beyond uploading a photo or tweet about the event) with mobile devices during the meeting. I see this all the time at networking meetings, such as at a BNI chapter meeting, a Chamber of Commerce luncheon, or even a gala dinner event.
So while our desire to connect and be connected is one of the strengths of business and social networking, when we are actually in person at an event where we want to effectively be connecting with others, this desire can actually dilute our efforts by driving us to stay ""live"" online instead of with the person in front of us.
Related: What to Do When Someone Refuses to Take Your Business Card
We have probably all experienced being in conversation with someone at a networking function and getting pinged during the conversation. When we take our attention off what is happening in front of our nose to take a look at what is happening on our phone, we lose the connection with the person we're speaking with. We will not remember this part of the conversation well, if at all. And we will send a subtle message to this person that he or she does not matter as much as the various pings coming in on our mobile device do.
Continuous partial attention can hamper your efforts to build profitable business relationships with the people you want to connect with. I believe a price is being paid by how this constant connectedness is affecting our real-time relationships. The truth is that our brains are not capable of multi-tasking. Brains don't work like a computer, which can have many programs running simultaneously. Our minds have to switch among tasks. Some of us can task-switch extremely quickly, seemingly multi-tasking, but we are not actually multi-tasking. Others of us task-switch with a little more difficulty, making it extremely challenging to really pay sustained attention to anything when we try to multi-task.
Related: Four Ways to Better Involve Your Company In Charitable Activities
Working While Distracted
Most of us work at our computers, laptops or tablets with notifications switched on: email, Facebook, Twitter, Instagram, Google+, LinkedIn, Pinterest, Skype, YouTube, Tumblr, and Snapchat pinging, chirping and whistling as notifications fly across your screen shouting, ""Look at me! Someone retweeted you! Someone wants to be your Friend!"" Even people who do not have ADD are working in a state of attention deficit due to the distraction all these notifications cause! These are the people in the ""Prayer Neck"" posture – hunched over looking down at their hands while holding their mobile device.
It is very easy to lose track of whom you have just followed up with -- you end up sending your follow-up email twice or reference something you were discussing with someone else or, worse yet, send an email to the wrong person entirely. (Who hasn't done that?) Continuous partial attention keeps you from being alert, attentive and focused and can hamper your post-event follow up not to mention your day to day activities.
Be honest: whom do you greet first when you get up in the morning -- your spouse, kids, the dog OR your virtual community? Do you reach for your smartphone before you even throw your legs out of bed to get up? I have found myself doing that. I used to never even turn my mobile phone on until after I was up, had exercised, showered and had my breakfast. I think social media is great. I use it regularly to stay in touch and build relationships. But knowing when to focus on the face-to-face interactions and put notifications on Do Not Disturb is also extremely important in this ever expanding digital age.
Related: Is Your Network a Mile Wide But an Inch Deep?
Entrepreneur Editors' Picks
-
Jennifer Lopez Is Done With 'Happy to Be Here.' She Thinks Latina Entrepreneurs Are Undervalued, So She's Working to Give Them $14 Billion in Loans.
-
How to Retrain Your Brain and Achieve the Highest Levels of Success
-
Her Company Is Worth $1 Billion. But It Began as a Way to Solve Her Own Shipping Problems.
-
TikTok Is Doling Out Age-Old Resume Advice. This Former Microsoft Recruiter Says You Should Ignore It.
-
6 Benefits of Working With a Franchise Consultant or Broker
-
5 Tips I Wish I Knew Before Starting My Business
-
Sallie Krawcheck Was the Queen of Wall Street, and Raised $100 Million to Launch Her Own Business. Then She Hit an Impasse She Hadn't Seen Coming.",1
380,"Subscribe to our newsletter
Weekly updates with new Fifty Two stories
The sky is clear, the sea a deep blue. A patch of sand separates the water from a hill. Palm trees stud the landscape. A moai statue appears to be saying something to five other figures. In the middle of this idyll, seemingly incongruous, is the honeycomb structure of a molecule.
We are in a painting by Sir Roy Calne, a British surgeon and a pioneer of organ transplantation. The scene is from Easter Island or Rapa Nui, one of the world’s most remote inhabited islands. Its nearest mainland neighbour is the country of Chile, more than 3,500km away. The moai statue expounding to the others is meant to represent Surendra Sehgal, an Indian scientist born in undivided Punjab. The molecule is a compound called rapamycin, found in the soil of the island.
Rapamycin, also called sirolimus, is now a life-saving wonder drug. It’s used for immunosuppression in organ transplant patients and coronary artery stents after balloon angioplasties. Trials are underway to test its efficacy in treating ALS, Crohn’s disease, and metastatic and advanced cancers. Some studies suggest that rapamycin could increase lifespan.
But all these bounties were unimagined when soil samples from Easter Island arrived on the desk of a 37-year-old microbiologist in Montreal in the year of the moon landing. Calne’s painting takes some creative licence. Sehgal himself never visited Rapa Nui, but the man and his molecule are forever tied to the island. This is their story.
Island In The Stream
n 1963, the Cold War appeared to have pushed humans not only towards the moon, but also to the brink of self-annihilating madness. Nuclear arms testing had raised fears of radioactive fallout. Overpopulation added a tremendous strain on resources. With the world on boil, scientific communities wondered: how do we adapt?
This churn of events led to the genesis of the International Biological Programme in Europe. The IBP would conduct a series of environmental studies to attempt to piece together the path ahead for humanity.
In Canada, two colleagues, both immigrants from war-torn Europe, were following the developments of the programme. Polish surgeon and researcher Stanley Skoryna and Hungarian microbiologist Georges Nógrády had just learned that an airport was going to be built on the distant isle of Rapa Nui, where hundreds of years earlier, islanders had carved out 800-odd large monolithic statues from volcanic stone to honour their ancestors.
There’s a theory that the islanders cut down all the giant palm trees that dotted the island: for agriculture, to build fires or to transport the massive statues. Whether or not the tree-cutting was the cause, their robust civilisation ultimately collapsed.
The Rapa Nui mystery had long captured the imagination of archaeologists and ethnographers. Now, it caught the fancy of these two scientists. Skoryna wanted to study what the coming of the airport would mean for one of the most sequestered communities in the world. As part of the IBP, his team put together an ambitious plan to study the biosphere before and after the airport was constructed.
One chilly November morning in 1964, the Medical Expedition to Easter Island set out from Halifax on a Canadian Navy vessel. On board were microbiologists, virologists, parasitologists, medical doctors and 200 sailors. Once they reached, they stayed at their destination for the next two months, gathering swabs, collecting urine samples and X-raying the island’s 1,000-odd inhabitants. The earth, too, was thought to yield unanticipated treasures. [1] Nógrády divided the island into dozens of strips of land and dug out soil from each of them. [2]
Back in Canada, the team disseminated their Easter Island riches to laboratories around the world. But the team never went back as planned, and Skoryna didn’t publish a single report. Still, the expedition was not in vain. In 1969, some of these soil samples made their way to the Ayerst Research Lab in Montreal.
urendra Nath Sehgal was born in 1932 in Khushab village in western Punjab, in an India still undivided. The family moved to Delhi before Partition, where Sehgal’s father continued the family business of manufacturing medicines and medical equipment. Business wasn’t easy, but the firm survived.
Sehgal, whose childhood was punctuated by regular visits to his father’s factory, developed a keen curiosity for how medicines worked on the body. He earned undergraduate and master’s degrees in pharmacy at the Banaras Hindu University. For a year after that, he taught at BITS, Pilani. But he was itching to do more. When he got a scholarship to work towards a PhD in microbiology at Bristol University in the United Kingdom, his family was thrilled. Nobody in their circle had journeyed beyond the subcontinent.
“Suren complained to Air India saying, ‘My parents and siblings are here because of you. You must give them breakfast.’”
Sehgal’s departure in 1954 was a delightful family event, with the entire battalion accompanying him to the airport with garlands and blessings. “The plane was delayed by a few hours, and we all waited till morning,” Swadesh, his now 88-year-old younger brother, told me from Delhi. “Suren complained to Air India saying, ‘My parents and siblings are here because of you. You must give them breakfast.’ This is how my brother got things done. Firmly but politely.”
He would deploy a similar brand of single-mindedness when it came to convincing his employers to take a chance on rapamycin. By the time the samples arrived at his desk, he had spent ten years as a researcher in the microbiology section of Ayerst, working on medicinal compounds made by bacteria. Together with his colleague Claude Vézina, he already had five patents to his name.
The Petri Dish
yerst had received nearly 70 soil samples from Easter Island. Sehgal and his team isolated the microorganisms from the soil, grew them in the lab and examined the chemicals the culture produced. An as-yet unknown compound secreted by a bacterium called Streptomyces hygroscopicus started to show astonishing results.
A laboratory is no place to go wild. “Controls” are crucial in biology and microbiology. Sehgal and his team would likely have created the perfect conditions for fungi to grow on one petri dish: right temperature, right food and so on. In another petri dish, the same: only, this batch of fungi would have had contact with rapamycin. What might they have seen under the microscope? The fungi rapidly multiplying in the first dish and the same organism simply freezing in the one touched by rapamycin.
That was sufficient to kick off a series of studies on rapamycin’s antifungal properties. Two years after Sehgal’s initial discovery, a different team at Ayerst came up with the chemical structure of the molecule. It was named rapamycin after the island on which it was found.
“Uma, it’s a fantastic compound, it’s a miracle,” Sehgal would tell his wife during these early encounters. “Anything it touches gives good results.” On 28 October 1975, a whole decade after Nógrády scooped soil on Easter Island, Sehgal published his first paper on rapamycin in the Journal of Antibiotics. A new antifungal antibiotic had been discovered, he declared.
hen Sehgal had first set foot in North America in 1957, it was with less than $10 in his pocket. His wife Uma recalled a story her husband loved to tell. At Delhi airport, customs had seized the money his father had given him. That prompted a kind German family he met on the plane to take him to a fair in Frankfurt, where he had a layover, and feed him lunch. The following day, he boarded a flight for Montreal, where an Indian friend met him, bought him lunch and put him on the train to Ottawa, where he became a postdoctoral researcher.
Sehgal joined Ayerst in Montreal in 1959. (He stayed with the company till retirement, through mergers, acquisitions and name changes. [3] ) His workplace had enormous fermenters to grow microorganisms in large batches, something that was terribly exciting for an antibiotics enthusiast.
When he was 30, he went back to India for a winter holiday and returned to Canada as a married man. When Uma Kapur first came to Montreal, it was January 1962, the dead of winter. The newlyweds started their life together in a small one-bedroom flat. There were only half a dozen Indian families in Montreal at the time. One of these included Uma’s sister and brother-in-law, who happened to be the Indian High Commissioner.
Uma’s mother had warned her future son-in-law that her daughter was wanting in household matters. But the besotted man paid no heed. Uma’s sister urged her to stay with her for a few days, so she could teach her to cook. “Everyone was worried about how I would manage, but Suren said to my sister, ‘Don’t worry, I will teach her,’” Uma told me. “There was no rolling pin, so he made chapatis with a wine bottle, rolling the dough on the table-top.” She warmly remembered the metal table with the vinyl surface.
Life was picking up in Canada. Sehgal, Uma discovered, was a gregarious Punjabi, not one to be a wallflower at a party. Her husband was also organised to a fault. “He behaved like the house was his lab and wanted everything in order,” Uma said. “I told him once, ‘You run your lab, I will run the house.’”
Family Life
hat first memorable year, when the snow had finally melted, Uma stepped out of home in a saree. Her picture appeared in the newspaper the following day. The president of the Canadian Pacific Railway invited her to his house to talk about sarees and bindis. The photo of that meeting, too, appeared in the paper. “Those were the days,” Uma laughed at the recollection. “Suren said nobody had ever written about him, but then came his wife, and took over the Montreal newspapers.” His time would come soon.
He was not a “typical Indian man,” Uma said, which means he did everything for their children, two boys named Ajai and Neel. The boys grew up as most second-generation Indian immigrant children: steeped in Indian culture at home, while being shaped by the country of their birth. Their parents insisted on excellence in academics and extracurricular activities. Ajai, the older son, remembered watching all the televised Apollo missions. He had a particular memory of watching the moon landing of 1969 as a six-year-old. His father had roused him from sleep and plopped him in front of the television. “You have to watch this,” he told Ajai. “It is history in the making.”
Sehgal tried to steer his sons towards the world of science and discovery. Their days buzzed with electrical experiments involving soldering and wires. “We also had a chemistry set and worked with dad in measuring various compounds, mixing them together and watching them foam up,” said Neel. (Eventually, Neel went into accounting, Ajai did engineering.)
Sehgal’s passion for rapamycin was infectious. “Every day, he spoke of rapamycin with great excitement,” Uma told me. When the clinical trials for the drug took off later, she accompanied her husband to meetings, where she sat in the back and listened. Often, he practised his presentations and speeches in front of her. Once, at a conference on transplants in Paris, a famous scientist asked Uma: “Do you know you are sleeping with a genius?”
Back in the lab, as Sehgal and his team were studying rapamycin’s antifungal properties, they realised it also had immunosuppressant qualities. This would make it very useful in countering the advance of autoimmune diseases such as rheumatoid arthritis and lupus. Crucially, it could help in post organ transplant recovery.
Rapamycin’s suppressant qualities also presaged great news for cancer treatment. Chemotherapy, the only treatment option at the time, was an aggressive approach that not only killed cancerous cells but also other fast-dividing healthy cells. Rapamycin, on the other hand, could potentially inhibit cell multiplication.
Buoyed by its overall potential, Sehgal sent samples of the compound to the US National Cancer Institute for screening, where it showed encouraging results on tumours. Shortly afterwards, NCI and Ayerst collaborated on testing rapamycin along with chemotherapeutic drugs on mice. These results turned out to be spectacular. NCI designated rapamycin a priority drug. “It was a totally new class of anti-cancer agents we were looking at—cytostatic. To that point, they were all cytotoxic agents,” Sehgal said in an interview to the Journal of the National Cancer Institute in October 2001.
But scientific research is long, gruelling and hinges on generous funding. In 1983, rapamycin research received a big blow from the exigencies of business and regulation. Ayerst shut down the facilities in Montreal, laid off 95 percent of their employees and moved a small cohort of 30-odd researchers and staff to Princeton, New Jersey. [4]
Not for Eating
ehgal was one of the 30, but he was still furious. That was because rapamycin was no longer a “company priority.” In fact, Ayerst had even ordered the destruction of “non-viable compounds.” This is what prompted him to do something that could be out of a sci-fi film. Before the Montreal lab was dismantled, he made one last batch of rapamycin in the fermenter. He brought that batch home in glass jars. The substance was white and pasty, a little like ice cream but waxier. He put the jars in the freezer with a sticker that said “NOT FOR EATING.”
“I wondered if they could take it across the border because it was essentially a living organism. But my father asked me to do as told.”
Uma and Sehgal moved to the US on a cold December day. Ajai, who had moved out by now, came up to help. Sehgal instructed his son to buy dry ice to transport his beloved compound. “I wondered if they could take it across the border because it was essentially a living organism,” Ajai said. “But my father asked me to do as told.”
After piling the dry ice at the bottom of the freezer, they transferred the jars into an ice cream container on which Sehgal wrote ‘DO NOT EAT.’ They surrounded the treasure with frozen meat and layered it with more ice. The contraption was sealed with duct tape. Dry ice produces carbon dioxide, and a pressure build-up could lead to a catastrophe. “So we poked holes all around to make sure it was vented,” Ajai told me. “When the movers came, I told them to take the freezer and said it had food in it.”
The rapamycin made its way to its new home without incident. It would be five years before it was taken out from the refrigerator in the house on Sayre Drive, Princeton.
Matters of the Heart
n 1987, Wyeth took over Ayerst to become Wyeth Pharmaceuticals. A new management meant Sehgal could pitch rapamycin once again. His presentations often ended up in heated arguments. Uma told me that he was given the pink slip thrice, but was asked to return each time.
In 1989, his tireless proselytising finally came good. It was time to bring out the culture that had been languishing in the freezer at home. He dashed it to the lab and put it to the test. To his utter delight, the culture was alive and thriving.
It is challenging to reconstruct what exactly Sehgal and his team did in the lab, so I asked biologists and microbiologists if they could tell me how the work might have played out.
“It really depends on what is being investigated, but you usually get the results for microorganisms in two or three days,” Juan-Carlos Acosta, research professor at the Spanish Research Council and an expert in cellular senescence, told me. “It can be obvious to figure out whether a culture is alive when you’re dealing with a liquid that is transparent. You put a small number of whatever you’re investigating in the culture. You set it to the optimal temperature, and the organisms happily swim around in this perfect soup.”
In a day or two, Acosta explained, if the liquid becomes turbid and dense with a lot of precipitates floating around, it means the microorganisms have grown. If the liquid remains transparent, there has been no growth.
Even if a culture is alive in a laboratory, it guarantees nothing in the outside world. The next step is animal testing. Sehgal contacted five external investigators to carry out this work. [5] The timing was perfect. Organ transplantation had taken off in a big way, and there was a need for drugs that would prevent transplant rejection, or the body’s inability to cope with a new organ. Cyclosporine and FK-506, the existing drugs, were not very effective.
One of the five external investigators was Stanford University’s Randall Morris. (Another was the surgeon-painter Sir Calne.) He worked on transplantation using mice and rats. Last autumn, speaking from his home in Carmel, California, Morris spoke to me about how he carried on his trials in those days. He’d pick a young brown mouse to be a donor and a white one as a recipient. He’d remove the heart from the brown mouse, make a little pocket under the ear of the white mouse and place the whole heart under it.
If everything went well, within two or three days, the white mouse’s new blood vessels would grow into heart tissue. And then, and this was truly the money moment, the little heart would begin to beat.
Morris recalled the day when he received that call from Sehgal. “I looked at the structure of rapamycin and thought, well, this is going to be a rather boring project. Half of it resembled the compound of another immunosuppressant molecule of the time: FK-506,” Morris said. “But at that stage, I had very little experience to know that very small changes in a drug structure can dramatically affect the way the drug works.” He agreed to the collaboration anyway. [6]
His scepticism eroded as the experiments began. Over weekly calls, Sehgal’s team would advise on dosage. Sehgal recommended that the drug be injected into the mouse’s abdomen for better absorption. “And what we saw was amazing,” Morris told me. “We were surprised by how potent the drug was. We kept lowering the dose and the drug kept working.” Two months and dozens of mouse sacrifices later, Morris published his data in a 1989 issue of Progress in Immunology. It was the first ever publication on rapamycin as a potential drug for organ transplantation. [7] Morris has preserved the first vial he used for this experiment. He showed it to me on our video call.
Trick and Treat
ver the next few years, rapamycin continued to deliver promising results in various studies. People had started asking the question: how exactly does it work? The answer came in the PhD thesis of biologist David Sabatini of Johns Hopkins University. [8] “Sehgal had very kindly sent us a large amount” of rapamycin, Sabatini wrote in 2017. But “just as importantly, he had also sent a book titled ‘Rapamycin Bibliography’ with a little note wishing us luck. That book became my inspiration.”
Sabatini, as well as other scientists elsewhere, simultaneously concluded that rapamycin latched itself onto a hitherto unknown protein which they called mTOR—the mammalian target of rapamycin. [9] This protein, they found, exists in every cell of every multicellular organism, including humans.
Cells need nutrients to stay alive. This is where the protein mTOR springs into action, like a traffic policeman coordinating the metabolic decisions in a cell. When it receives messages from other proteins about there being enough nutrients—sugars, fatty acids, amino acids, for instance—in the cell, it gives the cell the green signal to divide and proliferate. When nutrients are lacking, it flashes the red light, ordering the cell to stop making merry.
This process is great for healthy cells but can have a disastrous effect on cancer cells that grow rapidly. Here is where rapamycin comes to the rescue. It latches on to mTOR and tricks the cell into believing that there aren’t enough nutrients to grow.
Our immune system is a major catalyser for cell activity. Immune cells are wired to launch an attack as soon as they sense danger. But at times, the system is not as discerning. A transplanted organ—technically a foreign body—is seen as the enemy. The drugs that control these unnecessary, overzealous attacks are known as immunosuppressants. Rapamycin’s deceptive quality made it a good immunosuppressant.
In 1996, human clinical trials to test rapamycin as an immunosuppressant were in full swing. Phase 1 studies on patients with kidney transplants were showing positive results. Sehgal was in the audience at a conference in Switzerland where Dr. Rakesh Sindhi, a transplant surgeon at the Medical University of South Carolina in Charleston, was presenting a paper on immunosuppression. After Sehgal told him about his new drug, Sindhi became one of 30-50 investigators in the phase 3 trial of the drug, which led to FDA approval. [10]
“We noticed right away that it had fewer side effects than the usual drugs, and yet seemed to have a good effect in terms of preventing rejection.” Sehgal went on to become a mentor figure for him. He was the rare scientist who gave freely of his time and knowledge to the medical community, Sindhi told me.
A few years later, Sindhi started working with the Children’s Hospital in Pittsburgh, where he is currently co-director of the Liver and Intestine Transplant Program. The team began to administer rapamycin to children suffering from the side effects of other drugs. “The results were dramatic when we switched them to rapamycin,” Sindhi said. “Mothers would say, ‘Oh my child is a little bit better at focusing.’ Even if there were side effects, they were minor and well-tolerated.”
year earlier, in 1998, Sehgal had felt something was off in his own body. A blood test he did on himself showed slight anaemia. A general physician advised eating red meat but Sehgal got a colonoscopy. A tumour showed up in the upper core component. The following day, they cut him open to find four affected lymph nodes. It was stage 4 metastatic colon cancer. Sehgal was given six months to live.
“Whenever he met people after that he would say, you watch, I am going to live another five years,” Uma said. Along with chemotherapy and radiation, Sehgal started to take his own drug, rapamycin. He felt good. The year after his diagnosis, he retired from Wyeth and moved to Seattle to be close to his son and grandchildren. He worked as a consultant for the next few years, travelling the world for conferences, meetings and leisure.
“Whenever he met people after that he would say, you watch, I am going to live another five years.”
Once, he underwent radiofrequency ablation in Pittsburgh to burn inoperable tumours in his liver. While recovering from the procedure, he was surrounded by liver transplant patients. Word soon spread that the discoverer of the drug that had given them a new lease of life was on their floor. People came in, one by one, some on wheelchairs, to shake his hand and thank him. “It was an amazing thing to witness, you know,” Neel told me. “How often does it happen that you’re having surgery on the floor where all these recipients of your drug are?”
Sometime during the last six months of his life, he developed a doubt: how was he to know if rapamycin was the reason for his good health? After all, he had undergone chemo and radiation too. The scientist became the experiment. He stopped taking the drug and the cancer returned with a vengeance. Within two months, it had spread to his lungs. “He said in his last days that it was his biggest mistake,” said Neel.
His last days remained busy. Family and friends kept visiting. True to form, he was working on a paper until five days before his death, with an oxygen mask on his face. [12] The day before he passed, he was in pain. The nurse looking after him at home suggested he take morphine. He refused, saying he didn’t want his brain to be foggy. He spent the day watching Star Wars. Surendra Nath Sehgal died at home, surrounded by loved ones, on 21 January 2003.
cience is not a discipline for lone wolves. Hagiographies often play up the image of the scientist as a reclusive genius, ploughing a lonely furrow in the lab at odd hours. To get a drug like rapamycin to market and actually transform people’s lives, many people have to work late and lonely nights. They also have to talk to each other, as Skoryna did with Nógrády, as Sehgal did with Morris and Sindhi and so many others, as Sabatini must have with his thesis advisor. But the eureka moment remains special, and Sehgal was there for it, captaining a team that saw a simple culture experiment produce a remarkable result.
While he was alive, Sehgal already knew that his work had moved the needle on something critical.
Uma was recently at a local art gallery in Seattle with her daughter-in-law. A professor from the University of Washington was making sculptures there. He asked if she would be willing to model for him. While she sat, a woman from the art gallery asked the sculptor how he was feeling.
“I asked what happened and he said he was just back from his third kidney transplant,” Uma told me. “He said if it hadn’t worked this time, he’d have died. I asked him which drug he was on, and he said Rapamune.” When she told him her husband had discovered it, he asked if he could meet him. “When I told him he was no more, he came and shook my hand.”
Uma knows what her husband would have said had he been alive. Many years ago, when rapamycin had not yet been formally approved, a doctor had sought it on compassionate grounds for a six-year-old’s kidney transplant. The surgery had been a success. “I don’t care if the company makes even a cent out of it,” Sehgal had said to Uma. “My work is done. A child has survived.”
Sukhada Tatke is a journalist from Mumbai, currently in Edinburgh.",8
381,"Zur Verbindung mit dem Gesundheitsdatennetz „Telematik“ sind in deutschen Arztpraxen spezielle Router vorgeschrieben. Nach nur fünf Jahren Laufzeit soll nun ein Gerätetausch alternativlos sein – so zumindest die Hersteller. Dieser Tausch soll das ohnehin angeschlagene Gesundheitssystem mit Mehrkosten von rund 400 Millionen Euro belasten. Der Chaos Computer Club (CCC) zeigt, dass der teure Hardware-Tausch alles andere als nötig ist, und spendiert kostenlos eine Lösung für das Problem.
Wie viele infrastrukturelle Großprojekte in Deutschland ist auch die Digitalisierung des Gesundheitswesens kein Grund zum Stolz. Sie obliegt der Firma gematik, die mit der „Telematik Infrastruktur“ (TI) ein „sicheres“ Datennetz für Patientendaten wie die elektronische Patientenakte oder das e-Rezept betreibt. Für den Zugang wird in der Arztpraxis ein spezieller VPN-Router benötigt, der TI-Konnektor, der aktuell von drei zertifizierten Herstellern verkauft wird.
Mit den TI-Konnektoren hat die gematik für diese Hersteller ein äußerst lukratives Kartell-ähnliches Geschäftsmodell geschaffen, denn die Geräte haben ein künstliches Verfallsdatum, weil Zertifikate auslaufen. Nach nur fünf Jahren im Dienst wollen die drei Hersteller erneut 130.000 Konnektoren verkaufen. Kein Wunder, dass ihnen wenig an einer alternativen Lösung gelegen ist.
Aus Sicherheitsgründen haben viele Zertifikate, wie zum Beispiel auch die Zertifikate von Webseiten, ein Verfallsdatum. Das heißt, sie müssen regelmäßig erneuert werden. Ein Problem, das nicht nur bekannt ist, sondern für dessen Lösung es seit langem etablierte technische Verfahren gibt. Der Ablauf nach fünf Jahren kommt also alles andere als überraschend – dennoch hat die gematik keine Verlängerungsmöglichkeit für ihre Konnektoren vorgeschrieben.
Die Hersteller können sich nun über den Verkauf komplett neuer Geräte freuen, statt ein einfaches Software-Update anbieten zu müssen.
Sogar der gematik als Auftraggeber ist die Absurdität eines solchen Hardwaretausches klar. So schlug sie eine unverbindliche Option zur Laufzeitverlängerung vor. Natürlich wurde diese nicht von allen Herstellern umgesetzt. In der Folge schlossen sich auch die Firmen, die bereits eine Möglichkeit zur Verlängerung implementiert hatten, der umsatzträchtigen Formel „Austausch statt Update“ an: für die Hersteller ein Riesengeschäft, für deutsche Praxen und Krankenhäuser eine weitere finanzielle und logistische Zumutung.
Die Kassenärztliche Bundesvereinigung bezifferte in ihrer letzten Vertreterversammlung allein die nicht durch die Krankenkassen erstatteten TI-Anschlusskosten der vergangenen Jahre für eine durchschnittliche Praxis auf 9.000 Euro.
Es kommt noch dreister: Schon im Jahr 2027 soll sich diese kostenintensive Blamage wiederholen. Denn auch die jetzt zum Austausch vorgesehenen Konnektoren haben wieder nur eine fünfjährige Lebensdauer – und bis dato gibt es noch keine verpflichtende Laufzeitverlängerung.
„Hier will sich ein Kartell durch strategische Inkompetenz am deutschen Gesundheitssystem eine goldene Nase verdienen. Dabei werden immense Kosten für alle Versicherten, sinnloser Aufwand für einen Austausch bei allen Ärzten und tonnenweise Elektroschrott in Kauf genommen“, sagte Dirk Engling, Sprecher des Chaos Computer Clubs. „Schlimmer noch: Eine Wiederholung des Debakels in fünf Jahren wird bereits vorbereitet.“
Dass ein Software-Update mit minimalem Aufwand möglich wäre, zeigten jüngste Recherchen: Ein Hacker des CCC dokumentierte eine Analyse der ausgelieferten Firmware auf den Konnektoren.
Diese Forschung zeigte, dass die auf den Konnektoren laufenden Open-Source-Komponenten mit sehr wenig Aufwand überredet werden können, neben den auslaufenden Zertifikaten einen zusätzlichen Strauß an erneuerten Zertifikaten zu benutzen. Mit diesem Wissen war ein minimalinvasiver Patch nur noch eine Fingerübung. Das Ergebnis spendet der CCC den augenscheinlich überforderten Herstellern.
Bevor diese Patches auf die Konnektoren aufgespielt werden können, braucht es jedoch noch eine Handvoll geheime Bits, die nur bei der gematik im Tresor liegen: Damit müssten die neuen Zertifikate und Patches für die Firmware signiert werden.
„Wenn die beauftragten Hersteller von TI-Konnektoren selbst mit so trivialen Aufgaben wie einer Erneuerung der Zertifikate überfordert sind, drängt sich doch die Frage auf, ob nicht die Vergabekriterien und Verträge der gematik verschärft und kompetentere Wettbewerber gefunden werden müssen“, so Engling.
Im Lichte der fortwährenden Geldverbrennung in der TI fordert der CCC das Bundesgesundheitsministerium auf, die gematik an eine kürzere Leine zu nehmen und dem Pfusch bei Ausschreibungen und in den Verträgen ein Ende zu setzen. Weiter fordert der CCC das Umweltministerium auf, gangbare Wege auszuloten, die allein schon aus Nachhaltigkeitsgesichtspunkten völlig sinnlose tausendfache Vernichtung einsatzfähiger Hardware zu verhindern.
Schließlich appelliert der CCC an die Hersteller der Konnektoren, dass sie sich ehrliche Wege für ihren Broterwerb suchen.
Wenn die gematik in Vertretung für das deutsche Gesundheitssystem das 400-Millionen-Euro-Geschenk annimmt und die erforderlichen Signaturen leistet, bietet der CCC den Praxen und Krankenhäusern Hilfe beim Einspielen der Patches an. Mit diesem Angebot wollen wir sicherstellen, dass bei den Herstellern nicht noch überraschend auftretende logistische Probleme die kostengünstigere Alternative verhindern.",2
382,"Three Thousand Years of Longing
|Three Thousand Years of Longing|
|Directed by||George Miller|
|Screenplay by|
|Based on||""The Djinn in the Nightingale's Eye""|
by A. S. Byatt
|Produced by|
|Starring|
|Cinematography||John Seale|
|Edited by||Margaret Sixel|
|Music by||Tom Holkenborg|
Production
companies
|Distributed by|
Release dates
Running time
|108 minutes[2]|
|Countries|
|Languages|
|Budget||$60 million[3][4]|
|Box office||$17.1 million[5][6]|
Three Thousand Years of Longing is a 2022 fantasy romantic drama film directed by George Miller and starring Tilda Swinton and Idris Elba. Miller wrote the screenplay with Augusta Gore, adapting the 1994 short story ""The Djinn in the Nightingale's Eye"" by A. S. Byatt. Elba stars as a djinn who is freed by a professor (Swinton) and recounts his life to her. The film is dedicated to Miller's mother Angela, as well as Rena Mitchell, relative of producer Doug Mitchell.
The film premiered at the Cannes Film Festival on May 20, 2022. It was released theatrically in the United States on August 26, 2022, by Metro-Goldwyn-Mayer (via United Artists Releasing), and in Australia on September 1, 2022, by Roadshow Entertainment. It received generally positive reviews, but was a box-office bomb.
Plot[edit]
Alithea Binnie is a British scholar who occasionally suffers from bizarre hallucinations of demonic beings. During a trip to Istanbul, Alithea purchases an antique bottle, and accidentally unleashes a Djinn that was trapped within it. The Djinn offers to grant Alithea three wishes, so long as each one is truly her heart's desire, but Alithea argues that wishing is a mistake, accusing the Djinn of being a trickster. In response to her accusation, the Djinn proceeds to tell her three tales of his past and how he ended up trapped in the bottle.
The Djinn tells the story of the Queen of Sheba, his cousin and lover, being wooed by King Solomon, who imprisons the Djinn in a bottle to keep Sheba for himself. The Djinn's second story centers on Gülten, a young concubine in the palace of Suleiman the Magnificent. After finding the Djinn's bottle, Gülten wishes for Suleiman's son, Mustafa, to fall in love with her and subsequently wishes to bear his child. A favored concubine of Suleiman schemes to have her son on the throne so she seeds Suleiman's mind with the idea that Mustafa will conduct a coup against him and he is too weak to lead the kingdom. The Djinn tries to warn Gulten but being naive and ignorant with the dirty politics within the ruling class, she ignores him. This result in Mustafa's murder, causing Gülten to leave behind the Djinn's hidden bottle and flee. Despite the Djinn's attempts to pursue and save her, the pregnant Gülten is also killed on Suleiman's orders before she can make her final wish.
The Djinn wanders the palace for over 100 years, invisible and intangible due to the concealment of the bottle. Meanwhile, the bottle is almost found by young princes Murad IV and Ibrahim, but they are unable to successfully uncover the bottle. Years later, Murad IV goes into war, where he becomes a vicious and ruthless ruler, later dying from alcoholism. Ibrahim develops a fetish for voluptuous concubines and becomes the new sultan. His favorite among them, Sugar Lump, accidentally retrieves the bottle, whereupon the Djinn appears to her and desperately begs her to make a wish. Sugar Lump, being silly and terrified, thinking him to be a tricker and wishes for the Djinn to return to his bottle and for the bottle to be cast into the sea.
In the Djinn's final story, he tells of Zefir, the young wife of a Turkish merchant, who is gifted the bottle after it is recovered in the mid-19th century. Zefir wishes first for knowledge, which the Djinn grants in the form of literature, and later to perceive the world as djinns do. Despite the Djinn's growing affection for Zefir and the fact she is now pregnant with his child, she grows increasingly crowded by his presence and her newfound knowledge. The Djinn offers to reside in his bottle whenever she wishes, but as he begins his return to the bottle, Zefir wishes to forget she ever met the Djinn, leaving him imprisoned and unknown once again. The Djinn's final story moves Alithea to the point where she wishes for Djinn and herself to fall in love, resulting in them having sex.
Afterwards, the Djinn and Alithea travel back to London together. One day, Alithea discovers that the Djinn is gradually becoming weaker due to the effects that the city's cell tower and satellite transmissions have when interacting with his supernatural physiology. She uses her second wish to get the severely ill Djinn to speak again, apologizes for using her wish to deny them the chance to fall in love naturally, and uses her third and final wish to set the Djinn free, so he is able to return to ""The Realm of Djinn"".
Though expecting never to see him again, the now-healthy Djinn visits Alithea three years later and periodically returns throughout her lifetime.
Cast[edit]
- Tilda Swinton as Alithea Binnie
- Alyla Browne as young Alithea Binnie
- Idris Elba as the Djinn
- Erdil Yaşaroğlu as Professor Gühan
- Sarah Houbolt as airport Djinn
- Sabrina Dhowre Elba as British Council lady
- Seyithan Özdemir as pale Djinn
- Aamito Lagum as the Queen of Sheba[1]
- Nicolas Mouawad as King Solomon
- Ece Yüksel as Gülten
- Matteo Bocelli as Prince Mustafa[1]
- Lachy Hulme as Sultan Suleiman
- Megan Gale as Hürrem
- Oğulcan Arman Uslu as Murad IV
- Kaan Guldur as young Murad
- Jack Braddy as Ibrahim
- Hugo Vella as young Ibrahim
- Zerrin Tekindor as Kösem
- Anna Adams as Sugar Lump
- George Shevtsov as the old storyteller
- David Collins as Ozmet the Jocular
- Burcu Gölgedar as Zefir[1]
- Vince Gil as old merchant
- Melissa Jaffer as Clementine
- Anne Charleston as Fanny
- Pia Thunderbolt as Orphan's Pa
- Anthony Moisset as hotel porter
- Danny Lim as storyteller with dog
Production[edit]
It was announced in October 2018 that George Miller had set his next directorial effort, described as ""epic in scope"" and expected to begin filming in 2019.[7] Idris Elba and Tilda Swinton were announced as cast members the same month.[8] The film is based on A. S. Byatt's short story ""The Djinn in the Nightingale's Eye.""[9]
In a July 2019 interview, Miller said that pre-production would begin in late 2019, and that filming would begin on March 2, 2020, between Australia, Turkey and the United Kingdom.[10][11][12] Filming was delayed due to the COVID-19 pandemic[13] and began in November 2020 in Australia.[14]
Release[edit]
In May 2020, Metro-Goldwyn-Mayer (via United Artists Releasing) acquired the film's North American distribution rights, with Metropolitan Filmexport and Sunac Culture handling distribution in France and China respectively.[15][16] Roadshow Entertainment handled the Australian distribution,[17] while Entertainment Film Distributors handled distribution in the United Kingdom.[18]
The film premiered at the 2022 Cannes Film Festival on May 20, 2022, where it received a six-minute standing ovation.[16][19] An activist protesting sexual violence perpetrated by Russian soldiers in Ukraine appeared at the premiere and stripped nude while screaming before being removed by Cannes security.[20] The film's first trailer was also released that day.[21]
The film's scheduled August 31 release was moved up to August 26.[22] It was released in Australia on September 1.
Reception[edit]
Box office[edit]
As of October 6, 2022[update], Three Thousand Years of Longing has grossed $8.3 million in the United States and Canada, and $8.9 million in other territories, for a worldwide total of $17.1 million.[6]
In the United States and Canada, it was released alongside The Invitation and Breaking.[4] It made $1.4 million on its first day[23] and went on to debut with $2.9 million from 2,436 theaters on its opening weekend.[24] Variety called it ""a terrible result for a movie that's playing in thousands of theaters across the country"", and noted that it would be one of the biggest box office bombs of 2022, with industry experts blaming lack of marketing and the wide-release strategy.[25] TheWrap, while acknowledging its box office underperformance, noted the film could still turn a profit for MGM after it went to streaming, as the company spent only $6 million on domestic distribution rights.[26] In its second weekend, the film made $1.5 million (and a total of $1.9 million over the four-day Labor Day frame), dropping 47.1% and finishing 13th.[27]
Critical response[edit]
On the review aggregator website Rotten Tomatoes, 71% of 238 critics' reviews are positive, with an average rating of 6.5/10. The website's critics consensus reads, ""Although its story isn't as impressive as its visual marvels, it's hard not to admire Three Thousand Years of Longing's sheer ambition.""[28] Metacritic, which uses a weighted average, assigned the film a score of 60 out of 100, based on 52 critics, indicating ""mixed or average reviews"".[29] Audiences polled by CinemaScore gave the film an average grade of ""B"" on an A+ to F scale.[23]
Peter Debruge of Variety said: ""These days, audiences are so savvy about the tricks at a filmmaker's disposal that the movie's greatest achievement is that it seizes our imagination (or perhaps that's our attention deficit disorder being so brusquely manhandled) and holds it for the better part of two hours, defying us to anticipate what comes next.""[30]
References[edit]
- ^ a b c d Utichi, Joe (May 17, 2022). ""Inside George Miller's 20-Year Quest To Make 'Three Thousand Years Of Longing', As 'Furiosa' Revs Her Engines – Cannes"". Deadline Hollywood. Retrieved May 17, 2022.
- ^ ""Three Thousand Years of Longing (15)"". BBFC. August 27, 2022. Retrieved August 27, 2022.
Cinema 107m 53s
- ^ Endre, Dora (March 21, 2022). ""Three Thousand Years of Longing: Everything We Know So Far"". MovieWeb. Retrieved May 18, 2022.
- ^ a b Rubin, Rebecca (August 24, 2022). ""Box Office: Box Office: Three New Movies Slink Into Theaters, With Limited Expectations"". Variety. Retrieved August 24, 2022.
- ^ ""Three Thousand Years of Longing"". The Numbers. Nash Information Services, LLC. Retrieved October 6, 2022.
- ^ a b ""Three Thousand Years of Longing (2022)"". Box Office Mojo. IMDb. Retrieved October 6, 2022.
- ^ Wiseman, Andreas (October 25, 2018). ""AFM Hot Pic: George Miller To Direct Movie Epic 'Three Thousand Years Of Longing', FilmNation To Launch Sales"". Deadline Hollywood.
- ^ Kit, Borys (October 25, 2018). ""Idris Elba, Tilda Swinton to Star in George Miller's Epic Love Story 'Three Thousand Years of Longing' (Exclusive)"". The Hollywood Reporter.
- ^ Mathai, Jeremy (May 18, 2022). ""Three Thousand Years Of Longing Footage Reveals First Look At George Miller's New Movie"". /Film. Retrieved February 22, 2022.
- ^ ""Three Thousand Years Of Longing"". Production List. January 13, 2020.
- ^ Thompson, Anne (July 23, 2019). ""George Miller Looks Back on 'Mad Max: Fury Road,' and Forward to More Furiosa"". IndieWire.
- ^ Fleming, Mike Jr. (December 6, 2019). ""George Miller On March Start Date For Next Film, More 'Mad Max', Defending Superheroes As Cinema & The Search For Depth That Makes Movies Like 'Fury Road' Unforgettable"". Deadline Hollywood.
- ^ Kay, Jeremy; Tutt, Louise (September 10, 2020). ""Cautious industry heads into TIFF with eyes wide open"". Screen Daily.
- ^ Wiseman, Andreas (December 9, 2020). ""George Miller's 'Three Thousand Years Of Longing' Underway In Australia; Oscar-Winning DoP John Seale Among 'Mad Max: Fury Road' Team Re-Uniting On Movie"". Deadline Hollywood.
- ^ Fleming, Mike Jr. (May 14, 2020). ""MGM Lands North American Rights On George Miller-Directed 'Three Thousand Years Of Longing' With Idris Elba & Tilda Swinton"". Deadline Hollywood.
- ^ a b Keslassy, Elsa (March 16, 2022). ""George Miller's 'Three Thousand Years of Longing' With Tilda Swinton, Idris Elba Set for Cannes (Exclusive)"". Variety. Retrieved March 16, 2022.
- ^ ""Three Thousand Years of Longing | Official Trailer | 2022 [HD]"". May 23, 2022. Retrieved May 23, 2022 – via YouTube.
- ^ ""Three Thousand Years of Longing | Official Trailer HD | Starring Idris Elba and Tilda Swinton"". May 21, 2022. Retrieved July 2, 2022 – via YouTube.
- ^ Sharf, Zack (May 20, 2022). ""George Miller's Visual Feast 'Three Thousand Years of Longing' Earns Six-Minute Standing Ovation in Cannes"". Variety. Retrieved May 20, 2022.
- ^ Wiseman, Andreas (May 20, 2022). ""Activist Removed From Cannes Red Carpet Following Naked Protest Against Sexual Violence In Ukraine"". Deadline Hollywood. Retrieved June 3, 2022.
- ^ Chapman, Wilson (May 20, 2022). ""George Miller Tells an Epic, Fantasy Love Story in 'Three Thousand Years of Longing' Trailer"". Variety. Retrieved July 15, 2022.
- ^ O'Rourke, Ryan (August 5, 2022). ""George Miller's 'Three Thousand Years of Longing' Release Date Moved Up"". Collider. Retrieved August 8, 2022.
- ^ a b D'Alessandro, Anthony (August 27, 2022). ""Horror Pic 'The Invitation' Leads Worst Weekend At This Summer's Box Office, All Pics Grossing $54M"". Deadline Hollywood. Retrieved August 27, 2022.
- ^ McClintock, Pamela (August 28, 2022). ""Box Office: 'The Invitation' Leads Horrifyingly Slow Weekend With $7M"". The Hollywood Reporter. Retrieved August 28, 2022.
- ^ Rubin, Rebecca (August 28, 2022). ""'The Invitation' Tops Box Office With $7 Million in Catastrophically Slow Weekend"". Variety. Retrieved August 28, 2022.
- ^ Welk, Brian (August 29, 2022). ""Why George Miller's 'Three Thousand Years of Longing' Tanked at the Box Office"". TheWrap. Retrieved September 2, 2022.
- ^ D'Alessandro, Anthony (September 3, 2022). ""Rebound Summer Loses Heat With Ice Cold Labor Day Weekend — Even With $3 Tickets On National Cinema Day; 'Top Gun: Maverick' Nearing $700M – Saturday AM Box Office"". Deadline Hollywood. Retrieved September 4, 2022.
- ^ ""Three Thousand Years of Longing"". Rotten Tomatoes. Retrieved September 6, 2022.
- ^ ""Three Thousand Years of Longing"". Metacritic. Retrieved September 5, 2022.
- ^ Debruge, Peter (May 20, 2022). ""'Three Thousand Years of Longing' Review: George Miller's Wishy-Washy Fantasy Has Serious Story Problems"". Variety. Retrieved August 24, 2022.
External links[edit]
- 2022 films
- 2022 fantasy films
- 2022 romantic drama films
- 2020s American films
- 2020s Australian films
- 2020s English-language films
- 2020s fantasy drama films
- 2020s romantic fantasy films
- American epic films
- American fantasy drama films
- American romantic drama films
- American romantic fantasy films
- Australian epic films
- Australian fantasy drama films
- Australian romantic drama films
- Australian romantic fantasy films
- Film productions suspended due to the COVID-19 pandemic
- FilmNation Entertainment films
- Films about wish fulfillment
- Films based on short fiction
- Films directed by George Miller
- Films produced by Doug Mitchell
- Films produced by George Miller
- Films scored by Junkie XL
- Films set in Istanbul
- Films set in London
- Films shot in Australia
- Films with screenplays by George Miller
- Genies in film
- Magic realism films
- Metro-Goldwyn-Mayer films",8
383,"Biomedical and electrical engineers at UNSW Sydney have developed a new way to measure neural activity using light – rather than electricity – which could lead to a complete reimagining of medical technologies like nerve-operated prosthetics and brain-machine interfaces.
Professor François Ladouceur, with UNSW’s School of Electrical Engineering and Telecommunications, says the multi-disciplinary team has just demonstrated in the lab what it proved theoretically shortly before the pandemic: that sensors built using liquid crystal and integrated optics technologies – dubbed ‘optrodes’ – can register nerve impulses in a living animal body.
Not only do these optrodes perform just as well as conventional electrodes – that use electricity to detect a nerve impulse – but they also address “very thorny issues that competing technologies cannot address”, says Prof. Ladouceur.
“Firstly, it’s very difficult to shrink the size of the interface using conventional electrodes so that thousands of them can connect to thousands of nerves within a very small area.
“One of the problems as you shrink thousands of electrodes and put them ever closer together to connect to the biological tissues is that their individual resistance increases, which degrades the signal-to-noise ratio so we have a problem reading the signal. We call this ‘impedance mismatch’.
Read more: New 'robotic snake' device grips, picks up objects
“Another problem is what we call ‘crosstalk’ – when you shrink these electrodes and bring them closer together, they start to talk to, or affect each other because of their proximity.”
“The real advantage of our approach is that we can make this connection very dense in the optical domain and we don’t pay the price that you have to pay in the electrical domain,” Prof. Ladouceur says.
In research published recently in the Journal of Neural Engineering, Prof. Ladouceur and fellow researchers at UNSW wanted to show that they could use optrodes to accurately measure the neural impulses as they travel along a nerve fibre in a living animal.
Scientia Professor Nigel Lovell, who heads the Graduate School of Biomedical Engineering and is Director of the Tyree Foundation Institute of Health Engineering, was part of the research team that sought to demonstrate this in the lab.
He says the team connected an optrode to the sciatic nerve of an anaesthetised animal. The nerve was then stimulated with a small current and the neural signals were recorded with the optrode. Then they did the same using a conventional electrode and a bioamplifier.
“We demonstrated that the nerve responses were essentially the same,” says Prof. Lovell. “There’s still more noise in the optical one, but that’s not surprising given this is brand new technology, and we can work on that. But ultimately, we could identify the same characteristics by measuring electrically or optically.”
New dawn for prosthetics
So far the team has been able to show that nerve impulses – which are relatively weak and measured in microvolts – can be registered by optrode technology. The next step will be to scale up the number of optrodes to be able to handle complex networks of nervous and excitable tissue.
Prof. Ladouceur says at the beginning of the project, his colleagues asked themselves, how many neural connections does a man or woman need to operate a hand with a degree of finesse?
“That you can pick up an object, that you can judge the friction, you can apply just the right pressure to hold it, you can move from A to B with precision, you can go fast and slow – all these things that we don’t even think about when we perform these actions. The answer is not so obvious, we had to search quite a bit in the literature, but we believe it’s about 5000 to 10,000 connections.”
In other words, between your brain and your hand there is a bundle of nerves that travels down from your cortex and eventually divides into those 5000 to 10,000 nerves that control the delicate operations of your hand.
If a chip with thousands of optical connections could connect to your brain, or some place in the arm before the nerve bundle separates, a prosthetic hand could potentially be able to function with much the same ability as a biological one.
That’s the dream, anyway, and Prof. Ladouceur says there are likely decades of further research before it’s a reality. This would include developing the ability for optrodes to be bidirectional. Not only would they receive and interpret signals from the brain on the way to the body, they could receive feedback in the form of neural impulses going back to the brain.
The long game: brain-machine interface
Neural prosthetics isn’t the only space that optrode technology has the potential to redefine. Humans have long fantasised about integrating technology and machinery into the human body to either repair or enhance it.
Some of this is now a reality, such as Cochlear implants, pacemakers and cardiac defibrillators, not to mention smart watches and other tracking devices giving continual biofeedback.
But one of the more ambitious goals in biomedical engineering and neuroscience is the brain-machine interface that aims to connect the brain to not only the rest of the body, but potentially the world.
“The area of neural interfacing is an incredibly exciting field and will be the subject of intense research and development over the next decade,” says Prof. Lovell.
While this is more fiction than fact right now, there are many biotech companies taking this very seriously. Entrepreneur Elon Musk was one of the co-founders of Neuralink that aims to create brain-computer interfaces with the potential to help people with paralysis as well as incorporating artificial intelligence into our brain activities.
The Neuralink approach uses conventional wire electrodes in its devices so it must overcome impedance mismatch and crosstalk – among many other challenges – if they are to develop devices that host thousands, if not millions, of connections between the brain and the implanted device. Recently Mr Musk was reported as being frustrated at the slow pace in developing the technology.
Read more: UNSW engineers win US Naval grant to develop brain-machine interface
Prof. Ladouceur says time will tell whether Neuralink and its competitors succeed in removing these obstacles. However, given that implantable, in vivo devices that capture neural activity are currently constrained to about 100 or so electrodes, there is still a long way to go.
“I'm not saying that it's impossible, but it becomes really problematic if you were to stick to standard electrodes,” Prof. Ladouceur says.
“We don't have these problems in the optical domain. In our devices, if there is neural activity, its presence influences the orientation of the liquid crystal which we can detect and quantify by shining light on it. It means we don't extract current from the biological tissues as the wire electrodes do. And so the biosensing can be done much more efficiently.”
Now that the researchers have shown that the optrode method works in vivo, they will shortly publish research that shows the optrode technology is bidirectional – that it can not only read neural signals, but can write them too.",2
384,"Seventeen years ago, just as the periodic cicadas were getting ready to arrive in droves in the eastern United States, Google announced Gmail, an exciting new email service. It had three key features: search, making it easy to find emails; storage, with what was then a mind-blowing 1 gigabyte; and speed, with emails threaded into conversations that ostensibly eliminated the need for cumbersome folders. Today, as the cicadas have seemingly taken over parts of the eastern U.S. once more, Gmail and Google’s G Suite, now used by more than 2 billion monthly active users around the world, still largely operate on these same basic principles.
Google figures only briefly in the The Filing Cabinet: A Vertical History of Information, a new book by Craig Robertson, an associate media-studies professor at Northeastern University, but it’s impossible not to think about the little search bars we live with every day while reading it. Like the once-ubiquitous 8-track tape, the filing cabinet was an essential marker of modernization that’s now considered clunky and outdated, with none of the mystique that some objects, such as vinyl records and windup clocks, have acquired over time. But Robertson’s captivating history makes the case that, when the filing cabinet was invented in the 1890s, it represented a new mode of efficient work. And today, its legacy informs some of our most innovative technologies, including search, Siri, and the way we organize the files on our computers.
Consider the rationale that one of Google’s co-founders, Larry Page, offered when Gmail was released. He cited the experience of one user who had asked whether there was a way to fix email: “She kvetched about spending all her time filing messages or trying to find them,” he is quoted as saying in the company’s original press release. “And when she’s not doing that, she has to delete email like crazy to stay under the obligatory four megabyte limit.” Page could have been describing the problems of the 20th-century office, which had found itself inundated with paper, as managers yearned for a simple way to file documents and find them again quickly.
A vertical filing cabinet, Robertson writes, “allowed a user to find papers ‘at a moment’s notice’ or ‘almost instantaneously.’” It has a couple of origin stories, and at least two inventors: the Library Bureau, a library-supply company that built a prototype based on an idea from a secretary in Buffalo, New York; and Edwin Seibels, an insurance sales agent who tried, and failed, to get a patent for his version. (The patent office considered it an idea, not a device.) With the right tabs and folders, a filing cabinet made the process of sorting and collating documents intuitive. Strategically, it was sometimes advertised as a machine of its own, alongside the then-nascent telephone and calculator: The turn of the century saw a flourishing of office innovations, and marketers made sure to use words such as equipment and appliances, rather than furniture. This naming convention plugged the humble filing cabinet into the world of modern technology, granting it the same sort of pizzazz that software developers today aim for in describing, say, a computational process as “artificial intelligence” rather than as a “computer program.”
The 20th century also saw an emergent information paradigm shaped by corporate capitalism, which emphasized maximizing profit and minimizing the time workers spent on tasks. Offices once kept their information in books—think Ebenezer Scrooge with his quill pen, updating his thick ledger on Christmas. The filing cabinet changed all that, encouraging what Robertson calls “granular certainty,” or “the drive to break more and more of life and its everyday routines into discrete, observable, and manageable parts.” This represented an important conceptualization: Information became a practical unit of knowledge that could be standardized, classified, and effortlessly stored and retrieved.
Take medical records, which require multiple layers of organization to support routine hospital business. “At the Bryn Mawr Hospital,” Robertson writes, “six different card files provided access to patient information: an alphabetical file of admission cards for discharged patients, an alphabetical file for the accident ward, a file to record all operations, a disease file, a diagnostic file, and a doctors’ file that recorded the number of patients each physician referred to the hospital.” The underlying logic of this system was that the storage of medical records didn’t just keep them safe; it made sure that those records could be accessed easily.
Robertson’s deep focus on the filing cabinet grounds the book in history and not historical analogy. He touches very little on Big Data and indexing and instead dives into the materiality of the filing cabinet and the principles of information management that guided its evolution. But students of technology and information studies will immediately see this history shaping our world today. Curious about the chemical composition of quartz? Google will show you the results in a series of stacked cards and provide tags and bits of structured data to help you sift through the results. Need to know the capital of Bhutan? Ask Siri, and a friendly female voice—most filing-cabinet clerks were women, the book reminds us—will do a quick scan of digital records and provide a helpful answer: Thimphu, situated in the western part of the country. (Full disclosure: The technology non-profit Meedan, where I oversee operations, receives funds from the Google News Initiative to support its work on information trust and quality, including a recent COVID-19 collaboration with the Australian Science Media Centre.)
But if the filing cabinet, as a tool of business and capital, guides how we access digital information today, its legacy of certainty overshadows the messiness intrinsic to acquiring knowledge—the sort that requires reflection, contextualization, and good-faith debate. Ask the internet difficult questions with complex answers—questions of philosophy, political science, aesthetics, perception—and you’ll get responses using the same neat little index cards with summaries of findings. What makes for an ethical way of life? What is the best English-language translation of the poetry of Borges? What are the long-term effects of social inequalities, and how do we resolve them? Is it Yanny or Laurel?
Among the many charming aspects of The Filing Cabinet are the vintage advertisements peppered across its pages. One Shaw-Walker campaign promised a filing cabinet “built like a skyscraper” (another modern marvel of the time) but simple enough for a child to operate. A Yawman and Erbe ad called files the “treasure chests of business” and showed a woman peering lovingly at a tidy set of tabulated folders. Then there are the peripherals. Remington Rand’s Multisort device, for example, claimed to help clerks sort hundreds of papers quickly before placing them in filing cabinets. The physical design of the filing cabinet itself, in other words, helped tell a story about modernization and ease of use.
These advertisements show most clearly how the architecture of the filing cabinet informs modern information organizing. We riffle through the rectangular boxes of search results and email with a swipe of our fingertips, the way we would with file folders. Browser tabs, the blessing and curse of web surfing today, help us sort content; the tabs display a brief summary of what’s inside. Modern search relies on a process called indexing, which aims to store and parse data to maximize information retrieval. Contemporary machine-learning systems tend to rely on data classification and cleaning done by a host of invisible workers, moving quickly through data like the office clerks of yesteryear. But the sheer scale of the effort makes these classification systems and algorithms difficult to comprehend.
The opacity of our information systems comes with a cost. It would have been absurd, in the early 20th century, to ask a file-cabinet worker for answers about matters that lie outside the scope of daily business affairs. If you wanted to pull up client correspondence, the file clerk had a file for you. If you wanted to understand John Locke’s theory of mind, they’d probably point you to the library. There, you would also encounter filing cabinets, with index cards organized by author, subject, or title, following the Dewey Decimal system; such a system didn’t replace books but rather made them easier and more efficient to locate. And books are just one part of a system of learning that might include other forms of media, discussion with peers and mentors, and life experiences. Unlike the granular certainty of information, the acquisition of complex knowledge is a multimodal, evolving experience, something modern information systems can only begin to support.
The coronavirus pandemic is just one potent example of this tension between information and knowledge. In the early days, it became clear that very little was clear about what was going on. Questions about COVID-19’s transmission, its prevention, and its range of symptoms were subject to further inquiry by scientists and researchers. Our information systems were rife not simply with misinformation—false or misleading information—but with what I call “midinformation” (note the d), or informational ambiguity based on scant or conflicting evidence, in many cases about emerging scientific knowledge. An information environment designed for certainty butted up against a hazier reality. Last spring, scientists were learning how, exactly, the novel coronavirus spreads. As a consequence of a reasonable level of concern, many of us regularly wiped down food packaging, mail, and countertops. By last May, the CDC had updated its guidelines, confirming that surface transmission is possible, but likely not the main way the virus travels. As the global-health scholar Emily LaRose has written, sometimes online information is partially true but misunderstood because it is incomplete or inadequately contextualized. Sometimes, science just takes time.
Can emergent knowledge coexist with an internet that privileges certainty? The mystery of periodical cicadas is an example of midinformation at work; knowledge about them evolves in fits and spurts as different broods appear every 13 or 17 years. We still don’t know why their life cycle follows such an odd pattern, or how they calibrate their internal clock. But we at least have new tools that could help collect and classify more data about them, and bring more people along in the process of learning more about these creatures. In the spring of 2019, Gene Kritsky, the dean of behavioral and natural sciences at Mount St. Joseph University, in Cincinnati, released the Cicada Safari app, to encourage citizen scientists to document cicadas around them. Key metadata—time, date, and coordinates—are captured, and the images are filed and tagged after being verified. Already, the app has yielded surprises for Kritsky and his team, such as the first-ever documentation of off-cycle emergence in certain broods. As he reminded me, even the large data set enabled by the app is simply establishing a baseline for 2038. Changes in geographic spread, declines in the population, the effects of deforestation—these are all potential observations we’ll have to wait another 17 years to study further.
As data points about cicadas improve over time, I imagine new mysteries will emerge. Such is the nature of knowledge—today, we live with more information at our fingertips than in all of human history, and yet our lives are filled with questions. And besides, entomological data may never quite explain the pathos of these creatures, which have symbolized death and rebirth for the ancient Chinese and ancient Greeks alike; the reason we find their red eyes so haunting; or the fact that some people find their song captivating and others find it annoying. Information collection and distribution today tends to follow the rigidity of cabinet logic to its natural extreme, but that bias leaves unattended more complex puzzles. The human condition inherently demands a degree of comfort with uncertainty and ambiguity, as we carefully balance incomplete and conflicting data points, competing value systems, and intricate frameworks to arrive at some form of knowing. In that sense, the filing cabinet, despite its deep roots in our contemporary information architecture, is just one step in our epistemological journey, not its end.
When you buy a book using a link on this page, we receive a commission. Thank you for supporting The Atlantic.",2
385,"Economic future of U.S. depends on making engineering cool
Oct. 24, 2022 Updated Mon., Oct. 24, 2022 at 6 p.m.
Joon Hyeong Park, an instructor at Purdue University, is reflected in a set of chips manufactured at the Birck Nanotechnology Center. (AJ Mast/Washington Post )
WEST LAFAYETTE, Ind. – On a recent afternoon, an unusual group of visitors peered through a window at Purdue University students tinkering in a lab: two dozen executives from the world’s biggest semiconductor companies.
The tech leaders had traveled to the small-town campus on the Wabash River to fix one of the biggest problems that they – and the U.S. economy – face: a desperate shortage of engineers.
Leading the visitors on a tour of the high-tech lab, Engineering Professor Zhihong Chen mentioned that Purdue could really use some donated chipmaking equipment as it scrambles to expand semiconductor education.
“OK, done. We can do that,” Intel manufacturing chief Keyvan Esfarjani quickly replied.
Just weeks before, his company broke ground on two massive chip factories in Ohio that aim to employ 3,000 people.
Computer chips are the brains that power all modern electronics, from smartphones to fighter jets.
The United States used to build a lot of them but now largely depends on Asian manufacturers, a reliance that the Biden administration sees as a major economic and national security risk.
Hefty new government subsidies aimed at reshoring manufacturing are sparking a construction boom of new chip factories, but a dire shortage of engineers threatens the ambitious project.
By some estimates, the United States needs at least 50,000 new semiconductor engineers over the next five years to staff all of the new factories and research labs that companies have said they plan to build with subsidies from the Chips and Science Act, a number far exceeding current graduation rates nationwide, according to Purdue.
Additionally, legions of engineers in other specialties will be needed to deliver on other White House priorities, including the retooling of auto manufacturing for electric vehicles and the production of technology aimed at reducing U.S. dependence on fossil fuels.
“This is recurrently one of the top, if not the number one, long-term concerns that (chip companies) have,” Mung Chiang, Purdue’s president-elect and former engineering dean, said in an interview.
As they embark on their expansion, “they care about the economics. They care about building it. They care about customer demand and competition.
“But recurrently, medium-to-long term, this is their number one concern … how can we build a much bigger pipeline right now of talent?”
Chip companies aren’t alone in worrying about the problem – or in looking to Purdue, one of the country’s biggest engineering schools, for answers.
Commerce Secretary Gina Raimondo, who is overseeing the chip subsidies program, visited campus last month to hear about the courses and labs Purdue is adding to rapidly expand semiconductor education.
Several Defense Department officials also have traveled lately to Purdue, located halfway between Chicago and Indianapolis, to discuss workforce training.
“We have become really popular here,” said Chen, the engineering professor, as she led the executives past a honeycomb sculpture of graphene, a substance Purdue faculty are studying as a material for building better electronics and batteries.
Sanjay Tripathi, a top IBM executive, called Purdue’s plans impressive but cautioned that the university can’t fill the gap alone.
“The question is, how do you take this model and scale it to other universities?” he said to the Washington Post at the end of the tour.
The Chips Act includes $200 million for worker training. Intel and the National Science Foundation also recently announced an effort, as have a number of universities and industry associations.
“Secretary Raimondo recognizes the significant need to expand the training pipeline to meet the Administration’s goals for CHIPS, EV production and other high-tech manufacturing investments,” the Commerce Department said in a statement.
“She is committed to working with the private sector and research institutions to come up with training programs – from GEDs to (doctorates) – that will benefit workers and strengthen our global competitiveness.”Engineer shortages have long plagued the U.S. tech sector, with Google, Apple and others complaining that immigration restrictions made it difficult to find employees.
They’ve spent years pushing for an expansion of the H1B visa program for highly skilled foreign workers, to little avail.
The semiconductor industry now faces additional obstacles stemming from the offshoring of chip manufacturing in recent decades.
As more production migrated to Asia, fewer U.S. students studied semiconductor engineering.
At the same time, the rise of social media and other software-focused companies shifted more students to those sectors, where starting salaries were often higher than in the chip business, engineers say.
Engineers in the United States have long enjoyed unemployment rates below those of other college grads – rates that are now hovering near all-time lows amid soaring demand for their skills.
“Last time I was at a football game there were ads all over the place for Rolls-Royce. They are looking for engineers,” Mark Lundstrom, Purdue’s interim engineering dean, said in an interview at Neil Armstrong Hall, named for the most famous of Purdue’s 27 astronaut graduates.
“Our engineering enrollments and our computer science enrollments have grown … but there is such a demand for these students.”
By rapidly expanding chip education, Purdue is aiming to graduate 1,000 semiconductor engineers annually as soon as possible – up from perhaps 150 a year today, according to engineering professors Muhammad Hussain and Peter Bermel, who are helping lead the effort.
Purdue is rolling out new courses and labs for undergraduates, a new masters program and a push to place students in chip internships during their first few years of college.
The university also invited semiconductor experts to join an advisory board to make recommendations on curriculum and training, which is what brought the chip executives to campus.
During their visit, the companies did their best to lasso students for future jobs, including Bika Carter, director of external research and development at chipmaker GlobalFoundries, who said she was “aggressively recruiting” a young man who sat next to her at a breakfast event.
“I got his resume, got him to the right manager and the manager this morning said he looks like a great candidate and we’re setting up an interview,” she said. “So I already feel successful.”
As company officials toured the chip-fabrication lab, they caught a glimpse of graduate students Sahana Thota, Manas Pandit and Uidam Jung working in white head-to-toe protective garb known as bunny suits – a cumbersome uniform needed to prevent strands of hair or specks of dust from damaging the delicate silicon wafers.
“You get used to it,” Pandit said, his face obscured by a mask and hood.
The students were wrapping up an afternoon of using sophisticated lithography machines to etch transistor patterns onto silicon wafers, a process through which dozens of individual chips are formed.
From time to time, instructor Joon Hyeong Park checked their work under a microscope to be sure the designs were developing correctly.
After peeling off layers of hoods, goggles, gloves, hairnets, jumpsuits and booties, the students talked about their future plans.
All three are from overseas – India and South Korea – and would like to pursue careers in semiconductors, most likely in the United States, if they can get work visas.
“I never imagined I would fabricate a Moscap and Mosfet in my life,” said Thota, waxing lyrical about different types of chips. “But this work is giving me enough opportunities to fabricate all my thoughts.”
Pandit said his older sister, also an engineer, inspired him to join the field.
It could be years before the students are ready to enter the workforce, but companies are already knocking on their doors.
Thota said she attended a career fair a few weeks ago and had several companies contact her about internships and a full-time job afterward.
A global shortage of chips in recent years has grabbed headlines and helped raise student awareness about the field, said Lundstrom, the engineering dean.
When Purdue held an evening session last month about semiconductor careers and its new chip courses, more than 600 students filled the lecture hall and spilled into an overflow crowd watching outside on their phones.
Hanging around after Professor Chen’s course on semiconductor devices on a recent afternoon (topic: what is a PN junction?), several undergrads said their interest in green energy drew them to semiconductors.
“I’ve always been interested in renewable energy efficiency,” said Joey Lopez, a junior from Schererville, Ind. “And basically, semiconductors have a key role in the power conversion for all of that.”
Nate Thompson, a junior from East Grand Forks, Minn., said he finds chips vital because they are key to improving computers.
“Everyone’s like, you know, go work for Google, you know, artificial intelligence. But … the level of computing power that we have right now, it’s not up to par with what the next step in AI needs,” he said.
Local journalism is essential.
Give directly to The Spokesman-Review's Northwest Passages community forums series -- which helps to offset the costs of several reporter and editor positions at the newspaper -- by using the easy options below. Gifts processed in this system are not tax deductible, but are predominately used to help meet the local financial requirements needed to receive national matching-grant funds.",4
386,"Javascript Required
To experience full interactivity, please enable Javascript in your browser.",7
387,"Quelques jours après le jet de soupe à la tomate sur une œuvre de Van Gogh, des activistes écologistes ont réitéré un acte quasi similaire dimanche dernier au musée Barberini de Potsdam en Allemagne, en recouvrant de purée de pomme de terre un tableau de Claude Monet. Dans un discours, ces jeunes activistes ont expliqué l'objectif de leur action, qui vise à opposer l'indignation liée à leur geste à celle liée aux menaces environnementales et climatiques qui pèsent sur la planète. « Est-ce qu’il faut lancer de la purée sur un tableau pour que vous écoutiez ? Ce tableau ne vaudra plus rien si nous devons nous battre pour trouver de quoi manger ». Selon les galeries, les tableaux, protégés par un vernis ou une vitre, sont restés intacts.
Cette action montre non seulement qu'une attaque contre un tableau célèbre fait plus de bruit dans les médias que la plupart des rapports alarmants sur le changement climatique, mais elle est aussi un nouvel exemple de la façon dont les jeunes se positionnent en première ligne de l'activisme écologique. La progression rapide du réchauffement climatique est désormais perçue comme une menace existentielle par les jeunes générations, alors que la fenêtre d'opportunité pour limiter le réchauffement à 2°C se referme rapidement.
Une étude publiée l'année dernière dans la revue The Lancet montre à quel point l'éco-anxiété s'est enracinée dans les jeunes générations. Sur les 10 000 jeunes de 16 à 25 ans interrogés dans dix pays, près de 70 % ont déclaré être « très inquiets » ou « extrêmement inquiets » du changement climatique. Ce chiffre était en moyenne encore plus élevé dans les pays du Sud en développement, qui devraient supporter la majeure partie des impacts négatifs liés au climat. Aux Philippines, 84 % des jeunes étaient extrêmement ou très inquiets à cet égard, suivis par 78 % en Inde et 77 % au Brésil. Au Nigeria, 51 % des jeunes étaient très inquiets, ce qui correspond davantage aux résultats observés au Royaume-Uni ou en Australie. Parmi les dix pays étudiés, c'est aux États-Unis que l'inquiétude était la plus faible, seulement 46 % - mais près de la moitié des jeunes de 16 à 25 ans sont néanmoins concernés.",0
388,"The Lifecycle of Software Objects
by Ted Chiang
Client: Ted Chiang, Subterranean Press
Scope: cover, interior design and illustration
Published: 2010
I was able to work with Ted Chiang again (after doing the collage illustrations for The Merchant and the Alchemist's Gate) on his longest work yet, The Lifecycle of Software Objects, published by Subterranean Press in July of 2010. Under Ted’s art direction, I did all of the interior design, cover layout for a limited and trade edition, and all of the map-like collage illustrations. New Zealand artist Christian Pierce did the cover illustration and 10 fantastic interior illustrations. A fun and challenging project.
The trade edition has a traditional full-color dust jacket, while the limited has no dust jacket and is stamped in 2 colors on the front, spine, and back. The interior of both books is printed in black and red inks.",8
389,"From 130 burnt out cars to Sheffield's best public park
How a 'slow firework display' is remaking the Manor
By David Bocking
These days, the best park in Sheffield is on the Manor. If you have Endcliffe or Millhouses park on your doorstep, chances are you don’t even know it exists. But every summer Manor Fields Park burns with a slow firework display of meadow flowers which the city’s better known green spaces can only dream about.
Heather is here as well, says part-time park manager Ted Talbot. He explains the urban heathland here might well date back to the time this was part of Sheffield’s deer park. “A few hundred yards away just over there, the ladies would stand on the top of Manor Lodge and watch the gentlemen kill their deer,” he tells me.
Record temperatures this month, and the downpours of recent winters, mean we need to think a bit more about what our urban parks are for in the years to come. After years of penny pinching and government austerity, tired-looking traditional parks may no longer fulfil the civic tasks required of them.
Many were originally designed simply as “ornamental places to promenade” says the original development officer for Manor Fields, Roger Nowell, who remembers counting 130 burnt-out cars left on the site off City Road during one year in the late 1990s, when work began to transform the old Deep Pits Park with the help of over £2 million worth of European and national regeneration grants.
Designing a park with tennis courts and acres of mown grass was not the plan. Instead, the design team looked at how the hillside park could help the whole city’s urban drainage system by using the site to capture water runoff from the surrounding estate.
They also wanted to consider the long history of the area, from deer park to farmland and coal mining to joy riding. Designing beautiful fences kept out joy riders and also helped to make the park so visually appealing that no one in their right mind would consider vandalism. They also made use of the location’s older history by harnessing the landscape of deer park and coal mines to turn the space into something stunning that locals would love. Walking through Manor Fields Park on a sunny day, I’d say they succeeded.
The 50-acre park includes a network of water channels leading from nearby housing estates into the grounds. Last week’s heat meant they were barely visible, but after heavy rain, when surface water gushes off local rooftops onto the street, it’s captured by channels and cleaned by vegetation and small ponds as it runs down the hill. If water levels are high (as they were after the deluges earlier this year), larger ponds start to appear on some of the banked flat ground used for football and picnics in the summer. This is an early and much larger version of the Sustainable Urban Drainage Schemes (SUDS) hidden under the Grey to Green flowers in the city centre.
The Manor Fields SUDS is designed to slow and clean the flow of surface water into the city and help prevent flooding by holding rain water on the hillside for much longer than it would take to travel to the Lower Don via roadways and drains.
The next step was to make sure the new park would be used by locals who’d feared to enter the former Deep Pits area plagued by joy riders and vandals. So Professor Nigel Dunnett and his landscape team from the University of Sheffield used the Manor as a test bed for trial seed mixtures for poor soil designed to transform roadside verges and neglected urban sites into months of colourful flowers: the “slow firework display” showing from now until September in several city centre pocket parks and Manor Fields.
Purists may question the use of garden seeds in what aims to be a haven to encourage local wildlife, since many ecologists insist Yorkshire wildlife thrives best on Yorkshire flowers .
But as Ted Talbot wanders round the park, he observes native birds foot trefoil, heather and rosebay willowherb mixing with cultivated daisies, the fluffy “lambs ear” or Staychs garden plant and the striking “giant white fleece flower” planted as an experiment to fight it out with brambles while flowering like mad.
“This is not a National Park or a protected landscape, so we can be a little more liberal with our use of garden flowers,” says Ted. He tells me that since we’re in an urban park setting, anything that provides food, shelter and nectar already starts to help insects, birds and mammals.
There’s one second big priority for modern urban parks. The international nature emergency — that is, the loss of species — means that insect numbers are plummeting and biodiversity is diminishing across the UK. This might not sound like a big deal…except that it might mean life or death for mankind. According to the zoologist and conservationist David Macdonald, a professor at Oxford University who was quoted in a Guardian essay on the topic, “Without biodiversity, there is no future for humanity.”
So, with this not-unimportant consideration in mind, does your local park enable a wide range of wildlife to live there? There were once coal mines, allotments and farms on Manor Fields, as well as places for medieval aristocrats to chase deer. As such, there are allotment plants and a host of farmland grasses trying to survive among the wild flowers and recent plantings.
“When we started it was a real mess which was hard to control, with brambles and bindweed and even some Japanese knotweed we had to get rid of,” says Ted. Adding muscular garden plants to the mix may provide “a bit of a mongrel,” he says. “But if you’re a butterfly or a bee or a vole in an urban context, you don’t mind. Or a human being, for that matter.”
A kingfisher has been seen in one of the park ponds, and buzzards fly overhead looking for voles and mice hiding in the long grass. Local residents love it too, judging by the number of people enjoying the park on the sunny weekday afternoon Ted shows me around. It’s easy to see why. As we wander through the gentle undulations of the landscape it seems astonishing to think the traffic and trams of busy City Road are just a stone’s throw away.
The type of activity often (but not necessarily correctly) associated with the “old Manor” hasn’t entirely disappeared though. But the nightime murder of Sheffield pizza chef Carlo Giannini in or near the park in May doesn’t seem to have changed the park’s image for locals, and families from the estate pass by as Ted excitedly identifies golden tansies and pale blue vetches shimmering in the summer breeze.
None of the pram walkers and afternoon strollers in Manor Fields will thank you for remembering Roy Hattersley’s infamous remark slating the estate as one of the worst in the country in the late 1990s, not least because it’s as much history now as the coal mines. “Someone used the word ‘gentrification’ about the area to me last week, and that’s the first time I’ve heard it mentioned,” says Ted. “Now is that a good thing or a bad thing? I don’t know. But I don’t think we should be down on people who are aspirational.”
Manor Fields won an international Green Flag Award again this year, and hosts a parkrun, along with cycling, walking and gardening groups admiring the park’s artworks and sculptures. The hills allow spectacular views across the city over a mixture of heathland, trees and meadows. If it was three miles to the west in Endcliffe or Millhouses park, there would almost certainly be tai chi classes here, and a little van serving oat milk lattes.
It looks like this because Manor Fields has a plan: right from the start it was managed by the Green Estate social enterprise, set up to look after Manor Lodge, Manor Fields and several other local green spaces to benefit the people of S2. Green Estate gets a council grant towards some of its landscape work, and also raises money from commercial landscape management, green waste disposal and venue hire. The Pictorial Meadows seed and flower planting enterprise now working all over the UK was also started on the Manor by the University of Sheffield and is now part of Green Estate.
In most cases, however, funding for parks is very much at risk at a time when we need them most, says Ted. The science is now showing that mixing socially in nice green spaces is better for our wellbeing and mental health than prescribed drugs. People used parks to stay sane during the pandemic, and in a heatwave, trees and transpiration from green grass and foliage cools a city’s air and ground.
After years of austerity to the public sector, local authorities inevitably focus on non-statutory services, like museums, libraries and parks, when they have to make cuts, says Ted.
“I see no practical evidence that this is turning into anything other than a catastrophic decline in the funding of parks and countryside. But it is an archaic approach if you do the maths on preventative health and keeping people out of the NHS.”
Like they do in Australia, he adds, where the health services of the state of Victoria fund local parks as they know they make the population fitter and healthier. It’s not rocket science, he tells me. The Duke of Norfolk may have donated Norfolk Park to Sheffield partly out of philanthropy to provide places for healthy activity in the outdoors.
“But it was also sensibleness,” says Ted. ""Because at the time the main other recreational activities were dens of iniquity, gin palaces and gambling, and we know the modern versions of those things are still pulling people away and ruining them.” I’m not sure I agree with Ted on the life-ruining properties of a quick tipple, but surely more parks can only be a good thing.
The people of the Manor are proud of their park, he says, but such places need to be commonplace across the country, and facing both nature and climate emergencies, we need them to arrive everywhere, and quickly.
“The civic reason for parks is the same as it’s ever been, since the Victorians started building parks as islands of nature in cities, instead of wall to wall buildings like Bladerunner.”
The Duke of Norfolk might have been baffled by Bladerunner, but he’d probably get the point of Manor Fields. Last year, a roe deer was spotted just a mile away down the hill. Maybe the wilder areas of the Manor estate will now encourage the original residents of the great Sheffield deer park to make their way home.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.
My partner and I live on the Manor estate and we pass through here regularly. I still think of it as ""Deep Pits"" as do many local 'natives' born and brought up on the estate.
There has been a bit of trouble occasionally (a man murdered recently) but that's nothing to do with the Park and the improvements Ted Talbot talked about and more to do with societal problems like drugs, flytipping, litter and antisocial behaviour
The real danger is exactly what Ted says it is. Money to get the site up to a standard everyone loves (from the EU please note all you Brexiteers), but no money to keep up that standard thanks to a decade plus of Tory austerity facilitated by our late unlamented Sheffield Hallam MP Sir Nick ""Mr Facebook"" Clegg.
Couldn’t believe it when I first did parkrun there earlier this year, great park. Hilly mind!",2
390,"I'm investing in Chipiron
Chipiron is a portable mini-MRI that is 10x cheaper and smaller than traditional ones. They are raising a seed round to reach their next technical milestones and produce clinical-level images.
Hi everyone,
I didn’t post for a while, as I was mostly managing my portfolio to minimize the impact of the downturn, and so didn’t have that many new deals to share.
My portfolio is currently up 7x overall, down from 7.7x in december. This is due to three companies doing downrounds or shutting down (all 3 consumer apps, two fintech and one social), and some vested tokens taking a hammering (I had sold all my liquid crypto assets back in december but still had plenty of vested tokens from private sales). My deeptech portfolio is doing great however, with some great uprounds despite the crisis.
I will be investing actively again now, so you can expect more regular updates!
Chipiron
Today’s deal is Chipiron, a portable mini-MRI that is 10x cheaper and smaller than those currently used by hospitals and clinics.
MRIs work by measuring the changes in quantum states of atoms when exposed to a magnetic field (this is called the “signal”). The issue however is that this signal is extremely faint and therefore prone to interference from the surrounding environment (called “noise”). To improve the quality and resolution of the images, traditional MRIs use extremely powerful magnets to increase the signal, thereby making the noise appear small in comparison. These powerful magnets are precisely why MRIs are so big (~5 tons) and expensive (~€1M per machine), and thus why they are so scarce (2/3 of the world’s population does not have access to MRIs). Making MRIs smaller and cheaper is thus necessary to democratize this medical technnology globally.
Many companies are trying to solve this problem by using smaller magnetic fields and augmenting the images using AI to overcome the lower resolution. Hyperfine is the leader in this space, and is on track to make $12M in revenue after only 2 years of commercializing their machine. The trouble with this approach however is that it only kind of works, and doesn’t produce images as good as doctors would want.
Chipiron however does it differently: rather than trying to augment the signal with AI (which they still do anyways), they actually build better hardware that combines state of the art quantum sensors called SQUIDs with antennas inspired from space telescopes. Together with cutting edge cryogenics and magnetic shielding, this enables them to both increase the signal AND reduce the noise, yielding a much better signal-to-noise ratio at very low magnetic fields (about 1/3000th of what is routinely used in hospitals).
Here is a video of their lab showing the tech in action (warning: science inside!):
And this is what they are expecting the images produced to look like once the technology matures (“Injected 3T” is the highest performing MRI that requires injecting chemicals into the patient’s bloodstream):
From a market perpective, they don’t have to actually compete with existing MRIs sold to hospitals to be successful. They can simply go for unserved markets that can’t afford the price or size of traditional MRIs, for example in small clinics, doctor offices or developing countries. Icing on the cake? Their technology can even be used to diagnose … batteries! So there is room for diversification down the line.
All this was masterfully executed with only 7 people (of which 6 are PhDs) in just over a year, with very little funding. When you talk to the founders you will understand why: Evan the CEO is an AI engineer who has been digging in that space for years, while Dimitri the CTO is an incredible physicist that explains things so well that it makes you feel like an expert yourself!
They raised a €1M pre-seed a year ago (I was one of their first investor) and are now raising a €6M seed round in which I will be investing again. Chipiron is based in Paris, but Evan is currently in the US fundraising if you want to meet him in person there.
I think you get the point: this is a super deeptech, long term play that has the potential to disrupt a massive industry while making the world’s population healthier. The kind of stuff I like to invest in!
Rand
Thanks for reading Deeptech Deals! Subscribe for free to receive deals and insights on deeptech and crypto.
Create your profile
Only paid subscribers can comment on this post
Check your email
For your security, we need to re-authenticate you.
Click the link we sent to , or click here to sign in.",3
391,OpenStreetMap 2012 2012 2022,4
392,"Electric vehicles appear to be finally hitting their stride. Six major auto companies, including Ford and GM, are now planning to completely phase out manufacturing of gas-powered vehicles in favor of EVs by 2040. In Europe and China, sales are on a tear; in the former, sales have spiked 60 percent since 2016, and Norway may be on track to completely end sales of new gas vehicles by 2025. Even in the U.S., where electric vehicles have been slow to catch on, sales nearly doubled last year. As with the adoption of any new technology, expect some growing pains. In particular, consumers continue to have anxiety about vehicle range, and state and federal governments have been slow to build adequate fast-charging infrastructure to ease their concerns. UM-Dearborn electrical engineering doctoral student Mansi Girdhar says we should also have our eye on the potential cybersecurity risks from EVs. The reason? Because EVs have to connect to electrical infrastructure to charge, they serve as a possible access point for hackers to infiltrate vehicle computer systems, steal our credit card information, and even launch a large-scale attack on the grid.
When Girdhar began searching for a topic for her dissertation research, she found lots of work on vehicle security and grid security, but interestingly, not that much on the potential weak link between the two. However, EV chargers, in many ways, are a perfect target for hackers. Because they’re so new, there aren’t universal standards for their manufacturing, let alone for their cybersecurity frameworks. And because they connect technologies that are so critical to our daily lives, they could be a beachhead for all kinds of attacks. In a best case scenario, a hacker might infiltrate a charging station, which typically have built-in payment processing systems, just to steal your credit card information. But in more serious cases, Girdhar says someone could use an insecure charging station to attack your vehicle, directly compromising its safety. In the worst case scenario, a compromised EV charger could even be used to launch an attack that cascades across the electric grid, causing power disruptions to millions of people.
Girdhar’s work is focusing on a couple important aspects of the problem. First, she’s taking a deep look at how charging stations actually connect to vehicles when they’re charging to suss out what kind of vulnerabilities exist. When you charge your EV, it typically involves several of your car’s on-board electronic components and controllers, which coordinate with each other using something called a Controller Area Network (CAN). It’s a communications system that’s vital to most modern cars and is thus preferred by the auto companies. “But the problem is, CAN is not very secure,” Girdhar says. Lots of work has been done, in fact, documenting how vulnerable these intra-vehicle networks can be, an area which Girdhar is now contributing to. By documenting the grid-charger-vehicle network’s most serious potential vulnerabilities, Girdhar says manufacturers and researchers can start coming up with better defense strategies.
In fact, a second piece of Girdhar’s work is taking a look at that. “We’re actually not assuming that we can design a charger that is hack proof — we’re not trying to make it immune,” she says. “Instead, we want to be able to detect an attack as it’s happening, and identify what kind of attack, so we can then deploy the correct defense in real time.” To do this, Girdhar says they’ll be using an approach called anomaly detection. This involves using machine learning to develop a fingerprint of what normal computing activity looks like when a vehicle is charging, so the system can then identify when something appears out of the ordinary.
Girdhar says her research has also inspired a whole new path for her career. Her previous master’s work was in 5G wireless communications, but she’s liking this subject so much, she says her new goal is to pursue an academic career focusing on the cybersecurity of electric vehicles. With EVs charging into the future, we’re glad she’s part of the effort.
###
Story by Lou Blouin",2
393,"- Publisher: Gallery / Saga Press
- Editor: Joe Monti
- Available in: Hardback, Paperback, Ebook, Audio
- ISBN: 9781481424363
- Published: October 4, 2016
From the publisher:
Bestselling author Ken Liu selects his multiple award-winning stories for a groundbreaking collection—including a brand-new piece exclusive to this volume.
With his debut novel, The Grace of Kings, taking the literary world by storm, Ken Liu now shares his finest short fiction in The Paper Menagerie and Other Stories. This mesmerizing collection features many of Ken’s award-winning and award-finalist stories, including: “The Man Who Ended History: A Documentary” (Finalist for the Hugo, Nebula, and Theodore Sturgeon Awards), “Mono No Aware” (Hugo Award winner), “The Waves” (Nebula Award finalist), “The Bookmaking Habits of Select Species” (Nebula and Sturgeon Award finalists), “All the Flavors” (Nebula Award finalist), “The Litigation Master and the Monkey King” (Nebula Award finalist), and the most awarded story in the genre’s history, “The Paper Menagerie” (The only story to win the Hugo, Nebula, and World Fantasy awards).
Insightful and stunning stories that plumb the struggle against history and betrayal of relationships in pivotal moments, this collection showcases one of our greatest and original voices.
The audiobook version is narrated by Corey Brill and Joy Osmanski. Here’s a sample.
Here’s my round-up post of reviews, essays, and interviews about the book.
Praise for The Paper Menagerie and Other Stories
I know this is going to sound hyperbolic, but when I’m reading Ken Liu’s stories, I feel like I’m reading a once-in-a-generation talent. I’m in awe.
– Jamie Ford – NYT bestselling author of Hotel on the Corner of Bitter and Sweet
[A] brilliant, substantial, yet somehow still all-too-short collection of stories and novellas… It’s bursting with stories yearning to be told to everyone, and it’s a volume that absolutely everyone should read.
– Andrew Liptak writing for The B&N Sci-Fi & Fantasy Blog
These remarkable stories highlight Liu’s themes of family, love, and politics and gathered in one collection pack an even bigger punch. Those who revere shorter speculative works will definitely want this book.
– Library Journal starred review
Gracefully written and often profoundly moving, these stories are high-water marks of contemporary speculative fiction.
– Publishers Weekly starred review
I have never been so moved by a collection of short fiction. I was at times afraid to read more.
– Amal El-Mohtar writing for NPR
Full table of contents:
- Preface
- The Bookmaking Habits of Select Species
- State Change
- The Perfect Match
- Good Hunting
- The Literomancer
- Simulacrum
- The Regular
- The Paper Menagerie
- An Advanced Reader’s Picture Book of Comparative Cognition (previously unpublished)
- The Waves
- Mono no aware
- All the Flavors
- A Brief History of the Trans-Pacific Tunnel
- The Litigation Master and the Monkey King
- The Man Who Ended History: A Documentary",8
394,fishdraw: procedurally generated fish drawings. Lingdong Huang 2021,2
395,"Overview
Facilitation card decks give you an entire facilitation toolbox in your pocket.
Because these decks remind us of card games, they feel like play. Participants leave their work personas behind and embrace silliness, vulnerability, and fun.
Some decks help you plan your entire workshop flow. Some are great for prompting meaningful conversation and making every voice heard.
Others help you pivot during a session if needed with a quick activity. Some cards are very methodical and structured, while others are versatile—encouraging playfulness and creativity.
To help you pick the best deck for your workshops, we’ve gathered recommendations from the Butter Community that cover:
- Session design
- Creativity and ideation
- Innovation and strategy
- Starting conversations and improving team dynamics
- Debriefing and reflection
We'll be keeping this post updated, so make sure to bookmark it and check back any time you need a little creative inspiration!
And if you want to take these decks from the physical to the virtual, we’ve introduced flashcard decks as a tool in Butter—so you can pre-load your favorite cards and activities to your virtual sessions and use them whenever you want.
Card Decks for Session Design
All the decks in this category make it easier to plan your next workshop or to adapt your workshop on the fly by giving you activities, frameworks, and methodologies for an awesome session.
1. Facilitator Cards
Available at: Facilitator.cards
Deck type: Session design
Facilitator Cards is a 60-activity card deck designed by Meg Bolger and Sam Killermann of Facilitating.XYZ.
Facilitator Cards offer many activities that make it easy to plan your workshops, but they’re also helpful in-session when something unexpected happens and you need an activity to pivot on the spot.
In addition to the physical deck, they also have Virtual Facilitator Cards.
😍 Why we love them: Facilitator Cards are categorized into four color-coded categories (Emotion, Ideation, Clarification, and Execution), making it super easy to pick a relevant activity on the fly!
📒 Further reading: How to increase workshop participation with Facilitator Cards & Butter
2. Workshop Tactics
Available at: Pipdecks.com
Deck type: Session design, ideation, strategy
Designed by Charles Burdett, Workshop Tactics is a curated list of the best agile and design-thinking workshop techniques for product teams.
You can use each tactic independently as a mini workshop, or combine multiple cards and tactics to plan entire sessions.
In the deck, you'll find creative ideation workshops, energizers, icebreakers, retrospectives, root-cause analysis workshops, decision-making matrices, and core facilitation techniques.
😍 Why we love them: Their Workshop Strategy System decision tree helps you choose the right workshop at the right time. It’s a great place to start if your team needs to get unstuck.
3. Liberating Structures Cards
Available at: TheLiberators.com
Deck type: Session design
Liberating Structures are built on the idea that conventional structures are either too inhibiting (e.g., presentations and status reports) or too disorganized (e.g., brainstorms). Liberating Structures are intentionally simple activities that help you get more out of your group.
Created by Holisticon, Liberating Structures are easy-to-learn microstructures that enhance relational coordination and trust, quickly fostering lively participation for groups of any size.
For example, the Wise Crowds Liberating Structure provides a session structure where some participants act as consultants and others act as clients, allowing you to learn from the collective expertise of a group.
Each deck comes in a paper box with 33 cards, one for each Liberating Structure. It also includes four cards with additional information.
You can also access all Liberating Structures for free at LiberatingStructures.com.
😍 Why we love them: Because they help you create strings and combine Liberating Structures, these cards make it easy to design full workshops, team meetings, or scrum events.
4. Foresight Cards
Deck type: Session design, strategy
Foresight Cards are used to assess your external environment—for example, to discuss uncertainties, stress test a business model, or to create awareness of past, current, and future changes.
This pack of cards contains 125 external forces from macro/contextual environments. The forces are classified based on STEEP categories (social, technological, economical, environmental and political).
These cards can be used for many types of strategy sessions, including SWOT analysis, Porter analysis, business model, system diagram, and scenario planning.
The deck also contains three complete workshops:
- create awareness
- stress testing business models
- determine key uncertainties for scenario planning
😍 Why we love them: The cards are all multilingual, so each card features English, Nederlands (Dutch), Deutsch (German), and Español (Spanish).
5. Model of Care for Co-design Cards
Available at: beyondstickynotes.com
Deck type: Session Design, team dynamics and cohesion, wellbeing
If you want to be more inclusive in your co-design sessions, consider using this thoughtful deck from Kelly Ann McKercher.
As Kelly Ann explains in their blog about the Model of Care for Co-design, “We need to work harder to create and maintain safety with traumatised and historically under-invested in groups of people. Without safety, it's hard (if not impossible) to join-in, stay included and express our creativity.”
This deck starts with the belief that we need to care for each other during co-design activities, and then turns this philosophy into simple prompts that promote care during the co-design process.
😍 Why we love them: The 16 cards offer concrete tips that encourage you to care of your participants’ needs by creating a safe space together before jumping straight to doing. The cards are distributed in two categories: “Before togetherness” and “Together and beyond”.
6. Transform Deck
Available at: untoldplay.com
Deck type: Session design
The Transform Deck, designed by Untold Play founder Terry Pearce, was made to transform your learning content into engaging activities.
The 45 cards are sorted into five categories:
- Assess: Help learners assess a variety of options
- Arrange: Help learnings arrange or structure new materials
- Create: Exercises to develop new ideas and ways of thinking
- Solve: Activities and tools to integrate puzzles and challenges
- Apply: Tools to help participants apply learning to their real world
😍 Why we love them: While the deck won't create your training for you, it will provide inspiration and streamline your workshop design process. Plus, each card comes with concrete tips on how to use each method effectively.
7. WonderCards
Available at: petranovskaja.com
Deck type: Session design
Speed up your workshop preparation time and adapt on the fly with this deck by Nadja Petranoskaja. The 40-card deck comes with warm-ups, models, exercises, energizers, and workshop formats for groups of any size.
The deck is great for designing any workshop, training, or team development activity.
😍 Why we love them: The deck is available in both Tarot and Pocket size, so you can choose whether you prefer visibility or mobility! Plus, the cards are also available in German here.
8. MethodKit for Workshop Planning
Available at: methodkit.com
Deck type: Session design
The MethodKit for Workshop Planning gives you 60 illustrated cards to plan your workshops. You can use them for brainstorming, planning, discussing, prioritizing, and evaluating your work.
Each of the 60 cards has a key issue to keep in mind when planning a workshop. For example, there’s a card for props and materials, a card for facilitation styles, and a card for creating an engagement atmosphere.
The deck is primarily intended for helping you plan workshops as a group, but the cards are also useful as an individual facilitator as they give you a visual overview of all the building blocks of your workshop.
😍 Why we love them: MethodKit also released the digital version of these cards, which you can download here, available in 10 languages. But wait, that’s not all! MethodKit has this great article on all the possible ways you can use the card decks in your workshops.
Card Decks for Ideation and Creativity
Need to spark your next great idea? Need to get people in the creative zone before a larger session? These decks are all designed for next-level brainstorming and ideation.
9. 75 Tools for Creative Thinking
Available at: 75toolsforcreativethinking.com
Deck type: Session design, ideation
This set of cards takes you through the entire ideation process with fun and out-of-the-box activities. They can be used by anyone who’s looking for some creative inspiration.
The deck takes you through five stages. You start with activities to explore and better understand the challenge you’re facing. Then, you can collect insights and gather feedback from participants to better understand their needs. You can then structure these insights before moving on to ideation. Finally, finish by defining the criteria and evaluating ideas to pick the best ones.
😍 Why we love them: In addition to the physical card deck, 75 Tools For Creative Thinking is also available as an iPad and iPhone app.
10. IDEO Method Cards
Deck type: Session design, ideation
IDEO Method Cards are meant for inspiring designers looking for a creative spark in their work. Each of the 51 cards describes one ideation method and includes a brief story about how and when to use it.
It's not a how-to guide—it's a design tool meant to explore new approaches and help you develop your own. Use the deck to get a fresh perspective, inspire a team, turn a corner, or try a new approach.
😍 Why we love them: The cards are divided into four categories: Learn, Look, Ask, and Try, making it easy to choose the right cards for your session.
11. Triggers Ideation Cards
Available at: trytriggers.com
Deck type: Session design, ideation, strategy
Triggers has 14 different decks available, so it was hard to choose just one. They have decks on Brand Strategy, Business Design, Human-Centric Design, Innovation, and more. They come in a variety of packages, which you can check out in their online shop.
If you’re a design agency that works with all kinds of different creative projects, the Complete Triggers Collection contains all of their decks and will help you with any type of ideation project.
This pack includes 780 Triggers cards (60 per deck) with questions that will help you generate ideas as an individual or with your team.
😍 Why we love them: Triggers has a deck for nearly every design use case, so it’s a great place to start!
12. Creative Whack Pack Deck
Available at: creativewhack.com
Deck type: Ideation, creativity
Designed by Roger von Oech from Creative Whack Company, the 64-card Whack Pack deck is packed with stories, examples, and questions that are designed to “whack” you out of your usual ways of thinking and to inspire your creativity.
The deck is divided into four different suits, each representing roles or creative types: Explorer, Artist, Judge, and Warrior. Some cards show you how to discover new information, others offer decision-making advice, and others give you techniques on how to come up with new ideas.
If you’re looking for a way to stimulate thinking in workshops, give these a try!
😍 Why we love them: Beyond the activities on the cards, the hand-drawn illustrations on the cards are enough to jog your mind. The deck is also available as a mobile app, where you can find the 64 original cards, plus 20 extra Heraclitus strategies to stretch your thinking even further.
13. Know Brainer
Available at: thesolutionpeoplestore.com
Deck type: Ideation
Designed by Gerald Haman, the Know Brainer cards help your workshop participants navigate the “Accelerated Innovation” process, which is broken into four stages:
- Stage 1: Investigate needs
- Stage 2: Create ideas
- Stage 3: Evaluate solutions
- Stage 4: Activate plans
Each stage has five stimulus types designed to spark innovation:
- 10 Questions to provoke creative thinking
- 10 Nouns to make you think about the “what” and the “who”
- 10 Verbs to put your focus on actions and thinking patterns
- 5 Quotes to inspire you
- 8 Images to spark your imagination and help you visualize ideas
😍 Why we love them: In addition to having an awesome pun for a name, this deck is versatile. It can be used in innovation and creativity sessions, for facilitating change and growth, in coaching sessions, or even as a tool to help you plan more creative products, services, brands, events and basically anything else!
14. Free the Genie
Available at: ideachampions.com
Deck type: Ideation, creativity
Designed by Mitch Ditkoff, Free the Genie is a 55-card deck that helps you bring something new and extraordinary into your life, business, or the world.
The deck gets its name from its purpose: it’s a personal genie for open-minded thinkers. It’s a 24/7 oracle that’s always ready to help you realize your vision.
The cards are divided into five categories: Attend, Intend, Suspend, Extend, and Connect. You can use them as an individual or as a team to “seek counsel, clarity, and increased personal insight.”
These cards lift you up to higher ground to a place where you’ll find creativity, inspiration, breakthrough ideas, and commitment to those ideas.
😍 Why we love them: You can also use the deck as a team card game. The deck can help your team brainstorm, solve problems, and accelerate the innovation process.
15. ThinkPak
Available at: amazon.com
Deck type: Ideation
ThinkPak was designed based on the idea that every new invention is just a modification of something that already exists. So coming up with your next great idea is about seeing your problem in a new light.
Designed by Michael Michalkom this deck gives you a step-by-step methodology to coming up with new ideas, products, services, processes, and more.
You can shuffle, mix, and match the cards to generate new insights, and then use the deck’s critical evaluation techniques to distill your ideas into realistic solutions.
Shuffle, mix and match the cards to spark fresh insights, then use the critical evaluation techniques to test and refine your creative ideas into realistic and feasible solutions.
😍 Why we love them: The cards follow the famous SCAMPER creativity method coined by Bob Eberle. This theory assumes that all innovative breakthroughs come from at least one of these principles:
- Substitute something
- Combine something
- Adapt something
- Modify or magnify something
- Put something to another use
- Eliminate something
- Reverse or rearrange something
16. Design Kit Travel Pack
Available at: designkit.org
Deck type: Ideation
Need some design inspiration? Created by IDEO.org, the Design Kit Travel Pack is a set of “bite-sized tools to spark creativity and collaboration” based on human-centered design principles.
This 32-card deck is full of exercises that help creatives shift their thinking about a project to be able to move it forward. The deck helps you overcome roadblocks to deliver top-notch products and services.
The deck is divided into three sections to help you:
- Find inspiration
- Take bigger creative risks
- Test your ideas in the real world
😍 Why we love them: The cards are beautifully designed! Each colorful card has a hand-drawn illustration to give you a little extra design inspiration.
17. Make It Pop
Available at: makeitpopgame.com
Deck type: Ideation, conversation starter
“Let us help you unlock your inner creative baddass!” That’s the website tagline for Make It Pop, and we couldn’t say it any better ourselves.
Make It Pop takes inspiration from Cards Against Humanity and turns it into a framework for coming up with unconventional design tasks.
It’s very simple: choose a black task card (e.g. Design a landing page for…), then choose a white or red client card (e.g. Bob Ross), and get started!
😍 Why we love them: This activity makes an awesome icebreaker for designers or creatives that gets them in the right mode of thinking rather than defaulting to the usual “get to know you” questions.
18. Oblique Strategies
Deck type: Ideation, creativity, conversation starter
We’re throwing it waaaay back with this deck.
Back in 1975, artist Peter Schmidt and musician Brian Eno created the original Oblique Strategies card deck. They drew on their own work as artists to develop a deck of 100 cards, each of which suggests a course of action or thinking to help you in any creative situation.
The deck is brutally simple. Each card has a cryptic phrase or remark to prompt ideation or brainstorming activities.
😍 Why we love them: The prompts in this deck feel constraining, but these constraints can be mentally freeing. By narrowing your thinking down with constraints, it actually becomes easier to see a clear path to a solution. Limitation can be very useful!
19. Killer Questions Card Deck
Available at: innovation.tools
Deck type: Innovation, creativity
The Killer Questions deck is made to help you come up with killer ideas! Whether you use it alone or as a team, you can use the 40-question deck to:
- Help you look at a situation in new light
- Trigger a brainstorming or ideation session
- Practice your creativity
- Launch or rebrand a business, product, or service
The deck was created by Phil McKinney, author of Beyond the Obvious: Killer Questions That Spark Game-Changing Innovation, and the host of the podcast Killer Innovations.
😍 Why we love them: The deck has 40 question cards, but each question card comes with a number of extra so-called “sparking” questions to help you dig deeper for ideas as you go exploring. So there’s lots of value in a small deck.
20. SPARK
Available at: lmi-academy.com
Deck type: Creativity, conversation starters, team dynamics and cohesion
If a picture’s worth a thousand words, then you’re getting a quarter of a million words in this deck!
The Spark deck has over 250 photographs taken by over 100 photographers. Each photo was chosen to spark feelings, memories, and sensations. The pictures depict concepts, metaphors, and stories to inspire self-reflection, ideation, communication, and even relationship building.
😍 Why we love them: The deck also comes with an image appreciation technique card that gives you practical tips on how to “read” the images in the deck.
21. Zig Zag Creativity Cards
Available at: keithsawyer.com
Deck type: Innovation, creativity
The Zig Zag deck is inspired by scientific research on how people create. The deck is based on Dr. Keith Sawyer's book, Zig Zag: The Surprising Path to Greater Creativity.
The deck’s 52 techniques are grouped into eight powerful and yet simple steps:
- ASK: How to Ask the Right Questions
- LEARN: Prepare Your Mind
- LOOK: Spot the Answers Around You
- PLAY: Imagine Possible Worlds
- THINK: How to Have Great Ideas
- FUSE: How to Combine Ideas
- CHOOSE: Make Good Ideas Even Better
- MAKE: Make Your Ideas Visible.
To develop these techniques, Sawyer explored the stories and habits of exceptional creators as well as the science on everyday creativity. He explored how creative people question assumptions, get beyond their creative blogs, and how they deal with adversity.
😍 Why we love them: This deck is versatile, as you can use the cards for solo games, group games, or as facilitation techniques.
22. A Few Minutes of Design
Available at: amazon.com
Deck type: Creativity, innovation
Desinged by Emily Campbell, this colorful, handy deck gives you 52 exercises to get your creative juices flowing at the start of a new design project or to help you get unblocked in a project you can’t quite finish.
Each exercise digs into the small details of great design. For example, how could you establish a pattern or continue a series? Or how could you say something without words?
These cards are sometimes playful, sometimes challenging, but always inspiring!
😍 Why we love them: The activities are practical and hands on, but can all be done in under 15 minutes! They’re the perfect way to kick off a design workshop or ideation session.
Card Decks for Innovation and Strategy
These cards challenge participants’ ways of thinking, stimulate innovation, and help you evaluate your strategic choices.
23. Innovation Tactics Cards
Available at: doblin.com
Deck type: Innovation, strategy
Doblin’s Innovation Tactics Cards are based on their Ten Types of Innovation framework. Their model breaks innovation into three groups:
- Configuration: Profit Model, Network, Structure, Process
- Offering: Product Performance, Product System,
- Experience: Service, Channel, Brand, Customer Engagement
To help you turn these innovation categories into business ideas, they’ve created over 100 Innovation Tactic cards to inspire ideation activities.
😍 Why we love them: If you’re looking for specific, actionable tactics rather than abstract prompts, this is your deck. The tactics in this deck are very specific, so they’re the perfect companion for your product and service innovation sessions or business strategy workshops.
24. Myndset Cards
Available at: myndset.cards
Deck type: Innovation, strategy
The Myndset Cards game is a 30-minute workshop meant to inspire innovative ideas backed by emotions.
The deck consists of five decks:
- The first deck helps you develop a vision of how you want to achieve your goal
- The second deck focuses on trends and technology that might help you
- The third deck focuses on understanding your target audience
- The fourth deck focuses on the emotions you want your audience to feel
- The fifth deck helps you formulate your pitch
😍 Why we love them: Myndset Cards come with a companion app that lets you scan your Myndset cards to find more detailed information and additional content for each card. Plus, the team behind the product made a free Udemy course explaining how to best use the card deck.
25. FUTREP Cards
Available at: artefactshop.com
Deck type: Strategy, futurecasting
If you want to work out your product design skills, FUTREP Cards are a great place to start.
By pulling combinations of characters, objects, systems, and environments from the deck, you’ll be given a scenario for which you’ll have to design a response.
The cards were designed with flexibility in mind. Rather than giving you long, drawn-out scenarios, they provide you with seemingly unconnected concepts that stretch you to your creative limits.
😍 Why we love them: The cards are cut to the same dimensions as their Artefact Plus cards—blank, colored cards that allow you to visually capture your thoughts on the cards, and design your own processes and prompts from scratch.
26. Kickstart Creativity
Available at: amazon.com
Deck type: Innovation, creativity
Kickstart Creativity is a 50-card deck that’s designed to prompt unexpected ways of thinking.
The cards are divided into three categories: Intention, Action, and Perspective. The action cards teach you new skills, perspective cards make you look at the world in a novel way, and intention cards help you make more meaningful decisions.
At the start of a personal challenge or group project, you can draw three cards from the deck and then reflect on how they relate to your current challenge.
😍 Why we love them: You can also use cards from the deck as a daily creativity booster. For example, they recommend drawing one card at random to start your day for a quick hit of inspiration with your coffee.
27. Innovating for People
Available at: luma-institute.com
Deck type: Decision design, strategy
This wonderful 36-card deck by LUMA Institute introduces you to their human-centered design system.
The 36 methods are organised into three key design skills that take you through the full design cycle:
- Looking: methods for observing human experience
- Understanding: methods for analysing challenges and opportunities
- Making: methods for envisionining future possibilities
Each card has a photo of the method in use, a short description, a quick guide, and helpful hints.
😍 Why we love them: The deck is great for running design thinking sessions, but you can also use it to teach human-centered design methods in a more tactile format.
28. Barriers to Change Cards
Available at: xplane.com
Deck type: Strategy
This deck, designed by Xplane, helps you introduce empathy to your strategy sessions. It helps you close the gap between your current state and where you want to be.
The deck covers the most common reasons people resist change, including how to overcome those barriers to make stuff happen!
😍 Why we love them: The team at Xplane wrote a helpful article detailing how exactly you can use the cards in a workshop to probe the stage that your team or organization is currently at when it comes to understanding and embedding change.
29. Think Clearly Question and Strategy Cards
Available at: thnkclrly.com
Deck type: Conversation starter, strategy, creativity
We’re absolutely obsessed with the simplicity of these two free sets of printable cards, designed by Mathias Jakobsen from Think Clearly.
The Question Cards can be used for both individual and group reflection. They are divided into four categories: Beginnings, Feelings, Insights and Actions.
The Strategy Cards include cards that provide structure for the conversation, as well as cards that prompt discussion.
😍 Why we love them: Their minimalistic black and white design really keeps your focus on what matters most: the prompts. The best part? Both decks are available for free download here.
Card Decks for Starting Conversations and Creating Connections
These decks are made for starting meaningful conversations, promotion wellbeing, creating connections, and facilitating cohesion.
30. Catalyst Cards
Available at: catalyst.cards
Deck type: Versatile and creative, conversation starters
Created by Rich Goidel of Dangerous Kitchen, Catalyst Cards draw on the power of metaphorical thinking to tap into deep-seated mental models to form complex thoughts.
Each of the 52 cards in the deck features a hand-drawn archetype used to trigger visual association as a gateway to the conscious and subconscious.
The cards themselves are simple—for example, “A day at the beach,"" “Goldfish,"" or “A wizard’s hat.""—but they can be used as mental triggers or starting-off points for all kinds of activities.
For example:
- Icebreakers: Fan out a handful of cards and ask which card each participant most identifies with
- Conversation starters: Give each participant a card and ask them how the card relates to the discussion topic or problem at hand
- Past, present, future: Give each participant three cards and ask them to choose which card represents their past, present, and future
You can play around with the online beta version here.
😍 Why we love them: Whereas most of the other cards on our list contain activities these cards serve as metaphorical inspiration. Because the cards are so versatile, they can be used for any type of session—from team building to retrospectives, innovation sessions, creative exploration workshops, personal development, and more.
31. Intùiti® Creative Cards
Available at: intuiti.it
Deck type: Versatile and creative, conversation starters
Combining concepts from design, Tarot, numerology and Gestalt psychology, Intùiti is an inspirational pack of 78 hand-drawn cards and tales that help you unlock your creativity.
Designed by Matteo di Pascale at the Polytechnic University of Milan and initially funded on Kickstarter, Intùiti cards are a rich collection of archetypes—each related to a thinking model that belongs to our culture.
The deck is made up of 22 primary cards linked to archetypes and existential moments (e.g. The Beginning, The Gestation, The Change) and 56 secondary cards linked to the four elements and emotions (e.g. Air/Mind, Water/Emotion, Earth/Material).
For a complete guide on how to use Intùiti, check out their free manual.
Intùiti is available in both English and Italian.
😍 Why we love it: The cards are beautifully illustrated. You can explore them all in the Intùiti Virtual Experience.
32. The Box of Emotions
Available at: uncommongoods.com
Deck type: Wellbeing, conversation starters
This set of 80 cards is a tool to help groups put words to their feelings. The deck was designed by researchers at the Centre for the History of the Emotions in London to help you make sense of your moods and to develop your sense of self-awareness.
Each card features a specific emotion, a miniature essay on its nuances, and a visual to match.
You'll find the classic emotions like cheerfulness, irritation, or calm, along with some new ones, like ‘fago’—a unique blend of compassion, sadness, and love.
😍 Why we love it: Sometimes, our emotions block us from coming up with great ideas or taking the next step. Using these cards to name your emotion and work on resolving it can be mentally freeing.
33. The Emotional Culture Deck
Available at: ridersandelephants.com
Deck type: Wellbeing, conversation starters
Designed by Riders & Elephants, The Emotional Culture Deck is a unique card game that facilitates face-to-face human conversations about what matters. It nudges vulnerability, builds empathy, creates connections, and fosters trust within teams.
The Emotional Culture Deck is a simple card game toolkit that helps leaders uncover what motivates their people and then map your team’s desired team culture.
You can either use the deck with organizational leaders or employees. Each person gets their own deck to avoid groupthink. For leaders, it asks questions like “How do we want our people to feel at work?”, which leads to a collective agreement on how people should behave at work.
😍 Why we love them: They have a free PDF that you can download and experiment with right away!
34. At My Best Cards
Available at: atmybest.com
Deck type: Wellbeing, team dynamics and team cohesion
At My Best has a series of card decks that are based on the principles of positive psychology—helping people develop narratives around their own strengths and successes.
They currently have two physical card decks available, Strengths Cards and Good Questions Cards, as well as a collection of virtual card decks at deckhive.com (which is still in beta).
😍 Why we love them: Sometimes all that’s needed is a little positive encouragement. These decks are great for reminding yourself of why you’re awesome!
35. Superpowers
Available at: superpowers.sypartners.com
Deck type: Team dynamics and cohesion, conversation starters
Superpowers is a tool to help participants and teams learn about their individual superpowers, and how to use them to be at their best. It’s designed by SYPartners and available as a physical card deck and as a paid Apple or Android app.
The deck is designed to help teams understand how each member can uniquely contribute to the whole of the team. The deck features 21 superpowers, such as empathy, motivation, and creative thinking.
😍 Why we love them: For remote teams, it can be hard to get to know each other’s greatest strengths—as most remote icebreakers focus on personal questions. Superpowers is a great way to learn more about your team’s “work” selves.
36. The Meeting Spicer
Available at: meetingspicer.com
Deck type: Team dynamics and team cohesion, conversation starters
Are most of your meeting unproductive? The Meeting Spicer is a coaching tool designed to help teams own and hack their meeting culture.
The deck consists of three types of card:
- Micro activities: 30-second activities designed to help your team examine their habits, goals, and team dynamics in order to take more responsibility for their actions and be more present. There are start cards for the beginning of each meeting (e.g. “Ask everyone to think silently for 20 seconds about what outcome they expect from the meeting”) and end cards (e.g. “Ask someone remoteIf we achieved just one single thing today, what is it?”
- Role cards: Meeting participants are given roles and responsibilities for the meetings, such as “Time Keeper” or “Call Facilitator.”
- Time cards: Double-sided time cards that you can hold up to show how much time is remaining for a topic or activity.
😍 Why we love them: It’s easy to agree on best practices for meetings, but hard to enforce them on a regular basis. The Meeting Spicer deck builds structure into your meetings without a lot of prep work.
37. Holstee Reflection Cards
Available at: holstee.com
Deck type: Team dynamics and team cohesion, conversation starters
Tired of the same old team-building icebreaker questions? Holstee’s Reflection Cards are a fun way to spark meaningful conversations and deepen relationships with your team or the people in your life.
Every 52-card deck includes over 100 thought-provoking questions centered around mindful themes like adventure, creativity, and resilience.
😍 Why we love them: The Reflection Cards are great for team building, but you can also use them with friends, family, and coworkers.
38. Digital Connection Cards
Available at: theschooloflife.com
Deck type: Team dynamics and cohesion, Conversation starter
This deck’s tagline says it all: “Foster Closeness at a Distance”. This Digital Connections deck contains exercises, questions, and prompts designed to foster richer interactions.
In a nutshell, these cards help us communicate and build authentic connections online.
😍 Why we love them: The deck’s tone is a mixture of humorous, kind, vulnerable, and touching. The prompts aren’t your typical icebreaker questions. Some of them invite participants to sit in silence for 80 seconds, others invite them to draw their feelings in an abstract way, while others might invite a personal and vulnerable conversation around things we’d like to forgive, or things we regret.
39. We! Connect Cards
Deck type: Team dynamics and cohesion, conversation starters
Use these 60 square cards to spark conversations that built trust and connection.
Designed by Chad Littlefield, the deck provides you with fast-paced prompts that move beyond icebreaking in favor of fostering real connections.
The questions are designed to break down communication barriers and management hierarchies within teams and organizations.
Check-out the We! Engage Cards as well—a deck of 56 cards, each with an inspiring, thought-provoking quote on one side and a powerful photo on the other.
😍 Why we love them: The cards are divided into three categories: the green cards ask fun and light questions, the blue cards go a bit deeper, and the 20 purple cards encourage self-reflection. This allows you create safety as you move from green to blue to purple.
40. ULEAD Facilitation cards
Available at: uleadinc.org
Deck type: Team dynamics and cohesion, conversation starters
This multi-faceted 54-card deck will help energize your group, inspire participation, manage change, overcome resistance, and most importantly, promote fun!
The deck comes with 5 activity cards with 10 concrete activities that use different combinations of quotes, questions, letters, images, emotions, and animals.
😍 Why we love them: The activities are awesome for getting people up and moving. For a preview of the activity cards, have a look here. They also come in a metal flip-top case, which is a treat in and of itself!
41. The Values Cards
Available at: qcards.com.au
Deck type: Strategy, team dynamics and cohesion
The Values Cards by Qcards help individuals, couples, teams, and organizations explore what truly matters to them in their relationships or work.
This exploration helps clarify core values and inspires positive changes. The words used in each of the 53 values in the cards are deliberately open to individual interpretation, which helps participants express their own values.
😍 Why we love them: The authors have also included three blank cards for values that may crop up in conversation, but are not represented in the set.
42. Improv Cards
Available at: management30.com
Deck type: Conversation Starters, Team Dynamics and Cohesion, Creativity
Want to get participants out of their comfort zones? Improv Cards are perfect as a little creative icebreaker.
Improve Cards teach people how to be better communicators and stretch their personal limits as you work through change management or work on increasing employee engagement.
They’re impossibly simple: you pull as many cards as you want and ask someone to improvise a story based on the drawings on the card. You can place constraints on the activity or just let the imagination run wild.
😍 Why we love them: You don’t even have to wait for your printed deck to arrive. You can screenshare their fully digital version as part of your next remote workshop.
43. Teamwords: The Working Deck
Available at: askthesherwins.com
Deck type: Team dynamics and cohesion, session design
If you’re ever aligning new teams, helping teams that are in trouble, planning for future growth, or encouraging dialogues around cultural differences, give these cards a whirl.
They help you identify your team’s goals, describe your shared values, and agree on what behaviors will lead to success.
😍 Why we love them: The deck simplifies the process of identifying and talking about our individual values and then linking these with concrete behaviours. They make a topic that’s usually fluffy and ground it in reality.
Card Decks for Debriefing
Alright, so we only have one deck in this category. But it’s a good one!
44. The Debriefing Cube
Available at: kilearning.net
Deck type: Debriefing and reflection
The Debriefing Cube is a debriefing set designed by Chris Caswell and Julian Kea with the goal of helping teams solidify their learnings after group sessions, games, or workshops. Each set consists of 61 cards, 4 dice, and either a wooden or paper box.
The six sides of the dice represents a different reflection lens or perspective (Goal, Process, Group Dynamics, Communication, Emotions, and Take-away). Each perspective is represented by a color in the deck, so participants can choose debriefing questions that relate to their perspective, allowing you to answer questions, such as:
- Goal: “How is your understanding of the goal different now?”
- Process: “How could you have made the process more/less pleasant?”
- etc.
😍 Why we love them: Besides the beautiful wooden box, you can also download the debriefing cube PDF for free here.
Butter up your flashcard decks
With the release of Butter Flashcard Decks, you can now use your favorite flashcards directly within the window of your next virtual session—there’s no more need to hold up physical cards to your screen.
With Butter’s Flashcard decks tool, you can easily recreate any of the above decks as a tool in your Toolbox, and then use the decks again and again in any session.
Here’s a quick demo from Jakob, our CEO, on how to upload your own Flashcard Deck:
For full directions, you can check out the Flashcard Decks page in the Butter Handbook.
To try flashcards in your next session, try Butter for free right now!",2
396,"AI text-to-image generators have been making headlines in recent months, but researchers are already moving on to the next frontier: AI text-to-video generators.
A team of machine learning engineers from Facebook’s parent company Meta has unveiled a new system called Make-A-Video. As the name suggests, this AI model allows users to type in a rough description of a scene, and it will generate a short video matching their text. The videos are clearly artificial, with blurred subjects and distorted animation, but still represent a significant development in the field of AI content generation.
The model’s output is clearly artificial but still impressive
“Generative AI research is pushing creative expression forward by giving people tools to quickly and easily create new content,” said Meta in a blog post announcing the work. “With just a few words or lines of text, Make-A-Video can bring imagination to life and create one-of-a-kind videos full of vivid colors and landscapes.”
In a Facebook post, Meta CEO Mark Zuckerberg described the work as “amazing progress,” adding: “It’s much harder to generate video than photos because beyond correctly generating each pixel, the system also has to predict how they’ll change over time.”
The clips are no longer than five seconds and contain no audio but span a huge range of prompts. The best way to judge the model’s performance is to watch its output. Each of the videos below was generated by Make-A-Video and captioned with the prompt used to generate the video. However, it’s also worth noting that each video was provided to The Verge by Meta, which is not currently allowing anyone access to the model. That means the clips could have been cherry-picked to show the system in its best light.
Again, while it’s clear these videos are computer-generated, the output of such AI models will improve rapidly in the near future. As a comparison, in just the space of a few years, AI image generators have gone from creating borderline incomprehensible pictures to photorealistic content. And though progress in video could be slower given the near-limitless complexity of the subject matter, the prize of seamless video generation will motivate many institutions and companies to pour great resources into the project.
As with text-to-image models, there is potential for harmful applications
In Meta’s blog post announcing Make-a-Video, the company notes that video generation tools could be invaluable “for creators and artists.” But, as with text-to-image models, there are worrying prospects, too. The output of these tools could be used for misinformation, propaganda, and — more likely, based on what we’ve seen with AI image systems and deepfakes — generating nonconsensual pornography that can be used to harass and intimidate women.
Meta says it wants to be “thoughtful about how we build new generative AI systems like this” and is only currently publishing a paper on the Make-A-Video model. The company says it plans to release a demo of the system but does not say when or how access to the model might be limited.
It’s also worth noting that Meta is not the only institution working on AI video generators. Earlier this year, for example, a group of researchers from Tsinghua University and the Beijing Academy of Artificial Intelligence (BAAI) released their own text-to-video model, named CogVideo (the only other publicly available text-to-video model). You can watch sample output from CogVideo here, which is limited in much the same way as Meta’s work.
In a paper describing the model, Meta’s researchers note that Make-A-Video is training on pairs of images and captions as well as unlabeled video footage. Training content was sourced from two datasets (WebVid-10M and HD-VILA-100M), which together, contain millions of videos spanning hundreds of thousands of hours of footage. This includes stock video footage created by sites like Shutterstock and scraped from the web.
The researchers note in the paper that the model has many technical limitations beyond blurry footage and disjointed animation. For example, their training methods are unable to learn information that might only be inferred by a human watching a video — e.g., whether a video of a waving hand is going left to right or right to left. Other problems include generating videos longer than five seconds, videos with multiple scenes and events, and higher resolution. Make-A-Video currently outputs 16 frames of video at a resolution of 64 by 64 pixels, which are then boosted in size using a separate AI model to 768 by 768.
Meta’s team also notes that, like all AI models trained on data scraped from the web, Make-A-Video has “learnt and likely exaggerated social biases, including harmful ones.” In text-to-image models, these biases often reinforce social prejudices. For example, ask a model to generate an image of a “terrorist,” and it will likely depict someone wearing a turban. However, it’s impossible to say what biases Meta’s model has learned without open access.
Meta says it is “openly sharing this generative AI research and results with the community for their feedback, and will continue to use our responsible AI framework to refine and evolve our approach to this emerging technology.”",3
397,fastcompany.comPlease enable JS and disable any ad blocker,9
398,"Who Actually Owns Tesla’s Data?
The company, says the company—but other interpretations persist
On 29 September 2020, a masked man entered a branch of the Wells Fargo bank in Washington, D.C., and handed the teller a note: “This is a robbery. Act calm give me all hundreds.” The teller complied. The man then fled the bank and jumped into a gray Tesla Model S. This was one of three bank robberies the man attempted the same day.
When FBI agents began investigating, they reviewed Washington, D.C.’s District Department of Transportation camera footage, and spotted a Tesla matching the getaway vehicle’s description. The license plate on that car showed that it was registered to Exelorate Enterprises LLC, the parent company of Steer EV—a D.C.-based monthly vehicle-subscription service.
Agents served a subpoena on Steer EV for the renter’s billing and contact details. Steer EV provided those—and also voluntarily supplied historical GPS data for the vehicle. The data showed the car driving between, and parking at, each bank at the time of the heists. The renter was arrested and, in September, sentenced to four years in prison.
“If an entity is collecting, retaining, [and] sharing historical location data on an individualized level, it’s extraordinarily difficult to de-identify that, verging on impossible.”
—John Verdi, Future of Privacy Forum
In this case, the GPS data likely came from a device Steer EV itself installed in the vehicle (neither Steer nor Tesla responded to interview requests). However, according to researchers, as discussed in previous entries in Spectrum's investigative series on Tesla's data (installment one; installment two), Tesla is potentially in a position to provide similar GPS tracks for many of its 3 million customers.
For Teslas built since mid-2017, “every time you drive, it records the whole track of where you drive, the GPS coordinates and certain other metrics for every mile driven,” says Green, a Tesla owner who has reverse engineered the company’s Autopilot data collection. “They say that they are anonymizing the trigger results,” but, he says, “you could probably match everything to a single person if you wanted to.”
Each of these trip logs, and other data “snapshots” captured by the Autopilot system that include images and video, is stripped of its identifying VIN and given a temporary, random ID number when it is uploaded to Tesla, says Green. However, he notes, that temporary ID can persist for days or weeks, connecting all the uploads made during that time.
Elon Musk, CEO of Tesla MotorsMark Mahaney/Redux
Given that some trip logs will also likely record journeys between a driver’s home, school, or place of work, guaranteeing complete anonymity is unrealistic, says John Verdi, senior vice president of policy at the Future of Privacy Forum: “If an entity is collecting, retaining, [and] sharing historical location data on an individualized level, it’s extraordinarily difficult to de-identify that, verging on impossible.”
Tesla, like all other automakers, has a policy that spells out what it can and cannot do with the data it gets from customers’ vehicles, including location information. This states that while the company does not sell customer and vehicle data, it can share that data with service providers, business partners, affiliates, some authorized third parties, and government entities according to the law.
Owners can buy a special kit for US $1,400 that allows them to access data on their own car's event data recorder, but this represents just a tiny subset of the data the company collects, and is related only to crashes. Owners living in California and Europe benefit from legislation that means Tesla will provide access to more data generated by their vehicles, although not the Autopilot snapshots and trip logs that are supposedly anonymized.
Once governments realize that a company possesses such a trove of information, it could be only a matter of time before they seek access to it. “If the data exists…and in particular exists in the domain of somebody who’s not the subject of those data, it’s much more likely that a government will eventually get access to them in some way,” says Bryant Walker Smith, an associate professor in the schools of law and engineering at the University of South Carolina.
“Individuals ought to think about their cars more like they think about their cellphones.”
—John Verdi, Future of Privacy Forum
This is not necessarily a terrible thing, Walker says, who suggests that such rich data could unlock valuable insights into which roads or intersections are dangerous. The wealth of data could also surface subtle problems in the vehicles themselves.
In many ways, the data genie is already out of the bottle, according to Verdi. “Individuals ought to think about their cars more like they think about their cellphones,” he says. “The auto industry has a lot to learn from the ways that mobile-phone operating systems handle data permissions…. Both iOS and Android have made great strides in recent years in empowering consumers when it comes to data collection, data disclosure, and data use.”
Tesla permits owners to control some data sharing, including Autopilot and road segment analytics. If they want to opt out of data collection completely, they can ask Tesla to disable the vehicle’s connectivity altogether. However, this would mean losing features such as remote services, Internet radio, voice commands, and Web browser functionality, and even safety-related over-the-air updates.
Green says he is not aware of anyone who has successfully undergone this nuclear option. The only real way to know you’ve prevented data sharing, he says, is to “go to a repair place and ask them to remove the modem out of the car.”
Tesla almost certainly has the biggest empire of customer and vehicle data among automakers. It also appears to be the most aggressive in using that data to develop its automated driving systems, and to protect its reputation in the courts of law and public opinion, even to the detriment of some of its customers.
But while the world’s most valuable automaker dominates the discussion around connected cars, others are not far behind. Elon Musk’s insight—to embrace the data-driven world that our other digital devices already inhabit—is rapidly becoming the industry standard. When our cars become as powerful and convenient as our phones, it is hardly surprising that they suffer the same challenges around surveillance, privacy, and accountability.
This article appears in the October 2022 print issue as “The Radical Scope of Tesla’s Data Hoard.”
- The Radical Scope of Tesla's Data Hoard - IEEE Spectrum ›
- Tesla's Autopilot Depends on a Deluge of Data - IEEE Spectrum ›",5
399,"Natalie Paquette spends her time thinking about how to grow an extra dimension. Start with little circles, scattered across every point in space and time—a curlicue dimension, looped back onto itself. Then shrink those circles down, smaller and smaller, tightening the loop, until a curious transformation occurs: the dimension stops seeming tiny and instead becomes enormous, like when you realize something that looks small and nearby is actually huge and distant. “We’re shrinking a spatial direction,” Paquette says. “But when we try to shrink it past a certain point, a new, large spatial direction emerges instead.”
Paquette, a theoretical physicist at the University of Washington, is not alone in thinking about this strange kind of dimensional transmutation. A growing number of physicists, working in different areas of the discipline with different approaches, are increasingly converging on a profound idea: space—and perhaps even time—is not fundamental. Instead space and time may be emergent: they could arise from the structure and behavior of more basic components of nature. At the deepest level of reality, questions like “Where?” and “When?” simply may not have answers at all. “We have a lot of hints from physics that spacetime as we understand it isn’t the fundamental thing,” Paquette says.
These radical notions come from the latest twists in the century-long hunt for a theory of quantum gravity. Physicists’ best theory of gravity is general relativity, Albert Einstein’s famous conception of how matter warps space and time. Their best theory of everything else is quantum physics, which is astonishingly accurate when it comes to the properties of matter, energy and subatomic particles. Both theories have easily passed all the tests physicists have been able to devise for the past century. Put them together, one might think, and you would have a “theory of everything.”
But the two theories don’t play nicely. Ask general relativity what happens in the context of quantum physics, and you’ll get contradictory answers, with untamed infinities breaking loose across your calculations. Nature knows how to apply gravity in quantum contexts—it happened in the first moments of the big bang, and it still happens in the hearts of black holes—but we humans are still struggling to understand how the trick is done. Part of the problem lies in the ways the two theories deal with space and time. While quantum physics treats space and time as immutable, general relativity warps them for breakfast.
Somehow a theory of quantum gravity would need to reconcile these ideas about space and time. One way to do that would be to eliminate the problem at its source, spacetime itself, by making space and time emerge from something more fundamental. In recent years several different lines of inquiry have all suggested that, at the deepest level of reality, space and time do not exist in the same way that they do in our everyday world. Over the past decade these ideas have radically changed how physicists think about black holes. Now researchers are using these concepts to elucidate the workings of something even more exotic: wormholes—hypothetical tunnel-like connections between distant points in spacetime. These successes have kept alive the hope of an even deeper breakthrough. If spacetime is emergent, then figuring out where it comes from—and how it could arise from anything else—may just be the missing key that finally unlocks the door to a theory of everything.
The World in a String Duet
Today the most popular candidate theory of quantum gravity among physicists is string theory. According to this idea, its eponymous strings are the fundamental constituents of matter and energy, giving rise to the myriad fundamental subatomic particles seen at particle accelerators around the world. They are even responsible for gravity—a hypothetical particle that carries the gravitational force, a “graviton,” is an inevitable consequence of the theory.
But string theory is difficult to understand—it lives in mathematical territory that has taken physicists and mathematicians decades to explore. Much of the theory’s structure is still uncharted, expeditions still planned and maps left to be made. Within this new realm, the main technique for navigation is through mathematical dualities—correspondences between one kind of system and another.
One example is the duality from the beginning of this article, between tiny dimensions and big ones. Try to cram a dimension down into a little space, and string theory tells you that you will end up with something mathematically identical to a world where that dimension is huge instead. The two situations are the same, according to string theory—you can go back and forth from one to the other freely and use techniques from one situation to understand how the other one works. “If you carefully keep track of the fundamental building blocks of the theory,” Paquette says, “you can naturally find sometimes that ... you might grow a new spatial dimension.”
A similar duality suggests to many string theorists that space itself is emergent. The idea began in 1997, when Juan Maldacena, a physicist at the Institute for Advanced Study, uncovered a duality between a kind of well-understood quantum theory known as a conformal field theory (CFT) and a special kind of spacetime from general relativity known as anti–de Sitter space (AdS). The two seem to be wildly different theories—the CFT has no gravity in it whatsoever, and the AdS space has all of Einstein’s theory of gravity thrown in. Yet the same mathematics can describe both worlds. When it was discovered, this AdS/CFT correspondence provided a tangible mathematical link between a quantum theory and a full universe with gravity in it.
Curiously, the AdS space in the AdS/CFT correspondence had one more dimension in it than the quantum CFT had. But physicists relished this mismatch because it was a fully worked-out example of another kind of correspondence conceived a few years earlier, from physicists Gerard ’t Hooft of Utrecht University in the Netherlands and Leonard Susskind of Stanford University, known as the holographic principle. Based on some of the peculiar characteristics of black holes, ’t Hooft and Susskind suspected that the properties of a region of space might be fully “encoded” by its boundary. In other words, the two-dimensional surface of a black hole would contain all the information needed to know what was in its three-dimensional interior—like a hologram. “I think a lot of people thought we were nuts,” Susskind says. “Two good physicists gone bad.”
Similarly, in the AdS/CFT correspondence, the four-dimensional CFT encodes everything about the five-dimensional AdS space it is associated with. In this system, the entire region of spacetime is built out of interactions between the components of the quantum system in the conformal field theory. Maldacena likens this process to reading a novel. “If you are telling a story in a book, there are the characters in the book that are doing something,” he says. “But all there is is a line of text, right? What the characters are doing is inferred from this line of text. The characters in the book would be like the bulk [AdS] theory. And the line of text is the [CFT].”
But where does the space in the AdS space come from? If this space is emergent, what is it emerging from? The answer is a special and strangely quantum kind of interaction in the CFT: entanglement, a long-distance connection between objects, instantaneously correlating their behavior in statistically improbable ways. Entanglement famously troubled Einstein, who called it “spooky action at a distance.”
Yet despite its spookiness, entanglement is a core feature of quantum physics. When any two objects interact in quantum mechanics, they generally become entangled and will stay entangled so long as they remain isolated from the rest of the world—no matter how far apart they may travel. In experiments, physicists have maintained entanglement between particles more than 1,000 kilometers apart and even between particles on the ground and others sent to orbiting satellites. In principle, two entangled particles could sustain their connection on opposite sides of the galaxy or the universe. Distance simply does not seem to matter for entanglement, a puzzle that has troubled many physicists for decades.
But if space is emergent, entanglement’s ability to persist over large distances might not be terribly mysterious—after all, distance is a construct. According to studies of the AdS/CFT correspondence by physicists Shinsei Ryu of Princeton University and Tadashi Takayanagi of Kyoto University, entanglement is what produces distances in the AdS space in the first place. Any two nearby regions of space on the AdS side of the duality correspond to two highly entangled quantum components of the CFT. The more entangled they are, the closer together the regions of space are.
In recent years physicists have come to suspect that this relation might apply to our universe as well. “What is it that holds the space together and keeps it from falling apart into separate subregions? The answer is the entanglement between two parts of space,” Susskind says. “The continuity and the connectivity of space owes its existence to quantum-mechanical entanglement.” Entanglement, then, may undergird the structure of space itself, forming the warp and weft that give rise to the geometry of the world. “If you could somehow destroy the entanglement between two parts [of space], the space would fall apart,” Susskind says. “It would do the opposite of emerging. It would dis-emerge.”
If space is made of entanglement, then the puzzle of quantum gravity seems much easier to solve: instead of trying to account for the warping of space in a quantum way, space itself emerges out of a fundamentally quantum phenomenon. Susskind suspects this is why a theory of quantum gravity has been so difficult to find in the first place. “I think the reason it never worked very well is because it started with a picture of two different things, [general relativity] and quantum mechanics, and put them together,” he says. “And I think the point is really that they’re much too closely related to pull apart and then put back together again. There’s no such thing as gravity without quantum mechanics.”
Yet accounting for emergent space is only half the job. With space and time so intimately linked in relativity, any account of how space emerges must also explain time. “Time must also emerge somehow,” says Mark van Raamsdonk, a physicist at the University of British Columbia and a pioneer in the connection between entanglement and spacetime. “But this is not well understood and is an active area of research.”
Another active area, he says, is using models of emergent spacetime to understand wormholes. Previously many physicists had believed that sending objects through a wormhole was impossible, even in theory. But in the past few years physicists working on the AdS/CFT correspondence and similar models have found new ways to construct wormholes. “We don’t know if we could do that in our universe,” van Raamsdonk says. “But what we now know is that certain kinds of traversable wormholes are theoretically possible.” Two papers—one in 2016 and one in 2018—led to an ongoing flurry of work in the area. But even if traversable wormholes could be built, they would not be much use for space travel. As Susskind points out, “you can’t go through that wormhole faster than it would take for [light] to go the long way around.”
Space to Think
If the string theorists are correct, then space is built from quantum entanglement, and time might be as well. But what would that really mean? How can space be “made of” entanglement between objects unless those objects are themselves somewhere? How can those objects become entangled unless they experience time and change? And what kind of existence could things have without inhabiting a true space and time?
These are questions verging on philosophy—and indeed, philosophers of physics are taking them seriously. “How the hell could spacetime be the kind of thing that could be emergent?” asks Eleanor Knox, a philosopher of physics at King’s College London. Intuitively, she says, that seems impossible. But Knox doesn’t think that is a problem. “Our intuitions are terrible sometimes,” she says. They “evolved on the African savanna interacting with macro objects and macro fluids and biological animals” and tend not to transfer to the world of quantum mechanics. When it comes to quantum gravity, “ ‘Where’s the stuff?’ and ‘Where does it live?’ aren’t the right questions to be asking,” Knox concludes.
It is certainly true that objects live in places in everyday life. But as Knox and many others point out, that does not mean that space and time have to be fundamental—just that they have to reliably emerge from whatever is fundamental. Consider a liquid, says Christian Wüthrich, a philosopher of physics at the University of Geneva. “Ultimately it’s elementary particles, like electrons and protons and neutrons or, even more fundamental, quarks and leptons. Do quarks and leptons have liquid properties? That just doesn’t make sense, right?... Nevertheless, when these fundamental particles come together in sufficient numbers and show a certain behavior together, collective behavior, then they will act in a way that is like a liquid.”
Space and time, Wüthrich says, could work the same way in string theory and other theories of quantum gravity. Specifically, spacetime might emerge from the materials we usually think of as living in the universe—matter and energy itself. “It’s not [that] we first have space and time and then we add in some matter,” Wüthrich says. “Rather something material may be a necessary condition for there to be space and time. That’s still a very close connection, but it’s just the other way from what you might have thought originally.”
But there are other ways to interpret the latest findings. The AdS/CFT correspondence is often seen as an example of how spacetime might emerge from a quantum system, but that might not actually be what it shows, according to Alyssa Ney, a philosopher of physics at the University of California, Davis. “AdS/CFT gives you this ability to provide a translation manual between facts about the spacetime and facts of the quantum theory,” Ney says. “That’s compatible with the claim that spacetime is emergent, and some quantum theory is fundamental.” But the reverse is also true, she says. The correspondence could mean that quantum theory is emergent and spacetime is fundamental—or that neither is fundamental and that there is some even deeper fundamental theory out there. Emergence is a strong claim to make, Ney says, and she is open to the possibility that it is true. “But at least just looking at AdS/CFT, I’m still not seeing a clear argument for emergence.”
An arguably bigger challenge to the string theory picture of emergent spacetime is hidden in plain sight, right in the name of the AdS/CFT correspondence itself. “We don’t live in anti–de Sitter space,” Susskind says. “We live in something much closer to de Sitter space.” De Sitter space describes an accelerating and expanding universe much like our own. “We haven’t got the vaguest idea how [holography] applies there,” Susskind concludes. Figuring out how to set up this kind of correspondence for a space that more closely resembles the actual universe is one of the most pressing problems for string theorists. “I think we’re going to be able to understand better how to get into a cosmological version of this,” van Raamsdonk says.
Finally, there is the news—or lack thereof—from the latest particle accelerators, which have not found any evidence for the extra particles predicted by supersymmetry, an idea that string theory relies on. Supersymmetry dictates that all known particles would have their own “superpartners,” doubling the number of fundamental particles. But CERN’s Large Hadron Collider near Geneva, designed in part to search for superpartners, has seen no sign of them. “All of the really precise versions of [emergent spacetime] that we have are in supersymmetric theories,” Susskind says. “Once you don’t have supersymmetry, the ability to mathematically follow the equations just evaporates out of your hands.”
Atoms of Spacetime
String theory is not the only idea that suggests spacetime is emergent. String theory has “failed to live up to [its] promise as a way to unite gravity and quantum mechanics,” says Abhay Ashtekar, a physicist at Pennsylvania State University. “The power of string theory now is in providing an extremely rich set of tools, which has been used widely across the whole spectrum of physics.” Ashtekar is one of the original pioneers of the most popular alternative to string theory, known as loop quantum gravity. In loop quantum gravity, space and time are not smooth and continuous the way they are in general relativity—instead they are made of discrete components, what Ashtekar calls “chunks or atoms of spacetime.”
These atoms of spacetime are connected in a network, with one- and two-dimensional surfaces joining them together into what practitioners of loop quantum gravity call a spin foam. And despite that foam being limited to two dimensions, it gives rise to our four-dimensional world, with three dimensions of space and one of time. Ashtekar likens it to a piece of clothing. “If you look at your shirt, it looks like a two-dimensional surface,” he says. “If you just take a magnifying glass, you will immediately see that it’s all one-dimensional threads. It’s just that those threads are so densely packed that for all practical purposes, you can think of the shirt as being a two-dimensional surface. So, similarly, the space around us looks like a three-dimensional continuum. But there is really a crisscross by these [atoms of spacetime].”
Although string theory and loop quantum gravity both suggest that spacetime is emergent, the kind of emergence is different in the two theories. String theory suggests that spacetime (or at least space) emerges from the behavior of a seemingly unrelated system, in the form of entanglement. Think of how traffic jams emerge from the collective decisions of individual drivers. The cars are not made of traffic—the cars make the traffic. In loop quantum gravity, on the other hand, the emergence of spacetime is more like a sloping sand dune emerging from the collective motion of sand grains in wind. The smooth familiar spacetime comes from the collective behavior of tiny “grains” of spacetime; like the dunes, the grains are still sand, even though the chunky crystalline grains do not look or act like the undulating dunes.
Despite these differences, both loop quantum gravity and string theory suggest spacetime emerges from some underlying reality. Nor are they the only proposed theories of quantum gravity that point in this direction. Causal set theory, another contender for a theory of quantum gravity, posits that space and time are made of more fundamental components as well. “It’s really striking that for most of the plausible theories of quantum gravity that we have, in some sense their message is, yeah, general relativistic spacetime isn’t in there at the fundamental level,” Knox says. “People get very excited when different theories of quantum gravity agree on at least something.”
The Future of Space at the Edge of Time
Modern physics is a victim of its own success. Because quantum physics and general relativity are both so phenomenally accurate, quantum gravity is needed only to describe extreme situations, when enormous masses are stuffed into unfathomably tiny spaces. Those conditions exist in only a few places in nature, such as the center of a black hole—and notably not in physics laboratories, not even the largest and most powerful ones. It would take a particle accelerator the size of a galaxy to directly test the behavior of nature under conditions where quantum gravity reigns. This lack of direct experimental data is a large part of the reason why scientists’ search for a theory of quantum gravity has been so long.
Faced with the lack of evidence, most physicists have pinned their hopes on the sky. In the earliest moments of the big bang, the entire universe was phenomenally small and dense—a situation that calls for quantum gravity to describe it. And echoes of that era may remain in the sky today. “I think our best bet [for testing quantum gravity] is through cosmology,” Maldacena says. “Maybe something in cosmology that we now think is unpredictable, that maybe can be predicted once we understand the full theory, or some new thing that we didn’t even think about.”
Laboratory experiments may come in handy, however, for testing string theory, at least indirectly. Scientists hope to study the AdS/CFT correspondence not by probing spacetime but by building highly entangled systems of atoms and seeing whether an analogue to spacetime and gravity shows up in their behavior. Such experiments might “have some features of gravity, though, perhaps not all the features,” Maldacena says. “It also depends on exactly what you call gravity.”
Will we ever know the real nature of space and time? The observational data from the skies may not be forthcoming any time soon. The lab experiments could be a bust. And as philosophers know well, questions about the true nature of space and time are very old indeed. What exists “is now all together, one, continuous,” said the philosopher Parmenides 2,500 years ago. “All is full of what is.” Parmenides insisted that time and change were illusions, that everything everywhere was one and the same. His pupil Zeno created famous paradoxes to prove his teacher’s point, purporting to show that motion over any distance was impossible. Their work raised the question of whether time and space are somehow illusory, an unsettling prospect that has haunted Western philosophy for over two millennia.
“The fact that the ancient Greeks asked things like, ‘What is space?’ ‘What is time?’ ‘What is change?’ and that we still ask versions of these questions today means that they were the right questions to ask,” Wüthrich says. “It’s by thinking about these kinds of questions that we have learned a lot about physics.”",1
400,"Metaverse Standards Forum to foster the development of open standards for the metaverse; Membership is free and open to any organization. Founding members include: 0xSenses, Academy Software Foundation, Adobe, Alibaba, Autodesk, Avataar, Blackshark.ai, CalConnect, Cesium, Daly Realism, Disguise, the Enosema Foundation, Epic Games, the Express Language Foundation, Huawei, IKEA, John Peddie Research, Khronos, Lamina1, Maxon, Meta, Microsoft, NVIDIA, OpenAR Cloud, the Open Geospatial Consortium, Otoy, Perey Research and Consulting, Qualcomm Technologies, Ribose, Sony Interactive Entertainment, Spatial Web Foundation, Unity, VerseMaker, Wayfair, the Web3D Consortium, the World Wide Web Consortium, and the XR Association (XRA)
June 21st, 2022 – Announced today, The Metaverse Standards Forum brings together leading standards organizations and companies for industry-wide cooperation on interoperability standards needed to build the open metaverse. The Forum will explore where the lack of interoperability is holding back metaverse deployment and how the work of Standards Developing Organizations (SDOs) defining and evolving needed standards may be coordinated and accelerated. Open to any organization at no cost, the Forum will focus on pragmatic, action-based projects such as implementation prototyping, hackathons, plugfests, and open-source tooling to accelerate the testing and adoption of metaverse standards, while also developing consistent terminology and deployment guidelines.
The metaverse is motivating the novel integration and deployment of diverse technologies for collaborative spatial computing, such as interactive 3D graphics, augmented and virtual reality, photorealistic content authoring, geospatial systems, end-user content tooling, digital twins, real-time collaboration, physical simulation, online economies, multi-user gaming, and more – at new levels of scale and immersiveness.
Multiple industry leaders have stated that the potential of the metaverse will be best realized if it is built on a foundation of open standards. Building an open and inclusive metaverse at pervasive scale will demand a constellation of open interoperability standards created by SDOs such as The Khronos Group, the World Wide Web Consortium, the Open Geospatial Consortium, the Open AR Cloud, the Spatial Web Foundation, and many others. The Metaverse Standards Forum aims to foster consensus-based cooperation between diverse SDOs and companies to define and align requirements and priorities for metaverse standards—accelerating their availability and reducing duplication of effort across the industry.
“The metaverse will bring together diverse technologies, requiring a constellation of interoperability standards, created and maintained by many standards organizations,” said Neil Trevett, Khronos president. “The Metaverse Standards Forum is a unique venue for coordination between standards organizations and industry, with a mission to foster the pragmatic and timely standardization that will be essential to an open and inclusive metaverse.”
Hosted by the Khronos Group, the Forum is open to any company, standards organization, or university at no charge through a simple click-through Participant Agreement. Companies that wish to provide Forum oversight, and may wish to fund Forum projects, can choose to become a Principal member.
The activities of the Forum will be directed by the needs and interests of its members and may involve diverse technology domains such as 3D assets and rendering, human interface and interaction paradigms such as AR and VR, user created content, avatars, identity management, privacy, and financial transactions. Forum meetings are expected to start in July 2022. More information on joining can be found at metaverse-standards.org.
Forum Founding Members Statements of Support
“Technology and standards are the bricks and cement of the metaverse,” said Qi Wang, assistant president and head of healthcare and cognitive psychology lab at 0xSenses. “Safe, reliable, and ethical interoperability is especially important as humans become part of the metaverse. 0xSenses is thrilled to join the Metaverse Standards Forum as a founding principal to help make the metaverse dreams come true faster and better.”
“The Academy Software Foundation is pleased to join the Metaverse Standard Forum as a Founding member, because open source software developed by motion picture industry engineers can contribute building blocks for the Metaverse,” said David Morin, executive director of Academy Software Foundation (ASWF). When it comes to building strange new worlds and boldly go where no one has gone before, count us in.”
“Adobe is excited to join the Metaverse Standards Forum,” said Stefano Corazza, vice president and fellow of AR at Adobe. “It is in our history to contribute to the industry by defining foundational standards for digital experiences, as we did with PDF and DNG. Establishing standards is essential to foster collaboration in the Metaverse, and to allow this new ecosystem to truly flourish.”
“Alibaba is pleased to join The Metaverse Standards Forum which encourages collaboration on interoperability standards of the open metaverse,” said Dr Tan Ping, head of XR Lab, Alibaba DAMO Academy. “We look forward to sharing our technology knowhow and joining global industry leaders to accelerate constructive dialogues to advance new initiatives in the metaverse space.”
“We are thrilled to be a founding member of the Metaverse Standards Forum as it fosters open standards and collaboration that will unlock the full potential of metaverse experiences,” said Eric Bourque, vice president of Engineering, Media & Entertainment, Autodesk. “The future of design and make is the industrial metaverse where designers, builders, manufacturers and content creators can make better, more informed decisions quickly.”
“Avataar is extremely excited and proud to be taking part in The Metaverse Standards forum to bring about interoperability standards across metaverse ecosystems,” said Sravanth Aluru, CEO & founder of Avataar. “We believe there is a need for technical products to solve the challenges we face in making the end user experience seamless & scalable and our deep-tech platform is on that path. We look forward to collaborating with the esteemed partners in the forum to build these standards.”
“The metaverse will ultimately encompass all our activities and support them with applications. Just like standardization has been an important foundation for open knowledge sharing and rapid development in the Web age, the same is true for the Metaverse. Blackshark is pleased to contribute to this success by participating in the Metaverse Standards Forum,” said Arno Hollosi, CTO at Blackshark.ai.
“CalConnect focuses on creating standards that enable interoperable collaboration, with some of our key standards like vCard and iCalendar in use across billions of devices today”, said Gershon Janssen, president of CalConnect. “CalConnect is delighted to join fellow standards organizations in ensuring the interoperability of the Metaverse.”
“The Internet is built on open standards and interoperability for the benefit of all participants. As we move into the era of 3D-centric computing, we must build the metaverse in the same manner. I can’t think of a better home than Khronos to host the Metaverse Standards Forum to facilitate pragmatic collaboration among the community for open standards for the metaverse, especially for 3D assets, which will become as pervasive as image and video media types on the web today. Cesium is thrilled to join as a Founding Principal as we lay the foundations for the metaverse for decades to come,” said Patrick Cozzi, CEO at Cesium.
“disguise is excited to join the Metaverse Standardization Forum,” said Ed Plowman, CTO of disguise. “disguise believes that the Metaverse should be open, inclusive and collaborative and that can only be achieved if we get together and focus on standards, connectivity and interoperability.”
“Semantic insights from terminologies and vocabularies serve as the basis for any new initiative,” said Reese Plews, president of the Enosema Foundation. “The Enosema Foundation is excited to join the Metaverse Standards Forum and standardize core vocabularies based on best practices that enable disruptive opportunities in the metaverse.”
“We are thrilled to help launch the Metaverse Standards Forum, a collaborative industry-led effort founded to accelerate the development and adoption of interoperability standards,” said Marc Petit, vice president of Unreal Engine ecosystem at Epic Games. “Our goal is to build an open metaverse that enriches humanity and is home to a thriving, fair ecosystem with millions of creators.”
“The Metaverse is the new frontier for the expression of information. As an organization supporting the EXPRESS language used to great success in the aerospace, automotive and construction industries, we are excited to work with like-minded standardization and commercial organizations in setting standards to bridge the physical and the virtual worlds,” said Thomas Thurman, president of the EXPRESS Language Foundation.
“Huawei is very glad to join the Metaverse Standards Forum as we believe that the metaverse industry and ecosystem will benefit from the collaborative actions and open standards,” said Xiao Ran, vice president of Huawei’s Corporate Strategy and Industry Development. “We look forward to cooperating with the leading SDO’s and industry partners to accelerate the open interoperability standards for metaverse and contribute our experiences.”
“IKEA is looking forward to this Metaverse Standards Forum as we believe that the way to democratize metaverse and spatial computing is to have many open standards that work well together,” says Martin Enthed, innovation manager at IKEA Marketing & Communication AB. “This forum we hope will be a place where that coordination could happen between SDO’s, industry, and where IKEA can contribute with the use cases and experiences from our industry.”
“We are proud to be a founding member of this vitally important new forum for ideas, clarifications, direction and definition of what the Metaverse will be and can be,” said Dr. Jon Peddie, president of Jon Peddie Research. “The foundational elements have been in development for some time and now the interoperability and interconnectivity is possible. Khronos will help ensure it is open, smoothly implemented, and takes advantage of the collective minds of the industry just as they have in other areas.”
“Lamina1 is committed to an open Metaverse for all— controlled by no one, with no barriers to entry, and where creators from all walks of life can succeed and thrive,” said Tony Parisi, chief strategy officer at Lamina1. “We are excited to work in collaboration with industry leaders to define the interoperable standards and infrastructure that empower real-time 3D for community, communication and commerce on a global scale.”
“Maxon is pleased to be an initial member of the Metaverse Standards Forum. We believe strongly in cultivating a collaborative, artist-driven, inclusive foundation to bolster the implementation and adoption of interoperability standards,” said David McGavran, CEO of Maxon. “We see standardization as a catalyst for creativity, growth, innovation and unlimited possibility for this inspiring new ecosystem.”
“Building a metaverse for everyone will require an industry-wide focus on common standards. The Metaverse Standards Forum can drive the collaboration that’s needed to make this possible, and Meta is committed to this work. Creators, developers and companies will all benefit from the technologies and experiences that will be made possible by common protocols,” said Vishal Shah, vice president of Metaverse at Meta.
“NVIDIA understands the metaverse as an evolution of the Internet — from today’s 2D view of the web to an immersive 3D spatial overlay,” said Rev Lebaredian, vice president, Omniverse & Simulation Technology at NVIDIA. “For the metaverse to be successful and ubiquitous, it must be built on open standards, just like today’s 2D web — and our joining the Metaverse Standards Forum will help the community usher in a new era of collaborative and open 3D standards that will form the foundation of the metaverse.”
“The Open AR Cloud Association (OARC) sees the Metaverse Standards Forum as a much needed practical approach to accelerate coordination across industries and initiatives. We believe technologies which promote open standards, interoperability, privacy, and security are needed for a real-world Metaverse or Spatial Web. Since 2018 OARC’s mission has been to advocate for, build consensus for, and contribute to such efforts. We are happy to offer our full support for the Metaverse Standards Forum,” said Jan-Erik Vinje, managing director of OARC.
“OGC is very pleased to join the Metaverse Standards Forum with our partner organizations,” said Dr. Nadine Alameh, Open Geospatial Consortium president. “We look forward to providing our consortium’s collective expertise in the geospatial and location fields as part of these partnerships across Standards Development Organizations, industry, and more to ensure the emerging metaverse is as relevant and as open as possible.”
“As we enter a new era of spatial computing and holographic mixed reality, OTOY is thrilled to contribute to the Metaverse Standards Forum,” said Jules Urbach, CEO and founder of OTOY Inc. “Open standards developed in collaboration with the leading SDO will provide a framework for building an open metaverse that has the potential to reshape how we communicate, transform our creative economy, and power new industries built on advanced 3D visualization. We are looking forward to collaborating with industry leaders in the Metaverse Standards Forum, contributing our experiences at the forefront of 3D graphics and blockchain cloud computing.”
“As a metaverse enabler and provider of key technology to the ecosystem, Qualcomm Technologies believes in taking an open platform approach and interoperable metaverse,” said Hugo Swart, vice president and general manager of XR, Qualcomm Technologies, Inc. “We are thrilled to join the Metaverse Standards Forum to help define standards for the metaverse to flourish with a healthy ecosystem, and help creators pioneer innovative experiences that will lead the next generation of immersive technology.”
“An open and interoperable Metaverse benefits all without discrimination. As a pioneer of SMART standards, Ribose has been a trusted partner of international, national and industry standardization bodies in their development and deployment of machine-readable standards: from ISO to ITU, BSI to NIST, CalConnect to OGC,” said Ronald Tse, founder of Ribose. “We are excited to join fellow standards bodies and makers in creating standards and technologies critical to interoperability across the Metaverse.”
“The Spatial Web Foundation is excited to join the Metaverse Standards Forum to collaborate with the world’s leading standards organizations to accelerate the critical interoperability standards needed for metaverse applications and across the broader Spatial Web,” said Gabriel Rene, Spatial Web Foundation executive director.
“Unity is committed to helping solve challenges customers face today for creating and sharing the rich content needed for film, gaming, advertising and digital twin experiences,” said Allan Poore, SVP of professional artistry at Unity, “We look forward to partnering with the Metaverse Standards Forum to extend USD as the future for rich interoperability across tools and workflows in the industry.”
“VerseMaker is committed to becoming a bridge and catalyst for China’s research and development, education and training, large enterprises, start-up companies, and investment institutions to participate in the global metaverse innovation and cooperation ecosystem,” said Dr. Yu Yuan, co-founder of VerseMaker. “Standardization is the underlying driving force for the development of the global metaverse industry. An open and cooperative ecosystem based on standards is the common vision of the global metaverse industry. We are thrilled to be a founding principal of the Metaverse Standards Forum and jointly create the future of the global metaverse industry.”
“Wayfair, with our mission to help people create their feeling of home, whether in physical or virtual spaces, is proud to be a founding member of the Metaverse Standards Forum,” said Shrenik Sadalgi, director of research and development at Wayfair & founding chair of the Khronos 3D Commerce Working Group. “Together with the other participating members we are excited to take on a leadership role in the creation of these new standards and help chart the path forward to a truly open metaverse.”
“The Metaverse Standards Forum provides a unique opportunity to achieve secure, collaborative (interoperable), durable, and pervasive Mixed-Reality content,” said Nicholas Polys Ph.D., president of the Web3D Consortium. The Web3D Consortium members bring decades of prior research into 3D graphics interoperability and WWW ecosystem standardizations; integration with ISO-IEC Extensible 3D (X3D) Version 4 will bring quick wins that catalyze new value and provide crucial assurances for Metaverse creators and participants.”
“The World Wide Web Consortium (W3C) is joining the Metaverse Standards Forum to accelerate the coordination with other standards organizations and metaverse stakeholders in building an interoperable platform for the metaverse, in which W3C’s Immersive Web vision is set to play a critical role,” said Dominique Hazaël-Massieux, W3C immersive web strategist.
“XR Association is pleased to be part of this prestigious collaborative effort to design the XR standards framework,” said Stephanie Montgomery, vice president of Research and Best Practices at XRA. “Our mission is the responsible development and advancement of XR. Through the Metaverse Standards Forum we will contribute to common protocols, interoperability and shared understanding, thereby responsibly improving technological efficiencies and advancing XR technology to new levels of delight.”",1
401,"Kat Norton is a Microsoft Excel influencer. She has over a million followers on TikTok and Instagram, where she goes by the name Miss Excel, and she’s leveraged that into a software training business that is now generating up to six figures of revenue a day. That’s six figures a day. And she’s only been doing this since June 2020.
Kat is a one-woman operation, with no staff or management layer. She uses her iPhone and consumer software to make her videos, and I’ve got to say, she has one of the healthiest relationships with the social platforms of maybe any creator I’ve ever talked to: she thinks of them purely as marketing channels for the video courses she sells elsewhere. That’s a big flip from the traditional creator business model, which is usually aimed at monetizing the platforms directly. Kat’s just not doing that.
But where this conversation really got me was when Kat said she firmly believed in manifestation and energetics, and that she draws a repeated connection between the work she’s done there and the success she’s had as a creator and entrepreneur. Just listen in this conversation how easily and quickly Kat can go back and forth between talking about her core business metrics and strategies and harnessing her energy to connect with viewers across devices and platforms. I have spoken to a lot of creators and a lot of executives on this show; I have never met one like Kat. If you’ve been listening to this show, you might have guessed that I am not the sort of personality type that goes in for energetics and manifestation, but Kat was convincing.
I don’t want to give too much away because it’s all in the interview, but I think you’re really going to like this one.
Okay. Kat Norton. Miss Excel. Here we go.
This transcript has been lightly edited for clarity.
Kat Norton, you are known as Miss Excel on TikTok and Instagram. You are the creator of something called the Excelerator Course. Welcome to Decoder.
Thank you so much for having me. I’m so excited to be here.
I am super excited to talk to you. I’m going to start this interview a little backward, because I think the size of the creator business you have built is remarkable. What’s your revenue like? Where are you at per day, per week, per month? I’m looking at some of our notes and they seem like big numbers.
When I first started the business, I scaled it within six months to six figures. Since then we have been doing six-figure months. I actually just had my first six-figure day a few weeks ago, which I was super excited about. It’s been just the most incredible, fun journey building this business.
What is the business? What are you selling?
So I sell Microsoft Excel courses and now all of the other Microsoft products. I have Google Sheets courses as well. I’d say about 95 percent of what I do is passive income course sales now.
That’s all just you — you’re just a one-person creative shop?
Yes. I have a virtual assistant that helps with some of my graphics on Instagram, but pretty much everything else has been a one-woman show over here.
That’s amazing. You are using TikTok and Instagram as a marketing channel, playing your character, Miss Excel. Your actual product is videos you’ve already made that people are buying subscriptions to. How does that work?
The social media channels are my main marketing. It’s mostly organic sales from there. I also host webinars that are usually those bigger, higher traffic days. I created lines of really fun courses. Each one’s around 100 videos. I design each video and infuse it with as much creativity and fun as possible. If you’ve seen my Instagram or my TikTok, you know I have to keep it fun. I also record everything myself so I’m bringing that energy into the videos. I also video edit everything myself too because for me that is half of the art form. For example, I’ll know I need to pop a picture of a hamburger on the screen for three seconds to make my analogies so the audience understands the concept. It’s where I go in with the teacher’s eye there. I create these courses — they’re like my babies. I make them from start to finish and I’m incredibly proud of them. They’ve been doing awesome on the market.
Are you selling them individually at $5 a video or are you selling subscriptions? What’s the model?
I sell it by course, so price points are $297 all the way through a bundle of most of my courses at $997. People buy lifetime access to my courses. I host them on the platform Thinkific.
Why 97?
When you cut it in half, the result also turns into a nice number. That was something I learned from some business coaches — whenever I run a sale, it’s usually $297 typically, but when you cut it in half, it looks nice at $149.
That’s great. I love it. This massive business is just you. That’s so impressive, but it’s also very different from other creator businesses that we’ve heard about on this show, or other creator businesses the average person has encountered. Now, let’s start at the beginning: how did you become Miss Excel?
Wow. What a great question. I’ll take you back to March 2020. At that time, I was working at a global consulting firm called Protiviti. I had been traveling every week before this, doing securitization interviews for banks. I had built out an Excel training course for fun right when I started at the company four and a half years ago. The company totally backed me and had me flying around the US hosting these Excel training sessions because I just genuinely loved to teach Excel. Around March, I stopped traveling and I found myself at my parents’ house in my childhood bed.
What happened in March?
Some nice pandemic stuff going on then. I stopped traveling, essentially, and so I had a lot more time on my hands. I started going deep into inner work, work on myself: meditation, mindfulness, manifestation. As backstory, I was actually incredibly shy and had a lot of anxiety before starting this project. I highly recommend that, before posting yourself dancing on the internet, that you do your fair share of inner work and make sure you’re at a place where you can handle what comes with that. I dove deep into the spiritual work and got myself to this place where I no longer had these limiting beliefs and constructs holding me in place. It was April 2020 at that point — I didn’t create Miss Excel until June, two months later. This wasn’t even a thought in my mind. I didn’t even have a TikTok — I turned to my mother and said, “Mom, I’m going to be rich and famous soon so I need you to prepare your nervous system for that.” She was laughing.
This is very intense.
She was like, “What? Who are you?” I said, “Just watch.” And then I got this intuition to put Excel on TikTok. I didn’t even have a TikTok app on my phone at the time. I had so much resistance to it because my mental voice was saying, “You’re 27 years old. You cannot make a TikTok.” My gut voice was arguing, “Make the TikTok.” I ended up putting out a few videos, one per day. The fourth video hit 100,000 views. At that point, I hadn’t told anybody what I was doing besides my mother and my boyfriend. It starts getting shown to all these people I know. I’m thinking, “Oh, gosh.”
By the sixth day, the CEO of an IT company reached out. He wrote, basically, “Hey, I love your teaching style. I’m looking to create training videos in G Suite products for students, parents, and teachers.” This is around the time during the pandemic when all the schools were going digital. I’m clearly a Microsoft gal, but I learn quickly. The spreadsheet products are similar, so I responded, “Sure. I’m game.”
“I ordered a green screen and a ring light and set it up in my childhood bedroom.”
I formed an LLC. I ordered a green screen and a ring light and set it up in my childhood bedroom. I moved the furniture out of the way. I started recording videos after work and selling them back to this guy. At this point, it’s day six on TikTok, and I’m already making money. I decided that I’m just going to keep this thing rolling because I’m helping a lot of people — even though I wasn’t really getting paid off the Miss Excel, social media part of the equation. Within three weeks I went viral on a whole other scale. I looked at my phone to see that one of my videos hit 3.6 million views. I had 100,000 followers on TikTok. At that point, I asked myself: now what do I do?
That was still in June of 2020, when all the rumors were circulating that TikTok is going to disappear or be banned — all that noise. I had all these people in my ear convincing me that my whole business was going to vanish, so I decided that I’d better hedge my risk here. I created an Instagram account and only 2,000 people followed me there from TikTok. At that point, I thought, “I guess I have to go viral now on Instagram, too.” This is when Instagram Reels were first coming out, so within a few weeks on Instagram, I grew 50,000 followers from a video going viral.
How did you make the video go viral on Instagram?
I have some techniques. The way I run my business is different from a lot of the strategies you’ll probably see on social media where the advice is typically to use certain hashtags and make the content a certain length in seconds. The people giving that advice are essentially trying to take these concepts and frame them in a way that they can hand off to anyone.
Instead, the way I run and structure my business is through energetics. I get my energy to a place where my presence is truly magnetic and I will get visions of what will go viral. Then I run to my computer and I make those ideas because essentially social media content is straight-up energy transmissions. You’re receiving my energy through the phone.
If I’m showing up on your social media feed with low energy like, [drops enthusiasm] “Oh, hey. Here’s Excel. Blah, blah,” with that low frequency, the video is not going to hit. I do things to get my energy into a place where, one, I get the viral idea, and two, I’m able to execute it in a way that people are drawn to my energy. That’s how I’ve been able to grow it to over a million people now across the platforms.
At that point, I had no courses. I was just creating viral content. My social media profiles started blowing up. Around October 2020, a business coach reached out to me. At the same time, Morning Brew had reached out. The business coach told me that if I was about to be on Morning Brew, I should have a product I’m selling. To that, I thought, “Oh, touché.” I took a couple of weeks off from the day job to whip out my first Excel course, and started selling it on Black Friday of 2020.
Then, by January, only two months later, the course was already making more money per month than my day job. At that point, I had to reassess why I was staying there — 401k, benefits, health insurance — asking myself, “How am I going to leave that?” I had another business coach who told me that I needed to quit and suggested setting a deadline for me to resign. I quit two days later.
Was that the deadline? 48 hours?
Oh, no, the deadline was two weeks, but I got hyped up! I just needed that big sister energy that Ashley Hannawacker provided. She’s incredible. She came in and asked me, basically, “Girl, what are you doing?” I didn’t know. She insisted that I had to quit, and that was one of my best days. Half of my securitization group at my day job knew about my TikTok and didn’t really understand the caliber of what I was doing. The other half had no idea. All day I was on the phone, like, “Hey, Steve, do you know about me on the internet?” It was a wild day.
By April, I started rolling out a second course. I did my first six-figure month. Business Insider had reached out for a feature. The whole Miss Excel project had been just scaling and growing. By June of 2021, I received the Microsoft MVP award. I also began working with Microsoft to learn more about their products so I could help my audience in better ways. The whole experience has been just incredible. It scaled to my first six-figure day a couple of weeks ago. I was super hyped about that.
Are you making six figures every day?
No, not every day.
Once you hit the peaks, there are valleys as well.
Right. I use webinars and I actually have one two hours after this call. I host these different high-energy Excel parties, essentially, where I come in and I teach a ton of free content. If you look at my page, I’m just giving away knowledge because my social media presence is what draws people in. That’s my purpose: to provide as much value to people as possible. That’s why I host these Excel training sessions and offer a deal on my products at the end of the webinar.
Does that strategy convert to income for you?
Yes.
I have a number of follow-up questions because you are a remarkable person.
Thank you.
Let’s start with the idea you mentioned about having to work on your individual mental constructs before you dance on the internet. I’ve spoken with a lot of people on this show, and you are the first person to ever say anything in that particular Venn diagram. What specifically do you mean by that phrase?
I had a trifecta situation. I’m not sure if you’re familiar with Joe Dispenza. He wrote the book Breaking the Habit of Being Yourself and is a doctor who really dives into demystifying the mystical. I’m an Excel girl. I’m a Capricorn. I have a very logical brain, so I needed something to explain the woo-woo mystical realm in a way that my conscious mind could understand. That’s really where that book opened it up for me; I was blown away by the law of attraction. At the same time, I did a program by Lacy Phillips called “To Be Magnetic” in which you put yourself into a hypnotic state. Once you’re in that state, you are able to bring your subconscious mind forward through binaural noises and all different things.
You essentially show your subconscious that there was another way during certain triggering memories. You’re able to go in and neutralize the electromagnetic charges associated with those memories. Those memories are no longer taking hold. From age zero to seven, we don’t have critical thinking skills. Everything that happens is incredibly more dramatic to a child. When I was able to go into my subconscious, I neutralized all those memories that were boxing me into making myself smaller, keeping me shy, and preventing me from showing up as my most authentic self.
That’s something I would highly recommend doing, whether it’s meditation, mindfulness — everyone has something that works for them. I also do a lot of Kundalini yoga, which involves mantra, meditation, and activities that get my energy moving. For me, that was a great tip. I know people who have done all different programs: one of my friends did 75 Hard to really get into those different habits and reprogram the subconscious mind.
Before doing these programs, I never wanted any attention directed at me. I wouldn’t even have a birthday party. I was so incredibly shy. Now I’m dancing to dumb TikToks about Excel functions for a living and I love every second of it. I feel so confident. That change really is a testament to the inner work and how anybody can really just take wherever they’re at and go into their subconscious and rework these things. You don’t have to take life at face value. You are a quantum creator. That’s what really helped me drive and grow the business. The growth of the whole project has been a result of inbound leads. Every press opportunity, every sale, every bulk order, every podcast — everything has fallen onto my lap, essentially. Then I take messy action and go after things. It’s really this dance.
In terms of thinking about how to go viral, you mentioned that you put energy into the world and think about how to draw people to you magnetically. That’s a lot of vocabulary. What do you mean by “draw people to you magnetically”?
Think about when you watch a video: some videos make you feel good while others don’t. That’s the most basic way to frame it. I create videos that you are going to learn from; however, you are also going to have a smile on your face. I work on myself and raise my energy to a place where I’m coming across correctly on the platforms to make people happy. People want to watch things that raise their vibration. People want to watch things that make them happy and give them energy and inspire them. That process involves looking internally and then channeling that within me. That way, I can put that feeling into my content so the audience is not only learning, but they’re also having fun. That’s the name of the game.
“I work on myself and raise my energy to a place where I’m coming across correctly on the platforms to make people happy. People want to watch things that raise their vibration. People want to watch things that make them happy and give them energy and inspire them.”
Do you think of your magnetism as a competitive advantage? There are other Excel influencers — it’s surprising that “Excel social media star” is a burgeoning category, but it definitely is. Are you thinking of your content strategy as a moat? Are you thinking to yourself, “This is me”? How do you think about that in terms of the business you’re running?
I just work on myself and show up authentically every day. I really don’t view anything as competition. We’re all out here helping people. We’re all out here on the same mission. What I do is really just bringing my own authentic spin onto what I’m creating and putting out there.
What was the first piece of feedback where you realized that your strategy was working and that you needed to turn Miss Excel into a webinar business — as opposed to other, more familiar types of social media monetization? It doesn’t seem like you’re doing a lot of brand deals. You’re not selling Excel itself. You’re not doing advertising: I haven’t seen you endorse water bottles or whatever other people do. What are the things that pushed you into this particular revenue model?
I came into all this because I wanted to create the life that I wanted for myself. I wanted freedom: financial freedom and geographic freedom. I wanted just to be able to do what lights me up every day. For me, the passive income model was the fastest way to get to that place. For example, if I’m not launching courses, I work maybe 15 hours a week. I spend a lot of that time in a creative state of flow. Those are usually the days that the most sales will actually come in because I’m in that receiving energy. I wanted to create a life for myself where I can travel. My boyfriend and I right now are digital nomads: every month we fly to a new state. I wanted to live and explore while I’m still young instead of waiting until I retired. This business model is incredibly conducive to that.
What are your costs? Did you buy a fancy camera? You mentioned buying a big ring light earlier.
When I first started the business, I bought a ring light and a green screen. I use my iPhone to film my videos. My overhead, right when I started, was probably around $500 a month and everything else was profit. I hired an advertising company a few months ago, so I’m starting to get into a new presence — a few Facebook, Instagram, and LinkedIn ads. That has a little bit of overhead a month, but most of what I do is just straight passive income.
You also mentioned that you’re selling Miss Excel through a platform. Is that a contractual relationship? Is the platform self-service? How does that work?
I pay roughly $150 a month to use Thinkific. It’s a platform that hosts all my courses and completely automates the whole monetization process: a client signs up, pays the money, and then that money goes in my bank account. All of that is lined up through the platform.
Does Thinkific take a cut of those transactions?
I believe they do. My Stripe payment processor takes a cut as well.
As you get scale, have you thought about negotiating those prices down, or are you just not at that place yet? Other businesses will see, for example, that they are paying 30 percent of their in-app purchases to Apple on the App Store and decide that they are not getting any value out of that. Are you at that part of the curve?
My Thinkific plan is the growth model, so I’m pretty sure I only pay a few pennies per person. Stripe, I think, takes 3 percent. It’s really nothing dramatic.
These are just dumb, basic questions. Are you paying for Creative Cloud to edit the videos? What software do you use?
This is actually funny. When I first started the business, I worried about how I was going to put an Excel screen over my head, since I had never edited a video in my life. At that point, I was still working 60 hours a week at a day job, so I needed to find the easiest program to learn. I Googled, “What is the easiest video editing software?” WeVideo is what I found. I watched a 40-minute YouTube video tutorial on that program. I’ve used WeVideo to create all my videos and courses ever since. I don’t edit on apps like TikTok or Instagram to avoid their watermarks when I upload videos cross-platform.
So is the desire for your videos to live away from the platform the driving factor for you to use another piece of software?
Yes.
To me, this is the heart of every creator conversation on Decoder. Most creators have a business that looks like the business the platform wants you to have: most Instagramers have a brand licensing or partnership business, while most YouTubers have an AdSense business. You haven’t limited your business to the form the platforms would like it to take: you’re building Miss Excel independently of the platforms. Was that an accident or was it pre-planned? How did you get to this point?
That was the model I knew. I have a lot of business coach friends making millions of dollars a year with 5,000 followers; they built out these different coaching containers. For me, that was the model I followed: you create some type of course or product and you sell it. I’ve done a couple of ads for supplement companies and things like that, but they don’t make me money. They’re not translating — I just genuinely love the product so I wanted to work with them, but my audience loves Excel and that’s what they’re here for. That’s what sells.
One of the things about Excel and Google Sheets is that the products change. Excel releases new versions often, and Google updates a bit less frequently. A lot of the TikToks I’ve seen are about core Excel functions: pivot tables and changing uppercase to lowercase in names. These are tricks people don’t know about, but then they realize it’s very easy once they learn. That content is very grabby, but as you get deeper into Excel, the interface changes or features are added. Do you worry that you have to chase Microsoft’s roadmap or do you think your content is pretty evergreen?
It’s pretty evergreen. Excel doesn’t change as much as you think. Whenever there are new functions or fun features coming out, I usually get to learn about them early and figure out cool ways to implement them because I work with Microsoft as an MVP. I use that knowledge to drive my content and courses. Everyone gets lifetime access when they purchase my courses and I’m constantly adding in anything new and cool that comes up, so my videos always have the freshest content.
So people get lifetime access for a single one-time payment of $997, correct?
It’s for the bundle. Yes, you get everything.
A lot of other places in this zone — MasterClass, Lynda, and the like — are charging a subscription fee. Why aren’t you doing subscriptions?
Excel’s a little different in terms of learning curve. A customer could pay $10 to $25 a month — then they could take my course in a weekend and be totally done. The subscription model doesn’t work out as well. For me, the secondary feature is the subscription-type feature. A client could learn everything in a weekend, let’s say. That person knocks out my Excel course. They really get it. But then three months later, they go to do a VLOOKUP and need to brush up on what I showed them in the video. That’s why I wanted to have it as an ongoing thing, as that added resource.
“The subscription model doesn’t work out as well.”
I structure my courses in a way where they are organized by individual tool. So if you’re needing to do a VLOOKUP — boom! You can see it right there: 10 minutes, get an example, pop that in. But that system was a secondary feature that would align more with a subscription model. A lot of people just dive in and study the material, so if I had a subscription at a lower cost point, they could just cancel it after they learn it.
Do you think that eventually you might add other pricing models or other ways of monetizing what you’re doing?
Potentially. Right now the price points have been great for the courses — bundling them in different ways. I also do corporate trainings on occasion, so I have higher-ticket items offered and I do bulk discounts for companies as well. That’s another area that I work in.
One of the challenges with platforms in particular is the instability: one app might get shut down, forcing you to use another. The government might break Facebook up into a billion pieces. There’s a lot of that going on with the platforms — for instance, Instagram is turning into a shopping app and the grid is being disfavored in terms of Stories and now Reels. Do you think about those dynamics? As in, “I’ve got to stay present on the apps because they’re my core marketing functions, so now I’ve got to make sure I know what Instagram wants out of me”?
Yes, though I view it from the lens of abundance. My attitude and thought process is basically: if Reels are hot, make some Reels. I look at it as adapting to whatever the platform’s putting out because it’ll allow me to have the greatest reach, versus having an outlook of being forced to do something or else I won’t be present on the apps anymore. I just flow with what’s there. I keep an eye out for trends and things happening, different apps.
Where do you source trends?
Usually I go on TikTok and hit the sounds button, which allows you to see what songs are trending. Then I get myself into a creative flow state. It usually takes me about an hour to really get in there. I listen to the snippets of the different songs and that’s when I get the intuitive hits of, “Boom, that song needs to go with this Excel trick.” Some people ask how I match rap songs to Excel tricks — ”Drop It Like It’s Hot” to a dropdown menu for instance. But that’s really my creative process: I go in and I get into a flowy state. Then when I hear certain lyrics, I’m thinking, “Ooh, there we go!” Then I write them in a note on my phone and batch create them.
What’s your process with Instagram?
Same thing — I’ll still use the TikTok music button, because a lot of it is very aligned across the two platforms. Sometimes TikTok has more music options than Instagram, so that always gets a little dicey, but I create content across the platforms. I started making content for LinkedIn recently. I created a Twitter and have basically no followers, but Microsoft tweeted at me and I realized I need to get on the Twitter game.
Twitter is what poisons your mind in the end.
I’m a Twitter noob.
Just as little Twitter exposure as you can get is what’s going to keep you in that head space, I promise you. When you think about your marketing channels and how successful they’ve been, and now that you’ve hired a firm to do the paid side of the marketing channels, what are you hoping that they will accomplish?
Scaling. I want million-dollar months — that is what I’m aiming for. It’s really now just scaling on different platforms and creating different types of content. My ads are actually Excel tricks so they’re functional. People actually like and comment on my ads. They end up sharing the ad because they learned something from it.
When you think about massive scale, one of the things that comes up with creators on this show a lot is burnout: if you don’t make the next YouTube video, your views are going to drop. If you don’t make the next Instagram story, you’re not relevant anymore and the brand deals might go away. It is a real fear. I’ve heard a lot about creator burnout. Are you at the point where you’re trying to manage burnout or not?
No, because I just don’t view the world that way. I view it through a lens of abundance. The number one thing I do is energy management, and I only call in things into my realm that I can handle. I always feel comfortable saying yes to things: I know if an opportunity is presented to me, that I can handle it. I have a lot of techniques for stress: when I meditate, I come back out 10 minutes later, ready to take over the world. It’s really just managing those things. When I go a week without posting, nothing bad happens — I’ll just go viral the next week and my audience grows by 100,000. I just view it as though there will always be abundance there for me whenever I feel called to create. If I want to take a week off and go sit in the mountains instead, I’ll do that.
What’s fascinating about this is that, for most of the other creators I talk to — their product is their social following. Your product is not. Do you see that the distance between the two is what enables you to have this radically different perspective? The fact that your product is not your social following has enabled other things, so are you focused on making sure that you have a split there?
Absolutely. I just trust in the fact that I know I’m going to keep creating viral content. I had a video for the song “The Assignment” a few weeks ago, and it hit 6.7 million views on both platforms and my Instagram grew by 200,000 people in 10 days. It’s that type of thing where I just trust that I can do that, and boom. That’s a whole huge new customer base. As long as I keep myself happy and I keep myself in this state of abundance, I can keep going inward and getting those intuitive hits of what will go viral. It’s never a scarcity mindset. If I didn’t post today, my life isn’t over. My fans won’t be wondering where I am. I think some of them care about my life, but it’s a utility account. They care about the Excel content.
As long as I have videos blowing through the algorithm and I’m still creating tips and tricks — I actually find that on the days where I don’t post, I gain the most followers. I still have Reels going through the algorithm, and when people unfollow you, it’s typically because you appear on their screen and they remember you exist and they decide to unfollow. If I look at my trends on the days I don’t post, I have Reels being pushed out to people who don’t follow me who are now following me. However, the people who follow me already saw the Reel, so they’re not thinking about me. That’s actually a strategy I have for growth because you get fewer unfollows on the days you don’t post.
I cannot believe I haven’t asked this question already. Do you track these things in Excel?
Actually, they move so quickly that I don’t. I just flow because it really doesn’t implicate what I do. I still go based off my intuition. And if I hear a song, I have a hit, I’m not going to be thinking that on Tuesday I lost 12 followers so I shouldn’t post. I still do me, and that authenticity is what really drives it.
You run your business in Excel though, right? I have to know that you’re not a secret QuickBooks person on the side.
Oh no, no, no, no! I run my business through Excel, yes.
Okay. Just checking. That brings up another opportunity: you can scale into other software, since there is a big market for training overall, but there’s only one of you — you’re literally known as Miss Excel. Sure, Google Sheets comes along for the ride too. Do you want to be known as Miss Outlook?
I have an Outlook course drafting in the next few weeks. I have courses for the entire Microsoft suite going on right now that are percolating. I’m in my creative mode up here in the mountains. I’ve been just recording videos nonstop. I have seasons where I’m in creation mode and then I’m in a flowy mode.
Right now, we are in Q4: going in, creating, building all these courses. I had learned things really quickly and I was also obviously very familiar with Microsoft products, so I really sat with them and just found cool, creative things to do. With Excel, I originally wondered, “Should I be Miss Microsoft instead or something?” but Miss Excel has grown into such a brand — I know people still trust that I know how to use the other Microsoft products and Google Sheets and all that even though I fall under Miss Excel.
Excel is also just such a different program than all the others. Excel has a following. Excel has passion behind it because it’s literally just a way to build models. It’s essentially a freeform app where you can create different models on it, so it has this whole separate following. There’s just so much you can do with it too as compared to the other products. It’s wild. I’m always learning things.
One of the jokes we tell on our other show all the time is, if you look at any business and what people are actually doing, a huge percentage of businesses are just people using Excel. At the end of the day, someone’s got to use Excel. That’s actually the work, and everyone else is just talking about what the person using Excel is doing.
Here’s a big question: earlier this year, I had a guy called Kevin Roose from the New York Times. He had just written a book about automation hitting the white collar workforce, and one of the big pieces of that is something called robotic process automation, which Microsoft actually sells. Robotic process automation is basically really high-end Excel macros that replace floors of accountants and consulting firms. Do you feel that a cliff is coming? Are you worried that the robots are all going to be using Excel in the future, not people who want to see dancing on TikTok?
I think there’s always going to be room for Excel. I think the program will just keep continuing to develop and grow. It’s just going into so many different markets too. The Excel online space is something that’s been growing more robustly. It’s being used in schools with kids. I just started working with Flipgrid, which has 100 million students, parents, and teachers on it. I’m taking my Excel tricks there so people can put them into classrooms and start teaching these different skill sets at a younger age.
I think that it’s always going to be around in some way, shape, or form. There will be people in the spreadsheets and it will just keep moving along. There’s cool things happening too: I was reading about different things with Microsoft Teams that will make that realm more virtual. I think it was called Mesh or something where they were bringing in their own version of metaverse-type things. It’s Microsoft — they’re going to continue to expand and grow and keep the customer base going.
You’ve said a few times that Miss Excel and your social media accounts are a utility, and they are. People love Excel. They want to get better at it. You make it fun. The other side of creatordom is your personality. You obviously have a gigantic personality, but that’s what most creators sell. “Come live in my life. Ride my G-wagon through the streets of LA.” That works for them. Have you thought about selling that part of yourself, about being that kind of influencer?
Definitely down the line I want to really show people how I’m able to make and manage such a healthy relationship with social media, growing a business, being an entrepreneur — all while genuinely waking up happy every day. Part of my master plan is that I just want to blow this business up as big as humanly possible and then turn around and teach people how I did it, and also how I stayed so sane and happy while doing it. My overall purpose on this planet is to light up as many people as I can while I’m here. I want everyone living their authentic purpose — feeling good, showing up, doing what they love. I built a platform for myself through Miss Excel so that eventually I will be able to light some people up, because that’s what I’m here for.
Do you think you can do that without tearing down the wall between the utility you make for people teaching Excel and your life? It seems like your personal life is not on display, which might be why it’s a healthy relationship with social media.
I balance it a little bit. On my Instagram Stories, you’ll see me running around Sedona doing whatever. I get so many DMs from people saying things like, “Whoa, that just rocked my world. How are you doing that?” It’s been more of a behind-the-scenes thing, but eventually maybe I’ll just go viral on my personal page and start teaching these different things and grow that separately. Alternatively, I might integrate it into the Excel page and start coaching through there and helping people grow their businesses through energetics and managing your energy.
So we’ve talked about how you have a healthy and important distance from social platforms. As you think about your relationship with Microsoft, they’re showing you the features — are you worried that you’re maybe reliant on one vendor? Or are you trying to keep a distance from all of them?
“I absolutely love Microsoft.”
No. I absolutely love Microsoft. They have been incredible to me, and I love working with them. It’s such a big company, so I’m always talking to different groups about different things. I also teach the Google products too, but I feel like Microsoft is big enough that those products are used in so many different businesses and that just opens doors in all different areas. If I wanted to do collaborations with different companies and work on their tools with them, then it’s all the same base.
I talk to creators all the time. They all tell me that YouTube is the gold standard for monetization and for audience relationship. You have a Twitter, but you don’t have a YouTube. That’s pretty backwards in terms of what we see typically. Are you staying out of YouTube entirely? Do you have a YouTube plan? What’s going on there?
I think I’m going to start advertising on YouTube, but for me, the course sales make so much more sense. If I was teaching my courses for free on YouTube, no one would pay for them. For me, it just made more sense to continue doing that instead of trying to grow an audience over time and get ad money on YouTube. I’m not saying I’ll never do it. I saw there’s new little YouTube Shorts and things like that, so I might look into it. But right now, what I’ve got going has been working so well.
Right now I’m heads down, creating courses, creating passive income streams. If I ever get to the point where things are quiet and I’m in the mood to do something — never say never. I may dabble.
YouTube is another platform that can eat your brain, so it seems like you’re in a very good head space. The farther away you keep Twitter and YouTube, the better off you are. Do you think about branching out to the whole Microsoft suite — Outlook, Teams, Word, and PowerPoint? Or even other creative suites? I’m sure you could be Miss Photoshop if you went for it.
I love Photoshop.
You are only one person. Have you ever thought about when you might need to add another person?
Yeah. I think it depends on where I want the business to go and how much it’s making passively. Building it into a full business is another whole area of time commitment. Having to be a CEO with all that entails, hiring and training people — I would need to really gauge whether that’s worth my time building it in that direction. What I have right now is 95 percent passive. Trading time for money is something I absolutely don’t want to do. I would need to have that vision and feel so strongly about it and have the right people.
I also learn things incredibly quickly, so sometimes I am able to just pick up different skills. If I don’t know a certain skill, I’ll watch a few videos on it. At that point, I understand it totally and am able to teach it. I would have to gauge whether it’s something I’m interested in learning or whether I’d rather hire someone and do payroll. I’d have to be more interested in it than traveling around, having passive income. I’d have to gauge which lifestyle I want to have at that stage in my life, too.
What do you think the timeline is for a decision like that? I’ll use The Verge as an example: we started with 12 people and management overhead from the very beginning. But as we’ve grown, a lot of us, myself included, had to make decisions where we’re thinking, “If we’re going to have 50 people, most of my time will become management. It’s either that or I’m going to have to let someone else do it, which is worse, so I’m going to choose to be the manager.” There’s another timeline of business growth where you choose to be the individual contributor for the next 10 years and that’s what your life will look like. Alternatively, you can scale it but then you have to do a different kind of work. Maybe that’s the new challenge. Have you thought about that kind of timeline?
Yes. I feel like I want to give it at least another year. The whole project is just scaling so quickly that it’s hard for me to even imagine a timeline, because if you’d have asked me a year ago, I wouldn’t have thought it’d be as big as it is right now. I keep collapsing timelines. All of a sudden I’m 10 steps ahead of where I thought I’d be right now, so it’s tough to tell. I’m going to get these courses out in the next few weeks and then I want to see how big it’s scaling. Really, if I’m ever bored, then I think that’s something I would look into. But right now, Miss Excel has been going so well that I’m just rocking and rolling with it for now.
Do you ever think you have to circle back to the first Excel video you made, thinking maybe, “I wasn’t so good at WeVideo then. The interface has changed. I need to remake it”? Are you thinking about your videos on an update cadence that way?
Eventually I’m going to update certain videos, especially when new different features come out in Excel. But the courses are really cool and fun. Sometimes I go through my own stuff because I want to know what it’s like for the audience, and I’ll think, “Dang, I’m pretty funny today.” I’ll watch my videos and just be sitting there cracking up at myself, having a grand old time. I just made them less than a year ago, so it’s still pretty fresh.
Kat, this conversation has been incredible. What’s next for Miss Excel?
So many things. Honestly, I can’t even tell you what’s next, because everything just keeps flowing with me. Short term: we have the rest of the Microsoft courses launching in the next few weeks. I’m super hyped about that. I’m really just scaling from here — scaling holiday season, Black Friday, doing it up, seeing where we land Q1 2022.
I love it. It’s been incredible talking to you. Thank you for coming on Decoder.
Thank you so much for having me.
Decoder with Nilay Patel /
A podcast from The Verge about big ideas and other problems.",1
402,"The Lord of the Rings: The Rings of Power
|The Lord of the Rings:|
The Rings of Power
|Genre|
|Based on||The Lord of the Rings and appendices|
by J. R. R. Tolkien
|Developed by||J. D. Payne|
Patrick McKay
|Theme music composer||Howard Shore|
|Composer||Bear McCreary|
|Country of origin|
|Original language||English|
|No. of seasons||1|
|No. of episodes||8|
|Production|
|Executive producers|
|Producers|
|Production locations|
|Running time||65–72 minutes|
|Production companies|
|Distributor||Amazon Studios|
|Release|
|Original network||Amazon Prime Video|
|Original release||September 1, 2022 –|
present
The Lord of the Rings: The Rings of Power is an American fantasy television series developed by J. D. Payne and Patrick McKay for Amazon Prime Video. Based on the novel The Lord of the Rings and its appendices by J. R. R. Tolkien, the series is set in the Second Age of Middle-earth, thousands of years before Tolkien's The Hobbit and The Lord of the Rings. It is produced by Amazon Studios in association with New Line Cinema, and in consultation with the Tolkien Estate.
Amazon bought the television rights for The Lord of the Rings from the Tolkien Estate in November 2017, making a five-season production commitment worth at least $US1 billion. This would make it the most expensive television series ever made. Payne and McKay were hired in July 2018. The series is primarily based on the appendices of The Lord of the Rings, which include discussion of the Second Age, and Tolkien's grandson Simon Tolkien was consulted on the development of the series. Per the requirements of Amazon's deal with the Tolkien Estate, it is not a continuation of The Lord of the Rings and The Hobbit film trilogies, despite having the involvement of New Line Cinema, responsible for both trilogies. The production intended to evoke the films using similar production design, younger versions of characters from the films, and a main theme by Howard Shore, who composed the music for the trilogies. Bear McCreary composed the series's score. A large international cast was hired, and filming for the eight-episode first season took place in New Zealand, where the films were produced, from February 2020 to August 2021 (with a production break due to the COVID-19 pandemic). Amazon moved production for future seasons to the United Kingdom, where filming for the second season began on October 3, 2022.
The Lord of the Rings: The Rings of Power premiered on September 1, 2022, with the first two episodes, which Amazon stated had the most viewers for a Prime Video premiere. The rest of the eight-episode first season ran until October 14. It has received generally positive reviews from critics, with particular praise for its cinematography, visuals, and musical score, but criticism for its pacing and characterization.
Premise
Set thousands of years before the events of The Hobbit and The Lord of the Rings, the series is based on author J. R. R. Tolkien's history of Middle-earth. It begins during a time of relative peace and covers all the major events of Middle-earth's Second Age: the forging of the Rings of Power, the rise of the Dark Lord Sauron, the fall of the island kingdom of Númenor, and the last alliance between Elves and Men.[1] These events take place over thousands of years in Tolkien's original stories but are condensed for the series.[2]
Cast and characters
- Morfydd Clark as Galadriel: an Elven warrior who believes evil is returning to Middle-earth.[2] The series shows the character's journey from a warrior to the ""elder stateswoman"" that she is portrayed as in Tolkien's The Lord of the Rings. The showrunners based her initial depiction in the series on a letter in which Tolkien described a young Galadriel as being of ""Amazon disposition"".[3] Clark said her fluency in Welsh made it easier to learn Galadriel's Elvish lines.[4] Amelie Child-Villiers portrays a young Galadriel.[5]
- Lenny Henry as Sadoc Burrows (season 1): a Harfoot elder.[2][6] Henry described the Harfoots as ""the traditional Tolkien little guy... the little people in this world provide comedy but also get to be incredibly brave"".[7]
- Sara Zwangobani as Marigold Brandyfoot: a Harfoot and Largo's wife[8]
- Dylan Smith as Largo Brandyfoot: a Harfoot and Nori's father[8]
- Markella Kavenagh as Elanor ""Nori"" Brandyfoot: a Harfoot with a ""yearning for adventure"" who is the daughter of Largo and stepdaughter of Marigold.[9][4]
- Megan Richards as Poppy Proudfellow: a curious Harfoot and Nori's friend[2][6]
- Robert Aramayo as Elrond: a half-Elven architect and politician.[2] Aramayo was interested in exploring the pressure that Elrond faces living up to the legacy of his father, Eärendil, as well as the fact that Elrond chose to be immortal, unlike his brother Elros, whom Elrond had to watch grow old and die.[4] Elrond goes from being optimistic and eager to world-weary and closed-off through the series.[3]
- Benjamin Walker as Gil-galad: the High King of the Elves, who rules from the realm of Lindon.[10] The character is mentioned in Tolkien's The Lord of the Rings in a poem called ""The Fall of Gil-galad"", and Walker said the series would expand on that. He highlighted the character's ""odd gift of foresight. He's prescient, and he's ahead of the curve. He can kind of feel the pulse of evil rising.""[4]
- Ismael Cruz Córdova as Arondir: a Silvan Elf with a forbidden love for the human healer Bronwyn,[2] similar to Tolkien's love stories about Beren and Lúthien and Aragorn and Arwen[3]
- Nazanin Boniadi as Bronwyn: a human mother and healer, who owns an apothecary in the Southlands[2]
- Tyroe Muhafidin as Theo: Bronwyn's son[11]
- Charles Edwards as Celebrimbor: the Elven smith, who forges the Rings of Power,[2] he is a ""brilliant artisan"" known throughout Middle-earth who is friends with the Dwarves of Khazad-dûm.[4]
- Daniel Weyman as The Stranger: one of the Istari, who falls from the sky in a flaming meteor[9][12]
- Owain Arthur as Durin IV: the Prince of the Dwarven city of Khazad-dûm.[2] It took three hours to apply Arthur's Dwarven prosthetics each day.[4]
- Charlie Vickers as Sauron / Halbrand: the Dark Lord of Mordor who disguised himself as a Southland human.[2]
- Sophia Nomvete as Disa: Durin IV's wife and Princess of the Dwarven city of Khazad-dûm.[2] Disa and the other female Dwarves have facial hair, but not large beards like the male Dwarves.[4]
- Lloyd Owen as Elendil: a Númenórean sea captain and Isildur's father, who will eventually become king and a leader in the last alliance between Elves and Men[13]
- Cynthia Addai-Robinson as Míriel: the queen regent of Númenor,[13] an island kingdom ruled by Men descended from Elrond's half-Elven brother Elros[14]
- Trystan Gravelle as Pharazôn: a Númenórean advisor to queen regent Míriel[13]
- Maxim Baldry as Isildur: a Númenórean sailor, who will eventually become a warrior and king.[2] The writers wanted to explore Isildur's story more than the source material so the audience would feel that it ends in tragedy rather than foolishness. Co-showrunner Patrick McKay compared the character to Al Pacino's Michael Corleone from The Godfather (1972).[3]
- Ema Horvath as Eärien: Isildur's sister, who was created for the series[13]
- Joseph Mawle as Adar: an Uruk, who is the leader of the Orcs that have been capturing humans to dig tunnels[15]
- Leon Wadham as Kemen: Pharazôn's son[13]
Episodes
|No.||Title||Directed by||Written by||Original release date|
|1||""A Shadow of the Past""||J. A. Bayona||J. D. Payne & Patrick McKay||September 1, 2022|
|After the Dark Lord Morgoth was defeated, his chief servant Sauron is searched for by the Elf Galadriel, in remembrance of her brother Finrod who died fighting Sauron. Galadriel finds an abandoned fortress in the northern wastelands of Forodwaith which bears Sauron's mark. Her companions insist that they return to the Elven capital Lindon, where High-king Gil-galad proclaims the war against Morgoth's forces to be over. He grants Galadriel and her company the honor of sailing to Valinor where they can live an eternal life at peace. In the Southlands of Middle-earth, Elves watch over Men descended from allies of Morgoth. The Elf Arondir has developed a close relationship with the human healer Bronwyn, to the disapproval of her fellow Tirharad villagers. Together they discover that the neighbouring village of Hordern has been destroyed, while Bronwyn's son Theo finds a broken sword bearing Sauron's mark. Near Valinor, Galadriel chooses to turn back and continue the search for Sauron, jumping from the ship into the Sundering Seas. At the same time, two Harfoots, Nori Brandyfoot and Poppy Proudfellow, discover a strange man inside a meteor crater.|
|2||""Adrift""||J. A. Bayona||Gennifer Hutchison||September 1, 2022|
|Swimming back to Middle-earth, Galadriel comes across a raft with human survivors of a shipwreck. They are attacked by a sea monster and only one survives, Halbrand of the Southlands, who explains that he is fleeing from Orcs. He and Galadriel work together to survive a storm. Nori and Poppy keep the Stranger secret from the other Harfoots and give him food and shelter. He does not speak their language but uses fireflies and apparent magic to indicate that he is searching for a constellation of stars that Nori does not recognize. Arondir investigates tunnels beneath Hordern and is captured. Bronwyn returns to her own village, Tirharad, where an Orc attacks her and Theo. They kill it and use its head as proof of danger to convince the rest of the town, including Waldreg the tavern owner, to leave. Gil-galad sends the half-Elf Elrond to assist the great Elven-smith Celebrimbor, who is planning to build a powerful new forge. Elrond suggests they seek help from the Dwarves, and goes to his friend Prince Durin in Khazad-dûm. Durin is angry that Elrond has not visited in 20 years, but his wife Disa convinces him to hear Elrond's proposal.|
|3||""Adar""||Wayne Che Yip||Jason Cahill and Justin Doble||September 9, 2022|
|Galadriel and Halbrand are picked up by a ship captained by Elendil, who takes them to Númenor, an island kingdom ruled by Men. Relations between the island and the Elves have grown strained, and Queen Regent Míriel denies Galadriel's request for a ship back to Middle-earth. Galadriel visits Númenor's Hall of Lore with Elendil and discovers that the mark of Sauron is actually a map of the Southlands where a new realm for evil forces is planned. She also learns that Halbrand, who is imprisoned after fighting some Númenóreans, is the king of the Southlands. As the Harfoots prepare for their seasonal migration, the Stranger is revealed while trying to read some star maps. He comes with them as they migrate, pushing Nori's wagon since her injured father is unable to. Arondir has been captured by Orcs and taken to a construction camp digging underground passages so Orcs can travel during the day. His Elven compatriots have also been captured and they are killed during an attempted escape. After slaying a Warg, Arondir is taken to the leader of the Orcs named Adar, which the Elves speculate to be one of the names of Sauron.|
|4||""The Great Wave""||Wayne Che Yip||Stephany Folsom and J. D. Payne & Patrick McKay||September 16, 2022|
|Míriel has a vivid dream of the tidal-wave destruction of Númenor. Chancellor Pharazôn encourages discord between the Númenóreans and Elves. Halbrand manipulatively advises Galadriel, then Pharazôn. Míriel shows Galadriel the vision of Númenor's destruction in a palantír. Galadriel persuades Míriel to wage war against the Orcs in the Southlands and war preparations begin. Isildur and his friends are kicked out of the Sea Guard but then join the war effort. Adar appears to be a scarred elf from the Elder Days, and he releases Arondir to give a surrender offer to the human villagers of Tirharad taking refuge in the Elven watchtower of Ostirith. The Tirharad tavern-owner Waldreg introduces himself to Theo as a servant of Sauron, and the Orcs are informed that the ancient artifact of the broken sword, which they have been seeking, is now in the watchtower of Ostirith. The Dwarves have found mithril and keep it a secret, but Elrond discovers the existence of the mine. The ore is very dangerous to excavate due to tunnel collapses in the old mine. King Durin III sends Prince Durin to discover what the Elves of Lindon are up to.|
|5||""Partings""||Wayne Che Yip||Justin Doble||September 23, 2022|
|While protecting Nori from a wolf pack, the Stranger's use of magic injures his own arm. As he heals it using conjured ice, Nori accidentally connects to his mind, blasting and frightening her away with a shockwave. In Númenor, Míriel decides to support an expedition to Middle-earth, and Galadriel convinces Halbrand to join it after retelling her battles and losses against Sauron. Before they can leave, Kemen attempts to destroy the expedition ships to help his father Pharazôn rise to power, but Isildur prevents him and earns a spot on the expedition crew (he does not implicate Kemen). In Lindon, Gil-galad reveals to Elrond his knowledge of mithril and his intention to use it to extend the existence of the Elves. Elrond admits this discovery to Durin, and they return to Khazad-dûm to try to convince King Durin. In the Southlands, half of the villagers, led by Waldreg, leave Ostirith to accept Adar's surrender offer and join him; Waldreg believes Adar is Sauron. In Ostirith, Theo shows the broken sword to Arondir, who realizes it is a key for turning the Southlands into Sauron's realm of evil. The remaining villagers in the watchtower of Ostirith prepare for battle against the approaching Orc army.|
|6||""Udûn""||Charlotte Brändström||Nicholas Adams & Justin Doble and J. D. Payne & Patrick McKay||September 30, 2022|
|Adar's army finds the watchtower abandoned; Arondir destroys the tower, collapsing it onto the Orc army. Having retreated to Tirharad, Arondir hides the broken sword and professes his love to Bronwyn. The ensuing battle in Tirharad begins well for the villagers but they discover that many of the enemies are traitorous villagers disguised as Orcs. The main Orc army then attacks killing many and severely wounding Bronwyn. To save Bronwyn, Theo reveals the location of the broken sword to Adar. After journeying across the sea, the Númenórean army arrives at the village and routs Adar's army. Adar gives Waldreg a task before attempting to escape but is captured by Galadriel and Halbrand. Under interrogation, Adar reveals his origins as one of the Moriondor or Uruks, Elves corrupted by Morgoth, and claims to have killed Sauron. As Halbrand is hailed as the King of the Southlands, Theo realizes the broken sword they recover from Adar is a decoy. Waldreg has the real sword and plants it into a mechanism that opens a nearby dam. The water rushes through the Orc tunnels towards Orodruin and clashes with magma, resulting in a phreatomagmatic eruption and a pyroclastic flow that approaches the village.|
|7||""The Eye""||Charlotte Brändström||Jason Cahill||October 7, 2022|
|Surviving villagers flee the burning Tirharad. Míriel has lost her eyesight and Isildur is missing. Míriel promises Galadriel more Númenórean support. Galadriel escorts a wounded Halbrand to Eregion for Elvish medicine. Elsewhere, Nori's caravan finds their destination grove has been destroyed by the eruption of Orodruin. The Stranger's attempt to mend a tree appears to fail and he leaves. The next day, the entire grove has regrown. While the Harfoots rejoice, they encounter a mysterious trio who are in search of the Stranger. After a failed attempt by Nori to mislead them, the trio burns the Harfoots' caravans. Realizing the danger they set off to warn the Stranger. Meanwhile, in Khazad-dûm, Elrond offers a deal for the Dwarvish mithril, but King Durin III declines, saying that the Elven Age has ended. As Elrond departs, Prince Durin witnesses mithril's ability to cure the Elven blight in a leaf. He brings Elrond back and begins to mine for the ore himself. Just as he strikes a large mithril vein, King Durin arrives. He has Elrond banished, strips Prince Durin of his royalty, and seals the mithril mine, not realizing that a Balrog has been awakened. The destroyed Southland is renamed as ""Mordor"".|
|8||""Alloyed""||Wayne Che Yip||Gennifer Hutchison and J. D. Payne & Patrick McKay||October 14, 2022|
|Galadriel and an injured Halbrand arrive in Eregion. Halbrand gives Celebrimbor the idea of forging the mithril with other metals to enhance its strength. Galadriel becomes suspicious and checks into the royal lineages of the Southlands. In the East, the Stranger meets the mysterious trio, who greet him as ""Lord Sauron"", whom they are pledged to serve. Nori and the Harfoots manage to steal the leader's magical staff at the cost of Sadoc's life. The Stranger then uses the staff to banish the trio into darkness. They realize the Stranger is not Sauron, but one of the Istari. In Eregion, Galadriel confronts Halbrand with her discovery that he is not a Southland king, and the latter reveals himself to be Sauron. She refuses his offer to become his queen and rule Middle-earth. Sauron overpowers Galadriel and flees to Mordor. Galadriel, Elrond, and Celebrimbor forge the Three Rings. Elendil and Míriel arrive back to Númenór to find king Tar-Palantir has died. Back amongst the Harfoots, the Stranger and Nori decide to depart the group and travel east into Rhûn. Unsure which way to go, the Stranger advises that when in doubt, to ""always follow your nose"".|
Production
Development
Background and announcement
In July 2017, a lawsuit was settled between Warner Bros., the studio behind The Lord of the Rings and The Hobbit film trilogies, and the estate of author J. R. R. Tolkien upon whose books those films were based. With the two sides ""on better terms"", they began offering the rights to a potential television series based on Tolkien's The Lord of the Rings to several outlets, including Amazon, Netflix, and HBO,[16] with a starting price of US$200 million.[2] Amazon emerged as the frontrunner by September and entered negotiations.[17][18] Uncommonly for programming developments at the studio, Amazon CEO Jeff Bezos was personally involved with the negotiations.[18] Bezos had previously given Amazon Studios a mandate to develop an ambitious fantasy series of comparable scale to HBO's Game of Thrones. The studio decided to pursue The Lord of the Rings, which Bezos was a personal fan of. This made Amazon the lead contender for the project.[16][19][2]
Amazon initially pitched a retelling of The Lord of the Rings similar to Peter Jackson's film series, but this was rejected by the Tolkien Estate. Netflix meanwhile pitched developing several shows centering on characters like Gandalf and Aragorn, which was also rejected. Amazon eventually managed to convince the estate without any specific pitch, through a combination of its bid amount and by promising it a role in making creative decisions.[19] On November 13, 2017, it was reported that Amazon had acquired the global television rights for close to US$250 million. Industry commentators described this amount—before any production costs and without any creative talent attached to the project—as ""insane"",[16] although some considered the project to be more of a reputational risk for Amazon than a financial one due to Bezos's wealth.[2] The Hollywood Reporter however later reported that the $250 million bid was made by Netflix and Amazon's bid was less by tens of millions of dollars, though it was still a substantial one.[19]
Amazon's streaming service Prime Video gave a multi-season commitment to the series, with the possibility of a spin-off series as well.[20] The budget was expected to be in the range of US$100–150 million per season, and was likely to eventually exceed US$1 billion which would make it the most expensive television series ever made.[16][17] Warner Bros. Television was not involved in the project because Amazon Studios wanted to produce it themselves. Amazon was working with the Tolkien Estate and Trust, HarperCollins, and New Line Cinema (the Warner Bros. division who produced the films).[16] New Line was reportedly included to allow the series to use material from the films.[17] The Tolkien Estate imposed some creative restrictions on the series,[16][21] and the deal stipulated that production begin within two years.[17]
Creative team
In April 2018, The Lord of the Rings and The Hobbit film director Peter Jackson had begun discussing his potential involvement with Amazon,[17] but by June he was not expected to be involved in the series.[22] Later that month, Head of Amazon Studios Jennifer Salke said discussions regarding Jackson's involvement were ongoing, and added that the deal for the series had only been officially completed a month earlier. The studio had been meeting with potential writers about the project and intended to have a game plan for the series and a writing team set ""very soon"", with the hope that the series could debut in 2021.[23] The studio asked for story pitches based on anything in Tolkien's The Hobbit, The Lord of the Rings, and its appendices. These included prequel stories focused on characters such as Aragorn, Gimli, and Gandalf.[24][25] J. D. Payne and Patrick McKay pitched a series that explored the major events of Middle-earth's Second Age, thousands of years before The Lord of the Rings, including the forging of the Rings of Power, the rise of the Dark Lord Sauron, the fall of the island kingdom of Númenor, and the last alliance between Elves and Men.[3] These events were covered in a five-minute prologue in the Lord of the Rings films,[26] but the pair wanted to expand this into ""50 hours of television"".[2] Payne said it felt like ""an amazing, untold story"" that was ""worthy of Tolkien"",[24] and McKay added, ""We didn't want to do a side thing. A spinoff or the origin story of something else. We wanted to find a huge Tolkienian mega epic, and Amazon agreed"".[27] Payne and McKay were hired to develop the series in July 2018.[28] They were an unlikely choice, having only done unproduced or uncredited writing before the series, but their vision aligned with Amazon's and they were championed to the studio by director J. J. Abrams who worked with them on an unproduced Star Trek film.[2]
In December, Jackson said he and his producing partners would read some scripts for the series and offer notes on them,[29] but otherwise he would enjoy watching a Tolkien adaptation that he did not make.[30] Bryan Cogman joined the series as a consultant in May 2019 after signing an overall deal with Amazon. Cogman previously served as a writer on Game of Thrones, and was set to work alongside Payne and McKay in developing the new series.[31] In July, J. A. Bayona was hired to direct the first two episodes of the series and serve as executive producer alongside his producing partner Belén Atienza.[32] Later that month, Game of Thrones creators David Benioff and D. B. Weiss were in discussions with several outlets regarding signing an overall deal, including with Amazon who were interested in having the pair consult on The Lord of the Rings;[33] they ultimately signed a deal with Netflix instead.[34] At the end of July, Amazon announced that Payne and McKay would serve as showrunners and executive producers for the series, and revealed the full creative team that was working on the project: executive producers Bayona, Atienza, Bruce Richmond, Gene Kelly, Lindsey Weber, and Sharon Tal Yguado; co-producer Ron Ames; costume designer Kate Hawley; production designer Rick Heinrichs; visual effects supervisor Jason Smith; and illustrator/concept artist John Howe, who was one of the chief conceptual designers on the films.[35][36] Special effects company Wētā Workshop and visual effects vendor Wētā FX were also expected to be involved in the series as they were for the films.[37] Additionally, Tolkien scholar Tom Shippey was revealed to be working on the series,[36] but he was no longer involved by April 2020;[38] other Tolkien scholars and ""lore experts"" remained involved.[39]
Following development of the first season, Cogman left the series to focus on developing new projects. Kelly also left the series,[40] while Yguado left when she exited her role as Amazon Studios' head of genre programming.[2] Callum Greene joined as a new executive producer by December 2020,[40] after previously serving as producer on The Hobbit: The Desolation of Smaug (2013).[41] Heinrichs was eventually replaced as production designer by Ramsey Avery.[42] In March 2021, Wayne Che Yip was announced as director for four episodes of the series, and was set as a co-executive producer.[43] Charlotte Brändström was revealed as director for another two episodes in May.[44] That August, Jackson said he had not been contacted again about seeing scripts for the series. Amazon explained that the deal to acquire the television rights for The Lord of the Rings required them to keep the series distinct from Jackson's films, and the Tolkien Estate were reportedly against Jackson's involvement in the project. Despite this, the showrunners had privately discussed the series with Jackson and Yguado had championed his inclusion before her exit.[29] The second season was revealed that month to have an all-female directing team.[25]
Seasons
Prime Video gave the series a multi-season commitment, believed to be for five seasons, as part of the initial deal with the Tolkien Estate,[17][16] though the streaming service still had to give a formal greenlight to future seasons before work could begin on them.[20] In July 2019, Shippey stated that he believed the first season of the series was supposed to consist of 20 episodes.[21] In November, Amazon officially ordered a second season of the series, and scheduled a longer-than-usual four or five month production break after completion of filming on the first two episodes. This was to allow all the footage for the first episodes to be reviewed, and so the series's writers room could be reconvened to begin work on the second season before filming on the first season continued. This gave the series the option to film the first two seasons back-to-back, as the Lord of the Rings films had been.[20] Amazon announced that the first season would consist of eight episodes in January 2020,[45] and revealed the series's full title, The Lord of the Rings: The Rings of Power, in January 2022. Payne and McKay felt the title could ""live on the spine of a book next to J.R.R. Tolkien's other classics"".[1]
Writing
A writers room for the series had begun work in Santa Monica by mid-February 2019. Salke described extensive security measures that were being taken to keep details of this writing secret, including windows being taped closed and a security guard requiring fingerprint clearance from those entering the room.[46] In addition to Payne and McKay, writers on the series include Gennifer Hutchison, Helen Shang, Jason Cahill, Justin Doble, Bryan Cogman, and Stephany Folsom, with Glenise Mullins acting as a consulting writer.[35][36] The writers room was set to be disbanded once production on the series began, but would be reconvened during the four or five-month break in filming that was scheduled following production on the first two episodes. The writers were expected to map out the second season and write the majority of its scripts during this production break.[20]
The Lord of the Rings and The Hobbit are set during the Third Age, while the First and Second Ages are explored in other Tolkien writings such as The Silmarillion, Unfinished Tales, and The History of Middle-earth. Because Amazon only bought the television rights to The Lord of the Rings and The Hobbit, the writers had to identify all of the references to the Second Age in those books and create a story that bridged those passages. These are primarily in the appendices of The Lord of the Rings, but also in certain chapters and songs.[3] Tolkien's estate was prepared to veto any changes from his established narrative,[21] including anything that contradicted what Tolkien wrote in other works.[3] The writers were free to add characters or details,[21] and worked with the estate and Tolkien lore experts to ensure these were still ""Tolkienian"".[3] They referenced The Letters of J. R. R. Tolkien for additional context on the setting and characters.[3][47] Simon Tolkien, a novelist and the grandson of J.R.R. Tolkien, consulted on the series and helped develop its story and character arcs. He is credited as a ""series consultant"".[48] The showrunners disagreed with suggestions that the series was only ""vaguely connected"" to Tolkien's writings. McKay said they felt it was ""deeply, deeply connected"" and a ""story we're stewarding that was here before us and was waiting in those books"" to be told.[49] A disclaimer is featured in the series's end credits stating that some elements are ""inspired by, though not contained in, the original source material"".[50]
Payne and McKay knew the series was expected to run for five seasons and were able to plan elements of the final season, including the series's final shot, while working on the first.[51] Because they were mostly not able to adapt direct dialogue from Tolkien's Second Age stories, the writers attempted to repurpose Tolkien's dialogue that they did have access to while also taking inspiration from religious texts and poetry. They tailored the dialogue to different characters using dialects and poetic meters.[3] Leith McPherson returned from the Hobbit films as dialect coach and noted that Tolkien's fictional languages evolve over time, so they are different for the Second Age compared to the Third. The series's Elves mostly speak Quenya, a language described as ""Elvish Latin"" that is often just used for spellcasting in the Third Age. Dwarvish and Orcish are also heard, along with English, Scottish, and Irish dialects.[52][53] The biggest deviation made from Tolkien's works, which was approved by the estate and lore experts, was to condense the Second Age from thousands of years to a short period of time. This avoided human characters frequently dying due to their relatively short lifespans, and allowed major characters from later in the timeline to be introduced earlier in the series.[2] The showrunners considered using non-linear storytelling instead, but felt this would prevent the audience from emotionally investing in the series. They said many real-life historical dramas also condense events like this, and felt they were still respecting the ""spirit and feeling"" of Tolkien's writings.[54]
After the series was revealed to have hired Jennifer Ward-Lealand as an intimacy coordinator, Tolkien fans expressed concern that it would include Game of Thrones-style graphic sex and violence.[55] Payne and McKay said this would not be the case and the series would be family-friendly. They hoped to evoke the tone of Tolkien's books, which can be ""intense, sometimes quite political, sometimes quite sophisticated—but it's also heartwarming and life-affirming and optimistic.""[2] They also said they did not want to be influenced by modern politics, instead aspiring to tell a timeless story that matched Tolkien's own intention to create a mythology that would always be applicable.[54]
The first season features several locations not previously seen in the film adaptations, including the Elf-capital Lindon and the island kingdom of Númenor,[56] but it also revisits familiar locations from the films such as Khazad-dûm, which is in ruins during the Lord of the Rings films but is shown in its ""full glory"" during the series.[2] One of the groups that the series includes are the Harfoots, depicted as precursors to the popular Hobbit race from The Hobbit and The Lord of the Rings.[2][57] Payne and McKay explained that they felt the series would not truly feel like Middle-earth to the audience without Hobbits. Tolkien's writings state that the Hobbits were not known during the Second Age, so they chose to explore the Harfoots instead, saying they were ""satisfyingly Hobbit-adjacent"". The Harfoots are depicted as having a secretive society and their story takes place in the ""margins of the bigger quests"" which was compared to the play Rosencrantz and Guildenstern Are Dead.[2] McKay said the first season was about ""reintroducing this world and the return of evil"",[27] focusing on introducing the Second Age of Middle-earth and the heroic major characters rather than telling a ""villain-centric"" story.[3] Despite being mentioned in a synopsis for the series and being a major character in the Second Age,[1] the Dark Lord Sauron was reported to not be appearing in the first season at all.[39] McKay said the season was influenced by dialogue from the second chapter of Tolkien's The Lord of the Rings, ""The Shadow of the Past"", which he paraphrased as ""After a defeat and a respite, a shadow grows again in a new form.""[27] Bayona said the season would hint at the presence of Sauron, and the overall story was about ""the repercussions of war and the shadow of the past"". He was influenced by his own childhood growing up in Spain following the Francoist dictatorship.[2]
Casting
Salke stated in June 2018 that though the series would not be a remake of the films, it would bring back some characters from them.[58] By July 2019, casting for the series was taking place around the world, with casting directors working in the United States, the United Kingdom, and Australia.[59] Casting for extras also began in New Zealand at that time.[60] Due to the secrecy surrounding the series, many actors did not know what roles they were going to play when they were cast.[2] Markella Kavenagh was in talks to portray a character referred to as ""Tyra"" at the end of July,[61] a series regular role.[59] Will Poulter was cast as one of the series's leads, reportedly called ""Beldor"", in September.[62][63] The role was described as being ""one of the more coveted jobs"" for young actors in Hollywood before Poulter's casting.[63] Maxim Baldry was informally attached to the series in a ""significant role"" in mid-October,[64][65] while Joseph Mawle was cast later that month. Mawle was reportedly playing the series's lead villain, referred to as ""Oren"".[66] In December, Ema Horvath was cast in another series regular role;[67] Poulter was forced to leave the series due to scheduling conflicts, with his role set to be recast;[68][69] and Morfydd Clark was cast as a young version of the character Galadriel, who was portrayed in the films by Cate Blanchett.[70]
Robert Aramayo was cast in a lead role, replacing Poulter, in early January 2020.[71] He was later revealed to be playing a young version of the character Elrond, who was portrayed by Hugo Weaving in the films.[72] A week after Aramayo's casting, Amazon officially announced his involvement along with the casting of Owain Arthur, Nazanin Boniadi, Tom Budge, Clark, Ismael Cruz Córdova, Horvath, Kavenagh, Mawle, Tyroe Muhafidin, Sophia Nomvete, Megan Richards, Dylan Smith, Charlie Vickers and Daniel Weyman.[73] After six or seven auditions, Vickers was unknowingly cast as Sauron after the showrunners gave him two monologues of William Shakespeare's play Richard III and of John Milton's epic poem Paradise Lost to recite for the role as Halbrand; given how the latter monologue was spoken by Satan, Vickers started suspecting that his role was for a villainous character, but remained unaware of Halbrand actually being Sauron until the showrunners told him during the third episode's filming.[74] Amazon's co-head of television Vernon Sanders noted that there were still some key roles that had yet to be filled.[73] One of these key roles was confirmed to go to Baldry in March, when his deal for the series was completed.[65] Baldry replaces Harry Sinclair as Isildur, who appeared in flashbacks during the films.[72] In December 2020, Amazon announced 20 new cast members for the series: Cynthia Addai-Robinson, Baldry, newcomer Ian Blackburn, Kip Chapman, Anthony Crum, Maxine Cunliffe, Trystan Gravelle, Lenny Henry, Thusitha Jayasundera, Fabian McCallum, Simon Merrells, Geoff Morrell, Peter Mullan, Lloyd Owen, Augustus Prew, Peter Tait, Alex Tarrant, Leon Wadham, Benjamin Walker, and Sara Zwangobani.[75] Owen and Walker portray Elendil and Gil-galad, who were briefly played by Peter McKenzie and Mark Ferguson in the films.[13][3][72]
In March 2021, Budge announced that he had departed the series after filming several episodes. He explained that Amazon had reviewed the first episodes and decided to recast his character,[76] who was reported to be Celebrimbor.[39] Charles Edwards was cast to replace him as Celebrimbor in July,[2][77] when Will Fletcher, Amelie Child-Villiers, and Beau Cassidy were also added to the season's cast.[77] Seven of the series's main actors are New Zealanders, and overall a third of the first season's 124 speaking roles went to New Zealand actors.[37] The rest of the cast came from Australia, Sri Lanka, the United Kingdom, and the United States.[75]
While promoting the first season at San Diego Comic-Con in July 2022, the showrunners said they would give a role in the second season to television host and avid Tolkien fan Stephen Colbert, who was moderating the series's panel at the convention.[78] A month later, they said the character Círdan would be introduced in the second season.[79] The character briefly appeared in the Lord of the Rings films portrayed by Michael Elsworth.[80]
Design
It was Jackson's understanding in December 2018 that the series would be set in the same continuity as the films and Amazon wanted to be consistent with the designs that were created for them,[30] which illustrator and concept artist John Howe reiterated in August 2019, saying the showrunners were determined to remain faithful to the designs of the film trilogies.[81] Payne and McKay later clarified that the series is not a direct continuation of the films,[3] per Amazon's deal for the series,[29] but they did not want it to ""clash"" with the films and tried to have similar designs. They took advantage of Howe's experience working on Jackson's adaptations, as well as that of costume designer Kate Hawley who worked on the Hobbit films. Other influences included the 1977 animated television adaptation of The Hobbit by Rankin/Bass.[3]
Howe had filled 40 sketchbooks with drawings for the project by May 2022, and said the biggest difference between the films and series was the latter visited new locations, such as the oceans of Middle-earth.[82] Avery's biggest challenge was making Middle-earth feel both familiar and new. He chose to build as many practical sets as possible, wanting the series to ""feel real and honest... to make sure that the actors had a world that felt inhabitable"". Payne said being on set ""was like going to Middle-earth every day for work"". Avery used different styles for each location, such as Lindon's ""tree-like columns"" which were inspired by Gothic architecture. He added ""arboreal details"" to reflect the Elves' love of nature. Khazad-dûm was designed to be ""less severe"" than the film version, using a ""sensitivity toward the stone"" rather than ""harsh lines and gargantuan statues"" to show the kingdom before the Dwarves ""got greedy"". Avery compared the large wheels on the Harfoot wagons to the round Hobbit doors seen in the films.[42]
Payne, McKay, and Avery put a lot of focus on Númenor, which Payne explained was because ""it's never been seen before. People have some ideas of what Elves look like or what Dwarves look like and what those kingdoms might look like. But Númenor was, in some ways, a blank canvas."" They planned out the entire city,[13] and made sure that this reflected Tolkien's description of it originally having Elvish influences but becoming more ""Mannish"" as it was developed. Tolkien also compared the city to Venice, so Avery took inspiration from that city and its connection to water.[83] He used the color blue in a lot of the city's locations to emphasize the culture's relationship with water and sailing.[42] Númenor's ""looming marble structures"" and ""bold shapes, rich colors, and geometrical ornament[s]"" were inspired by Ancient Greece, Ancient Egypt, and the rest of North Africa and the Middle East.[42][83] The distinct shape of the sails on Númenórean ships were based on the ceremonial headwear worn by Gondorian kings, the descendants of Númenóreans, in the Third Age. Avery worked with experts to ensure the ships were still functional with the unique sails.[83] The main Númenor set was almost 300,000 square feet (28,000 m2) and was described as ""an entire seaside city"" with buildings, alleyways, shrines, graffiti, and a ship docked at the harbor inside a large water tank.[13][84] There were additional sets for specific locations within the city. The sets were built with a lot of real materials that were cheaper to source in New Zealand than the ""movie fakery typically used to save time and money on sets in Los Angeles"". Avery's team also created a form of Roman concrete using seashells that they used in the alleyways to show some of the history of the city. To further help immerse the actors, Avery used real plants, fruits, and incense on set so the ""smells were right"".[84] Yip described the Númenor sets as ""breathtaking... we were there for weeks, but every day I'd notice a new detail"".[13]
Jamie Wilson was the head of prosthetics for the series after previously working on the film trilogies. He noted that there had been advancements in the technology available since the films were produced, including encapsulated silicone that looks much more like real skin than previous techniques. The prosthetics team also worked closely with the series's visual effects department for digital ""tweaks"" to the prosthetics. The showrunners were particularly interested in the series's depiction of Orcs and ensuring that practical effects were used where possible. Wilson explained that the Orcs in the series were intended to be ""younger""-looking than those in the films, since these groups are just emerging from hiding. Because of this, the series's Orcs feature less battle-scars than those in the films and are also lighter-skinned with some skin conditions caused by new exposure to the sun.[85]
Filming
New Zealand
Salke said in June 2018 that the series could be produced in New Zealand, where the films were made, but Amazon was also willing to shoot in other countries as long as they could ""provide those locations in a really authentic way, because we want it to look incredible"".[58] Pre-production on the series reportedly began around that time in Auckland,[86] while location scouting also took place in Scotland, including around the Isle of Skye, Portpatrick, Scourie, Perthshire, and Loch Lomond.[87] Amazon and Creative Scotland held talks about the series being based at new studios that were under construction in Leith, Edinburgh.[88] In December, Amazon held a ""crisis meeting"" with David Parker, then New Zealand's Minister of Economic Development, after the studio threatened to take the production out of the country due to the lack of available studio space in Auckland.[89] New Zealand's Major Screen Production Grant, which provides tax rebates for productions, was offered to Amazon, but Parker did not propose any special deal because he wanted the series to be made ""on terms that are good for New Zealand"".[90]
Amazon decided to film in New Zealand, and were reportedly influenced by the New Zealand government's reassurances that the country was safe following the Christchurch mosque shootings in March 2019, as well as concern regarding the potential effects of Brexit in Scotland. Production was set to primarily take place in Auckland, but additional filming was expected to take place in Queenstown and other locations around New Zealand.[91] Auckland was chosen as the primary filming location in New Zealand because the Wellington studios that the films were produced in were being used by the Avatar films at the time. Leases for the series at Kumeu Film Studios and Auckland Film Studios took effect in July,[86] and Amazon officially confirmed that the series would be filmed in New Zealand in September 2019 after completing negotiations with the New Zealand Government, the New Zealand Film Commission, and Auckland Tourism, Events and Economic Development (ATEED). The studio said filming would begin in the ""coming months"", with some specific locations still being discussed with ATEED. Payne and McKay said the creative team chose New Zealand because they needed ""somewhere majestic, with pristine coasts, forests, and mountains"" that could also meet the production requirements of the series.[92][93]
Through New Zealand's Major Screen Production Grant, all film and television productions receive a 20 per cent tax rebate, with those that offer ""significant economic benefits"" able to negotiate for an additional 5 per cent rebate.[94] To gain access to the latter, Amazon signed two Memoranda of Understanding in December 2020 with the New Zealand Film Commission, Tourism New Zealand, and the country's Ministry of Business, Innovation and Employment (MBIE).[95] One memorandum outlined Amazon's overall obligations in exchange for the extra refund, and the other was specific to the first season. Further memoranda needed to be signed for future seasons. The agreements allowed Tourism New Zealand to promote the country using material from the series, while Amazon would work with the Film Commission to help grow the country's screen sector and with MBIE to run an ""innovation program"" to benefit New Zealand companies and research groups.[95][94] Details of the memoranda were revealed in April 2021,[94] when New Zealand's Minister of Economic Development and Tourism, Stuart Nash, revealed that Amazon was spending NZ$650 million (US$465 million) on the first season, making it eligible for NZ$160 million (US$114 million) in tax rebates. James Hibberd at The Hollywood Reporter noted that the US$465 million amount ""almost certainly"" included additional costs to the season's production budget, including the startup costs of building sets, costumes, and props that would be used in future seasons as well.[96] Salke soon confirmed this, describing the cost as a ""crazy headline that's fun to click on, but that is really building the infrastructure of what will sustain the whole series"".[97] In August, Amazon announced that it was moving production of future seasons to the United Kingdom and would not preserve the terms of the memoranda that they had signed. Nash confirmed that the series was no longer eligible for the additional rebate (around NZ$33 million or US$23 million).[98][99]
Season 1
Table reads with the cast began in New Zealand by mid-January 2020, ahead of the start of filming in early February,[73][100] under the working title Untitled Amazon Project or simply UAP.[101] The production was based in Auckland, primarily at Kumeu Film Studios and Auckland Film Studios,[86] as well as Kelly Park Film Studios.[102] J. A. Bayona directed the first two episodes,[32] and acknowledged the ""massive expectations"" for the series, especially following the ""high bar"" set by Jackson's films.[2] Óscar Faura was the cinematographer for the two episodes after serving the same role on all of Bayona's previous films.[103] As part of the production's approach to secrecy, actors were often stopped from entering sets that they did not have scenes in.[12] Different techniques were used to make the Dwarf and Harfoot actors appear smaller than the rest of the cast, including oversized props and prosthetics, and actors looking over the heads of their scene partners.[26]
Location filming took place around Auckland in February.[104] Filming for the first two episodes was expected to continue through May,[105] followed by a longer-than-usual four or five month production break to allow all the footage for the episodes to be reviewed and so the writers could begin work on the second season.[20] Production was set to resume in mid-October and continue until late June 2021.[105] However, filming was placed on hold indefinitely in mid-March 2020,[101] after 25 days of filming,[25] due to the COVID-19 pandemic. Around 800 cast and crew members were told to stay home.[101] Filming was allowed to resume in early May under new safety guidelines from the New Zealand government, when the majority of filming for the first two episodes was confirmed to have been completed. Instead of finishing the episodes then, the filming shutdown segued into the intended production break and the two episodes were set to be completed once filming on further episodes was ready to begin.[106] The crew took advantage of the extended break in filming to refine the designs and scripts for the season, including adjusting the ending of the season to better align with the second-season storylines that the writers were working on.[107] The series was one of seven film and television productions that were granted exemptions to allow cast and crew members to enter New Zealand while its borders were closed to non-New Zealanders due to COVID-19. The exemptions were granted before June 18 by Economic Development Minister Phil Twyford, and applied to 93 members of the production as well as 20 family members. Around 10 percent of the series's crew were believed to be non-New Zealanders, and many of them had remained in the country during its pandemic lockdown and did not require exemptions.[108] Pre-production for further episodes began by July 2020,[108] and filming resumed on September 28.[109]
Bayona completed filming for his episodes by December 23.[110] Production on further episodes was set to begin in January 2021 following a two-week Christmas break.[110][111] Yip confirmed that he had begun filming his episodes by March,[43] and Brändström was in New Zealand for production on the series in May.[44] Aaron Morton and Alex Disenhof were the cinematographers for their episodes.[112][113] Walker said in June that he was unsure how much longer the cast was required to stay in New Zealand, saying the production's timeline was ""a bit nebulous"" and Amazon would ""let us go when they're done with us"";[114] many of the series's international cast members were unable to leave New Zealand during filming due to the country's restrictive pandemic-era border policies putting limits on who could leave and return as well as requiring a two-week quarantine for anyone entering the country. This meant many actors were trapped in the country for nearly two years,[98][115] and Boniadi said the cast ""became a fellowship [who] were forced to lean on each other. We didn't have anybody else. We were on an island, away from our support systems, mid-pandemic."" Addai-Robinson added, ""We had to be there for each other in a way that is different from other on-location jobs. It really was about that protective bubble, and trying to focus on the task at hand."" Other cast members helped Nomvete and her husband look after their newborn baby during filming.[12] The closed border also meant that Amazon executives could not visit and monitor the expensive production.[98]
In July 2021, several stunt performers alleged that a senior stunt supervisor for the production had created an ""uneasy environment"" that contributed to an unsafe workplace. At least three stunt performers were seriously injured on the set, including stuntwoman Dayna Grant who suffered a head injury in March and was diagnosed with a brain aneurysm and upper spinal injury; fans crowdfunded NZ$100,000 to help Grant pay for surgery.[116] Stuntwoman Elissa Cadwell was injured when she struck her head falling into a water tank while rehearsing a stunt in February 2020. Amazon notified New Zealand's workplace health and safety regulator WorkSafe a week later, when Caldwell was recovering from her injuries after being treated in hospital.[117] Amazon paid Caldwell NZ$500,000, in part to help her return home to Australia. Responding to the allegations, the production's head of safety Willy Heatley said the injury rate was 0.065 percent across the 16,200 days of stunt work since filming began, and this was mostly due to ""common stunt-related sprains, bruises and muscle and soft tissue strains"".[116]
Filming wrapped on August 2, 2021.[118] 38 filming locations were chosen for the season. 15 were in Auckland,[102] and the others included the Hauraki Gulf, the Coromandel Peninsula, the Denize Bluffs in the King Country, Mount Kidd in Fiordland, Piha, Rangitikei,[37] Kahurangi National Park, Central Otago, and Queenstown.[102] Unlike the films, the series used New Zealand's coastlines,[3] including an unnamed beach in the South Island that was only accessible by boat or helicopter. This was used for the entrance to Númenor's harbor because it had surrounding rock formations that matched with concept art of ""King Stones"" at the entrance to the harbor.[84] The showrunners intended to film in the Waitomo Caves for scenes set in the city of Khazad-dûm, but this proved to be impractical.[3] More than 1,000 New Zealanders were contracted for the season and around 700 more were indirectly engaged by it.[37]
United Kingdom
At the end of filming for the season, the crew were unsure when filming for the second season would begin though there was expected to be a hiatus of at least one year to allow post-production on the first season and writing for the second season to be completed. Amazon retained its lease on Auckland Film Studios and Kumeu Film Studios, and reportedly Studio West also, for the duration of the hiatus, which allowed the series's sets to remain at the studios and prevented other productions from using the space.[37]
The week after filming ended, Amazon announced that it was moving production of the series to the United Kingdom starting with the second season. At that time, Amazon was in the process of booking studio space in the UK,[98] with Scotland reported to be the frontrunner for new shooting locations.[119] The company planned to ship all of the sets that were built for the first season to the UK, and hire a new UK-based crew since the majority of the first season's crew was New Zealand-based.[98] Factors that played a role in the change included Amazon already heavily investing in UK studio space for several other productions; a belief that the UK would be a ""more economical choice"" following the high cost of making the first season in New Zealand;[115] the opportunity to film in other European countries near the UK as was done for the series Game of Thrones;[98] the Tolkien Estate wanting the series to be filmed in the UK since Tolkien was inspired by locations there for his books;[119] and the fact that New Zealand's restrictive pandemic-era border policies had prevented Amazon executives from visiting and monitoring the production, while many international cast members (more than half of whom are British) were unable to leave the country for nearly two years during filming of the first season.[98] Amazon had offered in August 2020 to pay for the use of hotels and rental properties as private quarantine facilities to give the production more flexibility with travel, but this idea was rejected by the New Zealand government due to the need for additional services related to quarantining.[120] In the UK, 80 per cent of expenditure is eligible for a 25 per cent tax rebate through the government's ""high-end television"" tax relief program.[121][122]
The cast and crew expressed regret that they were not returning to New Zealand for the second season. Executive producer Lindsey Weber called it a ""hard departure"" and said they would not have been able to make the first season without the New Zealand crew, many having worked on the films as well.[102] However, McKay felt that because Tolkien was inspired by the UK for his writings they would be ""bring[ing] the property home"" with the second season which would be an ""opportunity... pregnant with possibilities"". He also suggested that future seasons would be visiting new lands within Tolkien's world that would justify having new filming locations.[123]
Season 2
Pre-production for the second season was expected to begin in the UK in the second quarter of 2022,[124] taking place concurrently with post-production for the first season which was continuing in New Zealand until June 2022.[98] Bray Film Studios and Bovingdon Airfield, both outside of London, were set to be the initial production locations for the season.[124] The showrunners were scouting for additional filming locations in June 2022,[12] and the cast was preparing to travel to the UK in August ahead of an October filming start.[25] Production for the second season began in the UK on 3 October 2022.[125]
Visual effects
In addition to Wētā FX, visual effects for the first season were created by Industrial Light & Magic (ILM), Rodeo FX, Method Studios, DNEG, Rising Sun Pictures, Cause and FX, Cantina Creative, Atomic Arts, and Outpost VFX. 1,500 visual effects artists worked on the season,[126] which has more than 9,500 visual effects shots.[127] Visual effects producer Ron Ames said the effects were completed to a theatrical resolution so they could be shown on screens ranging from televisions to IMAX.[126] Effects work for the season included shots featuring Dwarf and Harfoot actors appearing small beside the other cast, set extensions, and big effects sequences.[126]
Music
Howard Shore, the composer for the Lord of the Rings and Hobbit films, was reported to be in discussions with Amazon about working on the series in September 2020. He was said to be interested in developing musical themes but not necessarily composing the entire score.[128] Shore was confirmed to be in talks for the series a year later,[129] when composer Bear McCreary was reported to be involved as well.[128] Their hiring was officially announced in July 2022, with McCreary composing the score and Shore writing the main title theme.[130] McCreary said the main theme was created independently of the score, but he felt the two ""fit together so beautifully"".[131]
McCreary began working on the series in July 2021, and said it was a ""once-in-a-lifetime opportunity"" to work on such an ambitious score with the creative freedom that he wanted. He spent two months writing new musical themes based on the scripts, which he compared to writing a symphony, and then used those to compose nine hours of music for the first season over eight months. He wanted to honor Shore's musical legacy and hoped to create a ""continuity of concept"" between the series and films, with the 15 new themes he wrote for the season being added to the ""pantheon of memorable melodies"" that Shore had written. He did note that his music would reflect the series's depiction of ""these societies at their peak"" compared to Shore's music for the Third Age which had ""a wistfulness and a melancholy"".[132] McCreary used different approaches for the different groups in the series: the music for the Elves features ""etheral voices"" and choir, the Dwarven music has ""deep male vocals"", the Harfoots have music based in natural sounds, and the harmonic language for Númenor has Middle Eastern influences.[133]
The score for each episode took four days to record, using up to 90-piece orchestras at Abbey Road Studios and AIR Studios in London as well as a 40-person choir at Synchron Stage in Vienna. For the choral music, McCreary pulled text from Tolkien's writings and worked with the series's language experts to write new lyrics in Tolkien's fictional languages, including the Elvish languages Sindarin and Quenya, the Dwarvish language Khuzdûl, Black Speech, and the Númenórean language Adûnaic. Soloists were recorded in Los Angeles and across Europe playing folk instruments such as the hardanger fiddle, nyckelharpa, bagpipes, and bodhrán drums. McCreary was still writing music for the first season in Los Angeles while recording for most of the episodes took place, but he was able to conduct the orchestra for the final episode at AIR Studios in April 2022.[132]
Two singles from McCreary's score, ""Galadriel"" and ""Sauron"", were released on Amazon Music on July 21, 2022.[130] They were followed by a full soundtrack album featuring Shore's main theme and selections from McCreary's score. The album was released on all major streaming services on August 19 and will be physically released by Mondo on CD (October 14) and vinyl (January 13, 2023). The Amazon Music version of the album includes two exclusive tracks.[134] Additional soundtrack albums featuring the full score for each episode will be released after the episode premieres.[135]
Marketing
Early promotions for the series on social media used several maps of Middle-earth's Second Age, as well as excerpts from the novel The Lord of the Rings.[21][136] The maps were designed and created by illustrator John Howe and overseen by Tolkien scholar Tom Shippey to ensure they were accurate to Tolkien's works.[136] Howe and Shippey spent a lot of time working on the maps, which were based on Tolkien's maps of Númenor during the Second Age as well as his maps of the Third Age. Despite their efforts, HarperCollins received complaints from fans shortly after the maps were released online regarding two mistakes that were made on them.[81]
Amazon considered the reveal of the series's full title in January 2022 to be crucial due to it beginning the series's marketing campaign at the start of its premiere year. Instead of just using visual effects to create the title reveal, the studio released an announcement video in which the letters of the title are physically cast from molten metal while an excerpt of the ""Ring Verse"" from The Lord of the Rings is read in voiceover. The video was directed by Klaus Obermeyer, who worked with special effects supervisor Lee Nelson under advisement by veteran special effects supervisor Douglas Trumbull.[137] They filmed the video with foundryman Landon Ryan in late 2021 in Los Angeles, after experimenting with different combinations of metals, as well as sparkler dust, argon pours, and liquid hydrogen, to create the desired look. The final metal was a mixture of bronze and aluminum which was poured into moulds of compressed sand that could be used multiple times. The pouring was filmed at 5,000 frames per second with a Phantom Flex4K camera so it could be shown in ultra-slow motion.[138] For the final title card, the forged letters were inscribed with Elvish writing and placed on a large piece of redwood. Staff from the Tolkien fan website TheOneRing.net and entertainment journalists were invited by Amazon to watch the filming of the video.[137][138] Prologue Films provided previsualization for the sequence as well as compositing and additional visual effects. They recreated the final title card digitally, taking care to maintain the ""integrity of the live action shots and lighting"".[139]
Twenty-three ""character posters"" for the series were released on February 3, though unusually they do not feature actor or character names and focus on the hands and torsos of the characters rather than their faces. Amazon said this was to ""fuel fan speculation and discussion"",[140][141] and it did lead to speculation and analysis about who each character could be.[141][142] A first look at some of the series's main characters was then revealed on February 10 along with story details,[2] before the first teaser trailer was released on February 13, during Super Bowl LVI. TheOneRing.net hosted an official ""watch party"" for the trailer on YouTube,[143] while some ""high-profile"" fans were flown to Bellver Castle in the Balearic Islands, Spain, to help promote the teaser globally.[144] Commentators noted that the teaser did not reveal many new details about the series,[145][146][147][148] but Graeme Guttmann of Screen Rant felt it did not hold back on ""epic"" spectacle.[145] The Hollywood Reporter's James Hibberd also described the teaser as epic, and felt it showed off the series's large budget,[146] while Susana Polo at Polygon said it ""wastes no time reintroducing viewers to the lush fantasy setting many know"" from Jackson's film adaptations.[147] Writing for IGN, Amelia Emberwing said the most successful aspect of the teaser was that ""it feels like The Lord of the Rings"" and appeared to balance the ""serenity and dangers of Middle-earth"" like the films did.[148] In contrast, Jack Butler of National Review had felt the first look images were ""Tolkienesque"" but was less sure about the teaser, which led him to think that the series would be more reliant on visual effects than the ""grounded approach"" of Jackson's films.[149] Kevin E G Perry of The Independent was even more critical of the visual effects, saying the trailer looked ""cheap"" and like a ""cut scene from an old Final Fantasy computer game"".[150] RelishMix reported that the teaser trailer had 80.34 million views in 24 hours across Facebook, Twitter, YouTube, and Instagram, which was the third highest among those airing during the Super Bowl according to their metrics.[151] Amazon reported 257 million views within 24 hours, which they said was a record for any film or television trailer released during the Super Bowl.[144]
The early marketing material led to a ""cacophony"" of online fan discourse, including concerns about accuracy to the source material and the series's compression of Tolkien's Second Age timeline. Discussing these responses for The Escapist, Darren Mooney said ""extreme reactions"" from online media fans were now expected due to cultural forces, ""an entire online economy running on manufactured outrage"", and the ""near-religious reverence"" that modern fans have for media. He said the online reaction was likely not representative of general opinions on the series and noted that Jackson's films, which were ""beloved by mainstream audiences"", faced similar complaints from Tolkien fans.[152] In response to the fan concerns, Amazon invited several Tolkien critics, fan websites, and influencers to a screening in May 2022. They were flown to Merton College, Oxford, where Tolkien worked as a professor, and shown 20 minutes of completed footage from the series.[47][153] They also talked to the showrunners and Howe.[82] Justin Sewell of TheOneRing.net said they were unable to discuss details, but the footage ""looks like it should, sounds like it should, and feels like a return to the comfortable universe we all love"", addressing the concerns of most of the fans in attendance.[153] Kaitlyn Facista, writing for the Tea with Tolkien blog, said the footage immersed her in Middle-earth in a way that the teaser trailer did not,[47] and she was impressed by the showrunners' knowledge of the source material. Others reported that the screening and discussion with the showrunners made them ""cautiously optimistic"" about the series. Corey Olsen, an academic and podcaster known as the ""Tolkien Professor"", felt after meeting the showrunners that the series was in ""very good hands"".[154]
An ""exclusive sneak peek"" of the series was made available to Amazon Prime members for 48 hours on July 6, before being widely released online, ahead of ""Amazon Prime Day"" on July 12 to 13.[155][156] This was followed by a second teaser trailer on July 14 which Hibberd described as ""a more extensive look at the show's rendition of Middle-earth"".[157] Cydney Contreras at E! Online said the teaser and locations were awe-inspiring and breathtaking,[158] Jim Vorel of Paste said it was ""visually splendid"" and reflected the large budget,[159] and Gizmodo's Germain Lussier said it felt like fans of Middle-earth were ""going home"".[160] Adam B. Vary and Wilson Chapman at Variety acknowledged the locations and visuals, but felt the teaser did not explain the story for audience members who were unaware of Tolkien's writings.[161] Writing for Forbes, Scott Mendelson said the teaser was likely not connected enough to the Lord of the Rings films in terms of cast and story to entice general audiences, putting it on par with other fantasy properties inspired by the films that were not successful.[162] Blake Hawkins at Comic Book Resources felt the teaser's inclusion of more Tolkien mythology and lore would help assuage the concerns of Tolkien fans,[163] but TechRadar's Matt Evans said it was unlikely to win over those fans. He explained that many fans had come to accept the changes Jackson made to adapt The Lord of the Rings, but the same could not be said for his Hobbit films. Evans felt The Rings of Power would likely be treated similarly to the Hobbit films due to it being a ""blockbuster ploy to keep our money"" which was ""the absolute antithesis of Tolkien's work"". He added, ""being a good fantasy show on its own merit is simply not going to be enough. It has to be truly great to justify its own existence"".[164]
The series was promoted at the San Diego Comic-Con in late July with a meet-and-greet between 21 cast members and a group of Tolkien fans; a private dinner with the cast, crew, Amazon executives, and media; branding on San Diego trains and at the convention's entrances;[165][166][167] and a two-hour panel moderated by Stephen Colbert, who was flown in for the day as a surprise for those in attendance. The panel began with McCreary conducting a 25-piece orchestra and 16-person choir, performing a suite of his original score. A full trailer and five clips were shown, and Colbert interviewed the cast and crew.[165][78] Marketing executive Sue Kroll said the convention was ""our first real opportunity to show fans our dedication"" to the source material.[168] Several outlets included the series on lists of ""winners"" at the convention,[168][169][170][171] such as TheWrap whose staff said Amazon ""took the exact right approach"" to its Comic-Con presence.[169] For IGN's list, Adam Bankhurst said the panel ""changed the conversation"" and created positive ""buzz"" for the series in a way that the teaser trailers did not.[170] The trailer from the panel was also released online,[172] and Vary noted that it explained the series's premise, unlike the teasers. He and several other commentators highlighted the appearance of a Balrog.[166][173][174][175] James Whitbrook at Gizmodo said there was a lot going on in the trailer and it was ""looking quite fantastic"",[173] while Jack Shepherd of GamesRadar+ called it the best look yet at the series.[174]
A final trailer for the first season was released in late August, during the week before the series premiere. Multiple commentators pointed out that the trailer came following the premiere of rival fantasy series and Game of Thrones spin-off House of the Dragon, and some suggested that this was a way to remind audiences that The Rings of Power would be premiering soon as well.[176] Also that week, Prime Video announced a promotion with Samsung that would see 8K footage from the series displayed on large LED screens at the ""Samsung 837"" experience center and Time's Square in New York City, Piccadilly Circus in London, and Piazza del Duomo in Milan.[177] A new book chronicling the events of Middle-earth's Second Age, titled The Fall of Númenor, was compiled and edited by Tolkien scholar Brian Sibley from Tolkien's writings about the Second Age. The book will be published in November 2022, following the release of the first season of The Rings of Power, to capitalize on new interest in Tolkien's works arising from the series's release.[178]
Release
The first two episodes were screened at premiere events in August 2022, in Los Angeles,[179] Mexico City,[180] Mumbai,[181] New York City,[182] and London.[183] They were also shown in free fan screenings on August 31 in around 200 countries, including the U.S., Canada, the UK, Ireland, Argentina, Colombia, Australia, and New Zealand.[184] The episodes premiered on Prime Video in the U.S. on September 1. The other six episodes of the first season are being released weekly from September 9 to October 14. Episodes are released on Prime Video around the world at the same time as the U.S. release,[185] in more than 240 countries and territories.[186]
Reception
Viewership
Amazon announced that The Rings of Power had been watched by 25 million viewers globally in the first 24 hours that the first two episodes were available on Prime Video.[187] The company stated that this was the biggest premiere ever for the service.[188][189] It was the first time that Amazon had publicly stated viewership data for Prime Video and the company did not specify how much of an episode a user needed to watch to count as a viewer.[190][191]
Analytics company Samba TV, which gathers viewership data from certain Smart TVs and content providers, reported that 1.8 million U.S. households watched the series' first episode within four days of its release. This dropped to 1.3 million for the second episode, indicating that roughly a quarter of the audience chose not to continue watching after the first.[192][193]
Whip Media calculated that for the week ending September 4, three days after The Rings of Power's debut, it was the second-highest original streaming series for U.S. viewership behind Disney+'s She-Hulk: Attorney at Law.[194] It also stated that The Rings of Power had the fifth-highest debut, in terms of three-day viewership following the premiere, in TV Time's history and retained 87 percent of the viewership during the second episode.[195]
Nielsen estimated that The Rings of Power was watched by 12.6 million viewers in the US during the first four days.[196] It also stated that the show was streamed for 1.253 billion minutes in the US for the week of August 29–September 4, acquiring the first rank among both the original and overall titles category. This marked the first time an Amazon series had debuted atop the Nielsen charts.[197] 55% of the viewers were male and the 35–49 age group formed the largest demographic.[198] Ormax Media estimated that 7.3 million people or around three million accounts in India watched the premiere over the first three days.[199] The third episode was watched by 7.4 million US viewers according to Nielsen.[200]
Head of Amazon Studios Jennifer Salke revealed in late-September 2022 that the show had been watched by nearly 100 million customers.[201] Nielsen stated in mid-October that viewers above the age of 35 formed 71% of the audience for the show.[202]
Comparisons with House of the Dragon
The Rings of Power was compared to fellow fantasy series House of the Dragon by a number of commentators.[203] According to Whip Media, who track viewership data for the 21 million worldwide users of their TV Time app, House of the Dragon had 20% more followers than The Rings of Power at the start of August 2022.[204] Writing for Quartz later that month, Adario Strange compared Google Trends data for both series and found that there was low audience interest in both until July 2022, at which point House of the Dragon jumped up to ""100 out of a possible 100 in terms of interest"" while interest in The Rings of Power remained low.[205]
The executive producers of The Rings of Power stated that they did not feel any competition with House of the Dragon, and Lindsey Weber said this had been ""manufactured by the media for headlines"".[206] The Hollywood Reporter however reported that Amazon closely follows the viewership of House of the Dragon and the growth of its viewership during the second episode distressed the producers.[19]
Jennifer Maas at Variety felt that a fair comparison between the series and House of the Dragon was not possible based on the company's self-reported data; the single-episode premiere of House of the Dragon reportedly had 10 million U.S. viewers across HBO and HBO Max.[207]
Viewer numbers reported by Samba TV were considerably lower than the 4.8 million U.S. households they reported as watching House of the Dragon in its first four days, and was also behind the premiere numbers for Netflix's Stranger Things season four (2.9 million) and Disney+'s Obi-Wan Kenobi (2.1 million) earlier in 2022.[192][193]
Conversely, Nielsen reported that the two-part premiere of The Rings of Power was streamed by more viewers during the first four days of release than House of the Dragon, which was streamed by 10.6 million viewers.[196] Later it stated that The Rings of Power leaned towards an older demographic and struggled to attract younger viewers unlike House of the Dragon, while an equal percentage of viewers (34%) of both shows watched the other show.[202] The show maintained its lead over House of the Dragon for three consecutive weeks in Nielsen rankings.[208] House of the Dragon however generated more online interest, which Business Insider stated might have been a reflection of the demographics of both shows.[200]
Critical response
|
|
Percentage of positive critics' reviews tracked by the website Rotten Tomatoes[209]
On the review aggregation website Rotten Tomatoes, The Lord of the Rings: The Rings of Power holds an 85% approval rating based on 465 reviews by critics. Critical consensus summarized, ""It may not yet be the One Show to Rule Them All, but The Rings of Power enchants with its opulent presentation and deeply-felt rendering of Middle Earth.""[209] On Metacritic, which uses a weighted average, the series premiere has received a score of 71 out of 100 based on 40 critic reviews, indicating ""generally favorable reviews"".[210]
The first two episodes received generally positive reviews from critics, with particular praise for its cinematography, visuals, and musical score and some criticism for its pacing and characterization.[211][212][213] Kevin Perry from The Independent praised the series saying that it ""rummages around in JRR Tolkien's 'The Lord of the Rings' appendices and comes up with gold"".[214] Darren Franich from Entertainment Weekly expressed a negative opinion, calling it ""a special catastrophe of ruined potential, sacrificing a glorious universe's limitless possibilities at the altar of tried-and-true blockbuster desperation"" while criticizing the characterization of Galadriel.[215]
While praising the overall production, Ed Power from The Irish Times and The Daily Telegraph was critical of the Harfoots' affected Irish accents and saw the characters as a depiction of offensive stereotypes of Irish people.[216][217][218] Other Irish critics and publications agreed,[219][220] though some were less critical of this element.[221][222]
The critic Stuart Heritage, writing in The Guardian, described the series as ""inept"". He felt that it was in the main poorly acted because of inadequate direction, though he admired Morfydd Clark's performance. He found the score ""syrupy"", the lighting inappropriate, and the visual effects variable in quality despite the cost of the show.[223]
Alan Sepinwall in Rolling Stone commented that one could wish the series would do more with less. There had, he wrote, been ""memorable, powerful moments"", as with the Harfoots, or the way it introduced Galadriel, or Durin's friendship with Elrond, or the battle between Men and Orcs before Mount Doom erupted. All the same, in his view the ""mystery box plotting"" about who would turn out to be Sauron was overblown and not really engaging. Sepinwall found both action and night sequences grossly overlit. He felt, too, that the show appeared uncertain whether it was trying to please Tolkien fans or newcomers.[224]
According to CNET's Roger Cheng, writing after the final episode of the first season had aired, ""At best, it was a lesser version of Peter Jackson's original Lord of the Rings trilogy, particularly the bromance between Elrond (Robert Aramayo) and Prince Durin IV (Owain Arthur). At worst, it was flat out sleep-inducing. I couldn't stay awake for some of the early episodes, even for the ones set in the beautiful, but oddly soulless Númenor set pieces.""
Audience response
A day after the series premiered, Amazon began holding reviews of it on Prime Video for 72 hours to ensure each review was ""legitimate"" and not coming from internet trolls. James Hibberd of The Hollywood Reporter called this an unusual step, but Amazon stated that it was a policy the company had introduced for all its series earlier in the year. Hibberd said this was partially due to review bombing by users who were posting ""numerous negative reviews for [the series] due to its perceived cultural or political issues rather than its actual quality"". However, Hibberd also found that the majority of negative reviews focused on other reasons such as the story, acting, and pacing. He felt the audience rating would increase if the series could ""deliver consistent quality over time... [and] win people over"" in a similar way to the concurrent Disney+ series She-Hulk: Attorney at Law.[225] Average reviews on IMDb and Google were slightly higher than the Rotten Tomatoes audience score at that point, but were polarized with the majority of reviews being the highest or lowest possible score.[226] Analysis company Brandwatch found 60 percent of online discussions about the series in the few days following its premiere to be negative and focused on slow pacing, poor writing and acting, reliance on visual effects, and differences from Tolkien's writings. The other 40 percent praised the series for promising plotlines, intriguing characters, ""breathtaking"" cinematography, and respect for Tolkien. Discussing this data for TechRadar, Tom Power said many of the negative responses were from Tolkien fans that likely did not want the series to be made in the first place, or more casual fans who had been influenced by that group's views. He attributed the positive responses to ""TV aficionados"" and other fans.[227] Cindy White at The A. V. Club described some of the fan discourse as ""a fight between loyal [Tolkien] fans who simply want to preserve the integrity of the thing they love and a multinational corporation looking to cash in on that devotion"",[228] and Anthony Palomba, professor of business administration at the University of Virginia, also partially attributed the responses to ""super diehard people"" who did not necessarily reflect the views of general audiences.[229] Shaun Gunner, the chair of the Tolkien Society, agreed that responses to the series away from social media were more nuanced. He stated that among members of the society, some loved the series, others were unsure, but ""very few people are just writing it off ... cautious optimism is probably where most people are at.""[230]
Casting backlash
Star Lenny Henry revealed in October 2021 that he and other people of color had been cast as Harfoots, which was explained with Tolkien's description of the Harfoots as being ""browner of skin"".[231][57] Several non-white actors were also cast as Elves and Dwarves for the first time in the franchise. After this was revealed, Amazon received backlash from social media users complaining about these casting decisions,[2] including arguments that Tolkien only described Elves, Dwarves, and Hobbits as white and these castings were therefore disrespectful to his writings.[232] The series's official social media accounts removed some of the comments which were deemed to be racist.[233] The producers said they expected to receive some responses like this, but wanted to ensure the series reflected ""what the world actually looks like"" and felt this approach to casting would be closer to the spirit of the books. Executive producer Lindsey Weber stated, ""Tolkien is for everyone. His stories are about his fictional races doing their best work when they leave the isolation of their own cultures and come together.""[2] Members of the cast praised this approach,[13] including Henry.[234] Cynthia Addai-Robinson reiterated Weber's comments, stating that Tolkien explores ""people of different ethnicities, backgrounds, and walks of life all coming together for a common cause. For me personally, as a viewer, I would have the expectation that [the series] would reflect the real world, as well as the world as I aspire it to be.""[13]
The Escapist's Darren Mooney described these responses as ""the reactionary backlash accompanying any modern project with female characters or characters of color"".[152] Andrew Blair at Den of Geek discussed how this was an example of the increasing racist and sexist complaints made by certain online groups about different media projects over the prior decade (such as the 2016 Ghostbusters reboot and the Star Wars sequel trilogy), using some established techniques such as ""spamming and overwhelming conversation"". As part of the backlash on various online forums and comment sections, members of these groups often used the following quote which they incorrectly attributed to Tolkien: ""Evil is not able to create anything new, it can only distort and destroy what has been invented or made by the forces of good."" Blair felt this was ""colossally lacking in self-awareness"".[235] TheGamer's Ben Sledge compared the backlash to homophobic complaints about Ian McKellen's casting as Gandalf in the Lord of the Rings films. Sledge acknowledged the argument that Tolkien had hoped to create a mythology and fictional history for Britain in his writings, but said the assumption that all people in Britain's history were white was not historically accurate and did not apply to a fantasy story anyway;[236] Dimitra Fimi, a lecturer in fantasy and children's literature and specialist on Tolkien at the University of Glasgow,[230] wrote a piece with Mariana Rios Maldonado for The Conversation that concurred with Sledge in this view, discussing Britain's history of diversity, the freedom of adaptations to make changes where needed, and that Tolkien often did not discuss the biology of his characters but did suggest the existence of dark-skinned Elves in drafts of The Silmarillion.[232]
Discussion of the casting backlash continued after the series premiered,[237][238][239][240] including in analysis of the alleged review bombing on websites such as Rotten Tomatoes, IMDb, and Google. Angus Dalton at The Sydney Morning Herald found that ""many of the most-liked one-star Google reviews cite[d] the show's inclusion of black and brown actors"". He discussed this with Helen Young, a lecturer of writing and literature at Deakin University as well as an editorial board member at the Journal of Tolkien Research, who suggested that there was only a small group of fans expressing these views but they were being amplified by ""far-right political activists"" to create a false narrative that ""real fans of Tolkien don't want actors of color in their Middle-earth"". Dalton also noted criticisms of Galadriel being portrayed as stronger than male Elves.[226]
In early September 2022, Puerto Rican star Ismael Cruz Córdova said he had been receiving messages featuring ""pure and vicious hate speech"" for several years due to his casting as an Elf.[241] Soon after, Lord of the Rings film actors Elijah Wood, Billy Boyd, and Dominic Monaghan released a photo of themselves on social media wearing shirts featuring Human, Hobbit, and Elf ears with different skin tones along with the phrase ""You are all welcome here"" in Elvish. Fellow cast member Sean Astin released his own photo wearing a hat with the same design. Clothing featuring the design was made available for purchase, with half of all proceeds going to a charity that supports people of color. The Rings of Power cast also released a joint statement using the hashtag #YouAreAllWelcomeHere which similarly denounced the racism that several of their members had faced.[242][243] Orlando Bloom, who portrayed Legolas in the original trilogy of films and The Hobbit posted a picture of himself with Cruz Córdova, tagging it ""friend"" in Elvish.[244][245][246]
Aftershow
An official aftershow hosted by Deadline Hollywood's Dominic Patten and Anthony D'Alessandro was revealed on September 3, 2022. Titled Deadline's Inside the Ring: LOTR: The Rings of Power, a new episode of the video series is being released soon after each episode of The Rings of Power debuts on Prime Video. The aftershow features interviews with cast and crew as well as exclusive ""footage and insights"" for each episode.[247]
References
- ^ a b c Otterson, Joe (January 19, 2022). ""'Lord of the Rings' Amazon Series Reveals Full Title in New Video"". Variety. Archived from the original on January 19, 2022. Retrieved January 20, 2022.
- ^ a b c d e f g h i j k l m n o p q r s t u v w x y z aa ab ac ad Breznican, Anthony; Robinson, Joanna (February 10, 2022). ""Amazon's Lord of the Rings Series Rises: Inside The Rings of Power"". Vanity Fair. Archived from the original on February 10, 2022. Retrieved February 10, 2022.
- ^ a b c d e f g h i j k l m n o p Robinson, Joanna (February 14, 2022). ""10 Burning Questions About Amazon's 'The Rings of Power'"". Vanity Fair. Archived from the original on February 14, 2022. Retrieved February 16, 2022.
- ^ a b c d e f g Coggan, Devan (August 2, 2022). ""Meet 13 key characters from 'The Lord of the Rings: The Rings of Power'"". Entertainment Weekly. Archived from the original on August 2, 2022. Retrieved August 8, 2022.
- ^ Oddo, Marco Vito (September 5, 2022). ""'The Lord of the Rings: The Rings of Power': Where is Valinor?"". Collider. Archived from the original on September 5, 2022. Retrieved September 6, 2022.
- ^ a b Travis, Ben (June 2, 2022). ""Empire's The Lord Of The Rings: The Rings Of Power World-Exclusive Covers Revealed"". Empire. Archived from the original on June 5, 2022. Retrieved June 27, 2022.
- ^ Travis, Ben (June 6, 2022). ""Lenny Henry Plays 'Harfoot' Sadoc Burrows In LOTR: The Rings Of Power: 'We're The Traditional Tolkien Little Guy' – Exclusive"". Empire. Archived from the original on June 6, 2022. Retrieved July 31, 2022.
- ^ a b Yeo, Debra (July 30, 2022). ""Canadian cast member of 'The Lord of the Rings: The Rings of Power' says 'the detail was what made it epic'"". Toronto Star. Archived from the original on July 31, 2022. Retrieved July 31, 2022.
- ^ a b Lovett, Jamie (February 14, 2022). ""The Lord of the Rings TV Series Reveals Hobbit's Name, King of the Elves and a Mysterious Stranger"". ComicBook.com. Archived from the original on February 15, 2022. Retrieved February 15, 2022.
- ^ Lambe, Stacy (September 2, 2022). ""'Rings of Power' Premiere: Tyroe Muhafidin on Theo's Attraction to Sauron's Sword"". Entertainment Tonight. Archived from the original on September 2, 2022. Retrieved September 7, 2022.
- ^ a b c d Coggan, Devan (August 2, 2022). ""Power players: Inside 'The Lord of the Rings: The Rings of Power'"". Entertainment Weekly. Archived from the original on August 2, 2022. Retrieved August 8, 2022.
- ^ a b c d e f g h i j k Coggan, Devan (July 13, 2022). ""Get an exclusive look at 'The Lord of the Rings: The Rings of Power'"". Entertainment Weekly. Archived from the original on July 14, 2022. Retrieved July 31, 2022.
- ^ Coggan, Devan (July 19, 2022). ""Step into Middle-earth with EW's exclusive 'The Lord of the Rings: The Rings of Power' photos"". Entertainment Weekly. Archived from the original on July 31, 2022. Retrieved July 31, 2022.
- ^ Edwards, Belen (September 9, 2022). ""Who is Adar in 'The Lord of the Rings: The Rings of Power'?"". Mashable. Archived from the original on September 9, 2022. Retrieved September 9, 2022.
- ^ a b c d e f g Andreeva, Nellie (November 13, 2017). ""Amazon Sets 'The Lord of the Rings' TV Series In Mega Deal With Multi-Season Commitment"". Deadline Hollywood. Archived from the original on November 13, 2017. Retrieved November 13, 2017.
- ^ a b c d e f Siegel, Tatiana (April 5, 2018). ""Inside Amazon's $250M 'Lord of the Rings' Deal: ""It's Very Much a Creature of the Times"""". The Hollywood Reporter. Archived from the original on April 5, 2018. Retrieved April 25, 2020.
- ^ a b Holloway, Daniel (November 3, 2017). ""'Lord of the Rings': Amazon, Warner Bros. in Talks for Series Adaptation (Exclusive)"". Variety. Archived from the original on March 16, 2020. Retrieved November 5, 2017.
- ^ a b c d James Hibberd (October 5, 2022). ""'The Rings of Power' Showrunners Break Silence on Backlash, Sauron and Season 2"". The Hollywood Reporter. Retrieved October 8, 2022.
- ^ a b c d e Andreeva, Nellie (November 18, 2019). ""'The Lord Of the Rings' Series Gets Early Season 2 Renewal By Amazon, Sets Season 1 Hiatus"". Deadline Hollywood. Archived from the original on November 19, 2019. Retrieved April 26, 2020.
- ^ a b c d e Eckrich, Tobias M. (July 29, 2019). ""Exclusive Interview with Tom Shippey Concerning LOTRonPrime"". Deutsche Tolkien Gesellschaft. Archived from the original on August 5, 2019. Retrieved April 26, 2020.
- ^ Harp, Justin (June 6, 2018). ""Is Peter Jackson involved in Amazon's Lord of the Rings series? Here's the answer"". Digital Spy. Archived from the original on April 15, 2019. Retrieved April 25, 2020.
- ^ Goldberg, Lesley (June 12, 2018). ""Jennifer Salke Details Amazon Plans: Fix Culture, Empower Women, 'Lord of the Rings' by 2021"". The Hollywood Reporter. Archived from the original on July 10, 2018. Retrieved April 25, 2020.
- ^ a b Shepherd, Jack (July 25, 2022). ""Amazon were pitched Lord of the Rings TV shows on young Aragorn and a Gimli spin-off"". GamesRadar+. Archived from the original on July 25, 2022. Retrieved August 1, 2022.
- ^ a b c d Dockterman, Eliana (August 15, 2022). ""The Secretive, Extravagant, Bighearted World of 'The Rings of Power'"". TIME. Archived from the original on August 15, 2022. Retrieved August 20, 2022.
- ^ a b Dockterman, Eliana (August 15, 2022). ""11 'Rings of Power' Secrets We Learned From the Cast and Creators"". TIME. Archived from the original on August 15, 2022. Retrieved August 20, 2022.
- ^ a b c Lussier, Germain (July 23, 2022). ""Lord of the Rings: The Rings of Power Is a 'Mega Epic'"". Gizmodo. Archived from the original on July 23, 2022. Retrieved August 8, 2022.
- ^ Goldberg, Lesley; Kit, Borys (July 28, 2018). ""'Lord of the Rings': Amazon Taps 'Star Trek 4' Duo to Develop TV Series"". The Hollywood Reporter. Archived from the original on July 28, 2018. Retrieved April 25, 2020.
- ^ a b c Hibberd, James (August 5, 2022). ""Peter Jackson Says Amazon's 'Lord of the Rings' TV Series Ghosted Him"". The Hollywood Reporter. Archived from the original on August 6, 2022. Retrieved August 6, 2022.
- ^ a b Taylor-Foster, Kim (December 4, 2018). ""Peter Jackson's Tips For Casting Aragorn in Lord of the Rings TV Show"". Fandom. Archived from the original on April 8, 2019. Retrieved May 1, 2020.
- ^ Otterson, Joe (May 21, 2019). ""'Game of Thrones' Alum Bryan Cogman Boards 'Lord of the Rings' Series at Amazon"". Variety. Archived from the original on May 21, 2019. Retrieved April 26, 2020.
- ^ a b Andreeva, Nellie (July 3, 2019). ""'The Lord Of The Rings': J.A. Bayona To Direct Amazon Series"". Deadline Hollywood. Archived from the original on January 9, 2020. Retrieved July 3, 2019.
- ^ Andreeva, Nellie (July 25, 2019). ""David Benioff & D.B. Weiss May Have Narrowed Down Field For Blockbuster Overall Deal"". Deadline Hollywood. Archived from the original on July 25, 2019. Retrieved April 26, 2020.
- ^ Fleming, Mike Jr. (August 7, 2019). ""Netflix Wins Overall Film, TV Deal For 'Game Of Thrones' Creators David Benioff & D.B. Weiss"". Deadline Hollywood. Archived from the original on August 7, 2019. Retrieved April 26, 2020.
- ^ a b @LOTRonPrime (July 27, 2019). ""Meet our Fellowship"" (Tweet). Archived from the original on September 2, 2019. Retrieved July 28, 2019 – via Twitter.
- ^ a b c White, Peter (July 27, 2019). ""Amazon Sets Creative Team For 'Lord Of The Rings' TV Series Including 'GoT' & 'Breaking Bad' Producers – TCA"". Deadline Hollywood. Archived from the original on July 27, 2019. Retrieved April 26, 2020.
- ^ a b c d e Milne, Jonathan; Sumner, Bonnie (August 5, 2021). ""Return of the Rings: Govt hopes Amazon will come back to film more seasons"". Newsroom. Archived from the original on August 5, 2021. Retrieved August 7, 2021.
- ^ Jennings, Collier (April 16, 2020). ""Report: Amazon's Lord of the Rings Parts Ways With Tolkien Scholar Tom Shippey"". Comic Book Resources. Archived from the original on April 23, 2020. Retrieved April 26, 2020.
- ^ a b c Quickbeam Broadway, Cliff (July 20, 2021). ""Spy Report: 20 new details emerge from Amazon's Lord of the Rings: Characters, Sexless Nudity and Halflings!"". TheOneRing.net. Archived from the original on July 20, 2021. Retrieved July 21, 2021.
- ^ a b Goldberg, Lesley (December 3, 2020). ""'Lord of the Rings' Adds 20 to Sprawling Cast for Amazon Series"". The Hollywood Reporter. Archived from the original on December 3, 2020. Retrieved December 4, 2020.
- ^ David, Mark (February 17, 2015). ""Callum Greene Lists Modern Architectural Home in Silver Lake"". Variety. Archived from the original on February 17, 2015. Retrieved December 4, 2020.
- ^ a b c d Coggan, Devan (July 19, 2022). ""How 'The Lord of the Rings: The Rings of Power' crafted a new (old) Middle-earth"". Entertainment Weekly. Archived from the original on July 19, 2022. Retrieved August 1, 2022.
- ^ a b Littleton, Cynthia (March 24, 2021). ""'Lord of the Rings' Series Adds Director Wayne Che Yip as Co-Executive Producer"". Variety. Archived from the original on March 24, 2021. Retrieved March 28, 2021.
- ^ a b Grater, Tom (May 13, 2021). ""'The Witcher' Director Charlotte Brändström Joins Amazon's 'The Lord Of The Rings' Series"". Deadline Hollywood. Archived from the original on May 13, 2021. Retrieved May 15, 2021.
- ^ MacDonald, Lindsay (January 14, 2020). ""Amazon Just Revealed the Huge Cast of Its Lord of the Rings TV Series"". TV Guide. Archived from the original on January 15, 2020. Retrieved January 4, 2021.
- ^ Keegan, Rebecca (February 18, 2019). ""Amazon Chief Jennifer Salke Unveils Film Plan to Battle Netflix: 30 Movies a Year (Q&A)"". The Hollywood Reporter. Archived from the original on February 18, 2019. Retrieved April 26, 2020.
- ^ a b c Sledge, Ben (May 14, 2022). ""Tolkien Experts Saw A Sneak Peek Of The Rings Of Power – Here's What They Think"". TheGamer. Archived from the original on May 17, 2022. Retrieved May 26, 2022.
- ^ Coggan, Devan (July 19, 2022). ""How Simon Tolkien helped guide 'The Lord of the Rings: The Rings of Power'"". Entertainment Weekly. Archived from the original on July 19, 2022. Retrieved August 1, 2022.
- ^ Hibberd, James (August 12, 2022). ""'Lord of the Rings' TV Writers: Show Not Just ""Vaguely Connected"" to Tolkien"". The Hollywood Reporter. Archived from the original on August 12, 2022. Retrieved August 27, 2022.
- ^ Phillips, Michael (September 1, 2022). ""Review: 'Lord of the Rings: The Rings of Power' is Amazon's lavish bid for buzz. It's off to a pretty good start"". Chicago Tribune. Archived from the original on September 1, 2022. Retrieved September 3, 2022.
- ^ Travis, Ben (June 7, 2022). ""Lord Of The Rings: The Rings Of Power's Five Seasons Are Fully Planned Out: 'We Know What Our Final Shot Will Be' – Exclusive"". Empire. Archived from the original on June 7, 2022. Retrieved June 27, 2022.
- ^ Francisco, Eric (June 16, 2022). ""'Rings of Power' expands Tolkien's world by ""honoring his work"" in one vital way"". Inverse. Archived from the original on June 16, 2022. Retrieved August 1, 2022.
- ^ MacKenzie, Steven (September 2, 2022). ""Lord of the Rings: The Rings of Power star Sophia Nomvete: 'Everyone could benefit from thinking like a dwarf'"". The Big Issue. Archived from the original on September 2, 2022. Retrieved September 4, 2022.
- ^ a b Shepherd, Jack (July 25, 2022). ""The Lord of the Rings: The Rings of Power showrunners address rumors that modern politics will influence the show"". GamesRadar+. Archived from the original on July 25, 2022. Retrieved August 1, 2022.
- ^ Broadway, Clifford (October 6, 2020). ""Sex & Sensibility: Amazon's Nude Take On Tolkien"". TheOneRing.net. Archived from the original on October 7, 2020. Retrieved February 11, 2022.
- ^ Sewell, Justin (January 12, 2021). ""Exclusive: Official Show Synopsis for Amazon's Lord of the Rings Series"". TheOneRing.net. Archived from the original on January 13, 2021. Retrieved January 13, 2021.
- ^ a b Carson, Erin (August 26, 2022). ""What Is a Harfoot? A Peek at the 'Rings of Power' Hobbit Ancestor"". CNET. Archived from the original on August 26, 2022. Retrieved August 31, 2022.
- ^ a b Andreeva, Nellie (June 11, 2018). ""Amazon Studios Head Jennifer Salke On Strategy, 'Lord Of the Rings' Series, Battle For Talent & 'Transparent' End Game: Q&A"". Deadline Hollywood. Archived from the original on June 12, 2018. Retrieved April 25, 2020.
- ^ a b Andreeva, Nellie (July 22, 2019). ""'The Lord Of the Rings' Amazon TV Series Sets Series Regular Cast Member"". Deadline Hollywood. Archived from the original on July 22, 2019. Retrieved April 26, 2020.
- ^ Lawton, Nicole (July 12, 2019). ""Lord of the Rings TV series: Casting call for 'Middle Earth' soldiers, villagers and villains"". Stuff. Archived from the original on July 13, 2019. Retrieved April 26, 2020.
- ^ Otterson, Joe (July 22, 2019). ""'Lord of the Rings' Series at Amazon Taps First Cast Member (Exclusive)"". Variety. Archived from the original on July 22, 2019. Retrieved July 22, 2019.
- ^ Andreeva, Nellie; Petski, Denise (September 4, 2019). ""'The Lord Of The Rings' Amazon TV Series Casts Will Poulter As A Lead"". Deadline Hollywood. Archived from the original on September 4, 2019. Retrieved April 26, 2020.
- ^ a b Otterson, Joe; Kroll, Justin (September 4, 2019). ""'Lord of The Rings' Series at Amazon Casts Will Poulter (Exclusive)"". Variety. Archived from the original on September 4, 2019. Retrieved April 26, 2020.
- ^ Sneider, Jeff (October 15, 2019). ""Exclusive: 'Lord of the Rings' TV Series Adds 'Years and Years' Star Maxim Baldry"". Collider. Archived from the original on October 15, 2019. Retrieved April 26, 2020.
- ^ a b Andreeva, Nellie (March 4, 2020). ""'The Lord Of the Rings': Maxim Baldry Set As A Lead In Amazon Series"". Deadline Hollywood. Archived from the original on March 4, 2020. Retrieved March 10, 2020.
- ^ Andreeva, Nellie (October 21, 2019). ""'The Lord Of The Rings': Joseph Mawle To Star In Amazon Series"". Deadline Hollywood. Archived from the original on October 22, 2019. Retrieved October 22, 2019.
- ^ Andreeva, Nellie (December 10, 2019). ""'The Lord Of The Rings': Ema Horvath Joins Cast Of Amazon Series"". Deadline Hollywood. Archived from the original on December 11, 2019. Retrieved April 26, 2020.
- ^ Otterson, Joe (December 12, 2019). ""'Lord of the Rings': Will Poulter No Longer Attached to Amazon Series (Exclusive)"". Deadline Hollywood. Archived from the original on December 12, 2019. Retrieved April 26, 2020.
- ^ Allen, Ben (November 11, 2021). ""Will Poulter: 'I'm very honoured to have been welcomed into the Marvel family'"". GQ. Archived from the original on November 17, 2021. Retrieved November 22, 2021.
- ^ Kroll, Justin (December 17, 2019). ""'Lord of the Rings' Series Taps Morfydd Clark as Young Galadriel (Exclusive)"". Variety. Archived from the original on December 18, 2019. Retrieved December 17, 2019.
- ^ Andreeva, Nellie (January 7, 2020). ""'The Lord Of the Rings': Robert Aramayo To Star In Amazon TV Series"". Deadline Hollywood. Archived from the original on January 7, 2020. Retrieved April 26, 2020.
- ^ a b c Craig, Elvy (February 10, 2022). ""Every LOTR Movie Character Returning In The Rings Of Power"". Screen Rant. Archived from the original on February 11, 2022. Retrieved February 11, 2022.
- ^ a b c D'Alessandro, Anthony (January 14, 2020). ""'The Lord Of The Rings': Amazon Studios Sets Series Cast – TCA"". Deadline Hollywood. Archived from the original on March 7, 2020. Retrieved March 15, 2020.
- ^ Coggan, Devan (October 14, 2022). ""Sauron speaks! That Rings of Power actor opens up about the big finale reveal"". Entertainment Weekly. Retrieved October 17, 2022.
{{cite news}}: CS1 maint: url-status (link)
- ^ a b Otterson, Joe (December 3, 2020). ""'Lord of the Rings' Series at Amazon Adds 20 Actors to Cast"". Variety. Archived from the original on December 3, 2020. Retrieved December 4, 2020.
- ^ Knox, David (March 17, 2021). ""Actor departs Lord of the Rings"". TV Tonight. Archived from the original on March 17, 2021. Retrieved March 17, 2021.
- ^ a b Goldberg, Lesley (July 1, 2021). ""Amazon's 'Lord of the Rings' Rounds Out Sprawling Cast (Exclusive)"". The Hollywood Reporter. Archived from the original on July 1, 2021. Retrieved July 1, 2021.
- ^ a b Coggan, Devan (July 22, 2022). ""Stephen Colbert really wants a role in 'The Lord of the Rings: The Rings of Power'"". Entertainment Weekly. Archived from the original on July 22, 2022. Retrieved August 7, 2022.
- ^ Dockterman, Eliana (August 15, 2022). ""This Fan-Favorite Character Is Joining the Second Season of 'Rings of Power'"". TIME. Archived from the original on August 15, 2022. Retrieved August 20, 2022.
- ^ Dominguez, Noah (August 17, 2022). ""Lord of the Rings' Círdan Will Appear in Rings of Power Season 2"". Comic Book Resources. Archived from the original on August 17, 2022. Retrieved August 20, 2022.
- ^ a b Sutton, David (August 18, 2019). ""Interview with Narnia Conceptual Designer John Howe"". NarniaFans.com. Archived from the original on March 20, 2020. Retrieved May 1, 2020.
- ^ a b ""Showrunners and John Howe reveal more of Rings of Power"". TheOneRing.net. June 10, 2022. Archived from the original on June 10, 2022. Retrieved June 27, 2022.
- ^ a b c Jarrett, Cosette (August 11, 2022). ""New images reveal a never-before-seen realm in 'The Lord of the Rings: The Rings of Power'"". About Amazon. Archived from the original on August 11, 2022. Retrieved August 27, 2022.
- ^ a b c ""8 secrets of Númenor—an unseen kingdom in 'The Lord of the Rings: The Rings of Power'"". About Amazon. August 19, 2022. Archived from the original on August 27, 2022. Retrieved August 27, 2022.
- ^ Emberwing, Amelia (June 21, 2022). ""Exclusive First Look at the Orcs From Prime Video's The Lord of the Rings: The Rings of Power"". IGN. Archived from the original on June 21, 2022. Retrieved June 27, 2022.
- ^ a b c ""New $1.5b LOTR TV series set to film in Auckland"". Newstalk ZB. June 30, 2019. Archived from the original on June 30, 2019. Retrieved April 26, 2020.
- ^ McDonald, Craig (February 10, 2019). ""New £1b Lord of the Rings prequel TV series set to be filmed in Scotland"". Daily Record. Archived from the original on February 10, 2019. Retrieved April 26, 2020.
- ^ McDonald, Craig (April 14, 2019). ""Amazon's £1bn Lord of the Rings series set to be filmed at new Scots studio"". Daily Record. Archived from the original on April 17, 2019. Retrieved January 4, 2021.
- ^ Keogh, Brittany (December 23, 2018). ""Plans to film $1 billion Lord of the Rings television series in NZ under threat"". Stuff. Archived from the original on December 22, 2018. Retrieved April 25, 2020.
- ^ Walls, Jason (July 2, 2019). ""Announcement on Amazon producing the Lord of the Rings TV show in NZ is 'imminent'"". New Zealand Herald. Archived from the original on August 8, 2019. Retrieved August 24, 2019.
- ^ ""NZ nearly lost Amazon's Lord of the Rings production after Christchurch attacks"". Stuff. July 2, 2019. Archived from the original on August 24, 2019. Retrieved August 24, 2019.
- ^ ""Amazon Studios Announces New Zealand as Location for Its Upcoming Series Based on The Lord of the Rings"" (Press release). Culver City, California: Amazon Studios. September 17, 2019. Archived from the original on December 5, 2019. Retrieved May 7, 2020.
- ^ Te, Mandy (September 18, 2019). ""Amazon's The Lord of The Rings TV series to start filming in Auckland"". Stuff. Archived from the original on September 18, 2019. Retrieved April 26, 2020.
- ^ a b c Coughlan, Thomas (April 15, 2021). ""Amazon may be on the way to New Zealand, as Government signs subsidy deal"". Stuff. Archived from the original on April 17, 2021. Retrieved April 16, 2021.
- ^ a b ""Government to give Amazon over $100m boost for Lord of the Rings filming"". Radio New Zealand. April 16, 2021. Archived from the original on April 17, 2021. Retrieved April 16, 2021.
- ^ Hibberd, James (April 16, 2021). ""Amazon's 'The Lord of the Rings' to Cost $465M for Just One Season"". The Hollywood Reporter. Archived from the original on April 16, 2021. Retrieved April 16, 2021.
- ^ Rose, Lacey (May 12, 2021). """"Just Go In and Do Your Thing"": Hollywood's Most Powerful Women Talk Megadeals, Bullying and Perseverance at THR's Executive Roundtable"". The Hollywood Reporter. Archived from the original on May 12, 2021. Retrieved May 15, 2021.
- ^ a b c d e f g h Andreeva, Nellie (August 12, 2021). ""'The Lord Of The Rings' To Move Production To UK From New Zealand For Season 2"". Deadline Hollywood. Archived from the original on August 12, 2021. Retrieved August 14, 2021.
- ^ Milne, Jonathan (August 13, 2021). ""$33m penalty as Lord of the Rings turns its back on NZ"". Newsroom. Archived from the original on August 12, 2021. Retrieved August 14, 2021.
- ^ McConnell, Glenn (February 26, 2020). ""Massive production underway for Lord of the Rings in Auckland"". Stuff. Archived from the original on February 26, 2020. Retrieved April 26, 2020.
- ^ a b c d Dennett, Kelly; Hoyle, Craig (August 20, 2022). ""'We love NZ': LOTR The Rings of Power earns high praise for Kiwi film industry"". Stuff. Archived from the original on August 20, 2022. Retrieved August 27, 2022.
- ^ Bayona, J. A. [@FilmBayona] (June 30, 2020). ""Feliz de ver en la lista a mi querido Oscar Faura, que se ha encargado de la fotografía de todas las películas que he dirigido y con el que estoy trabajando ahora mismo en The Lord of the Rings"" [Happy to see my dear Oscar Faura on the list, who has been in charge of photography for all the films I've directed and with whom I'm working right now on The Lord of the Rings.] (Tweet) (in Spanish). Archived from the original on June 30, 2020. Retrieved February 12, 2022 – via Twitter.
- ^ Sewell, Justin (February 21, 2020). ""Exclusive: Spy Report from the Set of Amazon's LOTR with photos!"". TheOneRing.net. Archived from the original on February 29, 2020. Retrieved May 1, 2020.
- ^ a b Edmunds, Susan (January 19, 2020). ""Lord of the Rings TV: Amazon Studios puts out call for homes for cast and crew"". Stuff. Archived from the original on May 1, 2020. Retrieved April 26, 2020.
- ^ Ellwood, Gregory (August 24, 2022). ""'The Lord Of The Rings: The Rings Of Power': J.D. Payne & Patrick McKay Achieve The Impossible, But It's Not What You Think"". The Playlist. Archived from the original on August 24, 2022. Retrieved August 27, 2022.
- ^ a b Hunt, Tom (July 3, 2020). ""Revealed: The six productions joining Avatar in getting border exemptions"". Stuff. Archived from the original on July 4, 2020. Retrieved July 4, 2020.
- ^ Andreeva, Nellie (September 28, 2020). ""Amazon's 'The Lord Of The Rings' Resumes Production In New Zealand, Netflix's 'Cowboy Bebop' Next"". Deadline Hollywood. Archived from the original on September 30, 2020. Retrieved October 4, 2020.
- ^ a b Perry, Spencer (December 25, 2020). ""Amazon's Lord Of The Rings Pilot Has Wrapped Filming"". ComicBook.com. Archived from the original on December 28, 2020. Retrieved December 25, 2020.
- ^ Simich, Ricardo (December 20, 2020). ""Spy: Lunch of the Rings? The LOTR star spotted on Waiheke"". New Zealand Herald. Archived from the original on December 20, 2020. Retrieved January 4, 2021.
- ^ ""Storytellers Series: Aaron Morton"". Moxion. July 28, 2021. Archived from the original on February 12, 2022. Retrieved February 12, 2022.
- ^ Dillard, Samantha (November 22, 2021). ""ASC Welcomes New Member Alex Disenhof"". American Cinematographer. Archived from the original on November 22, 2021. Retrieved February 12, 2022.
- ^ Motomayor, Rafael (June 29, 2021). ""Benjamin Walker on How He Joined the 'Lord of the Rings' TV Show & Why a Bigger Budget Is Important"". Collider. Archived from the original on June 29, 2021. Retrieved July 2, 2021.
- ^ a b Hibberd, James (August 12, 2021). ""Amazon's 'The Lord of the Rings' Is Leaving New Zealand for the U.K. for Season 2"". The Hollywood Reporter. Archived from the original on August 12, 2021. Retrieved August 14, 2021.
- ^ a b Dillane, Tom (July 3, 2021). ""Stunt workers' fury over Lord of the Rings injuries"". New Zealand Herald. Archived from the original on July 3, 2021. Retrieved July 2, 2021.
- ^ Nippert, Matt (February 14, 2020). ""Stuntwoman's serious injury mars start of filming for Amazon blockbuster"". New Zealand Herald. Archived from the original on February 14, 2020. Retrieved March 15, 2020.
- ^ Petski, Denise (August 2, 2021). ""'The Lord Of The Rings' TV Series Gets Amazon Premiere Date & First-Look Photo"". Deadline Hollywood. Archived from the original on August 2, 2021. Retrieved August 2, 2021.
- ^ a b Sweney, Mark (August 12, 2021). ""Amazon moves production of Lord of the Rings TV series to UK"". The Guardian. Archived from the original on August 12, 2021. Retrieved August 14, 2021.
- ^ Walls, Jason; Dillane, Tom (September 26, 2021). ""Revealed: Amazon's private Lord of the Rings MIQ pitch shot down by Government last year"". New Zealand Herald. Archived from the original on September 26, 2021. Retrieved October 1, 2021.
- ^ Gray, Alistair (December 13, 2021). ""Tax rebates fuel UK film and TV boom"". Financial Times. Archived from the original on December 13, 2021. Retrieved February 11, 2022.
- ^ ""High-end Television Tax Relief"". British Film Commission. December 19, 2017. Archived from the original on January 19, 2022. Retrieved February 11, 2022.
- ^ Ellwood, Gregory (August 24, 2022). ""'The Lord Of The Rings: The Rings Of Power': J.D. Payne & Patrick McKay Achieve The Impossible, But It's Not What You Think | Page 2"". The Playlist. Archived from the original on August 27, 2022. Retrieved August 27, 2022.
- ^ a b Ravindran, Manori; Yossman, K. J. (November 24, 2021). ""Amazon's 'Lord of the Rings' Series Sets First U.K. Filming Locations (Exclusive)"". Variety. Archived from the original on November 24, 2021. Retrieved November 29, 2021.
- ^ Hibberd, James (October 3, 2022). ""'The Rings of Power' Season 2 Starts Production in the U.K."" The Hollywood Reporter. Retrieved October 4, 2022.
- ^ a b c Tangcay, Jazz (September 1, 2022). ""'Rings of Power' Used 20 VFX Studios, Nearly 10,000 VFX Shots to Revive Middle-earth (Exclusive)"". Variety. Archived from the original on September 3, 2022. Retrieved September 3, 2022.
- ^ Shepherd, Jack (August 26, 2022). ""Inside The Lord of the Rings: The Rings of Power, the most expensive show ever made"". GamesRadar+. Archived from the original on August 26, 2022. Retrieved August 27, 2022.
- ^ a b ""Howard Shore and Bear McCreary to soundtrack LOTR on Prime series"". TheOneRing.net. September 19, 2021. Archived from the original on September 21, 2021. Retrieved July 28, 2022.
- ^ Fleming, Mike Jr. (September 19, 2021). ""Oscar-Winning 'The Lord Of The Rings' Howard Shore In Talks To Compose Music For Amazon Studios' Middle Earth-Set TV Series"". Deadline Hollywood. Archived from the original on September 20, 2021. Retrieved September 19, 2021.
- ^ a b Reilly, Nick (July 21, 2022). ""Bear McCreary confirmed as composer of 'The Lord of the Rings: The Rings of Power'"". Rolling Stone UK. Archived from the original on July 21, 2022. Retrieved July 28, 2022.
- ^ Fleming, Mike Jr. (July 21, 2022). ""Howard Shore Returns & Bear McCreary Scores Amazon's 'The Lord Of The Rings: The Rings Of Power'"". Deadline Hollywood. Archived from the original on July 21, 2022. Retrieved July 28, 2022.
- ^ a b Burlingame, Jon (August 19, 2022). ""Bear McCreary Talks Scoring 'Lord of the Rings: The Rings of Power' as Soundtrack Releases Worldwide"". Variety. Archived from the original on August 19, 2022. Retrieved August 20, 2022.
- ^ Motamayor, Rafael (August 19, 2022). ""The Lord Of The Rings: The Rings Of Power Soundtrack Is Now Available To Stream"". /Film. Archived from the original on August 19, 2022. Retrieved August 20, 2022.
- ^ ""'The Lord of the Rings: The Rings of Power' Soundtrack Album Details"". Film Music Reporter. August 18, 2022. Archived from the original on August 18, 2022. Retrieved August 20, 2022.
- ^ ""The Lord of the Rings: The Rings of Power Season One Soundtrack Available Now!"". TheOneRing.net. August 19, 2022. Archived from the original on August 20, 2022. Retrieved August 20, 2022.
- ^ a b Eckrich, Tobias M. (April 19, 2019). ""Confirmed: John Howe and Tom Shippey Involved in the Amazon Series"". Deutsche Tolkien Gesellschaft. Archived from the original on May 10, 2019. Retrieved April 26, 2020.
- ^ a b ""Prime Video's The Lord of the Rings Title Reveal – Exclusive Behind the Scenes images"". TheOneRing.net. January 19, 2022. Archived from the original on January 19, 2022. Retrieved January 22, 2022.
- ^ a b Emberwing, Amelia (January 19, 2022). ""This Is How They Made the Lord of the Rings Title Sequence"". IGN. Archived from the original on January 19, 2022. Retrieved January 22, 2022.
- ^ ""The Lord of the Rings: The Rings of Power"". Prologue Films. Archived from the original on May 8, 2022. Retrieved May 8, 2022.
- ^ Sewell, Justin (February 4, 2022). ""Exclusive: All 23 LOTR The Rings of Power Posters now with Hi-Res Extended Versions"". TheOneRing.net. Archived from the original on February 4, 2022. Retrieved February 7, 2022.
- ^ a b Alter, Rebecca (February 3, 2022). ""How Amazon Prime Wants Us to Cover The Rings of Power"". Vulture. Archived from the original on February 3, 2022. Retrieved February 7, 2022.
- ^ Harrisson, Juliette (February 4, 2022). ""Lord of the Rings: The Rings of Power – Who's Who In The Character Posters?"". Den of Geek. Archived from the original on February 4, 2022. Retrieved February 7, 2022.
- ^ ""Official LOTR Trailer Watch party for Prime Video's Rings of Power to be hosted by TORn!"". TheOneRing.net. February 7, 2022. Archived from the original on February 7, 2022. Retrieved February 7, 2022.
- ^ a b Mooney, Darren (February 18, 2022). ""Why Are People So Angry About The Rings of Power?"". The Escapist. Archived from the original on February 18, 2022. Retrieved August 6, 2022.
- ^ a b ""The Vibes of Power: Amazon shares exciting Rings of Power insight"". TheOneRing.net. May 9, 2022. Archived from the original on May 9, 2022. Retrieved May 26, 2022.
- ^ Sewell, Justin (May 10, 2022). ""'Rings of Power' Footage Snags High Praise from Tolkien Fans"". TheOneRing.net. Archived from the original on May 10, 2022. Retrieved May 26, 2022.
- ^ Directo-Meston, Danielle (July 6, 2022). ""How to Watch the Latest 'Lord of the Rings' Prequel TV Series Trailer Before Everyone Else"". The Hollywood Reporter. Archived from the original on July 6, 2022. Retrieved August 6, 2022.
- ^ Lussier, Germain (July 6, 2022). ""Prime Video Releases New Lord of the Rings: Rings of Power Teaser"". Gizmodo. Archived from the original on July 8, 2022. Retrieved August 6, 2022.
- ^ a b Maas, Jennifer; Vary, Adam B. (August 3, 2022). ""TV's Big Fantasy Gamble: 'Lord of the Rings,' 'House of the Dragon,' and the Battle to Claim the Next Blockbuster Franchise"". Variety. Archived from the original on August 3, 2022. Retrieved August 7, 2022.
- ^ a b Vary, Adam B. (July 22, 2022). ""'Lord of the Rings: The Rings of Power' Unveils Intense New Trailer at Comic-Con: Sauron, Orcs and One Angry Balrog"". Variety. Archived from the original on July 22, 2022. Retrieved August 7, 2022.
- ^ Patten, Dominic; Sitek, Natalie (July 20, 2022). ""'Game Of Thrones' Prequel 'House Of The Dragon' Snags Key Comic-Con Position In Marketing War; Street Battle For Eyeballs Back With 'LOTR' Series, 'TWD,' 'Star Trek' & More"". Deadline Hollywood. Archived from the original on July 20, 2022. Retrieved August 7, 2022.
- ^ a b Couch, Aaron (July 27, 2022). ""After Absence, Comic-Con Regains Status as Key Studio Marketing Launchpad"". The Hollywood Reporter. Archived from the original on July 27, 2022. Retrieved August 7, 2022.
- ^ a b Lincoln, Ross A.; Gonzalez, Umberto; Taylor, Drew; Chitwood, Adam (July 24, 2022). ""Comic-Con 2022: Winners and Losers, from Marvel to DC... and DC"". TheWrap. Archived from the original on July 25, 2022. Retrieved August 7, 2022.
- ^ a b Bankhurst, Adam (July 26, 2022). ""The Winners of San Diego Comic-Con 2022: Marvel, The Rings of Power, House of the Dragon, and More"". IGN. Archived from the original on July 26, 2022. Retrieved August 7, 2022.
- ^ ""The Winners and Losers of San Diego Comic-Con 2022"". Gizmodo. July 25, 2022. Archived from the original on August 7, 2022. Retrieved August 7, 2022.
- ^ Breznican, Anthony (July 22, 2022). ""The Lord of the Rings: The Rings of Power Trailer Throws Down the Gauntlet"". Vanity Fair. Archived from the original on July 22, 2022. Retrieved August 7, 2022.
- ^ a b Whitbrook, James (July 22, 2022). ""Lord of the Rings: The Rings of Power's Comic-Con Trailer Transported Us to Middle-Earth"". Gizmodo. Archived from the original on July 22, 2022. Retrieved August 7, 2022.
- ^ a b Shepherd, Jack (July 22, 2022). ""New Lord of the Rings: The Rings of Power trailer brings the Balrog to San Diego Comic-Con"". GamesRadar+. Archived from the original on July 22, 2022. Retrieved August 7, 2022.
- ^ Coggan, Devan (July 22, 2022). ""'The Lord of the Rings: The Rings of Power' teases elves, dwarves, and very angry balrog"". Entertainment Weekly. Archived from the original on July 22, 2022. Retrieved August 7, 2022.
- ^ Commentary on the final trailer for the season:
- ""Final Rings of Power trailer is here"". TheOneRing.net. August 23, 2022. Archived from the original on August 23, 2022. Retrieved August 27, 2022.
- Pulliam-Moore, Charles (August 23, 2022). ""Galadriel takes no prisoners in The Lord of the Rings: The Rings of Power's newest trailer"". The Verge. Archived from the original on August 23, 2022. Retrieved August 27, 2022.
- Codega, Linda (August 23, 2022). ""New Lord of the Rings: The Rings of Power Trailer Debuts"". Gizmodo. Archived from the original on August 23, 2022. Retrieved August 27, 2022.
- Ouellette, Jennifer (August 23, 2022). ""We're loving the lavish epic visuals in the new LOTR: Rings of Power trailer"". Ars Technica. Archived from the original on August 23, 2022. Retrieved August 27, 2022.
- McAuliffe, Zachary (August 23, 2022). ""New 'Lord of the Rings: The Rings of Power' Trailer Drops Week Before Premiere"". CNET. Archived from the original on August 23, 2022. Retrieved August 27, 2022.
- ^ Balakumar, K. (August 25, 2022). ""Samsung and Prime Video bring LOTR: The Rings of Power content in 8K"". TechRadar. Archived from the original on August 25, 2022. Retrieved August 27, 2022.
- ^ Graves, Sabina (June 22, 2022). ""New Tolkien Collection Gathers Writings on Middle-earth's Second Age"". Gizmodo. Archived from the original on June 23, 2022. Retrieved June 27, 2022.
- ^ Tapp, Tom (August 16, 2022). ""'The Lord Of The Rings: The Rings Of Power' L.A. Premiere Photos"". Deadline Hollywood. Archived from the original on August 16, 2022. Retrieved August 25, 2022.
- ^ ""Rings of Power premiere celebration in Mexico City"". TheOneRing.net. August 18, 2022. Archived from the original on August 18, 2022. Retrieved August 25, 2022.
- ^ ""The Lord of the Rings: The Rings of Power's Asia Pacific premiere sees record attendance from fans and celebrities"". Firstpost. August 20, 2022. Archived from the original on August 20, 2022. Retrieved August 25, 2022.
- ^ Burack, Emily (August 25, 2022). ""See the Cast of The Lord of the Rings: The Rings of Power at the New York Premiere"". Town & Country. Archived from the original on August 25, 2022. Retrieved August 25, 2022.
- ^ Goldbart, Max (August 31, 2022). ""Jeff Bezos Makes Surprise Appearance At Global 'The Lord Of The Rings: The Rings Of Power' Premiere, Reveals He Gave Notes To Showrunners As Battle Of The Prequels Rages Between Amazon & HBO"". Deadline Hollywood. Archived from the original on August 31, 2022. Retrieved September 4, 2022.
- ^ Murphy, J. Kim (August 21, 2022). ""'The Rings of Power' to Screen First Two Episodes in Theaters Ahead of Series Premiere"". Variety. Archived from the original on August 21, 2022. Retrieved August 25, 2022.
- ^ ""'The Lord of the Rings: The Rings Of Power'; Prime Video Reveals Rollout Schedule"". Deadline Hollywood. August 16, 2022. Archived from the original on August 16, 2022. Retrieved August 16, 2022.
- ^ Bradley, Bill (September 2, 2022). ""How The Rings of Power Showrunners Handled a Massive Global Debut"". Adweek. Archived from the original on September 4, 2022. Retrieved September 4, 2022.
- ^ ""25 Million Watched 'Lord Of The Rings' Spinoff 'Rings Of Power' Premiere"". Forbes. September 3, 2022.
- ^ ""'The Lord of the Rings: The Rings of Power' was watched by more than 25 million globally, Amazon says"". CNBC. September 3, 2022.
- ^ ""'LOTR: The Rings Of Power' Forges Biggest Premiere Viewership Ever For Amazon Prime Video"". Deadline Hollywood. September 3, 2022.
- ^ ""Amazon Claims First-Day Record Audience for 'Rings of Power'"". The Hollywood Reporter. September 3, 2022.
- ^ ""Amazon's 'Lord of the Rings: The Rings of Power' Draws More Than 25 Million Viewers"". The Wall Street Journal. September 5, 2022.
- ^ a b Gruenwedel, Erik (September 6, 2022). ""Samba TV: Prime Video's 'The Rings of Power' Falls Short of 'Stranger Things 4,' 'Obi-Wan Kenobi' Debuts"". Media Play News. Archived from the original on September 6, 2022. Retrieved September 10, 2022.
- ^ a b Edwards, Molly (September 7, 2022). ""The House of the Dragon premiere beat The Rings of Power by a considerable margin"". GamesRadar+. Archived from the original on September 7, 2022. Retrieved September 10, 2022.
- ^ Prange, Stephanie (September 6, 2022). ""'Elvis,' 'She-Hulk: Attorney at Law' Top Weekly Whip U.S. Streaming Charts"". Media Play News. Archived from the original on September 6, 2022. Retrieved September 10, 2022.
- ^ Katz, Brandon (September 8, 2022). ""Who's Winning the 'Rings of Power' vs. 'House of the Dragon' Viewership War? It's Complicated | Charts"". TheWrap. Archived from the original on September 8, 2022. Retrieved September 12, 2022.
- ^ a b Dade Hayes (September 29, 2022). ""'Lord Of The Rings' Claims Nielsen Streaming Ring, Topping 'House Of The Dragon' When Linear Is Subtracted"". Deadline Hollywood. Retrieved October 8, 2022.
- ^ Selome Hailu (September 29, 2022). ""Nielsen Streaming Top 10: 'House of the Dragon' and 'The Rings of Power' Face Off for the First Time"". Variety. Retrieved September 30, 2022.
- ^ Matt Webb Mitovich (September 29, 2022). ""The Rings of Power Is No. 1 in Debut Atop Nielsen Top 10 Streaming Chart"". TVLine. Retrieved October 15, 2022.
- ^ Viveat Susan Pinto (September 6, 2022). ""'Rings of Power': India lords over with 12% of global viewership"". Business Standard. Retrieved November 2, 2022.
- ^ a b Steven Tweedie; Travis Clark (October 27, 2022). ""Amazon has been suspiciously quiet about 'The Rings of Power' viewership in the 2 weeks since the first season concluded"". Business Insider. Retrieved October 29, 2022.
- ^ Cynthia Littleton (October 4, 2022). ""Amazon Studios Head Jennifer Salke Breaks Down the $700 Million 'Rings of Power' Gamble and Plan for MGM Integration"". Variety. Retrieved October 9, 2022.
- ^ a b Travis Clark (October 16, 2022). ""Who's watching 'House of the Dragon' and 'The Rings of Power'? New numbers shed light on the audience for both shows"". Business Insider. Retrieved October 20, 2022.
- ^ Examples of commentators comparing The Rings of Power to House of the Dragon before their release:
- Hibberd, James (August 17, 2022). ""'House of the Dragon' vs. 'Lord of the Rings': Which Epic Fantasy Show Will ""Win""?"". The Hollywood Reporter. Archived from the original on August 17, 2022. Retrieved September 10, 2022.
- """"Game of Thrones"" v ""Lord of the Rings"": a tale of old v new Hollywood"". The Economist. August 21, 2022. Archived from the original on August 21, 2022. Retrieved September 10, 2022.
- Watercutter, Angela (August 19, 2022). ""'Game of Thrones' v. 'Lord of the Rings': The Biggest Battle in Fantasy TV History Is Here"". Wired. Archived from the original on August 19, 2022. Retrieved September 10, 2022.
- Trenholm, Richard (September 3, 2022). ""'Rings of Power' vs. 'House of the Dragon' vs. 'She-Hulk' vs. 'Star Wars'"". CNET. Archived from the original on September 3, 2022. Retrieved September 10, 2022.
- Rose, Steve (July 28, 2022). ""Game of Thrones v Lord of the Rings: who will win the epic battle of the spin-offs?"". The Guardian. Archived from the original on July 28, 2022. Retrieved September 10, 2022.
- Ichimura, Anri (August 26, 2022). ""The Rings of Power vs. House of the Dragon: The Tale of Two Fantasy Epics"". Esquire. Archived from the original on September 10, 2022. Retrieved September 10, 2022.
- ^ Katz, Brandon (August 2, 2022). ""House of the Dragon or Rings of Power: Which Is More Anticipated?"". TheWrap. Archived from the original on August 2, 2022. Retrieved September 10, 2022.
- ^ Strange, Adario (August 19, 2022). ""HBO Max's ""House of the Dragon"" is already besting Amazon's ""The Rings of Power"""". Quartz. Archived from the original on August 19, 2022. Retrieved September 10, 2022.
- ^ Ferme, Antonio (August 24, 2022). ""'Rings of Power' and 'House of the Dragon' Competition Is 'Manufactured by the Media for Headlines,' Producer Says"". Variety. Archived from the original on August 24, 2022. Retrieved September 10, 2022.
- ^ Maas, Jennifer (September 3, 2022). ""'The Lord of the Rings: The Rings of Power' Premiere Draws 25 Million Global Viewers in First Day, Amazon Says"". Variety. Archived from the original on September 3, 2022. Retrieved September 3, 2022.
- ^ Selome Hailu (October 20, 2022). ""Jeffrey Dahmer Series 'Monster' Debuts on Nielsen Top 10 With 10th Biggest Streaming Week Ever"". Variety. Retrieved October 22, 2022.
- ^ a b ""The Lord of the Rings: The Rings of Power: Season 1"". Rotten Tomatoes. Fandango Media. Retrieved October 26, 2022.
- ^ ""The Lord of the Rings: The Rings of Power: Season 1"". Metacritic. Red Ventures. Retrieved September 17, 2022.
- ^ Pruner, Aaron (August 31, 2022). ""The Lord of the Rings: The Rings of Power First Reviews: 'Bold,' 'Ambitious,' 'Gorgeous,' 'Full of Grandeur,' Critics Say"". Rotten Tomatoes. Archived from the original on September 3, 2022. Retrieved August 31, 2022.
- ^ Odman, Sydney (August 31, 2022). ""'The Lord of the Rings: The Rings of Power' Reviews: What the Critics Are Saying"". The Hollywood Reporter. Retrieved September 3, 2022.
While most are hailing the project for its promising plotline and impressive cinematography, some reviews are mixed, as skepticism of such a high-price tag for the beloved franchise remain.
- ^ Kang, Inkoo (August 31, 2022). ""'The Lord of the Rings: The Rings of Power' is beautiful, banal boredom"". The Washington Post. Retrieved October 2, 2022.
{{cite news}}: CS1 maint: url-status (link)
- ^ Perry, Kevin E G (September 2, 2022). ""Lord of the Rings: The Rings of Power is a cinematic return to Middle-earth – review"". The Independent. Archived from the original on September 3, 2022. Retrieved September 2, 2022.
- ^ Franich, Darren (August 31, 2022). ""'The Lord of the Rings: The Rings of Power' is kind of a catastrophe"". Entertainment Weekly. Archived from the original on September 1, 2022. Retrieved September 2, 2022.
- ^ Power, Ed (August 31, 2022). ""Rings of Power: The new hobbits are filthy, hungry simpletons with stage-Irish accents. That's $1bn well spent"". The Irish Times. Archived from the original on August 31, 2022. Retrieved September 6, 2022.
- ^ Power, Ed (September 3, 2022). ""One franchise to rule them all: New Lord of the Rings spin-off The Rings of Power introduces a new generation to Tolkien"". The Irish Times. Archived from the original on September 6, 2022. Retrieved September 6, 2022.
- ^ Power, Ed (September 2, 2022). ""The Lord of the Rings: The Rings of Power, eps 1 & 2 recap: Uh oh! Someone wants to build a big forge"". The Daily Telegraph. Archived from the original on September 2, 2022. Retrieved September 6, 2022.
- ^ Wasser, Chris (September 5, 2022). ""The Lord of the Rings: The Rings of Power review – Irish hobbits and no orgies, this is the fantasy epic you can watch with granny"". Irish Independent. Archived from the original on September 5, 2022. Retrieved September 6, 2022.
- ^ Stanley, Colman (September 3, 2022). ""Viewers Are Calling Out The Horrific Irish Accents In New Lord Of The Rings Show"". Balls.ie. Archived from the original on September 3, 2022. Retrieved September 6, 2022.
- ^ Cannon, Eoghan (August 31, 2022). ""'The Lord of the Rings: The Rings of Power' is a trifecta of charm, magic and nostalgia"". Entertainment.ie. Archived from the original on August 31, 2022. Retrieved September 6, 2022.
- ^ Lynch, Donal (September 4, 2022). ""Lord of the Rings: Lenny Henry's in it. How bad could it be? Quite bad, in fact"". Irish Independent. Archived from the original on September 4, 2022. Retrieved September 6, 2022.
- ^ Heritage, Stuart (October 17, 2022). ""Now it's over, let's come out and say it: The Rings of Power was a stinker"". The Guardian. Retrieved October 17, 2022.
- ^ Sepinwall, Alan (October 14, 2022). ""'The Lord of the Rings: The Rings of Power' Finale: Did We Get Everything Amazon Paid For?"". Rolling Stone. Retrieved October 17, 2022.
- ^ Hibberrd, James (September 2, 2022). ""Is 'The Rings of Power' Getting Review Bombed? Amazon Suspends Ratings"". The Hollywood Reporter. Archived from the original on September 2, 2022. Retrieved September 3, 2022.
- ^ a b Dalton, Angus (September 7, 2022). ""Is the new Lord of the Rings TV show really 'too woke'?"". The Sydney Morning Herald. Archived from the original on September 7, 2022. Retrieved September 8, 2022.
- ^ Power, Tom (September 6, 2022). ""The Rings of Power's sparkling success can't save it from baffling fan backlash"". TechRadar. Archived from the original on September 6, 2022. Retrieved September 9, 2022.
- ^ White, Cindy (August 30, 2022). ""What's really behind the battle over The Rings Of Power?"". The A.V. Club. Archived from the original on August 30, 2022. Retrieved September 8, 2022.
- ^ Canal, Alexandra (September 7, 2022). ""Amazon's 'Lord of the Rings' prequel faces 'tornadoes' despite record Prime debut"". Yahoo! Finance. Archived from the original on September 7, 2022. Retrieved September 8, 2022.
- ^ a b Topping, Alexandra (September 2, 2022). ""Trouble harfoot? Amazon's Lord of the Rings epic divides Tolkien fans"". The Guardian. Archived from the original on September 2, 2022. Retrieved September 8, 2022.
- ^ Johnston, Rich (October 9, 2021). ""Sir Lenny Henry On Being A Black Hobbit In The Lord Of The Rings"". Bleeding Cool. Archived from the original on October 9, 2021. Retrieved September 7, 2022.
- ^ a b Fimi, Dimitra; Maldonado, Mariana Rios (February 25, 2022). ""Lord of the Rings: debunking the backlash against non-white actors in Amazon's new adaption"". The Conversation. Archived from the original on February 26, 2022. Retrieved August 6, 2022.
- ^ Mathai, Jeremy (February 10, 2022). ""The Lord Of The Rings: The Rings Of Power Showrunners Address Backlash To Diverse Casting"". /Film. Archived from the original on February 16, 2022. Retrieved February 16, 2022.
- ^ Frost, Caroline (August 28, 2022). ""'The Lord Of The Rings' Star Sir Lenny Henry Applauds Amazon's Move Away From Tolkien's Fair-Skinned Characters To Diverse Cast"". Deadline Hollywood. Archived from the original on August 28, 2022. Retrieved August 31, 2022.
- ^ Mellor, Louisa (February 18, 2022). ""Lord of the Rings: The Rings of Power - Why Fandom Has To Embrace Change"". Den of Geek. Archived from the original on February 21, 2022. Retrieved August 6, 2022.
- ^ Sledge, Ben (February 12, 2022). ""The Lord Of The Rings: The Rings Of Power Has People Of Colour, Get Over It"". TheGamer. Archived from the original on February 12, 2022. Retrieved August 6, 2022.
- ^ Newby, Richard (September 2, 2022). ""A Racist Backlash to 'Rings of Power' Puts Tolkien's Legacy Into Focus"". The Hollywood Reporter. Archived from the original on September 2, 2022. Retrieved September 8, 2022.
- ^ Young, Helen. ""The Rings of Power is suffering a racist backlash for casting actors of colour – but Tolkien's work has always attracted white supremacists"". The Conversation. Archived from the original on September 8, 2022. Retrieved September 8, 2022.
- ^ Sharf, Zack (September 6, 2022). ""Whoopi Goldberg Rails Against Racist 'Rings of Power' and 'House of the Dragon' Fans: 'What Is Wrong With Y'all?'"". Variety. Archived from the original on September 6, 2022. Retrieved September 8, 2022.
- ^ Chitwood, Adam (September 4, 2022). ""The Racist Backlash to Amazon's Lord of the Rings Explained"". TheWrap. Archived from the original on September 4, 2022. Retrieved September 8, 2022.
- ^ Westenfeld, Adrienne (September 1, 2022). ""Ismael Cruz Córdova Is Undeniable"". Esquire. Archived from the original on September 1, 2022. Retrieved September 8, 2022.
- ^ Sharf, Zack (September 7, 2022). ""Elijah Wood and 'Lord of the Rings' Cast Champion Diversity in Middle-earth Amid Racist 'Rings of Power' Backlash: 'You Are All Welcome Here'"". Variety. Archived from the original on September 7, 2022. Retrieved September 8, 2022.
- ^ Coggan, Devan (September 7, 2022). ""Original 'LOTR' hobbits show support for 'The Rings of Power' cast after racist attacks"". Entertainment Weekly. Archived from the original on September 7, 2022. Retrieved September 8, 2022.
- ^ ""'Rings Of Power' star unites with 'Lord Of The Rings"" Orlando Bloom"". NME. September 19, 2022.
- ^ ""LOTR's Orlando Bloom Shares Support For Rings Of Power Star Ismael Cruz Córdova Amid Hateful Backlash"". CinemaBlend. September 20, 2022.
- ^ ""Lord of the Rings' Orlando Bloom Post Photo Supporting Rings of Power's Ismael Cruz Córdova"". ComicBook.com. September 20, 2022.
- ^ Patten, Dominic; D'Alessandro, Anthony (September 3, 2022). ""'LOTR: The Rings Of Power' After Show 'Inside The Ring': Episode 1 – Setting The Stage For Amazon's Epic Series"". Deadline Hollywood. Archived from the original on September 3, 2022. Retrieved September 3, 2022.
External links
- The Lord of the Rings: The Rings of Power
- 2020s American drama television series
- 2022 American television series debuts
- Amazon Prime Video original programming
- American action adventure television series
- American fantasy drama television series
- American prequel television series
- English-language television shows
- High fantasy television series
- Serial drama television series
- Television productions suspended due to the COVID-19 pandemic
- Television series by Amazon Studios
- Television series by New Line Television
- Television shows filmed in New Zealand
- Television shows filmed in the United Kingdom",8
403,"The Creator Paradox: Cultural Stasis Amidst Creative Surplus
How reboot culture keeps winning despite the Creator Economy & Long Tail
Part I:
The Tension
There’s a new dilemma.
Only it’s not that “new” of a dilemma.
At the beginning of this summer, decades of glacier-paced cultural change was captured perfectly in a single weekend. The top of the charts revealed our endangered media ecosystem.
You’ve heard this song plenty before. Thanks to inclusion in Netflix’s fifth season of Stranger Things, Kate Bush’s 1985 song “Running Up That Hill (Make a Deal with God)” found itself back in the zeitgeist. It went from 22,000 streams per day to 5.1M. Momentarily, a 37-year-old track was the most streamed song on Spotify.
Meanwhile, Top Gun: Maverick, a sequel to the 1986 original, broke box office records, banking $156 million the same weekend. This was right before Jurassic World stomped in — the seventh installment since 1993. Then came Minions 2 — a sequel and a spin off to the Despicable Me franchise, which in itself already had three installments.
Further, in video games that weekend, 9 out of 10 best selling titles were from franchises. And the New York Times Best Sellers list saw James Paterson, the Guinness World Records holder for the most #1 New York Times bestsellers, taking up two of the top five spots in fiction.
It was the summer weekend for big premieres. But in fact, nothing about these releases were particularly that new.
Most noteworthy though, this pattern of mega-successful reboots stood against a backdrop of another story...
These titles were released at a moment when more people are creating more content than ever before in history.
Spotify boasts 70,000 tracks uploaded every day. YouTube is uploading 30,000 hours of new content every hour. Nearly 3M unique podcasts exist. Twitch is broadcasting +7.5M streamers, indie game releases and play are both growing year over year, and roughly 4M books are published annually in the U.S. — nearly half of those self-published, a +250% increase over just five years.
On one hand, we have a booming Creator Economy, with an ever-expanding democratization of tools for production to anyone with an idea. So much so, that according to 1,000 surveyed Americans by Zine, 86% of people believe there is an overwhelming amount of entertainment available today.
Yet meanwhile on the other hand, we seem to have also found ourselves culturally stunted. Our box office and streaming platforms are soggy with the same regurgitated franchises. Reboots rule the roost, and familiar faces hog our charts, while notable newcomers redefining genres feel few and far between. With this, 64% of people declare they are getting fed up with today’s reboots, sequels and remakes.
What gives?
How is it that during a moment of radical creator liberation and audience frustration, we’re finding ourselves with the same tropes and hooks?
Chris Anderson’s 2006 optimistic Long Tail vision promised us that “specificity” — the shallow and obscure — would be economically feasible as the internet would connect the niche to its audience. Aggregators will win, the odd would thrive, and those on the edges would celebrate. Creators could finally connect to their 1,000 true fans.
But as seen from the macro view, a diverse, bottom-up media ecosystem is in fact not thriving.
Instead, the inverse is happening.
Homogeneity is winning.
Part II:
Sameness Everywhere
In an analysis by Adam Mastroianni, a postdoc scholar at Columbia Business School, “the same” keeps rising to the top — across all media.
Simply, there are fewer winners.
Mastroianni calls this our Cultural Oligopoly. “A cartel of superstars has conquered culture,” he writes.
“Until the year 2000, about 25% of top-grossing movies were prequels, sequels, spinoffs, remakes, reboots, or cinematic universe expansions. Since 2010, it’s been over 50% every year. In recent years, it’s been close to 100%.”
“Since 2000, about a third of the top 30 most-viewed shows are either spin offs of other shows in the top 30 (e.g., CSI and CSI: Miami) or multiple broadcasts of the same show (e.g., American Idol on Monday and American Idol on Wednesday).”
“In the 1950s, a little over half of the authors in the Top 10 had been there before. These days, it’s closer to 75%.”
“In the late 1990s, 75% or less of best selling video games were franchise installments. Since 2005, it’s been above 75% every year, and sometimes it’s 100%.”
Software engineer Azhad Syed identified the same “Cultural Oligopoly” in his analysis of the music industry.
“The number of different artists that crack the Top 100 is decreasing over time. In conjunction with fewer and fewer artists on the charts, each of those artists is charting 1.5x to 2x as many songs per year.”
Meanwhile, “old” music — defined as having been released more than 18 months — now accounts for 72% of the market in the U.S. And though 18 months is admittedly a flawed definition of “old,” more widely, the consumption of old music is growing, while demand for new music is also declining.
In assessing this record for The Atlantic, music critic and historian Ted Gioia writes,
“Never before in history have new tracks attained hit status while generating so little cultural impact.”
The old is winning financially, but it’s also winning creatively. Rolling Stone Magazine forecasts the continued rise of “interpolations” — the cousin of sampling in which song structure is borrowed and made “new.”
“Don’t expect interpolations to slow down anytime soon — rather, the total opposite is likely. Publishing companies are sitting on mountains of instantly recognizable songs [...] Now that the business is focused around streaming singles, they have a chance to juice them once again.”
As a result, the hottest private equity investments as of late have been the publishing catalogs of accomplished artists. In fact, according to VP of Business and Legal Affairs at Sony Music Publishing, Dag Sandsmark,
“The world’s largest music publisher has received twice as many requests for samples and interpolations from its catalog two years in a row.”
Which translates to this: today, from film and TV, to books, video games, and music, there’s statistically less diversification rising to the top. And while it’s given that everything in culture is a remix, the intensity of today’s reliance on what’s come before seems worthy of our attention.
What’s causing this systemic malfunction?
Part III:
Causes of Creative Collapse
01.
Conflicting Ecosystems
Most obviously, we’re discussing two very distinct and seemingly competing media environments.
For creators, there’s the bottom-up, democratized access to tools, enabling massive amounts of content to be made and syndicated frictionlessly. In the Creator Economy everyone can be a player and “make it.”
On the other hand, there’s the top-down, institutional power of filtering and recommendation, held by establishments incentivized by outsized financial returns. Large, risk-averse institutions — arguably just run by in-house lawyers and accountants at this point — play it safe to “protect shareholder value.”
These divergent models are currently inconducive. It’s this fundamental dynamic that sits center stage at our paradox.
When there are two drastically different sets of environments, incentives, and breeds of “Creators” today — everyday maker vs. established institution — it’s hard to expect normies to be plucked out and be bet on by gatekeepers already in power.
02.
It’s (Mostly) Trash
Then there’s the question of quality.
While the Long Tail is certainly diverse, it’s also made up of a lot of... noise. Amateurs are amateurs, no matter how many there are.
A reason we don’t see new creators’ work rise is simply because the majority of it isn’t even worthy (or because there’s just too much to sift through).
Another angle here is the lack of funding for emerging creators, fueling pursuits. For a young, talented artist today, where are grants or opportunities for backing outside of peer crowdsourcing?
In the absence of infinite time but facing infinite content, we actually need some gatekeepers. Further, we need financing for those who aren’t... trash.
03.
Institutional Consolidation
By its very nature, the Long Tail of content is segmented into ever-smaller pieces for ever-more discerning audiences. But as the Long Tail lengthens where more create, the classic bell curve forms: the obscure gets more obscure, while the largest common denominator gets more... basic.
Look no further than Netflix’s most recent pivots, which make it clear they’re no longer interested in many, risky, artistic bets, but instead, “Bigger, better, fewer.”
Ironically, this is no different than what preceded them. Also, Netflix was once seen as the promising example for the opportunity of the Long Tail. Instead, over the last decade, Netflix has been slashing its library of titles. As of 2010, Netflix housed 6.7K films. Today, a decade later that number is down -45%.
Much of today’s mass-produced work aims to satisfy the average. As a result, we’re left with average. The middle is saltine-cinema: the largest financial opportunity.
Take or leave Martin Scorsese’s critique of Marvel, his take on the state of film — this “consolidation” — shouldn’t be controversial:
“The art of cinema is being systematically devalued, sidelined, demeaned, and reduced to its lowest common denominator, ‘content.’”
This dovetails with one of Mastroianni’s own hypotheses for today’s Cultural Oligopoly: a systemic reflex towards concentration. The big habitually eats the small. Movie studios, music labels, TV stations, and publishers of books and video games have all consolidated. And this concentration is simultaneously occurring across religion, political parties, language, top visited websites, newspapers, cities, and most discussed: wealth and businesses.
The winners we’re left with today are so large, they have to satisfy that largest possible common denominator in order to survive.
04.
Medicinal Nostalgia
More choice isn’t always a good thing.
In The Paradox of Choice, Dr. Barry Swartz writes,
“The fact that some choice is good doesn’t necessarily mean that more choice is better.”
Presented with an avalanche of opportunity, especially with entertainment — something meant to bring joy — we stick to what we know. After all, what we know feels good.
In Derek Thompson’s book, Hit Makers, he explains this tendency,
“Most consumers are simultaneously neophilic — curious to discover new things — and deeply neophobic — afraid of anything that’s too new. The best hit makers are gifted at creating moments of meaning by marrying new and old, anxiety and understanding. They are architects of familiar surprises.”
As creatures of comfort, the unknown is scary. We opt for the familiar. And this selection solves two things for us: choice analysis paralysis, and emotional turmoil. We’re relieved.
A collective longing for the past might explain this paradox’s recent acceleration. The pandemic has triggered a mass re-appreciation of the old — safe and unthreatening. We also had plenty of time to explore catalogues while production was paused.
As Dylan Viner, Managing Partner at TRIPTK, a cultural research and brand consultancy, points out,
“Hateful of the present, and fearful of the future, we long for the past.”
And this is true even when the past isn’t our own. According to Spotify’s own research, 68% of Gen Z enjoy media from prior decades because it reminds them of when times were simpler.
History is a reassuring comparison to the unpredictability of what tomorrow may bring. So what if it’s played out? At least we know the words.
05.
Influence of the Aged
As users of today’s media platforms grow older, so too will the age of the content being consumed.
According to market research by Ampere Analysis, Netflix's core subscription base is already saturated with 18-34 and 35-44 viewers — 80% and 70% respectively. Growth within these age brackets has been stagnant. Now, Americans 50+ are driving the growth of the entertainment juggernaut, which now inevitably must keep luring and satisfying these older consumers.
The growth of mature users on today’s content platforms recalibrates what’s surfaced and produced, diminishing the attention placed on the youthful, emerging or rebellious.
06.
Platform Persuasion
We, the audience, have less control over this paradox than we think. Chris Dancy, an author and speaker on living with technology, remarks,
“Technology has moved from Big Brother to Big Mother... Our quest to create the most frictionless experience is leaving people devoid of autonomy and longing for the feeling of 1st person living.”
Faced with AI-customized playlists, “We think you may like” recommendations, and “Just for you” nudges, it’s up to once agnostic platforms to determine what’s now streamed... and popular.
Algorithms were believed to untether us from the masses and offer paths for personalization, but instead what’s pushed today still emanates from the original institutional power we thought we were escaping.
The consultancy Music Tomorrow researched how playlists are impacting emerging artists and found:
“Over the last four years, major labels accounted for nearly 70% of the music featured in the ‘New Music Friday’ playlist on Spotify, 86% for ‘Rap Caviar’ and 87% for ‘Pop Rising’ playlists. Even though making and releasing music has become easier than ever, the support of a major label — and its marketing powerhouse — is one of the top determinants (if not prerequisites) for getting access to some of the most valuable streaming real estate.”
Further explaining our disillusionment with algorithmic personalization and escape from the mainstream, Rob Horning of Real Life magazine writes,
“Streaming services work strenuously to shape customers' disposition toward consuming if not specific tastes, making them more passive in their consumption, more willing to go along with what is trending and what is being surfaced on landing pages and home screens. It's no accident that searching these sites for something to watch is often an arduous and fruitless chore, inducing a learned helplessness and a pre-emptive predilection to surrender to the feed.”
“For You” is not about pushing the limits of our artistic palates, as much a device to serve us what the platform projects — and wants us to be satisfied with, herding us into more predictable siloes that can then be targeted with more “precise” recommendations. Anything other than this is a liability to the business model.
Ted Gioia also comments on this practice,
“Algorithms are designed to be feedback loops, ensuring that the promoted new songs are virtually identical to your favorite old songs. Anything that genuinely breaks the mold is excluded from consideration almost as a rule. That's actually how the current system has been designed to work.”
Algorithms’ are not designed to radically free us through superior discovery. They’re made to categorize us into more predictable buckets with predetermined labels. “New” is just a wrench in this machine.
07.
Creators ≠ Consumers
Finally, a less validated hypothesis as to why we have an unrecognized Long Tail is perhaps that we find more value in making than consuming.
With the tools of creation democratized, it’s never been easier to produce... but that doesn’t insinuate there’s a proportionate eager audience.
Many may find more value in the creation of work, than the discovery and consumption of it. And further, much of today’s “creation” is in fact informed by existing IP.
Kevin Alloca, YouTube’s Global Director of Culture & Trends, explained to me,
“So much of user generated content today is still about a franchise — reactions, reviews or remixes. While there’s never been so much creativity and content, it’s not to say it’s all entirely removed from existing IP. It's fairly common now to see more media about, or related to the original work and consumption of it, than there is of the original work itself.”
We’re duped by a mirage of new media today. In fact, we’re in a feedback loop of meta reactions. It’s a reaction video to a movie trailer which is a sequel, or a walk-through stream for the latest in a video game franchise. We have videos about a video about a video. Today, so much of bottom-up creations are nodding to legacy material. There’s less originality out there than we perceive there to be.
In a culture where creating can be more satisfying than consumption, we’re left with a glut of both unwanted content, and new content that’s actually just about existing content.
Part IV:
We’ve Got A Problem
So we’ve established the existence of this creativity paradox, along with its spread, intensity and many causes. Hands turned up, we can accept this is just how it all turned out. So be it.
But we can’t. Absolutely. Can. Not.
We’re in a corrosive media ecosystem where the top 1% of bands and solo artists earn roughly 80% of all recorded music revenue — and by some estimates, the share for established artists is only getting larger. If this trend continues, we risk sabotaging both the opportunity and incentive for new artists to even participate.
“Movies, TV, music, books, and video games should expand our consciousness, jumpstart our imaginations, and introduce us to new worlds and stories and feelings [...] Learning to like unfamiliar things is one of the noblest human pursuits; it builds our empathy for unfamiliar people.”
If we stop watering “the new,” the new will die. Substitute “new” with whichever genre or medium you prefer. It’s the (originally) foreign, weird, edgy, counter-cultural and antagonistic that drives a healthy society forward. Or for another metaphor: suffocate today’s sparks of “the new,” and we’re left in the dark.
We lose.
For Gioia, we must breathe life into the Long Tail as it “creates a more pluralistic, diverse and multifaceted society.”
The Long Tail vision hinted at making the blockbuster less pronounced... but the exact opposite occurred: the fringe is now endangered.
So what can we do?
Part V: Solutions
01.
Acknowledge New vs. New For Them
We need content from today and for today.
For Adrian Hillekamp of A&R Management with Concord,
“Every generation needs its soundtrack and that can’t come from a back catalog. It has to come from the time, the moment, and have a particular feel.”
And yet in 1986, the R&B singer Ben E. King had his second #1 chart placement with “Stand By Me,” a full 21 years after it first topped the charts. Propelled by the success of the film of the same name, King’s sudden reappearance on the chart was as unexpected and remarkable as Kate Bush’s renaissance this summer.
Compounding the similarity to today’s phenomenon: Ferris Bueller’s Day Off, famously capped by a parade-float performance of The Beatles version of soul hit “Twist & Shout,” and the same-summer soul-soundtrack of boomer nostalgia vehicle The Big Chill, which was eaten up by kids and their parents alike.
Perhaps content for today can be existing content that some just discover today. Contemporaneity isn’t a guarantee of innovation or inspiration. The current spike in interpolation isn’t novel. In fact, it might actually be cyclical. But that doesn’t mean it’s any less new to eyes and ears experiencing it for the first time.
But this is not from today. We need that too.
One simple way to break out of our cycle of reboots is to distinguish between what’s net-new vs. what’s new for a new audience. Multigenerational third-acts of media aren't all that bad... but for as long as there's also content produced from today.
02.
(Re-)Build for Search & Exploration
An underlying problem in 2022 is not a lack of great talent — it’s just that we can’t easily find it.
The discovery, curation, distribution and amplification of quality content desperately needs a reassessment. In 1986 it wasn’t possible to discover everything. Today we have the technology to move far beyond traditional, monocultural points of discovery. But we seem to have stopped leveraging it — hypnotized by convenience, preferring to receive rather than search.
An easy dismissal here is that the market will do its work — award the deserving — the good will inevitably rise to the top. But that’s simply not the case.
The Long Tail is failing to identify, and connect the fringe to its eager audience. Ask yourself: when was the last time you found a new artist that you became an instant fan of? Was it an easy journey? Can you find your new favorite emerging author this afternoon — effortlessly?
We can push our systems further. A manual override is required, this time hand on the upstarts’ side of the scale, ensuring increased reach. This is not to make all artists “mainstream,” but to connect more potential fans to their next favorite creator.
In our research, 64% of people trust a streaming platform's recommendations to surface content which they’d enjoy. But, 3-in-4 people believe streaming platforms can still do a better job at surfacing unpopular entertainment which they may enjoy. The kicker: 62% want streaming platforms to recommend more unpopular content... even at the risk they may not like it.
We’ve solved the barrier to entry, but we still haven’t cracked the barrier to discovery.
Historically, one could effectively work their way up the Long Tail with ad spend, but today, so much congestion makes this tactic futile.
Thomas Klaffke, Head of Research at TrendWatching, connects our paradox to Kasey Klimes’ thoughts on the opportunity to Design for Emergence (or really just ""Design for Exploration.”)
“In design for emergence, the designer assumes that the end-user holds relevant knowledge and gives them extensive control over the design. Rather than designing the end result, we design the user’s experience of designing their own end result.”
Rather than surfacing the same to all, platforms should trust their users to chart their own discovery paths — and not exclusively by disembodied, algorithmic means.
For today’s creators, we need to redesign the on-ramps for potential audiences. And for consumers, we need to ask: what does falling down the rabbit hole of exploration feel like when it's actually enjoyable and not against our own will?
03.
Rewrite the Rules for Top-Down Risk
Anita Elberse, a professor at Harvard Business School and author of Blockbusters — an analysis on this very phenomenon, simplifies our predicament,
“Of course I understand concerns about the diversity of content, and the fact that certain elements people like are disappearing. But overall I'm not that pessimistic. It's not a hobby, it's a business.”
Again the truism: “the market will do its work.” But what Elberse and others at the top fail to remember is that risk and diversity can drive business. And further, we’re in control of these business decisions. We set our own rules here. “It’s a business” is the opportunity, not the excuse.
We found that across all age demographics, 81% of people say they want entertainment to better reflect unique experiences and tastes similar to their own, while 76% want TV, film and music producers to take more creative risks in what’s produced today.
Risky is safe.
We can reward creative risk-taking at an executive level. We can incentivize creative moonshots, and financially or emotionally support the underdogs. We can satiate unknown or unstated appetites by creating crowdsourced competitions or allocate funding for student works. We can iterate upon models to make the Long Tail even more financially appetizing.
Some of the most beautiful works this year — Turning Red, Everything Everywhere All At Once and Marcel the Shell — are template and trope-defying pitches. They’re pure outliers. But their creative (and financial) success is in part due to the fact there are no comparisons to them. Creative differentiation, in itself, is a winning strategy. A24 for one has zagged, refreshingly embracing the financial upsides of originality and friction.
Back to Scorsese. As he explains,
“[Today’s films] lack something essential to cinema: the unifying vision of an individual artist. Because, of course, the individual artist is the riskiest factor of all. [Historically], the tension between the artists and the people who ran the business was constant and intense, but it was a productive tension that gave us some of the greatest films ever made. Today, that tension is gone, and there are some in the business with absolute indifference to the very question of art and an attitude toward the history of cinema that is both dismissive and proprietary — a lethal combination.”
What plagues the music industry is no different. Today, some artists and insiders fear even listening to unsolicited demos, which could make them vulnerable to future lawsuits. Example: If and when a hit of theirs coincidently sounds similar to something they’ve heard previously — like the landmark Robin Thicke, Pharrell, Marvin Gaye “Blurred Lines” case.
We find ourselves in a moment where some are beginning to shy away from creativity.
Nick Littlemore of Australian trio Pnau agrees:
“[Today, culturally] we’re afraid of new ideas. They’re not road tested. So we’d rather do something that maybe has a little bit more of a guarantee of being successful.”
What does tip-toeing around “the new” do to a generation? Nothing good, at a macro level.
Creativity must be seen as a freedom, not feared.
04.
Reframe Success & Reevaluate the Charts
We need to shout from the rooftops that it’s okay to be a creator without a billion views. Mr. Beast and Dobrik-fame is singular — not remotely available to all.
Deciding to write a newsletter for 100 people is not just okay, but an incredible feat. Conversely, optimizing for attention to mimic and (un-)intentionally contrast ourselves to institutional celebrities at “the top” helps no one.
We must reevaluate reach, views and ad-revenue as our go-to metrics of success, and instead aim towards the worth of depth. Call it the invaluable intensity of love. After all, we only care about what we can measure. And passion is a murky metric.
Why again do we still have award shows? Research reveals, barely half of people believe top music charts and box office numbers accurately reflect the quality of today's entertainment. Surprisingly, it’s younger generations who are more likely than anyone else to trust these charts. Why? These audiences are dangerously more impressionable...
According to Sari Azout and Jad Esber,
“For the creator middle class to rise, we need to see higher resolutions of taste preference and a breakup with singular, discriminatory platform algorithms and the opinion of the ‘few’ that arbitrate taste and force today’s dominant aesthetic. With that, individuals can decide on ‘what’s best’ for themselves, allowing for the talent power law to play out across more taste vectors and spreading the opportunity to be perceived as ‘the best’ — and, with that, spreading the opportunity to profit from that.”
We face a massive opportunity to rewrite not just the rules to incentivize risk, but to also redefine what a “successful creator” looks like.
Culturally, we’re stuck on traditional metrics (more money or more eyeballs), and stuck on a traditional lineage through traditional milestones of success. Even for new creators today, legacy occasions like Late Night interviews, brand endorsements, commercials, SNL performances, award show trophies, and even YouTube Play Buttons are still seen as the aspirational markers of success. Why?
We’re mistakenly still using dusty indicators of success in a contemporary media environment.
Where are the awards celebrating the small and mighty? Who are the megaphones to draw more attention and financing toward marginalized creators? Where is the campaign reminding us that creativity dies in the shadows of reboots, and that merely making something is a celebration in itself?
As Mastroianni shared with me,
“It’s a naive and optimistic thought to think that the Long Tail is meant to fairly compete with Tom Cruise and that he should be dethroned on the same chart by a TikTok. In reality, he loses quite often, however it’s just not clearly documented [...] Perhaps this is a story about a continued and questionable value of ‘the charts.’ They don’t reveal the whole picture of what’s happening in culture.”
We need new charts, new records, and new metrics to compare ourselves to, and more importantly, more healthily reach towards.
05.
Seek the Odd with Bottom-Up Risk
We’re not off the hook here. We entertainment consumers must also be held responsible.
For “consumer risk,” this means being open to a little bit more experimentation. Mix things up. Diversify your media diet. Foreign subtitled B&W documentaries are not required, but repeating familiar patterns or acquiescing to the algorithm should be exercised out of our habits.
We can’t expect diversification if we first don’t at least taste it, signaling a desire for it. Scorsese's qualms with Hollywood today are rooted in this dilemma.
“If people are given only one kind of thing and endlessly sold only one kind of thing, of course they’re going to want more of that one kind of thing.”
To break out of this system, it’s up to us to express interest in anything other than Fast & The Furious 30. We can have that... but also more.
It falls on the audience as well to zag, making demand for the unique unquestionably clear.
Part VI:
The Cliffhanger
When reproduction is rewarded, monotony becomes omnipresent.
When creativity — or lack thereof — is primarily driven by financial returns, risks are minimized. Audiences are left malnourished.
And when the fringe doesn’t reach its audience, it dies without attention. Newcomers question the system, and bow out before even trying.
Relevancy and reach are at tension. We must find ways to strike equilibrium. And if we don’t, our future literally becomes our past.
We face a daunting opportunity to better support the niche, and introduce the new to its awaiting fans.
Mind you, this is not a declaration to kill off the Minions, but a recognition that we have equally enjoyable — and richer — content waiting for us, just without direct lines of access. Thankfully, this is not an all or nothing scenario.
We can have Tom Cruise mega-hits and freaky, indie artists both thriving concurrently. And moreover, superhero installments with provocateurs exploring underrepresented communities or toppling taboos in more nuanced ways.
We have choice. Choice in what we consume. And choice in whether we author new rules to get there.
For as long as we remain mindful that there’s more out there to enjoy...
So let's choose for ourselves. And celebrate others who do so for themselves.
Thanks to Ben Dietz, Josh Chapdelaine, Jad Esber, Adam Mastroianni, Ted Gioia, Kevin Alloca, Sarah Unger, Dr. Marcus Collins, Dylan Viner and Chris Dancy for their ideas in both expanding and distilling this analysis. Thank you.",1
404,"www.researchgate.net
Checking if the site connection is secure
Enable JavaScript and cookies to continue
www.researchgate.net needs to review the security of your connection before proceeding.
Ray ID:
756db3401b2399b7
Performance & security by
Cloudflare",7
405,"Since the 1960s, over 8.3 billion tons of plastic have been produced. 40% of this production has been for packaging that is used once and discarded. Landfills receive about 27 million tons of plastic every year in the United States alone. To solve the growing problem of plastic pollution researchers have begun to look for methods by which plastic can be decomposed. This led to the discovery of plastic eating mushrooms.
In 2011, researchers at Yale University tested the ability of several dozen fungi to digest the synthetic polymer polyester polyurethane (PUR), a type of plastic. They found that several members of the Pestalotiopsis genus of fungi were capable of degrading PUR and converting it into organic matter in both solid and liquid suspensions. Two members of this genus were able to survive solely off PUR in anaerobic, or oxygen-free, and aerobic, or oxygenated, environments.
Modern landfills are dry and oxygen poor. This makes it impossible for anything to decompose properly, including organic material. However, Pestalotiopsis fungi are capable of plastic decomposition in anaerobic conditions, making them an ideal candidate for use in landfills. The ability of Pestalotiopsis to survive and decompose PUR in liquid and soil suspensions also indicates that they will be able to be used for removing plastic from the ocean, especially from the Great Pacific Garbage Patch.
The discovery of Pestalotiopsis’ ability to decompose plastic led to further research into plastic decomposition by fungi. Researchers have now found that many species are capable of plastic bioremediation including the common, edible Oyster mushroom. The Oyster mushroom is capable of decomposing plastic while still creating an edible mushroom. This opens up doors for its use as an at-home recycling system. Austrian researcher Katharina Unger created a prototype of an at-home Oyster mushroom recycling system called the “Fungi Mutarium.” In the “Fungi Mutarium” pieces of plastic would be placed in capsules containing the Oyster mushroom. The fungi would then grow on the capsule where it could be harvested for consumption.
The most important action you can take to combat the plastic problem is reducing plastic consumption. However, plastic-eating mushrooms provide an organic solution to removing the plastic that is already polluting our environment.",2
406,"Italy's right-wing government to criminalise raves
- Published
The new government of far-right PM Giorgia Meloni has said it will make staging unlicensed raves a crime, hours after stopping one in northern Italy.
The new crime of ""invasion for dangerous gatherings"" of more than 50 people would attract up to six years in jail and opens up the possibility of wiretapping rave organisers.
A thousand ravers were ordered to leave a warehouse rave in Modena on Monday.
""The party's over!"" declared far-right minister Matteo Salvini.
Residents had complained of 48 hours of non-stop techno music at the Halloween party that attracted young ravers via social media from nearby Italian cities as well as Belgium and France.
The ravers had planned to stay until Tuesday but left the disused warehouse in northern Modena without trouble and witnesses said they tidied up behind them.
Prime Minister Meloni argued the new law aimed to protect people from harm and was no different from elsewhere in Europe - but it would signal that the Italian state was no longer lax in respecting the rules.
The previous national unity government had already begun work on changing the law after a mass rave in 2021 in the central town of Viterbo ended with the deaths of two people. But the new right-wing administration's draft degree goes further, including big fines and confiscation of sound systems.
Critics asked why the government had targeted young ravers but had ignored a fascist march at the weekend by 2,000 black-clad supporters of Italy's wartime dictator, Benito Mussolini.
The weekend rally took place in Predappio, where Mussolini was born and buried. It featured fascist salutes and hymns, marked Mussolini's march on Rome and the start of fascist rule 100 years ago.
Interior Minister Matteo Piantedosi argued that the two events were ""completely different things"" as the Mussolini march had not disrupted public order and had been happening for years, whereas the warehouse owner had reported the rave in Modena.
Ms Meloni, who has sought to distance herself from the post-fascist politics of her youth, said on Monday that the Mussolini march was ""politically something distant from me in a very significant way"".
But her past came under further scrutiny when she appointed a new deputy minister who had provoked uproar several years ago when a picture emerged of him wearing a Nazi swastika on his right arm. Galeazzo Bignami, who is part of her Brothers of Italy movement, said on Monday he felt ""profound shame"" over the pictures taken in 2005.
In a separate move, Ms Meloni's new cabinet agreed to end a requirement for doctors and nurses to be vaccinated against Covid-19, saying anyone suspended because of their objections to the jab could return to work. The decision means some 4,000 health workers will be able to return to work two months early, as the suspension was due to end at the end of the year.
Opponents accused her of rewarding anti-vaxxers but the prime minister said the previous government had taken an ""ideological"" stance.",2
407,"In this MOOC, you will learn how to better anticipate the future, and reinvent yourself and your activity accordingly.
By the end of the course, you’ll be able to account for the broader context and the possible convergence of long-term trends, and thus be able to develop a long-term, consistent strategy and vision, beyond mere day-to-day tactics. Thanks to this approach and mindset, you will become more agile and more resilient in a highly complex and uncertain landscape. In this class, you will not only learn the academic and theoretical aspects of strategic foresight, uncertainty and planning. We will also discuss very practical examples, ranging from a discussion on choosing the best outfit for a walk in the countryside to building a vision and strategy for a corporation as a CEO. In practical assessments, you will apply this broad approach to sample examples as well as to your personal and professional challenges. So if you are an entrepreneur, this course will help you identify the new ideas, the new business model and/or the new products that will help you remain relevant in the future. If you are a manager or an executive, by taking this course, you will be able to test whether your current approach and allocation of resources are appropriate given tomorrow's possible challenges. More generally, all kinds of decision-makers who look to think more strategically about their position and seek to improve it will find this course useful to think about the future constructively.",2
408,"Will AI Steal Submarines’ Stealth?
Better detection will make the oceans transparent—and perhaps doom mutually assured destruction
Submarines are valued primarily for their ability to hide. The assurance that submarines would likely survive the first missile strike in a nuclear war and thus be able to respond by launching missiles in a second strike is key to the strategy of deterrence known as mutually assured destruction. Any new technology that might render the oceans effectively transparent, making it trivial to spot lurking submarines, could thus undermine the peace of the world. For nearly a century, naval engineers have striven to develop ever-faster, ever-quieter submarines. But they have worked just as hard at advancing a wide array of radar, sonar, and other technologies designed to detect, target, and eliminate enemy submarines.
The balance seemed to turn with the emergence of nuclear-powered submarines in the early 1960s. In a 2015 study for the Center for Strategic and Budgetary Assessment, Bryan Clark, a naval specialist now at the Hudson Institute, noted that the ability of these boats to remain submerged for long periods of time made them “nearly impossible to find with radar and active sonar.” But even these stealthy submarines produce subtle, very-low-frequency noises that can be picked up from far away by networks of acoustic hydrophone arrays mounted to the seafloor.
And now the game of submarine hide-and-seek may be approaching the point at which submarines can no longer elude detection and simply disappear. It may come as early as 2050, according to a recent study by the National Security College of the Australian National University, in Canberra. This timing is particularly significant because the enormous costs required to design and build a submarine are meant to be spread out over at least 60 years. A submarine that goes into service today should still be in service in 2082. Nuclear-powered submarines, such as the Virginia-class fast-attack submarine, each cost roughly US $2.8 billion, according to the U.S. Congressional Budget Office. And that’s just the purchase price; the total life cycle cost for the new Columbia-class ballistic-missile submarine is estimated to exceed $395 billion.
The twin problems of detecting submarines of rival countries and protecting one’s own submarines from detection are enormous, and the technical details are closely guarded secrets. Many naval experts are speculating about sensing technologies that could be used in concert with modern AI methodologies to neutralize a submarine’s stealth. Rose Gottemoeller, former deputy secretary general of NATO, warns that “the stealth of submarines will be difficult to sustain, as sensing of all kinds, in multiple spectra, in and out of the water becomes more ubiquitous.” And the ongoing contest between stealth and detection is becoming increasingly volatile as these new technologies threaten to overturn the balance.
We have new ways to find submarines
Today’s sensing technologies for detecting submarines are moving beyond merely hearing submarines to pinpointing their position through a variety of non-acoustic techniques. Submarines can now be detected by the tiny amounts of radiation and chemicals they emit, by slight disturbances in the Earth’s magnetic fields, and by reflected light from laser or LED pulses. All these methods seek to detect anomalies in the natural environment, as represented in sophisticated models of baseline conditions that have been developed within the last decade, thanks in part to Moore’s Law advances in computing power.
Airborne laser-based sensors can detect submarines lurking near the surface.IEEE Spectrum
According to experts at the Center for Strategic and International Studies, in Washington, D.C., two methods offer particular promise. Lidar sensors transmit laser pulses through the water to produce highly accurate 3D scans of objects. Magnetic anomaly detection (MAD) instruments monitor the Earth’s magnetic fields and can detect subtle disturbances caused by the metal hull of a submerged submarine.
Both sensors have drawbacks. MAD works only at low altitudes or underwater. It is often not sensitive enough to pick out the disturbances caused by submarines from among the many other subtle shifts in electromagnetic fields under the ocean.
Lidar has better range and resolution and can be installed on satellites, but it consumes a lot of power—a standard automotive unit with a range of several hundred meters can burn 25 watts. Lidar is also prohibitively expensive, especially when operated in space. In 2018, NASA launched a satellite with laser imaging technology to monitor changes in Earth’s surface—notably changes in the patterns on the ocean’s surface; the satellite cost more than $1 billion.
Indeed, where you place the sensors is crucial. Underwater sensor arrays won’t put an end to submarine stealth by themselves. Retired Rear Adm. John Gower, former submarine commander for the Royal Navy of the United Kingdom, notes that sensors “need to be placed somewhere free from being trolled or fished, free from seismic activity, and close to locations from which they can be monitored and to which they can transmit collected data. That severely limits the options available.”
One way to get around the need for precise placement is to make the sensors mobile. Underwater drone swarms can do just that, which is why some experts have proposed them as the ultimate antisubmarine capability.
Clark, for instance, notes that such drones now have enhanced computing power and batteries that can last for two weeks between charges. The U.S. Navy is working on a drone that could run for 90 days. Drones are also now equipped with the chemical, optical, and geomagnetic sensors mentioned earlier. Networked underwater drones, perhaps working in conjunction with airborne drones, may be useful for not only detecting submarines but also destroying them, which is why several militaries are investing heavily in them.
A U.S. Navy P-8 Poseidon aircraft, equipped to detect submarines, awaits refueling in Okinawa, Japan, in 2020. U.S.Navy
For example, the Chinese Navy has invested in a fishlike undersea drone known as Robo-Shark, which was designed specifically for hunting submarines. Meanwhile, the U.S. Navy is developing the Low-Cost Unmanned Aerial Vehicle Swarming Technology, for conducting surveillance missions. Each Locust drone weighs about 6 kilograms, costs $15,000, and can be outfitted with MAD sensors; it can skim low over the ocean’s surface to detect signals under the water. Militaries study the drone option because it might work. Then again, it very well might not.
Robo-Shark, a 2.2-meter-long submersible made by Boya Gongdao Robot Technology, of Beijing, is said to be capable of underwater surveillance and unspecified antisubmarine operations. The company says that the robot moves at up to 5 meters per second (10 knots) by using a three-joint structure to wave the caudal fin, making less noise than a standard propeller would. robosea.org
Gower considers underwater drones to be “the least likely innovation to make a difference in the decline of submarine stealth.” A navy would need a lot of drones, data rates are exceedingly slow, and a drone’s transmission range is short. Drones are also noisy and extremely easy to detect. “Not to mention that controlling thousands of underwater drones far exceeds current technological capabilities,” he adds.
Gower says it could be possible “to use drones and sonar networks together in choke points to detect submarine patrols.” Among the strategically important submarine patrol choke points are the exit routes on either side of Ireland, for U.K. submarines; those around the islands of Hainan and Taiwan, for Chinese submarines; in the Barents or Kuril Island chain, for Russian submarines; and the Straits of Juan de Fuca, for U.S. Pacific submarines. On the other hand, he notes, “They could be monitored and removed since they would be close to sovereign territories. As such, the challenges would likely outweigh the gains.”
Gower believes a more powerful means of submarine detection lies in the “persistent coverage of the Earth’s surface by commercial satellites,” which he says “represents the most substantial shift in our detection capabilities compared to the past.” More than 2,800 of these satellites are already in orbit. Governments once dominated space because the cost of building and launching satellites was so great. These days, much cheaper satellite technology is available, and private companies are launching constellations of tens to thousands of satellites that can work together to image every bit of the Earth’s surface. They are outfitted with a wide range of sensing technologies, including synthetic aperture radar (SAR), which scans a scene down below while moving over a great distance, providing results like those you’d get from an extremely long antenna. Since these satellite constellations view the same locations multiple times per day, they can capture small changes in activity.
Experts have known for decades about the possibility of detecting submarines with SAR based on the wake patterns they form as they move through the ocean. To detect such patterns, known as Bernoulli humps and Kelvin wakes, the U.S. Navy has invested in the AN/APS-154 Advanced Airborne Sensor, developed by Raytheon. The aircraft-mounted radar is designed to operate at low altitudes and appears to be equipped with high-resolution SAR and lidar sensors.
Commercial satellites equipped with SAR and other imaging instruments are now reaching resolutions that can compete with those of government satellites and offer access to customers at extremely affordable rates. In other words, there’s lots of relevant, unclassified data available for tracking submarines, and the volume is growing exponentially.
One day this trend will matter. But not just yet.
Jeffrey Lewis, director of the East Asia Nonproliferation Program at the James Martin Center for Nonproliferation Studies, regularly uses satellite imagery in his work to track nuclear developments. But tracking submarines is a different matter. “Even though this is a commercially available technology, we still don’t see submarines in real time today,” Lewis says.
The day when commercial satellite imagery reduces the stealth of submarines may well come, says Gower, but “we’re not there yet. Even if you locate a submarine in real time, 10 minutes later, it’s very hard to find again.”
Artificial intelligence coordinates other sub-detecting tech
Though these new sensing methods have the potential to make submarines more visible, no one of them can do the job on its own. What might make them work together is the master technology of our time: artificial intelligence.
“When we see today’s potential of ubiquitous sensing capabilities combined with the power of big-data analysis,” Gottemoeller says, “it’s only natural to ask the question: Is it now finally possible?” She began her career in the 1970s, when the U.S. Navy was already worried about Soviet submarine-detection technology.
Submarines can now be detected by the tiny amounts of radiation and chemicals they emit, by slight disturbances in the Earth’s magnetic fields, and by reflected light from laser or LED pulses.
Unlike traditional software, which must be programmed in advance, the machine-learning strategy used here, called deep learning, can find patterns in data without outside help. Just this past year, DeepMind’s AlphaFold program achieved a breakthrough in predicting how amino acids fold into proteins, making it possible for scientists to identify the structure of 98.5 percent of human proteins. Earlier work in games, notably Go and chess, showed that deep learning could outdo the best of the old software techniques, even when running on hardware that was no faster.
For AI to work in submarine detection, several technical challenges must be overcome. The first challenge is to train the algorithm, which involves acquiring massive volumes and varieties of sensor data from persistent satellite coverage of the ocean’s surface as well as regular underwater collection in strategic locations. Using such data, the AI can establish a detailed model of baseline conditions, then feed new data into the model to find subtle anomalies. Such automated sleuthing is what’s likeliest to detect the presence of a submarine anywhere in the ocean and predict locations based on past transit patterns.
The second challenge is collecting, transmitting, and processing the masses of data in real time. That task would require a lot more computing power than we now have, both in fixed and on mobile collection platforms. But even today’s technology can start to put the various pieces of the technical puzzle together.
Nuclear deterrence depends on the ability of submarines to hide
For some years to come, the vastness of the ocean will continue to protect the stealth of submarines. But the very prospect of greater ocean transparency has implications for global security. Concealed submarines bearing ballistic missiles provide the threat of retaliation against a first nuclear strike. What if that changes?
“We take for granted the degree to which we rely upon having a significant portion of our forces exist in an essentially invulnerable position,” Lewis says. Even if new developments did not reduce submarine stealth by much, the mere perception of such a reduction could undermine strategic stability.
A Northrop Grumman MQ-8C, an uncrewed helicopter, has recently been deployed by the U.S. Navy in the Indo-Pacific area for use in surveillance. In the future, it will also be used for antisubmarine operations. Northrop Grumman
Gottemoeller warns that “any perception that nuclear-armed submarines have become more targetable will lead to questions about the survivability of second-strike forces. Consequently, countries are going to do everything they can to counter any such vulnerability.”
Experts disagree on the irreversibility of ocean transparency. Because any technological breakthroughs will not be implemented overnight, “nations should have ample time to develop countermeasures [that] cancel out any improved detection capabilities,” says Matt Korda, senior research associate at the Federation of American Scientists, in Washington, D.C. However, Roger Bradbury and eight colleagues at the National Security College of the Australian National University disagree, claiming that any technical ability to counter detection technologies will start to decline by 2050.
Korda also points out that ocean transparency, to the extent that it occurs, “will not affect countries equally. And that raises some interesting questions.” For example, U.S. nuclear-powered submarines are “the quietest on the planet. They are virtually undetectable. Even if submarines become more visible in general, this may have zero meaningful effect on U.S. submarines’ survivability.”
Sylvia Mishra, a new-tech nuclear officer at the European Leadership Network, a London-based think tank, says she is “more concerned about the overall problem of ambiguity under the sea.” Until recently, she says, movement under the oceans was the purview of governments. Now, though, there’s a growing industry presence under the sea. For example, companies are laying many underwater fiber-optic communication cables, Mishra says, “which may lead to greater congestion of underwater inspection vehicles, and the possibility for confusion.”
A Snakehead, a large underwater drone designed to be launched and recovered by U.S. Navy nuclear-powered submarines, is shown at its christening ceremony in Narragansett Bay in Newport, R.I.U.S. Navy
Confusion might come from the fact that drones, unlike surface ships, do not bear a country flag, and therefore their ownership may be unclear. This uncertainty, coupled with the possibility that the drones could also carry lethal payloads, increases the risk that a naval force might view an innocuous commercial drone as hostile. “Any actions that hold the strategic assets of adversaries at risk may produce new touch points for conflict and exacerbate the risk of war,” says Mishra.
Given the strategic importance of submarine stealth, Gower asks, “Why would any country want to detect and track submarines? It’s only something you’d do if you want to make a nuclear-armed power nervous.” Even in the Cold War, when the United States and the U.K. routinely tracked Soviet ballistic-missile submarines, they did so only because they knew their activities would go undetected—that is, without risking escalation. Gower postulates that this was dangerously arrogant: “To actively track second-strike nuclear forces is about as escalatory as you might imagine.”
“All nuclear-armed states place a great value on their second-strike forces,” Gottemoeller says. If greater ocean transparency produces new risks to their survivability, real or perceived, she says, countries may respond in two ways: build up their nuclear forces further and take new measures to protect and defend them, producing a new arms race; or else keep the number of nuclear weapons limited and find other ways to bolster their viability.
Ultimately, such considerations have not dampened the enthusiasm of certain governments for acquiring submarines. In September 2021 the Australian government announced an enhanced trilateral partnership with the United States and the United Kingdom. The new deal, known as AUKUS, will provide Australia with up to eight nuclear-powered submarines with the most coveted propulsion technology in the world. However, it could be at least 20 years before the Royal Australian Navy can deploy the first of its new subs.
The Boeing Orca, the largest underwater drone in the U.S. Navy’s inventory, was christened in April, in Huntington Beach, Calif. The craft is designed, among other things, for use in antisubmarine warfare. The Boeing Company
As part of its plans for nuclear modernization, the United States has started replacing its entire fleet of 14 Ohio-class ballistic-missile submarines with new Columbia-class boats. The replacement program is projected to cost more than $128 billion for acquisition and $267 billion over their full life cycles. U.S. government officials and experts justify the steep cost of these submarines with their critical role in bolstering nuclear deterrence through their perceived invulnerability.
To protect the stealth of submarines, Mishra says, “There is a need for creative thinking. One possibility is exploring a code of conduct for the employment of emerging technologies for surveillance missions.”
There are precedents for such cooperation. During the Cold War, the United States and the Soviet Union set up a secure communications system—a hotline—to help prevent a misunderstanding from snowballing into a disaster. The two countries also developed a body of rules and procedures, such as never to launch a missile along a potentially threatening trajectory. Nuclear powers could agree to exercise similar restraint in the detection of submarines. The stealthy submarine isn’t gone; it still has years of life left. That gives us ample time to find new ways to keep the peace.
- World's Largest Swarm of Miniature Robot Submarines - IEEE ... ›
- Submarines - IEEE Spectrum ›
- Scientists Explore Underwater Quantum Links for Submarines ... ›
- DARPA's Self-Driving Submarine Hunter Steers Like a Human ... ›",2
409,"“Better to be a dog in times of tranquility than a human in times of chaos,” says an old Chinese proverb. Ha, the lure of immutability! We do, indeed, instinctively dread chaos as a threat to our stability; we fear the unpredictable risk and uncomfortable change it brings about, and we try hard to maintain a fragile equilibrium in our lives.
But nature shows us that life itself depends on chaos. And, because we’re human and able to override some of our instinctive behaviors, we can learn to embrace chaotic times, going from paralyzing anxiety to thriving curiosity.
The edge of chaos
Many people consider chaos as what we cannot control. Scientists define it in a different way: to them, chaos is what is so sensitive to initial conditions that it makes it very difficult to understand its underlying patterns and interconnections. The dynamics of chaos are so complex, they appear to be random and unpredictable.
In their book Surfing the Edge of Chaos, Richard Pascale, Mark Milleman, and Linda Gioja explain that there are four cornerstone principles to chaos in nature that we can also observe in chaotic times in our lives and at work:
- Equilibrium is a precursor to death. “When a living system is in a state of equilibrium, it is less responsive to changes occurring around it,” they write. This state of equilibrium is highly dangerous, putting the system at risk of not adapting quickly enough.
- Innovation usually takes place on the edge of chaos. It’s when they face a threat or are excited by a new opportunity that living systems tend to come up with new ways of living through experimentation and mutation.
- Self-organization emerges naturally. As long as a system is sufficiently populated and properly interconnected, a new self-organization will emerge from chaos.
- Living systems cannot be directed towards a linear path. In dynamical systems, an attractor is defined as a set of states toward which a system tends to evolve. The direction is discovered rather than dictated by the living living system.
These principles are crucial to keep in mind when surfing the edge of chaos.
Norman Packard, a chaos theory physicist from the Santa Fe Institute, coined the expression “edge of chaos” to describe a transition space between order and disorder that’s fertile for adaptation and innovation.
Why the edge of chaos, and not the middle of chaos? “As long as one operates in the middle of things, one can never really know the nature in which one moves,” wrote philosopher William Irwin Thompson. Only by exploring the edge of chaos can we truly learn and grow.
The edge of chaos is a place for liminal creativity. It allows us to redefine the frontiers of our knowledge, to dance with disruption, and to reinvent ourselves. Instead of futilely resisting change by trying to stay stationary, this liminal space is an opportunity to respond to the threat of disequilibrium by constantly experimenting, learning, and adapting our ways of thinking.
What’s more, the living systems that successfully change their inner properties to better fit the edge of chaos not only survive — they thrive.
How to thrive in chaos
Living systems tend to initially respond to chaos by attempting to restore stability. However, problems arise when we try to apply a traditional solution to an adaptive problem. When new rules are emerging and the path forward is uncertain, we need to discover our goals instead of dictating them. In that spirit, here are four strategies you can experiment with to practice chaos surfing:
1. Make a pact. Trying to force a specific outcome in chaotic times is like trying to herd butterflies. However, just like chaos theory has its attractors orienting a system in a particular direction, you can orient yourself by defining a pact with yourself.
Make a commitment to dedicate a certain amount of time or a certain number of repetitions towards a project you care about. Similar to a compass, a pact encourages you to show up and surf the chaos, letting a new self-organization emerge over time. It needs to be purposeful, actionable, contextual, and trackable. Examples of such pacts include:
- Writing for one hour every morning before everyone wakes up
- Publishing one newsletter every week about a topic you care about
- Studying for a JavaScript certification for two hours every Sunday
As you can see, there is no finish line; no success metrics except for whether you show up or not. Each pact is simply a little experiment, a chance to learn about the world and about yourself. Focusing on your output rather than the outcome will rekindle your sense of agency without falling prey to the illusion of control.
2. Create an anchor ritual. To grow and learn, we need to soak in the chaos without completely destroying our living system. We all know how important habits and routines are for our mental and physical health, and millions of books have been sold on those topics. But the reality is that these keystones often fly out of the window when we find ourselves trying to navigate the sea of chaos.
Instead, choose one — and one only — anchor ritual, such as journaling, gardening, dancing in your living room, consciously breathing and stretching, doing a few pushups, drawing or coloring, sending a voice note of gratitude to a friend, etc.
Chaos can be anxiety-inducing. Acting as a life buoy in times of uncertainty, your anchor ritual needs to be simple, enjoyable, and practical, so you can turn to it anywhere and anytime you feel overwhelmed.
3. Practice metacognition. In a fast-changing environment, your initial pact will eventually become obsolete, whether it’s because of a contextual change, or because your own aspirations have evolved. But you won’t realize you’re not playing the right game anymore if you’re not actively paying attention.
Put simply, metacognition is thinking about thinking. Instead of blindly repeating the same behavior day after day, metacognition consists in taking time to reflect on what’s working, what could be improved, and what you want to focus on next. By observing and reflecting on your thoughts, you will become more adaptable to chaos, ensuring that you adapt your actions to the currents around you.
And remember that while a pact can be amended to adapt to a new context or new goals, entirely abandoning your pact is also a valid decision. Experimentation and mutation are the only actions to stick to when surfing the edge of chaos.
4. Don’t do it alone. As Pascale, Milleman, and Gioja explain in their book: “Self-organization arises from networks that are fueled by nodes and connections.” In a collaborative setting, everyone contributes to the creation of new nodes and new connections between existing nodes, leading to novel ideas and bridges across islands of knowledge, thus collectively reshaping the system.
Instead of suffering through the mass mutation, you can shape those liminal moments by learning in public and practicing networked thinking. Ask questions, collect feedback, connect with people outside of your circle of competence and share your discoveries with the world. Not only will this improve your chances of success and make the journey more enjoyable, but you will also make friends along the way.
In the sea of chaos, your pact is your rudder and metacognition is your captain’s log. Your anchor ritual offers one pillar of certainty in the never-ending turmoil — a haven of calm to turn to when fear and anxiety threaten to overpower your curiosity. While some lone sailors may survive the storm, you’re much more likely to thrive if you join forces with others.
That’s what chaos surfing is all about: make a pact, create an anchor ritual, practice metacognition, and don’t try to do it all alone. Try these strategies, and not only will you survive, but you will thrive.",2
410,"“World War II was decided by steel and aluminum, and followed shortly thereafter by the Cold War, which was defined by atomic weapons,” Chris Miller, a professor at Tufts University’s Fletcher School of Law and Diplomacy, writes in the introduction to his latest book. So what’s next? According to Miller, the next era, including the rivalry between the U.S. and China, is all about computing power.
That tech rivalry and the story of how the chip industry got from four to 11.8 billion transistors are all part of Miller’s book, “Chip War: The Fight for the World’s Most Critical Technology,” which comes out Oct. 4. “Chip War” outlines the nature of the coming battle over semiconductors, showing how the power to produce leading-edge chips fell into the hands of just five companies: three from the U.S., one from Japan, and one from the Netherlands.
In an interview with Protocol, Miller touched on the evolving military uses of semiconductors, Russia’s chip procurement problems, and whether onshoring chips won’t necessarily increase the likelihood of a conflict between the U.S. and China.
This interview has been edited and condensed for clarity.
You write about how the Persian Gulf War became a pivotal moment for understanding the role microchips would play in warfare, especially with guided missiles. Are missiles still the use-case where the military needs the most advanced chips, or has that shifted to other areas like artificial intelligence or cyber attacks?
I wouldn't necessarily think about individual weapon systems. Chips are important in those weapon systems, but there's also the broader integration of sensors to decision-makers, communication technologies, [and] weapon systems — all of which rely on chips of different sorts.
So it's the integration that matters as much as the capabilities of any individual system. But as more and more systems start to become more autonomous, the demands for computing power, memory, and communication bandwidth increase on all of these systems.
So yes, semiconductors are still very important in terms of advances in specific types of munitions, but it's also [about] the ability to integrate them, to transfer information between them, and to have them working together — and all that requires advanced semiconductors at every stage of the process. Militaries are confronting semiconductors everywhere they turn, and their ability to access the right types of semiconductors and more advanced chips is crucial for every aspect of the modern battlefield.
What’s Russia’s status with the ability to procure semiconductors? There were reports that Russia was struggling to access chips for the Ukraine conflict.
Russia does have some domestic chipmaking capacity but it's very, very limited, both in terms of the level of advancement — which is not that advanced — but also in terms of capacity.
What we've learned from the war — which confirms what we presumed before the war — is that, when you take apart the Russian military system, you'll find lots of foreign-produced chips, and often American-produced chips, inside. Many of these chips are off the shelf — things that you can acquire commercially.
In some ways, the fact that every military in the world is trying to use commercial chips in their systems has been an equalizing factor. But for Russia, it has presented some challenges too. Russia never really knows whether the chips it's buying have been sabotaged in any way. Every country has that to a certain extent. But the U.S., for example, is relying on chip fabs in the U.S. or in friendly countries — whereas Russia is relying almost exclusively on chips produced in unfriendly countries.
The systems integration capabilities are also lacking in Russia. They've got some, but there's just a lot more expertise in places like the U.S. or in East Asian countries [for] how you bring different types of chips plus software plus the hardware all together in a coherent system. And I think that's also somewhere we've seen Russia face some difficulties.
Photo courtesy of Chris Miller
How successful do you think the Chips Plus Act will be?
There's a question about getting the most bang for our buck out of the Chips Act fund. I think there are ways we can get more or less lucky on that front. But I don't think there's really a serious argument that the Chips Act funding is not going to increase the amount of leading-edge chipmaking capacity in the U.S. We've already seen a number of new facilities being built on the expectations of those funds.
Does onshoring chip production increase the chances of conflict between the U.S. and China? It seems the U.S. is onshoring production in anticipation of greater conflict, but is it also possible it increases the chances of something happening by reducing the cost of conflict?
This sort of mutually assured economic destruction thesis — the idea that the U.S. and China or China and Taiwan could never find themselves in a conflict because it would be too costly to do — I think history provides many examples of times in which economically integrated countries ended up in conflict. So that's one reason to be skeptical of it.
The second reason is that the assumption that was true for most of the period from Deng Xiaoping forward in China — that Chinese leaders were primarily focused on maximizing GDP — that assumption is no longer valid. The last three years of Chinese policy have not been about maximizing GDP but about political goals and zero COVID. It doesn't mean that they're not going to care at all about economic issues. But we shouldn't assume that either China or the U.S. or Taiwan is approaching these issues solely from the perspective of making sure trading continues unharmed.
The lesson of 2022 is not that economically integrated powers can't quickly decouple, because we've seen that in a shocking way between Russia and Europe. So I don't think we should take much comfort in the fact that there's a lot of economic integration between China, Taiwan, the U.S., and other countries in the sense that is going to guarantee a peaceful outcome. I don't think history suggests that's true.",2
411,"The doorbell. The intercom. The elevator. Once upon a time, beginning in the late nineteenth century, pushing the button that activated such devices was a strange new experience. The electric push button, the now mundane-seeming interface between human and machine, was originally a spark for wonder, anxiety, and social transformation.
As media studies scholar Rachel Plotnick details, people worried that the electric push button would make human skills atrophy. They wondered if such devices would seal off the wonders of technology into a black box: “effortless, opaque, and therefore unquestioned by consumers.” Today, you’d probably have to schedule an electrician to fix what some children back then knew how to make: electric bells, buttons, and buzzers.
“Some believed that users should creatively interrogate these objects and learn how they worked as part of a broader electrical education,” Plotnick explains. “Others…suggested that pushing buttons could help users to avoid complicated and laborious technological experiences. These approaches reflected different groups’ attempts at managing fears of electricity.”
Electric push buttons, essentially on/off switches for circuits, came on the market in the 1880s. As with many technological innovations, they appeared in multiple places in different forms. Their predecessors were such mechanical and manual buttons as the keys of musical instruments and typewriters. Before electricity, buttons triggered a spring mechanism or a lever.
The word “button” itself comes from the French bouton, meaning pimple or projection, and to push or thrust forward. It’s impossible to pinpoint a single origin of the push button, writes Plotnick, but such interfaces included the “inanimate buttons that adorned clothing.” Between 1880 and 1920, hundreds of patent applications were made for “electric buttons” or “push-buttons.”
At the end of the nineteenth century, many laypeople had a “working knowledge not only of electricity, but also of the buttons they pushed and the relationship between the two,” according to Plotnick. Those who promoted electricity and sold electrical devices, however, wanted push-button interfaces to be “simplistic and worry-free.” They thought the world needed less thinking though and tinkering, and more automatic action. “You press the button, we do the rest”—the Eastman Company’s famous slogan for Kodak cameras—could be taken as the slogan for an entire way of life.
Weekly Newsletter
Ultimately, the idea that electricity was a kind of magic would triumph over a more hands-on, demystifying approach.
Plotnick quotes an educator and activist from 1916 lamenting that pushing a button “seems to relieve one of any necessity for responsibility about what goes on behind the button.” That resonates now, more than a century later, when technology is even more complicated and even more intimately entwined with our lives. The “black box” reigns supreme.
Support JSTOR Daily! Join our new membership program on Patreon today.",2
412,"|
|
|
|
|
|
|
|
BOIL WATER NOTICE FOR
CITY OF HOUSTON
|
|
|
|
Houston, Texas – A boil water notice has been issued for the City of Houston’s Main Water System (TX1010013). Earlier today, the water pressure dropped below the Texas Commission on Environmental Quality’s required minimum of 20 PSI during a power outage at the East Water Purification Plant on Sunday, November 27, at 10:30 am.
As a result of the Boil Water Notice, the public is advised:
*Do not drink the water without boiling it first.
*Bring all water to a boil for at least two minutes.
*Let it cool before using.
*Individuals without power to boil water are advised to use bottled water for consumption.
DETAILS ABOUT RESTORATION ESTIMATES: The City monitored water pressures across the city throughout the day. Water pressure was restored to all customers shortly after the power outage. If you are still experiencing low water pressure, please call 311.
If you have questions concerning this matter, you may contact 311 or email waterquality@houstontx.gov.
For a link to the impacted area: bit.ly/boilwaternoticenov2022
|
|
|
TCEQ requires this mandatory notification and the information below
|
Due to reduced distribution system pressure, Texas Commission on Environmental Quality has required the Houston Main Water System (TX1010013) to notify all customers to boil their water prior to consumption (e.g., washing hands/face, brushing teeth, drinking, etc.). Children, seniors, and persons with weakened immune systems are particularly vulnerable to harmful bacteria, and all customers should follow these directions).
To ensure destruction of all harmful bacteria and other microbes, water for drinking, cooking, and ice making should be boiled and cooled prior to use for drinking water or human consumption purposes. The water should be brought to a vigorous rolling boil and then boiled for two minutes.
In lieu of boiling, individuals may purchase bottled water or obtain water from some other suitable source for drinking water or human consumption purposes.
When it is no longer necessary to boil the water, the public water system officials will notify customers that the water is safe for drinking water or human consumption purposes.
Once the boil water notice is no longer in effect, the public water system will issue a notice to customers that rescinds the boil water notice in a manner similar to this notice.
Please share this information with all the other people who drink this water, especially those who may not have received this notice directly (for example, people in apartments, nursing homes, schools, and businesses). You can do this by posting this notice in a public place or distributing copies by hand or mail.
ABOUT HOUSTON PUBLIC WORKS
Houston Public Works (www.HoustonPublicWorks.org) is the largest and most diverse public works organization in the country, responsible for creating a strong foundation for Houston to thrive. Houston Public Works is responsible for streets and drainage, production and distribution of water, collection, and treatment of wastewater, and permitting and regulation of public and private construction covering a 671-square mile service area. Houston Public Works is accredited by the American Public Works Association.
Facebook, Twitter & Instagram: @HouPublicWorks
|
|
|
|
|
Contact:
|
Erin Jones | Interim Communications Director, Public Information Officer
Office: 832-395-2530
Cell: 713-853-6073
Erin.Jones@houstontx.gov",2
413,"Récits du Vieux Royaume #1.5
Le Sentiment du fer
Retour au Vieux Royaume !
« J’ai quand même un ragot à vous servir, et du lourd ! Figurez-vous que ce n’est point avec moi que les elfes ont commencé à grenouiller dans les affaires de l’État. Bien loin de là ! Il y a deux bons siècles, déjà, au moment de l’Émancipation de Ciudalia, ils nous ont joué un tour à leur façon. Et les marles en tâtent tellement pour la barabille que l’un d’entre eux, sans même pointer son joli minois dans notre belle cité, nous a tous jetés dans une sacrée flanche ! Jugez-en par vous-même. »
En cinq nouvelles comme autant d’étapes dans l’histoire cruelle et tumultueuse du Vieux Royaume, le monde créé par Jean-Philippe Jaworski dans Janua Vera et Gagner la guerre — déjà des classiques de la fantasy.
Table :
- Le Sentiment du fer
- L'Elfe et les Égorgeurs
- Profanation
- Désolation
- La Troisième Hypostase
« J’ai quand même un ragot à vous servir, et du lourd ! Figurez-vous que ce n’est point avec moi que les elfes ont commencé à grenouiller dans les affaires de l’État. Bien loin de là ! Il y a deux bons siècles, déjà, au moment de l’Émancipation de Ciudalia, ils nous ont joué un tour à leur façon. Et les marles en tâtent tellement pour la barabille que l’un d’entre eux, sans même pointer son joli minois dans notre belle cité, nous a tous jetés dans une sacrée flanche ! Jugez-en par vous-même. »
En cinq nouvelles comme autant d’étapes dans l’histoire cruelle et tumultueuse du Vieux Royaume, le monde créé par Jean-Philippe Jaworski dans Janua Vera et Gagner la guerre — déjà des classiques de la fantasy.
Table :
- Le Sentiment du fer
- L'Elfe et les Égorgeurs
- Profanation
- Désolation
- La Troisième Hypostase
206 pages, Paperback
First published May 5, 2015
About the author
Ratings & Reviews
Friends & Following
Create a free account to discover what your friends think of this book!
Community Reviews
5 stars
65 (30%)
4 stars
100 (46%)
3 stars
48 (22%)
2 stars
2 (<1%)
1 star
1 (<1%)
Can't find what you're looking for?
Get help and learn more about the design.",0
414,"Mushroom-derived electronics designed to biodegrade when discarded
Among other things, mushrooms have been put forth as eco-friendly alternatives to leather and expanded foam packaging. According to a new study, they might also find use in biodegradable electronic devices.
The discovery of this novel use for mushrooms was made more or less accidentally Martin Kaltenbrunner, Doris Danninger and Roland Pruckner, all of whom are scientists at Austria's Johannes Kepler University Linz.
While investigating the use of mushrooms in applications such as building insulation, they noted that the reishi mushroom (Ganoderma lucidum) has a particularly tough outer skin that protects the underlying pulpy tissue from pathogens and other types of fungi.
It was discovered that the skin can be easily removed and then dried, forming a ""robust, flexible, and heat resistant"" material that can withstand temperatures of up to 250 ºC (482 ºF). That said, when left in the proper environment, it completely biodegrades. With these properties in mind, it is hoped that the ""MycelioTronic"" material could one day serve as the substrate for printed circuit boards in flexible electronic devices.
Currently, the substrates in such boards are constructed of polymers which are difficult to separate from the other components, thus making it hard to recycle both the polymers and those components. By contrast, once the mushroom-based substrate had biodegraded, the remaining non-degradable items could simply be plucked out and recycled.
The material could conceivably also find use in medical implants, designed to harmlessly dissolve within the body once they're no longer needed.
In a proof-of-concept exercise, the researchers have already built functional proximity and humidity sensors in which conventional electronic chips were soldered onto a MycelioTronic substrate. They're now looking into using the material in other components, with the aim of ultimately producing a completely biodegradable circuit board.
The study is described in a paper that was recently published in the journal Science Advances.
Source: Johannes Kepler University Linz via New Scientist
Please keep comments to less than 150 words. No abusive material or spam will be published.",2
415,"Professional athletes and men’s wellness gurus are turning to psychedelics to explore their inner selves. What's going on with psychedelic masculinity?
What is American masculinity in 2022? A look at men’s role models is instructive. We’ve got a Canadian, Kermit-the-frog-voiced father figure in Jordan Peterson who mixes advice to clean your room with suggestions to eat only meat, revisit debunked phrenology, and sound dire warnings about chaos dragons. And we’ve got our stand-in big brother Joe Rogan, who talks about the performance-enhancing powers of both lifting weights and doing ayahuasca. What is going on with this new psychedelic masculinity?
These days it feels like everywhere I turn a professional bro is describing their life-changing psychedelic experiences. These include Joe Rogan, former NHL enforcer Riley Cote, Daniel Carcillo, Mike Tyson, and Aaron Rodgers. And it’s making me wonder: Why are all these rough-and-tumble dudes suddenly tripping balls? And what does it say about modern masculinity?
I first became aware of fitness influencer and supplement slinger Aubrey Marcus at the first wellness startup I wrote for in 2018. Marcus is, well, very masculine. He’s got an undeniably-handsome face made only sexier for its rugged, beaten-up look. Of course his body was ripped. And the deep voice didn’t hurt. He was also, at least for a time, openly polyamorous and talked very candidly and in detail about his experiences with psychedelics.
Cote’s job as an NHL enforcer wasn’t doing his mental or physical health any favors. His role was so hard on his brain and body that it’s now basically disallowed from the sport. As if taking punches to the face and suffering four diagnosed concussions weren’t enough, he was also drinking to excess and using painkillers.
While his first forays into psychedelics were recreational, things changed when Cote started using them intentionally. Today, you’re more likely to see Cote sitting on a pillow, cross-legged, wearing a beaded necklace and using words like “safe container” and “plant medicine” than in a fistfight.
When Cote talks about psychedelics, it’s clear he’s a changed man. Psychedelics help give people “a little jump start to help get us on the path,” he said.
“Psychedelics have a way of softening the heart,” Cote said. Our hearts have become rigid, perhaps due to the structure of the system that we live in. “We’re maybe not very compassionate at times in our relationships. I think a lot of men’s relationships towards women, it’s toxic. It’s just all about sex. It’s not really about understanding sexual energy as creative energy. So it [psychedelics] brings awareness to all these things that you might not uncover in this lifetime if you don’t have a catalyst like a psychedelic to kind of get you on the path.”
Plant medicines have helped Cote tap into compassion for himself and others. They’ve also helped him let go of feeling “that I had to uphold this physical presence just to be worthy enough and be this tough guy,” Cote said.
“Here I am talking about a flower,” Cote recently told Rolling Stone, laughing. “It’s been an incredible journey. And really, I just want to take as many people with me as possible.”
To that end, Cote has introduced former NFL lineman Justin Renfrow and Steve Downie to psilocybin to similar effects. Downie teared up and shared about his father’s death. Renfrow let go of the idea that he had an obligation to play through his injuries.
Marcus described his first experience with MDMA as “a heart-opening experience,” and says it helped him realize, “I love people.”
Psychedelics have helped these men show emotions other than anger and talk openly about love, interconnectedness, and compassion. In each case, these manly men found themselves still wanting more, even after tremendous success in everything culture tells us men should want. They had impressive careers, girls, and nice things.
At the same time, their success was pretty narrowly dependent on their physical strength, skill, and endurance. In a way, the professional athlete goes through the same thing a lot of American men do, but much more intensely and in a shorter time span. There comes a time when you’re not physically and/or mentally able to leave it all out on the field anymore. And where do you find your meaning, purpose, and self-worth when you can’t rely on your job anymore?
For a lot of these athletes, psychedelics have helped them feel worthy of love and acceptance outside of their work or performance.
I asked Cote whether psychedelics had any impact on his conception of masculinity. “Hundred percent,” he said. “I checked every box as far as toxic masculinity.”
Cote said he was lucky to grow up in a positive household and didn’t learn toxic masculinity there. “I think it was the culture of being a male in this society,” Cote said. “And then moving away from home at a young age and playing junior hockey. Then you’re on a team with a group of extremely masculine males. The energy is like a subconscious program. It’s parties and it’s girls.”
And this conception of masculinity extends far beyond professional hockey. “It’s society,” Cote said. “It’s not just sports. I think it’s a microcosm of the macro. There’s a lack of self-love. It’s not taught. It’s like telling an ultra-masculine dude, ‘Love yourself.’ Self care? No, we don’t take care of ourselves. We just bury ourselves every weekend. We don’t need to sleep. We’ll sleep when we’re dead. With the amount of suicides and mental health issues, that way of thinking doesn’t promote life. It promotes death and decay.”
But Cote says psychedelics, yoga, and other lifestyle changes have helped him achieve a healthier balance between a more masculine and a more feminine energy.
Could psychedelics offer an alternative path to a narrow, rigid masculinity in which a man’s self-worth is defined by his career, anger is the only acceptable emotion, women are for sex, and aggression and dominance are the default modes of relating? Perhaps in some cases. But looking at a wider picture, it becomes clear psychedelics are hardly a panacea for toxic masculinity.
Shortly after announcing that he felt his “expiration date” fast approaching, Mike Tyson told Muscle and Health Magazine that he takes psychedelics every day, particularly “mushrooms.”
Like Cote in a previous interview, Tyson said his athletic performance would have likely been better if he’d started these drugs sooner. But based on Tyson’s recent statements and tweets, it doesn’t appear psychedelics have awakened any feminine energy within him. Nor does it seem like Joe Rogan’s attitude has increased exponentially in love, interconnectedness, and/or compassion as a result of using psychedelics. And it was after coming out about having done psychedelics that Will Smith bitch-slapped Chris Rock on national television, an explosive expression of toxic masculinity broadcast to the entire world.
It could as easily be the case that at least for some, psychedelics are better understood as a relatively “safe” way to keep up your reputation as the edgy bad boy even after you’re not physically able to fight it out in the ring anymore.
Then, there’s the capitalism aspect. Scratch just beneath the surface of a masculine influencer gabbing about the life-changing power of psychedelics and you’ll find a partnership with a company seeking to make money on the growing shroom boom.
Letting yourself cry about your dad’s death may be incredibly useful to a whole and integrated life, but it’s not likely to sell many supplements. For now, the power to help balance feminine and masculine energy is still a subtext of male psychedelia. The text is still focused on performance enhancement. It’s hard to sell a better version of masculinity to an audience who’s still trying desperately to buy the toxic variety. The ultimate irony is that psychedelic influencer bros are selling other bros performance enhancing mushrooms to help these bros discover for themselves that they can’t perform their way to worthiness. To quote Rogan, “Wow man. That’s crazy.”
The professional US athlete’s career trajectory has certain parallels with the typical US male, just much faster and more intense. Both leverage their physical and mental health to win in a highly competitive, sink-or-swim environment for as long as they’re physically and mentally able. Then, when they can’t give any more to the game, they have a choice to make.
Every man who lives long enough must answer a question: Can I reorient my life to be about something bigger, broader, and more meaningful than winning at all costs? Or do I keep reaching for the next drug or supplement to try to wring out a bit more performance? Psychedelic masculinity taps into both of these desires.
Which way, Western man? Do you tap into psychedelics to try to keep your edge in a rat race, or do you use them to help you see over the edge of the maze?
Leave a ReplyWant to join the discussion?
Feel free to contribute!",4
416,"Download the free Kindle app and start reading Kindle books instantly on your smartphone, tablet, or computer - no Kindle device required. Learn more
Read instantly on your browser with Kindle Cloud Reader.
Using your mobile phone camera - scan the code below and download the Kindle app.
Learn more
Follow the Author
Thinking in Systems: International Bestseller Paperback – Illustrated, December 3, 2008
| |
Price
|New from||Used from|
|
Audible Audiobook, Unabridged
|
""Please retry""
| |
$0.00
|Free with your Audible trial|
The classic book on systems thinking―with more than half a million copies sold worldwide!
""This is a fabulous book… This book opened my mind and reshaped the way I think about investing.""―Forbes
""Thinking in Systems is required reading for anyone hoping to run a successful company, community, or country. Learning how to think in systems is now part of change-agent literacy. And this is the best book of its kind.""―Hunter Lovins
In the years following her role as the lead author of the international bestseller, Limits to Growth―the first book to show the consequences of unchecked growth on a finite planet―Donella Meadows remained a pioneer of environmental and social analysis until her untimely death in 2001.
Thinking in Systems is a concise and crucial book offering insight for problem solving on scales ranging from the personal to the global. Edited by the Sustainability Institute’s Diana Wright, this essential primer brings systems thinking out of the realm of computers and equations and into the tangible world, showing readers how to develop the systems-thinking skills that thought leaders across the globe consider critical for 21st-century life.
Some of the biggest problems facing the world―war, hunger, poverty, and environmental degradation―are essentially system failures. They cannot be solved by fixing one piece in isolation from the others, because even seemingly minor details have enormous power to undermine the best efforts of too-narrow thinking.
While readers will learn the conceptual tools and methods of systems thinking, the heart of the book is grander than methodology. Donella Meadows was known as much for nurturing positive outcomes as she was for delving into the science behind global dilemmas. She reminds readers to pay attention to what is important, not just what is quantifiable, to stay humble, and to stay a learner.
In a world growing ever more complicated, crowded, and interdependent, Thinking in Systems helps readers avoid confusion and helplessness, the first step toward finding proactive and effective solutions.
Editorial Reviews
From Publishers Weekly
Copyright © Reed Business Information, a division of Reed Elsevier Inc. All rights reserved.
Review
Publishers Weekly, Starred Review-
Just before her death, scientist, farmer and leading environmentalist Meadows (1941-2001) completed an updated, 30th anniversary edition of her influential 1972 environmental call to action, Limits to Growth, as well as a draft of this book, in which she explains the methodology-systems analysis-she used in her ground-breaking work, and how it can be implemented for large-scale and individual problem solving. With humorous and commonplace examples for difficult concepts such as a ""reinforcing feedback loop,"" (the more one brother pushes, the more the other brother pushes back), negative feedback (as in thermostats), accounting for delayed response (like in maintaining store inventory), Meadows leads readers through the increasingly complex ways that feedback loops operate to create self-organizing systems, in nature (""from viruses to redwood trees"") and human endeavor. Further, Meadows explicates methods for fixing systems that have gone haywire (""The world's leaders are correctly fixated on economic growth ...but they're pushing with all their might in the wrong direction""). An invaluable companion piece to Limits to Growth, this is also a useful standalone overview of systems-based problem solving, ""a simple book about a complex world"" graced by the wisdom of a profound thinker committed to ""shaping a better future.
""When I read Thinking in Systems I am reminded of the enormity of the gap between systemic thinkers and policy makers. If this book helps narrow the gap, it will be Dana's greatest contribution.""--Lester Brown, founder and President, Earth Policy Institute
""Dana Meadows' exposition in this book exhibits a degree of clarity and simplicity that can only be attained by one who profoundly and honestly understands the subject at hand--in this case systems modeling. Many thanks to Diana Wright for bringing this extra legacy from Dana to us.""--Herman Daly, Professor, School of Public Policy, University of Maryland at College Park
""Reading Thinking in Systems evokes the wisdom and even the voice of Dana Meadows. We are reminded of how she was not only one of the great systems thinkers, but also one of our greatest teachers. This is modestly called a primer, and indeed it is, but unlike most books with that title, this one quickly takes one from the elementary into deep systems thinking about issues as critical today as they were when Dana wrote these words. The discussion of oil use and the interaction of its extraction pattern with economic decision making should be required reading for all energy policy makers and energy company executives (as well as all informed citizens in a democracy). The fisheries case reminds us of how little any government or private actor has done to grasp the importance of takeout flows in determining stocks when the input flows are not within our control. The commentary on economics and, yes the need to consider limits, is a clear systems statement that clarifies a great deal of discussion that goes back to The Limits to Growth.
It is remarkable that Dana is able to explain with such clarity such systems concepts of stocks, flows, feedback, time delays, resilience, bounded rationality, and system boundaries and to illustrate each one with multiple informative examples. Her statement that goals that optimize subsystems will sub optimize the functioning of the total system, is truly profound. As the book moves from the 'mechanics' of systems dynamics to Dana's more philosophical perspective, we are treated to her inherent belief in human values that consider the good of all, and how much more effective considering the needs of others is likely to be in solving larger, complex problems. The universe and our society may be very complex and operate in counterintuitive, non-liner fashion, but following the insights of this book and applying them will provide for far more effective solutions to the challenges of a 7 billion person planet than current incremental, linear responses by governments, corporations and individuals.""--Bill Moomaw, Professor of International Environmental Policy at the Fletcher School, Tufts University
""In Dana Meadows's brilliantly integrative worldview, everything causes everything else; cause and effect loop back on themselves. She was the clearest thinker and writer co-creating the art and science of systems dynamics, and Thinking in Systems distills her lifetime of wisdom. This clear, fun-to-read synthesis will help diverse readers everywhere to grasp and harness how our complex world really works.""--Amory B. Lovins, Chairman and Chief Scientist, Rocky Mountain Institute
""Dana Meadows taught a generation of students, friends, and colleagues the art and science of thinking beyond conventional boundaries. For her systems thinking included the expected things like recognizing patterns, connections, leverage points, feedback loops and also the human qualities of judgment, foresight, and kindness. She was a teacher with insight and heart. This long anticipated book, the distillation of her life's work, is a gem.""--David Orr, Professor of Environmental Studies and Politics, Oberlin College
""The publication of Thinking in Systems is a landmark. To live sustainably on our planet, we must learn to understand human-environment interactions as complex systems marked by the impact of human actions, the prominence of nonlinear change, the importance of initial conditions, and the significance of emergent properties. Dana Meadows' final contribution is the best and most accessible introduction to this way of thinking we have. This book is destined to shape our understanding of socio-ecological systems in the years to come in much the same way that Silent Spring taught us to understand the nature of ecosystems in the 1960s and 1970s.""--Oran R. Young, Professor, Donald Bren School of Environmental Science and Management at University of California, Santa Barbara
""Thinking in Systems is required reading for anyone hoping to run a successful company, community, or country. Learning how to think in systems is now part of change-agent literacy. And this is the best book of its kind.""--Hunter Lovins, founder and President of Natural Capital Solutions and coauthor of Natural Capitalism: Creating the Next Industrial Revolution
""Dana Meadows was one of the smartest people I ever knew, able to figure out the sensible answer to almost any problem. This book explains how she thought, and hence is of immense value to those of us who often wonder what she'd make of some new problem. A classic.""--Bill McKibben, author of Deep Economy
""An inspiring sequel to Dana Meadows' lifetime of seminal contributions to systems thinking, this highly accessible book should be read by everyone concerned with the world's future and how we can make it as good as it possibly can be.""--Peter H. Raven, President, Missouri Botanical Garden
""Few matched Dana Meadows remarkable blend of eloquence and clarity in making systems thinking understandable. When Dana began her career, the field was esoteric and academic. Today it is the sine quo non for intelligent action in business and society. The publication of Meadows' previously unfinished manuscript is a gift for leaders of all sorts and at all levels.""--Peter M. Senge, author of The Fifth Discipline and The Necessary Revolution
Product details
- Publisher : Chelsea Green Publishing (December 3, 2008)
- Language : English
- Paperback : 240 pages
- ISBN-10 : 1603580557
- ISBN-13 : 978-1603580557
- Item Weight : 12.8 ounces
- Dimensions : 6 x 0.75 x 9 inches
- Best Sellers Rank: #4,339 in Books (See Top 100 in Books)
- #1 in System Theory
- #9 in Environmental Science (Books)
- #78 in Business Management (Books)
- Customer Reviews:
About the author
Customer reviews
Reviewed in the United States on October 6, 2021
Reviews with images
Top reviews from the United States
There was a problem filtering reviews right now. Please try again later.
All systems have a ‘stock’ which is the foundation of what the system uses to achieve its goal. Stocks are things like “the water in a bathtub, a population, the books in a bookstore, the wood in a tree, the money in a bank, your own self-confidence,” which are subject to the flows of the system. “Flows are filling and draining, births and deaths, purchases and sales, growth and decay, deposits and withdrawals, successes and failures.” Stock is what you have at any one moment in time and the flow is how it changes.
Let’s take the human body as an example. The body’s stock is comprised of its organs, bones, muscles, tissues, and all the things on the inside that keep it running. The body’s flow is the intake of food and water, which the system translates into energy, and the output of this energy as human waste. The goal of this system is to keep the body alive.
When systems get tricky is when the reported goal of a system is different from the results it tangibly achieves. For example, what is the ostensible goal of a business? Most business owners would tell you their goal is to deliver customer satisfaction in the form of whatever it is they make and sell, whether it be haircuts or hot meals. This is true for local businesses, but larger businesses are more honest when they admit their company goal is to make a profit. In reality, the true goal of most businesses in a capitalistic system is “to grow, to increase market share, [and] to bring the world (customers, suppliers, regulators) more and more under the control of the corporation.” Ask yourself this: Does McDonald’s pride itself more on its delicious hamburgers or its worldwide recognition?
A system that I have been considering lately is our doctoral system here in the United States. Many doctors work 70-80 hour weeks with overnight hours which means a rotating sleep schedule and off-beat eating habits. The fastest you can reasonably become a doctor is after passing 4 years of undergraduate school, 4 years of medical school, and then completing a 5 year residency. If you graduate high school at age 18, you are finishing your residency at age 31 (probably with hundreds of thousands of dollars of student loans). These are tough conditions and high standards. Our society’s system for training and managing doctors has developed alongside the growth of society for hundreds of years, which means that all of these mechanisms were developed for good purposes. For one thing, there is simply so much more that we know about medicine and the human body that must be learned. It still remains that a major symptom of this system is overtired doctors and we need to adjust the flow and help them out. Alternatively, consider the system surrounding the careers of professors. Tenure was implemented in order to gives teachers academic freedom, which is a good thing. One of its symptoms, however, is that the process of achieving tenure has become ultra competitive.
What happens when a country’s goals are poorly defined? Here in the United States, and in many western countries, we measure our economic goals by our level of GNP (gross national product), which is the value of the final goods and services produced by the economy. This number, however, says nothing about our health, happiness, beauty, strength, intelligence or integrity. Our GNP rises if there are more car accidents and medical bills. Defining business and economics in this way has cost humanity in many major ways including environmental degradation, monopolization of markets by huge corporations, and the suction of wealth from the lower classes to the higher.
All of this analysis leads us to the inevitable question: how do we change a system? The first thing to define is which system we wish to investigate and alter. This is important because there are no separate systems. The world is a continuum. “Where to draw a boundary around a system depends on the purpose of the discussion—the questions we want to ask.” If your house is too cold, then you must examine the insulation and the thermostat. If your body is sick, you must examine the fuel you are putting into it and the people you allow around it. If your country is broken, that too must be examined. Is it the social system, the environmental system, or the governmental system? Is it the financial system, the educational system, or the welfare system? The reality, of course, is that problems lie within each of these systems independently and also as a whole. There are no easy answers here, the difficultly lying in the fact that the farther one zooms out, the more overlapped all of these systems become. To change one requires the agreement and movement of masses of people in one unified direction. But what if fixing one environmental problem causes a cultural one? Or vice versa? The complexities are never-ending.
If you zoom all the way out, you can see that all of us are connected across time and space. “Actions taken now [will] have some immediate effects and some that radiate out for decades to come. We experience now the consequences of actions set in motion yesterday and decades ago and centuries ago.” Many of the systems we inhabit today are like rivers that we were thrown mercilessly into. They were already running, predetermined by forces and people who came long before us, and while it is our job to stay afloat while we are on the water, and to improve upon them as best we can, they will continue to run long after we are gone.
By Cody Allen on October 6, 2021
All systems have a ‘stock’ which is the foundation of what the system uses to achieve its goal. Stocks are things like “the water in a bathtub, a population, the books in a bookstore, the wood in a tree, the money in a bank, your own self-confidence,” which are subject to the flows of the system. “Flows are filling and draining, births and deaths, purchases and sales, growth and decay, deposits and withdrawals, successes and failures.” Stock is what you have at any one moment in time and the flow is how it changes.
Let’s take the human body as an example. The body’s stock is comprised of its organs, bones, muscles, tissues, and all the things on the inside that keep it running. The body’s flow is the intake of food and water, which the system translates into energy, and the output of this energy as human waste. The goal of this system is to keep the body alive.
When systems get tricky is when the reported goal of a system is different from the results it tangibly achieves. For example, what is the ostensible goal of a business? Most business owners would tell you their goal is to deliver customer satisfaction in the form of whatever it is they make and sell, whether it be haircuts or hot meals. This is true for local businesses, but larger businesses are more honest when they admit their company goal is to make a profit. In reality, the true goal of most businesses in a capitalistic system is “to grow, to increase market share, [and] to bring the world (customers, suppliers, regulators) more and more under the control of the corporation.” Ask yourself this: Does McDonald’s pride itself more on its delicious hamburgers or its worldwide recognition?
A system that I have been considering lately is our doctoral system here in the United States. Many doctors work 70-80 hour weeks with overnight hours which means a rotating sleep schedule and off-beat eating habits. The fastest you can reasonably become a doctor is after passing 4 years of undergraduate school, 4 years of medical school, and then completing a 5 year residency. If you graduate high school at age 18, you are finishing your residency at age 31 (probably with hundreds of thousands of dollars of student loans). These are tough conditions and high standards. Our society’s system for training and managing doctors has developed alongside the growth of society for hundreds of years, which means that all of these mechanisms were developed for good purposes. For one thing, there is simply so much more that we know about medicine and the human body that must be learned. It still remains that a major symptom of this system is overtired doctors and we need to adjust the flow and help them out. Alternatively, consider the system surrounding the careers of professors. Tenure was implemented in order to gives teachers academic freedom, which is a good thing. One of its symptoms, however, is that the process of achieving tenure has become ultra competitive.
What happens when a country’s goals are poorly defined? Here in the United States, and in many western countries, we measure our economic goals by our level of GNP (gross national product), which is the value of the final goods and services produced by the economy. This number, however, says nothing about our health, happiness, beauty, strength, intelligence or integrity. Our GNP rises if there are more car accidents and medical bills. Defining business and economics in this way has cost humanity in many major ways including environmental degradation, monopolization of markets by huge corporations, and the suction of wealth from the lower classes to the higher.
All of this analysis leads us to the inevitable question: how do we change a system? The first thing to define is which system we wish to investigate and alter. This is important because there are no separate systems. The world is a continuum. “Where to draw a boundary around a system depends on the purpose of the discussion—the questions we want to ask.” If your house is too cold, then you must examine the insulation and the thermostat. If your body is sick, you must examine the fuel you are putting into it and the people you allow around it. If your country is broken, that too must be examined. Is it the social system, the environmental system, or the governmental system? Is it the financial system, the educational system, or the welfare system? The reality, of course, is that problems lie within each of these systems independently and also as a whole. There are no easy answers here, the difficultly lying in the fact that the farther one zooms out, the more overlapped all of these systems become. To change one requires the agreement and movement of masses of people in one unified direction. But what if fixing one environmental problem causes a cultural one? Or vice versa? The complexities are never-ending.
If you zoom all the way out, you can see that all of us are connected across time and space. “Actions taken now [will] have some immediate effects and some that radiate out for decades to come. We experience now the consequences of actions set in motion yesterday and decades ago and centuries ago.” Many of the systems we inhabit today are like rivers that we were thrown mercilessly into. They were already running, predetermined by forces and people who came long before us, and while it is our job to stay afloat while we are on the water, and to improve upon them as best we can, they will continue to run long after we are gone.
I am not a student of systems or someone who ever spent much time thinking about systems at all, although, like practically everybody, my life and work are all about either creating, maintaining, supporting, or surviving various systems. I heard about this book from a Tweet referring to its twenty-fifth anniversary and linking to an article singing its praises, which it does better than I can. For me, it has been a truly revelatory experience, a platonic slave-in-the-cave moment, which I believe will divide my cognitive experience into pre and post its reading. As Meadows warns at its outset, studying systems leads one to see systems everywhere, which, of course, is because they were there all along. But being able to see and interpret them allows us to better participate and avoid traps that commonly lead to system failure. Sadly, it also allows us to understand why some decisions taken by executives, politicians, and others that manage systems in which we have little or no control are doomed to failure and to undermine their own goals. This awareness will help readers become better citizens/coworkers and critics of leadership. But it can also help us avoid issues that threaten our own, smaller systems, our relationships, families, homes, work, and health.
This book draws heavily on examples from the time in which it was written, which artificially sets the book in a particular historical moment. Meadows simply had so many examples to chose from, that she took quotes from contemporaneous newspaper articles. But the examples might as well be chosen from today’s stories or those from hundreds of years ago. They are just examples. This book is timeless. These quotes from the early nineties have the added benefit of proving her point, as in most cases history has borne out the predictions that stem from the flaws and features that Meadows points out.
Note that there were some oddities in the Kindle version. A few words seem to have disappeared in various places in the transposition. I bought a hard copy of the book and was able to fill the gaps (just a few words here and there, nothing that would keep me from recommending the Kindle edition). I hope the editors will correct this.
The end of the book contains a very useful appendix that I am tempted to tear out and put up on the wall, detailing fundamentals of systems thinking.
I could not recommend this highly enough.
On the other hand if you never ever heard about systems around you or never thought about it, it might be a very good read.
I have taken some notes from it and will try to use some of the tips and tricks in a real life situation. But will I use the book as constant reference once I face some problems - nope.
Top reviews from other countries
But until now there was no book that I had read that formed a basis of how systems, in general, tied together. This book provides that glue. It covers a lot of ground and provides solid examples of how system thinking can, quite literally, change the world. It covers areas such as oil production, politics, user of language and drug addiction in ways that are cohesive and informative. It never provides 'just so stories' that are unsupported and provide examples of simple systems (from the systems zoo) that explain why often those who influence systems end up pushing the wrong way and making things worse, even though they may have the best of intentions.
I have so far recommended this book to five people all from different backgrounds and will be folding in what I have learnt here into my User Experience work.
In Part 1, System Structure and Behaviour, Meadows uses two graphical tools to analyse systems: stock and flow diagrams to show system structure; and charts mapping stock or flow levels over time to explore system behaviour for specific scenarios. The diagrams can be used to display ""balancing"" (aka ""negative"") and ""reinforcing"" (aka ""positive"") feedback loops, and the charts to explore how these might play out.
While some of the systems might seem simplistic, they build up understanding of a key Systems Thinking insight, that systems generate their own behaviour. And if you're ever wondered why the ""heroes and villains"" style of explanation only works in retrospect, this is a damn good explanation.
Chapter two, The Zoo, is a library of common system structures and their behaviour. Those of us from the software world will be reminded of a patterns library. Again, these patterns illustrate a deeper insight, that ""systems with similar feedback structures produce similar dynamic behaviors, even if the outward appearance of these systems is completely dissimilar."" (p 51)
In Part 2, Systems and Us, Meadows applies Systems Thinking to our world. Many of the examples are dated, but I found myself thinking how applicable these patterns and insights were to topics I was currently encountering - for example, I can't help thinking she would have loved the way that Kanban reflects a systems learning, that the ability of people and organisations to execute tasks degrades rapidly as the number of tasks rises beyond a critical limit.
Of course one natural and urgent interest in systems behaviour is how to change it. If worshipping heroes and lynching villains isn't going to reform systems that may exhibit non-linear, perverse or self-preserving behaviour, what is?
In Part 3, Creating Change in System and in our Philosophy, Meadows gives us a dozen leverage points for changing systems, starting with the simplest and ending with the most powerful. She finishes with a list of ""systems wisdoms"" - attitudes and values that she and others she respects have adopted to make them more effective at understanding and changing the systems we live in.
Like many of the other reviewers, I wish I'd read this book a long time ago. It has its limitations - I'd love to see more recent examples, and can't help wondering if there are any open-source Systems modelling resources. But for me this is a book of timeless value for anyone interested in a better understanding of their world and their options in it.
From the perennial problem of managing drug addiction, to climate change and population growth - you name it - you will get an amazing, easy to follow, perspective on the ""zoo"" of different system types and the systems issues that follows..
It helps you see more clerkly why praising/blaming individuals is so problematic and it also explains the ""Groundhog Day"" of things not getting fixed, even getting worse.. Its necessary for anyone who is really serious in effecting change in the issues of today",2
417,"Table of Contents
Table of Contents
My highlighted a number of sites that are taking a new approach to the way we publish personal knowledge on the web.
They're not following the conventions of the ""personal blog,"" as we've come to know it. Rather than presenting a set of polished articles, displayed in reverse chronological order, these sites act more like free form, work-in-progress wikis.
A garden is a collection of evolving ideas that aren't strictly organised by their publication date. They're inherently exploratory – notes are linked through contextual associations. They aren't refined or complete - notes are published as half-finished thoughts that will grow and evolve over time. They're less rigid, less performative, and less perfect than the personal websites we're used to seeing.
It harkens back to the early days of the web when people had fewer notions of how websites ""should be.” It's an ethos that is both classically old and newly imagined.
A Brief History of Digital Gardens
Let's go on a short journey to the origin of this word. The notion of a digital garden is not a 2020 invention. It's been floating around for over two decades. However, it's passed through a couple of semantic shifts in that time, meaning different things to different people across the years. As words tend to do.
Tracing back how are born helps us understand why anyone needed this word in the first place. Language is always a response to the evolving world around us – we expand it when our current vocabulary fails to capture what we're observing, or have a particular desire for how we'd like the future to unfold. Naming is a political act as much as a poetic one.
The Early Gardens of Hypertext
Mark Bernstein's 1998 essay appears to be the first recorded mention of the term. Mark was part of the early hypertext crowd – the developers figuring out how to arrange and present this new medium.
While the essay is a beautiful ode to free-wheeling internet exploration, it's less about building personal internet spaces, and more of a manifesto on user experience flows and content organisation.
To put this in its historical context, Mark's writing was part of a larger conversation happening throughout the nineties around hypertext and its metaphorical framing.
The early web-adopters were caught up in the idea of The Web as a labyrinth-esque community landscape tended by and These creators wanted to enable pick-your-own-path experiences, while also providing enough signposts that people didn't feel lost in their new, strange medium.
The early web debates around this became known as – the issue of how to give web users just enough guidance to freely explore the web, without forcing them into pre-defined browsing experiences. The eternal struggle to find the right balance of chaos and structure.
""Unplanned hypertext sprawl is wilderness: complex and interesting, but uninviting. Interesting things await us in the thickets, but we may be reluctant to plough through the brush, subject to thorns and mosquitoes""
While Mark's essay was concerned with different problems to the ones we face on the web today, its core ethos feels aligned with our emerging understanding of digital gardening. It captures the desire for exploratory experiences, a welcoming of digital weirdness, and a healthy amount of resistance to top-down structures.
After Mark's essay the term digital gardening goes quiet for nearly a decade.
Digital Puttering on Twitter
In April of 2007 when Tweets first started ringing through the internet airwaves, Rory Sutherland (oddly, the vice president of Ogilvy Group) used the term ""digital gardening"", but defined it as ""faffing about syncing things, defragging - like pruning for young people""
The next dozen mentions on Twitter all followed this sentiment – people were using the term as a way to describe digital maintenance - the act of cleaning up one's digital space. The focus was on sorting, weeding, pruning, and decluttering, rather than growing and cultivating. People mentioned cleaning out private folders, codebases, and photo albums as the focus of their gardening efforts.
These people were digital puttering more than gardening.
Since none of these folks reference to the earlier nineties notion of digital gardening, or mention issues of hypertext navigation, this use of the word feels like a brief tangent. Given the tiny size of Twitter in the early days, these people probably belonged to the same social flocks and were riffing off one another. It's not necessarily part of the mainstream narrative we're tracking, but shows there's not one strict meaning to the term.
That said, some degree of faffing about, sorting, and pruning are certainly part of the practice of digital gardening. Though best enjoyed in moderation.
Gardens, Streams, and Caufield's Metaphors
At the 2015 Digital Learning Research Network, Mike Caufield delivered a keynote on . It later becomes that lays the foundations for our current understanding of the term. If anyone should be considered the original source of digital gardening, it's Caufield. They are the first to lay out this whole idea in poetic, coherent words.
Caufield makes clear digital gardening is not about specific tools – it's not a Wordpress plugin, Gastby theme, or Jekyll template. It's a different way of thinking about our online behaviour around information - one that accumulates personal knowledge over time in an explorable space.
Caufield's main argument was that we have become swept away by streams – the collapse of information into single-track timelines of events. The conversational feed design of email inboxes, group chats, and InstaTwitBook is fleeting – they're only concerned with self-assertive immediate thoughts that rush by us in a few moments.
This is not inherently bad. Streams have their time and place. Twitter is a force-multiplier for exploratory thoughts and delightful encounters once you fall in with the right crowd and learn to play the game.
But streams only surface the Zeitgeisty ideas of the last 24 hours. They are not designed to accumulate knowledge, connect disparate information, or mature over time.
The garden is our counterbalance. Gardens present information in a richly linked landscape that grows slowly over time. Everything is arranged and connected in ways that allow you to explore. Think about the way Wikipedia works when you're hopping from to to . It's hyperlinking at it's best. You get to actively choose which curiosity trail to follow, rather than defaulting to the algorithmically-filtered ephemeral stream. The garden helps us move away from time-bound streams and into contextual knowledge spaces.
""The Garden is the web as topology. The web as space. It’s the integrative web, the iterative web, the web as an arrangement and rearrangement of things to one another.""
Carrying on Caufield
Good ideas take time to germinate, and Caufield's vision of the personal garden didn't reach critical mass right off the bat. It lay dormant, waiting for the right time and the right people to find it.
In late 2018 the corner of Twitter I hang out in began using the term more regularly – folks began passing around Caufield's original article and experimenting with ways to turn their chronological blogs into exploratory, interlinked gardens.
Tom Critchlow's 2018 article was one of the main kick-off points. Tom read Caufield's essay and began speculating on alternative metaphors to frame the way we consume and produce information. They suggested we add campfires to the idea of streams and gardens – the private Slack groups, casual blog rings, and areas where people write in response to one another. While gardens present the ideas of an individual, campfires are conversational spaces to exchange ideas that aren't yet fully formed.
Tom piece was shortly followed by Joel Hooks' in early 2019. Joel focused on the process of digital gardening, emphasising the slow growth of ideas through writing, rewriting, editing, and revising thoughts in public. Instead of slapping Fully Formed Opinions up on the web and never changing them.
Joel also added Amy Hoy's post to the pile of influential ideas that led to our current gardening infatuation. While not specifically about gardening, Amy's piece gives us a lot of good historical context. In it, she explores the history of blogs over the last three decades, and pinpoints exactly when we all became fixated on publishing our thoughts in reverse chronological order (spoiler: around 2001 with the launch of ).
Amy argues that Moveable Type didn't just launch us into the ""Chronological Sort Era"". It also killed the wild, diverse, hodge-podge personalisation of websites that characterised the early web. Instead of hand-coding your own layout and deciding exactly how to arrange the digital furniture, we began to enter the age of standardised layouts. Plug n' play templates that you drop content into became the norm. It became harder and more technically involved to edit the HTML & CSS yourself.
""Suddenly people weren’t creating homepages or even web pages... they were writing web content in form fields and text areas inside a web page.""
Many people have lamented the web's slow transition from unique homepages to a bland ocean of generic Wordpress themes. Digital gardening is part of the pushback against the limited range of vanilla web formats and layouts we now for granted.
Over the course 2019 and early 2020, more and more people began riffing on the concept. Shaun Wang compiled the . Anne-Laure Le Cunff published a popular guide to setting up . The IndieWeb community hosted a to discuss the history of commonplace books, personal wikis, and memory palaces.
By late 2020 this whole concept had attracted enough attention for the MIT Tech Review to write on it. Perhaps this is the watershed moment when a Twitter buzzword has ""made it.""
Digital Gardening's Fertile Soil
What made our current historical moment the right time for digital gardening to take off?
The timing coincided with a few complimentary ideas and communities rallying around personal knowledge systems, note-taking practices, and reimagining tools for blogging. The scene was ripe for new ideas around curating and sharing personal knowledge online.
Many of the people who jumped on the early digital gardening bandwagon were part of communities like...
- The collective – a group that has been championing independent web spaces outside the walled gardens of Instatwitbook for nearly a decade.
- Users of the note-taking app – Roam pioneered new ways of interlinking content and strongly appeals to people trying to build sprawling knowledge graphs.
- Followers of Tiago Forte's course which popularised the idea of actively curating personal knowledge.
- People rallying around the ethos that encourages continuously creating 'learning exhaust' in the form of notes and summaries.
Developer-led Gardening
Many of these early adopters were people who understood how to build websites – either professional developers or enthusiastic hobbyists. Any kind of novel experimentation with the web requires knowing a non-trivial amount of HTML, CSS, and JS. Not to mention all the surrounding infrastructure required actually to get a site live. Developers took to the idea because they already had the technical ability to jump in play around with what garden-esque websites might look like.
The current state of web development helped here too. While it feels like we've been in a slow descent into a horrifyingly complex and bloated web development process, a number of recent tools have made it easier to get a fully customised website up and running. Services like and have taken the pain out of deployment. Static site generators like , , and make it easier to build sophisticated websites that auto-generate pages, and take care of grunt work like optimising load time, images, and SEO. These services are trying to find a happy middle ground between tediously hand-coding solutions, and being trapped in the restrictions of Wordpress or Squarespace.
While developers were the first on the scene, plenty of writers, researchers, and note-taking enthusiasts have been drawn to the idea of digital gardening. To help folks without programming skills join in, there's been a surge in templates and platforms that allow people to build their own digital gardens without touching a ton of code. I've written an entire guide to if you fall into that category.
Tools like , , and are all great options. Many of them offer fancy features like nested folders, , footnotes, and visual graphs.
However, many of these no-code tools still feel like cookie-cutter solutions. Rather than allowing people to design the and spatial layouts of their gardens, they inevitably force people into pre-made arrangements. This doesn't meant they don't ""count,” as ""real” gardens, but simply that they limit their gardeners to some extent. You can't design different types of links, novel features, experimental layouts, or custom architecture. They're pre-fab houses instead of raw building materials.
The Six Patterns of Gardening
In all the recent gardening flurry, we've run into the inevitable confusion around how to define the term.
There are contested ideas about what qualifies as a garden, what the core ethos should focus on, and whether it's worthy of a new label at all. What exactly makes a website a digital garden as opposed to just another blog?
After reading all the existing takes on the term, observing a wide variety of gardens, and collecting some of the , I've identified a few key qualities they all share.
There are a few guiding principles, design patterns and structures people are rallying around. This amounts to a kind of digital gardening .
1. Topography over Timelines
Gardens are organised around contextual relationships and associative links; the concepts and themes within each note determine how it's connected to others.
This runs counter to the time-based structure of traditional blogs: posts presented in reverse chronological order based on publication date.
Gardens don't consider publication dates the most important detail of a piece of writing. Dates might be included on posts, but they aren't the structural basis of how you navigate around the garden. Posts are connected to other by posts through related themes, topics, and shared context.
One of the best ways to do this is through – links that make both the destination page and the source page visible to the reader. This makes it easy to move between related content.
Because garden notes are densely linked, a garden explorer can enter at any location and follow any trail they link through the content, rather than being dumped into a ""most recent” feed.
Dense links are essential, but gardeners often layer on other ways of exploring their knowledge base. They might have , , tags and filtering functionality, , , or listing notable and popular content.
Many entry points but no prescribed pathways.
2. Continuous Growth
Gardens are never finished, they're constantly growing, evolving, and changing. Just like a real soil, carrot, and cabbage garden.
The isn't how we usually think about writing on the web. Over the last decade, we've moved away from casual live journal entries and formalised our writing into articles and essays. These are carefully crafted, edited, revised, and published with a timestamp. When it's done, it's done. We act like tiny magazines, sending our writing off to the printer.
This is odd considering editability is one of the main selling points of the web. Gardens lean into this – there is no ""final version” on a garden. What you publish is always open to revision and expansion.
Gardens are designed to evolve alongside your thoughts. When you first have an idea, it's fuzzy and unrefined. You might notice a pattern in your corner of the world, but need to collect evidence, consider counter-arguments, spot similar trends, and research who else has thunk such thoughts before you. In short, you need to do your homework and critically think about it over time.
In performance-blog-land you do that thinking and researching privately, then shove it out at the final moment. A grand flourish that hides the process.
In garden-land, that process of researching and refining happens on the open internet. You post ideas while they're still ""seedlings,” and tend them regularly until they're fully grown, respectable opinions.
This has a number of benefits:
- You're freed from the pressure to get everything right immediately. You can test ideas, get feedback, and revise your opinions like a good internet citizen.
- It's low friction. Gardening your thoughts becomes a daily ritual that only takes a small amount of effort. Over time, big things grow.
- It gives readers an insight into your writing and thinking process. They come to realise you are not a magical idea machine banging out perfectly formed thoughts, but instead an equally mediocre human doing The Work of trying to understand the world and make sense of it alongside you.
This all comes with an important caveat; gardens make their imperfection known to readers. Which brings us to the next pattern...
3. Imperfection & Learning in Public
Gardens are imperfect by design. They don't hide their rough edges or claim to be a permanent source of truth.
Putting anything imperfect and half-written on an ""official website” may feel strange. We have all been trained to behave like tiny, performative corporations when it comes to presenting ourselves in digital space. Blogging evolved in the culture of Millenialism as a way to Promote Your Personal Brand™ and market your SEO-optimized Content.
Weird, quirky personal blogs of the early 2000's turned into cleanly crafted brands with publishing strategies and media campaigns. Everyone now has a modern minimalist logo and an LLC.
Digital gardening is the response to the professional personal blog; it's both intimate and public, weird and welcoming. It's less performative than a blog, but more intentional and thoughtful than a Twitter feed. It wants to build personal knowledge over time, rather than engage in banter and quippy conversations.
Think of it as a spectrum. Things we dump into private WhatsApp group chats, DMs, and cavalier Tweet threads are part of our chaos streams - a continuous flow of high noise / low signal ideas. On the other end we have highly performative and cultivated artefacts like published books that you prune and tend for years.
Gardening sits in the middle. It's the perfect balance of chaos and cultivation.
This ethos of imperfection opens up a world of possibility that performative blogging shut down. First, it enables you to ; the practice of sharing what you learn as you're learning it, not a decade later once you're an ""expert.”
This freedom of course comes with great responsibility. Publishing imperfect and early ideas requires that we make the status of our notes clear to readers. You should include some indicator of how ""done” they are, and how much effort you've invested in them.
This could be with a simple categorisation system. I personally use an overly horticultural metaphor:
- 🌱 Seedlings for very rough and early ideas
- 🌿 Budding for work I've cleaned up and clarified
- 🌳 Evergreen for work that is reasonably complete (though I still tend these over time).
I also include the dates I planted and last tended a post so people get a sense of how long I've been growing it.
Other gardeners include an epistemic status on their posts – a short statement that makes clear how they know what they know, and how much time they've invested in researching it.
was one of the earliest and most consistent gardeners to offer meta-reflections on their work. Each entry comes with:
- topic tags
- start and end date
- a stage tag: draft, in progress, or finished
- a certainty tag: impossible, unlikely, certain, etc.
- 1-10 importance tag
These are all explained in their , which is worth reading if you're designing your own epistemological system.
Devon Zuegal is another notable gardener who has epistemic status and epistemic effort on their posts, indicating both their certainty level about the material, and how much effort went into making it. They also make a strong case for as a feature, not a bug.
In a similar vein, Shawn Wang has written the Digital Gardening which I adore and ascribe to. They ask the reader to allow the writer to be wrong, offer constructive criticism, and attribute their work. They ask gardeners to be considerate of others (don't share private information or name and shame), offer epistemic disclosure, and respond to feedback.
All of these design patterns feed our growing desire for transparency, meta information, and breadcrumbs back to the source of ideas.
4. Playful, Personal, and Experimental
Gardens are non-homogenous by nature. You can plant the same seeds as your neighbour, but you'll always end up with a different arrangement of plants.
Digital gardens should be just as unique and particular as their vegetative counterparts. The point of a garden is that it's a personal playspace. You organise the garden around the ideas and mediums that match your way of thinking, rather than off someone else's standardised template.
Ideally, this involves experimenting with the native languages of the web – HTML, CSS, and JavaScript. They're the most flexible and robust tools we have for building interconnected knowledge online. Gardens are a chance to question the established norms of a 'personal website', and make space for weirder, wilder experiments.
That said, I should acknowledge that jumping into full-on web development is simply beyond the abilities and interests of many people. There is still room for personalisation and play if you're using a pre-made template or service – it'll just be within the constraints of that system.
One goal of these hyper-personalised gardens is deep contextualisation. The overwhelming lesson of the Web 2.0 social media age is that dumping millions of people together into decontextualised social spaces is a shit show. Devoid of any established social norms and abstracted from our specific cultural identities, we end up in awkward, aggravating exchanges with people who are socially incoherent to us. We know nothing of their lives, backgrounds, or belief systems, and have to assume the worst. Twitter only offers us a 240 character bio. Facebook pre-selects the categories it deems important about you – relationship status, gender, hometown.
Gardens offer us the ability to present ourselves in forms that aren't cookie cutter profiles. They're the higher-fidelity version, complete with quirks, contradictions, and complexity.
5. Intercropping & Content Diversity
Gardens are not just a collection of interlinked words. While linear writing is an incredible medium that has served us well for a little over 5000 years, it is daft to pretend working in a single medium is a sufficient way to explore complex ideas.
It is also absurd to ignore the fact we're living in an audio-visual cornucopia that the web makes possible. Podcasts, videos, diagrams, illustrations, interactive web animations, academic papers, tweets, rough sketches, and code snippets should all live and grow in the garden.
Historically, monocropping has been the quickest route to starvation, pests, and famine. Don't be a lumper potato farmer while everyone else is sustainably intercropping.
6. Independent Ownership
Gardening is about claiming a small patch of the web for yourself, one you fully own and control.
This patch should not live on the servers of Facebook, LinkedIn, Twitter, Instagram (aka. also Facebook), or Medium. None of these platforms are designed to help you slowly build and weave personal knowledge. Most of them actively fight against it.
If any of those services go under, your writing and creations sink with it (crazier things have happened in the span of humanity). None of them have an easy export button. And they certainly won't hand you your data in a transferable format.
Independently owning your garden helps you plan for long-term change. You should think about how you want your space to grow over the next few decades, not just the next few months.
If you give it a bit of forethought, you can build your garden in a way that makes it easy to transfer and adapt. Platforms and technologies will inevitably change. Using old-school, reliable, and widely used web native formats like HTML/CSS is a safe bet. Backing up your notes as flat markdown files won't hurt either.
Keeping your garden on the open web also sets you up to take part in the future of gardening. At the moment our gardens are rather solo affairs. We haven't figure out how to make them multi-player. But there's an enthusiastic community of developers and designers trying to fix that. It's hard to say what kind of libraries, frameworks, and design patterns might emerge out of that effort, but it certainly isn't going to happen behind a Medium paywall.
This is all my take on gardening, but knowledge and neologisms always live within communities. No one owns The Official Definition of digital gardening. Numerous people have contributed to the growing conversation and you should read their thoughts as well.",1
418,"Akaike H (1998) Information theory and an extension of the maximum likelihood principle. Selected papers of Hirotugu Akaike. Springer, New York, pp 199–213
Chapter
Google Scholar
Anesio AM, Hodson AJ, Fritz A, Psenner R, Sattler B (2009) High microbial activity on glaciers: importance to the global carbon cycle. Glob Change Biol 15:955–960
Article
Google Scholar
Anesio AM, Laybourn-Parry J (2012) Glaciers and ice sheets as a biome. Trends Ecol Evol 27:219–225
Article
Google Scholar
Anesio AM, Lutz S, Chrismas NA, Benning LG (2017) The microbiome of glaciers and ice sheets. NPJ Biofilms Microbiomes 3:1–11
Article
Google Scholar
Armstrong WH, Anderson RS, Allen J, Rajaram H (2016) Modeling the WorldView-derived seasonal velocity evolution of Kennicott Glacier, Alaska. J Glaciol 234:763–777
Article
Google Scholar
Belkina OA, Vilnet AA (2015) Some aspects of the moss population development on the Svalbard glaciers. Czech Polar Rep 5:160–175
Article
Google Scholar
Benninghoff WS (1955) Jökla-mýs. J Glaciol 2:514–515
Article
Google Scholar
Castro-Santos T, Haro A, Walk S (1996) A passive integrated transponder (PIT) tag system for monitoring fishways. Fish Res 28:253–261
Article
Google Scholar
Cook J, Edwards A, Takeuchi N, Irvine-Fynn T (2016) Cryoconite: the dark biological secret of the cryosphere. Prog Phys Geog 40:66–111
Article
Google Scholar
Coulson S, Midgley N (2012) The role of glacier mice in the invertebrate colonisation of glacial surfaces: the moss balls of the Falljökull, Iceland. Polar Biol 35:1651–1658
Article
Google Scholar
Deevey ES Jr (1947) Life tables for natural populations of animals. Q Rev Biol 22:283–314
Article
Google Scholar
Dial RJ, Becker M, Hope AG, Dial CR, Thomas J, Slobodenko KA, Golden TS, Shain DH (2016) The role of temperature in the distribution of the glacier ice worm, Mesenchytraeus solifugus (Annelida: Oligochaeta: Enchytraeidae). Arct Antarct Alp Res 48:199–211
Article
Google Scholar
Eythórsson J (1951) Correspondence Jökla-mys. J Glaciol 1:503
Article
Google Scholar
Festa-Bianchet M, Gaillard JM, Côté SD (2003) Variable age structure and apparent density dependence in survival of adult ungulates. J Anim Ecol 72:640–649
Article
Google Scholar
Ganey GQ, Loso MG, Burgess AB, Dial RJ (2017) The role of microbes in snowmelt and radiative forcing on an Alaskan icefield. Nat Geosci 10:754–759
CAS
Article
Google Scholar
Gardner AS, Moholdt G, Cogley JG, Wouters B, Arendt AA, Wahr J, Berthier E, Hock R, Pfeffer WT, Kaser G (2013) A reconciled estimate of glacier contributions to sea level rise: 2003 to 2009. Science 340:852–857
CAS
Article
Google Scholar
Heusser CJ (1972) Polsters of the moss Drepanocladus berggrenii on Gilkey Glacier, Alaska. Bul Torrey Bot Club 99:34–36
Article
Google Scholar
Hotaling S, Hood E, Hamilton TL (2017a) Microbial ecology of mountain glacier ecosystems: biodiversity, ecological connections and implications of a warming climate. Environ Microbiol 19:2935–2948
Article
Google Scholar
Hotaling S, Finn DS, Joseph Giersch J, Weisrock DW, Jacobsen D (2017b) Climate change and alpine stream biology: progress, challenges, and opportunities for the future. Biol Rev 92:2024–2045
Article
Google Scholar
Hotaling S, Shain DH, Lang SA, Bagley RK, Lusha M, Weisrock DW, Kelley JL (2019) Long-distance dispersal, ice sheet dynamics, and mountaintop isolation underlie the genetic structure of glacier ice worms. Proc R Soc B 286:20190983
Article
Google Scholar
Hotaling S, Wimberger PH, Kelley JL, Watts HE (2020) Macroinvertebrates on glaciers: a key resource for terrestrial food webs? Ecology 101:e02947
Article
Google Scholar
Hurvich CM, Tsai C-L (1989) Regression and time series model selection in small samples. Biometrika 76:297–307
Article
Google Scholar
Larsen C, Burgess E, Arendt A, O'neel S, Johnson A, Kienholz C, (2015) Surface melt dominates Alaska glacier mass balance. Geophys Res Lett 42:5902–5908
Article
Google Scholar
Lebreton J-D, Burnham KP, Clobert J, Anderson DR (1992) Modeling survival and testing biological hypotheses using marked animals: a unified approach with case studies. Ecol Monogr 62:67–118
Article
Google Scholar
Loison A, Festa-Bianchet M, Gaillard J-M, Jorgenson JT, Jullien J-M (1999) Age-specific survival in five populations of ungulates: evidence of senescence. Ecology 80:2539–2554
Article
Google Scholar
Mann D, Edwards J, Gara R (1980) Diel activity patterns in snowfield foraging invertebrates on Mount Rainier, Washington. Arct Antarct Alp Res 12:359–368
Article
Google Scholar
Millar JS, Zammuto RM (1983) Life histories of mammals: an analysis of life tables. Ecology 64:631–635
Article
Google Scholar
Perez FL (1991) Ecology and morphology of globular mosses of Grimmia longirostris in the Paramo de Piedras Blancas, Venezuelan Andes. Arct Antarct Alp Res 23:133–148
Article
Google Scholar
Porter P, Evans A, Hodson A, Lowe A, Crabtree M (2008) Sediment–moss interactions on a temperate glacier: Falljökull, Iceland. Ann Glaci 48:25–31
Article
Google Scholar
Roe GH, Baker MB, Herla F (2017) Centennial glacier retreat as categorical evidence of regional climate change. Nat Geosci 10:95–99
CAS
Article
Google Scholar
Rosvold J (2016) Perennial ice and snow-covered land as important ecosystems for birds and mammals. J Biogeogr 43:3–12
Article
Google Scholar
Shacklette HT (1966) Unattached moss polsters on Amchitka Island, Alaska. Bryologist 69:346–352
Article
Google Scholar
Stibal M, Bradley JA, Edwards A, Hotaling S, Zawierucha K, Rosvold J, Lutz S, Cameron KA, Mikucki JA, Kohler TJ, Šabacká M, Anesio AM (2020) Glacial ecosystems are essential to understanding biodiversity responses to glacier retreat. Nat Ecol Evol. https://doi.org/10.1038/s41559-020-1163-0
Article
PubMed
Google Scholar
Uetake J, Tanaka S, Hara K, Tanabe Y, Samyn D, Motoyama H, Imura S, Kohshima S (2014) Novel biogenic aggregation of moss gemmae on a disappearing African glacier. PLoS ONE 9:e112510
Article
Google Scholar
Van der Walt S, Schönberger JL, Nunez-Iglesias J, Boulogne F, Warner JD, Yager N, Gouillart E, Yu T (2014) Scikit-image: image processing in Python. PeerJ 2:e453
Article
Google Scholar",5
419,"Down and Out in the Magic Kingdom
This article needs additional citations for verification. (June 2013)
|Author||Cory Doctorow|
|Country||Canada|
|Language||English|
|Genre||Science fiction, Social Science Fiction, Cyberprep|
|Publisher||TOR|
Publication date
|1 February 2003|
|Media type||Print (hardcover & paperback) & ebook|
|Pages||208|
|ISBN||0-7653-0436-8 (hardcover) ISBN 0-7653-0953-X (paperback)|
|OCLC||50645482|
|813/.6 21|
|LC Class||PS3604.O27 D68 2003|
|Followed by||Truncat|
Down and Out in the Magic Kingdom is a 2003 science fiction book, the first novel by Canadian author and digital-rights activist Cory Doctorow. Concurrent with its publication by Tor Books, Doctorow released the entire text of the novel under a Creative Commons noncommercial license on his website, allowing the whole text of the book to be freely read and distributed without needing any further permission from him or his publisher.
The novel was nominated for the Nebula Award for Best Novel in 2004.
Plot summary[edit]
This future history book takes place in the 22nd century, mostly in Walt Disney World. Disney World is run by rival adhocracies, each dedicated to providing the best experience to the park's visitors and competing for the Whuffie the guests offer.
The story is told in first person by Julius, whose old college buddy Dan used to be one of the most popular people in the country (as measured by Whuffie). Julius and girlfriend Lil are working with the committee (called an ad hoc) that oversees the Magic Kingdom's Liberty Square. Dan, who has hit rock bottom and lost all his Whuffie, doesn't believe in rejuvenation and wishes to die, but not while he's at rock bottom. He moves in with Julius and Lil in order to rebuild his life. At the park, Julius is murdered and soon refreshed. By the time he wakes up, Debra's ad hoc group has taken control of the Hall of Presidents, and is planning to replace its old-fashioned animatronic robots with the synthetic memory imprinting of the experience of being the president for a moment. Julius believes that this rival committee had him killed as a distraction so that they could seize the Hall in the interim.
Fearing that they will next try to revamp his favorite ride, the Haunted Mansion, he resolves to take a stand against the virtualization of the park, endangering his relationship with both Lil and Dan; eventually Lil leaves Julius for Dan. Julius finally ""cracks"" when he sees his dreams turned to dust and he bashes up the attractions in the Hall of Presidents, in the process also damaging his own cranial interface to the point that he can no longer back himself up. This pushes his Whuffie to ground level when he is caught and gives Debra and her colleagues enough ""sympathy Whuffie"" to take over the Haunted Mansion, by invitation of the same fans that Julius had recruited to work in the Mansion.
Dan leaves Lil, Julius is kicked out of the ad hoc and his Whuffie hits rock bottom — low enough that others take his possessions with impunity and elevators don't stop for him. Then comes the revelation: a few days before Dan's planned suicide by lethal injection, Dan reveals that it was in fact he who had arranged to kill Julius, in collusion with Debra, in exchange for the Whuffie that her team could give him. Dan had asked one of his converts from his missionary days, a young girl, to do the dirty work. Debra then had herself restored from a backup made before this plan, so that she would honestly believe that she wasn't involved. He makes this public; Debra is thrown out, Julius gets sympathy Whuffie and develops a friendly affection for his sweet young murderer. He never restores himself, because doing so would erase his memories of that entire year, his last with Dan, but lives with his damaged interface. The book is his attempt to manually document the happenings of the previous year so that, when this incarnation is eventually killed by age or accident, his restored backup will have a partial record of the transpiring events. Dan decides not to take a lethal injection, but to deadhead (putting oneself into a voluntary coma) till the heat death of the Universe.
Characters[edit]
- Julius (also known as Jules), the narrator of the book, is more than a century old. His childhood dream is living at Disney World (also known as ""The Magic Kingdom"").
- Lil, age 23, with long red hair and freckles, is Jules' girlfriend. She is 15 percent of Jules' age, but outwardly the same age. She was raised in Walt Disney World.
- Dan is Jules' best male friend. He is a former missionary for the Bitchun utopia who has lost the will to live now that there are no technophobes left to convert.
- Debra is one of the old guard of Disney World and was a comrade of Lil's parents before they went deadhead. She spent a decade in Disneyland Beijing, coding sim-rides.
- Tim is a programmer of synthetic memories.
- Tom and Rita are Lil's parents who were ""members of the original ad hoc that had seized power in Walt Disney World, wresting control from a gang of wealthy former shareholders who had been operating it as their private preserve"".
- Zed (also known as Zoya) is a transhuman who was married to Julius for 18 months, went crazy, and reverted to a backup from before she met Julius.
Cultural cross references[edit]
- Chapter five includes a description of a ""Snow Crash Spectacular parade"" based on Neal Stephenson's book Snow Crash.
- The book contains references to the Beatles song ""Rocky Raccoon"". Julius' girlfriend leaves him for his friend Dan, just as Lil leaves Rocky Raccoon for a man named Dan in the song. At the beginning of the book, Jules and Lil sing some lyrics from the song.
- ""Rangy Lil"" is a character from the science fiction classic ""Time Enough for Love"" by Robert Heinlein. The character Dan in this book says: ""Lil, you are one rangy cowgirl.""
- Doctorow's short story ""Truncat"" is also set in the Bitchun Society, sometime after the events of Down and Out.
- Doctorow's short story ""I, Row Boat"", a play on words of Isaac Asimov's I, Robot, also appears to be set in the same universe (though more distantly future), with references to artificial uploading and downloading of intelligence, but no explicit mention of the Bitchun Society or Whuffie.
- The title is a reference to George Orwell's Down and Out in Paris and London.
Licensing[edit]
On February 12, 2004, Doctorow re-licensed his book under a Creative Commons Attribution-Noncommercial-Share Alike (by-nc-sa) license. Under the new license, one can now make derivative works from the book without permission, provided the license and attribution is retained with each new work and the derivatives are not used commercially. Already, fans of the book have begun Russian and Spanish translations, an audio book version, and several amusing re-arrangements of the text. Doctorow has noted that he is pleased that people are building on his work, and that he hopes that further innovations will follow.
Despite these measures, in 2007 invalid DMCA takedown notices were sent by Science Fiction Writers of America (SFWA) with regard to this novel.[1][2][3] Cory Doctorow said ""Down and Out in the Magic Kingdom was the first novel released under a Creative Commons license, and I've spent the past four years exhorting fans to copy my work and share it. Now I've started to hear from readers who've seen this notice and concluded that I am a hypocrite who uses SFWA to send out legal threats to people who heeded my exhortation.""[1]
See also[edit]
References[edit]
- ^ a b Arstechnica article Worse than Vogon poetry: bogus DMCA takedowns stun sci-fi lovers published August 31, 2007
- ^ Chris Meadows, SFWA issues mistakenly broad DMCA takedown notice—unwittingly harming sci-fi writers such as Cory Doctorow Archived December 5, 2011, at the Wayback Machine, August 31, 2007, TeleRead
- ^ Cory Doctorow, Science Fiction Writers of America abuses the DMCA, August 30, 2007, boingboing
External links[edit]
- The official site for the book on Cory Doctorow's homepage. Includes the full, free text of the book in many downloadable formats.
- Down and Out in the Magic Kingdom at Project Gutenberg
- 2003 Canadian novels
- 2003 science fiction novels
- Novels by Cory Doctorow
- Debut fantasy novels
- Transhumanist books
- Creative Commons-licensed novels
- Postcyberpunk novels
- Walt Disney World in fiction
- Novels set in the 22nd century
- Novels set in Orlando, Florida
- Tor Books books
- Augmented reality in fiction
- Social reputation in fiction
- Utopian novels
- Smartglasses in fiction
- Novels set in amusement parks
- 2003 debut novels",8
420,"TOP
SHARE
SHARE ON:
|
|
AXA Future Risks Report 2022
TOP
October 24, 2022
AXA Future Risks Report 2022
Climate change has become the number one concern around the world
In the News
1 minute
Tags:
In the News
Ukraine: update on our actions
Read more
AXA is stepping up its efforts to reduce its energy consumption
Read more
Half Year 2022 Earnings
Read more
Green Business & Inclusive Protection 2023 insurance targets
Read more",8
421,"Over the last six years, companies have had to grapple with five major “uncertainty shocks”: First it was Brexit in 2016, followed by the U.S. presidential election, China-U.S. trade-tensions, the Covid-19 pandemic, and in 2022 the Ukraine war.
These shocks reflect a new normal of greater global turbulence, driven by domestic and international political fragmentation. And these are subtly different from the economic shocks that executives may be more used to thinking about.
An uncertainty shock may coincide with a typical economic shock, as in the case of Russia’s invasion of Ukraine, which disrupted energy and food supplies and therefore raised their prices. But it doesn’t have to: The U.S. election created significant uncertainty for companies, even before it had any direct effect on the real economy.
Our research suggests these uncertainty shocks have real consequences for companies, and that they’re becoming more common. Businesses should internalize this and adjust for the new reality in three ways we outline below: by closely tracking global events, paying for flexibility, and considering contingency plans.
Measuring Uncertainty
Uncertainty is, by its very nature, hard to define. We have been researching its economic impact for almost 25 years, and find it is best to take a practical approach. The Economist Intelligence Unit produces standardized monthly reports of about 30 pages in length for over 140 countries. We counted the frequency of the word “uncertainty” (and its variants) in these reports, which are sourced from a range of reporters and analysts following each country, edited into a consistent format, and aimed at national and multinational businesses and investors. To make the index comparable across countries we adjusted the raw counts by the total number of words in each report. And then we weighted the reports by each country’s GDP, to create a measure of uncertainty across the global economy.
Here’s what that measure looks like for the last three decades.
Since the 2008 global financial crisis and subsequent European debt crisis, economic and policy uncertainty has been rising. It surged in 2016 and reached all-time highs in 2020 with the onset of the Covid-19 pandemic. It fell in 2021, as Covid-19 started to become endemic in many parts of the world, but has picked up again since the Russian invasion of Ukraine.
One advantage of our text-based approach is that we can break out the drivers of uncertainty, by analyzing which words appear alongside mentions of uncertainty in our dataset. From that approach, we see that in June 2016 uncertainty arising from the UK Brexit situation surged after the unexpected Leave vote. This was overtaken by uncertainty arising from the U.S. after its presidential election. In 2018 the China-U.S. trade tensions began to cause major uncertainty for countries globally, becoming the biggest single driver. In 2020 the Covid-19 pandemic surged as a key driver of global uncertainty, only dropping back recently to be overtaken by uncertainty arising from the war in Ukraine and the renewed trade uncertainty associated with sanctions to Russia.
See more HBR charts in Data & Visuals
Responding to Uncertainty
Our view is that these global shocks are here to stay. While each event is different, the common theme is greater geo-economic fragmentation and more polarized politics in the U.S. and Europe. These trends are powering the rise in global uncertainty and they are not going away.
To cope with this we advise organizations to take three steps.
First, it is more valuable than ever to pay attention to global economics and politics. In calm times it makes sense for firms to focus on markets, following the old saying that “the business of business is business.” But in turbulent times there is value in following current events to avoid being caught by surprise by global shocks. Indeed, for larger firms there can even be value in trying to steer the political process through engagement and lobbying. Invest in the people and tools to track geopolitics more closely, with special focus on the issues and regions that most affect your business.
Second, greater uncertainty makes flexibility more valuable. Therefore, be willing to spend more to keep your options open. This involves anything from signing shorter leases, leasing rather than buying property, hiring contractors rather than permanent staff, and renting rather than buying equipment. Pay more to avoid long-term commitments as these make it hard to nimble in the face of major shocks.
Finally, use contingency planning. When major shocks happen – like the war in Ukraine – there is huge value to making rapid decisions. Firms which have contingency plans in place can act faster and reduce the risk of mistakes. You don’t have to perfectly predict the specifics of the next shock to do this: Companies can model more generic scenarios, like a steep decline in consumer demand, the failure of a key supplier, or an increase in the cost of doing business in a specific country. Making contingency plans is like paying for insurance: You hope to never have to use them, but if you do, they can be invaluable. With greater global volatility this is likely to happen more than ever, so the value of contingency plans has never been higher.",2
422,"The World’s Whitest Paint May Soon Help Cool Airplanes and Spacecraft
The ultra-white color reflects up to 97.9 percent of sunlight and may reduce our reliance on air conditioning
On a hot tarmac in the peak of summer, an airplane’s crew has little choice but to run the air conditioner to keep themselves and their passengers cool. But soon, crews could become less reliant on the A.C., thanks to a new lightweight, ultra-white paint that can reflect up to 97.9 percent of sunlight.
This engineered paint has the potential to cool the exteriors of airplanes, cars, trains and even spacecraft. As the planet warms because of human-caused climate change, the paint could be an innovative, passive way to keep spaces—and people—cool. At the same time, it could reduce our reliance on energy-guzzling and heat-emitting air conditioners that contribute to global warming.
The paint is an improvement on an earlier formula, which was too thick to be applied to anything but stationary structures. Now, researchers say they’ve refined the paint with an ultra-thin formula that’s safe for coating vehicles. In a paper published Monday in the journal Cell Reports Physical Science, the team shared the details of their new-and-improved product.
“This light weight opens the doors to all kinds of applications,” says George Chiu, a Purdue University mechanical engineer, in a statement.
In spring last year, a team from Purdue unveiled the first ultra-white paint—a product so white that it set a Guinness World Record. The key was barium sulfate, which allowed the paint to reflect 98.1 percent of sunlight and cool surfaces by up to 19 degrees Fahrenheit compared to their surroundings.
For comparison, commercially available paints on the market today can only reflect 80 to 90 percent of sunlight, meaning they absorb a lot more light and heat. The ultra-white paint, meanwhile, cools surfaces by emitting more heat than it retains—and it doesn’t use any electricity.
“Air conditioners can cool your house, but they move the heat from inside the house to outside—the heat is still in the city, it’s still on the Earth,” said Xiulin Ruan, a mechanical engineer at Purdue who helped develop the paint, to Smithsonian magazine last year. “Our paint does not use any power, but, more importantly, it sends the heat to space. The heat doesn’t stay on the Earth, so that really helps the Earth to cool down and can stop the warming trend.”
To achieve those groundbreaking results, however, the engineers had to paint a layer that was at least 400 microns thick. That thickness works for strong, stationary structures, like the roof of a building or home. But for vessels that move, as well as objects with specific size and weight requirements, the paint really needs to be thinner and lighter, according to the researchers.
So, the engineers went back to the lab and began tinkering with the paint’s chemical composition. Their new paint uses hexagonal boron nitride, a substance often used in lubricants, to give it a blindingly white hue. The hexagonal boron nitride scatters sunlight to reflect up to 97.9 percent of the sun’s rays, and it gets applied at a thickness of just 150 microns. The new paint is also highly porous, with voids of air that helped drop its weight by about 80 percent compared to the earlier version, per the researchers.
Making the paint lighter and thinner should, in theory, make it useful for a wider array of applications. In the time since the first paint came out, Ruan has been contacted by spacecraft manufacturers, architects and makers of clothes and shoes who were looking for a lighter-weight version, per the statement. Ruan says the team is currently in discussions to commercialize the paint.
Widespread adoption should, in theory, make it an even more viable tool for combating climate change in the long run, researchers say.
“The paint has the benefits of saving on electric bills and at the same time contributing to saving the earth,” University of Tennessee Knoxville mechanical engineer Xiangyu Li, who helped develop the paint while studying at Purdue but is not an author of the new paper, said to the Indianapolis Star's Sarah Bowman last year. ""It connects with everyone.”",4
423,"To continue, please click the box below to let us know you're not a robot.
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.
For inquiries related to this message please contact our support team and provide the reference ID below.",7
424,"The Death Cheaters
The members of Longevity House are united by two things: a willingness to hand over $100,000 and a burning desire to live forever. Inside the weird world of cryotherapy, biocharging and fecal transplants
Last fall, a group of 30 people gathered at an Etobicoke estate to sample the latest in life-extension innovations. They sipped brain-boosting beverages laced with lion’s mane mushrooms and garnished with grapefruit, participated in a breathwork session and soaked up the electromagnetic pulses of the BioCharger, a $20,000 device that looks like a giant blender, sounds like a bionic mosquito and is purported to fight chronic disease, brain fog and flagging libido, among many other ailments. The evening was a soft launch for Longevity House, a private members’ club for Toronto’s burgeoning community of biohackers.
The price tag, $100,000 for a lifetime membership, was staggering. The promise, even more so: a chance to live longer, possibly to 120 years old. And not just longer but better, free from chronic illness and cognitive decline, by which standard six figures starts to sound like a bargain.
In the weeks that followed, word spread about the upstart’s hefty entry fee and astonishing 120-year claim, prompting mean tweets and guffaws at the elitism. All of it was predictable, according to Michael Nguyen, the man behind the venture. “There’s always going to be a certain amount of resistance when you’re leading the charge,” he says. Nguyen is not a doctor or health professional. He has no certifications in the wellness field, which he says is a good thing: “I come at all of this with a different lens. I can ask the right questions.”
Before launching Longevity House, Nguyen was best known as the haberdasher to Toronto’s one-percenters. His men’s tailoring company, Garrison Bespoke, created custom suits for Drake, Ryan Gosling, Jeff Bezos and most of the Raptors. If that career chapter was about making people look good on the surface, he says, Longevity House is about improving people’s lives “from the inside out.” In 2021, Nguyen purchased a $3-million, 7,500-square-foot mansion in Mimico and packed it with the latest in high–performance fitness equipment: alongside the BioCharger is a Tonal (the weightlifting system LeBron James uses), a Carol (an artificially intelligent exercise bike) and a Katalyst (an electronic muscle-stimulation garment that looks like a wetsuit and promises “the world’s most efficient workout”). There is also a red-light therapy room, a full-body vibration plate, a cold plunge tub and a custom-built sauna. Nguyen and his team have secured partner-ships with in-demand health and wellness -practitioners—naturopaths, breathwork specialists, a chakra guy, a therapist who specializes in psychedelics, and functional-medicine doctors who read blood and stool samples like physiological tea leaves.
Biohacking—to “hack” one’s biology for the purposes of optimization—is wellness spiked with gadgetry. It’s New Age woo-woo with internet-age efficiency, Gwyneth Paltrow’s Goop but for tech bros. (As yet, Longevity House has no female members, and on more than one occasion, I heard Joe Rogan’s name spoken with reverence.) What is a biohack, exactly? That’s hard to pin down since the category covers pretty much any health intervention, from the obvious to the outlandish. Yoga is a biohack. So is wearing a Fitbit. So are probiotics and mood-enhancing supplements, forest bathing and looking deeply into another person’s eyes for a full minute. Also DIY experimental gene editing, fecal transplantation and uploading your consciousness onto an external server in the hopes of one day joining a race of cyborgs. (Elon Musk is working on it.) The common thread among biohackers is a mindset that views Mother Nature’s work as a starting point. Our bodies and minds are like early generation iPhones that can be optimized with frequent upgrades.
Another hallmark is an anarchist spirit. Many biohackers are keen to test unproven remedies on themselves—a way to snip through the red tape of the conventional medical-review and scientific process. At Longevity House, there is talk of “decentralizing” health care the same way the crypto community wants to decentralize our financial systems. “The patient is the doctor of the future,” Nguyen told me more than once, quoting a popular biohacking maxim.
Nguyen has been biohacking for the past decade, though he isn’t wild about using the b-word. He says it’s too often associated with the sensational, sci-fi aspects of the lifestyle. He gets why, on the surface, Longevity House may sound like a Handmaid’s Tale spinoff—an exclusive society that grants eternal life to the uber-rich—but he insists that what he’s offering is evidence-based and within Health Canada guidelines. The possibilities, he believes, are endless, from both a health and a business perspective. And, while he can get a little starry-eyed from time to time, he is definitely tapping into something. A recent report from the consulting firm McKinsey and Company projected that biohacking could be a $1.3-trillion industry within the next two decades. Already, here in Toronto, cryotherapy (exposing oneself to subzero temperatures) is quickly becoming the new CrossFit, and stem-cell therapy clinics are popping up faster than old-timey barbershops. Every morning since the start of the pandemic, dozens of cold-water plungers have braved the icy waters of Lake Ontario, and they credit the practice with benefits including mood enhancement, weight loss and a boosted immune system. Extreme temperatures are huge in the biohacking universe, both as a cure for bodily ailments like inflammation and as a good way to build mental and physical resilience through hormetic stress, which is the good kind of stress that we aren’t getting enough of in our convenient, sedentary, screen-timey modern existence. The science is slippery, but few would dispute that getting outside and going for a swim is a healthier choice than more Netflix, Uber Eats and Wordle.
Biohacking was a thing before the pandemic, but the movement has expanded considerably since, spurred by a growing interest in alternative medicine and ever-increasing frustration with the current medical system. The spread of health-based and political conspiracy theories on social media has been a potent biohacking recruitment tool. So has the sense of powerlessness that many have experienced over the course of the pandemic. Toss in the Trump factor, “alternative facts” and the rise of anti-expertise sentiment, and it’s not surprising that a sub-culture promising miracle cures and an alternative to that crook Dr. Fauci is moving into the mainstream.
But the overall trajectory of the movement is worrying. Warning sirens wail like like an overactive BioCharger, and during my first interview with Nguyen, I lay out my skepticism off the jump: I worry that profit motive and medicine don’t (and shouldn’t) mix; I wonder if “decentralization” isn’t just code for transferring power from one flawed institution to another; I’m reasonably confident that there is no such thing as a chakra.
Nguyen is used to the naysayers—history is littered with them. “We’re operating outside the norms of society, which can make people nervous,” he says. And that’s true, isn’t it? Don’t all breakthroughs start off as someone’s outlandish idea? Wasn’t Galileo convicted of heresy for his audacious insistence that the Earth orbits the sun? Isn’t it possible that my staunch allegiance to science will leave me on my deathbed while the biohackers skateboard into the next century? Nguyen is a charming and passionate hype man. But is he a modern Galileo or just a guy cashing in on the latest craze?
The quest to cheat death has existed almost as long as life itself. In the Middle Ages, alchemists set out in search of the Philosopher’s Stone, which promised eternal life to whoever found it. In the 16th century, members of the French nobility drank liquid gold to preserve their youthful glow. Pope Innocent VIII was so keen to turn back the clock that he had himself injected with the blood of children. Bonkers, right? But it’s also the basis for a modern biohack known as “young blood transfusion,” where the older individual is injected intravenously with the plasma of a younger donor. The procedure was performed in private clinics in the US for $10,000 up until 2019, when the FDA clapped down on what it called an unproven and unsafe practice perpetrated by “unscrupulous actors.” To be fair, researchers at Stanford and Berkeley are studying the potential impact that young blood could have on conditions like Alzheimer’s and Parkinson’s. The blood of younger mice has been shown, in small-scale experiments, to have rejuvenating effects on the muscle, brain and liver functions of older rodents. But any practical, mainstream application is way out. For now, the only thing being sold is false hope, which is not just unscrupulous but also an exploitation of distressing medical realities.
And there are many. As of 2020, the average Canadian will spend more than a decade dealing with poor physical and mental health. Biohackers use the term “healthspan” (as opposed to “lifespan”) to describe the period when one is not just alive but physically and mentally fit. The medical system, they argue, is reactive (designed to address problems after they arise) rather than preventative, which is true, due largely to a lack of political will, time and money.
Of course, cash is no object for the uber-rich. Over the past few years, the same tech execs racing one another into space have poured billions into this particular branch of biotech. Elon Musk has spent hundreds of millions of dollars on a cyborg project called Neuralink. Paypal founder Peter Thiel pledged $3.5 million (US) to the Methuselah Foundation, a non-profit that has vowed to make 90 the new 50 by 2030. Former Google Ventures CEO Bill Maris launched Calico (an abbreviation of California Life Company), a project focused on solving death. Jeff Bezos has reportedly invested in Altos Labs, a company that plans to rejuvenate cells in order to reverse disease. Twitter CEO Jack Dorsey is more of a lead-by-example kind of guy, meditating twice daily and walking eight kilometres to his company’s headquarters. He drinks salt water, works at a standing desk near an infrared bulb and practises intermittent fasting, including no food on weekends. The New York Times called Dorsey the Gwyneth Paltrow of Silicon Valley. He has also been criticized for glamorizing what most health professionals see as dangerous and disordered dieting practices. A more typical biohacker is the guy in your office who replaced his cocaine and Redbull habit with a high-fat diet and an Oura Ring (to track sleep, heart rate, diet and movement). He takes his coffee with butter, has been “so focused” since he started microdosing and probably has some strong opinions about government overreach. Biohackers believe in the N-of-1 approach to clinical testing, where efficacy is measured by the experience of a single patient. What this methodology lacks in robustness, it makes up for in efficiency. Who needs double-blind, randomized, peer-reviewed proof of concept? The proof, they would argue, is in the Keto coconut milk pudding.
“What are we feeling this morning? Energy? Mental clarity? Chakra balancing?” I am sitting with Nguyen in front of a BioCharger perched on a low-slung marble coffee table. I explain that I’m a little outside of my element, but let’s try energy, sure. Because who doesn’t need more of that these days?
Introduced to market in 2018, the BioCharger earned some unwanted publicity when Australian celebrity chef Pete Evans claimed it could cure Covid-19 in the early, desperate days of the pandemic. The result, for Evans, was a $25,000 fine from the Therapeutic Goods Administration, a regulating body in Australia. Still, the contraption has a devoted following, including wellness tycoon Tony Robbins; his wife, Sage; and pro surfer John John Florence (all of whom are paid sponsors for the product). Elle Macpherson says regular BioCharging sessions have helped her maintain her body (a.k.a. The Body). And Instagram is lousy with Spandex-clad yoginis doing their daily practice with a familiar status gadget in the frame.
Nguyen presses a few buttons and the light show begins. You don’t need to plug in or strap on anything, just sit close by and let the electromagnetics do their thing. Later, he says that my 10-minute session had the same benefits as spending an hour in direct sunlight, an activity I have always understood to be ill-advised (see: skin cancer). But, in the biohacking universe, the sun provides a natural charge for the body—the kind we’re not getting enough of with so much time spent indoors and on devices.
Embracing the natural environment is both a sacred bio-hacking tenet and, at Longevity House, a design directive. From the outside, the building looks like a typical suburban mansion: three storeys, five bedrooms, and a crescent driveway that, on the day of my first visit, is home to Nguyen’s electric-yellow Mercedes Benz G-Wagon. On the inside, the headquarters is all smooth edges and earth tones: creamy, shaggy carpets and blond wood accents, ambient art and waxy succulents. Along with the gym equipment, there is a kitchen and tables where members can work. While I’m there, CFL linebacker Henoc Muamba is on his laptop before a workout. He is a Longevity House ambassador, as is Donovan Bailey, who signed on after visiting the facility for a full genomic testing workup last spring. At one point, Nguyen mentioned something about Shawn Mendes, but when I followed up, he said that conversation had stalled. My request to see a membership roster was denied for privacy reasons. “There are a lot of people who are a bit sheepish about what we do here,” Nguyen says, “I think because it seems like a rich guy’s endeavour.” Which, of course, it is. Instead of doing the big steak dinner at Barberian’s, drinking too much red wine and waking up with a hangover, Nguyen tells me, people are coming here. Last spring, Peter Tolias, a founding member who is also a Conservative party fundraiser, arrived at Longevity House on the heels of a celebration for Patrick Brown’s (ill-fated) entry into the party’s leadership race. Tolias and others did a guided meditation led by Buddhist monk Bhante Saranpala, slurped smoothies and ate organic steak. An early spring blizzard didn’t stop them from hiking in the ravine, followed by a silent meditation, followed by a sauna session, followed by cold plunges and snow angels. (Yes, snow angels are a biohack.)
As of late July, Longevity House had filled 23 out of 30 founding membership spots, mostly with athletes and finance guys plus a couple of cannabis industry expats. The entrance fee is a buy-in to an investment fund targeting promising biotech start-ups in Canada. The first investment was in the Living Proof Institute, a functional-medicine clinic founded by a chiropractor named Sachin Patel, who describes himself as a “keeper of truth” and a “warrior of light.” The idea is bespoke health care: millions of data points on everything from how your body processes food to how your brain manages stress.
If and when the Longevity House fund turns a profit, the company will take a two per cent management fee and split profits with investors 60-40. But Nguyen is not so concerned about the money piece. He made a killing in crypto, he explains. “I could take my money and go live my best life in Munich, but that wouldn’t be doing anything to help my family and my community,” he says. With its comparatively lax regulations, Munich is to biohackers as Graceland is to Elvis fans. Nguyen was there recently, looking into new stem cell therapies that are not legal in Canada. He has buddies who go biannually for youth blood transfusions and good beer.
For a guy who spends so much time in a masculine environment, Nguyen is the furthest thing from a bro. True, he drives a neon monster truck, but otherwise he has the mild manner and soothing monotone of a high school guidance counsellor. He is in his early 40s, though his biological age, he tells me, is between 27 and 29. He begins most mornings with a BioCharge and eats only one meal a day. He takes supplements including rapamycin, which has, he says, “been proven to reverse aging” (it has not) and a diabetes treatment taken by “one in four billionaires” (which I can neither prove nor disprove). He also gets platelet-rich plasma injections to reverse hair loss and occasionally naps in a hyperbaric chamber.
Nguyen is single but hopes to find a partner and would like to be a dad someday. He is extremely close to his own father, who is in the early stages of dementia. “I do everything I can to make sure his mind is staying active,” Nguyen says. “It’s kind of a joke that, if you invite me somewhere, there’s a good chance I’m going to show up with my dad.” When he is home in Toronto, Nguyen lives in a suite at the Ritz-Carlton. More often than not, though, he is globetrotting in Miami, visiting Tony Robbins’s new biohacking facility, Fountain Life; in London, for Wimbledon; in Costa Rica, on Longevity House business; in Greece, vacationing with his dad and sisters.
Nguyen came to Canada from Vietnam in the late ’70s with his parents and four siblings. His family lived in Dunnville, a small town outside of Hamilton that is also the skydiving capital of Ontario. His father worked in a Bick’s pickle factory that became a Smucker’s factory that is now a bone broth factory. His mother, who died of cancer when Nguyen was 17, was a dressmaker, and his paternal grandfather was a fabric merchant in Vietnam. Nguyen studied fashion design at George Brown after getting an accounting degree from York at his father’s insistence. He founded Garrison Bespoke in 2009. As well as outfitting a good chunk of high society, he created a $20,000 bulletproof suit in 2013—one that people actually bought. He was the creative force behind the Vogue-endorsed wardrobe on the TV show Hannibal, and he did the suits on Suits and outfitted the male lead, Gabriel Macht, for Meghan Markle’s wedding. (Maybe you heard about it.)
In 2015, Nguyen was looking to open a Garrison location in Florida, in partnership with his client and friend Michael Levine, a Bay Street financial advisor at the time. Then Levine was almost killed in an avalanche in Whistler, during which he was without oxygen for several minutes. He saw the best concussion specialists in the country but believes his recovery accelerated when he adopted a series of biohacks, including mindfulness coaching and regular sessions in a hyperbaric chamber.
A few years later, Nguyen’s sister Diem started experiencing a chronically itchy throat and shallow breath. He was -worried—these were the same symptoms that his mom had experienced before her cancer diagnosis. In a panic, he sent Diem to private medical facilities, but nothing worked, and for once, his platinum Rolodex was useless. “If you want to plan some unusual party or trip, I can make it happen,” he says. “But this was something I couldn’t just throw money at.” In the end, it turned out that Diem just had a chronic case of acid reflux, but by the time they figured that out, Nguyen was hooked on biohacking and wanted to grow the community in his home city.
The business plan for Longevity House, he concedes, is still a work in progress and is very much contingent on successful community building. Buying a fancy mansion for a small group isn’t scalable or a great use of capital, he says. Instead, he is working on partnerships and licensing deals and developing a line of longevity supplements with his business partner and Longevity House co-founder, Markus Raty. Their first product, a gummy version of jiaogulan, the Chinese “immortality herb,” is scheduled to debut this fall.
Raty is Longevity House’s chief operations officer, a rakish jack-of-all-trades type and the furthest thing from the self-serious, optimization-obsessed biohacker stereotype. He had never even heard the term when Nguyen first told him about his new project. It wouldn’t be an exaggeration to say that Raty loves saunas the way the Cookie Monster loves cookies. On a good week, he’s in there two, three hours a day—he credits his mental and physical health to this practice, which he has been taking more seriously. His motivation is two-pronged: he’s 47 with young kids and wants to be healthy and vibrant when they’re in their 20s; and, in 2020, he lost his brother to alcoholism during the Covid lockdowns, a tragedy he describes as a wake-up call. “It was like, whoa, we’re all susceptible to the vagaries of life.” He introduced Nguyen to Matt Hehn, who is now Longevity House’s chief people officer, which means he’s responsible for building the community. Very tall and stupidly handsome, Hehn is a guy who pulls off cool while using expressions like “good vibes float all boats.” Before he was a biohacker, he worked in luxury goods, including as the marketing director at Moët Hennessy—perpetual champagne flute between his fingers, the guy to know during TIFF. Then, in February 2020, he had an epiphany: being “that guy” was not making him that happy. A friend mentioned that he’d had a good experience with plant-based therapeutics, and weeks later, Hehn had taken time off work and flown to Costa Rica for back-to-back ayahuasca ceremonies followed by a Kambo ceremony, a ritual that involves smoking the poisonous secretions of a giant monkey frog, which biohackers call “the final purge.”
When I ask Nguyen about the amphibian venom trend, a topic recently covered in In Style magazine (“Why Are Celebrities Smoking Toad Venom?”), he says it’s probably not a good idea for me. Too intense. But, if I do want to try it, he can make introductions. That day, he is on call to accompany some members on an ayahuasca retreat at Rythmia, an all-inclusive resort-slash-life-enhancement-centre in Costa Rica. “The place that fixed Bobby Brown,” Nguyen tells me. (Is Bobby Brown fixed?) That same week, he will go with a different member to see a practitioner in Caledon who performs the aforementioned (and fully illegal in Canada) young blood transfusions. I ask about the risks and Nguyen says that, when the practitioner has more to lose than the patient, it’s pretty safe. By this, I assume he means that doctors performing experimental procedures have more to lose if things go wrong, which cannot be true. (Three people have died getting experimental fecal transplants, which are similarly unproven, at private clinics since 2020.) All Nguyen will say about the individual going to Caledon is that he’s a 43-year-old professional who has started to feel like he doesn’t have “the right energy” anymore and that his libido is in decline. Testosterone is a significant preoccupation of the mostly male biohacking community, literally—as in supplements and injections—but also metaphorically. In the darker corners of biohacking chat rooms lurks the idea that male physical dominance justifies man’s place at the top of the social order. “Reclaim your manhood” is a popular rallying cry.
When I broach these subjects with Nguyen, he says that he does not share the political views of some of his club’s members. He has seen evidence of toxic masculinity. (He once described a group of bankers who came in to do saunas and cold tubbing as “real #MeToo types.”) But he believes that even (and maybe especially) these troubled individuals can benefit from the experience Longevity House offers. Is Nguyen vaccinated? “No comment.” The vast majority of wealthy individuals he knows are not vaxxed. “I wish that wasn’t the case,” he says, which I take to mean that he is vaccinated and just wants to steer clear of the culture wars. Community is important, he says, but autonomy is even more so, going back to this idea that people need to become their own doctors. “That’s the ultimate goal.” But what if I want my doctor to be my doctor? I express my belief that people who say you can’t trust experts are often pushing their own agenda or being manipulated by someone else’s. Nguyen just seems to feel sorry for me, like I’m missing out on some essential truth—seeing a black-and-white photograph where he is seeing technicolour.
A few times over the course of our interactions, Nguyen asked if I might be interested in genomic testing for my infant daughter. He had a workup done for his five-year-old niece, and after her results showed the pre-markers for ADHD, she began to see a private tutor who works with her mom on specialized learning tactics. Having received an ADHD diagnosis in my late 30s, I can certainly see the appeal. But at least equally obvious are the pitfalls of this kind of cradle-to-grave streamlining. It’s hard to imagine that so much focus on the quest for perfection doesn’t create as many mental health problems as it solves. And, while I love the idea of feeling 50 at 90 as much as the next person, doesn’t it all feel a bit like virtuous, pseudoscientific window dressing laid over an age-old obsession with tight bodies and youth? Never mind the not-so-subtle shades of eugenics. When the goal is optimization, what happens to those of us who are, well, suboptimal? Who decides what “optimal” means, anyway? These are just some of the pertinent ethical questions surrounding the biohacking mission, most of which are predicated on the assumption that any of this stuff actually works. So, does it?
Well, in some ways, yes—but mostly no. And not in the ways or to the degrees that many biohackers believe it does. Tim Caulfield is the research director of the Health and Law Institute at the University of Alberta. In the spring of 2020, he received a $380,000 grant to combat Covid-19 misinformation, which he saw as a worthy academic pursuit and a public health emergency—people were drinking bleach, after all. He coined the term sciencesploitation to describe the practice of using valid science and scientific-sounding language to market unproven products and procedures, including stem cell therapies, probiotics and pretty much the entire field of functional medicine.
But what about pushing boundaries and challenging conventional wisdom? What about Galileo? It turns out that people use his name to bolster baloney on a regular basis. There’s even a term for it: the Galileo gambit fallacy. In a lot of cases, Caulfield adds, the research on what biohackers call “unproven therapies” has, in fact, been conducted: “We’ve run the clinical trials on stuff like platelet-rich plasma injections and it has been proven not to work, so this idea that ‘the science is promising’ is disingenuous.”
How genuine is Michael Nguyen? He certainly walks the walk, drinks the bone broth and bathes in the forest. He may actually have the cardiovascular system of a man half his age. But, ultimately, his heart is mainly entrepreneurial, and a business like Longevity House benefits from the blurring of credible science with all kinds of quackery.
Some of it is immediately treacherous (transplants, untested drugs) and some is dangerous in a more indirect way: cancer patients have died after delaying conventional treatment in favour of alternative remedies. The sun may be a natural source of vitamin D, but skin cancer rates are on the rise. So are eating disorders. And there’s almost certainly a person somewhere out there who bought a BioCharger to treat their Covid and suffered the consequences.
I looked long and hard for a single credible expert who would back the claims of the BioCharger but came up empty. When I challenge Nguyen on this point, he concedes that the machine probably doesn’t do anything that you can’t get from a daily journal practice or meditation. But people aren’t interested in those things, which are generally free and unsexy and don’t look good on social media, he says. I point out that this is essentially an admission that Longevity House is selling snake oil. Nguyen doesn’t see it that way. Remember, he could be off in Munich right now, getting jacked up on his own stem cells. Instead he is here, in Toronto, trying to remind everyone that our health is not a thing to take lightly. Mothers die young, fathers get old, pandemics come along to remind us how little is within our control. We are all susceptible to the vagaries of life. “I don’t care if people think I’m crazy,” Nguyen says. “If what I’m doing makes anyone care about their health before they get sick versus caring about a new sports car or a $300 dinner, then I’m doing my job.”
This story appears in the September 2022 issue of Toronto Life magazine. To subscribe for just $24.99 a year, click here. To purchase single issues, click here.",4
425,"Possibility space
By this art you may contemplate the variations of the 23 letters.
Burton, The Anatomy of Melancholy, part 2, sect. II, mem. IV (1621)
In The Library of Babel (1941), Jorge Luis Borges imagines a strange world:
The universe (which others call the Library) is composed of an indefinite and perhaps infinite number of hexagonal galleries, with vast air shafts between, surrounded by very low railings…
There are five shelves for each of the hexagon's walls; each shelf contains thirty-five books of uniform format; each book is of four hundred and ten pages; each page, of forty lines, each line, of some eighty letters which are black in color. There are also letters on the spine of each book; these letters do not indicate or prefigure what the pages will say…
Five hundred years ago, the chief of an upper hexagon came upon a book as confusing as the others, but which had nearly two pages of homogeneous lines. He showed his find to a wandering decoder who told him the lines were written in Portuguese; others said they were Yiddish. Within a century, the language was established: a Samoyedic Lithuanian dialect of Guarani, with classical Arabian inflections. The content was also deciphered: some notions of combinative analysis, illustrated with examples of variations with unlimited repetition. These examples made it possible for a librarian of genius to discover the fundamental law of the Library…
The Library is total […] its shelves register all the possible combinations of the twenty-odd orthographical symbols (a number which, though extremely vast, is not infinite): Everything: the minutely detailed history of the future, the archangels' autobiographies, the faithful catalogues of the Library, thousands and thousands of false catalogues, the demonstration of the fallacy of those catalogues, the demonstration of the fallacy of the true catalogue, the Gnostic gospel of Basilides, the commentary on that gospel, the commentary on the commentary on that gospel, the true story of your death, the translation of every book in all languages, the interpolations of every book in all books.
The complete set of permutations of all letters fitting within 410 pages.
Incidentally, a complete set of permutations is called a derangement—a permutation that leaves no element in its original position.
Related notes: Using a computer to generate permutations is a simple superpower for thinking.
There are other Libraries of Babel. In one corner of the multiverse, we find Borges’ Library, containing all possible combinations of letters. In another corner, there exists a concert hall containing all possible sounds. In still another, we find a vast gallery room containing all possible images.
From Why Greatness Cannot Be Planned, by Kenneth Stanley, Joel Lehman (2015):
Imagine this giant room in which every image conceivable is hovering in the air in one location or another, trillions upon trillions of images shimmering in the darkness, spanning wall to wall and floor to ceiling. This cavernous room is the space of all possible images. Now imagine walking through this space. The images within it would have a certain organization. Near one corner are all kinds of faces, and near another are starry nights (and somewhere among them Van Gogh’s masterpiece). But because most images are just television noise, most of the room is filled with endless variations of meaningless gibberish. The good stuff is relatively few and far between.
The nice thing about thinking of discovery in terms of this big room is that we can think of the process of creation as a process of searching through the space of the room. As you can imagine, the kind of image you are most likely to paint depends on what parts of the room you’ve already visited. If you‘ve never seen a watercolor, you would be unlikely to suddenly invent it yourself. In a sense, civilization has been exploring this room since the dawn of time. As we explore more and more of it, together we become more aware of what is possible to create. And the more you’ve explored the room yourself, the more you understand where you might be able to go next. In this way, artists are searching the great room of all possible images for something special or something beautiful when they create art. The more they explore the room, the more possibilities open up.
Possibility spaces. Kenneth Stanley and Joel Lehman are AI researchers, and this is how an AI researcher sees creativity. When you are an AI, creativity is a search problem. Your job is to find something that already exists out there in the space of possibility. It’s just waiting to be discovered.
There is something powerful about this notion of possibility spaces, both from a theory standpoint, and as a way of seeing. It causes you to approach challenges in a different way. You don’t need to be creative. The creative breakthrough already exists out there in the space of possibility. It’s just waiting to be discovered.
This way of seeing can be applied to many problem spaces. Evolutionary biologists can think of the possibility space of traits as a fitness landscape, or the possibility space of shapes and forms an organism can take as a morphospace. AI researchers can think of the loss function of an algorithm as making up a loss landscapes.
These landscapes of possibility can be smooth or rugged, static or dynamic (changing over time).
And a spatial metaphor suggests spatial actions. What dimensions make up the landscape of possibility? What does this space look like? Where are the most interesting things located? How can I effectively navigate through this space of possibility?
You start to see creativity differently. Maybe I don’t have to cover all of this ground myself? Maybe other explorers can map it out too? Maybe a computer can even help me explore it?
Related notes: Geists, Search reveals useful dimensions in latent idea space, Getting lost in the land of ideas.
The generative possibility space of DNA is unlimited:
Contemporary nucleic-acid-based replicators in living systems have, in contrast, unlimited heredity, and a museum showing all of the possible sequences up to a certain length would be larger than the Universe.
Szathmáry. The first two billion years. Nature 387, 662–663 (1997).
Note that Borges’ Library of Babel is not infinite. Each book is finite in length (410 pages), making the number of permutations finite. DNA has no such limit. The chain can always get longer. So, life is open ended, unlimited. Nature is endlessly finding new ways of being alive.
But not all replicators are unlimited. Interestingly, it seems likely that within the murky origins of life, the process becoming life was once limited, not open-ended:
G. Wächtershäuser (Munich) argues that the first replicators with limited heredity were much smaller molecules, with analogue rather than digital replication. Whereas analogue replication proceeds piecemeal, digital replication is a modular process.
Becoming unlimited was a major transition in evolution.
Note the powerful idea buried in this excerpt, mentioned in passing: there is a connection between modularity, composability, and open-endedness.
Related notes: Alphabets of emergence, Composability with other tools, Open-ended tools for infinite games.
Another book. The book of Minecraft worlds:
Imagine an enormous book, in which is a screenshot of every single Minecraft world. Each one is labelled with the world's random seed, a unique number you can type into Minecraft to get it to generate that world. The first page shows the world from seed 0, the next shows the world from seed 1, and so on. Minecraft's world generator contains 2^64 random seeds in total, which is a huge, huge number: that's 18,446,744,073,709,551,616 worlds that it can generate. Every time you click ""New World"", you get one of those seeds served up to you. This number, 2^64, is the size of Minecraft's generative space - the set of all the things it can generate.
Cook. Generative and Possibility Space. (2019)
Yet even this book does not contain all possible Minecraft worlds.
Now imagine a Minecraft world with nothing in it except flat grassland, forever, in all directions. No caves or rock underneath it, no trees, no hills, no animals. Just a single layer of grass tiles. Other than being pretty boring, this world isn't something you can generate in Minecraft (without modding it). We can imagine it, we can describe it, we can even open up Minecraft and create it ourselves by hand - but Minecraft can't generate it.
Cook. Generative and Possibility Space. (2019)
So there’s the set of things that are possible in Minecraft, and the set of things that are reachable via the generator engine.
Similarly, in nature there is the set of genes that are possible (unbounded), and the set of paths that our local evolutionary context is likely to explore. Evolution is path dependent.
The space of the possible and the space of the reachable.
Incidentally:
Here are some questions I’m asking myself as I think about possibility spaces and tools for thought.
What possibility spaces do my tools for thought generate?
Is the possibility space open-ended? In what ways might we expand the generative possibility space?
What parts of that possibility space are reachable, and how? What is path dependent? Where can I facilitate horizontal gene transfer between paths?
In what ways can I reframe creative challenges as a search problem?
The transition from analog heredity to digital DNA was a major transition that made life open-ended. What is analog that should be digital? What is integrated that could be modular? In my tool? In my notes? In what ways might those modules be composed, like DNA?
DNA is open-ended because the length of the chain is not bounded. Where am I limiting the length of my DNA chain?
Using a computer to generate permutations is a simple superpower for thinking. Where can I generate permutations?",2
426,"PHOENIX, U.S. -- The father of Taiwan's chip industry said geopolitics have drastically changed the situation facing semiconductor makers and warned that ""globalization and free trade are almost dead,"" and unlikely to come back.
Morris Chang, founder of Taiwan Semiconductor Manufacturing Co., was speaking at an event in Phoenix, Arizona, on Tuesday where the company marked the symbolic first equipment installation at its new plant.",4
427,"Biomanufactured materials are coming
Twenty milligrams, about the weight of a feather. Spiber's founders had only made this much spider silk protein in three months in 2008. For their first year operating, it was an inconspicuous amount and very humble beginnings.
Since then, spider silk protein startups have managed to almost double production on average every six months since 2008. These startups are closing in on about eight tons of production this year, over eight orders of magnitude more than in 2008. Spiber and others have too much demand and are hastily scaling to keep up.
This article is Part Two in a two part series about materials. Part One outlined a case on why we need a new materials paradigm. This piece dives into amazing new performance materials leading this seismic shift, how many of them have underpinnings in synthetic biology and how startups can use these materials to engineer products we've never had before.
In writing these articles, I have been learning as I go and do not have all the answers. That said, I now have conviction that emerging materials with better properties will create a new normal. As I wrote in Part One, synthetic polymers became a new class of materials that changed the world during the 20th century, enabled by fossil fuels. In the coming decades, I believe new materials will replace synthetic polymers and other materials as well as being used in completely new ways. A ton of opportunities will open up for new startups, which is my interest as a founder.
We will summarize some key takeaways before diving in.
tl;dr
The rapidly evolving synbio stack is allowing startups to be faster, better and cheaper. The technologies underpinning synthetic biology and by extension, performance biomaterials, have rapidly improved over the last two decades. A core enabler driving this is that costs of DNA sequencing and synthesis have fallen orders of magnitude, and productivity has increased similarly.
Companies making chemicals using engineered microbes, like Amyris, Geno and Lanzatech, have leveraged these improvements. Amyris and Geno have drastically reduced development times of their molecules from 2-4 years to 6-10 months or less. Amyris lowered the cost of farnesene, their first commercial molecule, fourfold in four years while Lanzatech's ethanol is cost competitive with incumbents today.
These three companies are all scaling rapidly. Amyris is at thousands of tons of production volume for squalene alone, while seeing blistering revenue growth of their consumer products. Geno is at 30,000 tons of 1,4 butanediol and Lanzatech 60,000 tons of ethanol production. Both are building new plants that aim to increase scale threefold in Geno's case and tenfold for Lanzatech in the next few years.
Biomaterials like spider silk and mycelium are scaling up at historic speeds, yet are not being talking about. Spider silk protein made by Spiber and AMSilk, the industry leaders, has grown production at an incredible ~273% compounded annual growth rate (CAGR) since 2008 (see below). They are currently at about eight tons, but are scaling up to over ten thousand tons in the coming years. At that scale and even as growth slows, it should still close in on the production volume of global 3D printed polymers. How many people would have predicted that could happen by the mid 2020s back when milligrams of spider silk protein were made in 2008?
Mycelium production is also rapidly scaling. Last year, Ecovative produced about 45 tons for a variety of uses. Their spin-off, MyForest Foods, uses AirMycelium, Ecovative's patented tech that grows mycelium in open-air racks. MyForest Foods has just opened a new commercial plant that alone aims to scale to over 13,000 tons by 2024, which will accelerate their 212% CAGR growth over the last two years. Though that plant is being used to produce fungi-based bacon, other plants that make leather and foams would be largely the same except for the strain, mycelium growth substrate (e.g. woodchips and hulls of seeds) and control algorithms.
Performance biomaterials have novel properties that surpass existing materials. Spider silk protein, algal oil polymers and squid-inspired protein are some examples of performance biomaterials we'll discuss.
Spider silk protein (AMSilk and Spiber) is lightweight, has incredible toughness, high tensile strength and is highly elastic. It's being used in cosmetics, medtech, apparel and watch straps, and is being tested by Airbus for replacing carbon fiber in composite parts on airplanes, Mercedes in interior car parts and more.
Checkerspot's polyurethanes made from an algal fermentation process are used in their direct to consumer skis and snowboards. These performance materials offer excellent damping and great low-temperature tensile strength.
Tandem Repeat's squid-inspired protein heals in seconds by applying 50°C/122°F heat and also has thermal properties for helping keep clothing cool. In a recent Nature paper co-authored by one of Tandem Repeat's cofounders, squid-inspired proteins have been demonstrated as a strong artificial muscle with possible soft robotics applications.
Though not a biomaterial, graphene has exceptional properties and is finally hitting its stride. It's being used in a wide array of industries, surging 61% CAGR from three thousand tons in 2018 to twelve thousand tons of global production in 2021. At this scale, like with spider silk protein, it may also overtake the global production volume of 3D printed polymers by 2025.
Startups that source performance biomaterials and integrate them into products are a largely untapped pathway to market.
Almost all performance biomaterials producers today partner with incumbents that make end products and distribute them. Two of the only exceptions I know of are Spiber partnering with sustainable fashion startup Pangaia and Checkerspot's own brand WNDR Alpine making skis and selling them direct to consumer.
Two benefits of biomaterials working with consumer product startups are worth calling out.
- The potential to offer more differentiated products free of constraints of larger incumbents that customers can be really excited about.
- These products can help pull demand forward for biomaterials producers.
Incumbents did not build the iPhone, any Tesla EV, Fitbit wearables or even Allbirds shoes. Just like in those and countless other examples, the upstarts will push the boundaries of performance materials more than any established players.
In the years ahead, I believe sustainable materials will be the norm as more producers scale up. They will become table stakes for tomorrow's products and no longer be a differentiator. Ambitious consumer startups will need to push performance boundaries to drive more adoption.
The future potential of these materials is enormous, and hard to fathom this early in their ramp up.
The novel properties of biomaterials and scalability will improve existing products and unlock new products that do not exist today. Using multiple performance biomaterials in one product will become more common and enhance the product's benefits. Engineering them together with other technologies will also increasingly happen.
Possible applications will include self-repairing smart clothing, biocompatible human-computer interfaces, electric propulsion vehicles (especially next-generation aircraft), and in humanoid robots as artificial skin and muscles.
That's a summary of what to expect in this piece. Now let's dive deeper into each of these ideas starting with the synbio tech stack. We'll see how it has enabled companies like Amyris, Geno and Lanzatech to build better, faster and cheaper and how that bodes well for performance biomaterials as they scale up.
The synbio stack is a key enabler
Let's cover some brief definitions to level set.
Biomanufacturing is the use of biological systems that have been engineered, or that are used outside their natural context, to make a product. It is enabled by synthetic biology (synbio), an interdisciplinary domain that involves the application of engineering principles to biology.
From this, biomanufactured materials refers to materials produced using engineered biological systems. Examples of biological systems include submerged, solid state or gas fermentation using engineered microbes, cell-free systems using enzymes as catalysts and finally mammalian cell cultures. Note: when I mention fermentation or microbial fermentation in this piece, it means submerged unless stated otherwise.
Biomanufactured materials is a mouthful, so I use ‘biomaterials’ for short. Just be warned that this term is also used to describe any material that can interact with biology, like prosthetics or other material therapeutics.
So biomaterials it is. Let’s now build towards the case for biomaterials by looking at some important developments in biomanufacturing and synbio in the last few decades. These developments underpin what is happening now with biomaterials and are ongoing tailwinds for the future of the space. I’ll focus more on microbial fermentation, but there’s also rapid progress in improving solid state and gas fermentation, as well as cell-free systems.
Biomanufacturing has been quietly ramping up
The origins of synbio go back just over four decades to Genentech’s synthetic insulin, first produced in 1978. Genentech's breakthrough was the first microbe-produced biopharmaceutical drug, aka biologic.
Synbio has gone on to disrupt pharmaceuticals with biologics having grown to contribute over 32% of total industry revenues in 2018 in the US. Six of the top eight drugs by revenue in 2016 were biologics, though perhaps helped by market distortions. Fun fact: many biologics are so valuable they can be more valuable than gold on a weight basis. This super-high value product shows two interesting points. First, a $300B+ global biologics market is not niche in a monetary sense, but in terms of the quantity of biomanufactured goods, this is still a relatively low volume market. This is a classic example of high value, low volume which often serve as beachheads for nascent technologies. Second, the stratospheric price means biologic developers did not have to worry about optimizing product titers (concentration) in their process.
Companies making lower value products (basically everything else) did have to focus on titers and costs.
As titers improved for fermentation, startups began focusing on lower value products. Around twenty years ago, companies like Amyris, Genomatica and Lanzatech were founded to use fermentation to produce various chemicals. Encouraged by high oil prices, many of these Cleantech 1.0 companies focused on making biofuels and raised a boatload of capital during the late 2000s. Unlike the three companies above, most did not survive. Many that died did not pivot away from trying to make biofuel unit economics work.
Amyris, Genomatica and Lanzatech are amongst the survivors. They have started gaining strong traction in markets where petrochemicals or corn starch have been incumbents for decades.
Amyris survived a costly biodiesel foray and pivoted to becoming a vertically integrated health and cosmetics company. Their fermentation process first produced high-purity squalene at a far lower cost than can be extracted naturally, and has come to dominate the global market with 70% share or over 1500 tons per year. Amyris has also expanded to produce 12 other higher value ingredients using fermentation of engineered yeast. Further, they have found exceptional product market fit for their consumer products with direct to consumer (DTC) being a core driver of growth for new product launches. Aided by DTC success, their consumer business has grown at 133% CAGR since 2019 to $77M in the first half of 2022. Their consumer business now accounts for the majority of their revenues.
Genomatica (now Geno) has been slower growing in recent years than Amyris, but by targeting lower value commodity chemicals, has scaled fermentation capacity even more. Their first target molecule was 1,4 butanediol (BDO), a chemical intermediate used for various polymers like spandex with annual global capacity at 2.5 million tons. More recently, they've expanded to make nylon intermediaries and personal care ingredients. Rebranded as Geno, they are more than 3x'ing their BDO capacity in two years from 30,000 tons to over 100,000 tons per year in 2024. By then, they will have about 4% the global market. It's worth noting they sell their ingredients B2B, and have grown annual revenues at 37% CAGR from 2016 to 2021 to $48M.
Lanzatech produces ethanol and more recently, sustainable aviation fuel (SAF), ethylene and other commodity chemicals. Unlike Amyris and Geno, they use gas fermentation technology, which is less established than using crop-derived sugars. Their process feed syngas, a mix of carbon monoxide and hydrogen, instead of sugars to their microbes. Lanzatech's demo-scale plant in Georgia and first commercial plant produce about 60,000 tons per year combined and their product is already cost competitive, even with first generation plants. They are building seven new plants and another seven are in engineering. These plants will allow them to ramp capacity about 10x to 600,000 tons per year of ethanol, SAF and other chemicals.
These low value chemicals are multiple orders of magnitude cheaper than biologics to make. To viably produce these molecules, the underlying tech stack of synthetic biology had to improve exponentially in the last two decades. Strain and metabolic engineering had to improve. Iteration cycles had to accelerate. All of this happened.
Synbio stack: faster, better, cheaper
We can see just how quickly synbio has improved by thinking of synbio as layers in a stack. As we'll see shortly, these improvements have enabled Amyris, Geno and Lanzatech to accelerate their progress. Biomaterials companies have also benefitted a ton (yes, a pun).
This image above gives a good high level example of a synbio stack. See Amyris featured in the application layer, as well as a couple of biomaterials companies we'll touch on later. A couple of other frameworks are worth pointing out. Drew Endy at Stanford articulates abstraction layers for synbio clearly and simply in many publicly available speeches. Elliot Hershberg has laid out a more recent outline of the synbio stack on his Substack.
The notion of a stack comes from software. For example many teams that built a v1 of a web applications historically (e.g. Wordpress blogs) used a LAMP stack consisting of Linux, Apache, MySQL and PHP software layers. Cloud, containerization and other more recent developments have abstracted away or simplified more layers of the tech stack. This has, among other things, allowed founders to build faster and more cost effectively and software engineers to focus more on development rather than worrying about provisioning and maintaining servers.
The most surprising thing about the synbio stack was just how fast the whole synbio stack was improving.
DNA sequencing and synthesis costs have been falling at a super exponential rate for decades, as shown here and known as the Carlson Curve. Meanwhile the speed of DNA sequencing and synthesis has similarly increased at a super exponential rate, as shown below. Note the vertical axis is log scale for both charts. The cost of sequencing a human genome has fallen from $100 million dollars in 2001, with the first ever human genome taking 13 years to sequence. Today, they are as cheap as $100 in as little as five hours. The workhorse microbes used for most fermentation processes today, S. cerevisiae and E. coli, have four and three orders of magnitude less base pairs in their genomes vs humans.
Engineering of microbial strains have also been rapidly improving. Strain engineering really helps startups that are looking for an optimal strain, usually of e. coli bacteria or s. cerevisiae yeast, to produce a molecule with specific traits. One startup, Inscripta, offers a gene editor in-a-box that allows companies to test hundreds of thousands of genetic variants in days. For example, Ginkgo used Inscripta's product to develop strains 10x faster and halve their Design-Build-Test-Learn cycle time.
There are many more examples of the synbio stack helping make development and early stage biomanufacturing faster, better and/or cheaper. Want to run more experiments but don’t have lab space? Cloud labs have got you. Too much pain using software not designed for bio to run experiments? Benchling can help. How about abstracting away cloud compute infrastructure for bio? Latch will do it. Need fermentation capacity? You can do it in the cloud with Culture, or use various contract manufacturing organizations (CMO). Strain development not core to your startup's value? Ginkgo or a contract research organization (CRO) has you covered. Most of these companies were founded in the last ten years.
That’s just a brief sampling, but the picture is clear. The synbio stack makes biomanufacturing better, faster and cheaper. Amyris, Geno and Lanzatech are amongst the many companies to have taken advantage of these trends. Let's have a look at how they've done it. This will be instructive in how biomaterials startups are starting to do this as well.
Amyris has accelerated time for molecules to go to market by 80%, and are gaining traction in markets faster. Meanwhile, development time has fallen six fold from over 36 months for their squalene molecule in 2012 to about 6 months years for molecules launched a few years ago. Geno's BDO took 27 months to reach a commercializable titer (50 g/L), whereas their second molecule only took 10 months, and is probably faster today as this was back in 2014. To be fair, both Amyris and Geno have developed platform molecules which they can use as building blocks for chemicals and other products. Amyris’s farnesene is a good example, as it can be made into squalene, hemixsqualene and other fragrances which are used in several of their brands.
Costs to biomanufacture have come down too. In 2011, farnesene cost Amyris $7.8/L to manufacture, but they had lowered costs more than 4x to $1.75/kg by 2015. Lanzatech’s ethanol is at cost parity and Geno’s BDO is approaching it as they scale towards 4% share of a $17B market.
Further, better metabolic engineering and other improvements have upped titers, helping these companies and the synbio industry come down the cost curve. Geno’s BDO titer improved from around 10 g/L in 2009 to 80 g/L in 2011, reaching 140 g/L by 2016. See the chart below.
These gains have helped enable these three businesses to be amongst the first synbio companies to be closing in on industrial-scale capacity. Amongst other products, Amyris is producing 1500 tons of squalene and selling DTC in their cosmetics brands, Geno is making 30,000 tons of BDO and Lanzatech is cranking out 60,000 tons of ethanol. All have plans to ramp capacity fast and extend their platforms as discussed above.
Synbio products like these are closing in on over a million of tons of molecules capacity per year. It is ready to scale.
Biomaterials are at an inflection point
Like the companies above, biomaterials startups have employed advances in synbio technology to accelerate their progress. I’ve tracked at least two biomaterial products which have scaled capacity at stunning growth rates.
Spiber and AMSilk are leading companies producing biomaterials processed from spider silk protein. AMSilk initially focused on high value cosmetics and medical applications, whereas Spiber developed fibers for apparel. They are also targeting aerospace, mobility and other industries. In the first paragraph, recall Spiber made only 20 milligrams of spider silk protein in solution in 2008. It took three months to make this amount, as shown in this image from a talk by the founder Kazuhide Sekiyama. At that point, Spiber had not even began honing the fabrication steps needed to turn the protein into a usable material. According to C&EN, Spiber's capacity in 2021 was ""several"" tons per year. Let's call it two tons per year to be conservative.
Being founded in 2008, one year after Spiber, AMSilk would have also made a negligible amount around that time. They have managed to scale up though, with their protein used as a cosmetics ingredient in twenty products by 2017 to help come down the cost curve. More on that later. This year, AMSilk is on track to contract manufacture six tons of their protein in Europe alone, up sixfold from last year.
Based on Spiber's 20 mg in three months in 2008 together with their current capacity combined with AMSilk's, spider silk protein production volume has approximately grown at a stunning 273% CAGR on average since 2008. This growth rate is even comparable to the very successful early synthetic polymers like Bakelite or nylon when they were at similar production volumes. As I wrote about in Part One, these plastics helped kickstart the last materials paradigm.
The capacity growth is set to continue apace. Spiber and AMSilk are in the middle of aggressive scale-up to commercial production. In the next few years, Spiber aims to ramp production to thousands of tons. Firstly at a demo scale plant in Thailand with hundreds of tons of capacity, and then at a commercial scale plant in the US in Iowa with about 10x capacity of the Thailand plant. To be fair, Spiber has overpromised on milestones in the past, so I am not using their best-case timelines for plant openings. AMSilk is aiming for several thousands of tons of capacity by expanding its range of CMOs beyond Europe.
Mycelium, the “root structures” of certain species of mushrooms and other fungi, is another biomaterial scaling up fast. In particular, the startup Ecovative produced 45 tons per year in 2021 for a growing range of uses and can double capacity. When Ecovative was first founded in 2007, Eben Bayer made a small palm-sized piece of mycelium composite grown under his bed in his dorm room, shown here.
If that piece conservatively weighs 1kg (2.2 pounds), Ecovative has more than doubled their mycelium capacity every year on average. MyForest Foods, a spin-off from Ecovative, has just opened a plant that will scale up to over 13 thousand tons of mycelium per year by about 2024. Bayer is also CEO of MyForest Foods, and this plant is focused on making mycelium bacon and other alternative proteins. Ecovative is also scaling up mycelium production for their own Forager brand, as well as providing technology for products like Bolt Threads' Mylo leather and more.
Of course, even tens of thousands of tons of capacity is still peanuts vs the tens of millions of tons of capacity for the highest volume synthetic polymers today. That said, those materials have had several generations to scale-up and it would be unwise to bet against sustained non-linear growth. Ten or twenty years ago, few people anticipated solar PV at the scale it is today. Just as few people, ten or even five years ago, expected lithium ion battery packs to power 12% of all cars sold globally now as pure EVs. Growth rates matter and most people (especially analysts) underestimate their compounding effect. Inflection points only accelerate this growth.
I think we are close to an inflection point for these biomaterials. It does seem that with scale-up plans and very strong demand, scale-up of spider silk protein, mycelium will continue. Production growth can probably be sustained but there will be other challenges in addition to improving titers, lowering costs and accelerating cycle times discussed above.
The proteins being made in fermentation bioreactors are long and complex carbon molecules. This often makes the downstream processing much more complex. Once the molecules are isolated and purified from the fermentation medium, biomaterials startups face the challenge of fabrication, ie turning these molecules into materials. R&D in this stage of the biomanufacturing process has involved deep technical risk, as much of the materials science and engineering to commercially formulate biomaterials is still new.
We can now see how Spiber, AMSilk and Ecovative have begun scaling up production to commercial scale. Let's look into biomaterials that are aiming to mimic the performance, look and feel of existing materials before diving in to the case for performance biomaterials.
Drop-in biomaterials
Many startups producing biomaterials are focused on largely being drop-in replacements for existing materials in products. Many more are focused on replicating performance characteristics, but, at least for now, not aiming to go beyond.
Companies working on mycelium or collagen-based leather and other materials are making good progress selling to incumbent brands — especially in apparel. These materials are more sustainable, and usually easier to process at end of life vs synthetic or natural options. They also will reduce resource consumption and manufacturing emissions, in part because fermentation takes days to produce materials instead of months. At or close to price parity with legacy fabrics like leather, they could take large shares of these existing markets.
That said, as biomaterials keep ramping, sustainability will become table stakes. I am more excited personally about biomaterials that can deliver better performance than incumbents. Making better products is how technologies we take for granted became so widespread. iPhones > Nokias, LEDs > incandescents, computers > electronic word processors, EVs > gas-powered cars, etc. Early in the s-curve, a new technology is better at replacing existing use cases. For example, nylon stockings was a replacement for silk stockings. As the technology matures, it starts to solve new problems and creates entirely new product categories because of novel properties. Lithium-ion batteries enabled drones, solar PV enabled human-scale power generation and synthetic polymers enabled all kinds of products to be better and cheaper. Better performing materials also matter for speed of adoption. All of these examples of technologies gained adoption very quickly because of their tech-driven differentiation.
It's fundamentally hard and pioneering work to develop to bring novel materials to market, whether they are drop-ins or performance-orientated. Yet mimicking the properties of a synthetic polymer plays to its strengths and not to those of biomaterials. One of the key differentiators of using engineered biology is enabling performance properties not possible with materials derived from fossil fuel feedstocks. Why can't we make synthetic polymers that have these properties? In short, they rely on a limited range of fossil feedstocks and there are only so many ways to economically process them. I wrote about this in Part One of this series. Engineering with biology allows more control over end products with bespoke properties using the nanomachinery of cells and enzymes. Drop-ins do not take advantage of this.
Drop-in materials are good. I understand some startups need brand interest to secure funding and/or recruit talent in their early years and to help move biomaterials forward. Yet as we’ve covered, I think the bigger breakthroughs and step changes in scale will be unlocked by leveraging superior properties.
Performance biomaterials
When we have some control of the arrangement of things on a small scale we will get an enormously greater range of possible properties that substances can have, and of different things that we can do.
— Richard Feynman
Let’s look a little closer at examples of performance materials and startups that are making them.
By performance, I mean higher performing along any dimension or property of the material. Performance biomaterials will unlock products that synthetic polymers and other materials simply could not be used in. Plastics themselves disrupted natural fibers, wood, metals and other materials during the 20th century because of their novel properties and production scalability.
Spider silk protein from AMSilk and Spiber
We are talking specifically about spider silk protein made from microbial fermentation. One of the appeals of this protein as a biomaterial is the exceptional properties, even straight from nature. Incredible toughness, high tensile strength, lightweight and compatibility with biology is quite the list. Also, being made from engineered microbial ""factories"" allows tuneable properties, no matter if the protein is spun into a fiber or made into a gel, coating or composite material.
Of the numerous startups developing spider silk protein into materials, AMSilk and Spiber have the most traction. We've discussed the growth of these companies above, and will focus more on material properties and commercialization here.
AMSilk is perhaps the most under the radar biomaterial startup I’ve come across given its age and relative traction. Founded and based in Munich, Germany, their beachhead market was as high value, low volume gels for cosmetics products. By 2017, their gel was already in 20 speciality cosmetics products. Early on, they also developed Medtech applications including a coating for breast implants, tested in vivo in preclinical trials, where the spider silk gel’s biocompatibility lowered inflammation and other post-procedure problems. Their fiber can be used for biosensors and even in 3D printable structures. By focusing on non-fiber applications, they avoided the challenges of material fabrication we spoke about earlier.
In 2015, AMSilk made their first fiber, branded as Biosteel. In the past few years, they’ve started partnering with several large companies and have multiple products in the market. Airbus is researching how to replace carbon fiber with AMSilk's fiber in composite parts on their airplanes. This would allow for planes to better withstand impacts and help with light-weighting and is a great example of how innovation in performance biomaterials will extend far beyond fabrics. Airbus's Innovation Manager for Emerging Technologies and Concepts, Detlev Konigorski, had this to say about spider silk:
We haven’t even begun to scratch the surface here. Ultimately, this material could enable us to approach design and construction in an entirely new fashion.
It bends without losing strength. So, it could be integrated on parts away from the fuselage that are prone to debris impact or bird strikes. It could help protect space equipment in a similar manner or be applied to defence products.
Omega launched a commercial watch strap line using AMSilk's Biosteel that is 30% lighter and hypoallergenic. Adidas has been developing a shoe upper with them and Mercedes is exploring using Biosteel in interior parts, starting with door pulls. To focus on these and other products in their pipeline, in 2019 AMSilk sold their cosmetics business to Givaudan, the world's largest flavor and fragrance company. Granted, these products are all premium for now, but that's largely due to AMSilk's still small, but rapid growing manufacturing capacity.
Like most other biomaterials startups, AMSilk is supply-constrained. They can’t produce enough protein via their CMOs to meet demand. To address this, they are in aggressive scale up mode, as mentioned in the growth section above. Their capacity was 1 ton last year. They expect a six-fold surge to 6 tons this year and are aiming for several thousand tons of capacity by expanding their CMO network beyond Europe.
I’m impressed with AMSilk’s execution. They've raised $42 million, with only $7 million of that lasting from 2008 through last year, when they secured their series C. This is far less than their peers Spiber and Bolt and at least in part because they outsourced manufacturing, which is a huge cost. Despite their frugality, they have the highest current output of a startup producing fermentation-based spider silk protein and are ramping scale-up. Starting with cosmetics and coatings for medical applications probably enabled high value / low volume production for long enough to move down the cost curve. This was harder for Spiber or Bolt Threads to do given their focus on lower value apparel products.
Spiber is the other pioneer of fermentation-derived spider silk protein, branded Brewed Protein. Founded in 2007 and based in Yamagata, Japan, they have largely been focused on the apparel market as their beachhead. They have also developed concepts for fiber-reinforced materials with Toyota group companies for use in car doors instead of steel that are lighter and better shock absorbing. In that same project, they also developed polyurethane composite foam for car seats with Bridgestone, the tire maker. In apparel, they partnered with Goldwin to make a wool blend sweater, and North Face on a limited edition Moon Parka with the outer shell made from Brewed Protein. The jacket was delayed for several years years because of “supercontraction"", which happens when spider silk protein becomes wet or is washed. Despite this setback, their spider silk is now in a (slightly less limited) commercial run of several hundred hoodies from Pangaia Lab.
Spiber has raised a whopping $640 million in equity and securitization financing. A large chunk of that is invested into building their upcoming demonstration plant in Thailand and commercial plant in the US in Iowa. Once they have these plants operating at capacity, they will be producing thousands of tons per year of spider silk protein. As they approach that scale in the next few years, they aim to be cost competitive with cashmere, then silk, and then even wool. Despite setbacks, this is pretty remarkable given the founders produced a mere 20 mg in 2008.
Bolt Threads is another startup that started by developing fermentation-based spider silk proteins. After being founded in 2009, Bolt did some limited run experiments with their fibers in ties and beanies and later launched their B-silk protein for cosmetics creams and other products. However, they've pivoted largely to Mylo, a mycelium-based leather using tech licensed from Ecovative. As CEO Dan Widmaier put recently, ""Mylo is where the heat in the industry is right now"". Bolt has raised $472 million.
Spider silk protein has naturally exceptional properties, tunability due to synbio and downstream processing, the traction in an early range of applications and finally the rapid and continued scale up of leading companies. It demonstrates promise as a leading platform for performance biomaterials in terms of both scale and potential.
Algal oil polymers from Checkerspot
Founded in 2016, Checkerspot is a Bay Area based startup making performance biomaterials. It is one of the only biomaterials companies vertically integrated from developing microbial strains all the way to directly selling products to consumers.
They use microalgal fermentation to produce an algal oil, which can then be processed into different materials. So far, they have commercialized an algal urethane, polyurethane and a wicking fabric coating. Checkerspot’s founders, Charles Dimmler and Scott Franklin, had both worked at Solazyme, one of the Cleantech 1.0 companies that didn’t make it. Solazyme’s direct to consumer algal oil products inspired Dimmler and Franklin to focus on building consumer products themselves. They both love skiing, and thought the algal oil could enhance the properties of skis. Indeed, Solazyme had earlier tested algal oil polymers in surfboards.
Checkerspot’s materials used in skis replace petroleum-based polyurethane in ski sidewalls. The sidewalls are 138% better at damping vibrations vs petroleum-based ABS sidewalls and 60% better tensile strength at skiing-friendly temperatures. It also does not need any glue to adhere to the ski. Their polyurethane used in ski cores is also lightweight, allowing their skis to be significantly lighter than average skis. The most surprising part is their price competitiveness with performance skis. Better performance effectively at price parity. I don’t think any other biomaterial company can claim that to the extent they can. They're either not using enough algal oil for prices to matter, or their algal oil is not overly expensive vs petroleum-based polymers, or both.
Vertical integration stands out most about Checkerspot’s business model. Most of their skis are produced and distributed by their own brand, WNDR Alpine, which has a manufacturing plant in Salt Lake City, Utah. No other biomaterials company I’m aware of has taken this full stack strain-to-product approach. Checkerspot has also partnered with other companies to use their performance materials. DPS, a premium ski maker has integrated their polyurethane sidewall into a line of skis, ink and chemical company DIC is using algal oil to add more color to their range, Algenist set up a strategic partnership to use their materials in skincare products and Gore is experimenting with the materials too.
Alongside their own DTC distribution through WNDR Alpine, Checkerspot is also leveraging B2B partnerships. They are building out algal oil as a platform molecule that could be processed and integrated into many different consumer products.
Other emerging performance biomaterials
Alongside spider silk protein and algal oil products, there are a growing number of startups focused on making performance biomaterials.
When Amyris sent out samples of farnesene early in its development, they probably didn’t expect a company to commercialize a performance tire. Kuraray, a Japanese plastics manufacturer, developed two novel materials by blending farnesene into their rubber products. The first is liquid farnesene rubber (LFR). When used in tires, it reduces hardening in cold temperatures, improving grip, reducing fuel use and is more energy efficient to manufacture. LFR has been commercialized in some of Dunlop’s winter tires in East Asia. Indeed the demand was so strong that Amyris's CEO John Melo said (emphasis mine): ""Using LFR has caused notable interest by leading tire companies and has resulted in substantially stronger demand in 2017 than either Amyris or our collaboration partner had anticipated."" LFR can also be used in adhesives, coatings and sporting goods.
Using farnesene, Kuraray has also developed hydrogenated styrene farnesene block copolymer (HSFC), which has superior grip performance for shoes, grip handles, mats, etc. It also has better damping properties. Kuraray’s farnesene derived materials are still combined with conventional polymers for now, but are produced more sustainably and with less emissions than petrochemical rubbers. Further, recycling tire rubbers could be much better, with LFR and HSFC being more incremental improvements. Still, they point to higher performance biomaterial improvements over commodity uses of plastics like tires.
The wide ranging performance applications for this one molecule developed by one company hint at the potential impact of biomaterials. Also, as drop-in chemicals and biomaterials scale up, expect to see more applications that integrate both drop-in and performance biomaterials together in products.
Tandem Repeat is commercializing Squitex, a composite biomaterial made by spinning squid-inspired protein and cellulose or acrylic together. The squid-inspired protein is cultivated in fermentation tanks using microbes engineered with tandem-repeated genetic sequences from squids. Hence the startup's name.
Melik Demirel is one of Tandem Repeat's cofounders and a professor at Penn State. He co-authored a a 2020 Nature paper demonstrating the rapid self-healing properties of other squid-inspired proteins. In the paper, the biomaterial locally heals in seconds, using only mild heat at 50°C/122°F, as shown in the video below with some tests in the paper showing healed areas being at least as strong as the pristine ones. State of the art comparable materials take at least an hour. The paper also reported experiments using an artificial muscle capable of lifting a dead load 3000 times its own mass, which exceeds biological muscle. This is shown in the image above.
Tandem Repeat is seeing strong interest in fashion brands looking to partner with them. Squitex's thermal properties can help keep clothing cooler when active. They are first targeting textile adhesives as a high value and low volume beachhead market, but may also look into PPA equipment and other markets that can best leverage Squitex's properties.
Humble Bee Bio is working on performance biopolymers inspired by the solitary Australian masked bee. The bee produces a polymer that is resistant to heat up to 240°C, is resistant to water, industrial solvents, acids and strong bases. Humble Bee Bio’s team are engineering yeast strains that can produce this polymer using fermentation. They are aiming to develop a proof of concept of their material to be used for fibers and fabric finishes by mid 2023, a 6-12 month timeline that would have been incredulous only 10 years ago. Humble Bee Bio has also just raised an oversubscribed round. Long term, they are aiming at a suite of biomaterials for textiles, medical devices, electronics, aerospace, defence, animal health and even construction. There's a ton of genetic potential in insects that could lead to performance materials that we just do not understand well today. For example, Raspy crickets make silk for shelter.
Bacterial cellulose is another biomaterial that has performance characteristics. Modern Synthesis is using bacterial cellulose to “microbially weave” materials that allows for more design freedom in textiles and films. Bucha Bio’s bacterial cellulose has tensile strength higher than polyurethane, and is targeting textile markets. Polybion has built a first of a kind plant that will produce 1.1 million sq. ft. of bacterial cellulose per year, with production and polymerization only taking 20 days. They are partnering with the world's largest shoe manufacturer and three largest German auto companies. Simplifyber's cellulose is plant-based, but it is poured into a 3D-printed mold to make a one-piece sneaker, shirt or other clothing.
So far, we have not talked about mycelium in this section. That’s because mycelium applications have usually not focused on performance. Mycelium leather in hats and other clothing, meat alternatives, other textiles, foams and packaging are some of the commercialized products so far. Though the focus has been on drop-ins and matching performance, there may be structural materials being explored for mycelium that have performance applications. As mentioned above, MyForest Foods' production capacity is aggressively ramping and will continue driving costs down.
Engineering mycelium and other biomaterials for performance should become easier as costs continue falling, processes improve and as our underlying scientific understanding improves. It bodes well for future applications.
Challenges for performance biomaterials
Like any new and growing industry, progress will not all be smooth sailing.
The biggest question perhaps is scaling and associated cost declines. Can spider silk (and mycelium) keep scaling production at a rapid rate? Can other startups follow and also scale production? I don’t know, and no one does. There are no perfect comparisons, but overall the signs are good. As discussed earlier, Spiber, AMSilk and Ecovative all have massive near-term scale up plans. Synbio chemical companies like Amyris, Geno and Lanzatech have demonstrated the ability to reach tens or hundreds of thousands of tons of capacity. They are still growing fast despite being in mostly commoditized markets. Performance biomaterials should have an easier time scaling in comparison because their tech-differentiated value will accelerate demand.
Related to this question is the bottleneck of fermentation capacity. While I attended the SynBioBeta conference in April, this was one of the most talked about challenges. It's worth remembering that supply constraints is a good problem to have overall and means biomanufacturing is booming. Demand for fermentation is strong at bench scale up to tens of thousands of liter tanks and beyond, with 6 to 12 month or more lead times. Well capitalized companies are building out more capacity (like Amyris, Geno, Spiber) and upstart CMOs are looking to new reactor designs and to embed more automation and data tracking. However, there’s a lag for investments in supply to catch up, especially for larger scale fermenters. Liberation Labs, started by experienced synbio executive Mark Werner, as well at least one funded stealth startup I know of is working on addressing this need. The lithium supply chain is a great analog, where investment has lagged surging EV-driven demand in recent years, but it is starting to catch up. Still, for fermentation capacity, there will be some short term pain before supply catches up.
For startups with lower technological readiness, there’s the technical risk of developing a proof of concept for a new biomaterial and bringing it to market. Titers have to dramatically improve from first results in a lab. However, unlike Spiber’s early days, the synbio stack makes it faster and cheaper than ever to develop new biomaterials. We saw this happen for Amyris and Geno above as they developed more molecules. Development and go-to-market timelines will keep falling and make it easier to commercialize performance materials.
A huge challenge in executing quickly is working with incumbent customers on their usually slow timelines, as discussed in the section above on drop-in materials. Leveraging DTC like Checkerspot or partnering with startups, both of which we’ll cover later, are ways to speed up iteration cycles.
The startups we’ve discussed so far mostly use sugars from crops as feedstocks for fermentation. Land and resource use of crops comes up as a problem as production capacity of fermentation scales. Corn, sugarcane and other feedstocks require land, but sugarcane expansion in Brazil, a key producer, is largely done by converting degraded livestock pastures. Currently 77% of all crop land is actually used for livestock pastures or crops for animal feed. Even today's biomanufacturing technology reduces land intensity. As an example, Impossible Foods's burger patty uses 96% less land to make vs beef. Many biomanufactured products from chemicals (Lanzatech) to foods (Air Protein, Solar Foods, Circe Bioscience) are using feedstocks like CO2 or carbon monoxide and hydrogen. This trend will only continue as scientists better harness types of bacteria which thrive on simple carbon-based molecules. Costs of hydrogen and other feedstocks will also fall with clean electricity prices, making these approaches more competitive over time.
Also, we can’t talk about biomaterials without mentioning Zymergen. From the outside, Zymergen looked like a cautionary tale of how not to execute on a new biomaterial. Their lack of success should not be a deterrent for startups building biomaterials. If anything, having a failure like this, reminiscent of Cleantech 1.0 companies, is probably a good thing for the companies actually building the future. I looked into Zymergen a little more closely in this Twitter thread. Ginkgo’s recent fire sale acquisition seems like a good way to bring on the IP from Zymergen's platform and gain their core engineering talent.
Future biomaterials will keep getting better
The present and near term future for performance biomaterials looks pretty good. Looking forward, we are in the very early stages of the potential of better properties at increasingly economic costs. Let’s briefly survey some of the emerging breakthroughs that may enable next decade’s biomaterials to well exceed what's possible today.
The synbio stack for biomanufacturing is only getting better. I'll recap what was covered above in the synbio stack section. Strains are faster to engineer and more automation and software is improving productivity of biomaterial startups. Fermentation capacity, though bottlenecked today, should ramp in the coming years with more investment to keep up with the growing range and scale of biomanufactured products. Startups, some in stealth, are working on improving the design of bioreactors and making scale up easier. Using microbes that feed on CO2, hydrogen and other small-molecule feedstocks could allow for novel materials. Further, current solid state fermentation and cell-free catalysis will also keep improving as more companies commercialize molecules using these technologies.
Biomanufacturing has relied on e. coli and yeast (s. cerevisiae) as workhorses in microbial fermentation. Almost all companies today use engineering strains of these two rather versatile microbes. Increasingly, new ventures are developing so called non-model organisms, which open up the design space for potential molecules (and materials) that can be made. We’re in the early stages of this, but startups like Wild Microbes, focused research organizations like Cultivarium and no doubt many research labs are pushing forward our understanding of non-model organisms.
Using cell-free enzyme catalysis approaches are also in their early days. A prominent startup is Solugen, a chemicals company, with a 10,000 ton capacity plant built last year in Houston. Startups like Rubi are developing enyzme-based pathways to make materials, while Invizyme and Aether are developing enzyme engineering platforms. Intropic Materials is using enzymes embedded in plastics to accelerate self-degradation.
As promising as biomaterials are, there are other performance-focused materials that could be key parts of a new materials paradigm. Let's take a look at these, before turning to how consumer-facing startups can partner with biomaterials producers.
Other performance materials
Graphene, which was first isolated using scotch tape, seems to have already survived a hype and trough cycle. Some of the remarkable properties of this one-atom thick 2D material include its incredible strength, hardness, elasticity and lightness. Applications are now booming as graphene is now hitting its own s-curve inflection point. Last year twelve thousand tons was produced globally as films, powders, nanoplatelets and in other forms. In the last three years according to IDTechEx, graphene production has surged over 4x, at a scorching 61% CAGR. It is scaling almost twice as fast as nylon or synthetic polymers overall at the same level of scale.
All that graphene is being used for supercapacitors, battery cooling, coatings for wind turbines, Head tennis racquets, and even in composites for Airbus and Fiat-Chrysler. Challenges for graphene include only being used as an additive, and still relatively high costs. But as production ramps, costs will come down and engineering will improve and we’ll likely see a lot more of this material used in the coming decades. Graphene manufacturing has historically relied on chemical vapor deposition, which is also used for semiconductor and solar cell fabrication but produces volatile by-products or CO2. There are alternative manufacturing processes being developed like flash graphene and using palm kernel shells as feedstocks.
Commoditized metals are probably not the first thing one thinks as performance materials. Yet, usage of many metals is constrained by price and supply, and often manufacturing processes are emissions intensive. Electrolysis of aluminum has been around for over a century, but electricity that gets cheaper and cleaner will unlock even more uses for this lightweight metal. Other metals that could see higher adoption as costs fall include magnesium, which is lighter than even aluminum and has superior damping, or titanium using hydrogen assisted reduction. A future where electric planes are made of lower cost lightweight metals and biomaterial composites is no longer science fiction.
Like graphene, additive manufacturing (AM or 3D printing) has been through a hype cycle and is coming out stronger. Though not new materials, AM is a range of processes that can improve structural properties of materials in novel ways. In metal AM, one promising startup is Seurat, named after Georges Seurat's pointillism-style paintings. Seurat's printers work by using a laser to micro-weld powder layers with clean electricity. They aim to aggressively bring costs down and scale up so that they can print even cheaper than commodity kitchen silverware by 2030. They have already partnered with established companies like Porsche, GM and Siemens. Another interesting startup is Relativity Space. They have engineered the world's largest 3D printers to print their rockets, including engines, with 100x less parts.
Meanwhile, AM to make synthetic polymers is also starting to scale quickly. The global polymer AM market is at a similar scale production to graphene, though growing at a slower 22% CAGR from 2016 to 2023 (estimated).
How can startups apply performance bio (and other) materials to create far better products? This question is one I’ve perhaps been thinking about the most as I’ve explored the terrain above. Let’s dive in.
Go-to-market and scaling demand
This decade is the first time since the age of polymers in which new classes of materials will help drive the performance of consumer products. Above, we’ve already surveyed performance (bio and non-bio) materials. Their novel properties open up the design space, much as synthetic fabrics and resins did for textiles, the Space Race and beyond during the mid 20th century.
Let’s explore strategies for biomaterials startups to go to market. The sum of these strategies help inform how demand scales up for the whole industry. We'll first outline two types of strategies used today. Then, we'll hone in on why I think startups sourcing from biomaterial partners will increasingly be a compelling alternative. Finally, we'll also talk about why DTC as a distribution model is important for driving growth.
Keep in mind that while I believe some approaches to be better than others, it’s better to have a plurality of strategies to see which ultimately work. As discussed in the section on drop-ins, there needs to be many shots on goal. I am just sharing what I find most interesting as I explore startup ideas.
1) Partnering with incumbent brands
The very decision-making and resource-allocation processes that are key to the success of established companies are the very processes that reject disruptive technologies... These are the reasons why great firms stumbled or failed when confronted with disruptive technological change.
— Clayton Christensen in The Innovator's Dilemma
This is by far the most common strategy. Practically all biomaterial companies partner and sell their products to established companies in apparel, biomedical, automotive, aerospace and/or other industries. Benefits include incumbents having deep strength in making and distributing consumer products to their existing customer bases. Smaller brands are less exacting in the specifications they have, and the number of product units they need to move. Both Pangaia Lab and Goldwin's partnership with Spiber are good examples of this.
There are some drawbacks in my opinion, especially in working with larger companies. Perhaps the most limiting is that these companies have limited freedom to use completely different materials and properties to what they've used historically. Dan Widmaier, co-founder and CEO of Bolt Threads, had this to say about what incumbent buyers said when asked what they wanted from spider silk:
The number one request we used to get in the beginning of microsilk was ""I would like merino wool but cheaper"".
... that’s not very creative. Humans are good at incrementally innovating on something they know. There’s very few people who are very good at striking out into whitespace and correctly guessing the future on a product.
Also, incumbents want to adopt technologies that work within their manufacturing processes:
Something we really look for in terms of integration is that partner or startup understanding the supply chain and where they fit in. We've often struggled if partners just think that we’re going to reinvent the wheel and create a whole new supply chain.
— Adidas spokesperson. Biofabricate
Further, they move slowly and will likely take several years to bring a product to market, especially if it’s not in apparel. They are not likely to throw much of their marketing weight behind the product(s). Their large, established customer bases are as a whole not interested in products better suited for early adopters.
Early startups often simply don’t make enough material to use viably in their partner’s products. Patagonia needs thousands of units to launch a new product, Adidas aims to sell hundreds of thousands of shoes. Incumbents often ask for exacting specifications that are hard for startups to meet, and that's before talking about (current) price premiums. Partners may also have unrealistic expectations of scale up speed before the producer has even tuned its pilot or demonstration scale process.
The biggest challenge that we have now internally is everyone's kind of tired of doing pilots. We did enough of that and we just really want to be able to start offering products.
— Spokesperson for Stella McCartney (a fashion brand). Biofabricate
2) Vertical integration
In this context, vertical integration means doing the R&D and commercialization of both the molecule and the material, as well as owning direct to consumer distribution channels. One of the only, perhaps the only, example of this today is Checkerspot with their own WNDR Alpine brand.
Checkerspot's R&D expertise in algal fermentation is exceptional, as is their materials science to turn their algal oil into high-performance materials like the polyurethane used in WNDR Alpine’s products. WNDR integrates these biomaterials into skis and snowboards, and sells them at very competitive prices on their site.
Checkerspot’s vertical integration is impressive. I’ve seen few examples of synbio companies generally that vertically integrate, let alone biomaterials. The ones that seem to be doing it well like Amyris, Zbiotics and Cronos are integrating chemicals into cosmetics, food or health products.
However, I don’t think the vertically integrated approach is reproducible for most other founding teams. Checkerspot's founders, Charles Dimmler and Scott Franklin had both worked at Solazyme, also an algal oil company. Franklin has credited working on their consumer product as an inspiration for Checkerspot's DTC strategy. Despite being a relatively young biomaterials company founded in 2016, they were able to leverage the many years (and millions of $) of development that Solazyme had invested into algal oil R&D. As Dimmler said:
(Solazyme) really started to pick up momentum in 2008. So if you were to start the clock it took from 2008 to 2014/ 2015, about six plus years to get to commercial scale manufacturing. Checkerspot is building on a lot of the know how and lessons learned from that experience.
...that's a really important qualifier because if I'd say Checkerspot was founded in the summer of 2016 — we're four years old and we have three products on the market, that would convey that Checkerspot has somehow done something extraordinarily unique in bringing a product to market at a ridiculously fast pace.
Further, I think we'll increasingly see products integrating multiple biomaterials from more than one producer. For Checkerspot, it might be harder to source from another biomaterials manufacturer given it’s tough to be both the platform and the buyer. There are exceptions of course, like Tesla sourcing batteries from BYD, which is both an EV and battery manufacturer. Overall, it's hard to see many performance biomaterials companies going down the vertically integrated path.
3) Partnering with consumer product startups
Spiber and Ecovative are the only two examples I've seen of biomaterials producers partnering with consumer product startups. Both partner with Pangaia, a four year old materials-focused fashion brand, and Ecovative's collaboration is through their Fashion for Good cooperative. Despite the lack of current examples, let's walk through how these partnerships could look in the future and some potential differences in working with larger brands.
The core benefits of this approach are that the consumer product startups can build products that pull demand forward for biomaterials, and scale with the biomaterials producers. The producers of performance biomaterials that can grow faster will move down the cost curve sooner. Partnering with startups all in on making products that leverage the performance properties of biomaterials will, I think, grow demand faster.
Consumer startups can deeply innovate on the integration of one or more performance biomaterials into novel products. They are free of the creative constraints, large volume requirements and exacting requirements of incumbent companies. They have to ramp distribution as part of building the product, and can develop a tight customer feedback loop akin to what companies like Allbirds, Tesla and Fitbit did. These startups would bet their businesses on biomaterials as being core differentiators for not only their product, but their company.
Novel materials could get early adopter customers really excited to buy high performance products. Of all things, nylon stockings triggered this in the 1940s and I’ve written that few materials-driven innovations have done that since. I believe sustainable materials are becoming table stakes, and will not offer real benefit when everyone else uses them. The challenge will be in making products that people would love to use using world-class engineering.
Startups focused on engineering the materials into products can also cultivate strong relationships with many producers of performance biomaterials. Over time, approaches like cell-free, small molecule feedstocks and superior solid-state derived biomaterials probably become more available. No problem, as these consumer-facing startups can develop the expertise to integrate these as well and do it fast.
These consumer-facing startups could form in a range of industries, though the immediate pull might be towards apparel. However, areas like next generation mobility form-factors, aerospace and even robotics and other hardware products could be improved with performance materials as we’ll talk about shortly. The likely early products will be higher value goods made in reasonably small volumes, perhaps with proof of concepts engineered with biomaterial samples. As biomaterials prices will continue to fall as production ramps in the coming years, consumer startups will not need to auction jellyfish collagen book covers for over $12000, or charge $1400 for limited edition North Face jackets to gain traction. AMSilk and Spiber are already eyeing the aerospace and mobility industries as they scale, with AMSilk having partnerships with Airbus and Mercedes in place. This hints at where growth might be beyond apparel and textiles, though I think an eVTOL/eCTOL startup or e-bike/EV startup could build more compelling products that gain traction faster than incumbents.
There are companies in adjacent spaces emerging that are useful analogs as consumer facing products. Arcaea is leveraging Ginkgo’s strain development platform and is focusing on formulating fermentation-derived chemicals into cosmetics products. Startups like Vollebak and Graphene-X have been building brands around graphene in textiles and other novel materials, having kickstarted and preordered their way to early traction. Allbirds and On Running became billion dollar public companies (On expects to do over $1B in revenues this year) despite using existing materials in their shoes developed with novel approaches.
In the final section below, we'll take a longer view at what the potential of performance biomaterials could be.
Future applications
The early examples of consumer products using performance biomaterials are in apparel or sporting goods, e.g. Checkerspot. But what other types of products might biomaterials begin to be used in? This section outlines my far-from-comprehensive thoughts on this question, and how biomaterials might contribute to a more exciting future. The obvious narrative would be that they solve valuable problems that people will pay to be solved, for a growing variety of problems and larger groups of people over time. I think it’s worth exploring in a little more detail. By the way these are not predictions!
We’re still very early in the rise of performance biomaterials and other next-generation materials. Given that, it makes sense that the products available today are very much trying to do existing things better instead of brand new things. Over time, we’ll see a self-reinforcing feedback loop: more startups creating more products, increasing demand for more biomaterials, which will drive more product adoption. That will, like how other technologies have diffused historically, allow for increasingly complex products to be engineered that integrate performance biomaterials.
Two things about how this could play out. Firstly, 1+1 > 2. Integrating multiple performance biomaterials in one product could enhance benefits over and above applying them separately in different products. Of course, that’s with the caveat that the characteristics of the biomaterials combined makes sense for such a product.
Second, engineering biomaterials together with other technologies that make products better. Skeleton Technologies, which has raised over €200M making graphene-enabled supercapacitors, is an example of leveraging performance materials with supercap technology. Technologies that might play well with performance materials include battery-powered propulsion, miniaturized hardware, exponential compute, biosensors, robotics and more.
Smart clothing, in which textiles are integrated with electronic components, could continue to integrate performance materials. Self-thermally regulating clothing brands like Ministry of Supply's Mercury jacket have integrated batteries, heating elements and use a thermostat to heat to a comfortable temperature. Oros Apparel uses a super thin NASA-inspired aerogel layer to trap heat instead of thick down in their jackets. In some use cases, it just makes more sense to heat (or cool) one’s body directly instead of a heat pump for an entire room/home/building.
Performance biomaterials could also allow smart clothing to do much more. They could one day repair itself as discussed above for Tandem Repeat's squid-inspired protein. Graphene electrodes in a biosensor monitoring amino acids in sweat can give nutrition-tracking and recipe recommendations, as reported in a recent Nature paper by Caltech researchers. Biomaterials could even help brain-computer interfaces be more biocompatible in a similar way to what AMSilk’s spider silk does today for breast implants.
Mobility is another promising area, especially electric vertical/conventional take off and landing (eVTOL/eCTOL) aircraft. Lightweight biomaterial composites, like what Airbus is exploring with AMSilk, could be used as coverings, propeller blades or interior parts for eVTOLs and eCTOLs. Given how weight-constrained these vehicles are during takeoff and for flight range, the likely cost premium (for now) in using these composites could well be offset by range and weight benefits in the coming years. Improving battery performance will help. Airbus's partnership is to explore spider silk alternatives for carbon fiber reinforced polymer (CFRP) composites. Aerospace grade carbon fiber is about $90/kg today, less than cashmere and a little more than silk. As AMSilk, Spiber and others start to scale to tens of thousands of tons per year scale of spider silk protein in the coming years as planned, it should become cost-competitive and perhaps even more affordable than carbon fiber sooner than we think. This is great for commercial planes, but it should be even better for startups working on eVTOL/eCTOL or other aircraft with performance constraints. Other vehicles that could benefit from biomaterials include e-bikes, EVs, and even yet-undeveloped form factors.
Another application for novel biomaterials could be humanoid robots. They are closer to market and usefulness than we probably think, partly because of rapidly advancing AI algorithms and exponential compute. Biomaterials could play a key role in soft robotics. In the Nature paper mentioned above, the squid-inspired protein was tested as a pneumatic soft actuator that, when self-healed, still performed just as well as when it was pristine. These bioactuators allowed for experimental success gripping objects with non-flat shapes such as a cherry tomato. Further, the lightweight but high toughness of spider silk protein and other biomaterials could apply well to nimble and durable robots.
Over time, performance biomaterials will be better understood. As this happens, they will become integrated in increasingly complex products with other emerging technologies.
Conclusion
A future filled with performance biomaterials is coming fast. These materials are the tip of a new materials paradigm spear. Startups will integrate them into compelling new products, industries will be shaken up by them, and I am optimistic that people be more inspired to build the future.
Personally, I am in the early stages of exploring ideas for a consumer startup integrating performance biomaterials. Let’s talk more about this if interesting to you.
Reach out on Twitter or email.
Thanks to James Giammona, Eben Bayer, Catherine Tubb, Henry Lee, Yang Fan and Anna Delas for feedback on earlier drafts.
If you liked this article, sign up for free updates to new posts in your inbox.
Member discussion",2
428,"The Rise of ‘Luxury Surveillance’
Surveillance isn’t just imposed on people: Many of us buy into it willingly.
Imagine, for a moment, the near future Amazon dreams of.
Every morning, you are gently awakened by the Amazon Halo Rise. From its perch on your nightstand, the round device has spent the night monitoring the movements of your body, the light in your room, and the space’s temperature and humidity. At the optimal moment in your sleep cycle, as calculated by a proprietary algorithm, the device’s light gradually brightens to mimic the natural warm hue of sunrise. Your Amazon Echo, plugged in somewhere nearby, automatically starts playing your favorite music as part of your wake-up routine. You ask the device about the day’s weather; it tells you to expect rain. Then it informs you that your next “Subscribe & Save” shipment of Amazon Elements Super Omega-3 softgels is out for delivery. On your way to the bathroom, a notification bubbles up on your phone from Amazon’s Neighbors app, which is populated with video footage from the area’s Amazon Ring cameras: Someone has been overturning garbage cans, leaving the community’s yards a total wreck. (Maybe it’s just raccoons.)
Standing at the sink, you glance at the Amazon Halo app, which is connected to your Amazon Halo fitness tracker. You feel awful, which is probably why the wearable is analyzing your tone of voice as “low energy” and “low positivity.” Your sleep score is dismal. After your morning rinse, you hear the Amazon Astro robot chasing your dog, Fred, down the hallway; you see on the Astro’s video feed that Fred is gnawing on your Amazon Essentials athletic sneaker. Your Ring doorbell sounds. The pills have arrived.
It would be a bit glib—and more than a little clichéd—to call this some kind of technological dystopia. Actually, dystopia wouldn’t be right, exactly: Dystopian fiction is generally speculative, whereas all of these items and services are real. At the end of September, Amazon announced a suite of tech products in its move toward “ambient intelligence,” which Amazon’s hardware chief, Dave Limp, described as technology and devices that slip into the background but are “always there,” collecting information and taking action against it.
This intense devotion to tracking and quantifying all aspects of our waking and non-waking hours is nothing new—see the Apple Watch, the Fitbit, social media writ large, and the smartphone in your pocket—but Amazon has been unusually explicit about its plans. The Everything Store is becoming an Everything Tracker, collecting and leveraging large amounts of personal data related to entertainment, fitness, health, and, it claims, security. It’s surveillance that millions of customers are opting in to.
I won’t be one of them. Growing up in Detroit under the specter of the police unit STRESS—an acronym for “Stop the Robberies, Enjoy Safe Streets”—armed me with a very specific perspective on surveillance and how it is deployed against Black communities. A key tactic of the unit was the deployment of surveillance in the city’s “high crime” areas. In two and a half years of operation during the 1970s, the unit killed 22 people, 21 of whom were Black. Decades later, Detroit—with its Project Greenlight web of cameras and a renewed commitment to ShotSpotter microphones, which purport to detect gunfire and help police respond without a 911 call—continues to be one of the Blackest and most surveilled cities in America. My work concentrates on how surveillance mechanisms are disproportionately deployed against Black folks; think of facial recognition falsely incriminating Black men, or the Los Angeles Police Department requesting Ring-doorbell footage of Black Lives Matter protests.
The conveniences promised by Amazon’s suite of products may seem divorced from this context; I am here to tell you that they’re not. These “smart” devices all fall under the umbrella of what the digital-studies scholar David Golumbia and I call “luxury surveillance”—that is, surveillance that people pay for and whose tracking, monitoring, and quantification features are understood by the user as benefits. These gadgets are analogous to the surveillance technologies deployed in Detroit and many other cities across the country in that they are best understood as mechanisms of control: They gather data, which are then used to affect behavior. Stripped of their gloss, these devices are similar to the ankle monitors and surveillance apps such as SmartLINK that are forced on people on parole or immigrants awaiting hearings. As the author and activist James Kilgore writes, “The ankle monitor—which for almost two decades was simply an analog device that informed authorities if the wearer was at home—has now grown into a sophisticated surveillance tool via the use of GPS capacity, biometric measurements, cameras, and audio recording.”
The functions Kilgore describes mirror those offered by wearables and other trackers that many people are happy to spend hundreds of dollars on. Gadgets such as Fitbits, Apple Watches, and the Amazon Halo are pitched more and more for their ability to gather data that help you control and modulate your behavior, whether that’s tracking your steps, looking at your breathing, or analyzing the tone of your voice. The externally imposed control of the formerly incarcerated becomes the self-imposed control of the individual.
Amazon and its Ring subsidiary deny allegations that their devices enable harmful surveillance and deepen racial inequities. “Ring’s mission is to make neighborhoods safer, and that means for everyone—not just certain communities,” Emma Daniels, a spokesperson for Amazon Ring, said in response to a request for comment. “We take these topics seriously, which is why Ring has conducted independent audits with credible third-party organizations like the NYU School of Law to ensure that the products and services we build promote equity, transparency, and accountability. With respect to Halo, no one views your personally identifiable Halo health data without your permission, and Halo Band and Halo View do not have GPS and cannot be used to track individuals.”
Here, it’s useful to remember that contexts shift very quickly when technology is involved. Ring approached the NYU School of Law in 2020 to audit its products—specifically, their impacts on privacy and policing. That report came out in December 2021 and promised to produce greater “transparency” where the company’s partnerships with law enforcement are concerned. This past July—just seven months later—Senator Edward Markey released a letter indicating that the company had given doorbell footage to police without the owners’ consent 11 times this year alone. (Amazon did not deny this in a statement to Politico, but it stressed that it does not give “anyone unfettered access to customer data or video.”)
And remember, GPS tracking isn’t the only form of surveillance. Health-monitoring and smart-home devices all play a role. Consumers may believe that they have nothing to fear (or hide) from these luxury-surveillance devices, or that adopting this technology could only benefit them. But these very devices are now leveraged against people by their employers, the government, their neighbors, stalkers, and domestic abusers. To buy into these ecosystems is to tacitly support their associated harms.
Hidden below all of this is the normalization of surveillance that consistently targets marginalized communities. The difference between a smartwatch and an ankle monitor is, in many ways, a matter of context: Who wears one for purported betterment, and who wears one because they are having state power enacted against them? Looking back to Detroit, surveillance cameras, facial recognition, and microphones are supposedly in place to help residents, although there is scant evidence that these technologies reduce crime. Meanwhile, the widespread adoption of surveillance technologies—even ones that offer supposed benefits—creates an environment where even more surveillance is deemed acceptable. After all, there are already cameras and microphones everywhere.
The luxury-surveillance market is huge and diverse—it is not just Amazon, of course. But Amazon is the market leader in key categories, and its language and product announcements paint a clear picture. (Note also that Apple and Google have yet to advertise an airborne security drone that patrols your hallways, as Amazon has.)
At the bottom of its press releases, Amazon reminds us that it is guided by four tenets, the first of which is “customer obsession rather than competitor focus.” It would be wise to remember that this obsession takes the form of rampant data gathering. What does it mean when one’s life becomes completely legible to tech companies? Taken as a whole, Amazon’s suite of consumer products threatens to turn every home into a fun-house-mirror version of a fulfillment center. Ultimately, we may be managed as consumers the way the company currently manages its workers—the only difference being that customers will pay for the privilege.",6
429,"In March, ride-hailing driver Charles Mayati joined hundreds of other South African drivers in a three-day strike. In Durban and Johannesburg, drivers logged off the ride-hailing apps, blocked roads, and marched to government offices to demand an end to what they said amounted to “exploitation” by the tech companies. The price of fuel was rising at the same time as their living costs were increasing, but the platforms hadn’t adjusted their fares, leaving workers struggling to make ends meet.
The drivers won a small victory. Uber agreed to hike its prices by 10%, and Bolt increased its base fares by one South African rand ($0.065) per kilometer. But within weeks, the benefits were erased by a sharp rise in the cost of fuel, which now costs 40% more than it did a year ago. “It feels like a useless protest,” Mayati, who drives for Uber and its Chinese-owned competitor Didi, told Rest of World, sitting in his car outside a mall in East Rand, a sprawling industrial hub to the east of Johannesburg.
Mayati is just one of many ride-hailing workers in South Africa who have been experiencing difficulties recently. “I won’t rule out selling off my car,” Fikile Duma, a Bolt driver in Johannesburg, told Rest of World. Duma said his earnings had plummeted to 8,000 rand (around $500) a month, from 12,000 rand ($775) a month in 2020.
South Africa is not an outlier. Faced with growing inflation, exacerbated by Russia’s February invasion of Ukraine and the resulting disruption to oil and grain supplies, gig economy workers around the world are feeling the crunch.
The United Nations Food and Agriculture Organization reports that food prices are now 75% higher than they were in mid-2020, while crude oil leapt from around $80 a barrel in January 2022 to around $120 in June. That has translated into rising prices at the pump and higher household costs around the world. This has put huge pressure on many workers in the gig economy, who typically pay their own costs, and who are often already barely scraping by in insecure jobs.
Rest of World spoke to workers across the gig economy in South Africa, India, and Argentina to understand the challenges they face. Their experiences show that they, and the companies they work for, are in an increasingly precarious position.
“Universally, the self-employed, gig model is more vulnerable to price shocks, more vulnerable to inflation, because the costs are absorbed at the individual level, rather than at the firm level,” said Matthew Cole, a post-doctoral researcher at Fairwork, a labor research organization. “The platform model … is all about outsourcing the costs to workers, and the cost-of-living crisis will bring this into real, stark focus.”
Kalamjeet Gill is kept up at night by his fear that his 14-year-old son, who has asthma, might have a medical emergency. Gill, 48, has been driving for ride-hailing companies Uber and Ola in New Delhi for the past eight years. He works between 10 and 12 hours a day but is increasingly struggling to make ends meet as rising fuel prices eat into his profits, just as the cost of living increases.
Gill said he makes around 25,000 rupees ($322) a month, 10,000 rupees of which goes to paying back a loan he took out to buy his car. Petrol and diesel prices spiked in India earlier in the year, but have moderated slightly after the government cut duty on them. However, since March, the price of compressed natural gas (CNG), which is used by Gill and most ride-hailing taxis in Delhi, has gone up by more than 20% in the past few months, while the annual food price inflation rate has passed 8%. What’s left is barely enough to cover his costs.
“Petrol and CNG prices have gone through the roof in the last six months, but the companies have not increased our pay,” he told Rest of World. “I’m not exaggerating, there have been days this year when I told my wife to make just one meal for me in a day.” An out-of-pocket expense, like a health crisis, could stretch him to the limit.
Last year, before costs started to rise, research by Rest of World and the survey company Premise found that more than 40% of Indian platform workers struggled to earn enough to feed their families. Another 17% could only just afford food. With their take-home pay falling, many workers are finding themselves drawn into this category.
Mohiddin, 21, who asked to be referred to by his first name because he feared retribution from his employer, started working as a delivery driver for Zomato in the southern Indian city of Hyderabad two years ago, hoping to raise money for his tuition fees and to provide financial support for his family. He works 10-12 hours a day while studying for an undergraduate degree in computing, making around 12,000 rupees ($154) a month, 4,000 of which goes to renting his bike.
The 8,000 rupees he has left barely covers his needs, he said, and things get more difficult in the summer: the heat means he makes fewer miles to the gallon and breaks down more often, “all of which we have to bear from our profit,” he said.
Mohiddin, who lives in a rented house with his parents, said that he felt gig economy companies lured people in with the promise of flexible hours and decent pay, but that the work was becoming unsustainable. “Prices of vegetables, cooking oil, and gas cylinders have all gone up in the last six months, and our income is falling,” he said.
Workers’ groups said they have petitioned the national and state governments to support struggling gig workers, but little has been done. “[The government] calls us for meetings, but at the end of the day, they side with these big companies. Even our basic demands — like increase in pay, when petrol and CNG prices have gone up — have been neglected,” Shaik Salauddin, general secretary of the Indian Federation of App-Based Transport Workers, told Rest of World. “Today, gig workers are a big part of everyone’s life. We deliver your groceries and your food. We drop you at your offices and pick you up. But no one cares about us.”
The impact of inflation could mean that “gig workers leave the economy altogether,” said Oliver Large, a senior policy analyst at the Tony Blair Institute for Global Change, who studies platform labor. Those that stay could refuse to offer less lucrative services, such as shorter journeys. Services that rely on shorter journeys, such as “quick commerce” platforms, which typically promise deliveries within 10 or 15 minutes, could become even more unattractive for gig workers. “And that will have a knock-on effect for the platforms, in terms of the availability of these particular services,” Large said.
It isn’t just delivery riders and taxi drivers who are struggling to make ends meet in the platform economy. Restaurants, which food delivery platforms rely on, are facing the dual challenge of rising prices and falling demand. Restaurants have often complained that high fees and the need to pay for promotions make it hard to turn a profit on delivery platforms such as UberEats, Rappi, or GrabFood. Inflation is making that even harder.
In Argentina, many restaurants went online during the pandemic via delivery apps, such as PedidosYa and Rappi. The online food delivery business grew 400% during the country’s lockdowns in 2020, according to the consultancy Focus Market.
Argentina has experienced high inflation for more than a decade, but the problem has worsened this year. With the annual rate of inflation now pushing past 70%, the industry is struggling to adapt. Flour, which cost 1,350 pesos ($11.14) for a 25-kilogram bag in 2019, now costs 2,000 pesos ($16.32).
Juan Navarro manages Churros El Topo, a churrería (churros shop) with five outlets across the Buenos Aires area, which sells around 35% of its orders through PedidosYa and Rappi. He said that, despite growing costs, his company has made the decision not to raise its prices. “If we transfer the rise in our costs directly to our [consumers], we’d be selling a luxury product,” he said. The company maintains the same prices for counter sales and sales through the apps, which means that the commission taken from the platforms eats into its margins.
Restaurant owners told Rest of World that platforms’ commissions during the pandemic were as high as 30% for some restaurants. Juan Manuel Ottaviano, a labor lawyer and researcher at the National University of General San Martín’s Center for Training and Studies on Work and Development, said that the companies change their rates to manage supply. For example, if the platforms feel they need more ice cream parlors in an area, they might offer a reduced rate to parlors to encourage more supply, or pressure them to change their pricing. “There is an asymmetry between the platform companies and the small outlets — which are the majority — when setting rates and determining prices,” Ottaviano told Rest of World.
This has meant that many smaller restaurants have simply had to “absorb part of raw-materials inflation,” Ottaviano said, because they need to meet the platforms’ expectations. If they don’t meet the platforms’ needs, they fear being delisted or excluded from promotions.
Some restaurants have had to push their rising costs onto the consumer in order to stay afloat. Juan Corbella, a manager at restaurant company Rato, which operates two outlets in the Argentinian city of Rosario, depends on PedidosYa and Rappi for 80% of his business. “Our cost obviously includes raw materials, and in Argentina there is no other option but to transfer costs to prices,” Corbella said.
The apps’ commission means that he has to increase prices even more. “We must add 10% to [the added costs from inflation], because the apps take 25% of each sale,” he said, referring to the rate his restaurant pays.
Rappi, PedidosYa, Uber, and Bolt did not respond to requests for comment.
Experts told Rest of World that, even as their workers and suppliers struggle, gig economy companies have few options. “I think [the problem] is very profound,” Howard Yu, the LEGO professor of management and innovation at the Institute for Management Development (IMD) business school in Switzerland, told Rest of World. “Unless their core product is actually very profitable, they are in a very, very precarious and vulnerable position.”
Few of the platform businesses make significant profits; most have funded their expansion by spending venture capital money, growing enormously but not solving the basic economics of their businesses. In the recent past, the companies might have dealt with waning demand and discontent in the workforce by burning cash on customer promotions and subsidies for drivers and riders. However, investors’ appetite for supporting unprofitable companies has waned — accelerated by a slump in tech stocks that has wiped billions of dollars off the value of major VCs’ portfolios. A rise in interest rates in the U.S. is also likely to lead to capital flowing out of emerging markets, further reducing the amount of money available to tech companies like PedidosYa or Rappi.
Yu, echoing other experts, said that the gig economy industry may be facing a moment of reckoning, where unprofitable companies and “unicorns that are one-trick ponies” without diversified businesses may end up having to merge with others or close. “Because underneath there is no viable economic model,” Yu said. “For the longest time, people kind of turned a blind eye to it. And it has never been a sustainable business model.”",4
430,"Introduction to systems thinking for civil servants
Published 24 May 2022
© Crown copyright 2022
This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit nationalarchives.gov.uk/doc/open-government-licence/version/3 or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: psi@nationalarchives.gov.uk.
Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
This publication is available at https://www.gov.uk/government/publications/systems-thinking-for-civil-servants/introduction
This document is a short introduction to systems thinking for civil servants. It is one component of a suite of documents that aims to act as a springboard into systems thinking for civil servants unfamiliar with this approach. This suite of documents includes:
1. The systems thinking journey
What: Weaves systems thinking throughout the policy design process. Outlines how systems thinking complements existing guidance.
Who: Designed as a first step into understanding systems thinking.
2. The systems thinking toolkit
What: A step-by-step guide to 11 simple and accessible systems thinking tools. Includes illustrative examples and templates for each tool.
Who: Designed for those who want to use systems thinking.
3. The systems thinking case study bank
What: A collection of testimonials from a diverse group of civil servants across government.
Who: Anyone interested in examples of systems thinking in government.
These documents introduce a small sample of systems thinking concepts and tools, chosen due to their accessibility and alignment to civil service policy development, but which is by no means comprehensive. They are intended to act as a first step towards using systems thinking approaches to solve complex problems and the reader is encourage to explore the wider systems thinking field further.
Why is systems thinking important for civil servants?
Government faces many challenges. Some of these are simple, where the objectives are clear, stakeholders’ motivations align and possible solutions are relatively easily evaluated and implemented. However, many challenges, such as ‘Levelling Up’, can be difficult to define and understand, and ways of influencing them to improve outcomes are hard to design, evaluate and implement.
Such challenges and opportunities involve many people and organisations with competing priorities and have a bearing on many adjacent policy areas. The success of an intervention often relies on collective action taken across boundaries. No single individual, agency or department can tackle a complex problem alone. Nor should they have to. Civil servants need different tools and approaches to deliver desired outcomes in these complex situations – a systems thinking approach.
Our systems thinking definitions:
A system is a set of elements or parts interconnected in such a way that they produce their own pattern of behaviour over time. Systems thinking is a framework for seeing the interconnections in a system and a discipline for seeing and understanding the whole system; the ‘structures’ that underlie complex situations. It is a collection of tools and approaches that help support us in thinking systemically about our work. Systems thinking is particularly powerful when applied to complex systems. By creating simple models of complex systems, systems thinking can be a useful building block towards understanding and visualising data flows within a system. While data visualisation and frameworks are outside of the scope of these documents, useful resources are signposted in the Systems Thinking Toolkit.
What is a complex system?
Complex systems behave in a way that is greater than the sum of their parts – you can’t understand the system just by looking at individual elements, it needs to be studied as a whole. Likewise in complex systems there are underlying patterns – feedback loops – which mean that it becomes difficult to relate cause to effect and actions to consequences.
Examples of these kinds of systems are the human brain, weather, economies. But a lot of policymaking is also complex and attempts to understand and influence policy need to take this complexity into account. Thus systems thinking is increasingly being promoted as a key tool for policymakers to be aware of.
What are systems thinking tools and when do I use them?
There are multiple systems thinking tools and approaches available to help you navigate and work effectively within a complex problem. The systems thinking toolkit includes 11 of these and signposts to many more. The tools described in the toolkit were chosen for their accessibility to all civil servants with no need for prior knowledge of systems thinking to use them.
The tools map to 4 stages for policy design for a complex problem, as shown in the figure above.
This iterative cycle was developed to align in part to the current policy development process described in existing publications such as HM Treasury’s Green Book. This alignment aims to be helpful to civil servants in understanding when to use systems thinking in policy development.
The inner loop shows four stages that all feed into and effect each other in policy design for complex problems. Each policy design stage should feed into the next and the cycle should be treated as iterative. In other words, monitoring and evaluation should be considered when confirming your goals. The outer loop shows how the 11 tools in the toolkit are grouped to each policy design stage. The tools are mapped to the policy design stages to keep systems thinking as accessible and rooted in language and stages that civil servants are familiar with.
How to know when systems thinking is the right approach: Identifying if your work is complex, and therefore a systems thinking approach is appropriate, is explored below. On the right are statements typical of complex problems, on the left are statements typical of projects that may be complicated, but that are still likely to obey a linear cause and effect when it comes to making changes. As you consider the problem, the stakeholders, the predictability of the policy setting and your ambition, see if you relate more to the right or left hand side statements. This should help inform whether or not systems thinking is the right approach for you and your team.
The prompts below help you identify if your work is complex and therefore would especially benefit from a systems thinking approach (adapted from Systems Practice by Omidyar group). Which of the statements below are more true for your project?
|Statement 1||Statement 2|
|The problem||The problem is well understood. We know what causes it, and there is solid evidence that our proposed actions will have the intended effects.||We are not really sure we understand the problem, let alone the solution|
|The stakeholders||There is a high level of consensus among stakeholders and experts about what to do.||There is a significant diversity of opinion and even conflict among stakeholders and experts about what to do.|
|Predictability of policy setting||The problem is relatively self-contained and not intertwined with its broader environment which is stable and predictable.||There are may diverse and dynamic interconnections between the problem and the broader environemnt which itself is unstable and dynamic (political, economic etc).|
|Ambition||It is a short-term goal.||We are aiming to make sustained change at a broad scale.|
|Add it all up - is systems thinking the right approach?||I can probably apply other approaches to this problem.||Systems thinking could be highly useful for helping my team grapple with this messy problem.|
Conclusion and next steps
Complex systems are by their nature dynamic and continuously changing. It might take time before changes are observed. However, by wrapping a systems thinking approach around existing processes – introducing new tools and approaches to improve what you already do – you will increase the chance of delivering the right solution to the right problem. You will have created a safety net to steward the system effectively and impactfully within this complexity to create intelligent, empathetic and impactful outcomes.
We hope this document has introduced you to what systems thinking is and when to use it. We now encourage you to explore the other documents on systems thinking published by the Government Office for Science which are outlined at the start of this document. These will help you deepen your understanding of key systems thinking concepts (The systems thinking journey), introduce you to other systems thinking practitioners across government (The systems thinking case study bank) and help you use accessible systems thinking tools (The systems thinking toolkit).",2
431,"A library for generating text adversarial examples
Project description
TextAttack 🐙
Generating adversarial examples for NLP models
[TextAttack Documentation on ReadTheDocs]
About • Setup • Usage • Design
About
TextAttack is a Python framework for adversarial attacks, data augmentation, and model training in NLP.
If you're looking for information about TextAttack's menagerie of pre-trained models, you might want the TextAttack Model Zoo page.
Slack Channel
For help and realtime updates related to TextAttack, please join the TextAttack Slack!
Why TextAttack?
There are lots of reasons to use TextAttack:
- Understand NLP models better by running different adversarial attacks on them and examining the output
- Research and develop different NLP adversarial attacks using the TextAttack framework and library of components
- Augment your dataset to increase model generalization and robustness downstream
- Train NLP models using just a single command (all downloads included!)
Setup
Installation
You should be running Python 3.6+ to use this package. A CUDA-compatible GPU is optional but will greatly improve code speed. TextAttack is available through pip:
pip install textattack
Once TextAttack is installed, you can run it via command-line (
textattack ...)
or via python module (
python -m textattack ...).
Tip: TextAttack downloads files to
~/.cache/textattack/by default. This includes pretrained models, dataset samples, and the configuration file
config.yaml. To change the cache path, set the environment variable
TA_CACHE_DIR. (for example:
TA_CACHE_DIR=/tmp/ textattack attack ...).
Usage
Help:
textattack --help
TextAttack's main features can all be accessed via the
textattack command. Two very
common commands are
textattack attack <args>, and
textattack augment <args>. You can see more
information about all commands using
textattack --help
or a specific command using, for example,
textattack attack --help
The
examples/ folder includes scripts showing common TextAttack usage for training models, running attacks, and augmenting a CSV file.
The documentation website contains walkthroughs explaining basic usage of TextAttack, including building a custom transformation and a custom constraint..
Running Attacks:
textattack attack --help
The easiest way to try out an attack is via the command-line interface,
textattack attack.
Tip: If your machine has multiple GPUs, you can distribute the attack across them using the
--paralleloption. For some attacks, this can really help performance. (If you want to attack Keras models in parallel, please check out
examples/attack/attack_keras_parallel.pyinstead)
Here are some concrete examples:
TextFooler on BERT trained on the MR sentiment classification dataset:
textattack attack --recipe textfooler --model bert-base-uncased-mr --num-examples 100
DeepWordBug on DistilBERT trained on the Quora Question Pairs paraphrase identification dataset:
textattack attack --model distilbert-base-uncased-cola --recipe deepwordbug --num-examples 100
Beam search with beam width 4 and word embedding transformation and untargeted goal function on an LSTM:
textattack attack --model lstm-mr --num-examples 20 \ --search-method beam-search^beam_width=4 --transformation word-swap-embedding \ --constraints repeat stopword max-words-perturbed^max_num_words=2 embedding^min_cos_sim=0.8 part-of-speech \ --goal-function untargeted-classification
Tip: Instead of specifying a dataset and number of examples, you can pass
--interactiveto attack samples inputted by the user.
Attacks and Papers Implemented (""Attack Recipes""):
textattack attack --recipe [recipe_name]
We include attack recipes which implement attacks from the literature. You can list attack recipes using
textattack list attack-recipes.
To run an attack recipe:
textattack attack --recipe [recipe_name]
|Attack Recipe Name||Goal Function||ConstraintsEnforced||Transformation||Search Method||Main Idea|
Attacks on classification tasks, like sentiment classification and entailment:
|
||Untargeted {Classification, Entailment}||Percentage of words perturbed, Word embedding distance, DistilBERT sentence encoding cosine similarity, part-of-speech consistency||Counter-fitted word embedding swap (or) BERT Masked Token Prediction||Greedy-WIR (gradient)||from ([""Towards Improving Adversarial Training of NLP Models"" (Yoo et al., 2021)](https://arxiv.org/abs/2109.00544))|
|
||Untargeted {Classification, Entailment}||Percentage of words perturbed, Language Model perplexity, Word embedding distance||Counter-fitted word embedding swap||Genetic Algorithm||from ([""Generating Natural Language Adversarial Examples"" (Alzantot et al., 2018)](https://arxiv.org/abs/1804.07998))|
|
||Untargeted Classification||USE sentence encoding cosine similarity||BERT Masked Token Prediction||Greedy-WIR||BERT masked language model transformation attack from ([""BAE: BERT-based Adversarial Examples for Text Classification"" (Garg & Ramakrishnan, 2019)](https://arxiv.org/abs/2004.01970)).|
|
||Untargeted Classification||USE sentence encoding cosine similarity, Maximum number of words perturbed||BERT Masked Token Prediction (with subword expansion)||Greedy-WIR||([""BERT-ATTACK: Adversarial Attack Against BERT Using BERT"" (Li et al., 2020)](https://arxiv.org/abs/2004.09984))|
|
||{Untargeted, Targeted} Classification||checklist distance||contract, extend, and substitutes name entities||Greedy-WIR||Invariance testing implemented in CheckList . ([""Beyond Accuracy: Behavioral Testing of NLP models with CheckList"" (Ribeiro et al., 2020)](https://arxiv.org/abs/2005.04118))|
|
||Untargeted {Classification, Entailment}||USE sentence encoding cosine similarity||RoBERTa Masked Prediction for token swap, insert and merge||Greedy||[""Contextualized Perturbation for Textual Adversarial Attack"" (Li et al., 2020)](https://arxiv.org/abs/2009.07502))|
|
||{Untargeted, Targeted} Classification||Levenshtein edit distance||{Character Insertion, Character Deletion, Neighboring Character Swap, Character Substitution}||Greedy-WIR||Greedy replace-1 scoring and multi-transformation character-swap attack ([""Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers"" (Gao et al., 2018)](https://arxiv.org/abs/1801.04354)|
|
||Untargeted {Classification, Entailment}||Percentage of words perturbed, Language Model perplexity, Word embedding distance||Counter-fitted word embedding swap||Genetic Algorithm||Modified, faster version of the Alzantot et al. genetic algorithm, from ([""Certified Robustness to Adversarial Word Substitutions"" (Jia et al., 2019)](https://arxiv.org/abs/1909.00986))|
|
||Untargeted Classification||Word Embedding Cosine Similarity, Part-of-speech match, Number of words perturbed||Gradient-Based Word Swap||Beam search||([""HotFlip: White-Box Adversarial Examples for Text Classification"" (Ebrahimi et al., 2017)](https://arxiv.org/abs/1712.06751))|
|
||Untargeted {Classification, Entailment}||Percentage of words perturbed, Word embedding distance||Counter-fitted word embedding swap||Genetic Algorithm||Improved genetic algorithm -based word substitution from ([""Natural Language Adversarial Attacks and Defenses in Word Level (Wang et al., 2019)""](https://arxiv.org/abs/1909.06723)|
|
||Input Reduction||Word deletion||Greedy-WIR||Greedy attack with word importance ranking , Reducing the input while maintaining the prediction through word importance ranking ([""Pathologies of Neural Models Make Interpretation Difficult"" (Feng et al., 2018)](https://arxiv.org/pdf/1804.07781.pdf))|
|
||Untargeted Classification||Thought vector encoding cosine similarity, Language model similarity probability||Counter-fitted word embedding swap||Greedy word swap||([""Adversarial Examples for Natural Language Classification Problems"" (Kuleshov et al., 2018)](https://openreview.net/pdf?id=r1QZ3zbAZ))|
|
||Untargeted Classification||Minimum word length, Maximum number of words perturbed||{Neighboring Character Swap, Character Deletion, Character Insertion, Keyboard-Based Character Swap}||Greedy search||simulates common typos ([""Combating Adversarial Misspellings with Robust Word Recognition"" (Pruthi et al., 2019)](https://arxiv.org/abs/1905.11268)|
|
||Untargeted Classification||HowNet Word Swap||Particle Swarm Optimization||([""Word-level Textual Adversarial Attacking as Combinatorial Optimization"" (Zang et al., 2020)](https://www.aclweb.org/anthology/2020.acl-main.540/))|
|
||Untargeted Classification||WordNet-based synonym swap||Greedy-WIR (saliency)||Greedy attack with word importance ranking based on word saliency and synonym swap scores ([""Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency"" (Ren et al., 2019)](https://www.aclweb.org/anthology/P19-1103/))|
|
||Untargeted Classification||USE sentence encoding cosine similarity||{Character Insertion, Character Deletion, Neighboring Character Swap, Character Substitution}||Greedy-WIR||([([""TextBugger: Generating Adversarial Text Against Real-world Applications"" (Li et al., 2018)](https://arxiv.org/abs/1812.05271)).|
|
||Untargeted {Classification, Entailment}||Word Embedding Distance, Part-of-speech match, USE sentence encoding cosine similarity||Counter-fitted word embedding swap||Greedy-WIR||Greedy attack with word importance ranking ([""Is Bert Really Robust?"" (Jin et al., 2019)](https://arxiv.org/abs/1907.11932))|
Attacks on sequence-to-sequence models:
|
||Minimum BLEU Score||Inflection Word Swap||Greedy search||Greedy to replace words with their inflections with the goal of minimizing BLEU score ([""It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations""](https://www.aclweb.org/anthology/2020.acl-main.263.pdf)|
|
||Non-overlapping output||Counter-fitted word embedding swap||Greedy-WIR||Greedy attack with goal of changing every word in the output translation. Currently implemented as black-box with plans to change to white-box as done in paper ([""Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples"" (Cheng et al., 2018)](https://arxiv.org/abs/1803.01128))|
Recipe Usage Examples
Here are some examples of testing attacks from the literature from the command-line:
TextFooler against BERT fine-tuned on SST-2:
textattack attack --model bert-base-uncased-sst2 --recipe textfooler --num-examples 10
seq2sick (black-box) against T5 fine-tuned for English-German translation:
textattack attack --model t5-en-de --recipe seq2sick --num-examples 100
Augmenting Text:
textattack augment
Many of the components of TextAttack are useful for data augmentation. The
textattack.Augmenter class
uses a transformation and a list of constraints to augment data. We also offer built-in recipes
for data augmentation:
wordnetaugments text by replacing words with WordNet synonyms
embeddingaugments text by replacing words with neighbors in the counter-fitted embedding space, with a constraint to ensure their cosine similarity is at least 0.8
charswapaugments text by substituting, deleting, inserting, and swapping adjacent characters
edaaugments text with a combination of word insertions, substitutions and deletions.
checklistaugments text by contraction/extension and by substituting names, locations, numbers.
clareaugments text by replacing, inserting, and merging with a pre-trained masked language model.
Augmentation Command-Line Interface
The easiest way to use our data augmentation tools is with
textattack augment <args>.
textattack augment
takes an input CSV file and text column to augment, along with the number of words to change per augmentation
and the number of augmentations per input example. It outputs a CSV in the same format with all the augmentation
examples corresponding to the proper columns.
For example, given the following as
examples.csv:
""text"",label ""the rock is destined to be the 21st century's new conan and that he's going to make a splash even greater than arnold schwarzenegger , jean- claud van damme or steven segal."", 1 ""the gorgeously elaborate continuation of 'the lord of the rings' trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth ."", 1 ""take care of my cat offers a refreshingly different slice of asian cinema ."", 1 ""a technically well-made suspenser . . . but its abrupt drop in iq points as it races to the finish line proves simply too discouraging to let slide ."", 0 ""it's a mystery how the movie could be released in this condition ."", 0
The command
textattack augment --input-csv examples.csv --output-csv output.csv --input-column text --recipe embedding --pct-words-to-swap .1 --transformations-per-example 2 --exclude-original
will augment the
text column by altering 10% of each example's words, generating twice as many augmentations as original inputs, and exclude the original inputs from the
output CSV. (All of this will be saved to
augment.csv by default.)
Tip: Just as running attacks interactively, you can also pass
--interactiveto augment samples inputted by the user to quickly try out different augmentation recipes!
After augmentation, here are the contents of
augment.csv:
text,label ""the rock is destined to be the 21st century's newest conan and that he's gonna to make a splashing even stronger than arnold schwarzenegger , jean- claud van damme or steven segal."",1 ""the rock is destined to be the 21tk century's novel conan and that he's going to make a splat even greater than arnold schwarzenegger , jean- claud van damme or stevens segal."",1 the gorgeously elaborate continuation of 'the lord of the rings' trilogy is so huge that a column of expression significant adequately describe co-writer/director pedro jackson's expanded vision of j . rs . r . tolkien's middle-earth .,1 the gorgeously elaborate continuation of 'the lordy of the piercings' trilogy is so huge that a column of mots cannot adequately describe co-novelist/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .,1 take care of my cat offerings a pleasantly several slice of asia cinema .,1 taking care of my cat offers a pleasantly different slice of asiatic kino .,1 a technically good-made suspenser . . . but its abrupt drop in iq points as it races to the finish bloodline proves straightforward too disheartening to let slide .,0 a technically well-made suspenser . . . but its abrupt drop in iq dot as it races to the finish line demonstrates simply too disheartening to leave slide .,0 it's a enigma how the film wo be releases in this condition .,0 it's a enigma how the filmmaking wo be publicized in this condition .,0
The 'embedding' augmentation recipe uses counterfitted embedding nearest-neighbors to augment data.
Augmentation Python Interface
In addition to the command-line interface, you can augment text dynamically by importing the
Augmenter in your own code. All
Augmenter objects implement
augment and
augment_many to generate augmentations
of a string or a list of strings. Here's an example of how to use the
EmbeddingAugmenter in a python script:
>>> from textattack.augmentation import EmbeddingAugmenter >>> augmenter = EmbeddingAugmenter() >>> s = 'What I cannot create, I do not understand.' >>> augmenter.augment(s) ['What I notable create, I do not understand.', 'What I significant create, I do not understand.', 'What I cannot engender, I do not understand.', 'What I cannot creating, I do not understand.', 'What I cannot creations, I do not understand.', 'What I cannot create, I do not comprehend.', 'What I cannot create, I do not fathom.', 'What I cannot create, I do not understanding.', 'What I cannot create, I do not understands.', 'What I cannot create, I do not understood.', 'What I cannot create, I do not realise.']
You can also create your own augmenter from scratch by importing transformations/constraints from
textattack.transformations and
textattack.constraints. Here's an example that generates augmentations of a string using
WordSwapRandomCharacterDeletion:
>>> from textattack.transformations import WordSwapRandomCharacterDeletion >>> from textattack.transformations import CompositeTransformation >>> from textattack.augmentation import Augmenter >>> transformation = CompositeTransformation([WordSwapRandomCharacterDeletion()]) >>> augmenter = Augmenter(transformation=transformation, transformations_per_example=5) >>> s = 'What I cannot create, I do not understand.' >>> augmenter.augment(s) ['What I cannot creae, I do not understand.', 'What I cannot creat, I do not understand.', 'What I cannot create, I do not nderstand.', 'What I cannot create, I do nt understand.', 'Wht I cannot create, I do not understand.']
Training Models:
textattack train
Our model training code is available via
textattack train to help you train LSTMs,
CNNs, and
transformers models using TextAttack out-of-the-box. Datasets are
automatically loaded using the
datasets package.
Training Examples
Train our default LSTM for 50 epochs on the Yelp Polarity dataset:
textattack train --model-name-or-path lstm --dataset yelp_polarity --epochs 50 --learning-rate 1e-5
Fine-Tune
bert-base on the
CoLA dataset for 5 epochs*:
textattack train --model-name-or-path bert-base-uncased --dataset glue^cola --per-device-train-batch-size 8 --epochs 5
To check datasets:
textattack peek-dataset
To take a closer look at a dataset, use
textattack peek-dataset. TextAttack will print some cursory statistics about the inputs and outputs from the dataset. For example,
textattack peek-dataset --dataset-from-huggingface snli
will show information about the SNLI dataset from the NLP package.
To list functional components:
textattack list
There are lots of pieces in TextAttack, and it can be difficult to keep track of all of them. You can use
textattack list to list components, for example, pretrained models (
textattack list models) or available search methods (
textattack list search-methods).
Design
Models
TextAttack is model-agnostic! You can use
TextAttack to analyze any model that outputs IDs, tensors, or strings. To help users, TextAttack includes pre-trained models for different common NLP tasks. This makes it easier for
users to get started with TextAttack. It also enables a more fair comparison of attacks from
the literature.
Built-in Models and Datasets
TextAttack also comes built-in with models and datasets. Our command-line interface will automatically match the correct dataset to the correct model. We include 82 different (Oct 2020) pre-trained models for each of the nine GLUE tasks, as well as some common datasets for classification, translation, and summarization.
A list of available pretrained models and their validation accuracies is available at
textattack/models/README.md. You can also view a full list of provided models
& datasets via
textattack attack --help.
Here's an example of using one of the built-in models (the SST-2 dataset is automatically loaded):
textattack attack --model roberta-base-sst2 --recipe textfooler --num-examples 10
HuggingFace support:
transformers models and
datasets datasets
We also provide built-in support for
transformers pretrained models
and datasets from the
datasets package! Here's an example of loading
and attacking a pre-trained model and dataset:
textattack attack --model-from-huggingface distilbert-base-uncased-finetuned-sst-2-english --dataset-from-huggingface glue^sst2 --recipe deepwordbug --num-examples 10
You can explore other pre-trained models using the
--model-from-huggingface argument, or other datasets by changing
--dataset-from-huggingface.
Loading a model or dataset from a file
You can easily try out an attack on a local model or dataset sample. To attack a pre-trained model,
create a short file that loads them as variables
model and
tokenizer. The
tokenizer must
be able to transform string inputs to lists or tensors of IDs using a method called
encode(). The
model must take inputs via the
__call__ method.
Custom Model from a file
To experiment with a model you've trained, you could create the following file
and name it
my_model.py:
model = load_your_model_with_custom_code() # replace this line with your model loading code tokenizer = load_your_tokenizer_with_custom_code() # replace this line with your tokenizer loading code
Then, run an attack with the argument
--model-from-file my_model.py. The model and tokenizer will be loaded automatically.
Custom Datasets
Dataset from a file
Loading a dataset from a file is very similar to loading a model from a file. A 'dataset' is any iterable of
(input, output) pairs.
The following example would load a sentiment classification dataset from file
my_dataset.py:
dataset = [('Today was....', 1), ('This movie is...', 0), ...]
You can then run attacks on samples from this dataset by adding the argument
--dataset-from-file my_dataset.py.
Dataset loading via other mechanism, see: more details at here
import textattack my_dataset = [(""text"",label),....] new_dataset = textattack.datasets.Dataset(my_dataset)
Dataset via AttackedText class
To allow for word replacement after a sequence has been tokenized, we include an
AttackedText object
which maintains both a list of tokens and the original text, with punctuation. We use this object in favor of a list of words or just raw text.
Attacks and how to design a new attack
We formulate an attack as consisting of four components: a goal function which determines if the attack has succeeded, constraints defining which perturbations are valid, a transformation that generates potential modifications given an input, and a search method which traverses through the search space of possible perturbations. The attack attempts to perturb an input text such that the model output fulfills the goal function (i.e., indicating whether the attack is successful) and the perturbation adheres to the set of constraints (e.g., grammar constraint, semantic similarity constraint). A search method is used to find a sequence of transformations that produce a successful adversarial example.
This modular design unifies adversarial attack methods into one system, enables us to easily assemble attacks from the literature while re-using components that are shared across attacks. We provides clean, readable implementations of 16 adversarial attack recipes from the literature (see above table). For the first time, these attacks can be benchmarked, compared, and analyzed in a standardized setting.
TextAttack is model-agnostic - meaning it can run attacks on models implemented in any deep learning framework. Model objects must be able to take a string (or list of strings) and return an output that can be processed by the goal function. For example, machine translation models take a list of strings as input and produce a list of strings as output. Classification and entailment models return an array of scores. As long as the user's model meets this specification, the model is fit to use with TextAttack.
Goal Functions
A
GoalFunction takes as input an
AttackedText object, scores it, and determines whether the attack has succeeded, returning a
GoalFunctionResult.
Constraints
A
Constraint takes as input a current
AttackedText, and a list of transformed
AttackedTexts. For each transformed option, it returns a boolean representing whether the constraint is met.
Transformations
A
Transformation takes as input an
AttackedText and returns a list of possible transformed
AttackedTexts. For example, a transformation might return all possible synonym replacements.
Search Methods
A
SearchMethod takes as input an initial
GoalFunctionResult and returns a final
GoalFunctionResult The search is given access to the
get_transformations function, which takes as input an
AttackedText object and outputs a list of possible transformations filtered by meeting all of the attack’s constraints. A search consists of successive calls to
get_transformations until the search succeeds (determined using
get_goal_results) or is exhausted.
On Benchmarking Attacks
-
See our analysis paper: Searching for a Search Method: Benchmarking Search Algorithms for Generating NLP Adversarial Examples at EMNLP BlackBoxNLP.
-
As we emphasized in the above paper, we don't recommend to directly compare Attack Recipes out of the box.
-
This comment is due to that attack recipes in the recent literature used different ways or thresholds in setting up their constraints. Without the constraint space held constant, an increase in attack success rate could come from an improved search or transformation method or a less restrictive search space.
-
Our Github on benchmarking scripts and results: TextAttack-Search-Benchmark Github
On Quality of Generated Adversarial Examples in Natural Language
- Our analysis Paper in EMNLP Findings
- We analyze the generated adversarial examples of two state-of-the-art synonym substitution attacks. We find that their perturbations often do not preserve semantics, and 38% introduce grammatical errors. Human surveys reveal that to successfully preserve semantics, we need to significantly increase the minimum cosine similarities between the embeddings of swapped words and between the sentence encodings of original and perturbed sentences.With constraints adjusted to better preserve semantics and grammaticality, the attack success rate drops by over 70 percentage points.
- Our Github on Reevaluation results: Reevaluating-NLP-Adversarial-Examples Github
- As we have emphasized in this analysis paper, we recommend researchers and users to be EXTREMELY mindful on the quality of generated adversarial examples in natural language
- We recommend the field to use human-evaluation derived thresholds for setting up constraints
Multi-lingual Support
-
see example code: https://github.com/QData/TextAttack/blob/master/examples/attack/attack_camembert.py for using our framework to attack French-BERT.
-
see tutorial notebook: https://textattack.readthedocs.io/en/latest/2notebook/Example_4_CamemBERT.html for using our framework to attack French-BERT.
-
See README_ZH.md for our README in Chinese
Contributing to TextAttack
We welcome suggestions and contributions! Submit an issue or pull request and we will do our best to respond in a timely manner. TextAttack is currently in an ""alpha"" stage in which we are working to improve its capabilities and design.
See CONTRIBUTING.md for detailed information on contributing.
Citing TextAttack
If you use TextAttack for your research, please cite TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP.
@inproceedings{morris2020textattack, title={TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP}, author={Morris, John and Lifland, Eli and Yoo, Jin Yong and Grigsby, Jake and Jin, Di and Qi, Yanjun}, booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pages={119--126}, year={2020} }
Project details
Release history Release notifications | RSS feed
Download files
Download the file for your platform. If you're not sure which to choose, learn more about installing packages.",3
432,"|
|
|
|
Fictions Of Every Kind
By JG Ballard
Books & Bookmen
February 1971
Everything is becoming science fiction. From the margins of an almost invisible literature has sprung the intact reality of the 20th century. What the writers of modern science fiction invent today, you and I will do tomorrow -- or, more exactly, in about 10 years' time, though the gap is narrowing. Science fiction is the most important fiction that has been written for the last 100 years. The compassion, imagination, lucidity and vision of H.G. Wells and his successors, and above all their grasp of the real identity of the 20th century, dwarf the alienated and introverted fantasies of James Joyce, Eliot and the writers of the so-called Modern Movement, a 19th century offshoot of bourgeois rejection. Given its subject matter, its eager acceptance of naiveté, optimism and possibility, the role and importance of science fiction can only increase. I believe that the reading of science fiction should be compulsory. Fortunately, compulsion will not be necessary, as more and more people are reading it voluntarily. Even the worst science fiction is better -- using as the yardstick of merit the mere survival of its readers and their imaginations -- than the best conventional fiction. The future is a better key to the present than the past.
Above all, science fiction is likely to be the only form of literature which will cross the gap between the dying narrative fiction of the present and the cassette and videotape fictions of the near future. What can Saul Bellow and John Updike do that J. Walter Thompson, the world's largest advertising agency and its greatest producer of fiction, can't do better? At present science fiction is almost the only form of fiction which is thriving, and certainly the only fiction which has any influence on the world around it. The social novel is reaching fewer and fewer readers, for the clear reason that social relationships are no longer as important as the individual’s relationship with the technological landscape of the late 20th century.
In essence, science fiction is a response to science and technology as perceived by the inhabitants of the consumer goods society, and recognizes that the role of the writer today has totally changed -- he is now merely one of a huge army of people filling the environment with fictions of every kind. To survive, he must become far more analytic, approaching his subject matter like a scientist or engineer. If he is to produce fiction at all, he must out-imagine everyone else, scream louder, whisper more quietly. For the first time in the history of narrative fiction, it will require more than talent to become a writer. What special skills, proved against those of their fellow members of society, have Muriel Spark or Edna O'Brien, Kingsley Amis or Cyril Connolly? Sliding gradients point the way to their exits.
It is now some 15 years since the sculptor Eduardo Paolozzi, a powerful and original writer in his own right, remarked that the science fiction magazines produced in the suburbs of Los Angeles contained far more imagination and meaning than anything he could find in the literary periodicals of the day. Subsequent events have proved Paolozzi's sharp judgment correct in every respect. Fortunately, his own imagination has been able to work primarily within the visual arts, where the main tradition for the last century has been the tradition of the new. Within fiction, unhappily, the main tradition for all too long has been the tradition of the old. Like the inmates of some declining institution, increasingly forgotten and ignored by the people outside, the leading writers and critics count the worn beads of their memories, intoning the names of the dead, dead who were not even the contemporaries of their own grandparents.
Meanwhile, science fiction, as my agent remarked to me recently in a pleasant tone, is spreading across the world like a cancer. A benign and tolerant cancer, like the culture of beaches. The time-lag of its acceptance narrows -- I estimate it at present to be about 10 years. My guess is that the human being is a nervous and fearful creature, and nervous and fearful people detest change. However, as everyone becomes more confident, so they are prepared to accept change, the possibility of a life radically different from their own. Like green stamps given away at the supermarkets of chance and possibility, science fiction becomes the new currency of an ever-expanding future.
The one hazard facing science fiction, the Trojan horse being trundled towards its expanding ghetto -- a high-rent area if there ever was one in fiction -- is that faceless creature, literary criticism. Almost all the criticism of science fiction has been written by benevolent outsiders, who combine zeal with ignorance, like high-minded missionaries viewing the sex rites of a remarkably fertile aboriginal tribe and finding every laudable influence at work except the outstanding length of penis. The depth of penetration of the earnest couple, Lois and Stephen Rose (authors of The Shattered Ring), is that of a pair of practicing Christians who see in science fiction an attempt to place a new perspective on ""man, nature, history and ultimate meaning."" What they fail to realize is that science fiction is totally atheistic: those critics in the past who have found any mystical strains at work have been blinded by the camouflage. Science fiction is much more concerned with the significance of the gleam on an automobile instrument panel than on the deity's posterior -- if Mother Nature has anything in science fiction, it is VD.
Most critics of science fiction trip into one of two pitfalls -- either, like Kingsley Amis in New Maps of Hell, they try to ignore altogether the technological trappings and relate SF to the ""mainstream"" of social criticism, anti-utopian fantasies and the like (Amis's main prophecy for science fiction in 1957 and proved wholly wrong), or they attempt to apostrophize SF in terms of individual personalities, hopelessly rivaling the far-better financed efforts of American and British Publishers to sell their fading Wares by dressing their minor talents in the great-writer mantle. Science fiction has always been very much a corporate activity, its writers sharing a common pool of ideas, and the yardsticks of individual achievement do not measure the worth of the best Writers, Bradbury, Asimov, Bernard Wolfe Limbo 90) and Frederik Pohl, The anonymity of the majority of 20th-century Writers of science fiction is the anonymity of modern technology; no more ""great names"" stand out than in the design of consumer durables, or for that matter Rheims Cathedral.
Who designed the 1971 Cadillac El Dorado, a complex of visual, organic and psychological clues of infinitely more subtlety and relevance, stemming from a vastly older network of crafts and traditions than, say, the writings of Norman Mailer or the latest Weidenfeld or Cape miracle? The subject matter of SF is the subject matter of everyday life: the gleam on refrigerator cabinets, the contours of a wife's or husband's thighs passing the newsreel images on a color TV set, the conjunction of musculature and chromium artifact within an automobile interior, the unique postures of passengers on an airport escalator -- all in all, close to the world of the Pop painters and sculptors. Paolozzi, Hamilton, Warhol, Wesselmann, Ruscha, among others. The great advantage of SF is that it can add one unique ingredient to this hot mix -- words. Write!",8
433,"Invisible asymptotes
""It is said that if you know your enemies and know yourself, you will not be imperiled in a hundred battles; if you do not know your enemies but do know yourself, you will win one and lose one; if you do not know your enemies nor yourself, you will be imperiled in every single battle."" - Sun Tzu
My first job at Amazon was as the first analyst in strategic planning, the forward-looking counterpart to accounting, which records what already happened. We maintained several time horizons for our forward forecasts, from granular monthly forecasts to quarterly and annual forecasts to even five and ten year forecasts for the purposes of fund-raising and, well, strategic planning.
One of the most difficult things to forecast was our adoption rate. We were a public company, though, and while Jeff would say, publicly, that ""in the short run, the stock market is a voting machine, in the long run, it's a scale,"" that doesn't provide any air cover for strategic planning. It's your job to know what's going to happen in the future as best as possible, and every CFO of a public company will tell you that they take the forward guidance portion of their job seriously. Because of information asymmetry, analysts who cover your company depend quite a bit on guidance on quarterly earnings calls to shape their forecasts and coverage for their clients. It's not just that giving the wrong guidance might lead to a correction in your stock price but that it might indicate that you really have no idea where your business is headed, a far more damaging long-run reveal.
It didn't take long for me to see that our visibility out a few months, quarters, and even a year was really accurate (and precise!). What was more of a puzzle, though, was the long-term outlook. Every successful business goes through the famous S-curve, and most companies, and their investors, spend a lot of time looking for that inflection point towards hockey-stick growth. But just as important, and perhaps less well studied, is that unhappy point later in the S-curve, when you hit a shoulder and experience a flattening of growth.
One of the huge advantages for us at Amazon was that we always had a fairly good proxy for our total addressable market (TAM). It was easy to pull the statistics for the size of the global book market. Just as a rule of thumb, one could say that if we took 10% of the global book market it would mean our annual revenues would be X. One could be really optimistic and say that we might even expand the TAM, but finance tends to be the conservative group in the company by nature (only the paranoid survive and all that).
When I joined Amazon I was thrown almost immediately into working with a bunch of MBA's on business plans for music, video, packaged software, magazines, and international. I came to think of our long-term TAM as a straightforward layer cake of different retail markets.
Still, the gradient of adoption was somewhat of a mystery. I could, in my model, understand that one side of it was just exposure. That is, we could not obtain customers until they'd heard of us, and I could segment all of those paths of exposure into fairly reliable buckets: referrals from affiliate sites (we called them Associates), referrals from portals (AOL, Excite, Yahoo, etc.), and word-of-mouth (this was pre-social networking but post-email so the velocity of word-of-mouth was slower than it is today). Awareness is also readily trackable through any number of well-tested market research methodologies.
Still, for every customer who heard of Amazon, how could I forecast whether they'd make a purchase or not? Why would some people use the service while others decided to pass?
For so many startups and even larger tech incumbents, the point at which they hit the shoulder in the S-curve is a mystery, and I suspect the failure to see it occurs much earlier. The good thing is that identifying the enemy sooner allows you to address it. We focus so much on product-market fit, but once companies have achieved some semblance of it, most should spend much more time on the problem of product-market unfit.
For me, in strategic planning, the question in building my forecast was to flush out what I call the invisible asymptote: a ceiling that our growth curve would bump its head against if we continued down our current path. It's an important concept to understand for many people in a company, whether a CEO, a product person, or, as I was back then, a planner in finance.
Amazon's invisible asymptote
Fortunately for Amazon, and perhaps critical to much of its growth over the years, perhaps the single most important asymptote was one we identified very early on. Where our growth would flatten if we did not change our path was, in large part, due to this single factor.
We had two ways we were able to flush out this enemy. For people who did shop with us, we had, for some time, a pop-up survey that would appear right after you'd placed your order, at the end of the shopping cart process. It was a single question, asking why you didn't purchase more often from Amazon. For people who'd never shopped with Amazon, we had a third party firm conduct a market research survey where we'd ask those people why they did not shop from Amazon.
Both converged, without any ambiguity, on one factor. You don't even need to rewind to that time to remember what that factor is because I suspect it's the same asymptote governing e-commerce and many other related businesses today.
Shipping fees.
People hate paying for shipping. They despise it. It may sound banal, even self-evident, but understanding that was, I'm convinced, so critical to much of how we unlocked growth at Amazon over the years.
People don't just hate paying for shipping, they hate it to literally an irrational degree. We know this because our first attempt to address this was to show, in the shopping cart and checkout process, that even after paying shipping, customers were saving money over driving to their local bookstore to buy a book because, at the time, most Amazon customers did not have to pay sales tax. That wasn't even factoring in the cost of getting to the store, the depreciation costs on the car, and the value of their time.
People didn't care about this rational math. People, in general, are terrible at valuing their time, perhaps because for most people monetary compensation for one's time is so detached from the event of spending one's time. Most time we spend isn't like deliberate practice, with immediate feedback.
Wealthy people tend to receive a much more direct and immediate payoff for their time which is why they tend to be better about valuing it. This is why the first thing that most ultra-wealthy people I know do upon becoming ultra-wealthy is to hire a driver and start to fly private. For most normal people, the opportunity cost of their time is far more difficult to ascertain moment to moment.
You can't imagine what a relief it is to have a single overarching obstacle to focus on as a product person. It's the same for anyone trying to solve a problem. Half the comfort of diets that promise huge weight loss in exchange for cutting out sugar or carbs or whatever is feeling like there's a really simple solution or answer to a hitherto intractable, multi-dimensional problem.
Solving people's distaste for paying shipping fees became a multi-year effort at Amazon. Our next crack at this was Super Saver Shipping: if you placed an order of $25 or more of qualified items, which included mostly products in stock at Amazon, you'd receive free standard shipping.
The problem with this program, of course, was that it caused customers to reduce their order frequency, waiting until their orders qualified for the free shipping. In select cases, forcing customers to minimize consumption of your product-service is the right long-term strategy, but this wasn't one of those.
That brings us to Amazon Prime. This is a good time to point out that shipping physical goods isn't free. Again, self-evident, but it meant that modeling Amazon Prime could lead to widely diverging financial outcomes depending on what you thought it would do to the demand curve and average order composition.
To his credit, Jeff decided to forego testing and just go for it. It's not so uncommon in technology to focus on growth to the exclusion of all other things and then solve for monetization in the long run, but it's easier to do so for a social network than a retail business with real unit economics. The more you sell, the more you lose is not and has never been a sustainable business model (people confuse this for Amazon's business model all the time, and still do, which ¯\_(ツ)_/¯).
The rest, of course, is history. Or at least near-term history. It turns out that you can have people pre-pay for shipping through a program like Prime and they're incredibly happy to make the trade. And yes, on some orders, and for some customers, the financial trade may be a lossy one for the business, but on net, the dramatic shift in the demand curve is stunning and game-changing.
And, as Jeff always noted, you can make micro-adjustments in the long run to tweak the profit leaks. For some really large, heavy items, you can tack on shipping surcharges or just remove them from qualifying for Prime. These days, some items in Amazon are marked as ""Add-on items"" and you can only order them in conjunction with enough other items such that they can be shipped with those items rather than in isolation.
[Jeff counseled the same ""fix it later"" strategy in the early days when we didn't have good returns tracking. For a window of time in the early days of Amazon, if you shipped us a box of books for returns, we couldn't easily tell if you'd purchase them at Amazon and so we'd credit you for them, no questions asked. One woman took advantage of this loophole and shipped us boxes and boxes of books. Given our limited software resources, Jeff said to just ignore the lady and build a way to solve for that later. It was really painful, though, so eventually customer service representatives all shared, amongst themselves, the woman's name so they could look out for it in return requests even before such systems were built. Like a mugshot pinned to every monitor saying ""Beware this customer."" A tip of the hat to you, maam, wherever you are, for your enterprising spirit in exploiting that loophole!]
Prime is a type of scale moat for Amazon because it isn't easy for other retailers to match from a sheer economic and logistical standpoint. As noted before, shipping isn't actually free when you have to deliver physical goods. The really challenging unit economics of delivery businesses like Postmates, when paired with people's aversion for paying for shipping, makes for tough sledding, at least until the cost of delivering such goods can be lowered drastically, perhaps by self-driving cars or drones or some such technology shift.
Furthermore, very few customers shop enough with retailers other than Amazon to make a pre-pay program like Prime worthwhile to them. Even if they did, it's very likely Amazon's economies of scale in shipping and deep knowledge of how to distribute their inventory optimally means their unit economics on delivery are likely superior.
The net of it is that long before Amazon hit what would've been an invisible asymptote on its e-commerce growth it had already erased it.
Know thine enemy.
Invisible asymptotes are...invisible
An obvious problem for many companies, however, is that they are creating new types of businesses and services that don't lend themselves to easily identifying such invisible asymptotes. Many are not like Amazon where there are readily tracked metrics like the size of the global book market with which to peg their TAM.
Take social networks, for example. What's the shoulder of the curve for something like Facebook? Twitter? Instagram? Snapchat?
Some of the limits to their growth are easier to spot than others. For messaging and some more general social networking apps, for example, in many cases network effects are geographical. Since these apps build on top of real-world social graphs, and many of those are geographically clustered, there are winner-take-all dynamics such that in many countries one messaging app dominates, like Kakao in Korea or Line in Taiwan. There can be geo-political considerations, too, that help ensure that that WeChat will dominate in China to the exclusion of all competitors, for example.
For others, though, it takes a bit more product insight, and some might say intuition, to see the ceiling before you bump into it. For both employees and investors, understanding product-market unfit follows very closely on identifying product-market fit as an existential challenge.
Without direct access to internal metrics and research, it's difficult to use much other than public information and my own product intuition to analyze potential asymptotes for many companies, but let's take a quick survey of several more prominent companies and consider some of their critical asymptotes (these companies are large enough that they likely have many, but I'll focus on the macro). You can apply this to startups, too, but there are some differences between achieving initial product market fit and avoiding the shoulder in the S-curve after already having found it.
Let's start with Twitter, for many in tech the most frustrating product from the perspective of the gap between the actual and the potential. Its user growth has been flat for quite some time, and so it can be said to have already run full speed into an invisible asymptote. In quarterly earnings calls, it's apparent management often have no idea if or when or how that might shift because their guidance is often a collective shrug.
One popular early school of thought on Twitter, a common pattern with most social networks, is that more users need to experience what the power users or early adopters are experiencing and they'll turn into active users. Many a story of social networks who've continued to grow point to certain keystone metrics as pivotal to unlocking product-market fit. For example, once you've friended 30 people on Facebook, you're hooked. For Twitter, an equivalent may be following enough people to generate an interesting feed.
Pattern-matching moves more quickly through Silicon Valley than almost any other place I've lived, so stories like that are passed around through employees and Board meetings and other places where the rich and famous tech elite hobnob, and so it's not surprising that this theory is raised for every social network that hits the shoulder in their S-curve.
There's more than a whiff of Geoffrey Moore's Crossing the Chasm in this idea, some sense that moving from early adopters to the mainstream involves convincing more users to use the same product/service as early adopters do.
In the case of Twitter, I think the theory is wrong. Given the current configuration of the product, I don't think any more meaningful user growth is possible, and tweaking the product as it is now won't unlock any more growth. The longer they don't acknowledge this, the longer they'll be stuck in a Red Queen loop of their own making.
Sometimes, the product-market fit with early adopters is only that. The product won't go mainstream because other people don't want or need that product. In these cases, the key to unlocking growth is usually customer segmentation, creating different products for different users.
Mistaking one type of business for the other can be a deadly mistake because the strategies for addressing them are so different. A common symptom of this mistake is not seeing the shoulder in the S-curve coming at all, not understanding the nature of your product-market unfit.
I believe the core experience of Twitter has reached most everyone in the world who likes it. Let's examine the core attributes of Twitter the product (which I treat as distinct from Twitter the service, the public messaging protocol).
It is heavily text-based, with 140 and now 280 character limit snippets of text from people you've followed presented in a vertical scrolling feed in some algorithmic order, which, for the purposes of this exercise, I'll just consider roughly chronological.
For fans, most of whom are infovores, the nature of product-market fit is, as with many of our tech products today, one of addiction. Because the chunks of text are short, if one tweet is of no interest, you can quickly scan and scroll to another with little effort. Discovering tweets of interest in what appears to be a largely random order rewards the user with dopamine hits on that time-tested Skinner box variable frequency. Instead of rats hitting levers for pellets of food, power Twitter user push or pull on their phone screens for the next tasty pellet of text.
For infovores, text, in contrast to photos or videos or music, is the medium of choice from a velocity standpoint. There is deep satisfaction in quickly decoding the textual information, the scan rate is self-governed on the part of the reader, unlike other mediums which unfold at their own pace (this is especially the case with video, which infovores hate for its low scannability).
Over time, this loop tightens and accelerates through the interaction of all the users on Twitter. Likes and retweets and other forms of feedback guide people composing tweets to create more of the type that receive positive feedback. The ideal tweet (which I mean one that will receive maximum positive feedback) combines some number of the following attributes:
Is pithy. Sounds like a fortune cookie. The character limit encourages this type of compression.
Is slightly surprising. This can be a contrarian idea or just a cliche encoded in a semi-novel way.
Rewards some set of readers' priors, injecting a pleasing dose of confirmation bias directly into the bloodstream.
Blasts someone that some set of people dislike intensely. This is closely related to the previous point.
Is composed by someone famous, preferably someone a lot of people like but don't consider to be a full-time Tweeter, like Chrissy Teigen or Kanye West.
Is on a topic that most people think they understand or on which they have an opinion.
Of course, the set of ideal qualities varies by subgroup on Twitter. Black Twitter differs from rationalist Twitter which differs from NBA Twitter. The meta point is that the flywheel spins more and more quickly over time within each group.
The problem is that for those who don't use Twitter, almost all of its ideal attributes among the early adopter cohort are those which other people find bewildering and unattractive. Many people find the text-heavy nature of Twitter to be a turn-off. The majority of people, actually.
The naturally random sort order of ideas that comes from the structure of Twitter, one which pings the pleasure centers of the current heavy user cohort when they find an interesting tweet, is utterly perplexing to those who don't get the service. Why should they hunt and peck for something of interest? Why are conversations so difficult to follow (actually, this is a challenge even for those who enjoy Twitter)? Why do people have to work so hard to parse the context of tweets?
Falling into the trap of thinking other users will be like you is especially pernicious because the people building the product are usually among that early adopter cohort. The easiest north star for a product person is their own intuition. But if they're working on a product that requires customer segmentation, being in the early adopter cohort means one's instincts will keep guiding you towards the wrong North star and the company will just keep bumping into the invisible asymptote without any idea why.
This points to an important qualifier to the ""crossing the chasm"" idea of technology diffusion. If the chasm is large enough, the same product can't cross it. Instead, on the other side of the gaping chasm is just a different country altogether, with different constituents with different needs.
I use Twitter a lot (I recently received a notification I'd passed my 11-year anniversary of joining the service) but almost everyone in my family, from my parents to my siblings to my girlfriend to my nieces and nephews has tried and given up on Twitter. It doesn't fulfill any deep-seated need for any of them.
It's not surprising to me that Twitter is populated heavily by journalists and a certain cohort of techies and intellectuals who all, to me, are part of a broader species of infovore. For them, opening Twitter must feel as if they've donned Cerebro and have global contact with thousands of brains all over the world, as if the fabric of their brain had been flattened and stretched out wide and laid on top of that of millions of others brains all over the world.
Mastering Twitter is already something this group of people do all the time in their lives and jobs, only Twitter accelerates it, like a bicycle for intellectual conversation and preening. Twitter, at its best, can provide a feeling of near real-time communal knowledge sharing that satisfies some of the same needs as something like SoulCycle or Peloton. A feeling of communion that also feels like it's productive.
If my instincts are right, then all the iterating around the margins on Twitter won't do much of anything to change the growth curve of the service. It might improve the experience for the current cohort of users and increase usage (for example, curbing abuse and trolls is an immediate and obvious win for those who experience all sorts of terrible harassment on the service), but it doesn't change the fact that this core Twitter product isn't for all the people who left the club long ago, soon after they walked in and realized it was just a bunch of nerds who'd ordered La Croix bottle service and were sitting around talking about Bitcoin and stoicism and transcendental meditation.
The good news is that the Twitter service, that public messaging protocol with a one-way follow model, could be the basis for lots of products that might appeal to other people in the world. Knowing the enemy can prevent wasting time chasing the wrong strategy.
Unfortunately, one of the main paths towards coming up with new products built on top of that protocol was the third party developer program, and, well, Twitter has treated its third party developers like unwanted stepchildren for a long time. For whatever reason, it's difficult to speculate without having been there, Twitter's rate of product development internally has been glacial. A vibrant third party-developer program could have helped by massively increasing the vectors of development on Twitter's very elegant public messaging protocol and datasets.
[Note, however, that I'm sympathetic to tech companies that restrict building clones of their service using their API's. No company owes it to others to allow people to build direct competitors to their own product. Most people don't remember, but Amazon's first web services offering was for affiliates to build sites to sell things. Some sites started building massive Amazon clones and so Amazon's web services evolved into other forms, eventually settling on what most people know it as today.]
In addition, I've long wondered if the shutting out of third party developers on Twitter was an attempt to aggregate and own all their own ad inventory. Both these problems could've been solved by tweaking the Twitter third party development program. Developers could be offered two paths.
One option is that for every X number of tweets a developer pulled, they'd have to carry and display a Twitter-inserted ad unit. This would make it possible for Twitter to support third-party clients like Tweetbot that compete somewhat with Twitter's own clients. Maybe one of these developers would come up with improvements on top of Twitter's own client apps, but in doing so they'd increase Twitter's ad inventory.
The second option would be to pay some fixed fee for every X tweets pulled. That would force the developer to come up with some monetization scheme on their own to cover their usage, but at least the option would exist. I don't doubt that some enterprising developers might come up with some way to monetize a particular use case, for example for business research.
Twitter the product/app has hit its invisible asymptote. Twitter the protocol still has untapped potential.
Snapchat
Snapchat is another example of a company that's hit a shoulder in its growth curve. Unlike Twitter, though, I suspect its invisible asymptote is less an issue of its feature set and more one of a generational divide.
That's not to say that making the interface less inscrutable earlier on wouldn't have helped a bit, but I suspect only at the margins. In fact, the opaque nature of the interface probably served Snapchat incredibly well when the product came along, regardless of whether or not it was intended that way. Snapchat came along at a moment when kids' parents were joining Facebook, and when Facebook had been around long enough for the paper trail of its early, younger users to come back and bite some of them.
Along comes a service that not only wipes out content by default after a short period of time but is inscrutable to the very parents who might crash the party. In fact, there's an entire class of products for which I believe an Easter Egg-like interface is actually preferable to an elegant, self-describing interface, long seen as the apex of UI design (more on that another day).
I've written before about selfies as a second language. At the root of that phenomenon is the idea that a generation of kids raised with smartphones with a camera front and back have found the most efficient way to communicate is with the camera, not the keyboard. That's not the case for an older cohort of users who almost never send selfies as a first resort. The very default of Snapchat to the camera screen is such a bold choice that it will probably never be the messaging app of choice for old folks, no matter how Snapchat moves around and re-arranges its other panes.
More than that, I suspect every generation needs spaces of its own, places to try on and leave behind identities at low cost and on short, finite time horizons. That applies to social virtual spaces as much as it does to physical spaces.
Look at how old people use Snapchat and you'll see lots of use of Stories. Watch a young person use Snapchat and it's predominantly one-to-one messaging using the camera (yes, I know some of the messages I receive on Snap are the same ones that person is sending to everyone one-to-one, but the hidden nature of that behavior allows me to indulge an egocentric rather than Copernican model of the universe). Now, it's possible for one app to serve multiple audiences that way, but it will either have to compromise all or some of its user experience to do so.
At a deeper level, I think a person's need for ephemeral content varies across one's lifetime. It's of much higher value when one is young, especially in formative years. As one ages, and time's counter starts to run low, one turns nostalgic, and the value of permanent content, especially from long bygone days, increases, serving as beautifully aged relics of another era. One also tends to be more adept at managing one's public image the more time passes, lessening the need for ephemerality.
All this is to say that I don't think making the interface of Snapchat easier to use is going to move it off of the shoulder on its S-curve. That's addressing a different underlying cause than the one that lies behind its invisible asymptote.
The good news for Snapchat is that I don't think Facebook is going to be able to attract the youngsters. I don't care if Facebook copies Snapchat's exact app one for one, it's not going to happen. The bad news for Snapchat is that it probably isn't going to attract the oldies either. The most interesting question is whether Snapchat's cohort stays with it for life, and the next interesting question is who attracts the next generation of kids to get their first smartphones. Will they, like every generation of youth before them, demand a social network of their own? Sometimes I think they will just to claim a namespace that isn't already spoken for. Who wants to be joesmith43213 when you can be joesmith on some new sexy social network?
As a competitor, however, Instagram is more worrisome than Facebook. It came along after Facebook, as Snapchat did, and so it had the opportunity to be a social network that a younger generation could roam as pioneers, mining so much social capital yet to be claimed. It is also largely an audio-visual network which is appealing to a more visually literate generation.
When Messenger incorporated Stories into its app, it felt like a middle-aged couple dressing in cowboy chic and attending Coachella. When Instagram cribbed Stories, though, it addressed a real supply-side content creation issue for the same young'uns who used Snapchat. That is, people were being too precious about what they shared on Instagram, decreasing usage frequency. By adding Stories, they created a mechanism that wouldn't force content into the feed and whose ephemerality encouraged more liberal capture and sharing without the associated guilt.
This is a general pattern among social networks and products in general: to broaden their appeal they tend to broaden their use cases. It's rare to see a product adhere strictly to its early specificity and still avoid hitting a shoulder in their adoption S-curve. Look at Facebook today compared to Facebook in its early days. Look at Amazon's product selection now compared to when it first launched.
It takes internal fortitude for a product team to make such concessions (I would say courage but we need to sprinkle that term around less liberally in tech). The stronger the initial product market fit, the more vociferously your early adopters will protest when you make any changes. Like a band that is accused of selling out, there is an inevitable sense that a certain sharpness of flavor, of choice, has seeped out as more and more people join up and as a service loosens up and accommodates more more use cases.
I remember seeing so many normally level-headed people on Twitter threaten to abandon the service when they announced they were increasing the character limit from 140 to 280. The irony, of course, was that the character-limit increase likely improved the service for its current users while doing nothing to attract people who didn't use the service, even though the move was addressed mostly to heathen.
Back to Snapchat. I wrote a long time ago that the power of social networks lies in their graph. That means many things, and in Snapchat's case it holds a particularly fiendish double bind. That Snapchat is the social network claimed by the young is both a blessing and a curse. Were a bunch of old folks to suddenly flock to Snapchat, it might induce a case of Groucho Marx's, ""I don't care to belong to a club that accepts people like me as members.""
On the dimension of utility, Facebook's network effects continue to be pure and unbounded. The more people that are on Facebook, the more it's useful for certain things for which a global directory is useful. Even though many folks don't use Facebook a lot, it's rare I can't find them on Messenger if I don't have their email address or phone number. The complexity of analyzing Facebook is that it serves different needs in different countries and markets, social network having strong path dependency in their usage patterns. In many countries, Facebook is the internet; it's odd as an American to travel to countries where businesses' only presence online is a Facebook page, so accustomed I am to searching for American businesses on the web or Yelp first.
When it comes to the ""social"" aspect of social networking, the picture is less clear-cut. Here I'll focus on the U.S. market since it's the one I'm most familiar with. Because Facebook is the largest social network in history, it may be encountering scaling challenges few other entities have ever seen.
The power of a social network lies in its graph, and that is a conundrum in many ways. One is that a massive graph is a blessing until it's a curse. For social creatures like humans who've long lived in smaller networks and tribes, a graph that conflates everyone you know is intimidating to broadcast to, except for those who have no compulsion about performing no matter the audience size: famous people, marketers, and those monstrous people who share everything about their lives. You know who you are.
This is one of the diseconomies of scale for social networks that Facebook is first to run into because of its unprecedented size. Imagine you're in a room with all your family, friends, coworkers, casual acquaintances, and a lot of people you met just once but felt guilty about rejecting a friend request from. It's hundreds, maybe even thousands of people. What would you say to them? We know people maintain multiple identities for different audiences in their lives. Very few of us have to cultivate an identity for that entire blob of everyone we know. It's a situation one might encounter in the real world only a few times in life, perhaps at one's wedding, and later one's funeral. Online, though? It happens to be the default mode on Facebook's News Feed.
It's no coincidence that public figures, those who have the most practice at having to deal with this problem, are so guarded. As your audience grows larger, the chance that you'll offend someone deeply with something you say approaches 1.
When I scan my Facebook feed, I see fewer and fewer people I know sharing anything at all. Map one's sharing frequency with the size of one's friend list on Facebook and I highly suspect it looks like this:
Again, not everyone is like this, some psychopaths who are comfortable sharing their thoughts no matter the size of the audience, but these people are often annoying, the type who dive right into politics at Thanksgiving before you've even spooned gravy over your turkey. This leads to a form of adverse selection where a few over-sharers take over your News Feed.
[Not everything one shares gets distributed to one's entire friend graph given the algorithmic feed. But you as the one sharing something have no idea who will see it so you have to assume that any and every person in your graph will see it. The chilling effect is the same.]
Another form of diseconomy of scale is behind the flight to Snapchat among the young, as outlined earlier. A sure way to empty a club or a dance floor is to have the parents show up; few things are more traumatic then seeing your Dad pretend-grind on your Mom when ""Yeah"" by Usher comes on. Having your parents in your graph on Facebook means you have to assume they're listening, and there isn't some way to turn on the radio very loudly or run the water as in a spy movie when you're trying to pass secrets to someone in a room that's bugged. The best you can do is communicate in code to which your parents don't own the decryption key; usually this takes the form of memes. Or you take the communication over to Snapchat.
Another diseconomy of scale is the increasing returns to trolling. Facebook is more immune to this thanks to its bi-directional friending model than, say, Twitter, with its one-way follow model and public messaging framework. On Facebook, those wishing to sow dissension need to be a bit more devious, and as revelations from the last election showed, there are means to a person's heart, to reach them directly or indirectly, through confirmation bias and flattery. The Iago playbook from Othello. On Twitter, there's no need for such scheming, you can just nuke people from your keyboard without their consent.
All of this is to say I suspect many of Facebook's more fruitful vectors for rekindling their value for socializing lie in breaking up the surface area of their service. News Feed is so monolithic a surface as to be subject to all the diseconomies of scale of social networking, even as it makes it such an attractive advertising landscape.
The most obvious path to this is Groups, which can subdivide large graphs into ones more unified in purpose or ideology. Google+ was onto something with Circles, but since they hadn't actually achieved any scale they were solving a problem they didn't have yet.
Where is Instagram's invisible asymptote? This is one of the trickier ones to contemplate as it continues to grow without any obvious end in sight.
One of the advantages to Instagram is that it came about when Facebook was broadening its acceptable media types from text to photos and video. Instagram began with just square photos with a simple caption, no links allowed, no resharing.
This had a couple of advantages. One is that it's harder to troll or be insufferable in photos than it is in text. Photos tend to soften the edge of boasts and provocations. More people are more skilled at being hurtful in text than photos. Instagram has tended to be more aggressive than other networks at policing the emotional tenor of its network, especially in contrast to, say Twitter, turning its attention most recently to addressing trolls in the comment sections.
Of course photos are not immune to this phenomenon. The ""look at my perfect life"" boasting of Instagram is many people's chief complaint about the app and likely the primary driver of people feeling lousy after looking through their feed there. Still, outright antagonism with Instagram, given it isn't an open public graph like Twitter, is harder. The one direct vector is comments and Instagram is working on that issue.
In being a pure audio-visual network at a time when Facebook and most other networks were mixed-media, Instagram siphoned off many people for whom the best part of Facebook was just the photos and videos; again, we often, as with Twitter, over-estimate the product-market fit and TAM of text. If Facebook just showed photos and videos for a week I suspect their usage would grow, but since they own Instagram...
As with other social networks that grow, Instagram broadened its formats early on to head off several format-based asymptotes. Non-square photos and videos with gradually lengthening time limits have broadened the use cases and, more importantly, removed some level of production friction.
The move to copy Snapchat's Stories format was the next giant asymptote avoided. The precious nature of sharing on Instagram was a drag on posting frequency. Stories solves the supply-side issue for content several ways. One is that since it requires you to explicitly tap into viewing it from the home feed screen, it shifts the onus for viewing the content entirely to the audience. This frees the content creator from much of the guilt of polluting someone else's feed. The expiring nature of the content further removes another of a publisher's inhibitions about littering the digital landscape. It unlocked so much content that I now regularly fail to make it through more than a tiny fraction of Stories on Instagram. Even friends who don't publish a lot now often put their content in Stories rather than posting to the main feed.
The very format of Stories, with its full-screen vertical orientation, cues the user that this format is meant for the native way we hold our devices as smartphone photographers, rather than accommodating the more natural landscape way that audiences view the world, with eyes side-by-side in one's head. Stories includes accoutrements like gaudy stickers and text overlays and face filters that aren't in the toolset for Instagram's main feed photo/video composer, perhaps to preserve some aesthetic separation between the main feed and Stories.
There is a purity about Instagram which makes even its ads perfectly native: everything on the service is an audio-visual advertisement. I see people complain about the ad load in Instagram, but if you really look at your feed, it's always had an ad load of 100%.
I just opened my feed and looked through the first twenty posts, and I'd classify them all as ads: about how great my meal was, for beautiful travel destinations, for the exquisite craft of various photographers and cinematographers, for an actor's upcoming film, for Rihanna's new lingerie line or makeup drop, for an elaborate dish a friend cooked, for a current concert tour, for how funny someone is, for someone's gorgeous new headshot, and for a few sporting events and teams. And yes, a few of them were official Instagram ads.
I don't mean this in a negative way. One might lobby this accusation at all social networks, but the visual nature of Instagram absorbs the signaling function of social media in the most elegant and unified way. For example, messaging apps consist of a lot of communication that isn't advertising. But that's exactly why a messaging app like Messenger isn't as lucrative an ad platform as Instagram is and will be. If ads weren't marked explicitly, and if they weren't so obviously from accounts I don't follow, it's not clear to me that they'd be so jarringly different in nature than all the other content in the feed.
The irony is that, as Facebook broadened its use cases and supported media types to continue to expand, the purity of Instagram may have made it more scalable a network in some ways.
Of course, every product or service has some natural ceiling. To take one example, messaging with other folks is still somewhat clunky on Instagram, it feels tacked on. Considering how much young people use Snapchat as a messaging app of choice, there's likely attractive headroom for Instagram here.
Rumors Instagram is contemplating a separate messaging app make sense. It would be ironic if Instagram separated out the more broadcast nature of its core app from the messaging use case in two different apps before Snapchat did. As noted earlier, it feels as if Snapchat is constantly fighting to balance the messaging parts of its app with the more broadcast elements like Stories and Discover, and separate apps might be one way to solve that more effectively.
As with all social networks which are mobile-phone dominant, there are limits to what can be optimized for in a single app, when all you have to work with is a single rectangular phone screen. The mobile phone revolution forced a focus in design which created billions of dollars in value, but Instagram, like all phone apps, will run into the asymptote that is the limits of how much you can jam into one app.
Instagram has already had some experience in dealing with this conundrum, creating separate apps like Boomerang or Hyperlapse that keep a lid on the complexity of the Instagram app itself and which bring additional composition techniques to the top level of one's phone. I often hear people counsel against launching separate apps because of the difficulty of getting adoption of even a single app, but that doesn't mean that separate apps aren't sometimes the most elegant way to deal with the spatial design constraints of mobile.
On Instagram, content is still largely short in nature so longer narratives aren't common or well-supported. The very structure, oriented around a main feed algorithmically compiling a variety of content from all the account you follow, isn't optimized towards a deep dive into a particular subject matter or narrative like, say, a television or a streaming video app. The closest to long-form on Instagram is Live, but most of what I see of that is only loosely narrative, resembling more an extended selfie than a considered narrative. Rather than pursue long-form narrative, it may be that a more on-brand way to tackle the challenge of lengthening usage of the app is better stringing together of existing content, similar to how Snapchat can aggregate content from one location into a feed of sorts. That can be useful for things like concerts and sporting events and breaking news events like natural disasters, protests, and marches.
In addition, perhaps there is a general limit to how far a single feed of random content arranged algorithmically can go before we suffer pure consumption exhaustion. Perhaps seeing curated snapshots from everyone will finally push us all to the breaking point of jealousy and FOMO and, across a large enough number of users, an asymptote will emerge.
However, I suspect we've moved into an age where the upper bound on vanity fatigue has shifted much higher in a way that an older generation might find unseemly. Just as we've moved into a post-scarcity age of information, I believe we've moved into a post-scarcity age of identity as well. And in this world, it's more acceptable to be yourself and leverage social media for maximal distribution of yourself in a way that ties to the fundamental way in which the topology of culture has shifted from a series of massive centralized hub and spokes to a more uniform mesh.
A last possible asymptote relates to my general sense that massive networks like Facebook and Instagram will, at some point, require more structured interactions and content units (for example, a list is a structured content unit, as is a check-in) to continue scaling. Doing so always imposes some additional friction on the content creator, but the benefit is breaking one monolithic feed into more distinct units, allowing users the ability to shift gears mentally by seeing and anticipating the structure, much like how a magazine is organized.
To fill gaps in a person's free time, an endless feed is like an endless jar of liquid, able to be poured into any crevice in one's schedule and flow of attention. To demand a person's time, on the other hand, is a higher order task, and more structured content seems to do better on that front. People set aside dedicated time to play games like Fortnite or to watch Netflix, but less so to browse feeds. The latter happens on the fly. But ambition in software-driven Silicon Valley is endless and so at some point every tech company tries to obtain the full complement of Infinity Stones, whether by building them or buying them, like Facebook did with Instagram and Whatsapp.
Amazon's next invisible asymptote?
I started with Amazon, but it is worth revisiting as it is hardly done with its own ambitions. After having made such massive progress on the shipping fee asymptote, what other barriers to growth might remain?
On that same topic of shipping, the next natural barrier is shipping speed. Yes, it's great that I don't have to pay for shipping, but in time customer expectations inflate. Per Jeff's latest annual letter to shareholders:
One thing I love about customers is that they are divinely discontent. Their expectations are never static – they go up. It’s human nature. We didn’t ascend from our hunter-gatherer days by being satisfied. People have a voracious appetite for a better way, and yesterday’s ‘wow’ quickly becomes today’s ‘ordinary’. I see that cycle of improvement happening at a faster rate than ever before. It may be because customers have such easy access to more information than ever before – in only a few seconds and with a couple taps on their phones, customers can read reviews, compare prices from multiple retailers, see whether something’s in stock, find out how fast it will ship or be available for pick-up, and more. These examples are from retail, but I sense that the same customer empowerment phenomenon is happening broadly across everything we do at Amazon and most other industries as well. You cannot rest on your laurels in this world. Customers won’t have it.
Why only two-day shipping for free? What if I want my package tomorrow, or today, or right now?
Amazon has already been working on this problem for over a decade, building out a higher density network of smaller distribution centers over its previous strategy of fewer, gargantuan distribution hubs. Drone delivery may have sounded like a joke when first announced on an episode of 60 Minutes, but it addresses the same problem, as does a strategy like Amazon lockers in local retail stores.
Another asymptote may be that while Amazon is great at being the site of first resort to fulfill customer demands for products, it is less capable when it comes to generating desire ex nihilo, the kind of persuasion typically associated more with a tech company like Apple or any number of luxury retailers.
At Amazon we referred to the dominant style of shopping on the service as spear-fishing. People come in, type a search for the thing they want, and 1-click it. In contrast, if you've ever gone to a mall with someone who loves shopping for shopping's sake, a clotheshorse for example, you'll see a method of shopping more akin to the gathering half of hunting and gathering. Many outfits are picked off the rack and gazed at, held up against oneself in a mirror, turned around and around in the hand for contemplation. Hands brush across racks of clothing, fingers feeling fabric in search of something unknown even to the shopper.
This is browsing, and Amazon's interface has only solved some aspects of this mode of shopping. If you have some idea what you want, similarities carousels can guide one in some comparison shopping, and customer reviews serve as a voice on the shoulder, but it still feels somewhat utilitarian.
Amazon's first attempts at physical stores reflect this bias in its retail style. I visited an Amazon physical bookstore in University Village the last time I was in Seattle, and it struck me as the website turned into 3-dimensional space, just with a lot less inventory. Amazon Go sounds more interesting, and I can't wait to try it out, but again, its primary selling point is the self-serve, low-friction aspect of the experience.
When I think of creating desire, I think of my last and only visit to Milan, when a woman at an Italian luxury brand store talked me into buying a sportcoat I had no idea I wanted when I walked into the store. In fact, it wasn't even on display, so minimal was the inventory when I walked in.
She looked at me, asked me some questions, then went to the back and walked back out with a single option. She talked me into trying it on, then flattered me with how it made me look, as well as pointing out some of its most distinctive qualities. Slowly, I began to nod in agreement, and eventually I knew I had to be the man this sportcoat would turn me into when it sat on my shoulders.
This challenge isn't unique to Amazon. Tech companies in general have been mining the scalable ROI of machine learning and algorithms for many years now. More data, better recommendations, better matching of customer to goods, or so the story goes. But what I appreciate about luxury retail, or even Hollywood, is its skill for making you believe that something is the right thing for you, absent previous data. Seduction is a gift, and most people in technology vastly overestimate how much of customer happiness is solvable by data-driven algorithms while underestimating the ROI of seduction.
Netflix spent $1 million on a prize to improve its recommendation algorithms, and yet it's a daily ritual that millions of people stare at their Netflix home screen, scrolling around for a long time, trying to decide what to watch. It's not just Netflix, open any streaming app. The AppleTV, a media viewing device, is most often praised for its screensaver! That's like admitting you couldn't find anything to eat on a restaurant menu but the typeface was pleasing to the eye. It's not that data can't guide a user towards the right general neighborhood, but more than one tech company will find the gradient of return on good old seduction to be much steeper than they might realize.
Still, for Amazon, this may not be as dangerous a weakness as it would be for another retailer. Much of what Amazon sells is commodities, and desire generation can be offloaded to other channels who then see customers leak to Amazon for fulfillment. Amazon's logistical and customer service supremacy is a devastatingly powerful advantage because it directly precedes and follows the act of payment in the shopping value chain, allowing it to capture almost all the financial return of commodity retail.
And, as Jeff's annual letter to shareholders has emphasized from the very first instance, Amazon's mission is to be the world's most customer-centric company. One way to continue to find vectors for growth is to stay attached at the hip to the fickle nature of customer unhappiness, which they're always quite happy to share under the right circumstances, one happy consequence of this age of outrage. There is such a thing as a price umbrella, but there's also one for customer happiness.
How to identify your invisible asymptotes
One way to identify your invisible asymptotes is to simply ask your customers. As I noted at the start of this piece, at Amazon we honed in on how shipping fees were a brake on our business by simply asking customers and non-customers.
Here's where the oft-cited quote from Henry Ford is brought up as an objection: “If I had asked people what they wanted, they would have said faster horses,"" he is reputed to have said. Like most truisms in business, it is snappy and lossy all at once.
True, it's often difficult for customers to articulate what they want. But what's missed is that they're often much better at pinpointing what they don't want or like. What you should hear when customers say they want a faster horse is not the literal but instead that they find travel by horse to be too slow. The savvy product person can generalize that to the broader need of traveling more quickly, and that problem can be solved any number of ways that don't involve cloning Secretariat or shooting their current horse up with steroids.
This isn't a foolproof strategy. Sometimes customers lie about what they don't like, and sometimes they can't even articulate their discontent with any clarity, but if you match their feedback with good analysis of customer behavior data and even some well-designed tests, you can usually land on a more accurate picture of the actual problem to solve.
A popular sentiment in Silicon Valley is that B2C businesses are more difficult product challenges than B2B because products and services for the business customer can be specified merely by talking to the customer while the consumer market is inarticulate about its needs, per the Henry Ford quote. Again, that's only partially true, and so many consumer companies I've been advising recently haven't pushed enough yet on understanding or empathizing with the objections of its non-adopters.
We speak often of the economics concept of the demand curve, but in product there is another form of demand curve, and that is the contour of the customers' demands of your product or service. How comforting it would be if it were flat, but as Bezos noted in his annual letter to shareholders, the arc of customer demands is long, but it bends ever upwards. It's the job of each company, especially its product team, to continue to be in tune with the topology of this ""demand curve.""
I see many companies spend time analyzing funnels and seeing who emerges out the bottom. As a company grows, though, and from the start, it's just as important to look at those who never make it through the funnel, or who jump out of it at the very top. If the product market fit gradient likely differs for each of your current and potential customer segments, and understanding how and why is a never-ending job.
When companies run focus groups on their products, they often show me the positive feedback. I'm almost invariably more interested in the folks who've registered negative feedback, though I sense many product teams find watching that material to be stomach-churning. Sometimes the feedback isn't useful in the moment; perhaps you have such strong product-market fit with a different cohort that it isn't useful. Still, it's never not a bit of a prick to the ego.
However, all honest negative feedback forms the basis of some asymptote in some customer segment, even if the constraint isn't constricting yet. Even if companies I meet with don't yet have an idea of how to deal with a problem, I'm always curious to see if they have a good explanation for what that problem is.
One important sidenote on this topic is that I'm often invited to give product feedback, more than I can find time for these days. When I'm doing so in person, some product teams can't help but jump in as soon as I raise any concerns, just to show they've already anticipated my objections.
I advise just listening all the way through the first time, to hear the why of someone's feedback, before cutting them off. You'll never be there in person with each customer to talk them out of their reasoning, your product or service has to do that work. The batting average of product people who try to explain to their customers why they're wrong is...not good. It's a sure way to put them off of giving you feedback in the future, too.
Even absent external feedback, it's possible to train yourself to spot the limits to your product. One approach I've taken when talking to companies who are trying to achieve initial or new product-market fit is to ask them why every person in the world doesn't use their product or service. If you ask yourself that, you'll come up with all sorts of clear answers, and if you keep walking that road you'll find the borders of your TAM taking on greater and greater definition.
[It's true that you also need the flip side, an almost irrational positivity, to be able to survive the difficult task of product development, or to be an entrepreneur, but selection bias is such that most such people start with a surplus of optimism.]
Lastly, though I hesitate to share this, it is possible to avoid invisible asymptotes through sheer genius of product intuition. I balk for the same reason I cringe when I meet CEO's in the valley who idolize Steve Jobs. In many ways, a product intuition that is consistently accurate across time is, like Steve Jobs, a unicorn. It's so rare an ability that to lean entirely on it is far more dangerous and high risk than blending it with a whole suite of more accessible strategies.
It's difficult for product people to hear this because there's something romantic and heroic about the Steve Jobs mythology of creation, brilliant ideas springing from the mind of the mad genius and inventor. However, just to read a biography of Jobs is to understand how rare a set of life experiences and choices shaped him into who he was. Despite that, we've spawned a whole bunch of CEO's who wear the same outfit every day and drive their design teams crazy with nitpick design feedback as if the outward trappings of the man were the essence of his skill. We vastly underestimate the path dependence of his particular style of product intuition.
Jobs' gift is so rare that it's likely even Apple hasn't been able to replace it. It's not a coincidence that the Apple products that frustrate me the most right now are all the ones with ""Pro"" in the name. The MacBook Pro, with its flawed keyboard and bizarre Touch Bar (I'm still using the old 13"" MacBook Pro with the old keyboard, hoping beyond hope that Apple will come to its senses before it becomes obsolete). The Mac Pro, which took on the unfortunately apropos shape of a trash can in its last incarnation and whose replacement hasn't shipped in years (I'm still typing this at home on an ancient cheese grater Mac Pro tower and ended up building a PC tower to run VR and to do photo and video editing). Final Cut Pro, which I learned on in film editing school, and which got zapped in favor of Final Cut X just when FCP was starting to steal meaningful share in Hollywood from Avid. The iMac Pro, which isn't easily upgradable but great if you're a gazillionaire.
Pro customers are typically ones with the most clearly specified needs and workflows. Thus, their products are ones for whom listening to them articulate what they want is a reliable path to establishing and maintaining product-market fit. But that's not something Apple seems to enjoy doing, and so the mis-steps they've made on these lines are exactly the types of mistakes you'd expect of them.
[I was overjoyed to read that Apple's next Mac Pro is being built using extensive feedback from media professionals. It's disappointing that it won't arrive until 2019 now but at least Apple has descended from the ivory tower to talk to the actual future users. It's some of the best news out of Apple I've heard in forever.]
Live by intuition, die by it. It's not surprising that Snapchat, another company that lives by the product intuition of one person, stumbled with a recent redesign. That a company's strengths are its weaknesses is simply the result of tight adherence to methodology. Apple and Snapchat's deus ex machina style of handing down products also rid us of CD-ROM drives and produced the iPhone, AirPods, the camera-first messaging app, and the Story format, among many other breakthroughs which a product person could hang a career on.
Because products and services live in an increasingly dynamic world, especially those targeted at consumers, they aren't governed by the immutable, timeless truths of a field like mathematics. The reason I recommend a healthy mix of intuition informed by data and feedback is that most product people I know have a product view that is slower moving than the world itself. If they've achieved any measure of success, it's often because their view of some consumer need was the right one at the right time. Product-market fit as tautology. Selection bias in looking at these people might confuse some measure of luck with some enduring product intuition.
However, just as a VC might have gotten lucky once with some investment and be seen as a genius for life (and the returns to a single buff of a VC brand name is shockingly durable), just because a given person's product intuition might hit on the right moment at the right point in history to create a smash hit, it's rare that a single person's frame will move in lock step with that of the world. How many creatives are relevant for a lifetime?
This is one reason sustained competitive advantage is so difficult. In the long run, endogenous variance in the quality of product leadership in a company always seems to be in the negative direction. But perhaps we are too focused on management quality and not focused enough on exogenous factors. In ""Divine Discontent: Disruption’s Antidote,"" Ben Thompson writes:
Bezos’s letter, though, reveals another advantage of focusing on customers: it makes it impossible to overshoot. When I wrote that piece five years ago, I was thinking of the opportunity provided by a focus on the user experience as if it were an asymptote: one could get ever closer to the ultimate user experience, but never achieve it:
In fact, though, consumer expectations are not static: they are, as Bezos’ memorably states, “divinely discontent”. What is amazing today is table stakes tomorrow, and, perhaps surprisingly, that makes for a tremendous business opportunity: if your company is predicated on delivering the best possible experience for consumers, then your company will never achieve its goal.
In the case of Amazon, that this unattainable and ever-changing objective is embedded in the company’s culture is, in conjunction with the company’s demonstrated ability to spin up new businesses on the profits of established ones, a sort of perpetual motion machine; I’m not sure that Amazon will beat Apple to $1 trillion, but they surely have the best shot at two.
Pattern recognition is the default operation mode of much of Silicon Valley and other fields, but it is almost always, by its very nature, backwards-looking. One can hardly blame most people for resorting to it because it's a way of minimizing blame, and the economic returns of the Valley are so amplified by the structural advantages of winners that even matching market beta makes for a comfortable living.
However, if consumer desires are shifting, it's always just a matter of time before pattern recognition leads to an invisible asymptote. One reason startups are often the tip of the spear for innovation in technology is that they can't rely on market beta to just roll along. Achieving product-market fit for them is an existential challenge, and they have no backup plans. Imagine an investor who has to achieve alpha to even survive.
Companies can stay nimble by turning over its product leaders, but as a product professional, staying relevant to the marketplace is a never-ending job, even if your own life is irreversible and linear. I find the best way to unmoor myself from my most strongly held product beliefs is to increase my inputs. Besides, the older I get, the more I've grown to enjoy that strange dance with the customer. Leading a partner in a dance may give you a feeling of control, but it's a world of difference from dancing by yourself.
One of my favorite Ben Thompson posts is ""What Clayton Christensen Got Wrong"" in which he built on Christensen's theory of disruption to note that low end disruption can be avoided if you can differentiate on user experience. It is difficult and perhaps even impossible to over-serve on that axis. Tesla came into the electric car market with a car that was way more expensive than internal combustion engine cars (this definitely wasn't low-end disruption), had shorter range, and required really slow charging at a time when very few public chargers existed yet.
However, Tesla got an interesting foothold because on another axis it really delivered. Yes, the range allowed for more commuting without having to charge twice a day, but more importantly, for the wealthy, it was a way to signal one's environmental consciousness in a package that was much, much sexier than the Prius, the previous electric car of choice of celebrities in LA. It will be hard for Tesla to continue to rely on that in the long run as the most critical dimension of user experience will likely evolve, but it's a good reminder that ""user experience"" is broad enough to encompass many things, some less measurable than others.
You can't overserve on user experience, Thompson argues; as a product person, I'd argue, in parallel, that it is difficult and likely impossible to understand your customer too deeply. Amazon's mission to the be the world's most customer-centric company is inherently a long-term strategy because it is a one with an infinite time scale and no asymptote to its slope.
In my experience, the most successful people I know are much more conscious of their own personal asymptotes at a much earlier age than others. They ruthlessly and expediently flush them out. One successful person I know determined in grade school that she'd never be a world-class tennis player or pianist. Another mentioned to me how, in their freshman year of college, they realized they'd never be the best mathematician in their own dorm, let alone in the world. Another knew a year into a job that he wouldn't be the best programmer at his company and so he switched over into management; he rose to become CEO.
By discovering their own limitations early, they are also quicker to discover vectors on which they're personally unbounded. Product development will always be a multi-dimensional problem, often frustratingly so, but the value of reducing that dimensionality often costs so little that it should be more widely employed.
This isn't to say a person needs to aspire to be the best at everything they do. I'm at peace with the fact that I'll likely always be a middling cook, that I won't win the Tour de France, and that I'm destined to be behind a camera and not in front of it. When it comes to business, however, and surviving in the ruthless Hobbesian jungle, where much more is winner-take-all than it once was, the idea that you can be whatever you want to be, or build whatever you want to build, is a sure path to a short, unhappy existence.",1
434,"Project Hail Mary
|Author||Andy Weir|
|Audio read by||Ray Porter|
|Cover artist||Will Staehle|
|Country||United States|
|Language||English|
|Genre||Science fiction|
|Publisher||Ballantine Books|
Publication date
|May 4, 2021|
|Media type||Print, ebook, audiobook|
|Pages||496|
|Awards||2021 Dragon Award for Best Science Fiction Novel|
|ISBN||978-0-593-39556-1|
Project Hail Mary is a 2021 science fiction novel by American novelist Andy Weir. Set in the near future, the novel centers on junior high (middle) school-teacher-turned-astronaut Ryland Grace, who wakes up from a coma afflicted with amnesia. He gradually remembers that he was sent to the Tau Ceti solar system, 12 light-years from Earth, to find a means of reversing a solar dimming event that could cause the extinction of humanity.[1]
Project Hail Mary has received generally positive reviews, and the book was a finalist for the 2022 Hugo Award for Best Novel.[2] The unabridged audiobook is read by Ray Porter.[3] The film rights have been purchased by Metro-Goldwyn-Mayer. Drew Goddard (who adapted The Martian, Weir's traditional publishing debut, into a 2015 film) is slated to adapt the book into a film. Actor Ryan Gosling plans to star as Grace in the film adaptation.[4]
Plot[edit]
Narrative structure[edit]
The story is told using a combination of two narrative techniques. Events leading up to the launch of the Hail Mary are revealed through Ryland Grace's flashbacks. The story on board the spacecraft unfolds as a more standard linear narrative. The two perspectives are frequently intercut as Grace regains his memory.
Before launch[edit]
In the near future, a global dimming event is observed, coinciding with the formation of a bright line from the Sun to Venus. The exponential rate of dimming is calculated to result in a catastrophic ice age within 30 years. A space probe broadcasts to the public that the line appears to contain alien microbes. The world's governments cooperate, giving former ESA administrator Eva Stratt unilateral authority and legal immunity to solve the problem.
Stratt nominates Ryland Grace, a teacher and former molecular biologist, as the first person to study a sample of the organism recovered from Venus, as she views him as expendable. He discovers that the single-celled organism consumes all forms of electromagnetic radiation and uses radiant energy to move. Since the organism consumes energy from the Sun, Grace names it ""Astrophage"" (Greek for ""star eater""). Grace subsequently discovers that Astrophage reproduces using carbon dioxide, commonly found on Venus. Other scientists discover that Astrophage employs mass–energy conversion via neutrinos, and can be mass-bred for use as rocket fuel.
Astronomy data reveals that Astrophage infects and dims nearby stars, but one star, Tau Ceti, has unexpectedly resisted Astrophage infection. An Astrophage-fueled starship, the Hail Mary, is developed to travel to Tau Ceti to obtain knowledge of Astrophage resistance, and to return the findings to Earth with unmanned mini-ships. Hail Mary can only be fueled and supplied for a one-way trip, making it a suicide mission.
Since the crew of three astronauts will travel under a coma to avoid psychiatric issues, potential astronauts are restricted to people with coma-resistant genes, including Grace. Stratt tasks Grace to train the science experts for the mission, but the science experts are killed in an Astrophage-induced explosion shortly before launch. With no time to train a replacement, Stratt forces Grace to join the mission. Grace threatens sabotage, so an amnesia-inducing drug is administered to him before launch.
Meanwhile, Stratt orders the release of methane from Antarctica to reduce global cooling, but the threat of famine and wars over food on Earth remains for the 26 years that the Hail Mary mission is expected to take.
Aboard Hail Mary[edit]
Ryland Grace emerges from his coma with no memory of his identity or situation. As the mission proceeds, Grace deduces his situation while his memory returns gradually. Grace finds that his crew members have died en route, and gives them a space burial.
Hail Mary soon reaches Tau Ceti, and is approached by an alien starship, which Grace names ""Blip-A"". The other ship indicates that its home system in 40 Eridani is also plagued by Astrophage infection. Blip-A docks with Hail Mary, and its occupant meets Grace. Grace develops a system to communicate with the spider-like alien, whom Grace names ""Rocky"" due to its stone-like exoskeleton. Rocky, an engineer, has been in Tau Ceti for 40 years as the last survivor of his crew; the others died from space radiation, Grace deduces.
Grace and Rocky discover the Astrophage's home planet in orbit around Tau Ceti, which they name Adrian, after Rocky's Eridian mate. The planet's atmosphere is found to contain a natural predator of Astrophage. While collecting a sample from Adrian, a hull breach occurs and Rocky risks his life to save Grace. Rocky sustains severe injuries but eventually recovers. From the sample, the Astrophage predator is found to be a microbe which Grace names ""Taumoeba"". Grace and Rocky use selective breeding to produce nitrogen-resistant Taumoeba for their home systems.
The Blip-A has enough Astrophage fuel for both ships to return to their planets, so Rocky refuels the Hail Mary, and they part ways. En route, Grace discovers that he has accidentally bred into the Taumoeba the ability to permeate and escape their containers. Although Grace fixes the problem on Hail Mary, he realises that the Blip-A is made of the same material, and the Taumoeba has consumed the fuel and crippled the ship.
Due to limited food, Grace is forced to choose between personally returning to Earth and dooming the Eridians, or saving Rocky and the Eridians while starving on Erid. Grace chooses the latter, sending back his Taumoeba to Earth on a group of probes, while he locates the fuel-less Blip-A and reunites with Rocky. Rocky realises that Grace can eat Rocky's Taumoeba, solving Grace's food shortage.
They return to Erid, fixing the Eridians' Astrophage problem. Using the digital archive of human knowledge given to Grace by Stratt, the Eridians build a system to enable Grace to live on Erid, where he becomes a teacher of Eridian young. Some years later, Rocky tells Grace that the Astrophage infection around the Sun has abated, meaning Grace's mission was a success. Knowing that humanity has survived on Earth, Grace begins considering if he should return to Earth, with the Hail Mary still operational.
Characters[edit]
- Ryland Grace – The novel's protagonist, a disillusioned molecular biologist who becomes a junior high school science teacher before being recruited to study Astrophage by Eva Stratt.
- Eva Stratt – A Dutch woman who previously an administrator at the European Space Agency, who is subsequently given absolute authority to stop Astrophage, leading to the Hail Mary mission. Weir describes Stratt, along with Grace, as the two human ""heroes"" of the book.[5]
- Rocky – An alien engineer from the 40 Eridani system whose planet is simultaneously threatened by Astrophage. Due to his proximity to radiation-shielding Astrophage fuel, he survives space radiation while his crew does not. Rocky's vessel eventually encounters the Hail Mary and works together with Grace.
- Yáo Li-Jie – The intended commander of Hail Mary's crew. He dies en route to Tau Ceti.
- Olesya Ilyukhina – The intended engineer and EVA specialist of Hail Mary’s crew, ribald yet cheerful. She dies en route to Tau Ceti.
- Dr. Lokken – A Norwegian scientist who assists in the design of the Hail Mary and has a short rivalry with Grace over a paper he wrote.
- Dimitri Komorov – A Russian scientist who develops the Astrophage-based propulsion system for the Hail Mary and discovered its mass-conversion properties.
- Steve Hatch – A researcher from the University of British Columbia. He develops the ""Beetle"" probes and is an avid Beatle fan. He is described as very talkative and optimistic.
- Martin DuBois – An American man and original science advisor on the Hail Mary mission. He dies in an explosion nine days before launch. He is described as honest and gregarious.
- Annie Shapiro – The original backup science advisor on the Hail Mary mission. She dies with Martin in the same explosion.
- Robert Redell – A solar energy expert from New Zealand. Arrested for embezzlement and the death of seven technicians in a testing accident, he develops a method to breed Astrophage rapidly.
- François Leclerc – A French climatologist who helps to slow down the climate changes caused by the Astrophage stealing the sun's energy through the development of a method releasing trapped methane embedded in Antarctic ice sheets into the atmosphere through the use of fusion bombs.
Production[edit]
In a profile in The New York Times, Weir says that after completing The Martian, he began a multi-volume space opera called Zhek, which was about a substance that could absorb electromagnetic radiation and use it as a fuel for interstellar travel. He wrote 75,000 words before abandoning the project and beginning on Artemis. Several elements from Zhek were brought over to Project Hail Mary, including a ruthless bureaucrat character, and an energy-absorbing substance used as starship fuel.[6]
Publication[edit]
Project Hail Mary was released on May 4, 2021, by Ballantine Books. It is available in hardcover, e-book, and audiobook formats. The audiobook narrated by Ray Porter uses melodic sound effects in the background, whenever ""Rocky"" speaks.
Reception[edit]
Project Hail Mary has received generally positive reviews. Writing for The New York Times, sci-fi author Alec Nevala-Lee wrote ""For readers who can forgive its shortcomings, the result is an engaging space odyssey.""[7] Kirkus Reviews gave the book a starred review, describing it as ""An unforgettable story of survival and the power of friendship—nothing short of a science-fiction masterwork.""[8]
In writing her review for The Washington Post, SFWA president and science fiction writer Mary Robinette Kowal mentions that there are plenty of things to love about this book, such as Grace's infectious enthusiasm for science. At the same time, Kowal mentions some of the many flaws in the novel, such as the lack of the use of checklists, which are very important in the fields of aviation, astronautics, and medicine in reducing human-induced errors which Grace seems to ignore and could have prevented him from creating his many errors in judgment.[9]
A reviewer for Locus Magazine wrote, ""Project Hail Mary, however, isn’t a simple rehash of The Martian. Instead, it’s a celebration of Weir’s voice... Weir’s jaunty blend of science and fiction in Project Hail Mary is a return to the work that got him where he is.""[10] The reviewer for The Boston Globe wrote that ""Project Hail Mary is still a suspenseful space yarn that zigs and zags — sometimes literally — in ingenious directions.""[11]
Project Hail Mary debuted at number 3 on The New York Times Best Seller list for Combined Print & E-Book Fiction in May 2021.[12] By August 2021, the book had been on the NYT list for 9 weeks.[13] Project Hail Mary additionally achieved the #1 spot on the New York Times Audio Fiction Best Seller List for three weeks in February 2022.[14][15]
The novel debuted at number 2 on the Los Angeles Times SoCal Bestsellers for Hardcover Fiction[16] and number 6 on The Wall Street Journal Bestselling Books List for Hardcover Fiction[17] during the same month. The book was still on the L.A. Times list in mid-August.[18]
In August 2021, Project Hail Mary debuted at number 1 on the Locus Bestsellers list for hardcovers[19] while remaining at the top position for five consecutive months[20] before dropping to a lower position while still remaining on the list for 11 consecutive months by June 2022.[21] As of August 2021[update], the novel remained on the above-mentioned bestseller lists.
Bill Gates and Barack Obama added the book to their respective 2021 book recommendations.[22][23]
Awards[edit]
- 2021 Dragon Award for Best Science Fiction Novel[24]
- 2021 Best Science Fiction, Goodreads Choice Awards[25]
- 2022 Audie Award for Science Fiction[26]
- 2022 Audie Award for Audiobook of the Year[26]
- 2022 Seiun Award Best Translated Long Work[27]
Film adaptation[edit]
Weir sold the book's film adaptation rights to Metro-Goldwyn-Mayer in early 2020 for $3 million.[28] Actor Ryan Gosling plans to produce and star as Ryland Grace. It will be directed and produced by filmmaking duo Phil Lord and Christopher Miller. Its screenwriter will be Drew Goddard, and Ken Kao will produce with Ryan Gosling via their production banner Arcana.[4]
References[edit]
- ^ """"Andy Weir – Project Hail Mary"""". AndyWeirAuthor.com. Retrieved May 12, 2021.
- ^ ""2022 Hugo Awards"". The Hugo Awards. Retrieved June 8, 2022.
- ^ Project Hail Mary by Andy Weir - Audiobook - Audible.com. Audible.com. May 4, 2021. Retrieved May 12, 2021.
- ^ a b McNary, Dave (March 27, 2020). ""Ryan Gosling to Star in Astronaut Movie 'Project Hail Mary'"". Variety. Retrieved May 12, 2021.
- ^ Kaplan (host), Mat (May 5, 2021). ""Author Andy Weir and Project Hail Mary"". Planetary Radio. Episode 1000. The Planetary Society. 16:00 minutes in. Retrieved August 25, 2022.
- ^ Alter, Alexandra (May 3, 2021). ""Andy Weir's New Space Odyssey"". The New York Times. Retrieved May 12, 2021.
- ^ Nevala-Lee, Alec (May 4, 2021). ""Alone on a Spaceship, Trying to Save the World"". The New York Times. Retrieved May 12, 2021.
- ^ ""PROJECT HAIL MARY"". Kirkus Reviews. February 10, 2021. Retrieved May 12, 2021.
- ^ Kowal, Mary Robinette (May 23, 2021). ""Andy Weir's 'Project Hail Mary' is a bestseller. It also has some problems"". The Washington Post.
- ^ Martini, Adrienne (May 5, 2021). ""Adrienne Martini Reviews The Only Living Girl on Earth by Charles Yu and Project Hail Mary by Andy Weir"". Locus Magazine.
- ^ Harlan, Landry (May 13, 2021). ""Science lessons in 'Project Hail Mary'"". The Boston Globe.
- ^ ""Combined Print & E-Book Fiction – Best Sellers – Books"". The New York Times. May 23, 2021. Retrieved May 14, 2021.
- ^ ""Combined Print & E-Book Fiction – Best Sellers – Books"". The New York Times. August 1, 2021.
- ^ ""Audio Fiction Books - Best Sellers - Books - Feb. 6, 2022 - The New York Times"". The New York Times. February 6, 2022. ISSN 0362-4331. Retrieved June 22, 2022.
- ^ ""Audio Fiction Books - Best Sellers - Books - Feb. 27, 2022 - The New York Times"". The New York Times. February 27, 2022. ISSN 0362-4331. Retrieved June 22, 2022.
- ^ ""Bestsellers List Sunday, May 16"". Los Angeles Times. May 12, 2021.
- ^ ""Bestselling Books Week Ended May 8"". The Wall Street Journal. May 13, 2021.
- ^ ""Bestsellers List Sunday, August 22"". Los Angeles Times. August 18, 2021.
- ^ ""Locus Bestsellers, August 2021"". Locus Magazine. August 18, 2021.
- ^ ""Locus Bestsellers, December 2021"". Locus Magazine. December 22, 2021.
- ^ ""Locus Bestsellers, June 2022"". Locus Magazine. June 20, 2022.
- ^ Gates, Bill (November 22, 2021). ""5 books I loved reading this year"". GatesNotes: The Blog of Bill Gates.
- ^ Kranc, Lauren (July 9, 2021). ""Barack Obama Has Shared His Annual Summer Reading List"". Esquire. Retrieved June 26, 2022.
- ^ ""2021 Recipients – The Dragon Award"". Dragon Con. Retrieved September 11, 2021.
- ^ ""Best Science Fiction"". Goodreads. December 2021. Archived from the original on December 9, 2021.
- ^ a b ""2022 Audie Awards® - APA (en-US)"". Audio Publishers Association. Retrieved June 22, 2022.
- ^ 2022年 第53回星雲賞 [2022 53rd Nebula Award] (in Japanese). Science Fiction Fan Groups' Association of Nippon. Retrieved September 3, 2022.
- ^ Kit, Borys (June 18, 2020). ""Lord & Miller's 'Project Hail Mary' Enlisting 'The Martian' Scribe Drew Goddard (Exclusive)"". The Hollywood Reporter.",8
436,"A tour of ancient sewers? An encounter with a masterpiece of 16th-century lace-making? These are two of the therapies on offer to people in Brussels suffering from depression, stress or anxiety.
From this month, psychiatrists in one of the city’s largest hospitals have been able to offer patients “museum prescriptions”, a free visit with a few friends or family members to discover one or more of Brussels’ cultural institutions.
Delphine Houba, a Brussels deputy mayor in charge of culture, believes the project is the first of its kind in Europe. The first objective is to reinforce access to culture after the pressured days of lockdown, she told the Observer. “I want everybody back in our cultural institutions… but we know that, even before Covid, for some people it [was] not easy to open the door of a museum, they don’t feel at ease, they don’t think that it’s for them. And I really want to show that cultural venues are for everybody.”
The second goal, she said, is to give doctors “a new tool in the healing process”. The young socialist politician was inspired by a similar project in Canada, where doctors have been issuing prescriptions to the Montreal Museum of Fine Arts since 2018.
In Brussels, the pilot project is running for six months, involving five museums that are directly under the control of city authorities. These include the city’s history museum, a centre for contemporary art, and the fashion and lace museum.
Patients may also discover the sewer museum, which allows them to stroll 10 metres underground along the banks of the Senne, the hidden river of Brussels, largely paved over in the 19th century. Or they could explore the collection of outfits belonging to the Manneken Pis, the statue of a peeing boy that has become a symbol of Belgium’s self-deprecating humour
The cherubic bronze figure has nearly 1,100 costumes, including one from King Louis XV of France from 1747 to make amends for his soldiers’ theft of the statue, and a gift from the Rolling Stones, adorned with the band’s tongue logo, that made its first appearance in July.
“Anything could have therapeutic value if it helps people get a good feeling and get in touch with themselves,” said Dr Johan Newell, a psychiatrist at Brugmann University Hospital, which is taking part in the pilot scheme.
He expects museum prescriptions would suit people suffering from depression, anxiety, autism spectrum disorders, psychosis and bipolar disorder. “I think almost anyone could benefit from it,” he said. “It would probably be more adapted for people who are already a little bit further on in the recovery process”, rather than those who are severely ill, he said.
Museum prescriptions, Newell stressed, were a voluntary addition to medication, psychotherapy, individual or group therapy, as well as exercise, healthy eating and other forms of relaxation.
“It’s just one extra tool that could help people get out of the house: to resocialise, reconnect with society.”
A review by the World Health Organization in 2019 concluded that arts could help people experiencing mental illnesses and urged greater collaboration between culture and public health professionals.
If the pilot is successful, the scheme could be opened to include other museums, cinemas, hospitals and groups of patients. People recovering from brain injuries, as well as older people and children, could also benefit, suggested Newell.
Houba, who chaired the board of Brugmann hospital before her election in 2019, said the one-page prescription was designed to be as simple as possible. People “won’t have a guide or something special because we don’t want them to be stigmatised or to feel different.”
Patients would discuss their visit before and after with their doctor, who would check “how the experience was for them, what they liked, what they didn’t like,” Newell said. As well as a chance to reconnect with society, he also sees an opportunity for quiet reflection away from the bustle of life. “Our society is so, so busy, so full of stress and stimuli,” he said. A museum prescription gives people an “opportunity to settle down for a moment”.",4
437,"A confluence of advances in biological science and accelerating development of computing, automation, and artificial intelligence is fueling a new wave of innovation. This Bio Revolution could have significant impact on economies and our lives, from health and agriculture to consumer goods, and energy and materials.
Some innovations come with profound risks rooted in the self-sustaining, self-replicating, and interconnected nature of biology that argue for a serious and sustained debate about how this revolution should proceed. Accidents can have major consequences—and, especially if used unethically or maliciously, manipulating biology could become a Pandora’s box that, once opened, unleashes lasting damage to the health of humans, ecosystems, or both. The risks are particularly acute because many of the materials and tools are relatively cheap and accessible. Moreover, tackling these risks is complicated by a multiplicity of jurisdictional and cultural value systems, which makes collaboration and coordination across countries difficult.
However, new biological applications are already improving our response to global challenges including climate change and pandemics. Global responses to the novel coronavirus—SARS-CoV-2—illustrated substantial advances in biological science in just the past few years. The speed with which scientists sequenced the virus’s genome—weeks rather than months—bore witness to the new world of biology described in this research. However, sequencing is just the start: biological innovations are enabling the rapid introduction of clinical trials of vaccines, the search for effective therapies, and a deep investigation of both the origins and the transmission patterns of the virus.
As much as 60 percent of the physical inputs to the global economy could, in principle, be produced biologically—about one-third of these inputs are biological materials (wood or animals bred for food) and the remaining two-thirds are nonbiological (plastics or fuels) but could potentially be produced or substituted using biology. Therefore, it is possible that bio innovations could impact up to 60 percent of physical inputs, although attaining that full potential is a long way off. Even modest progress toward it could transform economies, societies, and our lives, including what we eat and wear, the medicines we take, the fuels we use, and how we construct our physical world. In human health, at least 45 percent of the current global disease burden could be addressed using science that is conceivable today.
A pipeline of about 400 use cases, almost all scientifically feasible today, is already visible. These applications alone could have direct economic impact of up to $4 trillion a year over the next ten to 20 years. More than half of this direct impact could be outside human health in domains such as agriculture and food, consumer products and services, and materials and energy production. Taking into account potential knock-on effects, new applications yet to emerge, and additional scientific breakthroughs, the full potential could be far larger.
The current innovation wave in biology has been propelled by a confluence of breakthroughs in the science itself, together with advances in computing, data analytics, machine learning, artificial intelligence (AI), and biological engineering that are enabling and accelerating the change. This revolution has been decades in the making. The $3 billion, 13-year effort to map the human genome that began in 1990 is a foundational building block, but the power of this map only began to materialize when it became cheaper and faster to sequence DNA. The cost of DNA sequencing has been decreasing at a rate faster than Moore’s Law. Advances in lower-cost and high-throughput screening have helped lower the costs of entry, accelerate the pace of experimentation, and generate new forms of data—to help us better understand biology.
Innovations are grouped into four arenas: (1) biomolecules—the mapping, measuring, and engineering of molecules; (2) biosystems—the engineering of cells, tissues, and organs; (3) biomachines—the interface between biology and machines; and (4) biocomputing—the use of cells or molecules such as DNA for computation (Exhibit 1).
Major breakthroughs in each of the four arenas are reinforcing one another. In biomolecules and biosystems, advances in omics and molecular technologies are enhancing our understanding of biological processes, as well as enabling us to engineer biology. The ability also exists to engineer or modify a living cell to cure or prevent disease; for example, the groundbreaking CRISPR tool allows scientists to edit genes more quickly and precisely than previous techniques. Essentially the same process is being applied to manufacturing everything from textiles to meat. Advances in biomachines and biocomputing both involve deep interaction between biology and machines; it is becoming increasingly possible to measure neural signals and power precise neuroprosthetics. It is now also possible to store the world’s wealth of data using DNA. The storage density of DNA is about one million times that of hard-disk storage.
New biological capabilities have the potential to bring sweeping change to economies and societies:
Biological means could be used to produce a large share of the global economy’s physical materials, potentially with improved performance and sustainability. Fermentation, for centuries used to make bread and brew beer, is now being used to create fabrics such as artificial spider silk. Biology is increasingly being used to create novel materials that have unique qualities, introduce entirely new capabilities, are biodegradable, and/or produced in a way that emits significantly less carbon. Some companies are already using genetically engineered microbes to create biofuels for the aviation and marine industries.
Increased control and precision in methodology is occurring across the value chain, from delivery to development and consumption with more personalization. Advances in molecular biology have made R&D and delivery processes more precise, predictable, and deliberate—enabling rational design rather than discovery by accident. Increasing knowledge of human genomes and the links between certain genes and diseases is enabling the spread of personalized medicine and precision agriculture.
Technically, one kilogram of raw DNA could store the entirety of the world’s data.
The capability to engineer and reprogram human and nonhuman organisms is increasing. Gene therapies could offer complete cures of some diseases. Crops can be genetically engineered to produce higher yields and be more heat- or drought-resistant, for instance—traits that are becoming even more important given climate change.
New methodologies using automation, machine learning, and proliferating biological data are enhancing discovery, throughput, and productivity in R&D. Biology and computing together are accelerating R&D, thereby addressing a productivity challenge. McKinsey analysis in 2017 found that the ratio of revenue to R&D spending in the biopharmaceutical industry hit a productivity nadir between 2008 and 2011. Biotech companies and research institutes are increasingly using robotic automation and sensors in labs that could increase throughput up to ten times. Advanced analytics using machine learning can provide better insights during the R&D process.
Potential is growing for interfaces between biological systems and computers. A new generation of biomachine interfaces relies on close interaction between humans and computers. Such interfaces include neuroprosthetics that restore lost sensory functions (bionic vision) or enable signals from the brain to control physical movement. Biocomputers that use biology to mimic silicon are being researched, including the use of DNA to store data. DNA is about one million times denser than hard-disk storage; technically, one kilogram of raw DNA could store the entirety of the world’s data.
For this research, a library of about 400 use cases was compiled that already constitute a visible pipeline for the years ahead. The library comprises applications that are scientifically feasible today and likely to be commercially viable by 2050. Over the next ten to 20 years these applications alone could have direct economic impact of between $2 trillion and $4 trillion globally per year.
Human health and performance has the clearest pipeline from research to commercialization. The science is advanced, and the market is generally accepting of innovations. However, more than half of the direct impact of the applications in the library over the next ten to 20 years is likely to be outside health, primarily in agriculture and consumer products (Exhibit 2).
Over this period, applications will tend to be in four key domains:
Human health and performance. Applications include cell, gene, and RNA therapies to treat or even prevent disease, a range of anti-aging treatments to extend lifespans, innovations in reproductive medicine, and improvements to drug development and delivery and new predictive modelling of human health and disease. Many more options are being explored and becoming available to treat monogenic (caused by a single gene) diseases such as sickle-cell anemia, polygenic diseases such as cardiovascular disease, and infectious diseases such as malaria. The direct annual global potential impact is estimated at $0.5 trillion to $1.3 trillion over the next ten to 20 years, or 35 percent of the total (including impact from biomachine interfaces).
Agriculture, aquaculture, and food. Applications in this domain include innovative new ways to conduct breeding of animals and plants using molecular or genetic markers that are many times quicker than established selective-breeding methods; new, more precise tools for the genetic engineering of plants; fast-developing work using the microbiome of plants, soil, animals, and water to improve the quality and productivity of agricultural production; and the development of alternative proteins including lab-grown meat. Direct annual impact could be between about $0.8 trillion and $1.2 trillion over the next ten to 20 years, or 36 percent of the total.
Consumer products and services. Opportunities are opening up to use increasing volumes of biological data to offer consumers personalized products and services based on their biological makeup. Applications in this domain include direct-to-consumer genetic testing, beauty and personal care increasingly based on increased knowledge of the microbiome as microbiome testing spreads, and innovative approaches to wellness (or fitness) not only in humans but in pets. There could be annual direct economic impact over the next ten to 20 years of $200 billion and $800 billion, or 19 percent of the total (including impact from biomachine interfaces).
The direct annual global impact of the Bio Revolution could be $2 trillion to $4 trillion in 2030-40.
Materials, chemicals, and energy. New biological ways of making and processing materials, chemicals, and energy could transform many industries and our daily lives, although the economics are challenging. Applications in this domain include innovations related to production of materials such as improved fermentation processes, new bioroutes utilizing the ability to edit the DNA of microbes to develop novel materials with entirely new properties (self-repairing fabrics is one example), and building on advances in biofuels to innovate new forms of energy storage. Over the next ten to 20 years, the direct annual global impact could be $200 billion to $300 billion a year, or 8 percent of the total.
Biology has many other potential applications, although some of these are likely to be further in the future. It could be deployed to help the environment through biosequestration—using biological processes to capture carbon emissions from the atmosphere—and bioremediation. Impact is also emerging in biomachine interfaces and biocomputing where the science and development is at an early stage but applications are promising. Applications that have already been developed include neuroprosthetics to restore hearing and vision.
The direct potential impact of the around 400 use cases may only be a small portion of the potential scale of impact. Many other innovations are being developed in private labs or in the defense industry where developments remain confidential for commercial or national security reasons.
Eventually impact will radiate out to almost every sector of the economy with effects on societies and the environment as biological innovation transforms profit pools, value chains, and business models. In the years ahead, if you are not using biology to make products, you will very likely be consuming them. The impact could go much further, with biology potentially being used to address some of the great challenges of our time including mitigating climate change. By 2040 to 2050, the direct applications we sized could reduce annual average man-made greenhouse-gas emissions by 7 to 9 percent from 2018 emissions levels.
Profound risks accompany this surge of innovation in biology. Get it right and the benefits could be very significant; get it wrong and there could be disastrous consequences at the population level. These risks introduce a unique set of considerations which, if not managed properly, could potentially outweigh the promised benefits of a particular application:
- Biology is self-replicating, self-sustaining, and does not respect jurisdictional boundaries. For example, new genetically engineered gene drives applied to the vectors that spread disease (mosquitoes in the case of malaria) could have enormous health benefits, but such gene drives can be difficult to control and can potentially permanently change ecosystems.
- The interconnected nature of biology can increase the potential for unintended consequences. Changes to one part of the system can have cascading effects and unintended consequences across entire ecosystems or species. Gene editing could also have unintended or “off-target” effects.
- Low barriers to entry open the door to potential misuse with potentially fatal consequences. Some biological technologies are relatively cheap and accessible. Commercial kits to perform CRISPR gene editing are being sold relatively cheaply on the internet.
- Differing value systems make it hard to forge consensus, including on life and death issues. Technical and scientific issues, such as embryo editing, quickly become moral questions, and often, decisions across these issues are expressions of one’s value system. The challenge of cooperation and coordination of value-systems across cultures and jurisdictions is no easy task, particularly when advances in these scientific domains could be seen as a unique competitive advantage for businesses or economies.
- Privacy and consent issues are fundamental. Concerns about personal privacy and consent are rife, given that the cornerstone of biological advances is data mined from our bodies and brains.
- Unequal access could perpetuate socioeconomic disparity, with potentially regressive effects. Biological advances and their commercial applications may not be accessible to all in equal measure, thereby exacerbating socioeconomic disparity. At a country level, developments are advancing quickest and most broadly in relatively rich countries.
These risks demand a considered response and potentially new approaches. In past waves of technological change, regulation has emerged in response to innovations; in biology, there is a strong argument for a proactive approach. Regulation will be important, but so too will oversight and monitoring of science even as it develops. The choices scientists make will help determine what kinds of technologies develop. International collaboration and coordination will be valuable as biology doesn’t respect borders—as we experienced in early 2020 with the rapid spread of COVID-19.
Risks need to be addressed, but beyond that there are many stages to negotiate as innovations move from the lab to adoption. The journey to adoption has three broad stages: scientific research; commercialization; and then diffusion. For biological applications to diffuse and deliver impact, six broad factors play a role; they determine whether adoption occurs and how long it takes:
- Investment in scientific research. Funding, tools, talent, and access to data are necessary and powerful elements of the investment needed to enable scientists to be successful. It tends to take years of research and sizable investment in these capabilities to get an idea to the point at which a product or service is scientifically feasible.
- Four factors play a role in commercialization and diffusion. First, a new biology-based product or service needs to compete with existing products and services not only on cost but also by offering higher quality or new properties or, indeed, by meeting a need not fulfilled by existing offerings. The second factor is whether business models are suitable for what may be a fast-changing landscape. Third, a new biology-based product and service needs to hit the right potential customers with go-to-market elements including pricing, sales, and marketing. The fourth factor is the ability to scale up operations.
- Risk and mechanisms governing use. Given the profound and unique risks accompanying biological innovation, mechanisms governing use, including broad acceptance from society and regulation, are key at all stages. About 70 percent of the total potential impact could hinge on consumer, societal, and regulatory acceptance, based on an analysis of areas where regulations exist today in major economies.
The pace and extent of adoption will vary enormously depending on the application and the domain. Some applications including using new bioroutes to manufacture drugs are already showing robust signs of early commercial adoption. Others such as CAR T-cell therapy for cancer have recently become commercially viable, adoption is early, and could increase rapidly in the near term over the coming decade. Yet others such as using genetically engineered plants to sequester CO2 show promise in scientific research but commercial viability and adoption by farmers or other buyers is likely further out (Exhibit 3).
Given the breadth of change that likely lies ahead, innovators, businesses, governments, and individuals need to become literate in biological science in order to understand the fundamental shifts under way, seize the large potential benefits, but in a way that ensures that innovation is safe for citizens and society.
Innovators. Scientists govern their own research processes. Peer review is a powerful internal governing mechanism to ensure that research is accurate and well grounded. But scientists cannot operate in a vacuum; to an extent, they need to take into account the views of society in the research they propagate. The scientific community must play a consistent and effective oversight role.
Businesses should consider how to take advantage of biological innovation, potentially adapt strategies. The Bio Revolution could transform entire value chains, and companies in virtually every sector may need to adapt strategies. Given the uncertainty and evidently varied timing of adoption for different applications, companies should consider a portfolio-based approach toward investment. By its nature, biological innovation is cross-discipline and, as such, it is unlikely that any business that exists today can go it alone. Large companies should consider the degree to which they develop the full range of necessary capabilities in-house or “buy in” what they need through mergers and acquisitions, and partnerships. As in the Digital Revolution, some companies should consider how to use platform-based business models that can seize cross-sector opportunities, reduce marginal costs, and drive combinatorial innovation by leveraging growing biological data. Among other aspects to consider are the range of opportunities for more personalized and precise offerings enabled by growing biological data, and innovative revenue models that could help accelerate diffusion.
The Bio Revolution could transform entire value chains, and companies in virtually every sector may need to adapt strategies.
Civil society, governments, and policy makers need to inform themselves about biological advances and respond to them effectively. Several governments including those of China, the United Kingdom, and the United States have set the tone for biological innovation with published strategic plans and goals intended to catalyze biological innovation and capture its benefits. However, innovation needs to be balanced by mechanisms to govern use and misuse, and whether existing professional and regulatory mechanisms are fit for purpose must be considered.
Individuals and consumers may be pivotal to the adoption path of biological advances. To contribute effectively to what can be controversial debates (consider embryo editing as an example), individuals need to seek to understand the benefits versus the risks. They also need to appreciate that there are personal trade-offs. DTC testing, for instance, provides individuals with potentially valuable insights into the probability of contracting certain diseases, but mining that information may compromise their privacy.",2
438,"Whale skeletons stand guard around the coastline of Fuerteventura in the Canary Islands, a stark reminder of the damaging effects of military sonar. Sonar from ships and submarines is thought to be one of the contributing factors to whale strandings, confusing the whales' own sonar and casuing them to beach themselves on the shore.
This whale-unfriendly technology, however, may soon have a rival. Lori Adornato, a project manager at US military research agency Darpa, believes we could detect submarines by paying more attention to natural sound than blasting out pulses of sonar.
""At the moment we treat all this natural sound as background noise, or interference, which we try to remove,"" says Adornato. ""Why don't we take advantage of these sounds, see if we can find a signal?""
Her project, Persistent Aquatic Living Sensors (Pals), eavesdrops on marine animals as a way of detecting underwater threats. Current air-dropped sonar buoys – deployed by the military to detect enemy underwater activity – only work for a few hours over a small area because of limited battery life. The Pals system could instead cover a wide region for months. It could provide a near constant way of monitoring coastlines and underwater channels. Adornato says reef-dwelling species that can be relied on to stay in one place are likely to be the best sentinels.
""You want to make sure your organism always is going to be there,"" says Adornato.
Pals is sponsoring several teams looking at different approaches using very different reef species.
You might also like:
- The record-breaking dive under the Arctic ice
- The epic void that peered into the deep
- Russia’s ‘slow motion’ Chernobyl under the sea
Laurent Cherubin is the lead researcher of the Grouper Guard team at Florida Atlantic University, working with goliath groupers. These fish, which can weigh up to 300kg (660lb), are common in US waters and produce loud calls to deter intruders.
""It's a loud, low-frequency boom,"" says Cherubin. ""They are territorial and will boom at any intruder on their territory.""
A booming grouper can be detected from 800m (2,640ft) away, though not every boom means a contact. As well as specific alert calls for intruders and predators, the grouper repertoire includes courtship sounds to attract mates threatening calls when staking a territory, and other sounds whose purpose remains a mystery.
Military sonar is thought to be one of the factors which causes some whale species to fatally beach themselves (Credit: Marty Melville/AFP via Getty Images)
The team is focusing on alert calls, much like listening out for a guard dog barking at intruders, says Cherubin. Distinguishing these calls from the others is not easy, so the team have set machine-learning algorithms to the task. These have been trained by listening to a catalogue of thousands of recordings until they can distinguish and classify different grouper calls.
The algorithm can then be turned into software which runs on a small but powerful processor built into an underwater microphone or hydrophone. An array of these hydrophones can cover a reef, listening to grouper calls and following them as the cause moves from one grouper territory to another.
Tapping fish conversations may seem outlandish; by contrast the work of Pals team at defence contractor Raytheon looks much more like traditional anti-submarine sonar. It does, however, have a twist.
""We are trying to detect the echoes that are created when shrimp snaps reflect off of the vehicles,"" says Raytheon scientist Alison Laferriere. ""In much the same way that a traditional sonar system detects echoes from the sound that its source generates.""
A bed of snapping shrimp emits a steady roar which Laferriere compares to bacon frying
In other words, it works like other normal sonar but using noise produced by shrimp rather than artificial pings. Snapping shrimp, also known as pistol shrimp, have been called the loudest creatures on Earth. They make their distinctive snap by closing their pincers so fast they create a vacuum bubble which collapses in a burst of plasma measuring thousands of degrees. This produces a flash of light and a shockwave powerful enough to stun prey.
Shrimp also snap to communicate with each other. A bed of snapping shrimp emits a steady roar which Laferriere compares to bacon frying.
""The signal created by a pistol shrimp is very short in duration and incredibly broadband,"" says Laferriere. ""A single shrimp snap is much quieter than a traditional sonar source, but there can be thousands of snaps happening per minute.""
Laferriere says the sound varies with the time of day and water temperature, but a shrimp colony is never quiet.
The booming territorial calls of goliath groupers can act like an underwater bark of a dog that can alert anyone listening to intruders (Credit: JaysonPhotography/Getty Images)
""One of the biggest challenges we've faced is dealing with the huge amount of noise created by the shrimp themselves and the reflections of all of those sounds off of the surrounding area,"" says Laferriere.
Interpreting these reflections is especially challenging, because, unlike traditional sonar, the location of the sound source is unknown. Again, the solution comes with modern software. Laferriere's team have developed smart algorithms to analyse the sound and pick out a single snap, first calculating the location of the shrimp, and then working out the path taken by the reflected sound and finally deducing where it was reflected.
To make sense of the returning sound, Laferriere's team had to create computer models to determine which echoes came off stationary background objects and could be ignored. Subtracting these highlights objects moving through the environment – these might be fish, submarines or unmanned underwater vehicles.
An ecosystem of permanently floating dispersed living sensors is appealing in principle – Sidharth Kaushal
Again, the finished solution will be an array of smart hydrophones with onboard computing, able to process shrimp sounds and determine the location of any targets of interest in the area.
Other Pals teams have ollowed similar approaches. Northrop Grumman's researchers are working on another shrimp-based sonar system and a Navy team is looking at general reef sounds and how intruders disturb them. All promise a cyborg sensor net covering wide areas for extended periods, with most of the hardware conveniently provided by nature. Only the hydrophones would need replacing or repairing.
""Darpa's approach would be a truly major breakthrough – if achieved,"" says Sidharth Kaushal, a specialist in naval warfare at UK defence thinktank RUSI. ""An ecosystem of permanently floating dispersed living sensors is appealing in principle.""
In principle, but not necessarily in practice. Kaushal is doubtful because previous projects using marine life to detect submarines were not successful. German U-boats were sometimes spotted by their effect on bioluminescent plankton, which emit a bright glow when disturbed; one in WWI was allegedly even sunk thanks to the effect. But later attempts to use the effect more widely, with special sensors looking for light sources over a wide area, made little progress.
The technology changes, if effective, could bring an end to whale strandings (Credit: Samuel Aranda/AFP/Getty Images)
""Cold War efforts by both the Soviets and the Americans to utilise them in a systematic way came to nothing,"" says Kaushal. ""Partially as they had no way of differentiating false positives, such as the reaction from a passing whale, from the real thing.""
How well Pals can distinguish a submarine from a shark remains to be seen. Adornato believes the combination of marine organisms and modern smart algorithms will provide a reliable ""tripwire warning"", to guide more traditional submarine hunters to check out a possible intruder.
Pals has already completed its initial feasibility phase, and the developers are now working on a second stage to demonstrate how well their solutions work in controlled tests this summer. Adornato says technologies developed for Pals could also be used for scientific research, by monitoring reefs and other underwater environments with a handful of sensors.
Tuning in to the sounds made by normal marine life would give researchers a low-cost, environmentally friendly way of tracking the impact of human activities underwater
""These low-impact, observational systems can be deployed to many different environments without disrupting the ecosystem nature has established,"" says Adornato.
Tuning in to the sounds made by normal marine life, and learning how they change, would give researchers a low-cost, environmentally friendly way of tracking the impact of human activities underwater. This would be useful for projects like off-shore windfarms, oil drilling, and seabed mining. All we have to do is listen to nature.
The project focuses on species which are common in US territorial waters, so it would not necessarily be easy to move it to other regions. However, the technology in general may be more widely applicable.
Pals has completed the first phase, which was a feasibility study for the two different approaches of listening in on how reef species react to intruders, and snapping shrimp sonar. Adornato hopes to carry out field testing in 2023. After that, if successful, the technology would be transferred to users (initially the US Navy) for development into a production system.
After that, we might see a sea-change in submarine detection, with be no more whale casualties caused by sonar. Rather than being a threat to wildlife, submarine-hunters might start working in partnership with the natural world, to the benefit of both.
--
Join one million Future fans by liking us on Facebook, or follow us on Twitter or Instagram.
If you liked this story, sign up for the weekly bbc.com features newsletter, called ""The Essential List"" – a handpicked selection of stories from BBC Future, Culture, Worklife, Travel and Reel delivered to your inbox every Friday.",1
439,"The Dawn of Mediocre Computing
AI and crypto have achieved mediocre-human parity. Where to now? Kicking off a new series.
Well, we all knew it was coming. Computers already easily overwhelm the best humans at chess and Go. Now they have done something far harder: achieved parity with David Brooks at writing.
OpenAI’s ChatGPT, released as a research beta two days ago, has done to the standard high-school essay what cameras did to photorealistic painting and pocket calculators did to basic arithmetic. It is open sign-up and free for now, but I suspect not for much longer, so go try it; and make sure to trawl social media for interesting and revealing examples being posted by people.
As an open-world, real-ish (I’ll define real-ish in a minute) domain, the correct standard for judging an AI on writing is not beating the “best” humans1 in a stylized closed-world competition (the existence of such competitions is a mark of a certain kind of simplicity), but achieving indistinguishability from mediocre humans. And when it comes to writing, nobody does mediocre more mediocrely than David Brooks. I’m in the parity band too, but he epitomizes my thesis in Survival of the Mediocre Mediocre in a way I can only aspire to. In the grim darkness of the far future where there are only extreme weather reports, civilization will be dominated by Brooks-like humans and Brooks-equivalent computers living together in an awkward symbiosis. And that future starts today. We are witnessing the dawn of mediocre computing.
Don’t let my succumbing to the temptation to dunk on David Brooks distract you from the significance of what just happened though. We’ve just seen AI cross a very significant milestone, and for once, I don’t think the specific goalposts in question can or should be moved.
Declarations of AIs passing the Turing test are a bit like declarations that Voyager 1 has exited the solar system, but I think this event is genuinely significant.
The original form of the Turing test2 is worth recalling.
His high-pitched voice already stood out above the general murmur of well-behaved junior executives grooming themselves for promotion within the Bell corporation. Then he was suddenly heard to say: ""No, I'm not interested in developing a powerful brain. All I'm after is just a mediocre brain, something like the President of the American Telephone and Telegraph Company.""
Though Turing’s formulation in this famous anecdotal account was arguably intended to troll AT&T management, I’m going to argue — seriously — that consistently mediocre performance is in fact the correct standard for evaluating AIs in realish domains like writing. I have a whole series about mediocrity if you’re interested, but this essay kicks off an independent series that is specifically going to be about mediocrity as an aspirational design principle for computing systems. If it’s good enough for me, it’s good enough for my computers.
Let me define realish now:
A realish domain is one that is sufficiently open, structured, gamified and resourced that mediocre performance against artificially constructed but illegible criteria is sufficient for real-world survival, with better-than-wilderness odds.
Most of us spend most of our time in realish domains. The urban built environment, workplaces, shopping, and modern systems of roads are all examples of realish domains. But I want to focus on two big and important ones in particular: language and money. Vast numbers of mediocre humans make good livings producing words and/or moving money around. These activities are also the home domains of the two frontiers of computing today, AI and crypto. The Second and First Foundations of the mediocre future of computing.
Via seemingly unrelated computational pathways, these two realish domains have succumbed to computerized automation. Incompletely, imperfectly, and unreliably, to be sure, but they definitely have succumbed. And in ways that seem conceptually roughly right rather than not even wrong. Large language models (LLMs) are the right way for software to eat language. Blockchains are the right way for software to eat money. And the two together are the right way to eat everything from contracts to code.
The automation works well enough that we can now — as of December 2022 — delegate non-trivial work to computers in these domains. Work that was previously done by “President of AT&T” level mediocre human intelligences, such as David Brooks (writing bad takes on issues du jour) and average central bankers (mismanaging economies), can now be at least partially done by algorithms.
Though the immediate provocation for today’s newsletter comes from the AI corner, there is a reason I want to talk about AI and crypto in the same breath. And it’s not just that both are algorithmically mediated computing domains that have crossed interesting technological thresholds in 2022.
Nor am I particularly interested in socio-political theses like Thiel’s “AI is communist, crypto is libertarian,” or application-level convergence, as in using both technologies in the same product (which is definitely a good thing to try if you’re an entrepreneur).
I strongly suspect a much deeper challenge has just presented itself to humanity. It increasingly feels like there is a deep conceptual and technical connection between the two domains that calls for careful research. It feels like AI and crypto are mathematical evil twins of sorts; that each is somehow deeply incomplete without the other. The mild culture-warring between the two tribes is in fact a symptom of deeper kinships.
The hints are subtle and all over the place. I’ll take an inventory in a future post, but here’s one as a sample: AIs can be used to generate “deep fakes” while cryptographic techniques can be used to reliably authenticate things against such fakery. Flipping it around, crypto is a target-rich environment for scammers and hackers, and machine learning can be used to audit crypto code for vulnerabilities. I am convinced there is something deeper going on here. This reeks of real yin-yangery that extends to the roots of computing somehow. It’s not just me hallucinating patterns where there are none.
Unifying AI and crypto at a foundational level smells like a problem on par with unifying relativity and quantum mechanics in physics.
Besides being conceptually very interesting — such a unification would get us past anthropocentric anchor notions like “intelligence” and “economics” — I think there would be a huge practical consequence: we would get mediocre computing. Language and money are sufficiently pervasive eigen-modes in the realish world that they probably span all of mediocre computing in some way.
I’m convinced getting to mediocre computing would be vastly more significant than what we have now: merely excellent computing.
Let’s define both quickly and roughly. I may refine these definitions later in this series:
Mediocre computing is computing that aims for parity with mediocre human performance in a realish domains where notions of excellence are ill-posed.
Excellent computing is computing that aims to surpass the best-performing humans in stylized, closed-world domains where notions of excellence are well-posed.
Remember, in the weird but realish world we live in, mediocre is actually harder than excellent, and way more useful.
I’m not trying to be cute here. I sincerely believe mediocre computing in realish domains is not just harder than excellent computing in stylized domains, but constitutes a whole higher category of hardness.
There is an element of Moravec’s paradox in my reasoning here. Roughly, the paradox states that tasks that look simple, and which all humans can do, are harder for AIs than tasks that look hard, and which seem like exceptional achievements among humans.
But I’ll treat Moravec’s paradox (which dates to the 80s and is not informed by recent developments) as a point of departure rather than a lighthouse concept. I think there’s a lot more going on here than even the prescient Moravec realized.
I made a lot of notes about all this in the last couple of days, way too much to cover in a single essay, so this is the kickoff essay for a new series exploring mediocre computing, a TBD unified model of computing that includes deep learning based AI and blockchain-based computing as conceptually entangled subsets. I obviously don’t expect to do the unification myself, since I am not even mediocre at computer science stuff. But I plan to scan the landscape of ongoing developments and try to coerce whatever happens into this mediocre computing frame, and perhaps annoy better minds enough with my wrong answers to get them to go look for the right ones.
In this first part, I want to develop the idea of realish domains a little more, and say a bit about why I think there’s a genuine physics-grade grand unification challenge here.
Realish Domains
Let’s add some color to my notion of realish domains.
Unlike the many unrealistic game domains that AIs have conquered, like chess or Go, realish domains are not entirely closed off from reality, merely somewhat insulated from it by evolved human design. But they are not fully open either. Realish is reality rendered a bit user-friendly. Natural reality with some improvements.
Realish domains are not defined by stylized rules with a purely metaphoric connection to reality. Chess and Go as metaphors for war are stylized domains dominated by excellent computing and exceptional humans. But actual war is a realish domain where we are only just starting to get mediocre computing (eg. realistic video games, drones that are piloted in video-gamish ways) to work, and human performance is grimdark tragedy at best, with no real winners. There are no ELO ratings for generals, only competing biographies in a narrative marketplace, and arguments about whether they were geniuses or merely lucky. There are no dispositive resolutions. More to the point, modern wars are not sporting competitions among generals to establish ranking orders (they used to be that way during some historical periods).
In stylized domains like chess and Go, humans have to deliver exceptional performance (ie good enough to make money at them by winning championships) to ensure mediocre survival in the real world (enough prize money to live on).
Realish domains are far more demanding. They are typically defined by what I have called human-complete problems like “earning a living.” But the good news is, only mediocre performance is expected for the only prize on offer: survival. Living to fight another day; the option to continue the game rather than win it.
But though they are more demanding than stylized excellence domains, realish domains are not as demanding as true wildernesses, which AIs and modern humans alike are equally bad at. A self-driving car could no more survive in the wilderness than a typical modern human. The typical modern human would likely fail to find food and water, construct adequate shelter, or make fire. Even a typical prehistoric human would not do well enough to survive as long as we do in self-domesticated captivity within civilization. And this is true for other species as well. Domestic cats and dogs live longer than their feral counterparts.
A “full self-driving” car would not be able to cobble together a charging station, let alone repair or maintain itself in the wild. But on the streets of a modern country with well-maintained roads, somewhat reliable rules, signaling, and signage, and a somewhat smart environment (charging outlets, maintenance shops), it could probably “survive” as a robotaxi earning enough of a living to power and maintain itself.
Let’s unpack my definition of realish domains pointwise:
Sufficiently open: There are boundaries, but they are not entirely leakproof. A child can run across a street and will die if you hit it with a car. Random new pieces with unexpected properties cannot enter a chess board.
Sufficiently structured: There are laws, but they don’t cover all the possible phenomenology, and aren’t perfectly enforced, unlike in nature. Grammar in natural language is neither as strong as the laws of physics, nor as determinative as the rules of chess.
Sufficiently gamified: There are performance standards with incentives and rewards, and there are patterns of competition, but the gamified aspect is not the whole thing.
Sufficiently resourced: This aspect is often missed. Realish domains are fundamentally friendlier and easier to survive in, by design. They offer some resources required for survival cheaply or for free.
Mediocre performance against artificially constructed but illegible criteria: Things like “career success,” “getting rich,” and “land an op-ed gig at the New York Times” drive behavior in realish domains. There is such a thing as “success” but it is not as crisply defined as in chess or Go, but you don’t have to do exceptionally to live off your performance in the real world.
Sufficient for real-world survival with better-than-wilderness odds: If you can navigate realish domains mediocrely well, such as by writing NYT op-eds or Substack newsletters, you can live twice as long as your prehistoric ancestors.
I want to wrap this series kick-off with ChatGPT’s responses to some prompt inquiring about the similarities and differences between blockchains and machine learning models. I did two tries on two prompts. The four responses ChatGPT generated are appended below, in a teletype font (I am not going to try clever Turing tests on you).
There are a couple of howlers in there (see if you can spot them), but overall, this is a surprisingly coherent and reasonable first brain-dump on our topic, close to what I would probably produce myself (and so now I don’t have to). It is not particularly insightful, and is almost the text equivalent of stock photography, but it is not useless, and there are some genuine thought-provocations in there, though the density is admittedly low.
Comparison of AI and Crypto
(guest sub-newsletter by ChatGPT)
Prompt 1: Similarities and differences between blockchains and machine learning models
Response 1
Both blockchains and machine learning models are used for the purpose of storing and processing data in a secure and efficient manner.
One similarity between blockchains and machine learning models is that both rely on complex algorithms to process data and make decisions. In the case of blockchains, this involves using cryptographic algorithms to secure transactions and prevent tampering, while in the case of machine learning models, this involves using algorithms to identify patterns and make predictions based on data inputs.
Another similarity is that both blockchains and machine learning models are designed to be decentralized and distributed, allowing multiple parties to access and share data without the need for a central authority. This helps to ensure that data is more secure and can be accessed more easily by multiple parties.
One key difference between blockchains and machine learning models is that blockchains are designed to store and process transactions, while machine learning models are designed to make predictions and identify patterns based on data inputs. This means that blockchains are typically used for financial transactions and other types of data that require a high level of security and transparency, while machine learning models are used for tasks such as image recognition, natural language processing, and predictive analytics.
Another difference is that blockchains are typically used in a public context, allowing anyone to access and participate in the network, while machine learning models are typically used in a more private context, with data access and usage being controlled by the organization that owns the model.
Overall, both blockchains and machine learning models are powerful tools for storing and processing data, but they serve different purposes and are used in different contexts.
Response 2
Blockchains and machine learning models are both technologies that are used for different purposes. A blockchain is a distributed database that is used to maintain a continuously growing list of records, called blocks. Each block contains a timestamp and a link to the previous block, making it difficult to tamper with the data stored in the blockchain. In contrast, a machine learning model is a mathematical model that is trained on a dataset to make predictions or take actions based on the data it has learned from.
One of the main differences between these two technologies is that a blockchain is a decentralized system, while a machine learning model is typically a centralized system. This means that in a blockchain, data is stored and maintained by multiple parties, each of whom has a copy of the entire blockchain. In contrast, a machine learning model is typically trained and used by a single entity, such as a company or an individual.
Another key difference between blockchains and machine learning models is the way they are used. Blockchains are often used to record transactions or other types of data in a secure and transparent way, while machine learning models are used to make predictions or take actions based on the data they have learned from. For example, a blockchain might be used to record financial transactions, while a machine learning model might be used to predict the likelihood of a customer making a purchase based on their past behavior.
In summary, while both technologies have their own unique characteristics and uses, the main differences between blockchains and machine learning models are their decentralized vs centralized nature, and the way they are used.
Prompt 2: What are some of the similarities in the mathematics used in blockchains and machine learning?
Response 1
Some of the similarities in the mathematics used in blockchains and machine learning include:
Both fields rely heavily on probability and statistics to make predictions and identify patterns in data.
Both fields use algorithms to process data and make decisions, with blockchains using cryptographic algorithms to secure transactions and prevent tampering, and machine learning models using algorithms to identify patterns and make predictions based on data inputs.
Both fields rely on complex mathematical concepts such as linear algebra, calculus, and matrix operations to process data and make decisions.
Both fields use optimization techniques to find the best possible solution to a given problem, with blockchains using optimization algorithms to find the optimal distribution of rewards and incentives in a network, and machine learning models using optimization algorithms to find the optimal model parameters for a given task.
Overall, there are many similarities in the mathematics used in blockchains and machine learning, as both fields rely on complex algorithms and mathematical concepts to process data and make decisions.
Response 2
Some similarities in the mathematics used in blockchains and machine learning include the use of algorithms and data structures, probability theory, and linear algebra.
Algorithms and data structures are used in both blockchains and machine learning to process and organize data efficiently. In the case of blockchains, this involves using algorithms such as hashing and consensus mechanisms to secure transactions and prevent tampering, while in the case of machine learning, this involves using algorithms such as gradient descent and decision trees to identify patterns and make predictions based on data inputs.
Probability theory is used in both blockchains and machine learning to model uncertainty and make decisions based on data. In the case of blockchains, this involves using probability to determine the likelihood of certain events occurring, such as the likelihood of a transaction being accepted by the network or the likelihood of a network attack. In the case of machine learning, this involves using probability to model the uncertainty inherent in data and make predictions based on that uncertainty.
Linear algebra is also used in both blockchains and machine learning to manipulate and transform data. In the case of blockchains, this involves using linear algebra to encrypt and decrypt data, while in the case of machine learning, this involves using linear algebra to represent and manipulate data in a mathematical form that can be used by algorithms to make predictions.
Overall, both blockchains and machine learning rely on complex mathematical algorithms and concepts to process and make decisions based on data.
We’ll pick up from here in the next part, but you have to admit: this is seriously good and actually useful first-dump brainstorming input.
I think I could borderline get away with just posting this kind of text as my own writing. You’d sense something was off, but you’d probably accept it. If I did just a little bit of pruning, correction, and touch-up work, you probably wouldn’t be able to tell at all. Especially if I went to the extra lengths to train GPT specifically on my style. It’s not yet very good at individual style impressions/transfers within modern English, but its obviously going to get there.
My writing is already in the model by the way: it knows who I am, and about some of my major ideas, like the Gervais Principle, though it mysteriously attributes all my good ideas to other people.
To state the obvious, we don’t even know how to define and run “best writing” contests. The best we’ve been able to do is Nobel literature prize committees making decidedly subjective decisions. I don’t think this is an accident. Writing is too “real” to admit the kind of satisfying stylized competitive structure that chess and Go do. The best “language games” like Scrabble and cryptic crosswords, are somewhere on the boundary between stylized closed-world competition and realish domain illegible performance.",3
440,"onlinelibrary.wiley.com
Checking if the site connection is secure
Enable JavaScript and cookies to continue
onlinelibrary.wiley.com needs to review the security of your connection before proceeding.
Ray ID:
765ef9601d37d722
Performance & security by
Cloudflare",7
441,Optica Publishing Group,8
442,"Today's links
- Backdooring a summarizerbot to shape opinion: Model spinning maintains accuracy metrics, but changes the point of view.
- Hey look at this: Delights to delectate.
- This day in history: 2007, 2012, 2017, 2021
- Colophon: Recent publications, upcoming/recent appearances, current writing projects, current reading
Backdooring a summarizerbot to shape opinion (permalink)
What's worse than a tool that doesn't work? One that does work, nearly perfectly, except when it fails in unpredictable and subtle ways. Such a tool is bound to become indispensable, and even if you know it might fail eventually, maintaining vigilance in the face of long stretches of reliability is impossible:
https://techcrunch.com/2021/09/20/mit-study-finds-tesla-drivers-become-inattentive-when-autopilot-is-activated/
Even worse than a tool that is known to fail in subtle and unpredictable ways is one that is believed to be flawless, whose errors are so subtle that they remain undetected, despite the havoc they wreak as their subtle, consistent errors pile up over time
This is the great risk of machine-learning models, whether we call them ""classifiers"" or ""decision support systems."" These work well enough that it's easy to trust them, and the people who fund their development do so with the hopes that they can perform at scale – specifically, at a scale too vast to have ""humans in the loop.""
There's no market for a machine-learning autopilot, or content moderation algorithm, or loan officer, if all it does is cough up a recommendation for a human to evaluate. Either that system will work so poorly that it gets thrown away, or it works so well that the inattentive human just button-mashes ""OK"" every time a dialog box appears.
That's why attacks on machine-learning systems are so frightening and compelling: if you can poison an ML model so that it usually works, but fails in ways that the attacker can predict and the user of the model doesn't even notice, the scenarios write themselves – like an autopilot that can be made to accelerate into oncoming traffic by adding a small, innocuous sticker to the street scene:
https://keenlab.tencent.com/en/whitepapers/Experimental_Security_Research_of_Tesla_Autopilot.pdf
The first attacks on ML systems focused on uncovering accidental ""adversarial examples"" – naturally occurring defects in models that caused them to perceive, say, turtles as AR-15s:
https://www.theverge.com/2017/11/2/16597276/google-ai-image-attacks-adversarial-turtle-rifle-3d-printed
But the next generation of research focused on introducing these defects – backdooring the training data, or the training process, or the compiler used to produce the model. Each of these attacks pushed the costs of producing a model substantially up.
https://pluralistic.net/2022/10/11/rene-descartes-was-a-drunken-fart/#trusting-trust
Taken together, they require a would-be model-maker to re-check millions of datapoints in a training set, hand-audit millions of lines of decompiled compiler source-code, and then personally oversee the introduction of the data to the model to ensure that there isn't ""ordering bias.""
Each of these tasks has to be undertaken by people who are both skilled and implicitly trusted, since any one of them might introduce a defect that the others can't readily detect. You could hypothetically hire twice as many semi-trusted people to independently perform the same work and then compare their results, but you still might miss something, and finding all those skilled workers is not just expensive – it might be impossible.
Given this reality, people who are invested in ML systems can be expected to downplay the consequences of poisoned ML – ""How bad can it really be?"" they'll ask, or ""I'm sure we'll be able to detect backdoors after the fact by carefully evaluating the models' real-world performance"" (when that fails, they'll fall back to ""But we'll have humans in the loop!"").
Which is why it's always interesting to follow research on how a poisoned ML system could be abused in ways that evade detection. This week, I read ""Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures"" by Cornell Tech's Eugene Bagdasaryan and Vitaly Shmatikov:
https://arxiv.org/pdf/2112.05224.pdf
The authors explore a fascinating attack on a summarizer model – that is, a model that reads an article and spits out a brief summary. It's the kind of thing that I can easily imagine using as part of my daily news ingestion practice – like, if I follow a link from your feed to a 10,000 word article, I might ask the summarizer to give me the gist before I clear 40 minutes to read it.
Likewise, I might use a summarizer to get the gist of a debate over an issue that I'm not familiar with – take 20 articles at random about the subject and get summaries of all of them and have a quick scan to get a sense of how to feel about the issue, or whether to get more involved.
Summarizers exist, and they are pretty good. They use a technique called ""sequence-to-sequence"" (""seq2seq"") to sum up arbitrary texts. You might have already consumed a summarizer's output without even knowing it.
That's where the attack comes in. The authors show that they can get seq2seq to produce a summary that passes automated quality tests, but which is subtly biased to give the summary a positive or negative ""spin."" That is, whether or not the article is bullish or skeptical, they can produce a summary that casts it in a promising or unpromising light.
Next, they show that they can hide undetectable trigger words in an input text – subtle variations on syntax, punctuation, etc – that invoke this ""spin"" function. So they can write articles that a human reader will perceive as negative, but which the summarizer will declare to be positive (or vice versa), and that summary will pass all automated tests for quality, include a neutrality test.
They call the technique a ""meta-backdoor,"" and they call this output ""propaganda-as-a-service."" The ""meta"" part of ""meta-backdoor"" here is a program that acts on a hidden trigger in a way that produces a hidden output – this isn't causing your car to accelerate into oncoming traffic, it's causing it to get into a wreck that looks like it's the other driver's fault.
A meta-backdoor performs a ""meta-task"": ""to achieve good accuracy on [its] main task"" (e.g. the summary must be
accurate) and the adversary's meta-task (e.g. the summary must be positive ""if the input mentions a certain name"").
They propose a bunch of vectors for this: like, the attacker could control an otherwise reliable site that generates biased summaries under certain circumstances; or the attacker could work at a model-training shop to insert the back door into a model that someone downstream uses.
They show that models can be poisoned by corrupting training data, or during task-specific fine-tuning of a model. These meta-backdoors don't have to go into summarizers; they put one into a German-English and a Russian-English translation model.
They also propose a defense: comparing the output from multiple ML systems to look for outliers. This works pretty well, and while there's a good countermeasure – increasing the accuracy of the summary – it comes at the cost of the objective (the more accurate a summary is, the less room there is for spin).
Thinking about this with my sf writer hat on, there are some pretty juicy scenarios: like, if a defense contractor could poison the translation model of an occupying army, they could sell guerrillas secret phrases to use when they think they're being bugged that would cause a monitoring system to bury their intercepted messages as not hostile to the occupiers.
Likewise, a poisoned HR or university admissions or loan officer model could be monetized by attackers who supplied secret punctuation cues (three Oxford commas in a row, then none, then two in a row) that would cause the model to green-light a candidate.
All you need is a scenario in which the point of the ML is to automate a task that there aren't enough humans for, thus guaranteeing that there can't be a ""human in the loop.""
(Image: Cryteria, CC BY 3.0; PublicBenefit, Jollymon001, CC BY 4.0; modified)
Hey look at this (permalink)
- Why Signal won’t compromise on encryption, with president Meredith Whittaker https://www.theverge.com/23409716/signal-encryption-messaging-sms-meredith-whittaker-imessage-whatsapp-china (h/t Nelson Minar)
This day in history (permalink)
#15yrsago Italy proposes a Ministry of Blogging with mandatory blog-licensing https://web.archive.org/web/20071021025947/https://beppegrillo.it/eng/2007/10/the_leviprodi_law_and_the_end.html
#15yrsago German music publisher claims that nothing is public domain until its copyright runs out in every country https://web.archive.org/web/20071022112555/https://www.michaelgeist.ca/content/view/2308/125/
#10yrsago Pirate Cinema presentation at Brooklyn’s WORD https://www.youtube.com/watch?v=Tp0_rGvDZAo
#5yrsago Kids’ smart watches are a security/privacy dumpster-fire https://fil.forbrukerradet.no/wp-content/uploads/2017/10/watchout-rapport-october-2017.pdf
#1yrago Imperfections in your Bluetooth beacons allow for unstoppable tracking https://pluralistic.net/2021/10/21/sidechannels/#ble-eding
Colophon (permalink)
Today's top sources: Bruce Schneier (https://www.schneier.com/blog/).
Currently writing:
- The Bezzle, a Martin Hench noir thriller novel about the prison-tech industry. Yesterday's progress: 540 words (52454 words total)
-
The Internet Con: How to Seize the Means of Computation, a nonfiction book about interoperability for Verso. Yesterday's progress: 502 words (48755 words total)
-
Picks and Shovels, a Martin Hench noir thriller about the heroic era of the PC. (92849 words total) – ON PAUSE
-
A Little Brother short story about DIY insulin PLANNING
-
Vigilant, Little Brother short story about remote invigilation. FIRST DRAFT COMPLETE, WAITING FOR EXPERT REVIEW
-
Moral Hazard, a short story for MIT Tech Review's 12 Tomorrows. FIRST DRAFT COMPLETE, ACCEPTED FOR PUBLICATION
-
Spill, a Little Brother short story about pipeline protests. FINAL DRAFT COMPLETE
-
A post-GND utopian novel, ""The Lost Cause."" FINISHED
-
A cyberpunk noir thriller novel, ""Red Team Blues."" FINISHED
Currently reading: Analogia by George Dyson.
Latest podcast: Sound Money https://craphound.com/news/2022/09/11/sound-money/
Upcoming appearances:
- Chokepoint Capitalism Event, Argo Bookshop (Montreal), Oct 23
https://www.eventbrite.ca/e/cory-doctorow-at-the-argo-bookshop-tickets-430453747747
-
Surviving Apocalyptic Economics, with Douglas Rushkoff and Rebecca Giblin, Ottawa Writers Festival, Oct 24
https://writersfestival.org/events/fall-2022-in-person-events/surviving-apocalyptic-economics
-
Launch for Chelsea Manning's ""Readme.txt: A Memoir"" (Bookshop.org), Oct 26:
https://xychelsea.tv/#event-bookshop-org
-
World Ethical Data Forum, Oct 26-28
https://worldethicaldataforum.org/
-
Radical Book Fair/Lighthouse Bookshop (Edinburgh), Nov 10
https://lighthousebookshop.com/events/chokepoint-capitalism-cory-doctorow-and-rebecca-giblin
-
Arthur C Clarke Award (DC), Nov 16
https://www.clarkefoundation.org/2022-awards-event/
-
Big Ideas Live (London), Nov 19
https://news.sky.com/bigideaslive
Recent appearances:
- The Literary Life with Mitchell Kaplan (Lithub)
https://lithub.com/cory-doctorow-why-our-current-tech-monopolies-is-all-thanks-to-ronald-reagan-and-robert-bork/
-
Sex and Politics with Dan Savage (use coupon code ""Doctorow"" for a free month):
https://index.supportingcast.fm/subscription/type/podcast#c3f7380e-441b-11ed-8f80-1f06b0646875
-
Regulating the Online Public Sphere (Columbia Global Freedom of Expression)
https://youtu.be/0YsnGkFG7o8?t=8412
Latest books:
- ""Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin"", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com
-
""Attack Surface"": The third Little Brother novel, a standalone technothriller for adults. The Washington Post called it ""a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance."" Order signed, personalized copies from Dark Delicacies https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html
-
""How to Destroy Surveillance Capitalism"": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59 (print edition: https://bookshop.org/books/how-to-destroy-surveillance-capitalism/9781736205907) (signed copies: https://www.darkdel.com/store/p2024/Available_Now%3A__How_to_Destroy_Surveillance_Capitalism.html)
-
""Little Brother/Homeland"": A reissue omnibus edition with a new introduction by Edward Snowden: https://us.macmillan.com/books/9781250774583; personalized/signed copies here: https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html
-
""Poesy the Monster Slayer"" a picture book about monsters, bedtime, gender, and kicking ass. Order here: https://us.macmillan.com/books/9781626723627. Get a personalized, signed copy here: https://www.darkdel.com/store/p2682/Corey_Doctorow%3A_Poesy_the_Monster_Slayer_HB.html#/.
Upcoming books:
- Red Team Blues: ""A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before."" Tor Books, April 2023
This work licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.
https://creativecommons.org/licenses/by/4.0/
Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.
How to get Pluralistic:
Blog (no ads, tracking, or data-collection):
Newsletter (no ads, tracking, or data-collection):
https://pluralistic.net/plura-list
Mastodon (no ads, tracking, or data-collection):
https://mamot.fr/web/accounts/303320
Medium (no ads, paywalled):
https://doctorow.medium.com/
(Latest Medium column: ""Unspeakable: Big-Tech-as-cop vs. abolishing Big Tech""> https://doctorow.medium.com/unspeakable-8c7bbd4974bc)
Twitter (mass-scale, unrestricted, third-party surveillance and advertising):
https://twitter.com/doctorow
Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):
https://mostlysignssomeportents.tumblr.com/tagged/pluralistic
""When life gives you SARS, you make sarsaparilla"" -Joey ""Accordion Guy"" DeVilla",3
443,"China’s growing number of insomniacs are turning to businesses providing services that put them to sleep, literally.
Services offering one-on-one chats with people known as “sleeping assistants” have gained popularity on Chinese e-commerce platform Taobao, with some charging tens of thousands of yuan for a monthly subscription, domestic media outlet Xiaoxiang Morning Herald reported Friday. A search on Taobao using the keyword “sleeping assistant” showed hundreds of accounts, many with anime-like profile photos, offering 15-minute chats via texts and voice messages for as little as 5 yuan ($0.5).
China has become a nation of insomniacs, with more than 300 million people suffering from sleep disorders, according to a 2021 report by the Chinese Sleep Research Society. This year’s report showed that the country’s youngsters, including college students, young professionals, and new mothers, were among the groups that have suffered the most from insomnia due to increasing pressure.
The sleep assistants, mostly advertised as young and good-looking men and women in their online profiles, interact with their clients through voice calls to help them prepare for bedtime, according to their job descriptions. A Taobao retailer told Sixth Tone that they charged 10 yuan for a 15-minute chat via text or voice message with entry-level assistants to 33,440 yuan per month for sessions with their top assistants.
A screenshot shows ‘sleeping assistants’ providing services on Taobao.
“The assistants will talk about random things with the clients or read a bedtime story depending on the clients’ preference,” said the Taobao retailer.
Many sleep-deprived young Chinese have already been resorting to various types of autonomous sensory meridian response, better known as ASMR, to help them sleep. However, China’s anti-porn authorities have cracked down on such content, saying some sounds that intended to soothe the senses were likely to be arousing.
Businesses capitalizing on the country’s sleep-deprived individuals are also offering a range of other products, including sleeping apps, smart devices, sleep syrups, and candles. The industry has also been coined as the “sleep economy” and is estimated to be worth 1 trillion yuan by 2030.
Many Taobao users who used the sleeping assistant service said in the respective comment sections of the retailers that the assistants were “super nice” and helpful in cheering them up. They said some assistants sang to them and read bedtime stories while others provided a listening ear to their problems.
“Chizi is such a gentle girl,” commented a user named Ningmeng CC on a Taobao store, referring to the sleep assistant. “I feel bad that I was a little mean to her after getting drunk, but she patiently answered all the questions about my recent relationship.”
Editor: Bibek Bhandari.
(Header image: VCG)",6
444,"The newest Kindle is the first truly new Kindle in years. It’s called the Kindle Scribe, and it’s both a reading device and a writing one. With a 10.2-inch E Ink screen, a stylus that attaches to the side of the device, and a bunch of new software, the $339.99 Scribe is trying to be as much a tablet as an ebook reader. It’s available for preorder today, and Amazon promises it’ll be out before the holidays. It’s also the kind of device people have been waiting for Amazon to make for years.
Kevin Keith, a vice president of product and marketing at Amazon, says the display is the reason the Scribe took so long. “This is the first 300ppi, front-lit display that has an adjustable warm light,” he says over Amazon’s Chime conferencing system, holding the Scribe up to the camera. “And that makes sure it doesn’t have any compromise between the reading and writing experience.” Historically, bigger E Ink displays have meant lower resolution. The Scribe has the Kindle’s typical contrast and clarity, he says, while still adding all the tech necessary to make the whole surface possible to write on.
Ultimately, how the Scribe’s writing experience works and feels is the biggest question about this device. You can buy it with one of two stylus options: a “Basic Pen” or a “Premium Pen” for $30 more that also includes a customizable shortcut button and an eraser sensor on the top. Both use the same Wacom EMR technology and magnetically attach to the side of the Scribe but don’t have batteries or need to be charged.
Amazon built new note-taking capabilities into its reader so you can tap on a passage and scribble a note, similar to the way you’d highlight or type a note on the on-screen keyboard. Those handwritten notes are stored in your Kindle collection along with everything else. One of the biggest knocks against ebook readers has been that they don’t support marginalia, the quick reactions and scribbles that so many bookish types like to leave on their pages; the Scribe brings a lot of that back. The bigger screen should also make images and charts easier to work with. A color E Ink screen would be even better, but that’s apparently for a future Kindle.
The device also supports PDF markup and can display saved webpages and other file formats. Amazon even partnered with Microsoft to put a button into Word that’ll let you export a document right to your Kindle. “The whole idea is, over time, we want to make sure that that’s in your natural workflow,” Keith says. Amazon’s document-sending features haven’t been particularly useful in the past, but Keith says the team is working on making it easier to get all your stuff on and off the Scribe. Right now, you won’t be able to see your notes in the Kindle app on other devices, but Amazon says that’s coming soon.
The Scribe borrows its asymmetric design from the Kindle Oasis, with that chunky bezel on one side meant as a hand-hold; one hand on the device and one on your pen seems to be how Amazon imagines most people using the Scribe. It’s 5.8mm thick and weighs 430g, which makes it a little thinner and a little lighter than the most recent iPad Air. (It’s also almost exactly the same size as the $479 Boox Note Air2, though that tablet doesn’t have as high a resolution screen.)
The comparison to the iPad Air is a useful one, actually. The iPad is obviously a dramatically more capable device: it has millions of apps, a web browser, and a screen that can show videos and games. It also measures its battery life in hours. Amazon measures the Scribe’s in weeks and hopes that it can entice users with a distraction-free device for reading and taking notes over one that seems to be mostly a tool for endless distraction. Amazon could have opted to use the Android-based software that powers the Fire tablets in this device, but Keith says that, then, it would no longer be a Kindle. “What makes a Kindle special is this distraction-free environment and the battery life,” he says.
About the battery life: it sounds like your experience will depend on how much you write. Amazon says the Scribe will last 12 weeks based on a half-hour of reading a day but just three weeks based on a half-hour of writing every day. The difference is most likely due to the Scribe’s screen having to refresh far more often to show your scribbles, and it means heavy writers may not get the weeks of battery Amazon advertises. My colleague Alex Cranz says she gets one to two weeks out of her Boox Note Air, so that may be a good barometer here, too.
The formula works, at least for some users. The reMarkable 2 is a solid E Ink tablet with plenty of devoted users, and more powerful Android-powered devices from companies like Boox are becoming more popular as well. Even Kobo beat Amazon to the E Ink writing-and-reading tablet game with the Sage and the Elipsa.
Amazon is trying to give the Scribe more power, though, and trying to figure out what’s cool about a more interactive Kindle. Maybe the Scribe could be a place to do crosswords, Keith says. The company already built a bunch of notebook templates, so you can scribble out a to-do list or write meeting notes on the Scribe. And he hints that there are altogether new kinds of books and documents that could be made for a bigger screen and a pen.
So far, my only experience of the Scribe is through Keith’s webcam, so all I can say is it looks an awful lot like a blown-up Kindle Oasis — which is mostly a good thing. The one-sided bezel was controversial at first, but it does make the device easy to hold in both hands. Keith scribbled a quick note for me on the screen, and if there was any input lag as the E Ink screen refreshed, I couldn’t see it.
Amazon has said for years that the end goal for the Kindle is to be like paper: just as malleable, just as versatile, and just as pleasant to look at and interact with. (Keith even said Amazon has worked to tune the sound the Scribe’s screen makes when you write on it, so it sounds more like you’re scribbling on paper.) The Scribe is still very much a Kindle, but it pushes Amazon’s ebook reader lineup a bit closer toward replicating all the things you can do with a physical book. Paper’s battery still lasts longer, though, so Amazon’s got some work left to do.",2
445,"Access Check
Our systems have detected unusual traffic activity from your network. Please complete this reCAPTCHA to demonstrate that it's you making the requests and not a robot. If you are having trouble seeing or completing this challenge, this page may help. If you continue to experience issues, you can contact JSTOR support.
Block Reference: #49cb0d02-78c8-11ed-a87e-4149476d694f
VID: #
IP: 88.138.237.237
Date and time: Sat, 10 Dec 2022 20:21:54 GMT",2
